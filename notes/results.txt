-------------------------------------------------------------------------------
PARITY
-------------------------------------------------------------------------------
arch vanilla seq_len 5 training_epochs 10000

mean accuracy 0.930313
indiv runs  [1.0, 1.0, 0.96875, 1.0, 1.0, 0.53125, 0.90625, 1.0, 1.0, 0.96875, 1.0, 0.96875, 0.90625, 0.96875, 0.96875, 1.0, 0.96875, 0.90625, 0.9375, 1.0, 0.96875, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.96875, 1.0, 0.96875, 1.0, 1.0, 0.90625, 1.0, 0.53125, 0.96875, 0.53125, 1.0, 1.0, 1.0, 0.71875, 1.0, 0.65625, 1.0, 0.96875, 0.53125, 0.875, 0.96875, 0.96875, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0, 0.53125, 1.0, 0.96875, 1.0, 1.0, 0.90625, 1.0, 1.0, 1.0, 1.0, 0.84375, 1.0, 1.0, 1.0, 1.0, 0.96875, 1.0, 1.0, 1.0, 0.71875, 0.96875, 0.96875, 0.96875, 1.0, 0.90625, 1.0, 0.8125, 1.0, 1.0, 0.71875, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.53125, 0.53125, 1.0, 0.96875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
mean epoch 2972.92982456
indiv epochs  [2601, 8801, 3801, 1201, 2001, 2201, 9601, 7201, 1001, 6201, 801, 1401, 1001, 6201, 1401, 1001, 2001, 4401, 1001, 3401, 6201, 601, 601, 801, 5201, 1801, 1001, 5401, 7001, 1001, 4801, 4601, 2001, 2601, 1601, 1001, 3201, 8001, 801, 1001, 2201, 1401, 1001, 1201, 3201, 3801, 4001, 5201, 3601, 3801, 1801, 401, 1801, 1201, 5001, 1001, 2401]


RESULTS WITH ATTRACTOR NET and TANH RNN ("vanilla")

arch tanh SEQ_LEN 5 training_epochs 10000 noise_level 0.25 n_attr_steps 5
lrate prediction 0.008  lrate attractor  0.008
mean accuracy 0.978125
indiv runs  [1.0, 1.0, 1.0, 1.0, 0.9375, 1.0, 0.96875, 1.0, 1.0, 0.96875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9375, 0.84375, 0.75, 0.96875, 1.0, 0.96875, 1.0, 0.96875, 0.96875, 1.0, 0.84375, 1.0, 0.96875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.96875, 1.0, 0.9375, 1.0, 0.9375, 1.0, 0.96875, 0.96875, 0.9375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.96875, 1.0, 0.96875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.96875, 1.0, 1.0, 1.0, 0.84375, 1.0, 0.90625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.96875, 0.90625, 1.0, 1.0, 1.0, 1.0, 0.8125, 0.96875, 1.0, 0.96875, 1.0, 1.0, 1.0, 0.96875, 0.96875, 1.0, 1.0, 1.0, 0.78125, 1.0, 1.0, 1.0]
mean epoch 2079.26086957
indiv epochs  [3601, 8001, 10001, 4001, 601, 801, 2001, 1201, 201, 1201, 1601, 801, 3001, 1001, 401, 1401, 7201, 4801, 2601, 801, 601, 1801, 1401, 3201, 401, 1401, 3401, 801, 601, 1001, 4601, 1001, 2201, 601, 401, 801, 3601, 1401, 4001, 1001, 401, 1401, 601, 9801, 3601, 4801, 1001, 801, 2401, 601, 801, 201, 601, 601, 601, 801, 3201, 5401, 2201, 801, 401, 1201, 401, 8401, 801, 201, 401, 1001, 601]


Attractor dynamics trained based on prediction error

Namespace(arch='tanh', attractor_train_delay=100, display_epoch=200, lrate_attractor=0.0, lrate_prediction=0.008, n_attractor_steps=5, n_hidden=5, n_replications=100, noise_level=0.25, seq_len=5, task='parity', train_attr_weights_on_prediction=True, training_epochs=10000)
********************************************************************
mean train accuracy 0.7575
indiv runs  [1.0, 0.5, 1.0, 0.53125, 1.0, 0.6875, 1.0, 0.71875, 0.625, 0.5, 0.625, 1.0, 0.5, 0.875, 0.5, 1.0, 0.5, 0.5, 0.625, 0.53125, 0.53125, 0.6875, 1.0, 0.53125, 0.5, 0.53125, 0.53125, 1.0, 0.5, 1.0, 1.0, 0.5, 0.5, 0.5, 1.0, 0.5, 1.0, 1.0, 0.96875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6875, 1.0, 0.53125, 0.71875, 1.0, 0.5, 1.0, 0.6875, 0.53125, 0.53125, 1.0, 0.8125, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.65625, 1.0, 1.0, 0.53125, 0.5, 1.0, 1.0, 0.5, 0.75, 0.78125, 1.0, 0.59375, 0.53125, 0.65625, 0.5, 0.5, 0.75, 0.90625, 0.5, 0.5, 1.0, 0.53125, 0.5, 0.625, 0.5, 0.5625, 0.5, 0.65625, 1.0, 1.0, 0.71875, 0.5, 1.0, 1.0]
mean epoch 1425.3902439
indiv epochs  [2801, 3601, 201, 2001, 201, 201, 8601, 201, 201, 601, 201, 201, 201, 3201, 401, 8001, 201, 401, 401, 201, 401, 5401, 401, 801, 201, 801, 601, 3601, 201, 1201, 601, 601, 1001, 401, 2801, 601, 3401, 1401, 201, 201, 1601]
mean test accuracy 0.0
indiv runs  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]


-------------------------------------------------------------------------------
MAJORITY SIMULATIONS
-------------------------------------------------------------------------------

NO ATTRACTORS
********************************************************************
Namespace(arch='tanh', attractor_train_delay=100, display_epoch=100, lrate_attractor=0.002, lrate_prediction=0.002, n_attractor_steps=0, n_hidden=5, n_replications=100, noise_level=0.25, seq_len=12, task='majority', training_epochs=2500)
********************************************************************
mean train accuracy 0.992813
indiv runs  [1.0, 0.953125, 1.0, 1.0, 1.0, 0.84375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.90625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.96875, 0.984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.96875, 0.953125, 1.0, 1.0, 1.0, 0.9375, 1.0, 1.0, 1.0, 0.921875, 1.0, 1.0, 1.0, 1.0, 0.96875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.96875, 1.0, 1.0, 1.0, 0.921875, 1.0, 1.0, 1.0, 0.984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
mean epoch 540.08045977
indiv epochs  [301, 601, 201, 201, 301, 701, 1101, 701, 201, 301, 201, 501, 601, 801, 1101, 501, 301, 301, 601, 701, 401, 701, 801, 801, 201, 2001, 201, 401, 401, 501, 401, 301, 401, 401, 401, 501, 801, 201, 201, 401, 1001, 501, 2201, 1001, 501, 2101, 201, 201, 201, 301, 401, 401, 901, 401, 401, 201, 801, 201, 201, 201, 301, 401, 401, 301, 401, 401, 401, 1301, 601, 501, 301, 301, 301, 401, 601, 201, 601, 301, 501, 1201, 1901, 201, 301, 501, 601, 501, 301]
mean test accuracy 0.864586
indiv runs  [0.93303573, 0.80505955, 0.8732639, 0.89508927, 0.94915676, 0.51041669, 0.86235118, 0.94717264, 0.84052581, 0.94866073, 0.88640875, 0.93998015, 0.89930558, 0.83680558, 0.84722221, 0.83333331, 0.87400794, 0.91145831, 0.91914684, 0.87872022, 0.81349206, 0.81051588, 0.91418654, 0.92807537, 0.88442463, 0.56994045, 0.91220236, 0.91493058, 0.76190478, 0.91716272, 0.89880955, 0.93725199, 0.92162699, 0.9464286, 0.91765875, 0.94345236, 0.90724206, 0.8660714, 0.90897816, 0.87152779, 0.88690478, 0.87127978, 0.91493058, 0.8660714, 0.95882934, 0.81175596, 0.890625, 0.86235118, 0.82390875, 0.87351191, 0.86954367, 0.88144839, 0.94543654, 0.88467264, 0.82266867, 0.91964287, 0.52281743, 0.6857639, 0.91716272, 0.93278772, 0.84027779, 0.52405757, 0.9375, 0.95114088, 0.85863096, 0.53670633, 0.92063493, 0.89831346, 0.96155757, 0.86483133, 0.56870037, 0.87276787, 0.93898809, 0.90079367, 0.89806545, 0.96279764, 0.90401787, 0.89459324, 0.92509919, 0.88095236, 0.86061507, 0.8856647, 0.92485118, 0.92832339, 0.51835316, 0.90699404, 0.92906743, 0.91964287, 0.58134919, 0.93998015, 0.8973214, 0.85019839, 0.8330853, 0.89211309, 0.92509919, 0.87723213, 0.85615081, 0.93055558, 0.91369045, 0.96875]


ATTRACTORS
********************************************************************
Namespace(arch='tanh', attractor_train_delay=100, display_epoch=100, lrate_attractor=0.002, lrate_prediction=0.002, n_attractor_steps=5, n_hidden=5, n_replications=100, noise_level=0.25, seq_len=12, task='majority', training_epochs=2500)
********************************************************************
mean train accuracy 0.994844
indiv runs  [1.0, 1.0, 1.0, 0.984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.96875, 1.0, 1.0, 1.0, 0.984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.984375, 1.0, 1.0, 1.0, 0.984375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.96875, 1.0, 1.0, 0.9375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.921875, 1.0, 0.859375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.984375, 1.0, 0.9375, 1.0, 1.0, 1.0, 0.984375, 1.0, 1.0, 1.0]
mean epoch 697.551724138
indiv epochs  [301, 2001, 601, 301, 701, 401, 501, 501, 601, 301, 1301, 601, 301, 401, 801, 601, 701, 201, 401, 301, 901, 601, 1501, 301, 401, 701, 801, 201, 201, 201, 601, 801, 801, 701, 201, 401, 601, 401, 901, 701, 401, 1901, 401, 801, 301, 301, 201, 801, 801, 701, 701, 401, 801, 701, 601, 201, 401, 601, 601, 601, 201, 501, 2201, 801, 1301, 901, 1101, 1001, 301, 401, 1301, 601, 501, 401, 601, 801, 1601, 1001, 801, 401, 801, 2201, 2201, 201, 1801, 501, 301]
mean test accuracy 0.902617
indiv runs  [0.94221228, 0.94196427, 0.91443455, 0.82465279, 0.91840279, 0.94072419, 0.92931545, 0.87425596, 0.93551588, 0.9754464, 0.94270831, 0.76488096, 0.92881942, 0.91840279, 0.95213294, 0.90153772, 0.88665676, 0.90029764, 0.89136904, 0.8923611, 0.91021824, 0.90376985, 0.97445434, 0.95213294, 0.92038691, 0.93129963, 0.86334324, 0.890625, 0.88368058, 0.93799603, 0.90600199, 0.96974206, 0.89682537, 0.97842264, 0.93675596, 0.89484125, 0.8973214, 0.88343257, 0.93278772, 0.88764882, 0.95610118, 0.93427581, 0.89980161, 0.94990081, 0.91468257, 0.98859125, 0.85119045, 0.88715279, 0.91617066, 0.93353176, 0.85515875, 0.9704861, 0.96453375, 0.87599206, 0.9308036, 0.89781743, 0.59325397, 0.92509919, 0.95014882, 0.51537699, 0.92336309, 0.85515875, 0.96825397, 0.90972221, 0.94866073, 0.78645831, 0.91269839, 0.89533728, 0.91393846, 0.8767361, 0.87475199, 0.6200397, 0.95238096, 0.89583331, 0.90079367, 0.94568455, 0.93998015, 0.97222221, 0.90153772, 0.88740081, 0.79786706, 0.91319442, 0.87872022, 0.90376985, 0.98487103, 0.91617066, 0.97792661, 0.89831346, 0.89459324, 0.97098213, 0.98363096, 0.94990081, 0.5329861, 0.98660713, 0.86160713, 0.90228176, 0.97594243, 0.90525794, 0.95238096, 0.95585316]

ATTRACTOR TRAINED ON PREDICTION TASK

Namespace(arch='tanh', attractor_train_delay=100, display_epoch=100, lrate_attractor=0.0, lrate_prediction=0.002, n_attractor_steps=5, n_hidden=5, n_replications=100, noise_level=0.25, seq_len=12, task='majority', train_attr_weights_on_prediction=True, training_epochs=2500)
********************************************************************
mean train accuracy 0.945781
indiv runs  [1.0, 0.71875, 0.75, 1.0, 1.0, 0.859375, 1.0, 0.953125, 1.0, 1.0, 1.0, 1.0, 0.796875, 0.953125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.859375, 1.0, 1.0, 0.953125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.96875, 0.84375, 1.0, 1.0, 0.84375, 1.0, 1.0, 1.0, 0.90625, 0.890625, 1.0, 1.0, 0.90625, 0.96875, 0.96875, 0.75, 0.984375, 1.0, 1.0, 0.984375, 0.984375, 1.0, 0.796875, 0.921875, 0.796875, 1.0, 1.0, 0.984375, 0.984375, 1.0, 1.0, 1.0, 0.859375, 1.0, 1.0, 1.0, 1.0, 0.75, 0.890625, 1.0, 1.0, 1.0, 0.890625, 0.703125, 0.90625, 1.0, 0.9375, 1.0, 0.796875, 1.0, 1.0, 0.765625, 0.734375, 1.0, 0.9375, 0.828125, 1.0, 0.75, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.953125, 1.0, 0.828125]
mean epoch 734.898305085
indiv epochs  [501, 801, 201, 601, 1401, 301, 301, 1801, 301, 1401, 1401, 1001, 601, 401, 301, 101, 301, 401, 1201, 401, 1701, 1101, 401, 501, 201, 201, 401, 1401, 301, 901, 601, 1601, 901, 601, 2001, 401, 301, 1801, 1001, 301, 401, 301, 501, 201, 501, 201, 1701, 401, 501, 201, 2101, 301, 401, 901, 901, 1301, 301, 1701, 201]
mean test accuracy 0.823943
indiv runs  [0.89533728, 0.71403772, 0.61061507, 0.83829367, 0.93874007, 0.56001985, 0.89434522, 0.7705853, 0.8348214, 0.96750993, 0.84375, 0.85615081, 0.62301588, 0.82192463, 0.79637897, 0.90848213, 0.90178573, 0.82390875, 0.85119045, 0.76314485, 0.90749007, 0.93179566, 0.87400794, 0.94717264, 0.9620536, 0.92212301, 0.87202382, 0.92881942, 0.55704367, 0.93625993, 0.78745037, 0.88616073, 0.92311507, 0.88095236, 0.65575397, 0.89186507, 0.9169147, 0.69841272, 0.91344243, 0.87872022, 0.8504464, 0.62772816, 0.88219243, 0.91468257, 0.86036706, 0.81870037, 0.80952382, 0.85317463, 0.63814485, 0.88715279, 0.86259919, 0.8839286, 0.91468257, 0.82787699, 0.85639882, 0.703125, 0.69345236, 0.6736111, 0.8018353, 0.92757934, 0.8526786, 0.85739088, 0.89335316, 0.92633927, 0.89136904, 0.5691964, 0.88343257, 0.9268353, 0.93005955, 0.96230161, 0.62425596, 0.77752978, 0.92584324, 0.90476191, 0.88839287, 0.62177581, 0.49652779, 0.84771824, 0.80332339, 0.70386904, 0.91567463, 0.71750993, 0.91071427, 0.87251985, 0.73115081, 0.5848214, 0.91393846, 0.80431545, 0.60143846, 0.91443455, 0.55828375, 0.85887897, 0.85912699, 0.89682537, 0.91195434, 0.89409721, 0.87425596, 0.87475199, 0.92460316, 0.71527779]



-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
arch GRU SEQ_LEN 5 training_epochs 10000 noise_level 0.25 n_attr_steps 0
mean accuracy 0.998438
indiv runs  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.90625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.96875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.96875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
mean epoch 1805.12371134
indiv epochs  [2001, 9601, 1401, 2801, 1001, 1601, 1801, 5601, 1401, 1801, 1001, 801, 1201, 1401, 1001, 1201, 2201, 801, 1801, 601, 1801, 1601, 1601, 1601, 801, 1801, 4201, 601, 1001, 1201, 601, 1001, 801, 2001, 1601, 1801, 1401, 3001, 801, 1401, 3201, 2801, 2001, 1001, 1601, 401, 801, 601, 1201, 801, 1401, 601, 1801, 1201, 2601, 601, 2401, 2401, 801, 1001, 1801, 1801, 1401, 1601, 1201, 2001, 7201, 1001, 8601, 7601, 1601, 3601, 2601, 1201, 1001, 1001, 1401, 1201, 1801, 1801, 3601, 1401, 1601, 801, 1201, 1801, 2001, 601, 1201, 1401, 1201, 1401, 601, 1001, 1401, 801, 801]

arch GRU SEQ_LEN 5 training_epochs 10000 noise_level 0.25 n_attr_steps 3
mean accuracy 0.958438
indiv runs  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.96875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.53125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.96875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.65625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
mean epoch 1906.61797753
indiv epochs  [1601, 1201, 1201, 1801, 2801, 5801, 1001, 3201, 1201, 1401, 601, 801, 1801, 801, 801, 4801, 401, 1801, 2401, 5401, 801, 2001, 1201, 7601, 401, 1601, 1001, 1201, 2401, 401, 1401, 1601, 1201, 1601, 2201, 3601, 601, 1401, 1801, 1201, 3401, 3201, 801, 401, 601, 601, 801, 601, 7601, 1801, 3801, 401, 3801, 3601, 1401, 6801, 2201, 1801, 1001, 1001, 1201, 2001, 1201, 1601, 801, 1601, 801, 601, 4401, 2001, 1001, 3401, 1001, 2001, 1201, 801, 2601, 1601, 1801, 401, 601, 801, 801, 5001, 401, 3601, 3401, 801, 601]


arch vanilla SEQ_LEN 5 training_epochs 10000 noise_level 0.25 n_attr_steps 0
mean accuracy 0.9025
indiv runs  [0.9375, 0.75, 0.75, 1.0, 0.96875, 0.65625, 1.0, 0.96875, 0.96875, 0.71875, 0.96875, 0.96875, 0.9375, 1.0, 0.90625, 1.0, 0.96875, 0.75, 1.0, 0.65625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.96875, 1.0, 0.78125, 0.96875, 0.9375, 0.96875, 1.0, 1.0, 0.53125, 0.9375, 0.625, 1.0, 1.0, 0.96875, 0.8125, 1.0, 0.71875, 1.0, 0.96875, 0.65625, 0.53125, 0.96875, 1.0, 1.0, 1.0, 0.75, 0.53125, 1.0, 1.0, 0.53125, 1.0, 0.78125, 0.875, 1.0, 1.0, 1.0, 0.75, 1.0, 0.75, 1.0, 0.75, 0.53125, 0.96875, 0.9375, 1.0, 1.0, 0.96875, 0.96875, 1.0, 0.96875, 0.8125, 0.96875, 0.75, 0.90625, 1.0, 0.9375, 1.0, 0.96875, 0.96875, 0.53125, 1.0, 1.0, 1.0, 0.5625, 1.0, 0.8125, 0.96875, 1.0, 0.90625, 1.0, 0.96875, 1.0, 0.9375, 1.0, 0.96875]
mean epoch 2986.36585366
indiv epochs  [4601, 2201, 1601, 3801, 2801, 5801, 2401, 3001, 1001, 2001, 2601, 8201, 601, 4001, 6401, 1201, 4001, 5001, 1001, 2001, 1201, 2801, 8801, 2801, 2201, 1201, 3201, 3801, 2601, 801, 1001, 5401, 5601, 2201, 1801, 1401, 3201, 1401, 601, 4001, 2201]

arch vanilla SEQ_LEN 5 training_epochs 10000 noise_level 0.25 n_attr_steps 3
mean accuracy 0.914062
indiv runs  [0.9375, 1.0, 1.0, 0.75, 1.0, 0.59375, 1.0, 0.8125, 0.9375, 0.75, 0.96875, 0.90625, 0.96875, 1.0, 0.75, 1.0, 0.96875, 1.0, 1.0, 1.0, 0.90625, 1.0, 0.96875, 1.0, 1.0, 1.0, 0.8125, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.96875, 0.96875, 0.65625, 1.0, 1.0, 0.96875, 0.8125, 0.9375, 0.84375, 1.0, 0.96875, 0.53125, 0.75, 0.96875, 0.84375, 1.0, 1.0, 0.75, 1.0, 1.0, 0.8125, 0.53125, 1.0, 0.8125, 1.0, 0.53125, 1.0, 1.0, 1.0, 1.0, 0.90625, 0.65625, 0.75, 0.6875, 0.96875, 0.9375, 1.0, 1.0, 0.90625, 0.96875, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8125, 0.96875, 1.0, 0.8125, 0.90625, 1.0, 1.0, 1.0, 1.0, 0.75, 0.8125, 0.96875, 0.96875, 0.84375, 1.0, 0.96875, 1.0, 0.96875, 0.96875, 0.96875]
mean epoch 2935.7826087
indiv epochs  [9401, 2401, 2201, 1401, 3801, 3401, 1601, 9401, 2201, 2001, 801, 2601, 3001, 2401, 4401, 1201, 2601, 401, 1001, 5401, 2001, 1001, 601, 8601, 2801, 801, 8601, 1001, 801, 1801, 3001, 1601, 801, 4801, 5201, 9201, 1001, 1401, 1201, 2401, 1001, 7001, 801, 1201, 2601, 2201]


-------------------------------------------------------------------------------
Sat Nov 25 16:14:02 PST 2017
Two noise levels of attractor net training with 5 attractor steps -- beats out 
vanilla in both accuracy and # training epochs for success

arch tanh SEQ_LEN 5 training_epochs 10000 noise_level 0.25 n_attr_steps 5
lrate prediction LRATE_PREDICTION  lrate attractor  0.008
mean accuracy 0.947187
indiv runs  [1.0, 1.0, 0.9375, 0.53125, 1.0, 1.0, 0.65625, 1.0, 1.0, 1.0, 0.875, 0.9375, 0.53125, 0.96875, 1.0, 1.0, 0.84375, 1.0, 1.0, 0.84375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.65625, 1.0, 1.0, 0.96875, 1.0, 0.96875, 1.0, 0.96875, 1.0, 0.96875, 1.0, 1.0, 1.0, 0.53125, 1.0, 1.0, 1.0, 0.875, 0.96875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8125, 1.0, 1.0, 0.84375, 1.0, 1.0, 1.0, 1.0, 0.90625, 0.53125, 1.0, 0.96875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.65625, 1.0, 0.96875, 1.0, 0.90625, 0.96875, 0.96875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.53125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 0.96875, 0.96875, 1.0, 1.0, 0.96875]
mean epoch 1289.23529412
indiv epochs  [401, 601, 401, 201, 401, 601, 601, 2601, 801, 201, 401, 1001, 1601, 6401, 201, 201, 1201, 201, 401, 401, 401, 401, 3201, 801, 201, 3001, 2201, 201, 3401, 2401, 601, 1401, 201, 2601, 601, 401, 401, 2001, 2401, 401, 401, 601, 3801, 801, 801, 601, 1601, 1001, 201, 1601, 201, 201, 601, 401, 201, 201, 401, 1401, 7201, 2001, 2401, 401, 8801, 601, 601, 201, 601, 3801]

arch tanh SEQ_LEN 5 training_epochs 10000 noise_level 0.125 n_attr_steps 5
lrate prediction LRATE_PREDICTION  lrate attractor  0.008
mean accuracy 0.945625
indiv runs  [1.0, 0.96875, 1.0, 0.53125, 1.0, 1.0, 0.65625, 1.0, 1.0, 1.0, 0.53125, 0.9375, 0.53125, 0.96875, 1.0, 1.0, 0.84375, 1.0, 1.0, 0.84375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.53125, 1.0, 1.0, 1.0, 0.96875, 0.53125, 1.0, 1.0, 1.0, 0.96875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.53125, 1.0, 1.0, 1.0, 0.90625, 0.9375, 1.0, 1.0, 1.0, 0.96875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.84375, 1.0, 1.0, 1.0, 0.96875, 0.90625, 1.0, 1.0, 0.96875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.65625, 0.9375, 0.96875, 1.0, 1.0, 0.96875, 0.96875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.53125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6875, 1.0, 1.0, 1.0, 1.0, 1.0]
mean epoch 1578.77777778
indiv epochs  [801, 1401, 401, 201, 801, 801, 601, 1201, 601, 801, 401, 1401, 1401, 2601, 401, 201, 9201, 4201, 2801, 1201, 801, 1001, 3001, 801, 7201, 401, 4201, 601, 201, 1001, 601, 1601, 2401, 201, 1201, 401, 201, 801, 1601, 3001, 401, 3201, 401, 5401, 2801, 401, 601, 1401, 401, 201, 201, 601, 201, 401, 401, 201, 201, 401, 1201, 9201, 4201, 401, 1601, 2201, 601, 601, 401, 401, 9801, 1001, 801, 801]

update frequency 5
arch tanh SEQ_LEN 5 training_epochs 10000 noise_level 0.25 n_attr_steps 5
lrate prediction LRATE_PREDICTION  lrate attractor  0.008
mean accuracy 0.94875
indiv runs  [1.0, 1.0, 0.96875, 1.0, 1.0, 1.0, 0.65625, 1.0, 1.0, 1.0, 0.53125, 0.625, 0.53125, 0.96875, 1.0, 1.0, 0.8125, 1.0, 1.0, 0.84375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.90625, 0.53125, 1.0, 0.65625, 1.0, 1.0, 1.0, 1.0, 0.9375, 0.96875, 0.84375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.53125, 1.0, 1.0, 1.0, 0.96875, 0.96875, 1.0, 1.0, 1.0, 0.96875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.96875, 1.0, 1.0, 1.0, 1.0, 0.8125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.65625, 1.0, 1.0, 1.0, 0.9375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.53125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9375, 1.0, 0.90625, 1.0, 0.90625, 1.0, 1.0, 1.0, 1.0, 1.0]
mean epoch 1449.64864865
indiv epochs  [401, 801, 3001, 401, 201, 801, 801, 601, 801, 601, 201, 401, 801, 801, 9801, 201, 201, 401, 1201, 401, 2401, 401, 801, 3201, 401, 1801, 601, 201, 801, 2201, 401, 1801, 201, 801, 401, 201, 5201, 2001, 4001, 401, 3801, 401, 2601, 1001, 1801, 601, 401, 1601, 1801, 401, 201, 2401, 2001, 201, 2201, 2001, 201, 801, 401, 401, 401, 401, 1601, 10001, 801, 801, 1601, 601, 3801, 401, 8801, 601, 601, 601]



-------------------------------------------------------------------------------
integrated objective function: denoising + prediction
varying lambda

arch vanilla SEQ_LEN 5 training_epochs 10000 noise_level 0.25 n_attr_steps 3 
lambda 0.08 mean accuracy 0.91375
lambda 0.04 mean accuracy 0.913125
lambda 0.01 mean accuracy 0.91
lambda 0.02 mean accuracy 0.91375
lambda 0.0  mean accuracy 0.92375
-------------------------------------------------------------------------------

testing attractor net (attractor_test.py)
10 replications, mean test relative distance 

unconstrained + h_out=W*tanh(h_net)+b	0.288803
zero diagonal + h_out=W*tanh(h_net)+b	0.311553
symmetry + h_out=W*tanh(h_net)+b	0.392045
0diag+symm + h_out=W*tanh(h_net)+b	0.430753
unconstrained + h_out=tanh(W*h_net+b)	0.490302
0diag+symm + h_out=tanh(W*h_net+b) 	0.577489
0diag+symm + h_out=tanh(h_net)      	0.979404
  

final xform = linear transform of [-1,+1] scaled output
-------------------------------------------------------------------------------

MIKE: try different variants of attractor net
- lose symmetry and diag zeros
- add linear transform after net
- add bias to internal dynamics
MIKE: allow attractor weights to be trained by prediction objective?
MIKE: specify schedule of updating:  P, A, or B-both
   e.g., PPPPPPPPPPAAAAAAAAAA [and then repeat]


-------------------------------------------------------------------------------
Running Reber

