Namespace(arch='tanh', batch_size=256, display_epoch=100, early_stop=True, input_noise_level=0.15, latent_attractor_space=True, loss_switch_frequency=0, lrate_attractor=0.002, lrate_prediction=0.002, lrate_wt_penalty=0.0, n_attractor_hidden=20, n_attractor_steps=5, n_hidden=10, n_replications=100, noise_level=0.25, report_best_train_performance=True, seq_len=30, task='majority', train_attr_weights_on_prediction=True, training_epochs=2500)
TRAINING ON 100 EXAMPLES, TESTING ON 3996
********** replication  0  **********
epoch   0 LossPred 1.2303 LossAtt 1.0253 TrainAcc 0.4700 TestAcc 0.5098 0.4800
epoch 100 LossPred 0.9303 LossAtt 0.6658 TrainAcc 0.6200 TestAcc 0.5335 0.6350
epoch 200 LossPred 0.8339 LossAtt 0.9703 TrainAcc 0.7000 TestAcc 0.5223 0.6950
epoch 300 LossPred 0.6924 LossAtt 0.9409 TrainAcc 0.7900 TestAcc 0.5255 0.7450
epoch 400 LossPred 0.5862 LossAtt 0.8847 TrainAcc 0.8300 TestAcc 0.5220 0.7600
epoch 500 LossPred 0.5465 LossAtt 0.7825 TrainAcc 0.8400 TestAcc 0.5290 0.7450
epoch 600 LossPred 0.5215 LossAtt 0.7396 TrainAcc 0.8500 TestAcc 0.5315 0.7700
epoch 700 LossPred 0.4574 LossAtt 0.6709 TrainAcc 0.8900 TestAcc 0.5388 0.7850
epoch 800 LossPred 0.4644 LossAtt 0.6404 TrainAcc 0.8900 TestAcc 0.5310 0.7650
epoch 900 LossPred 0.4221 LossAtt 0.6303 TrainAcc 0.9000 TestAcc 0.5328 0.7800
epoch 1000 LossPred 0.4282 LossAtt 0.6338 TrainAcc 0.9000 TestAcc 0.5400 0.7700
epoch 1100 LossPred 0.3556 LossAtt 0.6300 TrainAcc 0.9200 TestAcc 0.5348 0.7800
epoch 1200 LossPred 0.3344 LossAtt 0.6347 TrainAcc 0.9200 TestAcc 0.5370 0.7600
epoch 1300 LossPred 0.3174 LossAtt 0.6427 TrainAcc 0.9200 TestAcc 0.5428 0.7650
epoch 1400 LossPred 0.3152 LossAtt 0.6602 TrainAcc 0.9300 TestAcc 0.5428 0.7550
epoch 1500 LossPred 0.7240 LossAtt 0.9138 TrainAcc 0.7500 TestAcc 0.5330 0.7700
epoch 1600 LossPred 0.3620 LossAtt 0.6281 TrainAcc 0.9000 TestAcc 0.5308 0.8050
epoch 1700 LossPred 0.2930 LossAtt 0.6303 TrainAcc 0.9200 TestAcc 0.5363 0.8050
epoch 1800 LossPred 0.2726 LossAtt 0.6060 TrainAcc 0.9200 TestAcc 0.5385 0.7950
epoch 1900 LossPred 0.2631 LossAtt 0.6068 TrainAcc 0.9300 TestAcc 0.5408 0.7900
epoch 2000 LossPred 0.3426 LossAtt 0.6255 TrainAcc 0.9100 TestAcc 0.5375 0.7850
epoch 2100 LossPred 0.2959 LossAtt 0.6173 TrainAcc 0.9300 TestAcc 0.5385 0.7900
epoch 2200 LossPred 0.2590 LossAtt 0.6049 TrainAcc 0.9300 TestAcc 0.5378 0.7850
epoch 2300 LossPred 0.2501 LossAtt 0.5964 TrainAcc 0.9300 TestAcc 0.5405 0.7950
epoch 2400 LossPred 0.2447 LossAtt 0.6071 TrainAcc 0.9400 TestAcc 0.5415 0.8000
epoch 2500 LossPred 0.3763 LossAtt 0.6272 TrainAcc 0.8800 TestAcc 0.5378 0.7900
Optimization Finished!
********** replication  1  **********
epoch   0 LossPred 1.0663 LossAtt 1.0419 TrainAcc 0.5100 TestAcc 0.5470 0.5050
epoch 100 LossPred 0.8840 LossAtt 0.7819 TrainAcc 0.6400 TestAcc 0.6106 0.6350
epoch 200 LossPred 0.4826 LossAtt 0.6886 TrainAcc 0.8300 TestAcc 0.8116 0.8250
epoch 300 LossPred 0.3785 LossAtt 0.5084 TrainAcc 0.8800 TestAcc 0.7960 0.8250
epoch 400 LossPred 0.3585 LossAtt 0.4813 TrainAcc 0.8800 TestAcc 0.7968 0.8300
epoch 500 LossPred 0.3520 LossAtt 0.4725 TrainAcc 0.8800 TestAcc 0.7985 0.8300
epoch 600 LossPred 0.3500 LossAtt 0.4770 TrainAcc 0.8800 TestAcc 0.8026 0.8450
epoch 700 LossPred 0.3482 LossAtt 0.5187 TrainAcc 0.8800 TestAcc 0.8108 0.8500
epoch 800 LossPred 0.3481 LossAtt 0.4682 TrainAcc 0.8800 TestAcc 0.8018 0.8550
epoch 900 LossPred 0.3358 LossAtt 0.4582 TrainAcc 0.9100 TestAcc 0.7950 0.8450
epoch 1000 LossPred 0.3638 LossAtt 0.4676 TrainAcc 0.8700 TestAcc 0.8061 0.8550
epoch 1100 LossPred 0.4434 LossAtt 0.5152 TrainAcc 0.8700 TestAcc 0.7973 0.8200
epoch 1200 LossPred 0.3278 LossAtt 0.4477 TrainAcc 0.9000 TestAcc 0.7950 0.8600
epoch 1300 LossPred 0.3400 LossAtt 0.4336 TrainAcc 0.8900 TestAcc 0.8011 0.8600
epoch 1400 LossPred 0.3497 LossAtt 0.4233 TrainAcc 0.9000 TestAcc 0.8003 0.8550
epoch 1500 LossPred 0.3183 LossAtt 0.4290 TrainAcc 0.8900 TestAcc 0.7988 0.8750
epoch 1600 LossPred 0.3193 LossAtt 0.4451 TrainAcc 0.9100 TestAcc 0.7948 0.8600
epoch 1700 LossPred 0.3213 LossAtt 0.4135 TrainAcc 0.9000 TestAcc 0.7988 0.8700
epoch 1800 LossPred 0.3199 LossAtt 0.4296 TrainAcc 0.8900 TestAcc 0.7963 0.8600
epoch 1900 LossPred 0.2979 LossAtt 0.4250 TrainAcc 0.9200 TestAcc 0.8043 0.8750
epoch 2000 LossPred 0.3198 LossAtt 0.4212 TrainAcc 0.9000 TestAcc 0.8001 0.8650
epoch 2100 LossPred 0.2588 LossAtt 0.4372 TrainAcc 0.9200 TestAcc 0.8036 0.8600
epoch 2200 LossPred 0.3147 LossAtt 0.4188 TrainAcc 0.9000 TestAcc 0.7923 0.8700
epoch 2300 LossPred 0.3066 LossAtt 0.4101 TrainAcc 0.9000 TestAcc 0.7933 0.8650
epoch 2400 LossPred 0.2509 LossAtt 0.4117 TrainAcc 0.9100 TestAcc 0.7995 0.8800
epoch 2500 LossPred 0.2349 LossAtt 0.4165 TrainAcc 0.9400 TestAcc 0.8038 0.8800
Optimization Finished!
********** replication  2  **********
epoch   0 LossPred 1.0609 LossAtt 1.0187 TrainAcc 0.5000 TestAcc 0.4577 0.4650
epoch 100 LossPred 0.7678 LossAtt 0.9186 TrainAcc 0.7200 TestAcc 0.6356 0.7200
epoch 200 LossPred 0.2858 LossAtt 0.5905 TrainAcc 0.9000 TestAcc 0.8831 0.8800
epoch 300 LossPred 0.1580 LossAtt 0.5127 TrainAcc 0.9400 TestAcc 0.8754 0.9050
epoch 400 LossPred 0.1039 LossAtt 0.4764 TrainAcc 0.9700 TestAcc 0.8829 0.9150
epoch 500 LossPred 0.1056 LossAtt 0.4674 TrainAcc 0.9800 TestAcc 0.8899 0.9350
epoch 600 LossPred 0.1393 LossAtt 0.4609 TrainAcc 0.9600 TestAcc 0.8786 0.9300
epoch 700 LossPred 0.1355 LossAtt 0.4533 TrainAcc 0.9700 TestAcc 0.8686 0.9300
epoch 800 LossPred 0.1671 LossAtt 0.4324 TrainAcc 0.9500 TestAcc 0.8514 0.9200
epoch 900 LossPred 0.0829 LossAtt 0.4356 TrainAcc 0.9700 TestAcc 0.8874 0.9200
epoch 1000 LossPred 0.0690 LossAtt 0.4409 TrainAcc 0.9700 TestAcc 0.8771 0.9200
epoch 1100 LossPred 0.0514 LossAtt 0.4483 TrainAcc 0.9800 TestAcc 0.8651 0.9200
epoch 1200 LossPred 0.0997 LossAtt 0.4341 TrainAcc 0.9800 TestAcc 0.8729 0.9350
epoch 1300 LossPred 0.1018 LossAtt 0.4436 TrainAcc 0.9800 TestAcc 0.8714 0.9350
epoch 1400 LossPred 0.1186 LossAtt 0.4344 TrainAcc 0.9700 TestAcc 0.8834 0.9000
epoch 1500 LossPred 0.0708 LossAtt 0.4474 TrainAcc 0.9700 TestAcc 0.8769 0.9300
epoch 1600 LossPred 0.0497 LossAtt 0.4375 TrainAcc 0.9800 TestAcc 0.8671 0.9300
epoch 1700 LossPred 0.1824 LossAtt 0.4542 TrainAcc 0.9500 TestAcc 0.8629 0.8950
epoch 1800 LossPred 0.0233 LossAtt 0.4150 TrainAcc 1.0000 TestAcc 0.8611 0.9400
Optimization Finished!
********** replication  3  **********
epoch   0 LossPred 0.9954 LossAtt 1.0563 TrainAcc 0.4700 TestAcc 0.4575 0.4550
epoch 100 LossPred 0.4944 LossAtt 1.1273 TrainAcc 0.8700 TestAcc 0.7025 0.8350
epoch 200 LossPred 0.3717 LossAtt 0.6316 TrainAcc 0.8700 TestAcc 0.7392 0.8000
epoch 300 LossPred 0.2593 LossAtt 0.5143 TrainAcc 0.9200 TestAcc 0.7998 0.8750
epoch 400 LossPred 0.2192 LossAtt 0.4693 TrainAcc 0.9400 TestAcc 0.8021 0.8900
epoch 500 LossPred 0.1780 LossAtt 0.4745 TrainAcc 0.9400 TestAcc 0.8063 0.9300
epoch 600 LossPred 0.1107 LossAtt 0.4529 TrainAcc 0.9700 TestAcc 0.8046 0.9150
epoch 700 LossPred 0.1135 LossAtt 0.4445 TrainAcc 0.9600 TestAcc 0.8026 0.8750
epoch 800 LossPred 0.0854 LossAtt 0.4351 TrainAcc 0.9700 TestAcc 0.8151 0.9150
epoch 900 LossPred 0.1524 LossAtt 0.4289 TrainAcc 0.9500 TestAcc 0.8256 0.9300
epoch 1000 LossPred 0.0735 LossAtt 0.4531 TrainAcc 0.9800 TestAcc 0.8191 0.9150
epoch 1100 LossPred 0.1817 LossAtt 0.4484 TrainAcc 0.9200 TestAcc 0.7858 0.9000
epoch 1200 LossPred 0.0575 LossAtt 0.4588 TrainAcc 0.9900 TestAcc 0.8276 0.9550
epoch 1300 LossPred 0.0808 LossAtt 0.4349 TrainAcc 0.9900 TestAcc 0.8306 0.9500
epoch 1400 LossPred 0.0562 LossAtt 0.4363 TrainAcc 1.0000 TestAcc 0.8166 0.9550
Optimization Finished!
********** replication  4  **********
epoch   0 LossPred 1.0480 LossAtt 1.0278 TrainAcc 0.4400 TestAcc 0.4177 0.4400
epoch 100 LossPred 0.8875 LossAtt 0.8140 TrainAcc 0.6500 TestAcc 0.5708 0.6450
epoch 200 LossPred 0.7698 LossAtt 1.0422 TrainAcc 0.7000 TestAcc 0.5708 0.7050
epoch 300 LossPred 0.6720 LossAtt 0.8213 TrainAcc 0.7800 TestAcc 0.5658 0.7250
epoch 400 LossPred 0.6355 LossAtt 0.8129 TrainAcc 0.7900 TestAcc 0.5440 0.7300
epoch 500 LossPred 0.5787 LossAtt 0.7781 TrainAcc 0.8000 TestAcc 0.5455 0.7650
epoch 600 LossPred 0.5284 LossAtt 0.7975 TrainAcc 0.8400 TestAcc 0.5460 0.7950
epoch 700 LossPred 0.4290 LossAtt 0.8069 TrainAcc 0.8700 TestAcc 0.5460 0.8000
epoch 800 LossPred 0.3560 LossAtt 0.8135 TrainAcc 0.9000 TestAcc 0.5490 0.8200
epoch 900 LossPred 0.2845 LossAtt 0.7853 TrainAcc 0.9500 TestAcc 0.5305 0.8550
epoch 1000 LossPred 0.2556 LossAtt 0.8600 TrainAcc 0.9600 TestAcc 0.5303 0.8600
epoch 1100 LossPred 0.2165 LossAtt 0.8007 TrainAcc 0.9700 TestAcc 0.5195 0.8450
epoch 1200 LossPred 0.2531 LossAtt 0.8061 TrainAcc 0.9500 TestAcc 0.5295 0.8550
epoch 1300 LossPred 0.1541 LossAtt 0.7926 TrainAcc 0.9700 TestAcc 0.5195 0.8600
epoch 1400 LossPred 0.1410 LossAtt 0.7915 TrainAcc 0.9800 TestAcc 0.5175 0.8450
epoch 1500 LossPred 0.1288 LossAtt 0.7862 TrainAcc 0.9800 TestAcc 0.5163 0.8650
epoch 1600 LossPred 0.1073 LossAtt 0.7685 TrainAcc 0.9800 TestAcc 0.5035 0.8700
epoch 1700 LossPred 0.1471 LossAtt 0.8254 TrainAcc 0.9600 TestAcc 0.5015 0.8450
epoch 1800 LossPred 0.3396 LossAtt 0.8785 TrainAcc 0.8700 TestAcc 0.5005 0.8500
epoch 1900 LossPred 0.0738 LossAtt 0.7557 TrainAcc 0.9800 TestAcc 0.5015 0.8650
epoch 2000 LossPred 0.0545 LossAtt 0.7547 TrainAcc 1.0000 TestAcc 0.4960 0.8400
Optimization Finished!
********** replication  5  **********
epoch   0 LossPred 0.9748 LossAtt 1.0100 TrainAcc 0.5600 TestAcc 0.5055 0.5650
epoch 100 LossPred 0.9043 LossAtt 0.9522 TrainAcc 0.6400 TestAcc 0.5546 0.6300
epoch 200 LossPred 0.6291 LossAtt 1.3792 TrainAcc 0.7700 TestAcc 0.5323 0.7200
epoch 300 LossPred 0.5166 LossAtt 1.0744 TrainAcc 0.8400 TestAcc 0.5423 0.7800
epoch 400 LossPred 0.4804 LossAtt 0.9504 TrainAcc 0.8300 TestAcc 0.5460 0.7750
epoch 500 LossPred 0.4105 LossAtt 0.9359 TrainAcc 0.8600 TestAcc 0.5543 0.7900
epoch 600 LossPred 0.3790 LossAtt 0.8653 TrainAcc 0.8700 TestAcc 0.5506 0.8000
epoch 700 LossPred 0.4111 LossAtt 0.7567 TrainAcc 0.8600 TestAcc 0.5511 0.7900
epoch 800 LossPred 0.3707 LossAtt 0.7561 TrainAcc 0.8600 TestAcc 0.5428 0.7850
epoch 900 LossPred 0.6915 LossAtt 1.1087 TrainAcc 0.7500 TestAcc 0.5651 0.7700
epoch 1000 LossPred 0.4212 LossAtt 0.7479 TrainAcc 0.8600 TestAcc 0.5681 0.8000
epoch 1100 LossPred 0.3371 LossAtt 0.7967 TrainAcc 0.9200 TestAcc 0.5646 0.8150
epoch 1200 LossPred 0.3343 LossAtt 0.7485 TrainAcc 0.9200 TestAcc 0.5638 0.8250
epoch 1300 LossPred 0.2885 LossAtt 0.7361 TrainAcc 0.9400 TestAcc 0.5593 0.8250
epoch 1400 LossPred 0.3402 LossAtt 0.8109 TrainAcc 0.9000 TestAcc 0.5756 0.8550
epoch 1500 LossPred 0.2443 LossAtt 0.7283 TrainAcc 0.9500 TestAcc 0.5683 0.8500
epoch 1600 LossPred 0.2296 LossAtt 0.7099 TrainAcc 0.9500 TestAcc 0.5651 0.8500
epoch 1700 LossPred 0.3145 LossAtt 0.7476 TrainAcc 0.9100 TestAcc 0.5831 0.8450
epoch 1800 LossPred 0.6846 LossAtt 1.3829 TrainAcc 0.7300 TestAcc 0.5676 0.6950
epoch 1900 LossPred 0.3477 LossAtt 0.6994 TrainAcc 0.9000 TestAcc 0.5748 0.8100
epoch 2000 LossPred 0.3186 LossAtt 0.6783 TrainAcc 0.9100 TestAcc 0.5771 0.8300
epoch 2100 LossPred 0.3076 LossAtt 0.6781 TrainAcc 0.9200 TestAcc 0.5821 0.8300
epoch 2200 LossPred 0.3133 LossAtt 0.6996 TrainAcc 0.9200 TestAcc 0.5843 0.8500
epoch 2300 LossPred 0.3127 LossAtt 0.7270 TrainAcc 0.9000 TestAcc 0.5828 0.8600
epoch 2400 LossPred 0.2781 LossAtt 0.6941 TrainAcc 0.9200 TestAcc 0.5751 0.8200
epoch 2500 LossPred 0.4666 LossAtt 0.7720 TrainAcc 0.8500 TestAcc 0.5793 0.8200
Optimization Finished!
********** replication  6  **********
epoch   0 LossPred 1.0978 LossAtt 1.0169 TrainAcc 0.5000 TestAcc 0.4249 0.5150
epoch 100 LossPred 0.8680 LossAtt 0.5903 TrainAcc 0.6600 TestAcc 0.5918 0.6350
epoch 200 LossPred 0.5780 LossAtt 0.6239 TrainAcc 0.8200 TestAcc 0.7260 0.8000
epoch 300 LossPred 0.5491 LossAtt 0.4524 TrainAcc 0.8300 TestAcc 0.7422 0.7950
epoch 400 LossPred 0.5319 LossAtt 0.4273 TrainAcc 0.8300 TestAcc 0.7472 0.8100
epoch 500 LossPred 0.5169 LossAtt 0.4255 TrainAcc 0.8300 TestAcc 0.7540 0.8200
epoch 600 LossPred 0.3914 LossAtt 0.4451 TrainAcc 0.8600 TestAcc 0.8241 0.8400
epoch 700 LossPred 0.4450 LossAtt 0.4562 TrainAcc 0.8600 TestAcc 0.8031 0.8400
epoch 800 LossPred 0.2997 LossAtt 0.4296 TrainAcc 0.9100 TestAcc 0.8436 0.8600
epoch 900 LossPred 0.8187 LossAtt 0.3990 TrainAcc 0.6800 TestAcc 0.6116 0.6750
epoch 1000 LossPred 0.3729 LossAtt 0.4180 TrainAcc 0.8900 TestAcc 0.8343 0.8550
epoch 1100 LossPred 0.3920 LossAtt 0.3990 TrainAcc 0.8600 TestAcc 0.8076 0.8650
epoch 1200 LossPred 0.3414 LossAtt 0.4186 TrainAcc 0.8800 TestAcc 0.8446 0.8550
epoch 1300 LossPred 0.2824 LossAtt 0.4565 TrainAcc 0.8900 TestAcc 0.8216 0.8600
epoch 1400 LossPred 0.3525 LossAtt 0.3659 TrainAcc 0.8800 TestAcc 0.8183 0.8800
epoch 1500 LossPred 0.2663 LossAtt 0.3772 TrainAcc 0.9100 TestAcc 0.8376 0.8850
epoch 1600 LossPred 0.2380 LossAtt 0.3878 TrainAcc 0.9200 TestAcc 0.8699 0.8950
epoch 1700 LossPred 0.2402 LossAtt 0.3605 TrainAcc 0.9100 TestAcc 0.8363 0.8950
epoch 1800 LossPred 0.1829 LossAtt 0.3960 TrainAcc 0.9500 TestAcc 0.8514 0.9150
epoch 1900 LossPred 0.2169 LossAtt 0.3684 TrainAcc 0.9400 TestAcc 0.8736 0.8850
epoch 2000 LossPred 0.1926 LossAtt 0.3709 TrainAcc 0.9400 TestAcc 0.8546 0.9050
epoch 2100 LossPred 0.1773 LossAtt 0.3545 TrainAcc 0.9300 TestAcc 0.8661 0.9150
epoch 2200 LossPred 0.1750 LossAtt 0.3562 TrainAcc 0.9300 TestAcc 0.8566 0.9150
epoch 2300 LossPred 0.1868 LossAtt 0.3753 TrainAcc 0.9200 TestAcc 0.8566 0.9100
epoch 2400 LossPred 0.3465 LossAtt 0.3753 TrainAcc 0.8800 TestAcc 0.8188 0.8550
epoch 2500 LossPred 0.3717 LossAtt 0.3461 TrainAcc 0.8700 TestAcc 0.8521 0.8700
Optimization Finished!
********** replication  7  **********
epoch   0 LossPred 0.9974 LossAtt 1.0290 TrainAcc 0.5200 TestAcc 0.5078 0.5500
epoch 100 LossPred 0.7920 LossAtt 0.7261 TrainAcc 0.6900 TestAcc 0.5706 0.6850
epoch 200 LossPred 0.3132 LossAtt 0.6340 TrainAcc 0.9200 TestAcc 0.8153 0.8700
epoch 300 LossPred 0.2164 LossAtt 0.5468 TrainAcc 0.9500 TestAcc 0.8253 0.8600
epoch 400 LossPred 0.1844 LossAtt 0.4918 TrainAcc 0.9500 TestAcc 0.8363 0.8550
epoch 500 LossPred 0.1750 LossAtt 0.4552 TrainAcc 0.9500 TestAcc 0.8383 0.8450
epoch 600 LossPred 0.4426 LossAtt 0.6180 TrainAcc 0.8700 TestAcc 0.7858 0.8200
epoch 700 LossPred 0.1649 LossAtt 0.4441 TrainAcc 0.9500 TestAcc 0.8348 0.8450
epoch 800 LossPred 0.1574 LossAtt 0.4483 TrainAcc 0.9500 TestAcc 0.8358 0.8500
epoch 900 LossPred 0.1499 LossAtt 0.4456 TrainAcc 0.9600 TestAcc 0.8403 0.8350
epoch 1000 LossPred 0.1498 LossAtt 0.4485 TrainAcc 0.9600 TestAcc 0.8393 0.8650
epoch 1100 LossPred 0.1483 LossAtt 0.4529 TrainAcc 0.9600 TestAcc 0.8303 0.8900
epoch 1200 LossPred 0.1401 LossAtt 0.4521 TrainAcc 0.9600 TestAcc 0.8326 0.8700
epoch 1300 LossPred 0.1598 LossAtt 0.4640 TrainAcc 0.9700 TestAcc 0.8311 0.8800
epoch 1400 LossPred 0.1505 LossAtt 0.4565 TrainAcc 0.9600 TestAcc 0.8251 0.8950
epoch 1500 LossPred 0.1535 LossAtt 0.4424 TrainAcc 0.9500 TestAcc 0.8233 0.8800
epoch 1600 LossPred 0.1434 LossAtt 0.4421 TrainAcc 0.9600 TestAcc 0.8203 0.8900
epoch 1700 LossPred 0.1371 LossAtt 0.4521 TrainAcc 0.9600 TestAcc 0.8248 0.8800
epoch 1800 LossPred 0.1832 LossAtt 0.4681 TrainAcc 0.9700 TestAcc 0.8151 0.8750
epoch 1900 LossPred 0.1536 LossAtt 0.4381 TrainAcc 0.9600 TestAcc 0.8223 0.8900
epoch 2000 LossPred 0.1388 LossAtt 0.4384 TrainAcc 0.9600 TestAcc 0.8238 0.9000
epoch 2100 LossPred 0.1397 LossAtt 0.4334 TrainAcc 0.9600 TestAcc 0.8251 0.9000
epoch 2200 LossPred 0.1494 LossAtt 0.4483 TrainAcc 0.9600 TestAcc 0.8201 0.8850
epoch 2300 LossPred 0.1401 LossAtt 0.4319 TrainAcc 0.9600 TestAcc 0.8191 0.9050
epoch 2400 LossPred 0.1896 LossAtt 0.4506 TrainAcc 0.9500 TestAcc 0.8036 0.8800
epoch 2500 LossPred 0.2101 LossAtt 0.4340 TrainAcc 0.9400 TestAcc 0.8238 0.8900
Optimization Finished!
********** replication  8  **********
epoch   0 LossPred 1.1416 LossAtt 1.0423 TrainAcc 0.4600 TestAcc 0.4927 0.4450
epoch 100 LossPred 0.8471 LossAtt 0.6034 TrainAcc 0.6400 TestAcc 0.5418 0.6500
epoch 200 LossPred 0.4034 LossAtt 1.0723 TrainAcc 0.9000 TestAcc 0.8003 0.8800
epoch 300 LossPred 0.2179 LossAtt 0.5504 TrainAcc 0.9500 TestAcc 0.8323 0.8750
epoch 400 LossPred 0.1788 LossAtt 0.5268 TrainAcc 0.9600 TestAcc 0.8391 0.8750
epoch 500 LossPred 0.1590 LossAtt 0.5174 TrainAcc 0.9600 TestAcc 0.8413 0.8800
epoch 600 LossPred 0.1476 LossAtt 0.5053 TrainAcc 0.9600 TestAcc 0.8453 0.8850
epoch 700 LossPred 0.1423 LossAtt 0.5240 TrainAcc 0.9600 TestAcc 0.8381 0.8800
epoch 800 LossPred 0.1256 LossAtt 0.5163 TrainAcc 0.9700 TestAcc 0.8488 0.9050
epoch 900 LossPred 0.0993 LossAtt 0.5121 TrainAcc 0.9800 TestAcc 0.8514 0.9050
epoch 1000 LossPred 0.0850 LossAtt 0.4963 TrainAcc 0.9800 TestAcc 0.8478 0.9050
epoch 1100 LossPred 0.0795 LossAtt 0.4906 TrainAcc 0.9900 TestAcc 0.8393 0.9150
epoch 1200 LossPred 0.0683 LossAtt 0.4808 TrainAcc 0.9800 TestAcc 0.8561 0.9200
epoch 1300 LossPred 0.0733 LossAtt 0.4882 TrainAcc 1.0000 TestAcc 0.8413 0.9100
Optimization Finished!
********** replication  9  **********
epoch   0 LossPred 1.3289 LossAtt 1.0410 TrainAcc 0.3300 TestAcc 0.4337 0.3550
epoch 100 LossPred 0.8242 LossAtt 0.6489 TrainAcc 0.6700 TestAcc 0.5663 0.6700
epoch 200 LossPred 0.7262 LossAtt 1.0764 TrainAcc 0.6900 TestAcc 0.5796 0.7250
epoch 300 LossPred 0.5806 LossAtt 0.5395 TrainAcc 0.7900 TestAcc 0.7167 0.7550
epoch 400 LossPred 0.3598 LossAtt 0.4841 TrainAcc 0.9000 TestAcc 0.7625 0.8500
epoch 500 LossPred 0.3096 LossAtt 0.4341 TrainAcc 0.9200 TestAcc 0.8003 0.8600
epoch 600 LossPred 0.6018 LossAtt 0.4200 TrainAcc 0.8200 TestAcc 0.7700 0.8200
epoch 700 LossPred 0.2620 LossAtt 0.3883 TrainAcc 0.9300 TestAcc 0.8121 0.8800
epoch 800 LossPred 0.2366 LossAtt 0.3823 TrainAcc 0.9300 TestAcc 0.8191 0.8800
epoch 900 LossPred 0.2255 LossAtt 0.3690 TrainAcc 0.9200 TestAcc 0.8196 0.8800
epoch 1000 LossPred 0.2164 LossAtt 0.3639 TrainAcc 0.9400 TestAcc 0.8203 0.8800
epoch 1100 LossPred 0.2136 LossAtt 0.3678 TrainAcc 0.9500 TestAcc 0.8241 0.8950
epoch 1200 LossPred 0.2112 LossAtt 0.3668 TrainAcc 0.9400 TestAcc 0.8278 0.9000
epoch 1300 LossPred 0.2115 LossAtt 0.3538 TrainAcc 0.9300 TestAcc 0.8258 0.8900
epoch 1400 LossPred 0.2011 LossAtt 0.3508 TrainAcc 0.9500 TestAcc 0.8226 0.8850
epoch 1500 LossPred 0.1950 LossAtt 0.3414 TrainAcc 0.9600 TestAcc 0.8221 0.9050
epoch 1600 LossPred 0.2279 LossAtt 0.3519 TrainAcc 0.9400 TestAcc 0.8256 0.9050
epoch 1700 LossPred 0.2297 LossAtt 0.3610 TrainAcc 0.9100 TestAcc 0.8251 0.8850
epoch 1800 LossPred 0.1818 LossAtt 0.3599 TrainAcc 0.9400 TestAcc 0.8361 0.8950
epoch 1900 LossPred 0.3281 LossAtt 0.3656 TrainAcc 0.9200 TestAcc 0.8181 0.8650
epoch 2000 LossPred 0.2368 LossAtt 0.3435 TrainAcc 0.9200 TestAcc 0.8436 0.8600
epoch 2100 LossPred 0.1663 LossAtt 0.3436 TrainAcc 0.9600 TestAcc 0.8441 0.8750
epoch 2200 LossPred 0.1476 LossAtt 0.3384 TrainAcc 0.9600 TestAcc 0.8278 0.9000
epoch 2300 LossPred 0.4230 LossAtt 0.3337 TrainAcc 0.8800 TestAcc 0.8138 0.8800
epoch 2400 LossPred 0.1482 LossAtt 0.3217 TrainAcc 0.9600 TestAcc 0.8311 0.9050
epoch 2500 LossPred 0.1446 LossAtt 0.3171 TrainAcc 0.9600 TestAcc 0.8173 0.9100
Optimization Finished!
********** replication  10  **********
epoch   0 LossPred 1.0748 LossAtt 1.0214 TrainAcc 0.4600 TestAcc 0.4892 0.4950
epoch 100 LossPred 0.8287 LossAtt 0.7530 TrainAcc 0.6600 TestAcc 0.6346 0.6550
epoch 200 LossPred 0.3324 LossAtt 0.5426 TrainAcc 0.9100 TestAcc 0.8756 0.8750
epoch 300 LossPred 0.4697 LossAtt 0.4610 TrainAcc 0.8300 TestAcc 0.8323 0.8300
epoch 400 LossPred 0.1983 LossAtt 0.4396 TrainAcc 0.9300 TestAcc 0.9087 0.9000
epoch 500 LossPred 0.1973 LossAtt 0.5869 TrainAcc 0.9300 TestAcc 0.9017 0.8950
epoch 600 LossPred 0.1681 LossAtt 0.5097 TrainAcc 0.9500 TestAcc 0.9134 0.9000
epoch 700 LossPred 0.1450 LossAtt 0.5227 TrainAcc 0.9300 TestAcc 0.9109 0.9000
epoch 800 LossPred 0.0946 LossAtt 0.5352 TrainAcc 0.9900 TestAcc 0.9342 0.9400
epoch 900 LossPred 0.1120 LossAtt 0.5247 TrainAcc 0.9700 TestAcc 0.9314 0.9100
epoch 1000 LossPred 0.0703 LossAtt 0.4914 TrainAcc 0.9800 TestAcc 0.9267 0.9350
epoch 1100 LossPred 0.0670 LossAtt 0.5036 TrainAcc 0.9800 TestAcc 0.9312 0.9500
epoch 1200 LossPred 0.1441 LossAtt 0.4818 TrainAcc 0.9500 TestAcc 0.9069 0.9200
epoch 1300 LossPred 0.0424 LossAtt 0.4705 TrainAcc 1.0000 TestAcc 0.9364 0.9350
Optimization Finished!
********** replication  11  **********
epoch   0 LossPred 0.9905 LossAtt 1.0102 TrainAcc 0.6200 TestAcc 0.5736 0.6200
epoch 100 LossPred 0.7688 LossAtt 0.7230 TrainAcc 0.7100 TestAcc 0.6154 0.7150
epoch 200 LossPred 0.6505 LossAtt 0.7614 TrainAcc 0.7700 TestAcc 0.6134 0.7550
epoch 300 LossPred 0.5789 LossAtt 0.7645 TrainAcc 0.8100 TestAcc 0.6069 0.8000
epoch 400 LossPred 0.4503 LossAtt 0.8596 TrainAcc 0.8700 TestAcc 0.6096 0.8250
epoch 500 LossPred 0.3583 LossAtt 0.7834 TrainAcc 0.8900 TestAcc 0.6116 0.8500
epoch 600 LossPred 0.2696 LossAtt 0.7221 TrainAcc 0.9300 TestAcc 0.6099 0.8800
epoch 700 LossPred 0.2423 LossAtt 0.6304 TrainAcc 0.9400 TestAcc 0.6206 0.8700
epoch 800 LossPred 0.2322 LossAtt 0.6393 TrainAcc 0.9300 TestAcc 0.6186 0.8650
epoch 900 LossPred 0.4046 LossAtt 1.0283 TrainAcc 0.8900 TestAcc 0.6136 0.8150
epoch 1000 LossPred 0.2304 LossAtt 0.6196 TrainAcc 0.9400 TestAcc 0.6146 0.8800
epoch 1100 LossPred 0.3870 LossAtt 0.8213 TrainAcc 0.8800 TestAcc 0.6084 0.8350
epoch 1200 LossPred 0.1896 LossAtt 0.5853 TrainAcc 0.9400 TestAcc 0.6104 0.8850
epoch 1300 LossPred 0.1740 LossAtt 0.5777 TrainAcc 0.9400 TestAcc 0.6106 0.8750
epoch 1400 LossPred 0.1572 LossAtt 0.5690 TrainAcc 0.9400 TestAcc 0.6129 0.8700
epoch 1500 LossPred 0.4718 LossAtt 0.6851 TrainAcc 0.8400 TestAcc 0.6109 0.8400
epoch 1600 LossPred 0.1646 LossAtt 0.5801 TrainAcc 0.9400 TestAcc 0.6054 0.8750
epoch 1700 LossPred 0.1312 LossAtt 0.5494 TrainAcc 0.9700 TestAcc 0.6114 0.8600
epoch 1800 LossPred 0.2250 LossAtt 0.6263 TrainAcc 0.9400 TestAcc 0.6056 0.8400
epoch 1900 LossPred 0.1693 LossAtt 0.5609 TrainAcc 0.9500 TestAcc 0.6079 0.8900
epoch 2000 LossPred 0.1123 LossAtt 0.5309 TrainAcc 0.9800 TestAcc 0.6054 0.8900
epoch 2100 LossPred 0.1041 LossAtt 0.5352 TrainAcc 0.9900 TestAcc 0.6064 0.8800
epoch 2200 LossPred 0.0930 LossAtt 0.5284 TrainAcc 0.9900 TestAcc 0.6076 0.8750
epoch 2300 LossPred 0.0951 LossAtt 0.5273 TrainAcc 0.9900 TestAcc 0.6054 0.8850
epoch 2400 LossPred 0.0817 LossAtt 0.5256 TrainAcc 0.9900 TestAcc 0.6064 0.8950
epoch 2500 LossPred 0.2733 LossAtt 0.8256 TrainAcc 0.9300 TestAcc 0.6091 0.8700
Optimization Finished!
********** replication  12  **********
epoch   0 LossPred 1.0090 LossAtt 1.0345 TrainAcc 0.4900 TestAcc 0.5035 0.4900
epoch 100 LossPred 0.6355 LossAtt 0.8313 TrainAcc 0.8100 TestAcc 0.7570 0.7650
epoch 200 LossPred 0.2373 LossAtt 0.5930 TrainAcc 0.9300 TestAcc 0.8516 0.8900
epoch 300 LossPred 0.1653 LossAtt 0.5395 TrainAcc 0.9600 TestAcc 0.8909 0.9050
epoch 400 LossPred 0.1015 LossAtt 0.5134 TrainAcc 0.9800 TestAcc 0.8936 0.9200
epoch 500 LossPred 0.0873 LossAtt 0.4825 TrainAcc 0.9800 TestAcc 0.8934 0.9200
epoch 600 LossPred 0.0716 LossAtt 0.4976 TrainAcc 0.9900 TestAcc 0.8881 0.9250
epoch 700 LossPred 0.0915 LossAtt 0.4821 TrainAcc 0.9700 TestAcc 0.8951 0.9150
epoch 800 LossPred 0.0643 LossAtt 0.4703 TrainAcc 0.9900 TestAcc 0.8919 0.9200
epoch 900 LossPred 0.0446 LossAtt 0.4661 TrainAcc 1.0000 TestAcc 0.8876 0.9250
Optimization Finished!
********** replication  13  **********
epoch   0 LossPred 1.0851 LossAtt 1.0368 TrainAcc 0.5300 TestAcc 0.4600 0.5000
epoch 100 LossPred 0.8495 LossAtt 0.7191 TrainAcc 0.6400 TestAcc 0.5673 0.6400
epoch 200 LossPred 0.5512 LossAtt 0.5931 TrainAcc 0.8200 TestAcc 0.8196 0.8050
epoch 300 LossPred 0.3817 LossAtt 0.4470 TrainAcc 0.8600 TestAcc 0.8589 0.8100
epoch 400 LossPred 0.2766 LossAtt 0.4017 TrainAcc 0.9300 TestAcc 0.8626 0.8550
epoch 500 LossPred 0.2825 LossAtt 0.4128 TrainAcc 0.9100 TestAcc 0.8679 0.8300
epoch 600 LossPred 0.4751 LossAtt 0.3975 TrainAcc 0.8600 TestAcc 0.8158 0.8400
epoch 700 LossPred 0.2153 LossAtt 0.3885 TrainAcc 0.9300 TestAcc 0.8856 0.8750
epoch 800 LossPred 0.2266 LossAtt 0.3974 TrainAcc 0.9100 TestAcc 0.8621 0.8550
epoch 900 LossPred 0.1724 LossAtt 0.4059 TrainAcc 0.9700 TestAcc 0.8889 0.8750
epoch 1000 LossPred 0.1487 LossAtt 0.3664 TrainAcc 0.9600 TestAcc 0.8799 0.8850
epoch 1100 LossPred 0.1424 LossAtt 0.3654 TrainAcc 0.9600 TestAcc 0.8891 0.8750
epoch 1200 LossPred 0.1535 LossAtt 0.3500 TrainAcc 0.9700 TestAcc 0.8966 0.8500
epoch 1300 LossPred 0.1535 LossAtt 0.3476 TrainAcc 0.9700 TestAcc 0.8881 0.8600
epoch 1400 LossPred 0.1216 LossAtt 0.3495 TrainAcc 0.9800 TestAcc 0.8916 0.8800
epoch 1500 LossPred 0.1037 LossAtt 0.3461 TrainAcc 0.9800 TestAcc 0.8921 0.9150
epoch 1600 LossPred 0.1004 LossAtt 0.3467 TrainAcc 0.9800 TestAcc 0.8949 0.9200
epoch 1700 LossPred 0.1053 LossAtt 0.3327 TrainAcc 0.9600 TestAcc 0.8811 0.9250
epoch 1800 LossPred 0.1202 LossAtt 0.3330 TrainAcc 0.9600 TestAcc 0.8826 0.9050
epoch 1900 LossPred 0.1922 LossAtt 0.3395 TrainAcc 0.9300 TestAcc 0.8821 0.9100
epoch 2000 LossPred 0.1013 LossAtt 0.3344 TrainAcc 0.9800 TestAcc 0.8804 0.9150
epoch 2100 LossPred 0.0914 LossAtt 0.3141 TrainAcc 0.9800 TestAcc 0.8821 0.9000
epoch 2200 LossPred 0.0947 LossAtt 0.3330 TrainAcc 0.9800 TestAcc 0.8851 0.8950
epoch 2300 LossPred 0.2009 LossAtt 0.3394 TrainAcc 0.9400 TestAcc 0.8701 0.8700
epoch 2400 LossPred 0.1084 LossAtt 0.2959 TrainAcc 0.9800 TestAcc 0.8841 0.9000
epoch 2500 LossPred 0.0755 LossAtt 0.2898 TrainAcc 0.9800 TestAcc 0.8829 0.9300
Optimization Finished!
********** replication  14  **********
epoch   0 LossPred 0.9999 LossAtt 1.0142 TrainAcc 0.5200 TestAcc 0.5048 0.5100
epoch 100 LossPred 0.9441 LossAtt 0.5837 TrainAcc 0.5800 TestAcc 0.5475 0.5950
epoch 200 LossPred 0.7067 LossAtt 1.7030 TrainAcc 0.7200 TestAcc 0.5423 0.7100
epoch 300 LossPred 0.7555 LossAtt 0.7942 TrainAcc 0.6900 TestAcc 0.5811 0.6700
epoch 400 LossPred 0.3435 LossAtt 0.7647 TrainAcc 0.8900 TestAcc 0.7402 0.8850
epoch 500 LossPred 0.3359 LossAtt 0.8220 TrainAcc 0.8800 TestAcc 0.7588 0.8650
epoch 600 LossPred 0.2712 LossAtt 0.6114 TrainAcc 0.9100 TestAcc 0.7487 0.8750
epoch 700 LossPred 0.3221 LossAtt 0.6557 TrainAcc 0.8900 TestAcc 0.7555 0.8950
epoch 800 LossPred 0.2448 LossAtt 0.5937 TrainAcc 0.9300 TestAcc 0.7455 0.8850
epoch 900 LossPred 1.2361 LossAtt 0.8193 TrainAcc 0.5800 TestAcc 0.5736 0.5850
epoch 1000 LossPred 0.4015 LossAtt 0.6108 TrainAcc 0.8600 TestAcc 0.7280 0.8400
epoch 1100 LossPred 0.2459 LossAtt 0.5875 TrainAcc 0.9400 TestAcc 0.7678 0.8900
epoch 1200 LossPred 0.1985 LossAtt 0.5649 TrainAcc 0.9500 TestAcc 0.7685 0.8950
epoch 1300 LossPred 0.2132 LossAtt 0.5708 TrainAcc 0.9600 TestAcc 0.7735 0.9150
epoch 1400 LossPred 0.1886 LossAtt 0.5566 TrainAcc 0.9500 TestAcc 0.7700 0.9100
epoch 1500 LossPred 0.3948 LossAtt 0.7218 TrainAcc 0.8800 TestAcc 0.7668 0.8600
epoch 1600 LossPred 0.2407 LossAtt 0.5323 TrainAcc 0.9500 TestAcc 0.7708 0.9100
epoch 1700 LossPred 0.2282 LossAtt 0.5481 TrainAcc 0.9500 TestAcc 0.7683 0.9100
epoch 1800 LossPred 0.2164 LossAtt 0.5447 TrainAcc 0.9500 TestAcc 0.7703 0.9250
epoch 1900 LossPred 1.5059 LossAtt 0.6683 TrainAcc 0.5800 TestAcc 0.5733 0.5800
epoch 2000 LossPred 0.9660 LossAtt 0.5178 TrainAcc 0.6300 TestAcc 0.5318 0.6150
epoch 2100 LossPred 0.3033 LossAtt 0.5899 TrainAcc 0.9500 TestAcc 0.7623 0.9300
epoch 2200 LossPred 0.1910 LossAtt 0.5227 TrainAcc 0.9600 TestAcc 0.7758 0.9250
epoch 2300 LossPred 0.1347 LossAtt 0.5140 TrainAcc 0.9700 TestAcc 0.7755 0.9250
epoch 2400 LossPred 0.1146 LossAtt 0.5068 TrainAcc 0.9800 TestAcc 0.7730 0.9300
epoch 2500 LossPred 0.0934 LossAtt 0.5196 TrainAcc 0.9900 TestAcc 0.7735 0.9500
Optimization Finished!
********** replication  15  **********
epoch   0 LossPred 1.0247 LossAtt 1.0299 TrainAcc 0.5900 TestAcc 0.5290 0.5550
epoch 100 LossPred 0.8874 LossAtt 0.6950 TrainAcc 0.6300 TestAcc 0.6031 0.6100
epoch 200 LossPred 0.4071 LossAtt 0.5931 TrainAcc 0.8800 TestAcc 0.7855 0.8750
epoch 300 LossPred 0.3681 LossAtt 0.4977 TrainAcc 0.9000 TestAcc 0.7915 0.8850
epoch 400 LossPred 0.2343 LossAtt 0.4631 TrainAcc 0.9400 TestAcc 0.8013 0.9050
epoch 500 LossPred 0.2529 LossAtt 0.4705 TrainAcc 0.9100 TestAcc 0.8261 0.9100
epoch 600 LossPred 0.1841 LossAtt 0.4652 TrainAcc 0.9500 TestAcc 0.8076 0.9050
epoch 700 LossPred 0.1704 LossAtt 0.4743 TrainAcc 0.9600 TestAcc 0.8146 0.9150
epoch 800 LossPred 0.2135 LossAtt 0.4982 TrainAcc 0.9500 TestAcc 0.8286 0.9150
epoch 900 LossPred 0.2630 LossAtt 0.4925 TrainAcc 0.9000 TestAcc 0.8348 0.9000
epoch 1000 LossPred 0.2539 LossAtt 0.4974 TrainAcc 0.9100 TestAcc 0.8178 0.8950
epoch 1100 LossPred 0.1509 LossAtt 0.4628 TrainAcc 0.9700 TestAcc 0.8208 0.9300
epoch 1200 LossPred 0.1668 LossAtt 0.4983 TrainAcc 0.9600 TestAcc 0.8253 0.9300
epoch 1300 LossPred 0.2376 LossAtt 0.4685 TrainAcc 0.9100 TestAcc 0.8278 0.8950
epoch 1400 LossPred 0.1485 LossAtt 0.4694 TrainAcc 0.9700 TestAcc 0.8258 0.9400
epoch 1500 LossPred 0.1431 LossAtt 0.4665 TrainAcc 0.9700 TestAcc 0.8173 0.9450
epoch 1600 LossPred 0.1484 LossAtt 0.4461 TrainAcc 0.9600 TestAcc 0.8181 0.9150
epoch 1700 LossPred 0.1389 LossAtt 0.4327 TrainAcc 0.9700 TestAcc 0.8113 0.9200
epoch 1800 LossPred 0.1446 LossAtt 0.4209 TrainAcc 0.9600 TestAcc 0.8206 0.9250
epoch 1900 LossPred 0.1440 LossAtt 0.4254 TrainAcc 0.9600 TestAcc 0.8123 0.9100
epoch 2000 LossPred 0.1426 LossAtt 0.4312 TrainAcc 0.9700 TestAcc 0.8333 0.9300
epoch 2100 LossPred 0.1439 LossAtt 0.4116 TrainAcc 0.9600 TestAcc 0.8151 0.9100
epoch 2200 LossPred 0.1524 LossAtt 0.4062 TrainAcc 0.9600 TestAcc 0.8103 0.9050
epoch 2300 LossPred 0.1519 LossAtt 0.5388 TrainAcc 0.9600 TestAcc 0.8223 0.9250
epoch 2400 LossPred 0.1306 LossAtt 0.3935 TrainAcc 0.9700 TestAcc 0.8091 0.9200
epoch 2500 LossPred 0.1351 LossAtt 0.4569 TrainAcc 0.9700 TestAcc 0.8331 0.9300
Optimization Finished!
********** replication  16  **********
epoch   0 LossPred 1.2202 LossAtt 0.9860 TrainAcc 0.5100 TestAcc 0.4182 0.5100
epoch 100 LossPred 0.9203 LossAtt 0.6645 TrainAcc 0.6900 TestAcc 0.5673 0.6850
epoch 200 LossPred 0.3840 LossAtt 0.6216 TrainAcc 0.8700 TestAcc 0.8221 0.8800
epoch 300 LossPred 0.2531 LossAtt 0.4761 TrainAcc 0.9200 TestAcc 0.8541 0.8900
epoch 400 LossPred 0.1937 LossAtt 0.4547 TrainAcc 0.9500 TestAcc 0.8604 0.8950
epoch 500 LossPred 0.1678 LossAtt 0.4411 TrainAcc 0.9600 TestAcc 0.8681 0.8900
epoch 600 LossPred 0.1308 LossAtt 0.4299 TrainAcc 0.9600 TestAcc 0.8639 0.9000
epoch 700 LossPred 0.1379 LossAtt 0.4340 TrainAcc 0.9600 TestAcc 0.8716 0.8950
epoch 800 LossPred 0.1212 LossAtt 0.4285 TrainAcc 0.9600 TestAcc 0.8684 0.9050
epoch 900 LossPred 0.1179 LossAtt 0.4193 TrainAcc 0.9600 TestAcc 0.8694 0.9000
epoch 1000 LossPred 0.1149 LossAtt 0.4121 TrainAcc 0.9600 TestAcc 0.8646 0.8900
epoch 1100 LossPred 0.1129 LossAtt 0.4029 TrainAcc 0.9600 TestAcc 0.8639 0.8850
epoch 1200 LossPred 0.1196 LossAtt 0.4037 TrainAcc 0.9600 TestAcc 0.8629 0.8900
epoch 1300 LossPred 0.1127 LossAtt 0.3826 TrainAcc 0.9500 TestAcc 0.8649 0.9000
epoch 1400 LossPred 0.1131 LossAtt 0.3709 TrainAcc 0.9600 TestAcc 0.8616 0.8900
epoch 1500 LossPred 0.1965 LossAtt 0.3817 TrainAcc 0.9300 TestAcc 0.8554 0.8900
epoch 1600 LossPred 0.1124 LossAtt 0.3622 TrainAcc 0.9700 TestAcc 0.8759 0.9250
epoch 1700 LossPred 0.1064 LossAtt 0.3414 TrainAcc 0.9500 TestAcc 0.8766 0.9400
epoch 1800 LossPred 0.1046 LossAtt 0.3344 TrainAcc 0.9500 TestAcc 0.8749 0.9400
epoch 1900 LossPred 0.1044 LossAtt 0.3211 TrainAcc 0.9700 TestAcc 0.8696 0.9400
epoch 2000 LossPred 0.1029 LossAtt 0.3207 TrainAcc 0.9700 TestAcc 0.8711 0.9500
epoch 2100 LossPred 0.3808 LossAtt 0.4137 TrainAcc 0.8800 TestAcc 0.7990 0.8800
epoch 2200 LossPred 0.1035 LossAtt 0.3241 TrainAcc 0.9700 TestAcc 0.8666 0.9500
epoch 2300 LossPred 0.1006 LossAtt 0.3205 TrainAcc 0.9600 TestAcc 0.8711 0.9450
epoch 2400 LossPred 0.0988 LossAtt 0.3138 TrainAcc 0.9700 TestAcc 0.8664 0.9550
epoch 2500 LossPred 0.0955 LossAtt 0.3122 TrainAcc 0.9700 TestAcc 0.8586 0.9400
Optimization Finished!
********** replication  17  **********
epoch   0 LossPred 1.0547 LossAtt 1.0332 TrainAcc 0.4400 TestAcc 0.5088 0.4350
epoch 100 LossPred 0.8927 LossAtt 0.6478 TrainAcc 0.6000 TestAcc 0.5255 0.6300
epoch 200 LossPred 0.8488 LossAtt 0.6614 TrainAcc 0.6600 TestAcc 0.5596 0.6800
epoch 300 LossPred 0.7808 LossAtt 1.0770 TrainAcc 0.6800 TestAcc 0.5468 0.6700
epoch 400 LossPred 0.7372 LossAtt 1.1000 TrainAcc 0.7200 TestAcc 0.5353 0.6850
epoch 500 LossPred 0.6226 LossAtt 0.9006 TrainAcc 0.7500 TestAcc 0.5370 0.7050
epoch 600 LossPred 0.5901 LossAtt 0.8729 TrainAcc 0.7600 TestAcc 0.5325 0.7000
epoch 700 LossPred 0.5895 LossAtt 0.8894 TrainAcc 0.7600 TestAcc 0.5145 0.7200
epoch 800 LossPred 0.5445 LossAtt 0.6860 TrainAcc 0.8200 TestAcc 0.5108 0.7350
epoch 900 LossPred 0.5691 LossAtt 0.7967 TrainAcc 0.7900 TestAcc 0.5163 0.7450
epoch 1000 LossPred 0.4924 LossAtt 0.6903 TrainAcc 0.8300 TestAcc 0.5188 0.7300
epoch 1100 LossPred 0.5125 LossAtt 0.6691 TrainAcc 0.8400 TestAcc 0.5175 0.7250
epoch 1200 LossPred 0.5250 LossAtt 0.6312 TrainAcc 0.7900 TestAcc 0.5305 0.7050
epoch 1300 LossPred 0.4249 LossAtt 0.5962 TrainAcc 0.8500 TestAcc 0.5243 0.7200
epoch 1400 LossPred 0.4911 LossAtt 0.7272 TrainAcc 0.8200 TestAcc 0.5095 0.7200
epoch 1500 LossPred 0.3576 LossAtt 0.6367 TrainAcc 0.8800 TestAcc 0.5150 0.7500
epoch 1600 LossPred 0.4134 LossAtt 0.6297 TrainAcc 0.8500 TestAcc 0.5095 0.7500
epoch 1700 LossPred 0.3806 LossAtt 0.5866 TrainAcc 0.8600 TestAcc 0.5058 0.7450
epoch 1800 LossPred 0.3645 LossAtt 0.5941 TrainAcc 0.8800 TestAcc 0.5008 0.7350
epoch 1900 LossPred 0.5322 LossAtt 0.7644 TrainAcc 0.8100 TestAcc 0.4977 0.7150
epoch 2000 LossPred 0.3181 LossAtt 0.6187 TrainAcc 0.9100 TestAcc 0.4915 0.7450
epoch 2100 LossPred 0.2956 LossAtt 0.5915 TrainAcc 0.8900 TestAcc 0.4962 0.7600
epoch 2200 LossPred 0.2750 LossAtt 0.6033 TrainAcc 0.9100 TestAcc 0.4877 0.7400
epoch 2300 LossPred 0.3606 LossAtt 0.6289 TrainAcc 0.8700 TestAcc 0.4762 0.7600
epoch 2400 LossPred 0.2869 LossAtt 0.5998 TrainAcc 0.9100 TestAcc 0.4932 0.7800
epoch 2500 LossPred 0.4954 LossAtt 0.6255 TrainAcc 0.8300 TestAcc 0.4802 0.7350
Optimization Finished!
********** replication  18  **********
epoch   0 LossPred 1.1918 LossAtt 1.0436 TrainAcc 0.4100 TestAcc 0.4667 0.4000
epoch 100 LossPred 0.7899 LossAtt 0.8543 TrainAcc 0.6800 TestAcc 0.5963 0.6750
epoch 200 LossPred 0.4417 LossAtt 0.6044 TrainAcc 0.8600 TestAcc 0.8293 0.8300
epoch 300 LossPred 0.3481 LossAtt 0.4607 TrainAcc 0.8900 TestAcc 0.8263 0.8500
epoch 400 LossPred 0.2691 LossAtt 0.4109 TrainAcc 0.9300 TestAcc 0.8433 0.8500
epoch 500 LossPred 0.2986 LossAtt 0.4084 TrainAcc 0.9000 TestAcc 0.8321 0.8600
epoch 600 LossPred 0.2570 LossAtt 0.4071 TrainAcc 0.9300 TestAcc 0.8343 0.8550
epoch 700 LossPred 0.2360 LossAtt 0.3937 TrainAcc 0.9400 TestAcc 0.8361 0.8600
epoch 800 LossPred 0.2037 LossAtt 0.4072 TrainAcc 0.9500 TestAcc 0.8386 0.8400
epoch 900 LossPred 0.1772 LossAtt 0.4093 TrainAcc 0.9600 TestAcc 0.8396 0.8700
epoch 1000 LossPred 0.2292 LossAtt 0.4256 TrainAcc 0.9300 TestAcc 0.8376 0.8900
epoch 1100 LossPred 0.4880 LossAtt 0.4542 TrainAcc 0.8300 TestAcc 0.7680 0.7850
epoch 1200 LossPred 0.1742 LossAtt 0.3929 TrainAcc 0.9600 TestAcc 0.8311 0.8550
epoch 1300 LossPred 0.6655 LossAtt 0.4955 TrainAcc 0.7900 TestAcc 0.7412 0.7900
epoch 1400 LossPred 0.1580 LossAtt 0.3878 TrainAcc 0.9600 TestAcc 0.8353 0.8550
epoch 1500 LossPred 0.1759 LossAtt 0.3894 TrainAcc 0.9500 TestAcc 0.8311 0.8700
epoch 1600 LossPred 0.3444 LossAtt 0.3875 TrainAcc 0.8900 TestAcc 0.8276 0.9000
epoch 1700 LossPred 0.1533 LossAtt 0.3739 TrainAcc 0.9600 TestAcc 0.8391 0.8700
epoch 1800 LossPred 0.1970 LossAtt 0.3616 TrainAcc 0.9600 TestAcc 0.8331 0.8350
epoch 1900 LossPred 0.1566 LossAtt 0.3539 TrainAcc 0.9600 TestAcc 0.8441 0.8800
epoch 2000 LossPred 0.1846 LossAtt 0.3449 TrainAcc 0.9500 TestAcc 0.8298 0.8800
epoch 2100 LossPred 0.2727 LossAtt 0.3483 TrainAcc 0.9300 TestAcc 0.8178 0.8350
epoch 2200 LossPred 0.2570 LossAtt 0.3448 TrainAcc 0.9300 TestAcc 0.8396 0.8750
epoch 2300 LossPred 0.2363 LossAtt 0.3375 TrainAcc 0.9300 TestAcc 0.8281 0.8450
epoch 2400 LossPred 0.2662 LossAtt 0.3839 TrainAcc 0.9200 TestAcc 0.8216 0.8850
epoch 2500 LossPred 0.1258 LossAtt 0.3244 TrainAcc 0.9700 TestAcc 0.8486 0.8850
Optimization Finished!
********** replication  19  **********
epoch   0 LossPred 1.0950 LossAtt 1.0260 TrainAcc 0.4300 TestAcc 0.4457 0.4650
epoch 100 LossPred 0.8682 LossAtt 0.6556 TrainAcc 0.6600 TestAcc 0.6129 0.6650
epoch 200 LossPred 0.6085 LossAtt 0.6213 TrainAcc 0.8000 TestAcc 0.7287 0.7800
epoch 300 LossPred 0.7002 LossAtt 0.4662 TrainAcc 0.7500 TestAcc 0.6867 0.7250
epoch 400 LossPred 0.3593 LossAtt 0.3561 TrainAcc 0.8700 TestAcc 0.8506 0.8600
epoch 500 LossPred 0.3036 LossAtt 0.3336 TrainAcc 0.9200 TestAcc 0.8443 0.8650
epoch 600 LossPred 0.2770 LossAtt 0.2933 TrainAcc 0.9200 TestAcc 0.8391 0.8550
epoch 700 LossPred 0.2731 LossAtt 0.2769 TrainAcc 0.9200 TestAcc 0.8421 0.8450
epoch 800 LossPred 0.2721 LossAtt 0.2817 TrainAcc 0.9200 TestAcc 0.8456 0.8550
epoch 900 LossPred 0.2618 LossAtt 0.2733 TrainAcc 0.9300 TestAcc 0.8373 0.8750
epoch 1000 LossPred 0.3080 LossAtt 0.2689 TrainAcc 0.8900 TestAcc 0.8313 0.8600
epoch 1100 LossPred 0.2582 LossAtt 0.2738 TrainAcc 0.9200 TestAcc 0.8473 0.8650
epoch 1200 LossPred 0.2492 LossAtt 0.2695 TrainAcc 0.9200 TestAcc 0.8463 0.8750
epoch 1300 LossPred 0.2428 LossAtt 0.2732 TrainAcc 0.9300 TestAcc 0.8481 0.8650
epoch 1400 LossPred 0.2484 LossAtt 0.2605 TrainAcc 0.9100 TestAcc 0.8488 0.8750
epoch 1500 LossPred 0.2483 LossAtt 0.2753 TrainAcc 0.9300 TestAcc 0.8331 0.8950
epoch 1600 LossPred 0.2675 LossAtt 0.2657 TrainAcc 0.9100 TestAcc 0.8443 0.8900
epoch 1700 LossPred 0.2473 LossAtt 0.2807 TrainAcc 0.9200 TestAcc 0.8313 0.8950
epoch 1800 LossPred 1.1238 LossAtt 0.2836 TrainAcc 0.6700 TestAcc 0.6109 0.6500
epoch 1900 LossPred 0.2465 LossAtt 0.2497 TrainAcc 0.9000 TestAcc 0.8481 0.8500
epoch 2000 LossPred 0.2430 LossAtt 0.2401 TrainAcc 0.9000 TestAcc 0.8421 0.8700
epoch 2100 LossPred 0.2664 LossAtt 0.2469 TrainAcc 0.8800 TestAcc 0.8316 0.8550
epoch 2200 LossPred 0.4756 LossAtt 0.2811 TrainAcc 0.8100 TestAcc 0.8013 0.8300
epoch 2300 LossPred 0.3016 LossAtt 0.2615 TrainAcc 0.9100 TestAcc 0.8516 0.8500
epoch 2400 LossPred 0.2414 LossAtt 0.2315 TrainAcc 0.9300 TestAcc 0.8443 0.8750
epoch 2500 LossPred 0.2347 LossAtt 0.2431 TrainAcc 0.9200 TestAcc 0.8391 0.8800
Optimization Finished!
********** replication  20  **********
epoch   0 LossPred 0.9890 LossAtt 1.0463 TrainAcc 0.5700 TestAcc 0.5383 0.5650
epoch 100 LossPred 0.4540 LossAtt 1.0079 TrainAcc 0.8600 TestAcc 0.7768 0.8450
epoch 200 LossPred 0.2865 LossAtt 0.5984 TrainAcc 0.9200 TestAcc 0.8611 0.9150
epoch 300 LossPred 0.2537 LossAtt 0.5071 TrainAcc 0.9200 TestAcc 0.8661 0.9150
epoch 400 LossPred 0.2179 LossAtt 0.4712 TrainAcc 0.9400 TestAcc 0.8749 0.9150
epoch 500 LossPred 0.2119 LossAtt 0.4581 TrainAcc 0.9400 TestAcc 0.8726 0.9050
epoch 600 LossPred 0.1933 LossAtt 0.4507 TrainAcc 0.9500 TestAcc 0.8839 0.9100
epoch 700 LossPred 0.1712 LossAtt 0.4335 TrainAcc 0.9500 TestAcc 0.8946 0.9100
epoch 800 LossPred 0.1350 LossAtt 0.4169 TrainAcc 0.9600 TestAcc 0.9079 0.9100
epoch 900 LossPred 0.1716 LossAtt 0.4112 TrainAcc 0.9400 TestAcc 0.8959 0.9400
epoch 1000 LossPred 0.0918 LossAtt 0.4247 TrainAcc 0.9800 TestAcc 0.9102 0.9000
epoch 1100 LossPred 0.0591 LossAtt 0.3832 TrainAcc 0.9900 TestAcc 0.9252 0.9100
epoch 1200 LossPred 0.0570 LossAtt 0.3890 TrainAcc 0.9900 TestAcc 0.9209 0.9250
epoch 1300 LossPred 0.0590 LossAtt 0.3791 TrainAcc 0.9900 TestAcc 0.9162 0.9150
epoch 1400 LossPred 0.1118 LossAtt 0.4263 TrainAcc 0.9600 TestAcc 0.8971 0.9200
epoch 1500 LossPred 0.0629 LossAtt 0.3730 TrainAcc 0.9900 TestAcc 0.9154 0.9100
epoch 1600 LossPred 0.0580 LossAtt 0.4072 TrainAcc 0.9900 TestAcc 0.9252 0.9300
epoch 1700 LossPred 0.0789 LossAtt 0.3757 TrainAcc 0.9700 TestAcc 0.9102 0.9350
epoch 1800 LossPred 0.1011 LossAtt 0.3818 TrainAcc 0.9600 TestAcc 0.9022 0.9200
epoch 1900 LossPred 0.0917 LossAtt 0.3896 TrainAcc 0.9700 TestAcc 0.9182 0.9150
epoch 2000 LossPred 0.0729 LossAtt 0.3708 TrainAcc 0.9600 TestAcc 0.9197 0.9450
epoch 2100 LossPred 0.0823 LossAtt 0.3744 TrainAcc 0.9800 TestAcc 0.9059 0.9300
epoch 2200 LossPred 0.0528 LossAtt 0.3728 TrainAcc 0.9800 TestAcc 0.9284 0.9200
epoch 2300 LossPred 0.0460 LossAtt 0.3557 TrainAcc 0.9900 TestAcc 0.9199 0.9200
epoch 2400 LossPred 0.0841 LossAtt 0.3461 TrainAcc 0.9700 TestAcc 0.9049 0.8900
epoch 2500 LossPred 0.0774 LossAtt 0.3477 TrainAcc 0.9900 TestAcc 0.9072 0.9400
Optimization Finished!
********** replication  21  **********
epoch   0 LossPred 1.0915 LossAtt 1.0292 TrainAcc 0.4500 TestAcc 0.5068 0.4550
epoch 100 LossPred 0.8126 LossAtt 0.6005 TrainAcc 0.6700 TestAcc 0.5701 0.6700
epoch 200 LossPred 0.5702 LossAtt 0.5748 TrainAcc 0.8300 TestAcc 0.7160 0.8150
epoch 300 LossPred 0.5715 LossAtt 0.4164 TrainAcc 0.7900 TestAcc 0.7375 0.8450
epoch 400 LossPred 0.3766 LossAtt 0.3776 TrainAcc 0.8800 TestAcc 0.8433 0.8250
epoch 500 LossPred 0.3064 LossAtt 0.3550 TrainAcc 0.9000 TestAcc 0.8401 0.8450
epoch 600 LossPred 0.3525 LossAtt 0.3817 TrainAcc 0.9000 TestAcc 0.8213 0.8500
epoch 700 LossPred 0.2921 LossAtt 0.4017 TrainAcc 0.9000 TestAcc 0.8321 0.8550
epoch 800 LossPred 0.3027 LossAtt 0.3463 TrainAcc 0.8900 TestAcc 0.8361 0.8500
epoch 900 LossPred 0.2144 LossAtt 0.3405 TrainAcc 0.9300 TestAcc 0.8368 0.8600
epoch 1000 LossPred 0.2061 LossAtt 0.3327 TrainAcc 0.9400 TestAcc 0.8396 0.8600
epoch 1100 LossPred 0.2016 LossAtt 0.3401 TrainAcc 0.9300 TestAcc 0.8361 0.8600
epoch 1200 LossPred 0.2291 LossAtt 0.3427 TrainAcc 0.9300 TestAcc 0.8211 0.8700
epoch 1300 LossPred 0.2012 LossAtt 0.3146 TrainAcc 0.9400 TestAcc 0.8358 0.8600
epoch 1400 LossPred 0.1937 LossAtt 0.3087 TrainAcc 0.9400 TestAcc 0.8401 0.8600
epoch 1500 LossPred 0.2023 LossAtt 0.3065 TrainAcc 0.9500 TestAcc 0.8353 0.8600
epoch 1600 LossPred 0.2053 LossAtt 0.3037 TrainAcc 0.9500 TestAcc 0.8303 0.8600
epoch 1700 LossPred 0.2581 LossAtt 0.3133 TrainAcc 0.9400 TestAcc 0.8323 0.8700
epoch 1800 LossPred 0.1998 LossAtt 0.3036 TrainAcc 0.9400 TestAcc 0.8376 0.8650
epoch 1900 LossPred 0.3496 LossAtt 0.3236 TrainAcc 0.9000 TestAcc 0.8133 0.8300
epoch 2000 LossPred 0.2133 LossAtt 0.2984 TrainAcc 0.9400 TestAcc 0.8381 0.8700
epoch 2100 LossPred 0.2344 LossAtt 0.3112 TrainAcc 0.9500 TestAcc 0.8346 0.8650
epoch 2200 LossPred 0.2039 LossAtt 0.3191 TrainAcc 0.9400 TestAcc 0.8396 0.8800
epoch 2300 LossPred 0.2131 LossAtt 0.3175 TrainAcc 0.9400 TestAcc 0.8363 0.8750
epoch 2400 LossPred 0.1915 LossAtt 0.3045 TrainAcc 0.9500 TestAcc 0.8519 0.8800
epoch 2500 LossPred 0.1868 LossAtt 0.2984 TrainAcc 0.9400 TestAcc 0.8514 0.8700
Optimization Finished!
********** replication  22  **********
epoch   0 LossPred 1.0834 LossAtt 1.0072 TrainAcc 0.5100 TestAcc 0.5250 0.5000
epoch 100 LossPred 0.9042 LossAtt 0.6517 TrainAcc 0.6500 TestAcc 0.6171 0.6150
epoch 200 LossPred 0.6779 LossAtt 0.6800 TrainAcc 0.7800 TestAcc 0.7330 0.7400
epoch 300 LossPred 0.5300 LossAtt 0.5164 TrainAcc 0.8500 TestAcc 0.7793 0.7950
epoch 400 LossPred 0.4041 LossAtt 0.5145 TrainAcc 0.9000 TestAcc 0.8101 0.8600
epoch 500 LossPred 0.3821 LossAtt 0.5772 TrainAcc 0.9000 TestAcc 0.8136 0.8400
epoch 600 LossPred 0.4142 LossAtt 0.5139 TrainAcc 0.8900 TestAcc 0.8301 0.8600
epoch 700 LossPred 0.2638 LossAtt 0.5167 TrainAcc 0.9400 TestAcc 0.8649 0.9050
epoch 800 LossPred 0.2079 LossAtt 0.5086 TrainAcc 0.9700 TestAcc 0.8644 0.8950
epoch 900 LossPred 0.1522 LossAtt 0.5245 TrainAcc 0.9700 TestAcc 0.8806 0.9250
epoch 1000 LossPred 0.1141 LossAtt 0.5428 TrainAcc 0.9900 TestAcc 0.8844 0.9350
epoch 1100 LossPred 0.0996 LossAtt 0.5201 TrainAcc 0.9800 TestAcc 0.8796 0.9350
epoch 1200 LossPred 0.0898 LossAtt 0.5283 TrainAcc 0.9900 TestAcc 0.8771 0.9300
epoch 1300 LossPred 0.0820 LossAtt 0.5244 TrainAcc 0.9900 TestAcc 0.8756 0.9350
epoch 1400 LossPred 0.0637 LossAtt 0.5514 TrainAcc 1.0000 TestAcc 0.8666 0.9400
Optimization Finished!
********** replication  23  **********
epoch   0 LossPred 1.1146 LossAtt 1.0292 TrainAcc 0.5000 TestAcc 0.4960 0.4800
epoch 100 LossPred 0.9659 LossAtt 0.5599 TrainAcc 0.6500 TestAcc 0.5773 0.6500
epoch 200 LossPred 0.7579 LossAtt 1.1809 TrainAcc 0.7200 TestAcc 0.6812 0.7000
epoch 300 LossPred 0.3760 LossAtt 0.6687 TrainAcc 0.8900 TestAcc 0.8198 0.8650
epoch 400 LossPred 0.1618 LossAtt 0.6547 TrainAcc 0.9800 TestAcc 0.8539 0.9300
epoch 500 LossPred 0.0934 LossAtt 0.6129 TrainAcc 0.9900 TestAcc 0.8443 0.9400
epoch 600 LossPred 0.0762 LossAtt 0.5980 TrainAcc 0.9900 TestAcc 0.8376 0.9450
epoch 700 LossPred 0.0589 LossAtt 0.5913 TrainAcc 0.9900 TestAcc 0.8378 0.9350
epoch 800 LossPred 0.0590 LossAtt 0.5886 TrainAcc 1.0000 TestAcc 0.8321 0.9400
Optimization Finished!
********** replication  24  **********
epoch   0 LossPred 0.9802 LossAtt 1.0170 TrainAcc 0.5800 TestAcc 0.5143 0.5950
epoch 100 LossPred 0.8252 LossAtt 0.8595 TrainAcc 0.6600 TestAcc 0.5978 0.6650
epoch 200 LossPred 0.6760 LossAtt 0.7144 TrainAcc 0.7400 TestAcc 0.5761 0.7300
epoch 300 LossPred 0.5898 LossAtt 0.8100 TrainAcc 0.8200 TestAcc 0.5591 0.7850
epoch 400 LossPred 0.4564 LossAtt 0.7443 TrainAcc 0.8600 TestAcc 0.5508 0.7800
epoch 500 LossPred 0.3761 LossAtt 0.7318 TrainAcc 0.8800 TestAcc 0.5508 0.7700
epoch 600 LossPred 0.3484 LossAtt 0.7884 TrainAcc 0.8900 TestAcc 0.5375 0.8000
epoch 700 LossPred 0.2471 LossAtt 0.7314 TrainAcc 0.9600 TestAcc 0.5345 0.8250
epoch 800 LossPred 0.2216 LossAtt 0.6994 TrainAcc 0.9700 TestAcc 0.5355 0.8200
epoch 900 LossPred 0.2475 LossAtt 0.8124 TrainAcc 0.9600 TestAcc 0.5325 0.7900
epoch 1000 LossPred 0.1639 LossAtt 0.7106 TrainAcc 0.9800 TestAcc 0.5340 0.8100
epoch 1100 LossPred 0.1240 LossAtt 0.6957 TrainAcc 1.0000 TestAcc 0.5325 0.8200
Optimization Finished!
********** replication  25  **********
epoch   0 LossPred 1.0322 LossAtt 1.0355 TrainAcc 0.4600 TestAcc 0.4575 0.4650
epoch 100 LossPred 0.9321 LossAtt 0.6741 TrainAcc 0.6400 TestAcc 0.5646 0.6300
epoch 200 LossPred 0.5204 LossAtt 0.7072 TrainAcc 0.8300 TestAcc 0.7893 0.7900
epoch 300 LossPred 0.3491 LossAtt 0.5672 TrainAcc 0.9200 TestAcc 0.8696 0.8550
epoch 400 LossPred 0.2262 LossAtt 0.5519 TrainAcc 0.9500 TestAcc 0.8821 0.8850
epoch 500 LossPred 0.4183 LossAtt 0.5461 TrainAcc 0.8400 TestAcc 0.8311 0.8650
epoch 600 LossPred 0.2338 LossAtt 0.5021 TrainAcc 0.9400 TestAcc 0.8766 0.8850
epoch 700 LossPred 0.1292 LossAtt 0.4729 TrainAcc 0.9700 TestAcc 0.8804 0.9100
epoch 800 LossPred 0.1131 LossAtt 0.4655 TrainAcc 0.9700 TestAcc 0.8809 0.9150
epoch 900 LossPred 0.1169 LossAtt 0.4585 TrainAcc 0.9700 TestAcc 0.8884 0.9200
epoch 1000 LossPred 0.1383 LossAtt 0.4507 TrainAcc 0.9600 TestAcc 0.8901 0.9000
epoch 1100 LossPred 0.2080 LossAtt 0.4586 TrainAcc 0.9100 TestAcc 0.8599 0.9150
epoch 1200 LossPred 0.1118 LossAtt 0.4622 TrainAcc 0.9600 TestAcc 0.8739 0.9200
epoch 1300 LossPred 0.1113 LossAtt 0.4643 TrainAcc 0.9600 TestAcc 0.8866 0.9300
epoch 1400 LossPred 0.0622 LossAtt 0.4638 TrainAcc 0.9800 TestAcc 0.8846 0.9350
epoch 1500 LossPred 0.0633 LossAtt 0.4711 TrainAcc 0.9900 TestAcc 0.8744 0.9300
epoch 1600 LossPred 0.0552 LossAtt 0.4564 TrainAcc 0.9900 TestAcc 0.8681 0.9450
epoch 1700 LossPred 0.0992 LossAtt 0.4688 TrainAcc 0.9800 TestAcc 0.8691 0.9400
epoch 1800 LossPred 0.0594 LossAtt 0.4505 TrainAcc 0.9800 TestAcc 0.8764 0.9350
epoch 1900 LossPred 0.0491 LossAtt 0.4376 TrainAcc 0.9800 TestAcc 0.8816 0.9450
epoch 2000 LossPred 0.0375 LossAtt 0.4486 TrainAcc 0.9900 TestAcc 0.8701 0.9400
epoch 2100 LossPred 0.0756 LossAtt 0.4554 TrainAcc 0.9800 TestAcc 0.8791 0.9300
epoch 2200 LossPred 0.0395 LossAtt 0.4446 TrainAcc 0.9900 TestAcc 0.8726 0.9500
epoch 2300 LossPred 0.0349 LossAtt 0.4578 TrainAcc 1.0000 TestAcc 0.8679 0.9450
Optimization Finished!
********** replication  26  **********
epoch   0 LossPred 1.0982 LossAtt 1.0214 TrainAcc 0.4400 TestAcc 0.5390 0.4300
epoch 100 LossPred 0.7048 LossAtt 0.7713 TrainAcc 0.7500 TestAcc 0.5868 0.7650
epoch 200 LossPred 0.3090 LossAtt 0.6876 TrainAcc 0.9100 TestAcc 0.7813 0.8800
epoch 300 LossPred 0.2905 LossAtt 0.5208 TrainAcc 0.9200 TestAcc 0.8008 0.8850
epoch 400 LossPred 0.1909 LossAtt 0.4844 TrainAcc 0.9600 TestAcc 0.8351 0.9000
epoch 500 LossPred 0.0781 LossAtt 0.4835 TrainAcc 1.0000 TestAcc 0.8343 0.9400
Optimization Finished!
********** replication  27  **********
epoch   0 LossPred 1.1086 LossAtt 1.0161 TrainAcc 0.4600 TestAcc 0.4717 0.4600
epoch 100 LossPred 0.9394 LossAtt 0.6714 TrainAcc 0.6400 TestAcc 0.5831 0.6100
epoch 200 LossPred 0.4125 LossAtt 1.0133 TrainAcc 0.9100 TestAcc 0.7965 0.8800
epoch 300 LossPred 0.2292 LossAtt 0.6637 TrainAcc 0.9500 TestAcc 0.8391 0.8950
epoch 400 LossPred 0.1701 LossAtt 0.5913 TrainAcc 0.9600 TestAcc 0.8336 0.9050
epoch 500 LossPred 0.1570 LossAtt 0.5619 TrainAcc 0.9600 TestAcc 0.8296 0.9100
epoch 600 LossPred 0.1492 LossAtt 0.5785 TrainAcc 0.9500 TestAcc 0.8276 0.8950
epoch 700 LossPred 0.1124 LossAtt 0.5331 TrainAcc 0.9700 TestAcc 0.8311 0.9200
epoch 800 LossPred 0.1222 LossAtt 0.5397 TrainAcc 0.9700 TestAcc 0.8283 0.9200
epoch 900 LossPred 0.5901 LossAtt 0.6069 TrainAcc 0.8200 TestAcc 0.7815 0.8350
epoch 1000 LossPred 0.0836 LossAtt 0.5053 TrainAcc 0.9800 TestAcc 0.8278 0.9350
epoch 1100 LossPred 0.0778 LossAtt 0.5009 TrainAcc 0.9800 TestAcc 0.8281 0.9250
epoch 1200 LossPred 0.0739 LossAtt 0.4899 TrainAcc 0.9800 TestAcc 0.8306 0.9250
epoch 1300 LossPred 0.1426 LossAtt 0.4786 TrainAcc 0.9600 TestAcc 0.8306 0.9300
epoch 1400 LossPred 0.1730 LossAtt 0.6162 TrainAcc 0.9500 TestAcc 0.8206 0.8950
epoch 1500 LossPred 0.0691 LossAtt 0.4917 TrainAcc 0.9800 TestAcc 0.8358 0.9250
epoch 1600 LossPred 0.0668 LossAtt 0.4752 TrainAcc 0.9800 TestAcc 0.8356 0.9250
epoch 1700 LossPred 0.0667 LossAtt 0.4742 TrainAcc 0.9800 TestAcc 0.8363 0.9250
epoch 1800 LossPred 0.0822 LossAtt 0.4720 TrainAcc 0.9800 TestAcc 0.8263 0.9150
epoch 1900 LossPred 0.0716 LossAtt 0.5048 TrainAcc 0.9800 TestAcc 0.8331 0.9200
epoch 2000 LossPred 0.0670 LossAtt 0.4586 TrainAcc 0.9800 TestAcc 0.8323 0.9300
epoch 2100 LossPred 0.0654 LossAtt 0.4664 TrainAcc 0.9800 TestAcc 0.8336 0.9350
epoch 2200 LossPred 0.0635 LossAtt 0.4641 TrainAcc 0.9800 TestAcc 0.8338 0.9250
epoch 2300 LossPred 0.0624 LossAtt 0.4644 TrainAcc 0.9800 TestAcc 0.8333 0.9300
epoch 2400 LossPred 0.0619 LossAtt 0.4579 TrainAcc 0.9900 TestAcc 0.8381 0.9300
epoch 2500 LossPred 0.0612 LossAtt 0.4635 TrainAcc 0.9800 TestAcc 0.8376 0.9250
Optimization Finished!
********** replication  28  **********
epoch   0 LossPred 1.0779 LossAtt 1.0172 TrainAcc 0.5600 TestAcc 0.4507 0.5800
epoch 100 LossPred 0.8011 LossAtt 0.8956 TrainAcc 0.6900 TestAcc 0.5025 0.6850
epoch 200 LossPred 0.7518 LossAtt 0.6194 TrainAcc 0.7000 TestAcc 0.4997 0.6900
epoch 300 LossPred 0.7228 LossAtt 0.5779 TrainAcc 0.7200 TestAcc 0.4952 0.6750
epoch 400 LossPred 0.6665 LossAtt 0.6246 TrainAcc 0.7000 TestAcc 0.5000 0.7000
epoch 500 LossPred 0.6195 LossAtt 0.6893 TrainAcc 0.7600 TestAcc 0.5025 0.7350
epoch 600 LossPred 0.5349 LossAtt 0.7232 TrainAcc 0.8100 TestAcc 0.4995 0.7950
epoch 700 LossPred 0.5093 LossAtt 0.7199 TrainAcc 0.8400 TestAcc 0.5075 0.7950
epoch 800 LossPred 0.4186 LossAtt 0.6669 TrainAcc 0.8800 TestAcc 0.5088 0.8200
epoch 900 LossPred 0.3590 LossAtt 0.6742 TrainAcc 0.8900 TestAcc 0.5123 0.8400
epoch 1000 LossPred 0.3199 LossAtt 0.6456 TrainAcc 0.9100 TestAcc 0.5098 0.8500
epoch 1100 LossPred 0.2939 LossAtt 0.6128 TrainAcc 0.9100 TestAcc 0.5130 0.8500
epoch 1200 LossPred 0.2648 LossAtt 0.6204 TrainAcc 0.9100 TestAcc 0.5140 0.8200
epoch 1300 LossPred 0.2577 LossAtt 0.6343 TrainAcc 0.9200 TestAcc 0.5115 0.8300
epoch 1400 LossPred 0.2598 LossAtt 0.6369 TrainAcc 0.9200 TestAcc 0.5100 0.8200
epoch 1500 LossPred 0.2349 LossAtt 0.6049 TrainAcc 0.9300 TestAcc 0.5078 0.8300
epoch 1600 LossPred 0.2275 LossAtt 0.6472 TrainAcc 0.9500 TestAcc 0.5050 0.8150
epoch 1700 LossPred 0.1995 LossAtt 0.5806 TrainAcc 0.9300 TestAcc 0.5110 0.8150
epoch 1800 LossPred 0.2661 LossAtt 0.6203 TrainAcc 0.9000 TestAcc 0.4990 0.8400
epoch 1900 LossPred 0.1825 LossAtt 0.5794 TrainAcc 0.9500 TestAcc 0.5033 0.8450
epoch 2000 LossPred 0.1697 LossAtt 0.5589 TrainAcc 0.9500 TestAcc 0.5023 0.8550
epoch 2100 LossPred 0.1596 LossAtt 0.5668 TrainAcc 0.9500 TestAcc 0.5053 0.8500
epoch 2200 LossPred 0.1667 LossAtt 0.5720 TrainAcc 0.9400 TestAcc 0.5010 0.8400
epoch 2300 LossPred 0.1802 LossAtt 0.6045 TrainAcc 0.9600 TestAcc 0.5033 0.8600
epoch 2400 LossPred 0.1671 LossAtt 0.5555 TrainAcc 0.9600 TestAcc 0.5068 0.8800
epoch 2500 LossPred 0.1439 LossAtt 0.5557 TrainAcc 0.9600 TestAcc 0.5093 0.8700
Optimization Finished!
********** replication  29  **********
epoch   0 LossPred 1.0246 LossAtt 1.0551 TrainAcc 0.4800 TestAcc 0.4730 0.4800
epoch 100 LossPred 0.8638 LossAtt 1.0183 TrainAcc 0.6800 TestAcc 0.6299 0.6800
epoch 200 LossPred 0.6185 LossAtt 0.5042 TrainAcc 0.8200 TestAcc 0.8256 0.8200
epoch 300 LossPred 0.3943 LossAtt 0.3861 TrainAcc 0.8800 TestAcc 0.8423 0.8500
epoch 400 LossPred 0.3442 LossAtt 0.3506 TrainAcc 0.9200 TestAcc 0.8473 0.8600
epoch 500 LossPred 0.3300 LossAtt 0.3422 TrainAcc 0.9100 TestAcc 0.8478 0.8550
epoch 600 LossPred 0.3176 LossAtt 0.3296 TrainAcc 0.9100 TestAcc 0.8516 0.8650
epoch 700 LossPred 0.7835 LossAtt 0.3680 TrainAcc 0.7400 TestAcc 0.7660 0.7850
epoch 800 LossPred 0.3323 LossAtt 0.3394 TrainAcc 0.9100 TestAcc 0.8341 0.8750
epoch 900 LossPred 0.3138 LossAtt 0.3220 TrainAcc 0.9100 TestAcc 0.8493 0.8750
epoch 1000 LossPred 0.3083 LossAtt 0.3007 TrainAcc 0.9100 TestAcc 0.8504 0.8750
epoch 1100 LossPred 0.3047 LossAtt 0.3075 TrainAcc 0.9100 TestAcc 0.8536 0.8700
epoch 1200 LossPred 0.3039 LossAtt 0.3050 TrainAcc 0.9200 TestAcc 0.8536 0.8650
epoch 1300 LossPred 0.4146 LossAtt 0.3059 TrainAcc 0.8600 TestAcc 0.8248 0.8600
epoch 1400 LossPred 0.3143 LossAtt 0.2825 TrainAcc 0.9100 TestAcc 0.8453 0.8750
epoch 1500 LossPred 0.3010 LossAtt 0.2803 TrainAcc 0.9100 TestAcc 0.8559 0.8800
epoch 1600 LossPred 0.2988 LossAtt 0.2720 TrainAcc 0.9100 TestAcc 0.8549 0.8800
epoch 1700 LossPred 0.2977 LossAtt 0.2696 TrainAcc 0.9200 TestAcc 0.8514 0.8650
epoch 1800 LossPred 0.2940 LossAtt 0.2707 TrainAcc 0.9100 TestAcc 0.8554 0.8750
epoch 1900 LossPred 0.3737 LossAtt 0.3039 TrainAcc 0.8900 TestAcc 0.8398 0.8800
epoch 2000 LossPred 0.3163 LossAtt 0.3238 TrainAcc 0.9000 TestAcc 0.8448 0.8800
epoch 2100 LossPred 0.2966 LossAtt 0.2624 TrainAcc 0.9100 TestAcc 0.8541 0.8850
epoch 2200 LossPred 0.2925 LossAtt 0.2489 TrainAcc 0.9200 TestAcc 0.8564 0.8900
epoch 2300 LossPred 0.2910 LossAtt 0.2557 TrainAcc 0.9200 TestAcc 0.8541 0.8850
epoch 2400 LossPred 0.3211 LossAtt 0.2591 TrainAcc 0.9000 TestAcc 0.8428 0.8650
epoch 2500 LossPred 0.6562 LossAtt 0.6188 TrainAcc 0.8000 TestAcc 0.7550 0.7950
Optimization Finished!
********** replication  30  **********
epoch   0 LossPred 1.0875 LossAtt 1.0457 TrainAcc 0.4600 TestAcc 0.4174 0.4650
epoch 100 LossPred 0.8893 LossAtt 0.5807 TrainAcc 0.6300 TestAcc 0.5395 0.6300
epoch 200 LossPred 0.3880 LossAtt 0.5733 TrainAcc 0.8900 TestAcc 0.8116 0.8300
epoch 300 LossPred 0.3327 LossAtt 0.4537 TrainAcc 0.9000 TestAcc 0.8131 0.8200
epoch 400 LossPred 0.3129 LossAtt 0.4136 TrainAcc 0.9100 TestAcc 0.8106 0.8350
epoch 500 LossPred 0.3003 LossAtt 0.3779 TrainAcc 0.9100 TestAcc 0.8198 0.8500
epoch 600 LossPred 0.2831 LossAtt 0.3753 TrainAcc 0.9200 TestAcc 0.8246 0.8500
epoch 700 LossPred 0.3685 LossAtt 0.3942 TrainAcc 0.8700 TestAcc 0.7948 0.8150
epoch 800 LossPred 0.2661 LossAtt 0.3887 TrainAcc 0.9300 TestAcc 0.8196 0.8400
epoch 900 LossPred 0.2440 LossAtt 0.4206 TrainAcc 0.9300 TestAcc 0.8396 0.8400
epoch 1000 LossPred 0.5153 LossAtt 0.4070 TrainAcc 0.8300 TestAcc 0.7668 0.8050
epoch 1100 LossPred 0.3183 LossAtt 0.3626 TrainAcc 0.8700 TestAcc 0.8416 0.8700
epoch 1200 LossPred 0.1813 LossAtt 0.3706 TrainAcc 0.9500 TestAcc 0.8704 0.8400
epoch 1300 LossPred 0.1440 LossAtt 0.3682 TrainAcc 0.9600 TestAcc 0.8829 0.8900
epoch 1400 LossPred 0.2029 LossAtt 0.3679 TrainAcc 0.9400 TestAcc 0.8714 0.8650
epoch 1500 LossPred 0.2059 LossAtt 0.3900 TrainAcc 0.9200 TestAcc 0.8649 0.8550
epoch 1600 LossPred 0.1171 LossAtt 0.3731 TrainAcc 0.9700 TestAcc 0.8914 0.9150
epoch 1700 LossPred 0.1064 LossAtt 0.3701 TrainAcc 0.9800 TestAcc 0.8936 0.9150
epoch 1800 LossPred 0.1014 LossAtt 0.3620 TrainAcc 0.9800 TestAcc 0.9004 0.9100
epoch 1900 LossPred 0.1054 LossAtt 0.3558 TrainAcc 0.9800 TestAcc 0.9014 0.9200
epoch 2000 LossPred 0.2369 LossAtt 0.3577 TrainAcc 0.9400 TestAcc 0.8706 0.9100
epoch 2100 LossPred 0.0921 LossAtt 0.3573 TrainAcc 0.9800 TestAcc 0.9002 0.9250
epoch 2200 LossPred 0.0892 LossAtt 0.3451 TrainAcc 0.9800 TestAcc 0.8989 0.9350
epoch 2300 LossPred 0.1732 LossAtt 0.3478 TrainAcc 0.9600 TestAcc 0.8809 0.9150
epoch 2400 LossPred 1.5316 LossAtt 0.3911 TrainAcc 0.5600 TestAcc 0.5828 0.5650
epoch 2500 LossPred 0.7345 LossAtt 0.3202 TrainAcc 0.7800 TestAcc 0.6967 0.7650
Optimization Finished!
********** replication  31  **********
epoch   0 LossPred 1.0647 LossAtt 1.0148 TrainAcc 0.4900 TestAcc 0.4274 0.5150
epoch 100 LossPred 0.8661 LossAtt 0.7758 TrainAcc 0.7000 TestAcc 0.5160 0.6900
epoch 200 LossPred 0.6176 LossAtt 1.0217 TrainAcc 0.7300 TestAcc 0.5093 0.7150
epoch 300 LossPred 0.5190 LossAtt 0.9858 TrainAcc 0.8000 TestAcc 0.5203 0.7250
epoch 400 LossPred 0.4650 LossAtt 0.8840 TrainAcc 0.8500 TestAcc 0.5355 0.7300
epoch 500 LossPred 0.4072 LossAtt 0.8734 TrainAcc 0.8700 TestAcc 0.5383 0.7650
epoch 600 LossPred 0.3838 LossAtt 0.7478 TrainAcc 0.9100 TestAcc 0.5430 0.7750
epoch 700 LossPred 0.3434 LossAtt 0.7612 TrainAcc 0.9200 TestAcc 0.5413 0.7650
epoch 800 LossPred 0.3376 LossAtt 0.7096 TrainAcc 0.9200 TestAcc 0.5393 0.7800
epoch 900 LossPred 0.4377 LossAtt 0.8405 TrainAcc 0.8700 TestAcc 0.5430 0.7850
epoch 1000 LossPred 0.3017 LossAtt 0.6805 TrainAcc 0.9400 TestAcc 0.5330 0.7750
epoch 1100 LossPred 0.2796 LossAtt 0.6531 TrainAcc 0.9500 TestAcc 0.5345 0.7750
epoch 1200 LossPred 0.3241 LossAtt 0.6653 TrainAcc 0.9100 TestAcc 0.5495 0.7700
epoch 1300 LossPred 0.2517 LossAtt 0.6585 TrainAcc 0.9500 TestAcc 0.5365 0.7850
epoch 1400 LossPred 0.2720 LossAtt 0.6816 TrainAcc 0.9500 TestAcc 0.5513 0.8250
epoch 1500 LossPred 0.2427 LossAtt 0.6925 TrainAcc 0.9600 TestAcc 0.5443 0.7800
epoch 1600 LossPred 0.2190 LossAtt 0.6472 TrainAcc 0.9500 TestAcc 0.5423 0.8050
epoch 1700 LossPred 0.2047 LossAtt 0.6541 TrainAcc 0.9500 TestAcc 0.5383 0.7850
epoch 1800 LossPred 0.2594 LossAtt 0.8552 TrainAcc 0.9400 TestAcc 0.5423 0.7650
epoch 1900 LossPred 0.6460 LossAtt 0.9642 TrainAcc 0.7900 TestAcc 0.5601 0.7750
epoch 2000 LossPred 0.1904 LossAtt 0.6632 TrainAcc 0.9700 TestAcc 0.5420 0.8400
epoch 2100 LossPred 0.1707 LossAtt 0.6376 TrainAcc 0.9700 TestAcc 0.5343 0.8200
epoch 2200 LossPred 0.1597 LossAtt 0.6539 TrainAcc 0.9700 TestAcc 0.5360 0.8350
epoch 2300 LossPred 0.4044 LossAtt 1.0991 TrainAcc 0.8700 TestAcc 0.5190 0.7700
epoch 2400 LossPred 0.1748 LossAtt 0.7031 TrainAcc 0.9700 TestAcc 0.5390 0.8200
epoch 2500 LossPred 0.1523 LossAtt 0.6573 TrainAcc 0.9700 TestAcc 0.5323 0.8550
Optimization Finished!
********** replication  32  **********
epoch   0 LossPred 1.0208 LossAtt 0.9982 TrainAcc 0.4700 TestAcc 0.4837 0.4750
epoch 100 LossPred 0.8790 LossAtt 0.7212 TrainAcc 0.6700 TestAcc 0.5821 0.6550
epoch 200 LossPred 0.3512 LossAtt 0.6959 TrainAcc 0.9200 TestAcc 0.7938 0.8850
epoch 300 LossPred 0.1953 LossAtt 0.5200 TrainAcc 0.9600 TestAcc 0.8031 0.8650
epoch 400 LossPred 0.2322 LossAtt 0.5016 TrainAcc 0.9200 TestAcc 0.8128 0.8700
epoch 500 LossPred 0.1324 LossAtt 0.4666 TrainAcc 0.9700 TestAcc 0.8201 0.8850
epoch 600 LossPred 0.1149 LossAtt 0.4532 TrainAcc 0.9800 TestAcc 0.8208 0.8800
epoch 700 LossPred 0.1063 LossAtt 0.4577 TrainAcc 0.9700 TestAcc 0.8251 0.8750
epoch 800 LossPred 0.0922 LossAtt 0.4467 TrainAcc 0.9900 TestAcc 0.8311 0.8750
epoch 900 LossPred 0.0669 LossAtt 0.4488 TrainAcc 1.0000 TestAcc 0.8413 0.8800
Optimization Finished!
********** replication  33  **********
epoch   0 LossPred 1.0708 LossAtt 1.0356 TrainAcc 0.4500 TestAcc 0.4887 0.4150
epoch 100 LossPred 0.7851 LossAtt 0.5262 TrainAcc 0.6600 TestAcc 0.5716 0.6850
epoch 200 LossPred 0.7342 LossAtt 0.7787 TrainAcc 0.7600 TestAcc 0.6061 0.7450
epoch 300 LossPred 0.6610 LossAtt 0.5375 TrainAcc 0.7900 TestAcc 0.6639 0.7900
epoch 400 LossPred 0.5971 LossAtt 0.4686 TrainAcc 0.8000 TestAcc 0.6799 0.7950
epoch 500 LossPred 0.5782 LossAtt 0.4577 TrainAcc 0.8000 TestAcc 0.7090 0.7650
epoch 600 LossPred 0.7044 LossAtt 0.5391 TrainAcc 0.8000 TestAcc 0.6504 0.7550
epoch 700 LossPred 0.5849 LossAtt 0.4437 TrainAcc 0.8100 TestAcc 0.6777 0.8000
epoch 800 LossPred 0.5495 LossAtt 0.4669 TrainAcc 0.8100 TestAcc 0.7245 0.8050
epoch 900 LossPred 0.4060 LossAtt 0.5161 TrainAcc 0.8700 TestAcc 0.7357 0.8400
epoch 1000 LossPred 0.3832 LossAtt 0.4685 TrainAcc 0.8600 TestAcc 0.7457 0.8500
epoch 1100 LossPred 0.3607 LossAtt 0.4493 TrainAcc 0.8800 TestAcc 0.7508 0.8550
epoch 1200 LossPred 0.3388 LossAtt 0.4439 TrainAcc 0.8800 TestAcc 0.7550 0.8450
epoch 1300 LossPred 0.6688 LossAtt 0.4436 TrainAcc 0.7900 TestAcc 0.6429 0.7650
epoch 1400 LossPred 0.3419 LossAtt 0.4250 TrainAcc 0.8800 TestAcc 0.7407 0.8500
epoch 1500 LossPred 0.3113 LossAtt 0.4100 TrainAcc 0.8900 TestAcc 0.7497 0.8550
epoch 1600 LossPred 0.2961 LossAtt 0.4155 TrainAcc 0.9100 TestAcc 0.7465 0.8650
epoch 1700 LossPred 0.2927 LossAtt 0.4197 TrainAcc 0.9000 TestAcc 0.7445 0.8800
epoch 1800 LossPred 0.2984 LossAtt 0.4375 TrainAcc 0.8900 TestAcc 0.7470 0.8750
epoch 1900 LossPred 0.2655 LossAtt 0.4004 TrainAcc 0.9300 TestAcc 0.7432 0.8900
epoch 2000 LossPred 0.2584 LossAtt 0.3973 TrainAcc 0.9300 TestAcc 0.7347 0.8850
epoch 2100 LossPred 0.2811 LossAtt 0.4038 TrainAcc 0.9300 TestAcc 0.7302 0.8950
epoch 2200 LossPred 0.2549 LossAtt 0.3924 TrainAcc 0.9400 TestAcc 0.7385 0.8950
epoch 2300 LossPred 0.2536 LossAtt 0.4063 TrainAcc 0.9300 TestAcc 0.7362 0.8900
epoch 2400 LossPred 0.3584 LossAtt 0.4538 TrainAcc 0.9000 TestAcc 0.7275 0.8600
epoch 2500 LossPred 0.2402 LossAtt 0.3859 TrainAcc 0.9400 TestAcc 0.7325 0.8800
Optimization Finished!
********** replication  34  **********
epoch   0 LossPred 1.0672 LossAtt 1.0440 TrainAcc 0.4900 TestAcc 0.4877 0.5200
epoch 100 LossPred 0.8308 LossAtt 0.6594 TrainAcc 0.6300 TestAcc 0.6229 0.6400
epoch 200 LossPred 0.3106 LossAtt 0.6306 TrainAcc 0.9100 TestAcc 0.8193 0.8800
epoch 300 LossPred 0.2395 LossAtt 0.4780 TrainAcc 0.9200 TestAcc 0.8291 0.8900
epoch 400 LossPred 0.2381 LossAtt 0.4624 TrainAcc 0.9200 TestAcc 0.8338 0.9050
epoch 500 LossPred 0.2158 LossAtt 0.4238 TrainAcc 0.9300 TestAcc 0.8453 0.8900
epoch 600 LossPred 0.1703 LossAtt 0.4053 TrainAcc 0.9700 TestAcc 0.8441 0.9200
epoch 700 LossPred 0.1438 LossAtt 0.3967 TrainAcc 0.9700 TestAcc 0.8559 0.9150
epoch 800 LossPred 0.1316 LossAtt 0.3836 TrainAcc 0.9700 TestAcc 0.8604 0.9250
epoch 900 LossPred 0.1239 LossAtt 0.3750 TrainAcc 0.9700 TestAcc 0.8619 0.9200
epoch 1000 LossPred 0.1208 LossAtt 0.3666 TrainAcc 0.9800 TestAcc 0.8659 0.9100
epoch 1100 LossPred 0.1147 LossAtt 0.4625 TrainAcc 0.9700 TestAcc 0.8589 0.9100
epoch 1200 LossPred 0.1561 LossAtt 0.4004 TrainAcc 0.9500 TestAcc 0.8473 0.9200
epoch 1300 LossPred 0.1157 LossAtt 0.4079 TrainAcc 0.9800 TestAcc 0.8784 0.9150
epoch 1400 LossPred 0.1113 LossAtt 0.3537 TrainAcc 0.9700 TestAcc 0.8721 0.9050
epoch 1500 LossPred 0.1049 LossAtt 0.3842 TrainAcc 0.9800 TestAcc 0.8724 0.9000
epoch 1600 LossPred 0.0925 LossAtt 0.3837 TrainAcc 0.9800 TestAcc 0.8824 0.9000
epoch 1700 LossPred 0.0930 LossAtt 0.3782 TrainAcc 0.9800 TestAcc 0.8726 0.9000
epoch 1800 LossPred 0.0907 LossAtt 0.3414 TrainAcc 0.9900 TestAcc 0.8784 0.8950
epoch 1900 LossPred 0.1103 LossAtt 0.3628 TrainAcc 0.9800 TestAcc 0.8896 0.8850
epoch 2000 LossPred 0.0750 LossAtt 0.3379 TrainAcc 0.9800 TestAcc 0.8821 0.9050
epoch 2100 LossPred 0.2558 LossAtt 0.3382 TrainAcc 0.9000 TestAcc 0.8679 0.8750
epoch 2200 LossPred 0.0715 LossAtt 0.3216 TrainAcc 0.9900 TestAcc 0.8929 0.8900
epoch 2300 LossPred 0.1750 LossAtt 0.3405 TrainAcc 0.9300 TestAcc 0.8631 0.9050
epoch 2400 LossPred 0.0710 LossAtt 0.3456 TrainAcc 0.9900 TestAcc 0.8901 0.9050
epoch 2500 LossPred 0.0686 LossAtt 0.3308 TrainAcc 0.9900 TestAcc 0.8886 0.8950
Optimization Finished!
********** replication  35  **********
epoch   0 LossPred 1.0643 LossAtt 1.0199 TrainAcc 0.5400 TestAcc 0.4955 0.5350
epoch 100 LossPred 0.5536 LossAtt 0.8892 TrainAcc 0.7900 TestAcc 0.6436 0.8000
epoch 200 LossPred 0.2899 LossAtt 0.5756 TrainAcc 0.9200 TestAcc 0.8183 0.8800
epoch 300 LossPred 0.2320 LossAtt 0.4879 TrainAcc 0.9500 TestAcc 0.8231 0.8750
epoch 400 LossPred 0.2181 LossAtt 0.4740 TrainAcc 0.9500 TestAcc 0.8258 0.8800
epoch 500 LossPred 0.2095 LossAtt 0.4496 TrainAcc 0.9500 TestAcc 0.8263 0.8800
epoch 600 LossPred 0.2093 LossAtt 0.4273 TrainAcc 0.9500 TestAcc 0.8303 0.8900
epoch 700 LossPred 0.2055 LossAtt 0.4230 TrainAcc 0.9500 TestAcc 0.8238 0.8950
epoch 800 LossPred 0.2062 LossAtt 0.4023 TrainAcc 0.9500 TestAcc 0.8261 0.8950
epoch 900 LossPred 0.2026 LossAtt 0.4058 TrainAcc 0.9500 TestAcc 0.8236 0.8850
epoch 1000 LossPred 0.2042 LossAtt 0.3850 TrainAcc 0.9500 TestAcc 0.8273 0.8900
epoch 1100 LossPred 0.2360 LossAtt 0.3819 TrainAcc 0.9400 TestAcc 0.8148 0.8650
epoch 1200 LossPred 0.2155 LossAtt 0.3918 TrainAcc 0.9500 TestAcc 0.8211 0.8850
epoch 1300 LossPred 0.2060 LossAtt 0.3879 TrainAcc 0.9500 TestAcc 0.8311 0.8850
epoch 1400 LossPred 0.2022 LossAtt 0.3627 TrainAcc 0.9500 TestAcc 0.8266 0.8750
epoch 1500 LossPred 0.1948 LossAtt 0.3502 TrainAcc 0.9500 TestAcc 0.8243 0.8800
epoch 1600 LossPred 0.1894 LossAtt 0.3453 TrainAcc 0.9500 TestAcc 0.8241 0.8800
epoch 1700 LossPred 0.1912 LossAtt 0.3465 TrainAcc 0.9500 TestAcc 0.8256 0.8950
epoch 1800 LossPred 0.1735 LossAtt 0.3610 TrainAcc 0.9600 TestAcc 0.8203 0.8950
epoch 1900 LossPred 0.1830 LossAtt 0.3838 TrainAcc 0.9500 TestAcc 0.8253 0.9000
epoch 2000 LossPred 0.1744 LossAtt 0.3738 TrainAcc 0.9600 TestAcc 0.8188 0.8900
epoch 2100 LossPred 0.1667 LossAtt 0.3527 TrainAcc 0.9600 TestAcc 0.8183 0.8900
epoch 2200 LossPred 0.1583 LossAtt 0.3555 TrainAcc 0.9600 TestAcc 0.8251 0.8800
epoch 2300 LossPred 0.3094 LossAtt 0.3886 TrainAcc 0.9200 TestAcc 0.7800 0.8650
epoch 2400 LossPred 0.1766 LossAtt 0.4096 TrainAcc 0.9600 TestAcc 0.8236 0.8950
epoch 2500 LossPred 0.1731 LossAtt 0.3448 TrainAcc 0.9600 TestAcc 0.8118 0.8850
Optimization Finished!
********** replication  36  **********
epoch   0 LossPred 1.0308 LossAtt 1.0687 TrainAcc 0.4400 TestAcc 0.4717 0.5150
epoch 100 LossPred 0.8234 LossAtt 0.7568 TrainAcc 0.6700 TestAcc 0.5268 0.6550
epoch 200 LossPred 0.6010 LossAtt 1.1183 TrainAcc 0.8000 TestAcc 0.5230 0.7500
epoch 300 LossPred 0.5167 LossAtt 0.9097 TrainAcc 0.8300 TestAcc 0.5343 0.7800
epoch 400 LossPred 0.4336 LossAtt 0.8728 TrainAcc 0.8700 TestAcc 0.5310 0.8000
epoch 500 LossPred 0.2896 LossAtt 0.8689 TrainAcc 0.9400 TestAcc 0.5285 0.8000
epoch 600 LossPred 0.2813 LossAtt 0.7188 TrainAcc 0.9400 TestAcc 0.5290 0.8250
epoch 700 LossPred 0.2457 LossAtt 0.6599 TrainAcc 0.9600 TestAcc 0.5310 0.8200
epoch 800 LossPred 0.2142 LossAtt 0.6783 TrainAcc 0.9600 TestAcc 0.5298 0.8250
epoch 900 LossPred 0.2521 LossAtt 0.8723 TrainAcc 0.9500 TestAcc 0.5310 0.8150
epoch 1000 LossPred 0.2022 LossAtt 0.6141 TrainAcc 0.9600 TestAcc 0.5353 0.8150
epoch 1100 LossPred 0.1780 LossAtt 0.5988 TrainAcc 0.9700 TestAcc 0.5323 0.8000
epoch 1200 LossPred 0.1701 LossAtt 0.6110 TrainAcc 0.9700 TestAcc 0.5295 0.8000
epoch 1300 LossPred 0.2180 LossAtt 0.6718 TrainAcc 0.9600 TestAcc 0.5348 0.8050
epoch 1400 LossPred 0.1907 LossAtt 0.6570 TrainAcc 0.9700 TestAcc 0.5345 0.8450
epoch 1500 LossPred 0.1571 LossAtt 0.5862 TrainAcc 0.9700 TestAcc 0.5300 0.8350
epoch 1600 LossPred 0.1512 LossAtt 0.5929 TrainAcc 0.9700 TestAcc 0.5305 0.8400
epoch 1700 LossPred 0.1476 LossAtt 0.5639 TrainAcc 0.9700 TestAcc 0.5328 0.8350
epoch 1800 LossPred 0.1434 LossAtt 0.5908 TrainAcc 0.9700 TestAcc 0.5328 0.8350
epoch 1900 LossPred 0.2539 LossAtt 0.6405 TrainAcc 0.9300 TestAcc 0.5273 0.8400
epoch 2000 LossPred 0.2222 LossAtt 0.7054 TrainAcc 0.9500 TestAcc 0.5273 0.8400
epoch 2100 LossPred 0.1369 LossAtt 0.5632 TrainAcc 0.9700 TestAcc 0.5308 0.8550
epoch 2200 LossPred 0.1319 LossAtt 0.5694 TrainAcc 0.9700 TestAcc 0.5288 0.8450
epoch 2300 LossPred 0.1289 LossAtt 0.5578 TrainAcc 0.9700 TestAcc 0.5273 0.8350
epoch 2400 LossPred 0.1272 LossAtt 0.5504 TrainAcc 0.9700 TestAcc 0.5293 0.8350
epoch 2500 LossPred 0.1261 LossAtt 0.5553 TrainAcc 0.9700 TestAcc 0.5288 0.8250
Optimization Finished!
********** replication  37  **********
epoch   0 LossPred 1.0260 LossAtt 1.0427 TrainAcc 0.5200 TestAcc 0.4870 0.4850
epoch 100 LossPred 0.8835 LossAtt 0.8908 TrainAcc 0.6500 TestAcc 0.5258 0.6550
epoch 200 LossPred 0.7110 LossAtt 1.6149 TrainAcc 0.7300 TestAcc 0.5448 0.7100
epoch 300 LossPred 0.6548 LossAtt 1.2552 TrainAcc 0.7600 TestAcc 0.5390 0.7700
epoch 400 LossPred 0.5493 LossAtt 0.9790 TrainAcc 0.8000 TestAcc 0.5688 0.7600
epoch 500 LossPred 0.5836 LossAtt 0.9874 TrainAcc 0.8000 TestAcc 0.5618 0.7500
epoch 600 LossPred 0.4414 LossAtt 0.7748 TrainAcc 0.8800 TestAcc 0.5516 0.8050
epoch 700 LossPred 0.4448 LossAtt 0.7304 TrainAcc 0.8800 TestAcc 0.5561 0.8150
epoch 800 LossPred 0.4734 LossAtt 0.8587 TrainAcc 0.8800 TestAcc 0.5478 0.7850
epoch 900 LossPred 0.3911 LossAtt 0.6906 TrainAcc 0.9200 TestAcc 0.5588 0.8150
epoch 1000 LossPred 0.3855 LossAtt 0.6684 TrainAcc 0.9000 TestAcc 0.5758 0.8000
epoch 1100 LossPred 0.3721 LossAtt 0.7220 TrainAcc 0.9000 TestAcc 0.5576 0.7850
epoch 1200 LossPred 0.3461 LossAtt 0.6918 TrainAcc 0.9000 TestAcc 0.5495 0.8000
epoch 1300 LossPred 0.3241 LossAtt 0.6491 TrainAcc 0.9100 TestAcc 0.5583 0.8050
epoch 1400 LossPred 0.3324 LossAtt 0.6323 TrainAcc 0.9200 TestAcc 0.5526 0.8100
epoch 1500 LossPred 0.3556 LossAtt 0.6101 TrainAcc 0.8900 TestAcc 0.5541 0.7950
epoch 1600 LossPred 0.5497 LossAtt 1.0448 TrainAcc 0.8200 TestAcc 0.5616 0.7550
epoch 1700 LossPred 0.4715 LossAtt 0.6419 TrainAcc 0.8500 TestAcc 0.5776 0.7700
epoch 1800 LossPred 0.3096 LossAtt 0.6252 TrainAcc 0.9200 TestAcc 0.5541 0.8050
epoch 1900 LossPred 0.3477 LossAtt 0.5994 TrainAcc 0.8800 TestAcc 0.5621 0.8100
epoch 2000 LossPred 0.2999 LossAtt 0.5753 TrainAcc 0.9100 TestAcc 0.5465 0.8250
epoch 2100 LossPred 0.2997 LossAtt 0.6075 TrainAcc 0.9300 TestAcc 0.5543 0.8450
epoch 2200 LossPred 0.3324 LossAtt 0.5896 TrainAcc 0.9000 TestAcc 0.5606 0.8400
epoch 2300 LossPred 0.2794 LossAtt 0.5588 TrainAcc 0.9300 TestAcc 0.5470 0.8500
epoch 2400 LossPred 0.3188 LossAtt 0.6309 TrainAcc 0.9100 TestAcc 0.5513 0.8600
epoch 2500 LossPred 0.7921 LossAtt 0.7686 TrainAcc 0.7300 TestAcc 0.5563 0.7150
Optimization Finished!
********** replication  38  **********
epoch   0 LossPred 1.0665 LossAtt 1.0231 TrainAcc 0.4600 TestAcc 0.5055 0.4650
epoch 100 LossPred 0.7794 LossAtt 1.0734 TrainAcc 0.7000 TestAcc 0.6269 0.7200
epoch 200 LossPred 0.3723 LossAtt 0.5836 TrainAcc 0.8900 TestAcc 0.8368 0.8700
epoch 300 LossPred 0.2926 LossAtt 0.5326 TrainAcc 0.9000 TestAcc 0.8556 0.8850
epoch 400 LossPred 0.2780 LossAtt 0.4984 TrainAcc 0.9200 TestAcc 0.8506 0.8850
epoch 500 LossPred 0.2540 LossAtt 0.5423 TrainAcc 0.9200 TestAcc 0.8353 0.8800
epoch 600 LossPred 0.2407 LossAtt 0.4812 TrainAcc 0.9300 TestAcc 0.8596 0.8800
epoch 700 LossPred 0.1928 LossAtt 0.4748 TrainAcc 0.9300 TestAcc 0.8671 0.9100
epoch 800 LossPred 0.1515 LossAtt 0.4795 TrainAcc 0.9400 TestAcc 0.8571 0.9000
epoch 900 LossPred 0.1162 LossAtt 0.4630 TrainAcc 0.9600 TestAcc 0.8506 0.9300
epoch 1000 LossPred 0.3319 LossAtt 0.4656 TrainAcc 0.8900 TestAcc 0.8436 0.8750
epoch 1100 LossPred 0.0578 LossAtt 0.4489 TrainAcc 0.9900 TestAcc 0.8706 0.9450
epoch 1200 LossPred 0.1234 LossAtt 0.4453 TrainAcc 0.9800 TestAcc 0.8561 0.9300
epoch 1300 LossPred 0.0460 LossAtt 0.4478 TrainAcc 1.0000 TestAcc 0.8616 0.9500
Optimization Finished!
********** replication  39  **********
epoch   0 LossPred 1.0012 LossAtt 1.0122 TrainAcc 0.5600 TestAcc 0.5553 0.5700
epoch 100 LossPred 0.8751 LossAtt 0.7208 TrainAcc 0.6200 TestAcc 0.6206 0.6000
epoch 200 LossPred 0.4493 LossAtt 0.6586 TrainAcc 0.8500 TestAcc 0.7978 0.8150
epoch 300 LossPred 0.4425 LossAtt 0.5502 TrainAcc 0.8300 TestAcc 0.8148 0.8550
epoch 400 LossPred 0.2815 LossAtt 0.4599 TrainAcc 0.9200 TestAcc 0.8316 0.8650
epoch 500 LossPred 0.3203 LossAtt 0.4467 TrainAcc 0.9000 TestAcc 0.8316 0.8650
epoch 600 LossPred 0.2133 LossAtt 0.4134 TrainAcc 0.9500 TestAcc 0.8466 0.8750
epoch 700 LossPred 0.2123 LossAtt 0.4147 TrainAcc 0.9400 TestAcc 0.8406 0.8650
epoch 800 LossPred 0.4578 LossAtt 0.4604 TrainAcc 0.8700 TestAcc 0.7778 0.7850
epoch 900 LossPred 0.2171 LossAtt 0.4260 TrainAcc 0.9500 TestAcc 0.8303 0.8700
epoch 1000 LossPred 0.2443 LossAtt 0.3981 TrainAcc 0.9400 TestAcc 0.8301 0.8450
epoch 1100 LossPred 0.1487 LossAtt 0.3647 TrainAcc 0.9700 TestAcc 0.8478 0.8600
epoch 1200 LossPred 0.1421 LossAtt 0.3488 TrainAcc 0.9600 TestAcc 0.8473 0.8750
epoch 1300 LossPred 0.1358 LossAtt 0.3496 TrainAcc 0.9700 TestAcc 0.8461 0.9000
epoch 1400 LossPred 0.3817 LossAtt 0.3693 TrainAcc 0.9000 TestAcc 0.7993 0.8650
epoch 1500 LossPred 0.1371 LossAtt 0.3823 TrainAcc 0.9800 TestAcc 0.8401 0.9050
epoch 1600 LossPred 0.3288 LossAtt 0.4442 TrainAcc 0.9000 TestAcc 0.8208 0.8950
epoch 1700 LossPred 0.1340 LossAtt 0.3533 TrainAcc 0.9600 TestAcc 0.8478 0.9250
epoch 1800 LossPred 0.1379 LossAtt 0.3512 TrainAcc 0.9700 TestAcc 0.8326 0.9200
epoch 1900 LossPred 0.3055 LossAtt 0.4041 TrainAcc 0.9000 TestAcc 0.8293 0.8950
epoch 2000 LossPred 0.2360 LossAtt 0.3725 TrainAcc 0.9400 TestAcc 0.8188 0.9100
epoch 2100 LossPred 0.1508 LossAtt 0.3506 TrainAcc 0.9600 TestAcc 0.8408 0.9200
epoch 2200 LossPred 0.1162 LossAtt 0.3369 TrainAcc 0.9700 TestAcc 0.8536 0.9250
epoch 2300 LossPred 1.3309 LossAtt 0.3858 TrainAcc 0.6400 TestAcc 0.6169 0.6500
epoch 2400 LossPred 0.1143 LossAtt 0.3265 TrainAcc 0.9800 TestAcc 0.8441 0.9350
epoch 2500 LossPred 0.1026 LossAtt 0.3229 TrainAcc 0.9900 TestAcc 0.8438 0.9300
Optimization Finished!
********** replication  40  **********
epoch   0 LossPred 1.1027 LossAtt 1.0060 TrainAcc 0.5300 TestAcc 0.5303 0.5350
epoch 100 LossPred 0.8953 LossAtt 0.7272 TrainAcc 0.6200 TestAcc 0.5043 0.6250
epoch 200 LossPred 0.7554 LossAtt 1.0511 TrainAcc 0.7200 TestAcc 0.5591 0.6750
epoch 300 LossPred 0.5973 LossAtt 1.2378 TrainAcc 0.7900 TestAcc 0.5448 0.7500
epoch 400 LossPred 0.5773 LossAtt 1.1564 TrainAcc 0.8100 TestAcc 0.5501 0.7250
epoch 500 LossPred 0.4670 LossAtt 1.0132 TrainAcc 0.8600 TestAcc 0.5463 0.7400
epoch 600 LossPred 0.4034 LossAtt 1.0550 TrainAcc 0.8800 TestAcc 0.5511 0.7800
epoch 700 LossPred 0.3531 LossAtt 0.9575 TrainAcc 0.9100 TestAcc 0.5463 0.7950
epoch 800 LossPred 0.2884 LossAtt 0.8843 TrainAcc 0.9400 TestAcc 0.5488 0.7800
epoch 900 LossPred 0.2513 LossAtt 0.8699 TrainAcc 0.9500 TestAcc 0.5516 0.8000
epoch 1000 LossPred 0.2703 LossAtt 0.8711 TrainAcc 0.9400 TestAcc 0.5528 0.7900
epoch 1100 LossPred 0.2377 LossAtt 0.8853 TrainAcc 0.9500 TestAcc 0.5696 0.8150
epoch 1200 LossPred 0.1981 LossAtt 0.8269 TrainAcc 0.9500 TestAcc 0.5553 0.8000
epoch 1300 LossPred 0.3117 LossAtt 1.2575 TrainAcc 0.9200 TestAcc 0.5613 0.8000
epoch 1400 LossPred 0.1847 LossAtt 0.7607 TrainAcc 0.9500 TestAcc 0.5613 0.8150
epoch 1500 LossPred 0.1615 LossAtt 0.7667 TrainAcc 0.9600 TestAcc 0.5681 0.8100
epoch 1600 LossPred 0.1693 LossAtt 0.7645 TrainAcc 0.9600 TestAcc 0.5593 0.8200
epoch 1700 LossPred 0.1655 LossAtt 0.8223 TrainAcc 0.9500 TestAcc 0.5578 0.7850
epoch 1800 LossPred 0.1866 LossAtt 0.8277 TrainAcc 0.9500 TestAcc 0.5556 0.7850
epoch 1900 LossPred 0.1515 LossAtt 0.7431 TrainAcc 0.9600 TestAcc 0.5706 0.8250
epoch 2000 LossPred 0.1338 LossAtt 0.7398 TrainAcc 0.9700 TestAcc 0.5656 0.8250
epoch 2100 LossPred 0.1251 LossAtt 0.7342 TrainAcc 0.9800 TestAcc 0.5621 0.8000
epoch 2200 LossPred 0.1323 LossAtt 0.7780 TrainAcc 0.9700 TestAcc 0.5743 0.8150
epoch 2300 LossPred 0.1361 LossAtt 0.7557 TrainAcc 0.9700 TestAcc 0.5593 0.8150
epoch 2400 LossPred 0.1193 LossAtt 0.7700 TrainAcc 0.9700 TestAcc 0.5676 0.8200
epoch 2500 LossPred 0.4359 LossAtt 0.8996 TrainAcc 0.8300 TestAcc 0.5415 0.7950
Optimization Finished!
********** replication  41  **********
epoch   0 LossPred 1.0117 LossAtt 1.0084 TrainAcc 0.5500 TestAcc 0.5008 0.5400
epoch 100 LossPred 0.8646 LossAtt 0.6678 TrainAcc 0.6500 TestAcc 0.5748 0.6500
epoch 200 LossPred 0.6414 LossAtt 0.7496 TrainAcc 0.7800 TestAcc 0.7748 0.7850
epoch 300 LossPred 0.5887 LossAtt 0.5127 TrainAcc 0.8300 TestAcc 0.8368 0.8400
epoch 400 LossPred 0.5063 LossAtt 0.4187 TrainAcc 0.8600 TestAcc 0.8534 0.8500
epoch 500 LossPred 0.5111 LossAtt 0.4210 TrainAcc 0.8500 TestAcc 0.8178 0.8150
epoch 600 LossPred 0.7477 LossAtt 0.4333 TrainAcc 0.6900 TestAcc 0.7180 0.6950
epoch 700 LossPred 0.2700 LossAtt 0.3726 TrainAcc 0.9500 TestAcc 0.8674 0.9100
epoch 800 LossPred 0.3876 LossAtt 0.4548 TrainAcc 0.9000 TestAcc 0.8321 0.8900
epoch 900 LossPred 0.2000 LossAtt 0.3862 TrainAcc 0.9600 TestAcc 0.8699 0.9100
epoch 1000 LossPred 0.1842 LossAtt 0.3797 TrainAcc 0.9600 TestAcc 0.8784 0.9300
epoch 1100 LossPred 0.1794 LossAtt 0.3894 TrainAcc 0.9600 TestAcc 0.8759 0.9150
epoch 1200 LossPred 0.1606 LossAtt 0.3842 TrainAcc 0.9600 TestAcc 0.8781 0.9200
epoch 1300 LossPred 0.8827 LossAtt 0.5232 TrainAcc 0.7600 TestAcc 0.7375 0.7750
epoch 1400 LossPred 0.1480 LossAtt 0.3658 TrainAcc 0.9700 TestAcc 0.8786 0.9300
epoch 1500 LossPred 0.1428 LossAtt 0.3679 TrainAcc 0.9700 TestAcc 0.8789 0.9350
epoch 1600 LossPred 0.1372 LossAtt 0.3586 TrainAcc 0.9700 TestAcc 0.8776 0.9400
epoch 1700 LossPred 0.1318 LossAtt 0.3565 TrainAcc 0.9700 TestAcc 0.8784 0.9400
epoch 1800 LossPred 0.1269 LossAtt 0.3437 TrainAcc 0.9700 TestAcc 0.8796 0.9400
epoch 1900 LossPred 0.1204 LossAtt 0.3461 TrainAcc 0.9700 TestAcc 0.8781 0.9450
epoch 2000 LossPred 0.1145 LossAtt 0.3421 TrainAcc 0.9700 TestAcc 0.8784 0.9550
epoch 2100 LossPred 0.1019 LossAtt 0.3586 TrainAcc 0.9800 TestAcc 0.8721 0.9500
epoch 2200 LossPred 0.0728 LossAtt 0.3468 TrainAcc 0.9900 TestAcc 0.8686 0.9550
epoch 2300 LossPred 0.0658 LossAtt 0.3536 TrainAcc 0.9900 TestAcc 0.8624 0.9500
epoch 2400 LossPred 0.0641 LossAtt 0.3496 TrainAcc 0.9900 TestAcc 0.8626 0.9450
epoch 2500 LossPred 0.0666 LossAtt 0.3504 TrainAcc 0.9900 TestAcc 0.8624 0.9450
Optimization Finished!
********** replication  42  **********
epoch   0 LossPred 0.9791 LossAtt 1.0204 TrainAcc 0.5300 TestAcc 0.5040 0.5700
epoch 100 LossPred 0.8179 LossAtt 0.9045 TrainAcc 0.6800 TestAcc 0.5440 0.6850
epoch 200 LossPred 0.7357 LossAtt 0.8662 TrainAcc 0.7300 TestAcc 0.5458 0.7200
epoch 300 LossPred 0.7087 LossAtt 0.6211 TrainAcc 0.7600 TestAcc 0.5473 0.7250
epoch 400 LossPred 0.6734 LossAtt 0.6468 TrainAcc 0.7900 TestAcc 0.5526 0.7550
epoch 500 LossPred 0.6193 LossAtt 0.7221 TrainAcc 0.8000 TestAcc 0.5501 0.7850
epoch 600 LossPred 0.5793 LossAtt 0.6769 TrainAcc 0.8000 TestAcc 0.5558 0.8050
epoch 700 LossPred 0.5305 LossAtt 0.6724 TrainAcc 0.8600 TestAcc 0.5526 0.8350
epoch 800 LossPred 0.4828 LossAtt 0.7398 TrainAcc 0.8500 TestAcc 0.5531 0.8450
epoch 900 LossPred 0.4807 LossAtt 0.8542 TrainAcc 0.8400 TestAcc 0.5556 0.8350
epoch 1000 LossPred 0.4105 LossAtt 0.6945 TrainAcc 0.8800 TestAcc 0.5601 0.8300
epoch 1100 LossPred 0.3786 LossAtt 0.6801 TrainAcc 0.9000 TestAcc 0.5581 0.8200
epoch 1200 LossPred 0.5279 LossAtt 0.8192 TrainAcc 0.8300 TestAcc 0.5558 0.7850
epoch 1300 LossPred 0.3352 LossAtt 0.6541 TrainAcc 0.8900 TestAcc 0.5536 0.8250
epoch 1400 LossPred 0.3777 LossAtt 0.6896 TrainAcc 0.8900 TestAcc 0.5548 0.8300
epoch 1500 LossPred 0.3170 LossAtt 0.6297 TrainAcc 0.9300 TestAcc 0.5571 0.8100
epoch 1600 LossPred 0.4042 LossAtt 0.8576 TrainAcc 0.8600 TestAcc 0.5445 0.7850
epoch 1700 LossPred 0.3381 LossAtt 0.6858 TrainAcc 0.9200 TestAcc 0.5493 0.8250
epoch 1800 LossPred 0.2782 LossAtt 0.6134 TrainAcc 0.9400 TestAcc 0.5458 0.8200
epoch 1900 LossPred 0.2890 LossAtt 0.6451 TrainAcc 0.9400 TestAcc 0.5508 0.8450
epoch 2000 LossPred 0.3315 LossAtt 0.6361 TrainAcc 0.9300 TestAcc 0.5453 0.8600
epoch 2100 LossPred 0.8270 LossAtt 1.7802 TrainAcc 0.7200 TestAcc 0.5223 0.7150
epoch 2200 LossPred 0.4122 LossAtt 0.6313 TrainAcc 0.8500 TestAcc 0.5368 0.8050
epoch 2300 LossPred 0.3467 LossAtt 0.5909 TrainAcc 0.9300 TestAcc 0.5390 0.8150
epoch 2400 LossPred 0.3298 LossAtt 0.5902 TrainAcc 0.9400 TestAcc 0.5430 0.8100
epoch 2500 LossPred 0.3159 LossAtt 0.5805 TrainAcc 0.9400 TestAcc 0.5428 0.8200
Optimization Finished!
********** replication  43  **********
epoch   0 LossPred 1.0849 LossAtt 1.0428 TrainAcc 0.4300 TestAcc 0.4282 0.4300
epoch 100 LossPred 0.9042 LossAtt 0.6780 TrainAcc 0.6000 TestAcc 0.6089 0.6050
epoch 200 LossPred 0.7517 LossAtt 0.8583 TrainAcc 0.7300 TestAcc 0.6271 0.7150
epoch 300 LossPred 0.2829 LossAtt 0.7456 TrainAcc 0.9200 TestAcc 0.8819 0.8950
epoch 400 LossPred 0.1662 LossAtt 0.6137 TrainAcc 0.9700 TestAcc 0.9044 0.9100
epoch 500 LossPred 0.1272 LossAtt 0.5781 TrainAcc 0.9800 TestAcc 0.9024 0.8950
epoch 600 LossPred 0.1046 LossAtt 0.5506 TrainAcc 0.9800 TestAcc 0.8991 0.8950
epoch 700 LossPred 0.1070 LossAtt 0.5510 TrainAcc 0.9800 TestAcc 0.8929 0.9000
epoch 800 LossPred 0.0958 LossAtt 0.5512 TrainAcc 0.9800 TestAcc 0.8964 0.9150
epoch 900 LossPred 0.0942 LossAtt 0.5919 TrainAcc 0.9800 TestAcc 0.8944 0.9100
epoch 1000 LossPred 0.1024 LossAtt 0.5364 TrainAcc 0.9800 TestAcc 0.8799 0.9000
epoch 1100 LossPred 0.0884 LossAtt 0.5313 TrainAcc 0.9800 TestAcc 0.8859 0.9200
epoch 1200 LossPred 0.0914 LossAtt 0.5747 TrainAcc 0.9800 TestAcc 0.8796 0.9250
epoch 1300 LossPred 0.1087 LossAtt 0.5893 TrainAcc 0.9800 TestAcc 0.8784 0.9300
epoch 1400 LossPred 0.1669 LossAtt 0.5506 TrainAcc 0.9600 TestAcc 0.8604 0.8900
epoch 1500 LossPred 0.0981 LossAtt 0.5166 TrainAcc 0.9800 TestAcc 0.8756 0.9200
epoch 1600 LossPred 0.0735 LossAtt 0.4970 TrainAcc 0.9900 TestAcc 0.8714 0.9450
epoch 1700 LossPred 0.0722 LossAtt 0.5430 TrainAcc 0.9900 TestAcc 0.8684 0.9450
epoch 1800 LossPred 0.1056 LossAtt 0.5288 TrainAcc 0.9600 TestAcc 0.8546 0.9300
epoch 1900 LossPred 0.0730 LossAtt 0.4895 TrainAcc 0.9900 TestAcc 0.8646 0.9450
epoch 2000 LossPred 0.0661 LossAtt 0.4696 TrainAcc 0.9900 TestAcc 0.8576 0.9450
epoch 2100 LossPred 0.0861 LossAtt 0.5172 TrainAcc 0.9800 TestAcc 0.8498 0.9250
epoch 2200 LossPred 0.0672 LossAtt 0.5033 TrainAcc 0.9900 TestAcc 0.8619 0.9550
epoch 2300 LossPred 0.0658 LossAtt 0.5048 TrainAcc 0.9900 TestAcc 0.8481 0.9400
epoch 2400 LossPred 0.1389 LossAtt 0.5070 TrainAcc 0.9600 TestAcc 0.8401 0.9200
epoch 2500 LossPred 0.0628 LossAtt 0.4746 TrainAcc 0.9900 TestAcc 0.8574 0.9550
Optimization Finished!
********** replication  44  **********
epoch   0 LossPred 1.2463 LossAtt 1.0086 TrainAcc 0.3700 TestAcc 0.4304 0.3750
epoch 100 LossPred 0.8734 LossAtt 0.5633 TrainAcc 0.6500 TestAcc 0.6094 0.6500
epoch 200 LossPred 0.8546 LossAtt 0.5443 TrainAcc 0.6500 TestAcc 0.6094 0.6500
epoch 300 LossPred 0.8164 LossAtt 0.5857 TrainAcc 0.6500 TestAcc 0.6041 0.6450
epoch 400 LossPred 0.7420 LossAtt 0.7828 TrainAcc 0.7200 TestAcc 0.5591 0.6950
epoch 500 LossPred 0.6520 LossAtt 0.8237 TrainAcc 0.7900 TestAcc 0.5511 0.7750
epoch 600 LossPred 0.5380 LossAtt 0.8699 TrainAcc 0.8600 TestAcc 0.5598 0.8000
epoch 700 LossPred 0.4538 LossAtt 0.9108 TrainAcc 0.8800 TestAcc 0.5573 0.7950
epoch 800 LossPred 0.4188 LossAtt 0.8972 TrainAcc 0.8900 TestAcc 0.5628 0.8100
epoch 900 LossPred 0.4385 LossAtt 0.7066 TrainAcc 0.8800 TestAcc 0.5588 0.8200
epoch 1000 LossPred 0.3900 LossAtt 0.6953 TrainAcc 0.9000 TestAcc 0.5501 0.8250
epoch 1100 LossPred 0.4028 LossAtt 0.6743 TrainAcc 0.8900 TestAcc 0.5556 0.8000
epoch 1200 LossPred 0.3819 LossAtt 0.6491 TrainAcc 0.9000 TestAcc 0.5551 0.7900
epoch 1300 LossPred 0.3700 LossAtt 0.6449 TrainAcc 0.9000 TestAcc 0.5531 0.8150
epoch 1400 LossPred 0.3778 LossAtt 0.6097 TrainAcc 0.8900 TestAcc 0.5546 0.8250
epoch 1500 LossPred 0.4615 LossAtt 0.7002 TrainAcc 0.8400 TestAcc 0.5546 0.7750
epoch 1600 LossPred 0.3415 LossAtt 0.5985 TrainAcc 0.9000 TestAcc 0.5493 0.8050
epoch 1700 LossPred 0.3303 LossAtt 0.5914 TrainAcc 0.9200 TestAcc 0.5455 0.8000
epoch 1800 LossPred 0.3582 LossAtt 0.5745 TrainAcc 0.9200 TestAcc 0.5526 0.8150
epoch 1900 LossPred 0.3286 LossAtt 0.5481 TrainAcc 0.9200 TestAcc 0.5578 0.8250
epoch 2000 LossPred 0.5548 LossAtt 0.7525 TrainAcc 0.8000 TestAcc 0.5435 0.7500
epoch 2100 LossPred 0.3398 LossAtt 0.5517 TrainAcc 0.9100 TestAcc 0.5551 0.7900
epoch 2200 LossPred 0.3237 LossAtt 0.5461 TrainAcc 0.9200 TestAcc 0.5508 0.8050
epoch 2300 LossPred 0.3160 LossAtt 0.5377 TrainAcc 0.9200 TestAcc 0.5503 0.8150
epoch 2400 LossPred 0.3123 LossAtt 0.5341 TrainAcc 0.9200 TestAcc 0.5483 0.8050
epoch 2500 LossPred 0.4188 LossAtt 0.5751 TrainAcc 0.9000 TestAcc 0.5513 0.7950
Optimization Finished!
********** replication  45  **********
epoch   0 LossPred 1.0880 LossAtt 1.0498 TrainAcc 0.4000 TestAcc 0.5023 0.4150
epoch 100 LossPred 0.8552 LossAtt 0.7221 TrainAcc 0.7000 TestAcc 0.5666 0.6900
epoch 200 LossPred 0.4922 LossAtt 0.6302 TrainAcc 0.8400 TestAcc 0.7938 0.8550
epoch 300 LossPred 0.3829 LossAtt 0.4770 TrainAcc 0.8700 TestAcc 0.8108 0.8650
epoch 400 LossPred 0.3367 LossAtt 0.4639 TrainAcc 0.8900 TestAcc 0.8098 0.8700
epoch 500 LossPred 0.3422 LossAtt 0.4463 TrainAcc 0.8900 TestAcc 0.8298 0.8650
epoch 600 LossPred 0.2423 LossAtt 0.4342 TrainAcc 0.9300 TestAcc 0.7925 0.8700
epoch 700 LossPred 1.3228 LossAtt 0.5746 TrainAcc 0.5500 TestAcc 0.5228 0.5700
epoch 800 LossPred 0.2741 LossAtt 0.5101 TrainAcc 0.9200 TestAcc 0.7918 0.8900
epoch 900 LossPred 0.1955 LossAtt 0.4161 TrainAcc 0.9400 TestAcc 0.7893 0.9100
epoch 1000 LossPred 0.1849 LossAtt 0.4255 TrainAcc 0.9400 TestAcc 0.7848 0.9100
epoch 1100 LossPred 0.1790 LossAtt 0.4089 TrainAcc 0.9500 TestAcc 0.7858 0.9100
epoch 1200 LossPred 0.1739 LossAtt 0.4055 TrainAcc 0.9500 TestAcc 0.7790 0.9000
epoch 1300 LossPred 0.1753 LossAtt 0.3990 TrainAcc 0.9400 TestAcc 0.7810 0.8900
epoch 1400 LossPred 1.5261 LossAtt 0.5281 TrainAcc 0.5900 TestAcc 0.5385 0.5900
epoch 1500 LossPred 0.2142 LossAtt 0.3775 TrainAcc 0.9200 TestAcc 0.7795 0.9000
epoch 1600 LossPred 1.3217 LossAtt 0.5011 TrainAcc 0.5600 TestAcc 0.5818 0.5600
epoch 1700 LossPred 0.8329 LossAtt 0.3718 TrainAcc 0.6600 TestAcc 0.5766 0.6200
epoch 1800 LossPred 0.8049 LossAtt 0.3482 TrainAcc 0.6400 TestAcc 0.6086 0.6650
epoch 1900 LossPred 0.7970 LossAtt 0.3382 TrainAcc 0.6700 TestAcc 0.5836 0.6750
epoch 2000 LossPred 0.7918 LossAtt 0.3109 TrainAcc 0.6900 TestAcc 0.5761 0.6950
epoch 2100 LossPred 0.7877 LossAtt 0.3103 TrainAcc 0.7100 TestAcc 0.5763 0.6950
epoch 2200 LossPred 0.7842 LossAtt 0.3131 TrainAcc 0.6900 TestAcc 0.5763 0.6900
epoch 2300 LossPred 0.7821 LossAtt 0.2976 TrainAcc 0.6900 TestAcc 0.5761 0.6950
epoch 2400 LossPred 0.7799 LossAtt 0.2869 TrainAcc 0.6900 TestAcc 0.5771 0.6900
epoch 2500 LossPred 0.7779 LossAtt 0.2770 TrainAcc 0.6900 TestAcc 0.5788 0.6850
Optimization Finished!
********** replication  46  **********
epoch   0 LossPred 1.1175 LossAtt 1.0179 TrainAcc 0.5200 TestAcc 0.4972 0.5450
epoch 100 LossPred 0.9318 LossAtt 0.6609 TrainAcc 0.5900 TestAcc 0.5200 0.5850
epoch 200 LossPred 0.8273 LossAtt 0.9703 TrainAcc 0.6600 TestAcc 0.5270 0.6400
epoch 300 LossPred 0.6590 LossAtt 1.1933 TrainAcc 0.7900 TestAcc 0.5768 0.7150
epoch 400 LossPred 0.5785 LossAtt 0.8472 TrainAcc 0.8100 TestAcc 0.6369 0.7600
epoch 500 LossPred 0.4582 LossAtt 0.7472 TrainAcc 0.8500 TestAcc 0.6694 0.7950
epoch 600 LossPred 0.3364 LossAtt 0.6521 TrainAcc 0.9000 TestAcc 0.6984 0.8400
epoch 700 LossPred 0.2673 LossAtt 0.6224 TrainAcc 0.9300 TestAcc 0.7085 0.8250
epoch 800 LossPred 0.2790 LossAtt 0.6477 TrainAcc 0.9300 TestAcc 0.7182 0.8550
epoch 900 LossPred 0.2284 LossAtt 0.5846 TrainAcc 0.9300 TestAcc 0.7110 0.8200
epoch 1000 LossPred 0.1843 LossAtt 0.5693 TrainAcc 0.9700 TestAcc 0.7177 0.8400
epoch 1100 LossPred 0.1661 LossAtt 0.6060 TrainAcc 0.9600 TestAcc 0.7190 0.8400
epoch 1200 LossPred 0.2585 LossAtt 0.6085 TrainAcc 0.9400 TestAcc 0.7260 0.8250
epoch 1300 LossPred 0.1480 LossAtt 0.5955 TrainAcc 0.9800 TestAcc 0.7090 0.8450
epoch 1400 LossPred 0.1610 LossAtt 0.5763 TrainAcc 0.9600 TestAcc 0.7127 0.8500
epoch 1500 LossPred 0.1209 LossAtt 0.5851 TrainAcc 0.9800 TestAcc 0.7162 0.8550
epoch 1600 LossPred 0.0899 LossAtt 0.5729 TrainAcc 0.9900 TestAcc 0.7185 0.8700
epoch 1700 LossPred 0.0779 LossAtt 0.5937 TrainAcc 0.9900 TestAcc 0.7252 0.8800
epoch 1800 LossPred 0.0666 LossAtt 0.6118 TrainAcc 0.9900 TestAcc 0.7152 0.8700
epoch 1900 LossPred 1.6535 LossAtt 0.7903 TrainAcc 0.5700 TestAcc 0.5546 0.5550
epoch 2000 LossPred 1.0846 LossAtt 0.6427 TrainAcc 0.7100 TestAcc 0.5646 0.5850
epoch 2100 LossPred 0.6663 LossAtt 0.6488 TrainAcc 0.7700 TestAcc 0.6879 0.7300
epoch 2200 LossPred 0.3131 LossAtt 0.6108 TrainAcc 0.9200 TestAcc 0.7763 0.8650
epoch 2300 LossPred 0.2877 LossAtt 0.5982 TrainAcc 0.9200 TestAcc 0.7820 0.8600
epoch 2400 LossPred 0.2645 LossAtt 0.5953 TrainAcc 0.9400 TestAcc 0.7890 0.8550
epoch 2500 LossPred 0.2499 LossAtt 0.5833 TrainAcc 0.9400 TestAcc 0.7795 0.8450
Optimization Finished!
********** replication  47  **********
epoch   0 LossPred 1.1956 LossAtt 1.0361 TrainAcc 0.4600 TestAcc 0.4617 0.4700
epoch 100 LossPred 0.8605 LossAtt 0.6626 TrainAcc 0.6500 TestAcc 0.6049 0.6550
epoch 200 LossPred 0.3589 LossAtt 0.6807 TrainAcc 0.8900 TestAcc 0.8641 0.8300
epoch 300 LossPred 0.2153 LossAtt 0.5838 TrainAcc 0.9500 TestAcc 0.8756 0.9000
epoch 400 LossPred 0.1931 LossAtt 0.5596 TrainAcc 0.9500 TestAcc 0.8759 0.8900
epoch 500 LossPred 0.0989 LossAtt 0.5217 TrainAcc 0.9800 TestAcc 0.8844 0.9100
epoch 600 LossPred 0.0961 LossAtt 0.5234 TrainAcc 0.9800 TestAcc 0.8806 0.9150
epoch 700 LossPred 0.0769 LossAtt 0.4961 TrainAcc 0.9800 TestAcc 0.8861 0.9100
epoch 800 LossPred 0.0793 LossAtt 0.5147 TrainAcc 0.9800 TestAcc 0.8826 0.9200
epoch 900 LossPred 0.0406 LossAtt 0.4675 TrainAcc 0.9900 TestAcc 0.8814 0.9150
epoch 1000 LossPred 0.0325 LossAtt 0.4814 TrainAcc 0.9900 TestAcc 0.8759 0.9200
epoch 1100 LossPred 0.0545 LossAtt 0.5220 TrainAcc 0.9900 TestAcc 0.8914 0.9350
epoch 1200 LossPred 0.0355 LossAtt 0.4765 TrainAcc 0.9900 TestAcc 0.8729 0.9100
epoch 1300 LossPred 0.0172 LossAtt 0.4474 TrainAcc 1.0000 TestAcc 0.8791 0.9250
Optimization Finished!
********** replication  48  **********
epoch   0 LossPred 1.0324 LossAtt 1.0222 TrainAcc 0.5500 TestAcc 0.5313 0.5550
epoch 100 LossPred 0.6513 LossAtt 0.7605 TrainAcc 0.7800 TestAcc 0.7843 0.7100
epoch 200 LossPred 0.3775 LossAtt 0.4803 TrainAcc 0.8800 TestAcc 0.8333 0.8500
epoch 300 LossPred 0.3095 LossAtt 0.3895 TrainAcc 0.9200 TestAcc 0.8493 0.8400
epoch 400 LossPred 0.2705 LossAtt 0.3570 TrainAcc 0.9300 TestAcc 0.8486 0.8400
epoch 500 LossPred 0.2600 LossAtt 0.3408 TrainAcc 0.9300 TestAcc 0.8539 0.8400
epoch 600 LossPred 0.6710 LossAtt 0.3648 TrainAcc 0.7500 TestAcc 0.7740 0.7300
epoch 700 LossPred 0.4655 LossAtt 0.4241 TrainAcc 0.8300 TestAcc 0.8251 0.7800
epoch 800 LossPred 0.2846 LossAtt 0.3286 TrainAcc 0.9300 TestAcc 0.8639 0.8500
epoch 900 LossPred 0.2324 LossAtt 0.3302 TrainAcc 0.9400 TestAcc 0.8711 0.8550
epoch 1000 LossPred 0.1756 LossAtt 0.3169 TrainAcc 0.9500 TestAcc 0.8739 0.8600
epoch 1100 LossPred 0.3558 LossAtt 0.3198 TrainAcc 0.8900 TestAcc 0.8483 0.8350
epoch 1200 LossPred 0.1916 LossAtt 0.2897 TrainAcc 0.9400 TestAcc 0.8684 0.8650
epoch 1300 LossPred 0.2191 LossAtt 0.2608 TrainAcc 0.9400 TestAcc 0.8619 0.8450
epoch 1400 LossPred 0.1745 LossAtt 0.2626 TrainAcc 0.9500 TestAcc 0.8754 0.8550
epoch 1500 LossPred 0.2032 LossAtt 0.2547 TrainAcc 0.9300 TestAcc 0.8714 0.8450
epoch 1600 LossPred 0.2000 LossAtt 0.2702 TrainAcc 0.9200 TestAcc 0.8674 0.8400
epoch 1700 LossPred 0.4508 LossAtt 0.2821 TrainAcc 0.8300 TestAcc 0.8083 0.7850
epoch 1800 LossPred 0.1364 LossAtt 0.2534 TrainAcc 0.9600 TestAcc 0.8621 0.8400
epoch 1900 LossPred 0.1377 LossAtt 0.2517 TrainAcc 0.9700 TestAcc 0.8611 0.8400
epoch 2000 LossPred 0.2710 LossAtt 0.2554 TrainAcc 0.9100 TestAcc 0.8726 0.8500
epoch 2100 LossPred 0.3718 LossAtt 0.2345 TrainAcc 0.9000 TestAcc 0.8749 0.8400
epoch 2200 LossPred 0.2281 LossAtt 0.2424 TrainAcc 0.9500 TestAcc 0.8856 0.8750
epoch 2300 LossPred 0.2349 LossAtt 0.2402 TrainAcc 0.9300 TestAcc 0.8924 0.8400
epoch 2400 LossPred 0.1243 LossAtt 0.2318 TrainAcc 0.9600 TestAcc 0.8894 0.8800
epoch 2500 LossPred 1.4012 LossAtt 0.3110 TrainAcc 0.6300 TestAcc 0.6346 0.6150
Optimization Finished!
********** replication  49  **********
epoch   0 LossPred 1.0077 LossAtt 1.0122 TrainAcc 0.4900 TestAcc 0.4757 0.5000
epoch 100 LossPred 0.4867 LossAtt 0.8246 TrainAcc 0.8700 TestAcc 0.7860 0.8150
epoch 200 LossPred 0.3754 LossAtt 0.4377 TrainAcc 0.8800 TestAcc 0.8051 0.8650
epoch 300 LossPred 0.3408 LossAtt 0.3664 TrainAcc 0.9000 TestAcc 0.8181 0.8550
epoch 400 LossPred 0.3696 LossAtt 0.3306 TrainAcc 0.8900 TestAcc 0.8056 0.8250
epoch 500 LossPred 0.3484 LossAtt 0.3079 TrainAcc 0.8900 TestAcc 0.8271 0.8600
epoch 600 LossPred 0.3066 LossAtt 0.2903 TrainAcc 0.9100 TestAcc 0.8173 0.8550
epoch 700 LossPred 0.3031 LossAtt 0.2812 TrainAcc 0.9100 TestAcc 0.8281 0.8750
epoch 800 LossPred 0.3069 LossAtt 0.2623 TrainAcc 0.9100 TestAcc 0.8193 0.8700
epoch 900 LossPred 0.4277 LossAtt 0.2704 TrainAcc 0.8500 TestAcc 0.8186 0.8600
epoch 1000 LossPred 0.2911 LossAtt 0.2862 TrainAcc 0.9100 TestAcc 0.8356 0.8900
epoch 1100 LossPred 0.3432 LossAtt 0.2732 TrainAcc 0.9000 TestAcc 0.8524 0.8700
epoch 1200 LossPred 0.2418 LossAtt 0.2739 TrainAcc 0.9300 TestAcc 0.8386 0.8750
epoch 1300 LossPred 0.2542 LossAtt 0.2788 TrainAcc 0.9400 TestAcc 0.8318 0.8650
epoch 1400 LossPred 0.2421 LossAtt 0.2904 TrainAcc 0.9400 TestAcc 0.8291 0.8850
epoch 1500 LossPred 0.3419 LossAtt 0.2703 TrainAcc 0.9000 TestAcc 0.8401 0.8700
epoch 1600 LossPred 0.3969 LossAtt 0.2879 TrainAcc 0.8800 TestAcc 0.8213 0.8750
epoch 1700 LossPred 0.3945 LossAtt 0.2947 TrainAcc 0.8800 TestAcc 0.8626 0.8600
epoch 1800 LossPred 0.4077 LossAtt 0.2688 TrainAcc 0.8600 TestAcc 0.8266 0.8650
epoch 1900 LossPred 0.3189 LossAtt 0.2544 TrainAcc 0.8900 TestAcc 0.8033 0.8600
epoch 2000 LossPred 0.2836 LossAtt 0.2338 TrainAcc 0.9300 TestAcc 0.8166 0.8550
epoch 2100 LossPred 0.2666 LossAtt 0.2642 TrainAcc 0.9200 TestAcc 0.8201 0.8700
epoch 2200 LossPred 0.2440 LossAtt 0.2425 TrainAcc 0.9300 TestAcc 0.8398 0.8800
epoch 2300 LossPred 0.3343 LossAtt 0.2546 TrainAcc 0.9000 TestAcc 0.8516 0.8650
epoch 2400 LossPred 0.3198 LossAtt 0.2372 TrainAcc 0.9000 TestAcc 0.8498 0.8950
epoch 2500 LossPred 0.3723 LossAtt 0.2245 TrainAcc 0.8700 TestAcc 0.7888 0.8500
Optimization Finished!
********** replication  50  **********
epoch   0 LossPred 1.1723 LossAtt 1.0905 TrainAcc 0.5000 TestAcc 0.5153 0.4600
epoch 100 LossPred 0.9206 LossAtt 0.6947 TrainAcc 0.6200 TestAcc 0.6036 0.6450
epoch 200 LossPred 0.6243 LossAtt 0.8046 TrainAcc 0.8300 TestAcc 0.7743 0.7800
epoch 300 LossPred 0.8340 LossAtt 0.7649 TrainAcc 0.6700 TestAcc 0.6484 0.6550
epoch 400 LossPred 0.3046 LossAtt 0.5674 TrainAcc 0.9300 TestAcc 0.8211 0.8600
epoch 500 LossPred 0.2818 LossAtt 0.5301 TrainAcc 0.9200 TestAcc 0.8208 0.8550
epoch 600 LossPred 0.2589 LossAtt 0.5161 TrainAcc 0.9300 TestAcc 0.8186 0.8600
epoch 700 LossPred 0.2414 LossAtt 0.5326 TrainAcc 0.9200 TestAcc 0.8188 0.8600
epoch 800 LossPred 0.2338 LossAtt 0.5428 TrainAcc 0.9400 TestAcc 0.8248 0.8650
epoch 900 LossPred 0.2310 LossAtt 0.5239 TrainAcc 0.9400 TestAcc 0.8306 0.8750
epoch 1000 LossPred 0.2163 LossAtt 0.5123 TrainAcc 0.9300 TestAcc 0.8268 0.8700
epoch 1100 LossPred 0.2158 LossAtt 0.5135 TrainAcc 0.9400 TestAcc 0.8316 0.8700
epoch 1200 LossPred 0.2713 LossAtt 0.5491 TrainAcc 0.9200 TestAcc 0.8091 0.8800
epoch 1300 LossPred 0.2056 LossAtt 0.4875 TrainAcc 0.9400 TestAcc 0.8161 0.8950
epoch 1400 LossPred 0.2206 LossAtt 0.5010 TrainAcc 0.9200 TestAcc 0.8231 0.9250
epoch 1500 LossPred 0.1926 LossAtt 0.4771 TrainAcc 0.9400 TestAcc 0.8191 0.9300
epoch 1600 LossPred 0.1777 LossAtt 0.4645 TrainAcc 0.9500 TestAcc 0.8228 0.9150
epoch 1700 LossPred 0.1698 LossAtt 0.4660 TrainAcc 0.9500 TestAcc 0.8213 0.9050
epoch 1800 LossPred 0.1753 LossAtt 0.4720 TrainAcc 0.9500 TestAcc 0.8261 0.9200
epoch 1900 LossPred 0.1600 LossAtt 0.4467 TrainAcc 0.9500 TestAcc 0.8233 0.9250
epoch 2000 LossPred 0.2729 LossAtt 0.5162 TrainAcc 0.9200 TestAcc 0.8176 0.9000
epoch 2100 LossPred 0.1922 LossAtt 0.4572 TrainAcc 0.9500 TestAcc 0.8358 0.9150
epoch 2200 LossPred 0.1659 LossAtt 0.4346 TrainAcc 0.9700 TestAcc 0.8268 0.9300
epoch 2300 LossPred 0.1562 LossAtt 0.4320 TrainAcc 0.9700 TestAcc 0.8243 0.9300
epoch 2400 LossPred 0.1509 LossAtt 0.4303 TrainAcc 0.9700 TestAcc 0.8228 0.9300
epoch 2500 LossPred 0.1467 LossAtt 0.4276 TrainAcc 0.9700 TestAcc 0.8223 0.9300
Optimization Finished!
********** replication  51  **********
epoch   0 LossPred 1.1835 LossAtt 1.0094 TrainAcc 0.5500 TestAcc 0.5340 0.5050
epoch 100 LossPred 0.8737 LossAtt 0.6653 TrainAcc 0.6600 TestAcc 0.6079 0.6600
epoch 200 LossPred 0.6907 LossAtt 0.7058 TrainAcc 0.7700 TestAcc 0.7482 0.7800
epoch 300 LossPred 0.5628 LossAtt 0.5721 TrainAcc 0.8300 TestAcc 0.7858 0.8100
epoch 400 LossPred 0.4907 LossAtt 0.4560 TrainAcc 0.8500 TestAcc 0.8071 0.8750
epoch 500 LossPred 0.6404 LossAtt 0.4901 TrainAcc 0.8100 TestAcc 0.7953 0.7750
epoch 600 LossPred 0.4116 LossAtt 0.4673 TrainAcc 0.8800 TestAcc 0.8183 0.8900
epoch 700 LossPred 0.3774 LossAtt 0.4835 TrainAcc 0.8900 TestAcc 0.8336 0.8800
epoch 800 LossPred 0.2014 LossAtt 0.4872 TrainAcc 0.9500 TestAcc 0.8386 0.8850
epoch 900 LossPred 0.1797 LossAtt 0.4752 TrainAcc 0.9500 TestAcc 0.8451 0.8900
epoch 1000 LossPred 0.2469 LossAtt 0.4919 TrainAcc 0.8900 TestAcc 0.8516 0.8800
epoch 1100 LossPred 0.1514 LossAtt 0.4751 TrainAcc 0.9600 TestAcc 0.8516 0.8950
epoch 1200 LossPred 0.1358 LossAtt 0.4698 TrainAcc 0.9700 TestAcc 0.8586 0.9150
epoch 1300 LossPred 0.1264 LossAtt 0.4403 TrainAcc 0.9700 TestAcc 0.8616 0.9100
epoch 1400 LossPred 0.1659 LossAtt 0.5102 TrainAcc 0.9500 TestAcc 0.8654 0.9100
epoch 1500 LossPred 0.1277 LossAtt 0.4425 TrainAcc 0.9700 TestAcc 0.8686 0.9250
epoch 1600 LossPred 0.1254 LossAtt 0.4543 TrainAcc 0.9700 TestAcc 0.8659 0.9050
epoch 1700 LossPred 0.1731 LossAtt 0.4764 TrainAcc 0.9600 TestAcc 0.8569 0.9350
epoch 1800 LossPred 0.1252 LossAtt 0.4386 TrainAcc 0.9700 TestAcc 0.8581 0.9200
epoch 1900 LossPred 0.1470 LossAtt 0.4539 TrainAcc 0.9500 TestAcc 0.8641 0.9000
epoch 2000 LossPred 0.1174 LossAtt 0.4577 TrainAcc 0.9800 TestAcc 0.8574 0.9350
epoch 2100 LossPred 0.1562 LossAtt 0.4556 TrainAcc 0.9600 TestAcc 0.8491 0.9350
epoch 2200 LossPred 0.1089 LossAtt 0.4512 TrainAcc 0.9800 TestAcc 0.8574 0.9150
epoch 2300 LossPred 0.0978 LossAtt 0.4504 TrainAcc 0.9800 TestAcc 0.8646 0.9350
epoch 2400 LossPred 0.1493 LossAtt 0.4882 TrainAcc 0.9600 TestAcc 0.8561 0.9500
epoch 2500 LossPred 0.1291 LossAtt 0.4574 TrainAcc 0.9700 TestAcc 0.8501 0.9400
Optimization Finished!
********** replication  52  **********
epoch   0 LossPred 0.9936 LossAtt 1.0234 TrainAcc 0.5600 TestAcc 0.5771 0.5450
epoch 100 LossPred 0.8987 LossAtt 0.9329 TrainAcc 0.6400 TestAcc 0.5285 0.6500
epoch 200 LossPred 0.7973 LossAtt 0.9309 TrainAcc 0.6600 TestAcc 0.5581 0.5950
epoch 300 LossPred 0.7864 LossAtt 0.8594 TrainAcc 0.6700 TestAcc 0.5413 0.6450
epoch 400 LossPred 0.6879 LossAtt 0.5791 TrainAcc 0.7200 TestAcc 0.6532 0.7000
epoch 500 LossPred 0.7483 LossAtt 0.6246 TrainAcc 0.7500 TestAcc 0.7678 0.7000
epoch 600 LossPred 0.9398 LossAtt 0.5001 TrainAcc 0.6200 TestAcc 0.6512 0.6050
epoch 700 LossPred 0.9018 LossAtt 0.4757 TrainAcc 0.6400 TestAcc 0.6634 0.6450
epoch 800 LossPred 0.8253 LossAtt 0.4720 TrainAcc 0.6600 TestAcc 0.7077 0.7050
epoch 900 LossPred 0.7575 LossAtt 0.5259 TrainAcc 0.7200 TestAcc 0.8026 0.7350
epoch 1000 LossPred 0.8314 LossAtt 0.5085 TrainAcc 0.7300 TestAcc 0.7302 0.6900
epoch 1100 LossPred 0.5719 LossAtt 0.4749 TrainAcc 0.7900 TestAcc 0.7980 0.7600
epoch 1200 LossPred 0.5391 LossAtt 0.4670 TrainAcc 0.8300 TestAcc 0.7985 0.7750
epoch 1300 LossPred 0.6224 LossAtt 0.4735 TrainAcc 0.7900 TestAcc 0.7785 0.7450
epoch 1400 LossPred 0.6371 LossAtt 0.4781 TrainAcc 0.7600 TestAcc 0.7410 0.7400
epoch 1500 LossPred 0.9322 LossAtt 0.5345 TrainAcc 0.6300 TestAcc 0.5551 0.5950
epoch 1600 LossPred 0.6022 LossAtt 0.4474 TrainAcc 0.7800 TestAcc 0.7710 0.7550
epoch 1700 LossPred 0.5823 LossAtt 0.4472 TrainAcc 0.8100 TestAcc 0.7853 0.7550
epoch 1800 LossPred 0.6599 LossAtt 0.4737 TrainAcc 0.7400 TestAcc 0.7090 0.7450
epoch 1900 LossPred 0.5613 LossAtt 0.4345 TrainAcc 0.8300 TestAcc 0.7920 0.7750
epoch 2000 LossPred 0.5786 LossAtt 0.4400 TrainAcc 0.8200 TestAcc 0.7850 0.7800
epoch 2100 LossPred 0.5606 LossAtt 0.4451 TrainAcc 0.8100 TestAcc 0.7913 0.7700
epoch 2200 LossPred 1.0469 LossAtt 0.5907 TrainAcc 0.6200 TestAcc 0.6574 0.6350
epoch 2300 LossPred 0.8297 LossAtt 0.4753 TrainAcc 0.7200 TestAcc 0.7010 0.6800
epoch 2400 LossPred 0.6107 LossAtt 0.4183 TrainAcc 0.7900 TestAcc 0.7282 0.7400
epoch 2500 LossPred 0.5531 LossAtt 0.4008 TrainAcc 0.8400 TestAcc 0.7730 0.7700
Optimization Finished!
********** replication  53  **********
epoch   0 LossPred 1.2246 LossAtt 1.0337 TrainAcc 0.4600 TestAcc 0.4787 0.4650
epoch 100 LossPred 0.8188 LossAtt 0.7292 TrainAcc 0.6900 TestAcc 0.5611 0.6700
epoch 200 LossPred 0.4723 LossAtt 0.5300 TrainAcc 0.8600 TestAcc 0.7923 0.8300
epoch 300 LossPred 0.4264 LossAtt 0.4505 TrainAcc 0.8600 TestAcc 0.8156 0.8350
epoch 400 LossPred 0.3961 LossAtt 0.4260 TrainAcc 0.8800 TestAcc 0.8504 0.8350
epoch 500 LossPred 0.4177 LossAtt 0.4501 TrainAcc 0.8700 TestAcc 0.7878 0.8350
epoch 600 LossPred 0.3779 LossAtt 0.4121 TrainAcc 0.8900 TestAcc 0.8541 0.8400
epoch 700 LossPred 0.3970 LossAtt 0.4048 TrainAcc 0.8900 TestAcc 0.8511 0.8350
epoch 800 LossPred 0.3505 LossAtt 0.3778 TrainAcc 0.8900 TestAcc 0.8486 0.8100
epoch 900 LossPred 0.3381 LossAtt 0.3738 TrainAcc 0.9000 TestAcc 0.8611 0.8450
epoch 1000 LossPred 0.3165 LossAtt 0.3586 TrainAcc 0.9100 TestAcc 0.8671 0.8600
epoch 1100 LossPred 0.2746 LossAtt 0.3552 TrainAcc 0.9300 TestAcc 0.8666 0.8450
epoch 1200 LossPred 0.2320 LossAtt 0.3646 TrainAcc 0.9400 TestAcc 0.8689 0.8750
epoch 1300 LossPred 0.2119 LossAtt 0.3674 TrainAcc 0.9400 TestAcc 0.8674 0.8800
epoch 1400 LossPred 0.1699 LossAtt 0.3566 TrainAcc 0.9700 TestAcc 0.8579 0.8800
epoch 1500 LossPred 0.1397 LossAtt 0.3557 TrainAcc 0.9700 TestAcc 0.8646 0.8600
epoch 1600 LossPred 0.1318 LossAtt 0.3516 TrainAcc 0.9700 TestAcc 0.8689 0.8850
epoch 1700 LossPred 0.1384 LossAtt 0.3581 TrainAcc 0.9700 TestAcc 0.8609 0.8800
epoch 1800 LossPred 0.1300 LossAtt 0.3353 TrainAcc 0.9800 TestAcc 0.8591 0.8800
epoch 1900 LossPred 0.6481 LossAtt 0.3641 TrainAcc 0.7800 TestAcc 0.7165 0.7550
epoch 2000 LossPred 0.1156 LossAtt 0.3191 TrainAcc 0.9800 TestAcc 0.8626 0.9100
epoch 2100 LossPred 0.1034 LossAtt 0.3232 TrainAcc 0.9800 TestAcc 0.8634 0.9100
epoch 2200 LossPred 0.0996 LossAtt 0.3102 TrainAcc 0.9800 TestAcc 0.8631 0.9000
epoch 2300 LossPred 0.0957 LossAtt 0.3118 TrainAcc 0.9800 TestAcc 0.8641 0.9100
epoch 2400 LossPred 0.0928 LossAtt 0.3192 TrainAcc 0.9800 TestAcc 0.8666 0.9100
epoch 2500 LossPred 0.0959 LossAtt 0.3284 TrainAcc 0.9800 TestAcc 0.8694 0.9000
Optimization Finished!
********** replication  54  **********
epoch   0 LossPred 0.9963 LossAtt 1.0380 TrainAcc 0.5800 TestAcc 0.5728 0.5600
epoch 100 LossPred 0.7835 LossAtt 0.8613 TrainAcc 0.7000 TestAcc 0.5746 0.7100
epoch 200 LossPred 0.3670 LossAtt 0.7160 TrainAcc 0.9000 TestAcc 0.8433 0.8700
epoch 300 LossPred 0.2238 LossAtt 0.6153 TrainAcc 0.9400 TestAcc 0.8619 0.8800
epoch 400 LossPred 0.0866 LossAtt 0.5548 TrainAcc 0.9800 TestAcc 0.8811 0.8950
epoch 500 LossPred 0.0718 LossAtt 0.5259 TrainAcc 0.9900 TestAcc 0.8721 0.9000
epoch 600 LossPred 0.0511 LossAtt 0.5400 TrainAcc 1.0000 TestAcc 0.8694 0.9100
Optimization Finished!
********** replication  55  **********
epoch   0 LossPred 1.0859 LossAtt 1.0221 TrainAcc 0.4400 TestAcc 0.4302 0.4700
epoch 100 LossPred 0.9329 LossAtt 0.5895 TrainAcc 0.5700 TestAcc 0.6109 0.5400
epoch 200 LossPred 0.8894 LossAtt 0.8305 TrainAcc 0.6000 TestAcc 0.6109 0.5600
epoch 300 LossPred 0.5936 LossAtt 0.8289 TrainAcc 0.8000 TestAcc 0.7923 0.7950
epoch 400 LossPred 0.2664 LossAtt 0.5625 TrainAcc 0.9300 TestAcc 0.8959 0.8850
epoch 500 LossPred 0.2199 LossAtt 0.5259 TrainAcc 0.9400 TestAcc 0.8939 0.9100
epoch 600 LossPred 0.1524 LossAtt 0.5050 TrainAcc 0.9800 TestAcc 0.8944 0.9000
epoch 700 LossPred 0.1274 LossAtt 0.4745 TrainAcc 0.9800 TestAcc 0.8971 0.9000
epoch 800 LossPred 0.1124 LossAtt 0.4624 TrainAcc 0.9800 TestAcc 0.8946 0.9050
epoch 900 LossPred 0.0950 LossAtt 0.4614 TrainAcc 0.9900 TestAcc 0.8976 0.9100
epoch 1000 LossPred 0.1033 LossAtt 0.4347 TrainAcc 0.9800 TestAcc 0.8941 0.9200
epoch 1100 LossPred 0.0816 LossAtt 0.4264 TrainAcc 0.9900 TestAcc 0.8999 0.9150
epoch 1200 LossPred 0.2356 LossAtt 0.4177 TrainAcc 0.8900 TestAcc 0.8929 0.8800
epoch 1300 LossPred 0.2761 LossAtt 0.4342 TrainAcc 0.9200 TestAcc 0.8386 0.9000
epoch 1400 LossPred 0.0726 LossAtt 0.4038 TrainAcc 0.9900 TestAcc 0.8966 0.9100
epoch 1500 LossPred 0.3743 LossAtt 0.3896 TrainAcc 0.8800 TestAcc 0.8546 0.8700
epoch 1600 LossPred 0.3498 LossAtt 0.3948 TrainAcc 0.8900 TestAcc 0.8824 0.8600
epoch 1700 LossPred 0.0672 LossAtt 0.3914 TrainAcc 0.9900 TestAcc 0.8904 0.9100
epoch 1800 LossPred 0.0657 LossAtt 0.3763 TrainAcc 0.9900 TestAcc 0.8939 0.9200
epoch 1900 LossPred 0.0609 LossAtt 0.3689 TrainAcc 0.9900 TestAcc 0.8916 0.9200
epoch 2000 LossPred 0.0675 LossAtt 0.3671 TrainAcc 0.9900 TestAcc 0.8879 0.9150
epoch 2100 LossPred 0.0674 LossAtt 0.3820 TrainAcc 0.9900 TestAcc 0.8836 0.9250
epoch 2200 LossPred 0.0578 LossAtt 0.3753 TrainAcc 0.9900 TestAcc 0.8854 0.9200
epoch 2300 LossPred 0.0613 LossAtt 0.4006 TrainAcc 0.9900 TestAcc 0.8824 0.9200
epoch 2400 LossPred 0.0704 LossAtt 0.3871 TrainAcc 0.9900 TestAcc 0.8831 0.9100
epoch 2500 LossPred 0.0524 LossAtt 0.3623 TrainAcc 0.9900 TestAcc 0.8786 0.9200
Optimization Finished!
********** replication  56  **********
epoch   0 LossPred 1.0006 LossAtt 1.0309 TrainAcc 0.5000 TestAcc 0.4945 0.5250
epoch 100 LossPred 0.8114 LossAtt 0.6419 TrainAcc 0.6700 TestAcc 0.5898 0.6700
epoch 200 LossPred 0.5792 LossAtt 0.8261 TrainAcc 0.8400 TestAcc 0.7863 0.7900
epoch 300 LossPred 0.4140 LossAtt 0.4791 TrainAcc 0.8600 TestAcc 0.8201 0.8350
epoch 400 LossPred 0.3944 LossAtt 0.5093 TrainAcc 0.8800 TestAcc 0.8056 0.8450
epoch 500 LossPred 0.2934 LossAtt 0.4079 TrainAcc 0.9200 TestAcc 0.8393 0.8500
epoch 600 LossPred 0.2594 LossAtt 0.3952 TrainAcc 0.9300 TestAcc 0.8423 0.8550
epoch 700 LossPred 0.3722 LossAtt 0.5016 TrainAcc 0.8700 TestAcc 0.8381 0.8450
epoch 800 LossPred 0.2338 LossAtt 0.3821 TrainAcc 0.9400 TestAcc 0.8534 0.8600
epoch 900 LossPred 0.2207 LossAtt 0.3772 TrainAcc 0.9400 TestAcc 0.8649 0.8800
epoch 1000 LossPred 0.2496 LossAtt 0.3962 TrainAcc 0.9200 TestAcc 0.8308 0.8400
epoch 1100 LossPred 0.2517 LossAtt 0.4002 TrainAcc 0.9400 TestAcc 0.8321 0.8500
epoch 1200 LossPred 0.1748 LossAtt 0.3775 TrainAcc 0.9600 TestAcc 0.8654 0.8750
epoch 1300 LossPred 0.1668 LossAtt 0.3697 TrainAcc 0.9600 TestAcc 0.8646 0.8700
epoch 1400 LossPred 0.1757 LossAtt 0.3789 TrainAcc 0.9500 TestAcc 0.8586 0.8750
epoch 1500 LossPred 0.2970 LossAtt 0.3747 TrainAcc 0.9100 TestAcc 0.8739 0.8750
epoch 1600 LossPred 0.3299 LossAtt 0.3599 TrainAcc 0.8900 TestAcc 0.8674 0.8500
epoch 1700 LossPred 0.1815 LossAtt 0.3462 TrainAcc 0.9500 TestAcc 0.8481 0.8600
epoch 1800 LossPred 0.1809 LossAtt 0.3414 TrainAcc 0.9500 TestAcc 0.8541 0.8750
epoch 1900 LossPred 0.1856 LossAtt 0.3262 TrainAcc 0.9500 TestAcc 0.8629 0.8700
epoch 2000 LossPred 0.1560 LossAtt 0.3081 TrainAcc 0.9600 TestAcc 0.8591 0.8550
epoch 2100 LossPred 0.2264 LossAtt 0.3194 TrainAcc 0.9300 TestAcc 0.8406 0.8650
epoch 2200 LossPred 0.2025 LossAtt 0.2980 TrainAcc 0.9400 TestAcc 0.8526 0.8750
epoch 2300 LossPred 0.1837 LossAtt 0.3126 TrainAcc 0.9500 TestAcc 0.8551 0.8800
epoch 2400 LossPred 0.1848 LossAtt 0.3069 TrainAcc 0.9400 TestAcc 0.8596 0.8650
epoch 2500 LossPred 0.2529 LossAtt 0.2891 TrainAcc 0.9100 TestAcc 0.8779 0.8750
Optimization Finished!
********** replication  57  **********
epoch   0 LossPred 1.0618 LossAtt 1.0827 TrainAcc 0.5600 TestAcc 0.4510 0.5300
epoch 100 LossPred 0.8364 LossAtt 0.9106 TrainAcc 0.6500 TestAcc 0.4790 0.6500
epoch 200 LossPred 0.4779 LossAtt 1.4021 TrainAcc 0.8200 TestAcc 0.5390 0.7850
epoch 300 LossPred 0.3925 LossAtt 1.1667 TrainAcc 0.8600 TestAcc 0.5438 0.7950
epoch 400 LossPred 0.3588 LossAtt 0.9620 TrainAcc 0.8800 TestAcc 0.5536 0.8250
epoch 500 LossPred 0.3262 LossAtt 0.8958 TrainAcc 0.9000 TestAcc 0.5581 0.8100
epoch 600 LossPred 0.3419 LossAtt 0.9533 TrainAcc 0.9000 TestAcc 0.5455 0.8250
epoch 700 LossPred 0.3025 LossAtt 0.7986 TrainAcc 0.9100 TestAcc 0.5566 0.8000
epoch 800 LossPred 0.2690 LossAtt 0.8552 TrainAcc 0.9100 TestAcc 0.5485 0.8050
epoch 900 LossPred 0.2577 LossAtt 0.7358 TrainAcc 0.9200 TestAcc 0.5493 0.8100
epoch 1000 LossPred 0.2812 LossAtt 0.7304 TrainAcc 0.9000 TestAcc 0.5418 0.8050
epoch 1100 LossPred 0.1904 LossAtt 0.6944 TrainAcc 0.9400 TestAcc 0.5588 0.8350
epoch 1200 LossPred 0.2148 LossAtt 0.7043 TrainAcc 0.9400 TestAcc 0.5516 0.8550
epoch 1300 LossPred 0.4406 LossAtt 0.7188 TrainAcc 0.8600 TestAcc 0.5608 0.7700
epoch 1400 LossPred 0.3117 LossAtt 0.6811 TrainAcc 0.9200 TestAcc 0.5743 0.8100
epoch 1500 LossPred 0.2959 LossAtt 0.7278 TrainAcc 0.9000 TestAcc 0.5773 0.8400
epoch 1600 LossPred 0.2216 LossAtt 0.6833 TrainAcc 0.9400 TestAcc 0.5761 0.8250
epoch 1700 LossPred 0.2204 LossAtt 0.6812 TrainAcc 0.9500 TestAcc 0.5801 0.8250
epoch 1800 LossPred 0.1926 LossAtt 0.6690 TrainAcc 0.9600 TestAcc 0.5773 0.8400
epoch 1900 LossPred 0.3506 LossAtt 0.8626 TrainAcc 0.8600 TestAcc 0.5926 0.8350
epoch 2000 LossPred 0.1443 LossAtt 0.6394 TrainAcc 0.9600 TestAcc 0.5933 0.8700
epoch 2100 LossPred 0.1291 LossAtt 0.6468 TrainAcc 0.9800 TestAcc 0.5951 0.8500
epoch 2200 LossPred 0.2014 LossAtt 0.6686 TrainAcc 0.9500 TestAcc 0.6036 0.8350
epoch 2300 LossPred 0.1858 LossAtt 0.6684 TrainAcc 0.9400 TestAcc 0.5903 0.8600
epoch 2400 LossPred 0.1954 LossAtt 0.6905 TrainAcc 0.9400 TestAcc 0.6036 0.8350
epoch 2500 LossPred 0.2010 LossAtt 0.7156 TrainAcc 0.9500 TestAcc 0.6139 0.8550
Optimization Finished!
********** replication  58  **********
epoch   0 LossPred 1.0474 LossAtt 1.0285 TrainAcc 0.4700 TestAcc 0.4927 0.4700
epoch 100 LossPred 0.8195 LossAtt 0.9328 TrainAcc 0.6500 TestAcc 0.6519 0.6650
epoch 200 LossPred 0.5707 LossAtt 0.5356 TrainAcc 0.8200 TestAcc 0.8403 0.8100
epoch 300 LossPred 0.4286 LossAtt 0.4396 TrainAcc 0.8900 TestAcc 0.8446 0.8700
epoch 400 LossPred 0.2970 LossAtt 0.4029 TrainAcc 0.9200 TestAcc 0.8336 0.8950
epoch 500 LossPred 0.3020 LossAtt 0.3877 TrainAcc 0.9200 TestAcc 0.8316 0.8700
epoch 600 LossPred 0.3003 LossAtt 0.3529 TrainAcc 0.9100 TestAcc 0.8188 0.8700
epoch 700 LossPred 0.2726 LossAtt 0.3392 TrainAcc 0.9400 TestAcc 0.8311 0.8500
epoch 800 LossPred 0.2467 LossAtt 0.3391 TrainAcc 0.9400 TestAcc 0.8241 0.8500
epoch 900 LossPred 0.2957 LossAtt 0.3307 TrainAcc 0.9000 TestAcc 0.8418 0.8650
epoch 1000 LossPred 0.2615 LossAtt 0.3338 TrainAcc 0.9300 TestAcc 0.8423 0.8550
epoch 1100 LossPred 0.2587 LossAtt 0.3310 TrainAcc 0.9300 TestAcc 0.8428 0.8750
epoch 1200 LossPred 0.2518 LossAtt 0.3184 TrainAcc 0.9400 TestAcc 0.8213 0.8850
epoch 1300 LossPred 0.2159 LossAtt 0.3126 TrainAcc 0.9500 TestAcc 0.8223 0.8600
epoch 1400 LossPred 0.2337 LossAtt 0.3039 TrainAcc 0.9300 TestAcc 0.8393 0.8700
epoch 1500 LossPred 0.2429 LossAtt 0.3033 TrainAcc 0.9400 TestAcc 0.8348 0.8850
epoch 1600 LossPred 0.2275 LossAtt 0.2843 TrainAcc 0.9300 TestAcc 0.8356 0.8700
epoch 1700 LossPred 0.2383 LossAtt 0.2890 TrainAcc 0.9400 TestAcc 0.8436 0.8850
epoch 1800 LossPred 0.3149 LossAtt 0.2836 TrainAcc 0.9200 TestAcc 0.8216 0.8700
epoch 1900 LossPred 0.2350 LossAtt 0.3139 TrainAcc 0.9300 TestAcc 0.8428 0.8950
epoch 2000 LossPred 0.2941 LossAtt 0.2980 TrainAcc 0.9200 TestAcc 0.8246 0.8800
epoch 2100 LossPred 0.2129 LossAtt 0.2899 TrainAcc 0.9300 TestAcc 0.8641 0.8750
epoch 2200 LossPred 0.1715 LossAtt 0.2935 TrainAcc 0.9600 TestAcc 0.8431 0.8850
epoch 2300 LossPred 0.1862 LossAtt 0.2847 TrainAcc 0.9400 TestAcc 0.8579 0.8800
epoch 2400 LossPred 0.2445 LossAtt 0.3012 TrainAcc 0.9200 TestAcc 0.8468 0.8750
epoch 2500 LossPred 0.3002 LossAtt 0.3187 TrainAcc 0.9200 TestAcc 0.8599 0.8800
Optimization Finished!
********** replication  59  **********
epoch   0 LossPred 1.0461 LossAtt 1.0359 TrainAcc 0.5000 TestAcc 0.5103 0.5100
epoch 100 LossPred 0.7864 LossAtt 0.6693 TrainAcc 0.6900 TestAcc 0.6026 0.6750
epoch 200 LossPred 0.3692 LossAtt 0.4967 TrainAcc 0.8800 TestAcc 0.8463 0.8550
epoch 300 LossPred 0.2757 LossAtt 0.4164 TrainAcc 0.9200 TestAcc 0.8428 0.8800
epoch 400 LossPred 0.2837 LossAtt 0.4144 TrainAcc 0.9100 TestAcc 0.8293 0.8850
epoch 500 LossPred 0.2051 LossAtt 0.4050 TrainAcc 0.9200 TestAcc 0.8634 0.8850
epoch 600 LossPred 0.2857 LossAtt 0.4059 TrainAcc 0.9000 TestAcc 0.8531 0.8700
epoch 700 LossPred 0.2282 LossAtt 0.3884 TrainAcc 0.9300 TestAcc 0.8574 0.8900
epoch 800 LossPred 0.1762 LossAtt 0.3504 TrainAcc 0.9300 TestAcc 0.8804 0.8900
epoch 900 LossPred 0.1738 LossAtt 0.3441 TrainAcc 0.9400 TestAcc 0.8576 0.8850
epoch 1000 LossPred 0.1730 LossAtt 0.3427 TrainAcc 0.9400 TestAcc 0.8814 0.9000
epoch 1100 LossPred 0.2454 LossAtt 0.3574 TrainAcc 0.9000 TestAcc 0.8746 0.8850
epoch 1200 LossPred 0.1783 LossAtt 0.3144 TrainAcc 0.9400 TestAcc 0.8519 0.9050
epoch 1300 LossPred 0.2152 LossAtt 0.3050 TrainAcc 0.9200 TestAcc 0.8824 0.8900
epoch 1400 LossPred 0.4062 LossAtt 0.3123 TrainAcc 0.8900 TestAcc 0.7823 0.8750
epoch 1500 LossPred 0.1513 LossAtt 0.3117 TrainAcc 0.9500 TestAcc 0.8974 0.9250
epoch 1600 LossPred 0.1071 LossAtt 0.2881 TrainAcc 0.9700 TestAcc 0.9007 0.9500
epoch 1700 LossPred 0.0640 LossAtt 0.2676 TrainAcc 0.9900 TestAcc 0.9522 0.9600
epoch 1800 LossPred 0.5025 LossAtt 0.3924 TrainAcc 0.8600 TestAcc 0.8213 0.8450
epoch 1900 LossPred 0.0833 LossAtt 0.2430 TrainAcc 0.9900 TestAcc 0.9384 0.9650
epoch 2000 LossPred 0.0628 LossAtt 0.2499 TrainAcc 1.0000 TestAcc 0.9535 0.9750
Optimization Finished!
********** replication  60  **********
epoch   0 LossPred 1.0233 LossAtt 1.0284 TrainAcc 0.4400 TestAcc 0.5055 0.4750
epoch 100 LossPred 0.8716 LossAtt 0.6776 TrainAcc 0.6400 TestAcc 0.5668 0.6400
epoch 200 LossPred 0.5098 LossAtt 0.7247 TrainAcc 0.8100 TestAcc 0.7598 0.8400
epoch 300 LossPred 0.2782 LossAtt 0.5080 TrainAcc 0.9000 TestAcc 0.8423 0.9050
epoch 400 LossPred 0.1817 LossAtt 0.4396 TrainAcc 0.9300 TestAcc 0.8509 0.9050
epoch 500 LossPred 0.2068 LossAtt 0.4723 TrainAcc 0.9300 TestAcc 0.8488 0.8950
epoch 600 LossPred 0.1571 LossAtt 0.4482 TrainAcc 0.9500 TestAcc 0.8438 0.9400
epoch 700 LossPred 0.1078 LossAtt 0.4028 TrainAcc 0.9700 TestAcc 0.8574 0.9300
epoch 800 LossPred 0.0939 LossAtt 0.4096 TrainAcc 0.9800 TestAcc 0.8549 0.9350
epoch 900 LossPred 0.1330 LossAtt 0.4086 TrainAcc 0.9600 TestAcc 0.8526 0.9550
epoch 1000 LossPred 0.0828 LossAtt 0.3967 TrainAcc 0.9700 TestAcc 0.8504 0.9550
epoch 1100 LossPred 0.0525 LossAtt 0.3933 TrainAcc 0.9900 TestAcc 0.8509 0.9500
epoch 1200 LossPred 0.2357 LossAtt 0.3973 TrainAcc 0.9100 TestAcc 0.8413 0.9100
epoch 1300 LossPred 0.0510 LossAtt 0.4320 TrainAcc 0.9900 TestAcc 0.8461 0.9550
epoch 1400 LossPred 0.0536 LossAtt 0.4431 TrainAcc 0.9900 TestAcc 0.8438 0.9600
epoch 1500 LossPred 0.0360 LossAtt 0.3806 TrainAcc 1.0000 TestAcc 0.8539 0.9700
Optimization Finished!
********** replication  61  **********
epoch   0 LossPred 1.0095 LossAtt 1.0144 TrainAcc 0.5300 TestAcc 0.5125 0.5100
epoch 100 LossPred 0.8290 LossAtt 0.9197 TrainAcc 0.6500 TestAcc 0.5453 0.6700
epoch 200 LossPred 0.7086 LossAtt 0.8199 TrainAcc 0.7200 TestAcc 0.5533 0.6850
epoch 300 LossPred 0.6401 LossAtt 0.9360 TrainAcc 0.7700 TestAcc 0.5511 0.7250
epoch 400 LossPred 0.5837 LossAtt 1.0207 TrainAcc 0.7500 TestAcc 0.5323 0.6950
epoch 500 LossPred 0.5251 LossAtt 0.8614 TrainAcc 0.8000 TestAcc 0.5358 0.7200
epoch 600 LossPred 0.5798 LossAtt 0.7837 TrainAcc 0.7700 TestAcc 0.5390 0.7400
epoch 700 LossPred 0.5113 LossAtt 0.6759 TrainAcc 0.8200 TestAcc 0.5523 0.7650
epoch 800 LossPred 0.5186 LossAtt 0.7840 TrainAcc 0.7900 TestAcc 0.5438 0.7600
epoch 900 LossPred 0.5162 LossAtt 0.6918 TrainAcc 0.8200 TestAcc 0.5786 0.7850
epoch 1000 LossPred 0.4372 LossAtt 0.6896 TrainAcc 0.8500 TestAcc 0.5483 0.7750
epoch 1100 LossPred 0.5158 LossAtt 0.7402 TrainAcc 0.7900 TestAcc 0.5958 0.7450
epoch 1200 LossPred 0.4036 LossAtt 0.6073 TrainAcc 0.8500 TestAcc 0.5751 0.7900
epoch 1300 LossPred 0.3674 LossAtt 0.6126 TrainAcc 0.8600 TestAcc 0.5678 0.7950
epoch 1400 LossPred 0.3544 LossAtt 0.6381 TrainAcc 0.8800 TestAcc 0.5756 0.8050
epoch 1500 LossPred 0.3211 LossAtt 0.6424 TrainAcc 0.9000 TestAcc 0.5686 0.8000
epoch 1600 LossPred 0.8337 LossAtt 0.8196 TrainAcc 0.6900 TestAcc 0.5335 0.7200
epoch 1700 LossPred 0.4435 LossAtt 0.6276 TrainAcc 0.8700 TestAcc 0.5490 0.7800
epoch 1800 LossPred 0.2949 LossAtt 0.6229 TrainAcc 0.9100 TestAcc 0.5626 0.7750
epoch 1900 LossPred 0.2588 LossAtt 0.6217 TrainAcc 0.9300 TestAcc 0.5658 0.7950
epoch 2000 LossPred 0.2594 LossAtt 0.6759 TrainAcc 0.9400 TestAcc 0.5666 0.7900
epoch 2100 LossPred 0.2482 LossAtt 0.6278 TrainAcc 0.9400 TestAcc 0.5618 0.7800
epoch 2200 LossPred 0.2110 LossAtt 0.6127 TrainAcc 0.9400 TestAcc 0.5691 0.7850
epoch 2300 LossPred 0.2004 LossAtt 0.6121 TrainAcc 0.9500 TestAcc 0.5746 0.7950
epoch 2400 LossPred 0.2928 LossAtt 0.6557 TrainAcc 0.9200 TestAcc 0.5826 0.7800
epoch 2500 LossPred 0.2015 LossAtt 0.5998 TrainAcc 0.9500 TestAcc 0.5716 0.7900
Optimization Finished!
********** replication  62  **********
epoch   0 LossPred 1.0502 LossAtt 1.0233 TrainAcc 0.5500 TestAcc 0.5508 0.5350
epoch 100 LossPred 0.8682 LossAtt 0.8270 TrainAcc 0.6500 TestAcc 0.6339 0.6550
epoch 200 LossPred 0.9224 LossAtt 0.5872 TrainAcc 0.5800 TestAcc 0.4990 0.5700
epoch 300 LossPred 0.4050 LossAtt 0.5296 TrainAcc 0.9000 TestAcc 0.8401 0.8600
epoch 400 LossPred 0.1998 LossAtt 0.4770 TrainAcc 0.9500 TestAcc 0.8243 0.9300
epoch 500 LossPred 0.1613 LossAtt 0.4623 TrainAcc 0.9600 TestAcc 0.8271 0.9300
epoch 600 LossPred 0.1825 LossAtt 0.4567 TrainAcc 0.9600 TestAcc 0.8353 0.9350
epoch 700 LossPred 0.1528 LossAtt 0.4326 TrainAcc 0.9600 TestAcc 0.8193 0.9350
epoch 800 LossPred 0.1095 LossAtt 0.4170 TrainAcc 0.9700 TestAcc 0.8246 0.9400
epoch 900 LossPred 0.2102 LossAtt 0.4719 TrainAcc 0.9400 TestAcc 0.7995 0.9100
epoch 1000 LossPred 0.1749 LossAtt 0.4497 TrainAcc 0.9600 TestAcc 0.8504 0.9450
epoch 1100 LossPred 0.1069 LossAtt 0.4290 TrainAcc 0.9700 TestAcc 0.8298 0.9650
epoch 1200 LossPred 0.1026 LossAtt 0.4264 TrainAcc 0.9800 TestAcc 0.8338 0.9550
epoch 1300 LossPred 0.0865 LossAtt 0.4303 TrainAcc 0.9800 TestAcc 0.8273 0.9450
epoch 1400 LossPred 0.0857 LossAtt 0.4115 TrainAcc 0.9800 TestAcc 0.8321 0.9450
epoch 1500 LossPred 0.1349 LossAtt 0.4434 TrainAcc 0.9700 TestAcc 0.8273 0.9500
epoch 1600 LossPred 0.0722 LossAtt 0.4218 TrainAcc 0.9800 TestAcc 0.8246 0.9450
epoch 1700 LossPred 0.0688 LossAtt 0.4251 TrainAcc 0.9800 TestAcc 0.8316 0.9450
epoch 1800 LossPred 0.0620 LossAtt 0.4175 TrainAcc 0.9800 TestAcc 0.8283 0.9500
epoch 1900 LossPred 0.0670 LossAtt 0.4300 TrainAcc 0.9800 TestAcc 0.8378 0.9550
epoch 2000 LossPred 0.0532 LossAtt 0.4211 TrainAcc 0.9900 TestAcc 0.8283 0.9550
epoch 2100 LossPred 0.0487 LossAtt 0.4064 TrainAcc 0.9900 TestAcc 0.8296 0.9650
epoch 2200 LossPred 0.1292 LossAtt 0.4747 TrainAcc 0.9400 TestAcc 0.8666 0.9300
epoch 2300 LossPred 0.0485 LossAtt 0.4094 TrainAcc 0.9900 TestAcc 0.8288 0.9700
epoch 2400 LossPred 0.0649 LossAtt 0.4253 TrainAcc 0.9800 TestAcc 0.8609 0.9850
epoch 2500 LossPred 0.0354 LossAtt 0.4142 TrainAcc 0.9900 TestAcc 0.8168 0.9700
Optimization Finished!
********** replication  63  **********
epoch   0 LossPred 1.0171 LossAtt 1.0188 TrainAcc 0.5300 TestAcc 0.4820 0.5400
epoch 100 LossPred 0.8676 LossAtt 0.6539 TrainAcc 0.6100 TestAcc 0.5313 0.5950
epoch 200 LossPred 0.7617 LossAtt 1.0067 TrainAcc 0.7100 TestAcc 0.5310 0.6850
epoch 300 LossPred 0.5132 LossAtt 1.0871 TrainAcc 0.8400 TestAcc 0.5153 0.7250
epoch 400 LossPred 0.4668 LossAtt 0.8958 TrainAcc 0.8500 TestAcc 0.5155 0.7300
epoch 500 LossPred 0.4101 LossAtt 0.8390 TrainAcc 0.8500 TestAcc 0.5125 0.7350
epoch 600 LossPred 0.4026 LossAtt 0.7906 TrainAcc 0.8800 TestAcc 0.5000 0.7550
epoch 700 LossPred 0.4030 LossAtt 0.7703 TrainAcc 0.9000 TestAcc 0.5050 0.7800
epoch 800 LossPred 0.3460 LossAtt 0.7872 TrainAcc 0.9100 TestAcc 0.5083 0.8000
epoch 900 LossPred 0.2936 LossAtt 0.7288 TrainAcc 0.9400 TestAcc 0.5040 0.7950
epoch 1000 LossPred 0.3561 LossAtt 0.7466 TrainAcc 0.9000 TestAcc 0.5045 0.8100
epoch 1100 LossPred 0.2683 LossAtt 0.7193 TrainAcc 0.9400 TestAcc 0.5070 0.8100
epoch 1200 LossPred 0.2478 LossAtt 0.7003 TrainAcc 0.9400 TestAcc 0.5025 0.7800
epoch 1300 LossPred 0.2445 LossAtt 0.7159 TrainAcc 0.9300 TestAcc 0.5058 0.7850
epoch 1400 LossPred 0.4673 LossAtt 0.7653 TrainAcc 0.8800 TestAcc 0.5075 0.7500
epoch 1500 LossPred 0.2493 LossAtt 0.6546 TrainAcc 0.9300 TestAcc 0.4950 0.7800
epoch 1600 LossPred 0.2127 LossAtt 0.6578 TrainAcc 0.9500 TestAcc 0.4937 0.7950
epoch 1700 LossPred 0.2003 LossAtt 0.6564 TrainAcc 0.9500 TestAcc 0.4947 0.7850
epoch 1800 LossPred 0.1812 LossAtt 0.6622 TrainAcc 0.9600 TestAcc 0.4970 0.8000
epoch 1900 LossPred 0.1642 LossAtt 0.6598 TrainAcc 0.9600 TestAcc 0.4980 0.7850
epoch 2000 LossPred 0.1450 LossAtt 0.6604 TrainAcc 0.9700 TestAcc 0.4997 0.7800
epoch 2100 LossPred 0.1309 LossAtt 0.6584 TrainAcc 0.9700 TestAcc 0.5015 0.7700
epoch 2200 LossPred 0.6736 LossAtt 0.7452 TrainAcc 0.7900 TestAcc 0.4992 0.7250
epoch 2300 LossPred 0.4254 LossAtt 0.6400 TrainAcc 0.8700 TestAcc 0.5050 0.7550
epoch 2400 LossPred 0.3766 LossAtt 0.6446 TrainAcc 0.8900 TestAcc 0.5040 0.7900
epoch 2500 LossPred 0.3467 LossAtt 0.6309 TrainAcc 0.9200 TestAcc 0.5053 0.7800
Optimization Finished!
********** replication  64  **********
epoch   0 LossPred 1.0214 LossAtt 1.0373 TrainAcc 0.5000 TestAcc 0.5393 0.4950
epoch 100 LossPred 0.7867 LossAtt 0.9148 TrainAcc 0.7000 TestAcc 0.5143 0.6800
epoch 200 LossPred 0.5751 LossAtt 1.3661 TrainAcc 0.7900 TestAcc 0.5941 0.7450
epoch 300 LossPred 0.4673 LossAtt 1.1057 TrainAcc 0.8500 TestAcc 0.6044 0.7900
epoch 400 LossPred 0.3854 LossAtt 0.9633 TrainAcc 0.8700 TestAcc 0.6106 0.7950
epoch 500 LossPred 0.3478 LossAtt 0.8449 TrainAcc 0.9200 TestAcc 0.6134 0.8050
epoch 600 LossPred 0.3164 LossAtt 0.7520 TrainAcc 0.9200 TestAcc 0.6059 0.8000
epoch 700 LossPred 0.3015 LossAtt 0.7536 TrainAcc 0.9200 TestAcc 0.6154 0.7950
epoch 800 LossPred 0.2483 LossAtt 0.7154 TrainAcc 0.9400 TestAcc 0.6114 0.8150
epoch 900 LossPred 0.3480 LossAtt 0.7979 TrainAcc 0.9100 TestAcc 0.6149 0.8000
epoch 1000 LossPred 0.2413 LossAtt 0.8136 TrainAcc 0.9300 TestAcc 0.6101 0.7850
epoch 1100 LossPred 0.2388 LossAtt 0.6863 TrainAcc 0.9300 TestAcc 0.6081 0.8300
epoch 1200 LossPred 0.2155 LossAtt 0.6783 TrainAcc 0.9500 TestAcc 0.6026 0.8200
epoch 1300 LossPred 0.1923 LossAtt 0.7198 TrainAcc 0.9500 TestAcc 0.6069 0.8200
epoch 1400 LossPred 0.1555 LossAtt 0.6575 TrainAcc 0.9800 TestAcc 0.6081 0.8300
epoch 1500 LossPred 0.1667 LossAtt 0.6557 TrainAcc 0.9800 TestAcc 0.6011 0.8100
epoch 1600 LossPred 0.1463 LossAtt 0.6448 TrainAcc 0.9700 TestAcc 0.5988 0.8200
epoch 1700 LossPred 0.1583 LossAtt 0.6821 TrainAcc 0.9800 TestAcc 0.6019 0.8200
epoch 1800 LossPred 0.2951 LossAtt 0.7320 TrainAcc 0.9100 TestAcc 0.6149 0.8200
epoch 1900 LossPred 0.1072 LossAtt 0.6098 TrainAcc 0.9900 TestAcc 0.6014 0.8250
epoch 2000 LossPred 0.0969 LossAtt 0.6107 TrainAcc 0.9900 TestAcc 0.6056 0.8250
epoch 2100 LossPred 0.0933 LossAtt 0.6337 TrainAcc 0.9900 TestAcc 0.6134 0.8300
epoch 2200 LossPred 0.1219 LossAtt 0.6358 TrainAcc 0.9800 TestAcc 0.6119 0.8100
epoch 2300 LossPred 0.0917 LossAtt 0.5972 TrainAcc 0.9900 TestAcc 0.6039 0.8250
epoch 2400 LossPred 0.0759 LossAtt 0.5841 TrainAcc 0.9900 TestAcc 0.6044 0.8400
epoch 2500 LossPred 0.0736 LossAtt 0.5713 TrainAcc 0.9900 TestAcc 0.6059 0.8300
Optimization Finished!
********** replication  65  **********
epoch   0 LossPred 0.9790 LossAtt 1.0178 TrainAcc 0.6200 TestAcc 0.5475 0.6100
epoch 100 LossPred 0.5027 LossAtt 0.8562 TrainAcc 0.8200 TestAcc 0.8261 0.8450
epoch 200 LossPred 0.3960 LossAtt 0.4203 TrainAcc 0.8700 TestAcc 0.8458 0.8250
epoch 300 LossPred 0.2885 LossAtt 0.3864 TrainAcc 0.9100 TestAcc 0.8676 0.8500
epoch 400 LossPred 0.2705 LossAtt 0.3709 TrainAcc 0.9200 TestAcc 0.8671 0.8700
epoch 500 LossPred 0.2187 LossAtt 0.3389 TrainAcc 0.9300 TestAcc 0.8686 0.8850
epoch 600 LossPred 0.2006 LossAtt 0.3396 TrainAcc 0.9300 TestAcc 0.8606 0.8950
epoch 700 LossPred 0.1879 LossAtt 0.3304 TrainAcc 0.9400 TestAcc 0.8591 0.9050
epoch 800 LossPred 0.1941 LossAtt 0.3151 TrainAcc 0.9500 TestAcc 0.8428 0.8950
epoch 900 LossPred 0.2938 LossAtt 0.3281 TrainAcc 0.9000 TestAcc 0.8346 0.8700
epoch 1000 LossPred 0.1756 LossAtt 0.3051 TrainAcc 0.9500 TestAcc 0.8486 0.9050
epoch 1100 LossPred 0.2183 LossAtt 0.3277 TrainAcc 0.9400 TestAcc 0.8626 0.9050
epoch 1200 LossPred 0.1761 LossAtt 0.3042 TrainAcc 0.9500 TestAcc 0.8571 0.9000
epoch 1300 LossPred 0.1806 LossAtt 0.3165 TrainAcc 0.9500 TestAcc 0.8624 0.9050
epoch 1400 LossPred 0.1942 LossAtt 0.2846 TrainAcc 0.9400 TestAcc 0.8599 0.9000
epoch 1500 LossPred 0.1671 LossAtt 0.2765 TrainAcc 0.9400 TestAcc 0.8504 0.9050
epoch 1600 LossPred 0.1608 LossAtt 0.2736 TrainAcc 0.9400 TestAcc 0.8539 0.9150
epoch 1700 LossPred 0.3672 LossAtt 0.3135 TrainAcc 0.8600 TestAcc 0.8451 0.8650
epoch 1800 LossPred 0.1737 LossAtt 0.2844 TrainAcc 0.9400 TestAcc 0.8493 0.9100
epoch 1900 LossPred 0.1659 LossAtt 0.2799 TrainAcc 0.9500 TestAcc 0.8669 0.9150
epoch 2000 LossPred 0.1676 LossAtt 0.2785 TrainAcc 0.9600 TestAcc 0.8711 0.9100
epoch 2100 LossPred 0.1710 LossAtt 0.2883 TrainAcc 0.9600 TestAcc 0.8478 0.9100
epoch 2200 LossPred 0.1629 LossAtt 0.2711 TrainAcc 0.9500 TestAcc 0.8649 0.9000
epoch 2300 LossPred 0.2303 LossAtt 0.3215 TrainAcc 0.9100 TestAcc 0.8651 0.8700
epoch 2400 LossPred 0.2193 LossAtt 0.3211 TrainAcc 0.9500 TestAcc 0.8786 0.8950
epoch 2500 LossPred 0.1653 LossAtt 0.2868 TrainAcc 0.9500 TestAcc 0.8781 0.8900
Optimization Finished!
********** replication  66  **********
epoch   0 LossPred 1.0608 LossAtt 1.0516 TrainAcc 0.5400 TestAcc 0.5150 0.5250
epoch 100 LossPred 0.8835 LossAtt 0.7702 TrainAcc 0.6400 TestAcc 0.5733 0.6000
epoch 200 LossPred 0.8155 LossAtt 1.3701 TrainAcc 0.6800 TestAcc 0.5388 0.6600
epoch 300 LossPred 0.6659 LossAtt 0.9834 TrainAcc 0.7500 TestAcc 0.5158 0.7400
epoch 400 LossPred 0.5367 LossAtt 0.8707 TrainAcc 0.8600 TestAcc 0.4960 0.7550
epoch 500 LossPred 0.4709 LossAtt 0.7856 TrainAcc 0.8800 TestAcc 0.4995 0.7650
epoch 600 LossPred 0.4073 LossAtt 0.7034 TrainAcc 0.9000 TestAcc 0.5015 0.7700
epoch 700 LossPred 0.3744 LossAtt 0.6391 TrainAcc 0.9300 TestAcc 0.5010 0.7600
epoch 800 LossPred 0.3517 LossAtt 0.6891 TrainAcc 0.9300 TestAcc 0.5020 0.7750
epoch 900 LossPred 0.3235 LossAtt 0.6083 TrainAcc 0.8900 TestAcc 0.4937 0.7750
epoch 1000 LossPred 0.3038 LossAtt 0.6485 TrainAcc 0.9200 TestAcc 0.4997 0.7950
epoch 1100 LossPred 0.3854 LossAtt 0.5827 TrainAcc 0.9000 TestAcc 0.4980 0.7850
epoch 1200 LossPred 0.3352 LossAtt 0.5558 TrainAcc 0.8900 TestAcc 0.4975 0.7850
epoch 1300 LossPred 0.9749 LossAtt 0.8434 TrainAcc 0.6800 TestAcc 0.5128 0.6500
epoch 1400 LossPred 0.2939 LossAtt 0.5514 TrainAcc 0.9100 TestAcc 0.4992 0.7750
epoch 1500 LossPred 0.3943 LossAtt 0.5547 TrainAcc 0.8900 TestAcc 0.5005 0.7900
epoch 1600 LossPred 0.3344 LossAtt 0.5359 TrainAcc 0.9000 TestAcc 0.4937 0.8000
epoch 1700 LossPred 0.3291 LossAtt 0.5744 TrainAcc 0.8900 TestAcc 0.4970 0.7750
epoch 1800 LossPred 0.4878 LossAtt 0.5935 TrainAcc 0.8400 TestAcc 0.5105 0.7900
epoch 1900 LossPred 0.2723 LossAtt 0.5216 TrainAcc 0.9200 TestAcc 0.4945 0.7850
epoch 2000 LossPred 0.8843 LossAtt 0.7505 TrainAcc 0.6900 TestAcc 0.5080 0.6600
epoch 2100 LossPred 0.3336 LossAtt 0.5293 TrainAcc 0.9000 TestAcc 0.5043 0.8100
epoch 2200 LossPred 0.2529 LossAtt 0.5281 TrainAcc 0.9300 TestAcc 0.5025 0.8100
epoch 2300 LossPred 0.2976 LossAtt 0.5248 TrainAcc 0.9000 TestAcc 0.5038 0.7900
epoch 2400 LossPred 0.2498 LossAtt 0.5212 TrainAcc 0.9300 TestAcc 0.5020 0.8050
epoch 2500 LossPred 0.2261 LossAtt 0.5300 TrainAcc 0.9500 TestAcc 0.5025 0.8150
Optimization Finished!
********** replication  67  **********
epoch   0 LossPred 1.0563 LossAtt 1.0180 TrainAcc 0.5000 TestAcc 0.5073 0.4850
epoch 100 LossPred 0.9410 LossAtt 0.5957 TrainAcc 0.5500 TestAcc 0.5703 0.5250
epoch 200 LossPred 0.8502 LossAtt 0.9100 TrainAcc 0.6700 TestAcc 0.5646 0.6500
epoch 300 LossPred 0.4291 LossAtt 1.0227 TrainAcc 0.9300 TestAcc 0.6049 0.8400
epoch 400 LossPred 0.2522 LossAtt 0.8338 TrainAcc 0.9700 TestAcc 0.5993 0.8600
epoch 500 LossPred 0.1690 LossAtt 0.7691 TrainAcc 0.9900 TestAcc 0.5983 0.8800
epoch 600 LossPred 0.3966 LossAtt 0.8120 TrainAcc 0.8900 TestAcc 0.5998 0.8050
epoch 700 LossPred 0.1877 LossAtt 0.7100 TrainAcc 0.9600 TestAcc 0.5891 0.8550
epoch 800 LossPred 0.1351 LossAtt 0.7149 TrainAcc 0.9900 TestAcc 0.6046 0.8850
epoch 900 LossPred 0.3575 LossAtt 0.8198 TrainAcc 0.9000 TestAcc 0.5818 0.8150
epoch 1000 LossPred 0.0905 LossAtt 0.6359 TrainAcc 0.9900 TestAcc 0.6016 0.8750
epoch 1100 LossPred 0.0831 LossAtt 0.6529 TrainAcc 0.9900 TestAcc 0.6044 0.8700
epoch 1200 LossPred 0.0772 LossAtt 0.6421 TrainAcc 0.9900 TestAcc 0.5993 0.8950
epoch 1300 LossPred 0.0706 LossAtt 0.6443 TrainAcc 0.9900 TestAcc 0.6061 0.8700
epoch 1400 LossPred 0.0730 LossAtt 0.6778 TrainAcc 0.9900 TestAcc 0.5966 0.8800
epoch 1500 LossPred 0.1177 LossAtt 0.6269 TrainAcc 0.9800 TestAcc 0.6026 0.8650
epoch 1600 LossPred 0.0822 LossAtt 0.6209 TrainAcc 0.9900 TestAcc 0.5996 0.8750
epoch 1700 LossPred 0.0719 LossAtt 0.6138 TrainAcc 0.9900 TestAcc 0.5943 0.8750
epoch 1800 LossPred 0.0820 LossAtt 0.6156 TrainAcc 0.9800 TestAcc 0.6006 0.8800
epoch 1900 LossPred 0.0339 LossAtt 0.6008 TrainAcc 1.0000 TestAcc 0.6009 0.8950
Optimization Finished!
********** replication  68  **********
epoch   0 LossPred 1.0087 LossAtt 1.0293 TrainAcc 0.4700 TestAcc 0.4980 0.4900
epoch 100 LossPred 0.8057 LossAtt 0.8665 TrainAcc 0.7500 TestAcc 0.6126 0.6950
epoch 200 LossPred 0.5086 LossAtt 1.1213 TrainAcc 0.8400 TestAcc 0.6024 0.8100
epoch 300 LossPred 0.3336 LossAtt 0.8806 TrainAcc 0.8900 TestAcc 0.6789 0.8100
epoch 400 LossPred 0.1903 LossAtt 0.7747 TrainAcc 0.9500 TestAcc 0.6889 0.8300
epoch 500 LossPred 0.1744 LossAtt 0.7599 TrainAcc 0.9400 TestAcc 0.6949 0.8400
epoch 600 LossPred 0.1348 LossAtt 0.7207 TrainAcc 0.9700 TestAcc 0.6962 0.8550
epoch 700 LossPred 0.4830 LossAtt 0.8609 TrainAcc 0.8700 TestAcc 0.6269 0.7850
epoch 800 LossPred 0.1118 LossAtt 0.6856 TrainAcc 0.9600 TestAcc 0.7037 0.8500
epoch 900 LossPred 0.0920 LossAtt 0.6810 TrainAcc 0.9800 TestAcc 0.7047 0.8450
epoch 1000 LossPred 0.0963 LossAtt 0.6818 TrainAcc 0.9800 TestAcc 0.7050 0.8600
epoch 1100 LossPred 0.0986 LossAtt 0.7077 TrainAcc 0.9800 TestAcc 0.7057 0.8550
epoch 1200 LossPred 0.1116 LossAtt 0.6983 TrainAcc 0.9700 TestAcc 0.6722 0.8500
epoch 1300 LossPred 0.0749 LossAtt 0.6614 TrainAcc 0.9800 TestAcc 0.6877 0.8650
epoch 1400 LossPred 0.0696 LossAtt 0.6660 TrainAcc 0.9900 TestAcc 0.6879 0.8450
epoch 1500 LossPred 0.0655 LossAtt 0.6564 TrainAcc 0.9900 TestAcc 0.6877 0.8650
epoch 1600 LossPred 0.0612 LossAtt 0.6654 TrainAcc 0.9900 TestAcc 0.6847 0.8600
epoch 1700 LossPred 0.1073 LossAtt 0.7166 TrainAcc 0.9700 TestAcc 0.6817 0.8550
epoch 1800 LossPred 0.0669 LossAtt 0.6906 TrainAcc 0.9800 TestAcc 0.6844 0.8500
epoch 1900 LossPred 0.0527 LossAtt 0.6456 TrainAcc 0.9900 TestAcc 0.6924 0.8600
epoch 2000 LossPred 0.0458 LossAtt 0.6533 TrainAcc 0.9900 TestAcc 0.6957 0.8600
epoch 2100 LossPred 0.0371 LossAtt 0.6464 TrainAcc 0.9900 TestAcc 0.6924 0.8650
epoch 2200 LossPred 0.0411 LossAtt 0.6682 TrainAcc 0.9900 TestAcc 0.6997 0.8800
epoch 2300 LossPred 0.0354 LossAtt 0.6710 TrainAcc 0.9900 TestAcc 0.6937 0.8550
epoch 2400 LossPred 0.0280 LossAtt 0.6627 TrainAcc 0.9900 TestAcc 0.6839 0.8600
epoch 2500 LossPred 0.0226 LossAtt 0.6586 TrainAcc 1.0000 TestAcc 0.6862 0.8800
Optimization Finished!
********** replication  69  **********
epoch   0 LossPred 0.9923 LossAtt 1.0130 TrainAcc 0.4800 TestAcc 0.5506 0.5250
epoch 100 LossPred 0.7536 LossAtt 0.6372 TrainAcc 0.6700 TestAcc 0.5298 0.6800
epoch 200 LossPred 0.7092 LossAtt 0.7099 TrainAcc 0.7400 TestAcc 0.5435 0.7500
epoch 300 LossPred 0.6640 LossAtt 0.7281 TrainAcc 0.7600 TestAcc 0.5576 0.7550
epoch 400 LossPred 0.3257 LossAtt 1.1426 TrainAcc 0.9400 TestAcc 0.7220 0.9100
epoch 500 LossPred 0.1355 LossAtt 0.7546 TrainAcc 0.9700 TestAcc 0.7643 0.9400
epoch 600 LossPred 0.0739 LossAtt 0.6641 TrainAcc 0.9800 TestAcc 0.7833 0.9500
epoch 700 LossPred 0.1599 LossAtt 0.6714 TrainAcc 0.9600 TestAcc 0.7482 0.9200
epoch 800 LossPred 0.0554 LossAtt 0.6649 TrainAcc 0.9900 TestAcc 0.7610 0.9450
epoch 900 LossPred 0.0380 LossAtt 0.6338 TrainAcc 0.9900 TestAcc 0.7765 0.9500
epoch 1000 LossPred 0.0301 LossAtt 0.6301 TrainAcc 0.9900 TestAcc 0.7788 0.9450
epoch 1100 LossPred 0.0258 LossAtt 0.6363 TrainAcc 1.0000 TestAcc 0.7820 0.9600
Optimization Finished!
********** replication  70  **********
epoch   0 LossPred 1.0640 LossAtt 1.0124 TrainAcc 0.4400 TestAcc 0.4590 0.4350
epoch 100 LossPred 0.8719 LossAtt 0.7265 TrainAcc 0.6500 TestAcc 0.5848 0.6450
epoch 200 LossPred 0.3916 LossAtt 0.5934 TrainAcc 0.8600 TestAcc 0.8171 0.8300
epoch 300 LossPred 0.2383 LossAtt 0.5045 TrainAcc 0.9600 TestAcc 0.8679 0.8700
epoch 400 LossPred 0.1247 LossAtt 0.4613 TrainAcc 0.9700 TestAcc 0.8999 0.8850
epoch 500 LossPred 0.1040 LossAtt 0.4405 TrainAcc 0.9900 TestAcc 0.9062 0.9100
epoch 600 LossPred 0.0842 LossAtt 0.4300 TrainAcc 0.9900 TestAcc 0.9074 0.9150
epoch 700 LossPred 0.2108 LossAtt 0.4203 TrainAcc 0.9200 TestAcc 0.8811 0.8850
epoch 800 LossPred 0.0690 LossAtt 0.4347 TrainAcc 0.9900 TestAcc 0.9084 0.9150
epoch 900 LossPred 0.0780 LossAtt 0.4447 TrainAcc 0.9900 TestAcc 0.9064 0.9300
epoch 1000 LossPred 0.0778 LossAtt 0.4671 TrainAcc 0.9800 TestAcc 0.9027 0.9200
epoch 1100 LossPred 0.0860 LossAtt 0.4393 TrainAcc 0.9600 TestAcc 0.9079 0.9400
epoch 1200 LossPred 0.1042 LossAtt 0.4190 TrainAcc 0.9700 TestAcc 0.9084 0.9050
epoch 1300 LossPred 0.0740 LossAtt 0.4221 TrainAcc 0.9800 TestAcc 0.9079 0.9450
epoch 1400 LossPred 0.0665 LossAtt 0.4458 TrainAcc 0.9900 TestAcc 0.9052 0.9550
epoch 1500 LossPred 0.0870 LossAtt 0.4245 TrainAcc 0.9700 TestAcc 0.9042 0.9450
epoch 1600 LossPred 0.0752 LossAtt 0.4340 TrainAcc 0.9800 TestAcc 0.8924 0.9600
epoch 1700 LossPred 0.0611 LossAtt 0.4584 TrainAcc 0.9900 TestAcc 0.8856 0.9450
epoch 1800 LossPred 0.0433 LossAtt 0.4596 TrainAcc 0.9900 TestAcc 0.8911 0.9600
epoch 1900 LossPred 0.0535 LossAtt 0.4254 TrainAcc 0.9900 TestAcc 0.8846 0.9600
epoch 2000 LossPred 0.0657 LossAtt 0.4553 TrainAcc 0.9800 TestAcc 0.8864 0.9450
epoch 2100 LossPred 0.0535 LossAtt 0.4408 TrainAcc 0.9900 TestAcc 0.8839 0.9550
epoch 2200 LossPred 0.0451 LossAtt 0.4671 TrainAcc 0.9900 TestAcc 0.8886 0.9700
epoch 2300 LossPred 0.0794 LossAtt 0.4163 TrainAcc 0.9700 TestAcc 0.8879 0.9500
epoch 2400 LossPred 0.0417 LossAtt 0.4039 TrainAcc 0.9900 TestAcc 0.8899 0.9700
epoch 2500 LossPred 0.0286 LossAtt 0.3887 TrainAcc 1.0000 TestAcc 0.8844 0.9600
Optimization Finished!
********** replication  71  **********
epoch   0 LossPred 1.0672 LossAtt 1.0019 TrainAcc 0.4800 TestAcc 0.4635 0.5000
epoch 100 LossPred 0.9266 LossAtt 0.7151 TrainAcc 0.6100 TestAcc 0.4987 0.6050
epoch 200 LossPred 0.7795 LossAtt 1.0956 TrainAcc 0.7300 TestAcc 0.4680 0.7000
epoch 300 LossPred 0.5568 LossAtt 1.0546 TrainAcc 0.8500 TestAcc 0.4755 0.7700
epoch 400 LossPred 0.5067 LossAtt 0.8848 TrainAcc 0.8500 TestAcc 0.4792 0.7500
epoch 500 LossPred 0.5930 LossAtt 1.1189 TrainAcc 0.8000 TestAcc 0.4925 0.7450
epoch 600 LossPred 0.4556 LossAtt 0.6832 TrainAcc 0.8800 TestAcc 0.4890 0.7850
epoch 700 LossPred 0.4415 LossAtt 0.6906 TrainAcc 0.8800 TestAcc 0.4975 0.7850
epoch 800 LossPred 0.4314 LossAtt 0.7695 TrainAcc 0.8700 TestAcc 0.4912 0.7800
epoch 900 LossPred 0.3960 LossAtt 0.6813 TrainAcc 0.8700 TestAcc 0.5085 0.7750
epoch 1000 LossPred 0.3437 LossAtt 0.6276 TrainAcc 0.9000 TestAcc 0.4977 0.7900
epoch 1100 LossPred 0.4477 LossAtt 0.8088 TrainAcc 0.8700 TestAcc 0.5163 0.7500
epoch 1200 LossPred 0.2967 LossAtt 0.6482 TrainAcc 0.9100 TestAcc 0.5105 0.8600
epoch 1300 LossPred 0.2511 LossAtt 0.6271 TrainAcc 0.9500 TestAcc 0.5098 0.8500
epoch 1400 LossPred 0.2701 LossAtt 0.7041 TrainAcc 0.9100 TestAcc 0.5200 0.8400
epoch 1500 LossPred 0.2147 LossAtt 0.6184 TrainAcc 0.9500 TestAcc 0.5108 0.8850
epoch 1600 LossPred 0.1819 LossAtt 0.6122 TrainAcc 0.9600 TestAcc 0.5083 0.8850
epoch 1700 LossPred 0.1976 LossAtt 0.6167 TrainAcc 0.9500 TestAcc 0.5143 0.8550
epoch 1800 LossPred 0.1672 LossAtt 0.5982 TrainAcc 0.9700 TestAcc 0.5103 0.8900
epoch 1900 LossPred 0.1615 LossAtt 0.6120 TrainAcc 0.9600 TestAcc 0.5145 0.8950
epoch 2000 LossPred 0.1393 LossAtt 0.5858 TrainAcc 0.9700 TestAcc 0.5135 0.8950
epoch 2100 LossPred 0.3116 LossAtt 0.7504 TrainAcc 0.8900 TestAcc 0.5070 0.8150
epoch 2200 LossPred 0.1334 LossAtt 0.5930 TrainAcc 0.9700 TestAcc 0.5193 0.8900
epoch 2300 LossPred 0.4077 LossAtt 0.6668 TrainAcc 0.8700 TestAcc 0.5180 0.8200
epoch 2400 LossPred 0.2865 LossAtt 0.6555 TrainAcc 0.9300 TestAcc 0.5283 0.8450
epoch 2500 LossPred 0.1013 LossAtt 0.5981 TrainAcc 0.9900 TestAcc 0.5315 0.8900
Optimization Finished!
********** replication  72  **********
epoch   0 LossPred 1.0978 LossAtt 1.0466 TrainAcc 0.4200 TestAcc 0.4222 0.4200
epoch 100 LossPred 0.8843 LossAtt 0.5991 TrainAcc 0.6000 TestAcc 0.5410 0.6100
epoch 200 LossPred 0.8277 LossAtt 0.6718 TrainAcc 0.6600 TestAcc 0.5858 0.6300
epoch 300 LossPred 0.6753 LossAtt 0.9571 TrainAcc 0.7100 TestAcc 0.5263 0.6850
epoch 400 LossPred 0.5301 LossAtt 1.1831 TrainAcc 0.8000 TestAcc 0.5293 0.7300
epoch 500 LossPred 0.4043 LossAtt 0.9955 TrainAcc 0.8800 TestAcc 0.5353 0.7750
epoch 600 LossPred 0.3646 LossAtt 0.9490 TrainAcc 0.9000 TestAcc 0.5308 0.7750
epoch 700 LossPred 0.4276 LossAtt 0.7653 TrainAcc 0.8800 TestAcc 0.5318 0.7850
epoch 800 LossPred 0.3512 LossAtt 0.7378 TrainAcc 0.9300 TestAcc 0.5383 0.8050
epoch 900 LossPred 0.3013 LossAtt 0.7519 TrainAcc 0.9300 TestAcc 0.5353 0.8200
epoch 1000 LossPred 0.2875 LossAtt 0.7849 TrainAcc 0.9100 TestAcc 0.5375 0.8400
epoch 1100 LossPred 0.2568 LossAtt 0.7685 TrainAcc 0.9400 TestAcc 0.5310 0.8150
epoch 1200 LossPred 0.2244 LossAtt 0.7479 TrainAcc 0.9600 TestAcc 0.5350 0.8250
epoch 1300 LossPred 0.2323 LossAtt 0.7699 TrainAcc 0.9400 TestAcc 0.5415 0.8450
epoch 1400 LossPred 0.1948 LossAtt 0.7539 TrainAcc 0.9600 TestAcc 0.5318 0.8500
epoch 1500 LossPred 0.2472 LossAtt 0.8190 TrainAcc 0.9300 TestAcc 0.5390 0.8600
epoch 1600 LossPred 0.1868 LossAtt 0.7070 TrainAcc 0.9500 TestAcc 0.5413 0.8500
epoch 1700 LossPred 0.1634 LossAtt 0.6885 TrainAcc 0.9600 TestAcc 0.5343 0.8650
epoch 1800 LossPred 0.2482 LossAtt 0.8372 TrainAcc 0.9100 TestAcc 0.5438 0.8150
epoch 1900 LossPred 0.1505 LossAtt 0.6843 TrainAcc 0.9600 TestAcc 0.5395 0.8550
epoch 2000 LossPred 0.1386 LossAtt 0.6659 TrainAcc 0.9600 TestAcc 0.5428 0.8700
epoch 2100 LossPred 0.1532 LossAtt 0.6800 TrainAcc 0.9600 TestAcc 0.5450 0.8400
epoch 2200 LossPred 0.1342 LossAtt 0.6800 TrainAcc 0.9700 TestAcc 0.5455 0.8650
epoch 2300 LossPred 0.1226 LossAtt 0.6363 TrainAcc 0.9600 TestAcc 0.5506 0.8450
epoch 2400 LossPred 0.1127 LossAtt 0.6489 TrainAcc 0.9600 TestAcc 0.5493 0.8550
epoch 2500 LossPred 0.1058 LossAtt 0.6504 TrainAcc 0.9700 TestAcc 0.5501 0.8400
Optimization Finished!
********** replication  73  **********
epoch   0 LossPred 0.9638 LossAtt 1.0458 TrainAcc 0.6500 TestAcc 0.5713 0.6450
epoch 100 LossPred 0.8564 LossAtt 0.6002 TrainAcc 0.6500 TestAcc 0.5713 0.6650
epoch 200 LossPred 0.5710 LossAtt 0.4246 TrainAcc 0.8000 TestAcc 0.7588 0.7600
epoch 300 LossPred 0.4177 LossAtt 0.3626 TrainAcc 0.8700 TestAcc 0.8278 0.8150
epoch 400 LossPred 0.4214 LossAtt 0.3183 TrainAcc 0.8600 TestAcc 0.8228 0.8200
epoch 500 LossPred 0.3691 LossAtt 0.3220 TrainAcc 0.9000 TestAcc 0.8268 0.7950
epoch 600 LossPred 0.3503 LossAtt 0.3192 TrainAcc 0.9000 TestAcc 0.8151 0.8000
epoch 700 LossPred 0.3360 LossAtt 0.3052 TrainAcc 0.8900 TestAcc 0.8251 0.8050
epoch 800 LossPred 0.3305 LossAtt 0.3050 TrainAcc 0.9000 TestAcc 0.8241 0.8250
epoch 900 LossPred 0.3215 LossAtt 0.2891 TrainAcc 0.9000 TestAcc 0.8316 0.8200
epoch 1000 LossPred 0.3192 LossAtt 0.2931 TrainAcc 0.9000 TestAcc 0.8211 0.8200
epoch 1100 LossPred 0.3135 LossAtt 0.3425 TrainAcc 0.8900 TestAcc 0.8431 0.8550
epoch 1200 LossPred 0.3074 LossAtt 0.3147 TrainAcc 0.8900 TestAcc 0.8231 0.8500
epoch 1300 LossPred 0.2998 LossAtt 0.3627 TrainAcc 0.9000 TestAcc 0.8271 0.8500
epoch 1400 LossPred 0.2932 LossAtt 0.3540 TrainAcc 0.9200 TestAcc 0.8391 0.8850
epoch 1500 LossPred 0.2864 LossAtt 0.4095 TrainAcc 0.9200 TestAcc 0.8241 0.8650
epoch 1600 LossPred 0.2938 LossAtt 0.3653 TrainAcc 0.9000 TestAcc 0.8343 0.8700
epoch 1700 LossPred 0.2994 LossAtt 0.4332 TrainAcc 0.9000 TestAcc 0.8138 0.8500
epoch 1800 LossPred 0.2663 LossAtt 0.3746 TrainAcc 0.9200 TestAcc 0.8226 0.8800
epoch 1900 LossPred 0.2735 LossAtt 0.4239 TrainAcc 0.9000 TestAcc 0.8326 0.8950
epoch 2000 LossPred 0.2578 LossAtt 0.3237 TrainAcc 0.9300 TestAcc 0.8293 0.8950
epoch 2100 LossPred 0.3592 LossAtt 0.3280 TrainAcc 0.9000 TestAcc 0.8016 0.8550
epoch 2200 LossPred 0.2317 LossAtt 0.3290 TrainAcc 0.9400 TestAcc 0.8251 0.9100
epoch 2300 LossPred 0.2514 LossAtt 0.3487 TrainAcc 0.9200 TestAcc 0.8258 0.9100
epoch 2400 LossPred 0.3729 LossAtt 0.4675 TrainAcc 0.8900 TestAcc 0.8238 0.9050
epoch 2500 LossPred 0.2508 LossAtt 0.3865 TrainAcc 0.9300 TestAcc 0.8216 0.9000
Optimization Finished!
********** replication  74  **********
epoch   0 LossPred 1.0318 LossAtt 1.0708 TrainAcc 0.5800 TestAcc 0.5228 0.5650
epoch 100 LossPred 0.7894 LossAtt 1.1616 TrainAcc 0.6900 TestAcc 0.6234 0.7150
epoch 200 LossPred 0.8825 LossAtt 0.6681 TrainAcc 0.7000 TestAcc 0.6654 0.6650
epoch 300 LossPred 0.5055 LossAtt 0.5843 TrainAcc 0.8400 TestAcc 0.8351 0.8000
epoch 400 LossPred 0.3837 LossAtt 0.5274 TrainAcc 0.8800 TestAcc 0.8411 0.8150
epoch 500 LossPred 0.3192 LossAtt 0.4960 TrainAcc 0.8900 TestAcc 0.8501 0.8350
epoch 600 LossPred 0.2792 LossAtt 0.4898 TrainAcc 0.9200 TestAcc 0.8438 0.8450
epoch 700 LossPred 0.2722 LossAtt 0.4698 TrainAcc 0.9300 TestAcc 0.8411 0.8600
epoch 800 LossPred 0.2409 LossAtt 0.4493 TrainAcc 0.9300 TestAcc 0.8346 0.8550
epoch 900 LossPred 1.5303 LossAtt 0.7290 TrainAcc 0.5400 TestAcc 0.5648 0.5400
epoch 1000 LossPred 0.9029 LossAtt 0.4112 TrainAcc 0.6400 TestAcc 0.5673 0.6550
epoch 1100 LossPred 0.8688 LossAtt 0.4137 TrainAcc 0.6700 TestAcc 0.5761 0.6600
epoch 1200 LossPred 0.7808 LossAtt 0.4501 TrainAcc 0.6800 TestAcc 0.6259 0.6950
epoch 1300 LossPred 0.7733 LossAtt 0.5183 TrainAcc 0.7300 TestAcc 0.6882 0.6950
epoch 1400 LossPred 0.4398 LossAtt 0.4639 TrainAcc 0.8500 TestAcc 0.7858 0.8200
epoch 1500 LossPred 0.3944 LossAtt 0.4143 TrainAcc 0.8700 TestAcc 0.8298 0.8350
epoch 1600 LossPred 0.5525 LossAtt 0.4148 TrainAcc 0.8100 TestAcc 0.7698 0.8100
epoch 1700 LossPred 0.4266 LossAtt 0.4252 TrainAcc 0.8700 TestAcc 0.7913 0.8200
epoch 1800 LossPred 0.3296 LossAtt 0.4050 TrainAcc 0.9100 TestAcc 0.8303 0.8300
epoch 1900 LossPred 0.3505 LossAtt 0.3975 TrainAcc 0.8900 TestAcc 0.8406 0.8400
epoch 2000 LossPred 0.3703 LossAtt 0.4056 TrainAcc 0.8800 TestAcc 0.8101 0.8500
epoch 2100 LossPred 0.6740 LossAtt 0.4160 TrainAcc 0.7700 TestAcc 0.7280 0.7850
epoch 2200 LossPred 0.4836 LossAtt 0.5351 TrainAcc 0.8100 TestAcc 0.7287 0.8150
epoch 2300 LossPred 0.3582 LossAtt 0.3727 TrainAcc 0.9000 TestAcc 0.8303 0.8400
epoch 2400 LossPred 0.5648 LossAtt 0.3624 TrainAcc 0.7900 TestAcc 0.6484 0.7700
epoch 2500 LossPred 0.4712 LossAtt 0.3595 TrainAcc 0.8500 TestAcc 0.7487 0.8550
Optimization Finished!
********** replication  75  **********
epoch   0 LossPred 1.0399 LossAtt 1.0513 TrainAcc 0.4600 TestAcc 0.4467 0.4350
epoch 100 LossPred 0.7420 LossAtt 1.1524 TrainAcc 0.7500 TestAcc 0.6909 0.7400
epoch 200 LossPred 0.4876 LossAtt 0.5843 TrainAcc 0.8300 TestAcc 0.8208 0.8000
epoch 300 LossPred 0.3471 LossAtt 0.4655 TrainAcc 0.8900 TestAcc 0.8551 0.8500
epoch 400 LossPred 0.3002 LossAtt 0.4294 TrainAcc 0.9200 TestAcc 0.8646 0.8700
epoch 500 LossPred 0.2597 LossAtt 0.4182 TrainAcc 0.9200 TestAcc 0.8751 0.8850
epoch 600 LossPred 0.4394 LossAtt 0.4341 TrainAcc 0.8500 TestAcc 0.8296 0.8450
epoch 700 LossPred 0.1644 LossAtt 0.4449 TrainAcc 0.9500 TestAcc 0.8931 0.9200
epoch 800 LossPred 0.1775 LossAtt 0.4378 TrainAcc 0.9600 TestAcc 0.8841 0.9000
epoch 900 LossPred 0.2348 LossAtt 0.4210 TrainAcc 0.9400 TestAcc 0.8834 0.9050
epoch 1000 LossPred 0.1585 LossAtt 0.4149 TrainAcc 0.9700 TestAcc 0.8829 0.9050
epoch 1100 LossPred 0.2051 LossAtt 0.4136 TrainAcc 0.9500 TestAcc 0.8651 0.8950
epoch 1200 LossPred 0.4136 LossAtt 0.4292 TrainAcc 0.8700 TestAcc 0.8331 0.8350
epoch 1300 LossPred 0.3264 LossAtt 0.4018 TrainAcc 0.9200 TestAcc 0.8551 0.8900
epoch 1400 LossPred 0.1448 LossAtt 0.3850 TrainAcc 0.9600 TestAcc 0.8721 0.9300
epoch 1500 LossPred 0.1535 LossAtt 0.4779 TrainAcc 0.9700 TestAcc 0.8719 0.9200
epoch 1600 LossPred 0.3143 LossAtt 0.4139 TrainAcc 0.9000 TestAcc 0.8488 0.8950
epoch 1700 LossPred 0.1177 LossAtt 0.3936 TrainAcc 0.9700 TestAcc 0.8674 0.9350
epoch 1800 LossPred 0.1378 LossAtt 0.3816 TrainAcc 0.9800 TestAcc 0.8686 0.9300
epoch 1900 LossPred 0.1386 LossAtt 0.3777 TrainAcc 0.9500 TestAcc 0.8581 0.9150
epoch 2000 LossPred 0.1702 LossAtt 0.3861 TrainAcc 0.9500 TestAcc 0.8714 0.9150
epoch 2100 LossPred 0.1260 LossAtt 0.3660 TrainAcc 0.9600 TestAcc 0.8631 0.9300
epoch 2200 LossPred 0.1037 LossAtt 0.3686 TrainAcc 0.9800 TestAcc 0.8606 0.9100
epoch 2300 LossPred 0.1040 LossAtt 0.3933 TrainAcc 0.9800 TestAcc 0.8594 0.9100
epoch 2400 LossPred 0.4739 LossAtt 0.4228 TrainAcc 0.8700 TestAcc 0.8261 0.8600
epoch 2500 LossPred 0.5523 LossAtt 0.3962 TrainAcc 0.8600 TestAcc 0.8068 0.8650
Optimization Finished!
********** replication  76  **********
epoch   0 LossPred 1.1227 LossAtt 1.0988 TrainAcc 0.5600 TestAcc 0.4807 0.5600
epoch 100 LossPred 0.8615 LossAtt 0.8785 TrainAcc 0.6600 TestAcc 0.5200 0.6600
epoch 200 LossPred 0.5748 LossAtt 1.0614 TrainAcc 0.7900 TestAcc 0.7165 0.7650
epoch 300 LossPred 0.4715 LossAtt 0.7199 TrainAcc 0.8600 TestAcc 0.7815 0.8500
epoch 400 LossPred 0.1310 LossAtt 0.5828 TrainAcc 0.9900 TestAcc 0.8629 0.8950
epoch 500 LossPred 0.1694 LossAtt 0.5303 TrainAcc 0.9700 TestAcc 0.8669 0.9200
epoch 600 LossPred 0.0885 LossAtt 0.5085 TrainAcc 0.9900 TestAcc 0.8626 0.9100
epoch 700 LossPred 0.0847 LossAtt 0.5023 TrainAcc 0.9900 TestAcc 0.8621 0.8950
epoch 800 LossPred 0.0784 LossAtt 0.4997 TrainAcc 0.9900 TestAcc 0.8636 0.9000
epoch 900 LossPred 0.0781 LossAtt 0.4770 TrainAcc 0.9800 TestAcc 0.8596 0.9000
epoch 1000 LossPred 0.0915 LossAtt 0.4728 TrainAcc 0.9800 TestAcc 0.8566 0.9100
epoch 1100 LossPred 0.0937 LossAtt 0.4907 TrainAcc 0.9800 TestAcc 0.8559 0.9050
epoch 1200 LossPred 0.0797 LossAtt 0.4653 TrainAcc 0.9900 TestAcc 0.8609 0.9050
epoch 1300 LossPred 0.0811 LossAtt 0.4579 TrainAcc 0.9900 TestAcc 0.8626 0.9000
epoch 1400 LossPred 0.0991 LossAtt 0.4334 TrainAcc 0.9800 TestAcc 0.8614 0.9050
epoch 1500 LossPred 0.0800 LossAtt 0.4409 TrainAcc 0.9900 TestAcc 0.8611 0.9200
epoch 1600 LossPred 0.1064 LossAtt 0.4327 TrainAcc 0.9600 TestAcc 0.8604 0.9100
epoch 1700 LossPred 0.0696 LossAtt 0.4342 TrainAcc 0.9900 TestAcc 0.8641 0.9200
epoch 1800 LossPred 0.0606 LossAtt 0.4359 TrainAcc 0.9900 TestAcc 0.8679 0.9250
epoch 1900 LossPred 0.0524 LossAtt 0.4210 TrainAcc 0.9900 TestAcc 0.8691 0.9250
epoch 2000 LossPred 0.0521 LossAtt 0.4345 TrainAcc 0.9900 TestAcc 0.8671 0.9300
epoch 2100 LossPred 0.1089 LossAtt 0.4317 TrainAcc 0.9800 TestAcc 0.8569 0.9300
epoch 2200 LossPred 0.0508 LossAtt 0.3990 TrainAcc 0.9900 TestAcc 0.8569 0.9350
epoch 2300 LossPred 0.0459 LossAtt 0.3956 TrainAcc 0.9900 TestAcc 0.8616 0.9400
epoch 2400 LossPred 0.0463 LossAtt 0.3843 TrainAcc 0.9900 TestAcc 0.8616 0.9400
epoch 2500 LossPred 0.0466 LossAtt 0.3873 TrainAcc 0.9900 TestAcc 0.8614 0.9450
Optimization Finished!
********** replication  77  **********
epoch   0 LossPred 1.1190 LossAtt 1.0341 TrainAcc 0.3900 TestAcc 0.4249 0.3900
epoch 100 LossPred 0.8191 LossAtt 0.6439 TrainAcc 0.7000 TestAcc 0.6096 0.6850
epoch 200 LossPred 0.4170 LossAtt 0.5883 TrainAcc 0.8800 TestAcc 0.8271 0.8500
epoch 300 LossPred 0.2722 LossAtt 0.5285 TrainAcc 0.9100 TestAcc 0.8373 0.8950
epoch 400 LossPred 0.1612 LossAtt 0.5234 TrainAcc 0.9700 TestAcc 0.8511 0.9200
epoch 500 LossPred 0.1584 LossAtt 0.4863 TrainAcc 0.9700 TestAcc 0.8536 0.9150
epoch 600 LossPred 0.1355 LossAtt 0.4691 TrainAcc 0.9600 TestAcc 0.8526 0.9250
epoch 700 LossPred 0.1558 LossAtt 0.4536 TrainAcc 0.9400 TestAcc 0.8516 0.9100
epoch 800 LossPred 0.1249 LossAtt 0.4654 TrainAcc 0.9600 TestAcc 0.8586 0.9300
epoch 900 LossPred 0.2212 LossAtt 0.4804 TrainAcc 0.9400 TestAcc 0.8163 0.8600
epoch 1000 LossPred 0.1420 LossAtt 0.4016 TrainAcc 0.9700 TestAcc 0.8328 0.8800
epoch 1100 LossPred 0.1036 LossAtt 0.4015 TrainAcc 0.9700 TestAcc 0.8541 0.9150
epoch 1200 LossPred 0.1479 LossAtt 0.4003 TrainAcc 0.9600 TestAcc 0.8596 0.9150
epoch 1300 LossPred 0.1420 LossAtt 0.4235 TrainAcc 0.9700 TestAcc 0.8416 0.9100
epoch 1400 LossPred 0.1260 LossAtt 0.3621 TrainAcc 0.9700 TestAcc 0.8346 0.8850
epoch 1500 LossPred 0.1686 LossAtt 0.3703 TrainAcc 0.9400 TestAcc 0.8574 0.9150
epoch 1600 LossPred 0.0860 LossAtt 0.3616 TrainAcc 0.9800 TestAcc 0.8491 0.9400
epoch 1700 LossPred 0.2922 LossAtt 0.3664 TrainAcc 0.9000 TestAcc 0.8504 0.9100
epoch 1800 LossPred 0.1079 LossAtt 0.3497 TrainAcc 0.9700 TestAcc 0.8426 0.9450
epoch 1900 LossPred 0.1439 LossAtt 0.3380 TrainAcc 0.9600 TestAcc 0.8286 0.9150
epoch 2000 LossPred 0.1710 LossAtt 0.3484 TrainAcc 0.9400 TestAcc 0.8614 0.9100
epoch 2100 LossPred 0.1074 LossAtt 0.3615 TrainAcc 0.9800 TestAcc 0.8584 0.9500
epoch 2200 LossPred 0.1042 LossAtt 0.3328 TrainAcc 0.9700 TestAcc 0.8441 0.9400
epoch 2300 LossPred 0.0800 LossAtt 0.3416 TrainAcc 0.9800 TestAcc 0.8549 0.9600
epoch 2400 LossPred 0.1101 LossAtt 0.3440 TrainAcc 0.9800 TestAcc 0.8596 0.9450
epoch 2500 LossPred 0.1514 LossAtt 0.3310 TrainAcc 0.9600 TestAcc 0.8228 0.9450
Optimization Finished!
********** replication  78  **********
epoch   0 LossPred 1.2641 LossAtt 1.0183 TrainAcc 0.4100 TestAcc 0.4942 0.4800
epoch 100 LossPred 0.8142 LossAtt 0.4519 TrainAcc 0.6700 TestAcc 0.5658 0.6700
epoch 200 LossPred 0.5486 LossAtt 0.5787 TrainAcc 0.8100 TestAcc 0.7357 0.8200
epoch 300 LossPred 0.5513 LossAtt 0.5703 TrainAcc 0.7900 TestAcc 0.7217 0.8350
epoch 400 LossPred 0.7874 LossAtt 0.3171 TrainAcc 0.7100 TestAcc 0.6271 0.7100
epoch 500 LossPred 0.4087 LossAtt 0.3431 TrainAcc 0.8800 TestAcc 0.7850 0.8550
epoch 600 LossPred 0.4764 LossAtt 0.3032 TrainAcc 0.8500 TestAcc 0.7355 0.8050
epoch 700 LossPred 0.2408 LossAtt 0.2882 TrainAcc 0.9500 TestAcc 0.8614 0.9100
epoch 800 LossPred 0.2012 LossAtt 0.2711 TrainAcc 0.9500 TestAcc 0.8646 0.8800
epoch 900 LossPred 0.3261 LossAtt 0.2943 TrainAcc 0.8900 TestAcc 0.8559 0.8950
epoch 1000 LossPred 0.2404 LossAtt 0.2937 TrainAcc 0.9200 TestAcc 0.8664 0.8950
epoch 1100 LossPred 0.1762 LossAtt 0.2816 TrainAcc 0.9500 TestAcc 0.8541 0.9200
epoch 1200 LossPred 0.1744 LossAtt 0.2793 TrainAcc 0.9400 TestAcc 0.8646 0.9050
epoch 1300 LossPred 0.1571 LossAtt 0.2738 TrainAcc 0.9600 TestAcc 0.8531 0.8800
epoch 1400 LossPred 0.1557 LossAtt 0.2727 TrainAcc 0.9500 TestAcc 0.8571 0.9000
epoch 1500 LossPred 0.2724 LossAtt 0.2756 TrainAcc 0.9000 TestAcc 0.8529 0.8800
epoch 1600 LossPred 0.1493 LossAtt 0.2595 TrainAcc 0.9500 TestAcc 0.8526 0.8950
epoch 1700 LossPred 0.2754 LossAtt 0.3810 TrainAcc 0.9300 TestAcc 0.8458 0.8950
epoch 1800 LossPred 0.1533 LossAtt 0.2632 TrainAcc 0.9700 TestAcc 0.8498 0.8800
epoch 1900 LossPred 0.4475 LossAtt 0.2595 TrainAcc 0.8800 TestAcc 0.7598 0.8250
epoch 2000 LossPred 0.1612 LossAtt 0.2727 TrainAcc 0.9500 TestAcc 0.8326 0.8850
epoch 2100 LossPred 0.1498 LossAtt 0.2562 TrainAcc 0.9700 TestAcc 0.8416 0.8900
epoch 2200 LossPred 0.1393 LossAtt 0.2434 TrainAcc 0.9700 TestAcc 0.8476 0.8900
epoch 2300 LossPred 0.1368 LossAtt 0.2305 TrainAcc 0.9700 TestAcc 0.8413 0.8950
epoch 2400 LossPred 0.2716 LossAtt 0.2534 TrainAcc 0.9200 TestAcc 0.8363 0.8650
epoch 2500 LossPred 0.1383 LossAtt 0.2330 TrainAcc 0.9700 TestAcc 0.8428 0.9000
Optimization Finished!
********** replication  79  **********
epoch   0 LossPred 1.2619 LossAtt 1.0357 TrainAcc 0.4300 TestAcc 0.4785 0.4500
epoch 100 LossPred 0.9041 LossAtt 0.7212 TrainAcc 0.6700 TestAcc 0.5898 0.6700
epoch 200 LossPred 0.3603 LossAtt 0.6954 TrainAcc 0.9200 TestAcc 0.8386 0.8800
epoch 300 LossPred 0.1864 LossAtt 0.5824 TrainAcc 0.9600 TestAcc 0.8291 0.8800
epoch 400 LossPred 0.1260 LossAtt 0.5193 TrainAcc 0.9700 TestAcc 0.8458 0.8700
epoch 500 LossPred 0.1753 LossAtt 0.5502 TrainAcc 0.9500 TestAcc 0.8463 0.8800
epoch 600 LossPred 0.1081 LossAtt 0.5188 TrainAcc 0.9900 TestAcc 0.8463 0.8950
epoch 700 LossPred 0.0942 LossAtt 0.4937 TrainAcc 0.9800 TestAcc 0.8426 0.8900
epoch 800 LossPred 0.0873 LossAtt 0.5134 TrainAcc 1.0000 TestAcc 0.8443 0.9050
Optimization Finished!
********** replication  80  **********
epoch   0 LossPred 1.2401 LossAtt 1.0356 TrainAcc 0.4500 TestAcc 0.4597 0.4850
epoch 100 LossPred 0.8841 LossAtt 0.7289 TrainAcc 0.6700 TestAcc 0.5203 0.6750
epoch 200 LossPred 0.8697 LossAtt 0.4968 TrainAcc 0.6600 TestAcc 0.5373 0.6800
epoch 300 LossPred 0.8516 LossAtt 0.6885 TrainAcc 0.6700 TestAcc 0.5218 0.6800
epoch 400 LossPred 0.8045 LossAtt 0.6896 TrainAcc 0.6800 TestAcc 0.5225 0.6950
epoch 500 LossPred 0.7842 LossAtt 0.5794 TrainAcc 0.7000 TestAcc 0.5290 0.7000
epoch 600 LossPred 0.7603 LossAtt 1.0554 TrainAcc 0.7200 TestAcc 0.5325 0.7000
epoch 700 LossPred 0.7297 LossAtt 0.6372 TrainAcc 0.7400 TestAcc 0.5375 0.7100
epoch 800 LossPred 0.7270 LossAtt 0.9079 TrainAcc 0.7500 TestAcc 0.5410 0.7400
epoch 900 LossPred 0.6866 LossAtt 0.5743 TrainAcc 0.7500 TestAcc 0.5415 0.7250
epoch 1000 LossPred 0.6779 LossAtt 0.6370 TrainAcc 0.7500 TestAcc 0.5440 0.7300
epoch 1100 LossPred 0.6699 LossAtt 0.6169 TrainAcc 0.7500 TestAcc 0.5418 0.7300
epoch 1200 LossPred 0.6645 LossAtt 0.6289 TrainAcc 0.7500 TestAcc 0.5440 0.7200
epoch 1300 LossPred 0.6651 LossAtt 0.7683 TrainAcc 0.7600 TestAcc 0.5503 0.7350
epoch 1400 LossPred 0.6299 LossAtt 0.7051 TrainAcc 0.7600 TestAcc 0.5410 0.7250
epoch 1500 LossPred 0.5526 LossAtt 0.8751 TrainAcc 0.8100 TestAcc 0.5691 0.7500
epoch 1600 LossPred 0.7255 LossAtt 1.2794 TrainAcc 0.7400 TestAcc 0.5751 0.7300
epoch 1700 LossPred 0.5905 LossAtt 0.6738 TrainAcc 0.7700 TestAcc 0.6051 0.7650
epoch 1800 LossPred 0.4723 LossAtt 0.6330 TrainAcc 0.8400 TestAcc 0.6512 0.8050
epoch 1900 LossPred 0.9993 LossAtt 0.8787 TrainAcc 0.6100 TestAcc 0.6019 0.6500
epoch 2000 LossPred 0.3778 LossAtt 0.7243 TrainAcc 0.9000 TestAcc 0.7017 0.8500
epoch 2100 LossPred 0.3084 LossAtt 0.5947 TrainAcc 0.9200 TestAcc 0.7427 0.8600
epoch 2200 LossPred 0.2705 LossAtt 0.6133 TrainAcc 0.9200 TestAcc 0.7465 0.8600
epoch 2300 LossPred 0.5096 LossAtt 1.4352 TrainAcc 0.8400 TestAcc 0.6341 0.8350
epoch 2400 LossPred 1.5604 LossAtt 1.2939 TrainAcc 0.4700 TestAcc 0.4199 0.4700
epoch 2500 LossPred 0.8875 LossAtt 0.5208 TrainAcc 0.6600 TestAcc 0.5128 0.6700
Optimization Finished!
********** replication  81  **********
epoch   0 LossPred 1.1175 LossAtt 1.0376 TrainAcc 0.3800 TestAcc 0.4427 0.3850
epoch 100 LossPred 0.8577 LossAtt 0.6960 TrainAcc 0.6500 TestAcc 0.5596 0.6400
epoch 200 LossPred 0.4374 LossAtt 0.5373 TrainAcc 0.9000 TestAcc 0.8326 0.8100
epoch 300 LossPred 0.3100 LossAtt 0.4673 TrainAcc 0.9500 TestAcc 0.8699 0.8700
epoch 400 LossPred 0.4126 LossAtt 0.5910 TrainAcc 0.8600 TestAcc 0.8233 0.7900
epoch 500 LossPred 0.2266 LossAtt 0.4073 TrainAcc 0.9500 TestAcc 0.8791 0.8850
epoch 600 LossPred 0.2342 LossAtt 0.4034 TrainAcc 0.9400 TestAcc 0.8791 0.8850
epoch 700 LossPred 0.1909 LossAtt 0.3797 TrainAcc 0.9500 TestAcc 0.8799 0.8850
epoch 800 LossPred 1.2561 LossAtt 0.3991 TrainAcc 0.6200 TestAcc 0.5573 0.6200
epoch 900 LossPred 0.8598 LossAtt 0.3675 TrainAcc 0.7000 TestAcc 0.6321 0.6700
epoch 1000 LossPred 0.2235 LossAtt 0.3562 TrainAcc 0.9500 TestAcc 0.8836 0.8950
epoch 1100 LossPred 0.1923 LossAtt 0.3444 TrainAcc 0.9500 TestAcc 0.8889 0.9100
epoch 1200 LossPred 0.2167 LossAtt 0.3502 TrainAcc 0.9400 TestAcc 0.8776 0.8750
epoch 1300 LossPred 0.1932 LossAtt 0.3301 TrainAcc 0.9400 TestAcc 0.8939 0.9200
epoch 1400 LossPred 0.1885 LossAtt 0.3183 TrainAcc 0.9600 TestAcc 0.9009 0.9050
epoch 1500 LossPred 0.7149 LossAtt 0.3633 TrainAcc 0.7400 TestAcc 0.7523 0.7250
epoch 1600 LossPred 0.1714 LossAtt 0.3262 TrainAcc 0.9700 TestAcc 0.8839 0.9100
epoch 1700 LossPred 0.2384 LossAtt 0.3606 TrainAcc 0.9200 TestAcc 0.8766 0.8950
epoch 1800 LossPred 0.1774 LossAtt 0.3185 TrainAcc 0.9700 TestAcc 0.8879 0.9100
epoch 1900 LossPred 0.1698 LossAtt 0.3133 TrainAcc 0.9600 TestAcc 0.9004 0.9100
epoch 2000 LossPred 0.7337 LossAtt 0.3526 TrainAcc 0.7600 TestAcc 0.7600 0.7350
epoch 2100 LossPred 0.3068 LossAtt 0.3153 TrainAcc 0.9100 TestAcc 0.8909 0.8900
epoch 2200 LossPred 0.2810 LossAtt 0.3908 TrainAcc 0.9200 TestAcc 0.8929 0.9000
epoch 2300 LossPred 0.1490 LossAtt 0.3360 TrainAcc 0.9700 TestAcc 0.9062 0.9400
epoch 2400 LossPred 0.7501 LossAtt 0.3660 TrainAcc 0.7900 TestAcc 0.7470 0.7750
epoch 2500 LossPred 0.4621 LossAtt 0.3849 TrainAcc 0.8500 TestAcc 0.8298 0.8450
Optimization Finished!
********** replication  82  **********
epoch   0 LossPred 1.0539 LossAtt 1.0295 TrainAcc 0.4500 TestAcc 0.5118 0.4350
epoch 100 LossPred 0.7239 LossAtt 0.7353 TrainAcc 0.7500 TestAcc 0.6974 0.7200
epoch 200 LossPred 0.3715 LossAtt 0.4998 TrainAcc 0.9000 TestAcc 0.8418 0.8300
epoch 300 LossPred 0.2969 LossAtt 0.4220 TrainAcc 0.9300 TestAcc 0.8581 0.8500
epoch 400 LossPred 0.2293 LossAtt 0.4163 TrainAcc 0.9600 TestAcc 0.8779 0.8700
epoch 500 LossPred 0.2057 LossAtt 0.4227 TrainAcc 0.9500 TestAcc 0.8834 0.8800
epoch 600 LossPred 0.2545 LossAtt 0.4100 TrainAcc 0.9300 TestAcc 0.8699 0.8750
epoch 700 LossPred 0.1211 LossAtt 0.4080 TrainAcc 0.9800 TestAcc 0.8794 0.8950
epoch 800 LossPred 0.1945 LossAtt 0.3870 TrainAcc 0.9300 TestAcc 0.8631 0.8900
epoch 900 LossPred 0.1561 LossAtt 0.3845 TrainAcc 0.9700 TestAcc 0.8726 0.8900
epoch 1000 LossPred 0.1268 LossAtt 0.3622 TrainAcc 0.9700 TestAcc 0.8699 0.9000
epoch 1100 LossPred 0.1154 LossAtt 0.3517 TrainAcc 0.9700 TestAcc 0.8734 0.9000
epoch 1200 LossPred 0.1197 LossAtt 0.3821 TrainAcc 0.9500 TestAcc 0.8774 0.9000
epoch 1300 LossPred 0.1526 LossAtt 0.3515 TrainAcc 0.9700 TestAcc 0.8664 0.9150
epoch 1400 LossPred 0.2178 LossAtt 0.3611 TrainAcc 0.9300 TestAcc 0.8626 0.8900
epoch 1500 LossPred 0.1845 LossAtt 0.3413 TrainAcc 0.9500 TestAcc 0.8709 0.9100
epoch 1600 LossPred 0.1797 LossAtt 0.3360 TrainAcc 0.9500 TestAcc 0.8649 0.9150
epoch 1700 LossPred 0.1229 LossAtt 0.3213 TrainAcc 0.9800 TestAcc 0.8669 0.9000
epoch 1800 LossPred 0.1725 LossAtt 0.3273 TrainAcc 0.9400 TestAcc 0.8684 0.9350
epoch 1900 LossPred 0.1128 LossAtt 0.3431 TrainAcc 0.9600 TestAcc 0.8766 0.9150
epoch 2000 LossPred 0.1645 LossAtt 0.3076 TrainAcc 0.9500 TestAcc 0.8574 0.9200
epoch 2100 LossPred 0.1338 LossAtt 0.3378 TrainAcc 0.9600 TestAcc 0.8649 0.9250
epoch 2200 LossPred 0.1929 LossAtt 0.3072 TrainAcc 0.9500 TestAcc 0.8551 0.9250
epoch 2300 LossPred 0.1083 LossAtt 0.3187 TrainAcc 0.9600 TestAcc 0.8721 0.9350
epoch 2400 LossPred 0.1195 LossAtt 0.3206 TrainAcc 0.9600 TestAcc 0.8674 0.9300
epoch 2500 LossPred 0.1461 LossAtt 0.2857 TrainAcc 0.9600 TestAcc 0.8544 0.9300
Optimization Finished!
********** replication  83  **********
epoch   0 LossPred 1.0110 LossAtt 1.0415 TrainAcc 0.4900 TestAcc 0.4695 0.5200
epoch 100 LossPred 0.6711 LossAtt 0.8000 TrainAcc 0.7900 TestAcc 0.7322 0.7350
epoch 200 LossPred 0.2727 LossAtt 0.4955 TrainAcc 0.9100 TestAcc 0.8346 0.8900
epoch 300 LossPred 0.1529 LossAtt 0.4565 TrainAcc 0.9600 TestAcc 0.8413 0.8950
epoch 400 LossPred 0.0984 LossAtt 0.4626 TrainAcc 0.9800 TestAcc 0.8396 0.9100
epoch 500 LossPred 0.0775 LossAtt 0.4678 TrainAcc 0.9800 TestAcc 0.8388 0.9050
epoch 600 LossPred 0.0857 LossAtt 0.4483 TrainAcc 0.9700 TestAcc 0.8346 0.8900
epoch 700 LossPred 0.0596 LossAtt 0.4292 TrainAcc 0.9800 TestAcc 0.8328 0.9200
epoch 800 LossPred 0.0520 LossAtt 0.4252 TrainAcc 0.9800 TestAcc 0.8278 0.9050
epoch 900 LossPred 0.0523 LossAtt 0.4391 TrainAcc 0.9900 TestAcc 0.8306 0.9150
epoch 1000 LossPred 0.3175 LossAtt 0.4175 TrainAcc 0.9000 TestAcc 0.7903 0.8350
epoch 1100 LossPred 0.0417 LossAtt 0.3901 TrainAcc 0.9800 TestAcc 0.8291 0.9100
epoch 1200 LossPred 0.0370 LossAtt 0.3918 TrainAcc 0.9900 TestAcc 0.8301 0.9250
epoch 1300 LossPred 0.0433 LossAtt 0.3959 TrainAcc 0.9800 TestAcc 0.8333 0.8950
epoch 1400 LossPred 0.0604 LossAtt 0.3970 TrainAcc 0.9700 TestAcc 0.8371 0.9050
epoch 1500 LossPred 0.0361 LossAtt 0.4173 TrainAcc 0.9900 TestAcc 0.8323 0.9250
epoch 1600 LossPred 0.0287 LossAtt 0.3892 TrainAcc 0.9900 TestAcc 0.8291 0.9050
epoch 1700 LossPred 0.0862 LossAtt 0.3929 TrainAcc 0.9800 TestAcc 0.8148 0.9050
epoch 1800 LossPred 0.0999 LossAtt 0.3866 TrainAcc 0.9700 TestAcc 0.8251 0.8950
epoch 1900 LossPred 0.2143 LossAtt 0.4159 TrainAcc 0.9400 TestAcc 0.8241 0.9150
epoch 2000 LossPred 0.0941 LossAtt 0.3841 TrainAcc 0.9700 TestAcc 0.8343 0.9350
epoch 2100 LossPred 0.0448 LossAtt 0.3778 TrainAcc 0.9900 TestAcc 0.8413 0.9450
epoch 2200 LossPred 0.0217 LossAtt 0.3802 TrainAcc 0.9900 TestAcc 0.8326 0.9250
epoch 2300 LossPred 0.0281 LossAtt 0.3855 TrainAcc 1.0000 TestAcc 0.8358 0.9250
Optimization Finished!
********** replication  84  **********
epoch   0 LossPred 0.9988 LossAtt 1.0316 TrainAcc 0.5600 TestAcc 0.4950 0.5700
epoch 100 LossPred 0.8091 LossAtt 0.6609 TrainAcc 0.6800 TestAcc 0.5703 0.6800
epoch 200 LossPred 0.4803 LossAtt 0.5965 TrainAcc 0.8500 TestAcc 0.8161 0.8200
epoch 300 LossPred 0.3341 LossAtt 0.5291 TrainAcc 0.9000 TestAcc 0.8066 0.8800
epoch 400 LossPred 0.3060 LossAtt 0.5136 TrainAcc 0.8900 TestAcc 0.8406 0.8300
epoch 500 LossPred 0.2537 LossAtt 0.4956 TrainAcc 0.9400 TestAcc 0.8391 0.8650
epoch 600 LossPred 0.2487 LossAtt 0.5422 TrainAcc 0.9300 TestAcc 0.8211 0.8600
epoch 700 LossPred 0.2736 LossAtt 0.4513 TrainAcc 0.9200 TestAcc 0.8186 0.8750
epoch 800 LossPred 0.2857 LossAtt 0.4455 TrainAcc 0.9000 TestAcc 0.8443 0.8650
epoch 900 LossPred 0.2545 LossAtt 0.4216 TrainAcc 0.9100 TestAcc 0.8103 0.8600
epoch 1000 LossPred 0.2191 LossAtt 0.4423 TrainAcc 0.9400 TestAcc 0.8153 0.8650
epoch 1100 LossPred 0.2174 LossAtt 0.4195 TrainAcc 0.9300 TestAcc 0.8078 0.8750
epoch 1200 LossPred 0.2223 LossAtt 0.4983 TrainAcc 0.9400 TestAcc 0.8201 0.8700
epoch 1300 LossPred 0.1958 LossAtt 0.4208 TrainAcc 0.9400 TestAcc 0.8266 0.8650
epoch 1400 LossPred 0.1946 LossAtt 0.4171 TrainAcc 0.9400 TestAcc 0.8208 0.8750
epoch 1500 LossPred 0.2631 LossAtt 0.4166 TrainAcc 0.8900 TestAcc 0.7978 0.8800
epoch 1600 LossPred 0.1870 LossAtt 0.4754 TrainAcc 0.9400 TestAcc 0.8326 0.8950
epoch 1700 LossPred 0.1951 LossAtt 0.4505 TrainAcc 0.9400 TestAcc 0.7923 0.8850
epoch 1800 LossPred 0.1417 LossAtt 0.4371 TrainAcc 0.9500 TestAcc 0.8258 0.9100
epoch 1900 LossPred 0.1155 LossAtt 0.4421 TrainAcc 0.9600 TestAcc 0.8461 0.9300
epoch 2000 LossPred 0.0994 LossAtt 0.4518 TrainAcc 0.9700 TestAcc 0.8486 0.9400
epoch 2100 LossPred 0.0966 LossAtt 0.4621 TrainAcc 0.9900 TestAcc 0.8586 0.9450
epoch 2200 LossPred 0.0964 LossAtt 0.4654 TrainAcc 0.9800 TestAcc 0.8654 0.9200
epoch 2300 LossPred 0.1584 LossAtt 0.4429 TrainAcc 0.9600 TestAcc 0.8596 0.8750
epoch 2400 LossPred 0.1809 LossAtt 0.4507 TrainAcc 0.9300 TestAcc 0.8641 0.8650
epoch 2500 LossPred 0.1048 LossAtt 0.4356 TrainAcc 0.9700 TestAcc 0.8586 0.9350
Optimization Finished!
********** replication  85  **********
epoch   0 LossPred 1.0370 LossAtt 1.0231 TrainAcc 0.5400 TestAcc 0.5348 0.4850
epoch 100 LossPred 0.8266 LossAtt 0.6572 TrainAcc 0.6300 TestAcc 0.5315 0.6300
epoch 200 LossPred 0.6539 LossAtt 0.9800 TrainAcc 0.7800 TestAcc 0.5190 0.7450
epoch 300 LossPred 0.4672 LossAtt 1.3696 TrainAcc 0.8600 TestAcc 0.5333 0.7950
epoch 400 LossPred 0.3073 LossAtt 0.9131 TrainAcc 0.9400 TestAcc 0.5423 0.8400
epoch 500 LossPred 0.2462 LossAtt 0.9150 TrainAcc 0.9500 TestAcc 0.5631 0.8600
epoch 600 LossPred 0.2364 LossAtt 0.8393 TrainAcc 0.9400 TestAcc 0.5591 0.8800
epoch 700 LossPred 0.1778 LossAtt 0.7157 TrainAcc 0.9600 TestAcc 0.5703 0.8900
epoch 800 LossPred 0.1508 LossAtt 0.7085 TrainAcc 0.9600 TestAcc 0.5816 0.8950
epoch 900 LossPred 0.1492 LossAtt 0.7614 TrainAcc 0.9600 TestAcc 0.5806 0.9000
epoch 1000 LossPred 0.1307 LossAtt 0.6831 TrainAcc 0.9700 TestAcc 0.5783 0.8800
epoch 1100 LossPred 0.1184 LossAtt 0.6769 TrainAcc 0.9800 TestAcc 0.5831 0.8950
epoch 1200 LossPred 0.1222 LossAtt 0.6798 TrainAcc 0.9800 TestAcc 0.5826 0.8950
epoch 1300 LossPred 0.1007 LossAtt 0.6724 TrainAcc 0.9800 TestAcc 0.5751 0.9100
epoch 1400 LossPred 0.0951 LossAtt 0.6661 TrainAcc 0.9800 TestAcc 0.5768 0.9000
epoch 1500 LossPred 0.1531 LossAtt 0.8311 TrainAcc 0.9700 TestAcc 0.5788 0.8900
epoch 1600 LossPred 0.0884 LossAtt 0.6667 TrainAcc 0.9800 TestAcc 0.5791 0.9250
epoch 1700 LossPred 0.0827 LossAtt 0.6341 TrainAcc 0.9800 TestAcc 0.5758 0.9100
epoch 1800 LossPred 0.0778 LossAtt 0.6372 TrainAcc 0.9800 TestAcc 0.5726 0.9100
epoch 1900 LossPred 0.0765 LossAtt 0.6518 TrainAcc 0.9800 TestAcc 0.5723 0.9050
epoch 2000 LossPred 0.0769 LossAtt 0.6469 TrainAcc 0.9800 TestAcc 0.5781 0.9000
epoch 2100 LossPred 0.0682 LossAtt 0.6393 TrainAcc 0.9900 TestAcc 0.5736 0.9100
epoch 2200 LossPred 0.0637 LossAtt 0.6377 TrainAcc 0.9900 TestAcc 0.5733 0.9100
epoch 2300 LossPred 0.0612 LossAtt 0.6322 TrainAcc 0.9900 TestAcc 0.5723 0.9250
epoch 2400 LossPred 0.0597 LossAtt 0.6384 TrainAcc 0.9900 TestAcc 0.5678 0.9200
epoch 2500 LossPred 0.0581 LossAtt 0.6384 TrainAcc 0.9900 TestAcc 0.5671 0.9250
Optimization Finished!
********** replication  86  **********
epoch   0 LossPred 0.9985 LossAtt 1.0132 TrainAcc 0.5300 TestAcc 0.5363 0.5300
epoch 100 LossPred 0.5262 LossAtt 1.4414 TrainAcc 0.8600 TestAcc 0.8146 0.8350
epoch 200 LossPred 0.5268 LossAtt 0.5864 TrainAcc 0.8500 TestAcc 0.8088 0.8450
epoch 300 LossPred 0.4239 LossAtt 0.4795 TrainAcc 0.8500 TestAcc 0.8078 0.8650
epoch 400 LossPred 0.5118 LossAtt 0.4556 TrainAcc 0.8600 TestAcc 0.8426 0.8600
epoch 500 LossPred 0.4448 LossAtt 0.4840 TrainAcc 0.8500 TestAcc 0.7745 0.7950
epoch 600 LossPred 0.3415 LossAtt 0.4222 TrainAcc 0.8700 TestAcc 0.8433 0.8450
epoch 700 LossPred 0.3633 LossAtt 0.4162 TrainAcc 0.8800 TestAcc 0.8381 0.8550
epoch 800 LossPred 0.2985 LossAtt 0.4096 TrainAcc 0.8900 TestAcc 0.8461 0.8600
epoch 900 LossPred 0.2911 LossAtt 0.4039 TrainAcc 0.8900 TestAcc 0.8458 0.8600
epoch 1000 LossPred 0.2868 LossAtt 0.3923 TrainAcc 0.8900 TestAcc 0.8466 0.8600
epoch 1100 LossPred 0.2841 LossAtt 0.3930 TrainAcc 0.9000 TestAcc 0.8458 0.8600
epoch 1200 LossPred 0.3948 LossAtt 0.3985 TrainAcc 0.8700 TestAcc 0.8246 0.8500
epoch 1300 LossPred 0.2851 LossAtt 0.3913 TrainAcc 0.9000 TestAcc 0.8496 0.8800
epoch 1400 LossPred 0.2881 LossAtt 0.4164 TrainAcc 0.9000 TestAcc 0.8471 0.8700
epoch 1500 LossPred 0.2967 LossAtt 0.3735 TrainAcc 0.9000 TestAcc 0.8416 0.8600
epoch 1600 LossPred 0.2599 LossAtt 0.3805 TrainAcc 0.9100 TestAcc 0.8619 0.8800
epoch 1700 LossPred 0.2544 LossAtt 0.3792 TrainAcc 0.9100 TestAcc 0.8584 0.8900
epoch 1800 LossPred 0.2597 LossAtt 0.3890 TrainAcc 0.9100 TestAcc 0.8594 0.8650
epoch 1900 LossPred 0.2347 LossAtt 0.4299 TrainAcc 0.9100 TestAcc 0.8796 0.8850
epoch 2000 LossPred 0.2200 LossAtt 0.4172 TrainAcc 0.9200 TestAcc 0.8626 0.9200
epoch 2100 LossPred 0.2297 LossAtt 0.4035 TrainAcc 0.9300 TestAcc 0.8674 0.8500
epoch 2200 LossPred 0.2890 LossAtt 0.4091 TrainAcc 0.9100 TestAcc 0.8636 0.8650
epoch 2300 LossPred 0.2344 LossAtt 0.4558 TrainAcc 0.9300 TestAcc 0.8764 0.9050
epoch 2400 LossPred 0.1934 LossAtt 0.4338 TrainAcc 0.9300 TestAcc 0.8686 0.9100
epoch 2500 LossPred 0.2019 LossAtt 0.4605 TrainAcc 0.9200 TestAcc 0.8704 0.9100
Optimization Finished!
********** replication  87  **********
epoch   0 LossPred 0.9381 LossAtt 1.0429 TrainAcc 0.6200 TestAcc 0.5318 0.6350
epoch 100 LossPred 0.6350 LossAtt 1.2704 TrainAcc 0.7800 TestAcc 0.6664 0.7600
epoch 200 LossPred 0.4484 LossAtt 0.6650 TrainAcc 0.8400 TestAcc 0.8181 0.8650
epoch 300 LossPred 0.4578 LossAtt 0.5175 TrainAcc 0.8500 TestAcc 0.7923 0.8250
epoch 400 LossPred 0.3364 LossAtt 0.4136 TrainAcc 0.8800 TestAcc 0.8181 0.8550
epoch 500 LossPred 0.3215 LossAtt 0.3865 TrainAcc 0.9000 TestAcc 0.8203 0.8600
epoch 600 LossPred 0.3141 LossAtt 0.3754 TrainAcc 0.9000 TestAcc 0.8196 0.8650
epoch 700 LossPred 0.4126 LossAtt 0.4326 TrainAcc 0.8600 TestAcc 0.8108 0.8600
epoch 800 LossPred 0.3773 LossAtt 0.3970 TrainAcc 0.8800 TestAcc 0.8326 0.8700
epoch 900 LossPred 0.2713 LossAtt 0.3758 TrainAcc 0.9300 TestAcc 0.8316 0.8950
epoch 1000 LossPred 0.3611 LossAtt 0.4179 TrainAcc 0.9000 TestAcc 0.8373 0.8650
epoch 1100 LossPred 0.1977 LossAtt 0.3754 TrainAcc 0.9600 TestAcc 0.8321 0.8750
epoch 1200 LossPred 0.2690 LossAtt 0.3675 TrainAcc 0.9300 TestAcc 0.8308 0.8800
epoch 1300 LossPred 0.1832 LossAtt 0.3436 TrainAcc 0.9600 TestAcc 0.8411 0.8950
epoch 1400 LossPred 0.2708 LossAtt 0.3788 TrainAcc 0.9100 TestAcc 0.8376 0.9000
epoch 1500 LossPred 0.1635 LossAtt 0.3372 TrainAcc 0.9700 TestAcc 0.8278 0.8900
epoch 1600 LossPred 0.3022 LossAtt 0.3418 TrainAcc 0.9100 TestAcc 0.8356 0.9050
epoch 1700 LossPred 0.1555 LossAtt 0.3213 TrainAcc 0.9700 TestAcc 0.8318 0.8900
epoch 1800 LossPred 0.1646 LossAtt 0.3108 TrainAcc 0.9600 TestAcc 0.8293 0.9000
epoch 1900 LossPred 0.1466 LossAtt 0.3288 TrainAcc 0.9700 TestAcc 0.8206 0.9000
epoch 2000 LossPred 0.1621 LossAtt 0.3245 TrainAcc 0.9600 TestAcc 0.8313 0.9050
epoch 2100 LossPred 0.1391 LossAtt 0.2931 TrainAcc 0.9700 TestAcc 0.8238 0.9000
epoch 2200 LossPred 0.1555 LossAtt 0.3041 TrainAcc 0.9700 TestAcc 0.8276 0.9050
epoch 2300 LossPred 0.2182 LossAtt 0.2859 TrainAcc 0.9500 TestAcc 0.8163 0.9050
epoch 2400 LossPred 0.1723 LossAtt 0.2857 TrainAcc 0.9600 TestAcc 0.8206 0.9100
epoch 2500 LossPred 0.1865 LossAtt 0.2973 TrainAcc 0.9500 TestAcc 0.8361 0.9250
Optimization Finished!
********** replication  88  **********
epoch   0 LossPred 1.0585 LossAtt 1.0131 TrainAcc 0.4800 TestAcc 0.4535 0.4650
epoch 100 LossPred 0.9103 LossAtt 0.7467 TrainAcc 0.6300 TestAcc 0.5611 0.6350
epoch 200 LossPred 0.6549 LossAtt 1.2379 TrainAcc 0.8100 TestAcc 0.5280 0.7400
epoch 300 LossPred 0.4997 LossAtt 1.0721 TrainAcc 0.8300 TestAcc 0.5245 0.7400
epoch 400 LossPred 0.3489 LossAtt 0.8736 TrainAcc 0.8900 TestAcc 0.5215 0.7550
epoch 500 LossPred 0.3131 LossAtt 0.7432 TrainAcc 0.9200 TestAcc 0.5188 0.7800
epoch 600 LossPred 0.3007 LossAtt 0.7318 TrainAcc 0.9200 TestAcc 0.5195 0.8050
epoch 700 LossPred 0.2381 LossAtt 0.6815 TrainAcc 0.9300 TestAcc 0.5198 0.8150
epoch 800 LossPred 0.2182 LossAtt 0.7165 TrainAcc 0.9400 TestAcc 0.5155 0.8150
epoch 900 LossPred 0.2017 LossAtt 0.6808 TrainAcc 0.9400 TestAcc 0.5190 0.7950
epoch 1000 LossPred 0.2094 LossAtt 0.6951 TrainAcc 0.9500 TestAcc 0.5220 0.8050
epoch 1100 LossPred 0.1773 LossAtt 0.6789 TrainAcc 0.9600 TestAcc 0.5180 0.7950
epoch 1200 LossPred 0.2112 LossAtt 0.7347 TrainAcc 0.9400 TestAcc 0.5183 0.8250
epoch 1300 LossPred 0.2450 LossAtt 0.6986 TrainAcc 0.9500 TestAcc 0.5130 0.8050
epoch 1400 LossPred 0.1577 LossAtt 0.7010 TrainAcc 0.9700 TestAcc 0.5145 0.8200
epoch 1500 LossPred 0.1156 LossAtt 0.7110 TrainAcc 0.9800 TestAcc 0.5035 0.8500
epoch 1600 LossPred 0.0608 LossAtt 0.7047 TrainAcc 0.9900 TestAcc 0.5103 0.7900
epoch 1700 LossPred 0.0710 LossAtt 0.7110 TrainAcc 0.9900 TestAcc 0.5115 0.8000
epoch 1800 LossPred 0.0550 LossAtt 0.7188 TrainAcc 1.0000 TestAcc 0.5095 0.8200
Optimization Finished!
********** replication  89  **********
epoch   0 LossPred 1.0517 LossAtt 1.0147 TrainAcc 0.3700 TestAcc 0.4287 0.3800
epoch 100 LossPred 0.8552 LossAtt 0.6165 TrainAcc 0.6300 TestAcc 0.5713 0.6350
epoch 200 LossPred 1.1797 LossAtt 0.9828 TrainAcc 0.6300 TestAcc 0.6226 0.6350
epoch 300 LossPred 0.5112 LossAtt 1.0246 TrainAcc 0.8200 TestAcc 0.7875 0.8250
epoch 400 LossPred 0.5207 LossAtt 0.4115 TrainAcc 0.8300 TestAcc 0.7823 0.8400
epoch 500 LossPred 0.3946 LossAtt 0.3516 TrainAcc 0.8700 TestAcc 0.8133 0.8400
epoch 600 LossPred 0.3883 LossAtt 0.3507 TrainAcc 0.8700 TestAcc 0.8098 0.8400
epoch 700 LossPred 0.3869 LossAtt 0.3322 TrainAcc 0.8700 TestAcc 0.8116 0.8450
epoch 800 LossPred 0.3860 LossAtt 0.3188 TrainAcc 0.8800 TestAcc 0.8111 0.8400
epoch 900 LossPred 0.3855 LossAtt 0.3098 TrainAcc 0.8700 TestAcc 0.8106 0.8400
epoch 1000 LossPred 0.3848 LossAtt 0.2973 TrainAcc 0.8800 TestAcc 0.8108 0.8400
epoch 1100 LossPred 0.3840 LossAtt 0.2786 TrainAcc 0.8800 TestAcc 0.8108 0.8400
epoch 1200 LossPred 0.3830 LossAtt 0.2759 TrainAcc 0.8800 TestAcc 0.8101 0.8400
epoch 1300 LossPred 0.3819 LossAtt 0.2771 TrainAcc 0.8800 TestAcc 0.8088 0.8350
epoch 1400 LossPred 0.4422 LossAtt 0.3549 TrainAcc 0.8500 TestAcc 0.8073 0.8350
epoch 1500 LossPred 0.4294 LossAtt 0.2715 TrainAcc 0.8700 TestAcc 0.8021 0.8400
epoch 1600 LossPred 0.4233 LossAtt 0.2738 TrainAcc 0.8700 TestAcc 0.8006 0.8450
epoch 1700 LossPred 0.9882 LossAtt 0.4964 TrainAcc 0.6400 TestAcc 0.6599 0.6600
epoch 1800 LossPred 0.3810 LossAtt 0.2772 TrainAcc 0.8700 TestAcc 0.8123 0.8400
epoch 1900 LossPred 0.3728 LossAtt 0.2812 TrainAcc 0.8700 TestAcc 0.8121 0.8350
epoch 2000 LossPred 0.3702 LossAtt 0.2789 TrainAcc 0.8700 TestAcc 0.8118 0.8350
epoch 2100 LossPred 0.3673 LossAtt 0.2753 TrainAcc 0.8700 TestAcc 0.8118 0.8350
epoch 2200 LossPred 0.3640 LossAtt 0.2824 TrainAcc 0.8700 TestAcc 0.8103 0.8300
epoch 2300 LossPred 0.3592 LossAtt 0.2888 TrainAcc 0.8800 TestAcc 0.8096 0.8300
epoch 2400 LossPred 1.1704 LossAtt 1.0588 TrainAcc 0.6600 TestAcc 0.5636 0.6500
epoch 2500 LossPred 0.8973 LossAtt 0.2475 TrainAcc 0.6200 TestAcc 0.5490 0.6100
Optimization Finished!
********** replication  90  **********
epoch   0 LossPred 1.0414 LossAtt 1.0410 TrainAcc 0.4900 TestAcc 0.4995 0.4750
epoch 100 LossPred 0.8831 LossAtt 0.6498 TrainAcc 0.6600 TestAcc 0.5405 0.6600
epoch 200 LossPred 0.8655 LossAtt 0.7531 TrainAcc 0.6600 TestAcc 0.5405 0.6600
epoch 300 LossPred 0.8316 LossAtt 0.9776 TrainAcc 0.6800 TestAcc 0.5473 0.6850
epoch 400 LossPred 0.6348 LossAtt 1.3809 TrainAcc 0.7800 TestAcc 0.5345 0.7650
epoch 500 LossPred 0.4706 LossAtt 1.3166 TrainAcc 0.8700 TestAcc 0.5350 0.7950
epoch 600 LossPred 0.4003 LossAtt 1.0196 TrainAcc 0.8700 TestAcc 0.5395 0.8050
epoch 700 LossPred 0.3365 LossAtt 0.9543 TrainAcc 0.8900 TestAcc 0.5415 0.8200
epoch 800 LossPred 0.3003 LossAtt 0.8812 TrainAcc 0.9200 TestAcc 0.5363 0.8400
epoch 900 LossPred 0.2643 LossAtt 0.8482 TrainAcc 0.9400 TestAcc 0.5368 0.8150
epoch 1000 LossPred 0.2819 LossAtt 0.8083 TrainAcc 0.9400 TestAcc 0.5395 0.7900
epoch 1100 LossPred 0.2709 LossAtt 0.7891 TrainAcc 0.9400 TestAcc 0.5443 0.8300
epoch 1200 LossPred 0.2486 LossAtt 0.7620 TrainAcc 0.9400 TestAcc 0.5403 0.8200
epoch 1300 LossPred 0.3541 LossAtt 0.7542 TrainAcc 0.8900 TestAcc 0.5428 0.7950
epoch 1400 LossPred 0.1651 LossAtt 0.7312 TrainAcc 0.9700 TestAcc 0.5425 0.8150
epoch 1500 LossPred 0.1414 LossAtt 0.7217 TrainAcc 0.9700 TestAcc 0.5413 0.8250
epoch 1600 LossPred 0.3978 LossAtt 0.6945 TrainAcc 0.8900 TestAcc 0.5490 0.7950
epoch 1700 LossPred 0.2415 LossAtt 0.6882 TrainAcc 0.9600 TestAcc 0.5390 0.7850
epoch 1800 LossPred 0.1657 LossAtt 0.7021 TrainAcc 0.9600 TestAcc 0.5388 0.8050
epoch 1900 LossPred 0.3265 LossAtt 0.7726 TrainAcc 0.9000 TestAcc 0.5506 0.7900
epoch 2000 LossPred 0.1388 LossAtt 0.6936 TrainAcc 0.9700 TestAcc 0.5395 0.7800
epoch 2100 LossPred 0.3464 LossAtt 0.7382 TrainAcc 0.9000 TestAcc 0.5343 0.8050
epoch 2200 LossPred 0.5925 LossAtt 0.8520 TrainAcc 0.8000 TestAcc 0.5385 0.7800
epoch 2300 LossPred 0.1237 LossAtt 0.6812 TrainAcc 0.9800 TestAcc 0.5383 0.8000
epoch 2400 LossPred 0.1074 LossAtt 0.6797 TrainAcc 0.9900 TestAcc 0.5348 0.8000
epoch 2500 LossPred 0.1010 LossAtt 0.6762 TrainAcc 0.9900 TestAcc 0.5313 0.8000
Optimization Finished!
********** replication  91  **********
epoch   0 LossPred 1.0525 LossAtt 1.0794 TrainAcc 0.4700 TestAcc 0.4269 0.4800
epoch 100 LossPred 0.8672 LossAtt 0.8823 TrainAcc 0.6600 TestAcc 0.6436 0.6900
epoch 200 LossPred 0.4633 LossAtt 0.5542 TrainAcc 0.8400 TestAcc 0.8321 0.8050
epoch 300 LossPred 0.2185 LossAtt 0.4774 TrainAcc 0.9700 TestAcc 0.9012 0.9000
epoch 400 LossPred 0.1295 LossAtt 0.4154 TrainAcc 0.9800 TestAcc 0.9117 0.9250
epoch 500 LossPred 0.1046 LossAtt 0.4083 TrainAcc 0.9800 TestAcc 0.9084 0.9400
epoch 600 LossPred 0.1061 LossAtt 0.3772 TrainAcc 0.9900 TestAcc 0.8976 0.9200
epoch 700 LossPred 0.0917 LossAtt 0.3804 TrainAcc 0.9800 TestAcc 0.8949 0.9500
epoch 800 LossPred 0.0959 LossAtt 0.3889 TrainAcc 0.9800 TestAcc 0.9052 0.9350
epoch 900 LossPred 0.1226 LossAtt 0.4309 TrainAcc 0.9600 TestAcc 0.8624 0.9200
epoch 1000 LossPred 0.1196 LossAtt 0.4127 TrainAcc 0.9600 TestAcc 0.8884 0.9350
epoch 1100 LossPred 0.0833 LossAtt 0.4286 TrainAcc 0.9800 TestAcc 0.8924 0.9400
epoch 1200 LossPred 0.1292 LossAtt 0.3901 TrainAcc 0.9700 TestAcc 0.8904 0.9450
epoch 1300 LossPred 0.1830 LossAtt 0.3714 TrainAcc 0.9500 TestAcc 0.8684 0.9000
epoch 1400 LossPred 0.1624 LossAtt 0.4381 TrainAcc 0.9500 TestAcc 0.8676 0.9250
epoch 1500 LossPred 0.0821 LossAtt 0.4405 TrainAcc 0.9800 TestAcc 0.8766 0.9450
epoch 1600 LossPred 0.1076 LossAtt 0.3700 TrainAcc 0.9800 TestAcc 0.8631 0.9500
epoch 1700 LossPred 0.0904 LossAtt 0.3338 TrainAcc 0.9700 TestAcc 0.8731 0.9500
epoch 1800 LossPred 0.1173 LossAtt 0.3468 TrainAcc 0.9700 TestAcc 0.8691 0.9450
epoch 1900 LossPred 0.3382 LossAtt 0.3397 TrainAcc 0.8900 TestAcc 0.8318 0.9050
epoch 2000 LossPred 0.2133 LossAtt 0.3350 TrainAcc 0.9100 TestAcc 0.8448 0.9150
epoch 2100 LossPred 0.1136 LossAtt 0.3210 TrainAcc 0.9700 TestAcc 0.8493 0.9150
epoch 2200 LossPred 0.2621 LossAtt 0.3070 TrainAcc 0.9200 TestAcc 0.8336 0.8750
epoch 2300 LossPred 0.1919 LossAtt 0.3173 TrainAcc 0.9200 TestAcc 0.8481 0.9150
epoch 2400 LossPred 0.1349 LossAtt 0.3150 TrainAcc 0.9500 TestAcc 0.8566 0.9300
epoch 2500 LossPred 0.1485 LossAtt 0.2981 TrainAcc 0.9500 TestAcc 0.8616 0.9400
Optimization Finished!
********** replication  92  **********
epoch   0 LossPred 1.2032 LossAtt 1.0402 TrainAcc 0.5100 TestAcc 0.4642 0.5000
epoch 100 LossPred 0.8580 LossAtt 0.8044 TrainAcc 0.6900 TestAcc 0.5868 0.6600
epoch 200 LossPred 0.5074 LossAtt 0.7381 TrainAcc 0.8700 TestAcc 0.7855 0.8150
epoch 300 LossPred 0.2984 LossAtt 0.5362 TrainAcc 0.9300 TestAcc 0.8451 0.9000
epoch 400 LossPred 0.2623 LossAtt 0.4860 TrainAcc 0.9400 TestAcc 0.8486 0.8950
epoch 500 LossPred 0.1638 LossAtt 0.4428 TrainAcc 0.9700 TestAcc 0.8433 0.9000
epoch 600 LossPred 0.1960 LossAtt 0.4927 TrainAcc 0.9500 TestAcc 0.8521 0.9100
epoch 700 LossPred 0.1407 LossAtt 0.4356 TrainAcc 0.9700 TestAcc 0.8383 0.9050
epoch 800 LossPred 0.1387 LossAtt 0.4472 TrainAcc 0.9700 TestAcc 0.8554 0.9200
epoch 900 LossPred 0.2343 LossAtt 0.5182 TrainAcc 0.9300 TestAcc 0.8358 0.8900
epoch 1000 LossPred 0.0999 LossAtt 0.4217 TrainAcc 0.9800 TestAcc 0.8478 0.9300
epoch 1100 LossPred 0.0814 LossAtt 0.4278 TrainAcc 0.9800 TestAcc 0.8519 0.9250
epoch 1200 LossPred 0.0736 LossAtt 0.4202 TrainAcc 0.9800 TestAcc 0.8581 0.9400
epoch 1300 LossPred 0.1406 LossAtt 0.4379 TrainAcc 0.9600 TestAcc 0.8438 0.9000
epoch 1400 LossPred 0.0979 LossAtt 0.4257 TrainAcc 0.9700 TestAcc 0.8493 0.9050
epoch 1500 LossPred 0.1152 LossAtt 0.4294 TrainAcc 0.9600 TestAcc 0.8423 0.9200
epoch 1600 LossPred 0.3432 LossAtt 0.4387 TrainAcc 0.8800 TestAcc 0.8023 0.8500
epoch 1700 LossPred 0.0725 LossAtt 0.4102 TrainAcc 0.9900 TestAcc 0.8521 0.9150
epoch 1800 LossPred 0.0596 LossAtt 0.3930 TrainAcc 0.9900 TestAcc 0.8591 0.9050
epoch 1900 LossPred 0.0542 LossAtt 0.3957 TrainAcc 0.9900 TestAcc 0.8561 0.9100
epoch 2000 LossPred 0.0522 LossAtt 0.4020 TrainAcc 0.9900 TestAcc 0.8559 0.9150
epoch 2100 LossPred 0.0600 LossAtt 0.4235 TrainAcc 0.9900 TestAcc 0.8471 0.9150
epoch 2200 LossPred 0.0753 LossAtt 0.4301 TrainAcc 0.9800 TestAcc 0.8609 0.9150
epoch 2300 LossPred 0.0588 LossAtt 0.4111 TrainAcc 0.9900 TestAcc 0.8453 0.9050
epoch 2400 LossPred 0.0517 LossAtt 0.3901 TrainAcc 0.9900 TestAcc 0.8524 0.9100
epoch 2500 LossPred 0.1055 LossAtt 0.4471 TrainAcc 0.9600 TestAcc 0.8529 0.9200
Optimization Finished!
********** replication  93  **********
epoch   0 LossPred 1.1251 LossAtt 1.0112 TrainAcc 0.5000 TestAcc 0.5243 0.5050
epoch 100 LossPred 0.8564 LossAtt 0.6404 TrainAcc 0.6600 TestAcc 0.6039 0.6550
epoch 200 LossPred 0.5144 LossAtt 0.6180 TrainAcc 0.8500 TestAcc 0.7920 0.7950
epoch 300 LossPred 0.3604 LossAtt 0.4848 TrainAcc 0.8700 TestAcc 0.8473 0.8200
epoch 400 LossPred 0.3530 LossAtt 0.4862 TrainAcc 0.8800 TestAcc 0.8301 0.8350
epoch 500 LossPred 0.2821 LossAtt 0.4661 TrainAcc 0.9000 TestAcc 0.8458 0.8550
epoch 600 LossPred 0.2658 LossAtt 0.4502 TrainAcc 0.9100 TestAcc 0.8406 0.8700
epoch 700 LossPred 0.2539 LossAtt 0.4576 TrainAcc 0.9100 TestAcc 0.8396 0.8750
epoch 800 LossPred 0.2457 LossAtt 0.4429 TrainAcc 0.9200 TestAcc 0.8378 0.8700
epoch 900 LossPred 0.2396 LossAtt 0.4324 TrainAcc 0.9200 TestAcc 0.8388 0.8700
epoch 1000 LossPred 0.2644 LossAtt 0.5076 TrainAcc 0.8900 TestAcc 0.8318 0.8550
epoch 1100 LossPred 0.2879 LossAtt 0.4721 TrainAcc 0.8800 TestAcc 0.8213 0.8500
epoch 1200 LossPred 0.2335 LossAtt 0.4369 TrainAcc 0.9200 TestAcc 0.8316 0.8600
epoch 1300 LossPred 0.2301 LossAtt 0.4406 TrainAcc 0.9300 TestAcc 0.8308 0.8550
epoch 1400 LossPred 0.2511 LossAtt 0.4589 TrainAcc 0.9100 TestAcc 0.8231 0.8500
epoch 1500 LossPred 0.2015 LossAtt 0.4284 TrainAcc 0.9500 TestAcc 0.8336 0.8650
epoch 1600 LossPred 1.1648 LossAtt 0.5895 TrainAcc 0.6500 TestAcc 0.6004 0.6450
epoch 1700 LossPred 0.1685 LossAtt 0.4142 TrainAcc 0.9700 TestAcc 0.8243 0.8900
epoch 1800 LossPred 0.1546 LossAtt 0.4047 TrainAcc 0.9700 TestAcc 0.8216 0.8850
epoch 1900 LossPred 0.1445 LossAtt 0.4191 TrainAcc 0.9700 TestAcc 0.8206 0.8800
epoch 2000 LossPred 0.1397 LossAtt 0.4060 TrainAcc 0.9700 TestAcc 0.8211 0.8950
epoch 2100 LossPred 0.1884 LossAtt 0.4290 TrainAcc 0.9500 TestAcc 0.8178 0.8850
epoch 2200 LossPred 0.1190 LossAtt 0.4228 TrainAcc 0.9700 TestAcc 0.8248 0.9050
epoch 2300 LossPred 0.1124 LossAtt 0.4007 TrainAcc 0.9800 TestAcc 0.8178 0.9100
epoch 2400 LossPred 0.0977 LossAtt 0.4107 TrainAcc 0.9800 TestAcc 0.8298 0.9050
epoch 2500 LossPred 0.0936 LossAtt 0.3840 TrainAcc 0.9800 TestAcc 0.8261 0.9100
Optimization Finished!
********** replication  94  **********
epoch   0 LossPred 1.1923 LossAtt 1.0189 TrainAcc 0.4900 TestAcc 0.4862 0.4850
epoch 100 LossPred 0.9653 LossAtt 0.5743 TrainAcc 0.5700 TestAcc 0.5493 0.5700
epoch 200 LossPred 0.8731 LossAtt 0.8408 TrainAcc 0.6300 TestAcc 0.5293 0.6350
epoch 300 LossPred 0.7521 LossAtt 1.0384 TrainAcc 0.7300 TestAcc 0.5415 0.7000
epoch 400 LossPred 0.5468 LossAtt 1.1492 TrainAcc 0.8300 TestAcc 0.5293 0.7600
epoch 500 LossPred 0.5589 LossAtt 0.7278 TrainAcc 0.8400 TestAcc 0.5103 0.7500
epoch 600 LossPred 0.4825 LossAtt 0.7150 TrainAcc 0.8500 TestAcc 0.5113 0.7700
epoch 700 LossPred 0.4448 LossAtt 0.7153 TrainAcc 0.8600 TestAcc 0.5130 0.7750
epoch 800 LossPred 0.4305 LossAtt 0.7475 TrainAcc 0.8500 TestAcc 0.5118 0.7800
epoch 900 LossPred 0.3792 LossAtt 0.7171 TrainAcc 0.8900 TestAcc 0.5140 0.7550
epoch 1000 LossPred 0.3530 LossAtt 0.7341 TrainAcc 0.9100 TestAcc 0.5243 0.7750
epoch 1100 LossPred 0.2960 LossAtt 0.7038 TrainAcc 0.9200 TestAcc 0.5213 0.7800
epoch 1200 LossPred 0.2522 LossAtt 0.6775 TrainAcc 0.9500 TestAcc 0.5195 0.7950
epoch 1300 LossPred 0.2748 LossAtt 0.6815 TrainAcc 0.9200 TestAcc 0.5275 0.7900
epoch 1400 LossPred 0.2293 LossAtt 0.6572 TrainAcc 0.9500 TestAcc 0.5290 0.7950
epoch 1500 LossPred 0.3906 LossAtt 0.7076 TrainAcc 0.8800 TestAcc 0.5220 0.8000
epoch 1600 LossPred 0.3798 LossAtt 0.7125 TrainAcc 0.8600 TestAcc 0.5165 0.7900
epoch 1700 LossPred 0.2206 LossAtt 0.6229 TrainAcc 0.9600 TestAcc 0.5293 0.8250
epoch 1800 LossPred 0.3743 LossAtt 0.6575 TrainAcc 0.9000 TestAcc 0.5268 0.7750
epoch 1900 LossPred 0.2315 LossAtt 0.6171 TrainAcc 0.9400 TestAcc 0.5280 0.8050
epoch 2000 LossPred 0.3379 LossAtt 0.6346 TrainAcc 0.9000 TestAcc 0.5273 0.8150
epoch 2100 LossPred 0.2061 LossAtt 0.6365 TrainAcc 0.9600 TestAcc 0.5253 0.8450
epoch 2200 LossPred 0.3543 LossAtt 0.7336 TrainAcc 0.9100 TestAcc 0.5308 0.7950
epoch 2300 LossPred 0.1730 LossAtt 0.6752 TrainAcc 0.9600 TestAcc 0.5353 0.8200
epoch 2400 LossPred 0.1437 LossAtt 0.6167 TrainAcc 0.9700 TestAcc 0.5278 0.8450
epoch 2500 LossPred 0.2242 LossAtt 0.6296 TrainAcc 0.9300 TestAcc 0.5218 0.8200
Optimization Finished!
********** replication  95  **********
epoch   0 LossPred 1.1078 LossAtt 1.0531 TrainAcc 0.4600 TestAcc 0.4319 0.4450
epoch 100 LossPred 0.9507 LossAtt 0.5944 TrainAcc 0.6000 TestAcc 0.5103 0.5950
epoch 200 LossPred 0.8119 LossAtt 1.0193 TrainAcc 0.7200 TestAcc 0.5480 0.6700
epoch 300 LossPred 0.5961 LossAtt 1.1916 TrainAcc 0.8300 TestAcc 0.5508 0.7350
epoch 400 LossPred 0.5450 LossAtt 1.0336 TrainAcc 0.8400 TestAcc 0.5556 0.7150
epoch 500 LossPred 0.4451 LossAtt 0.9325 TrainAcc 0.8500 TestAcc 0.5543 0.7450
epoch 600 LossPred 0.4297 LossAtt 0.9243 TrainAcc 0.8600 TestAcc 0.5618 0.7500
epoch 700 LossPred 0.4617 LossAtt 0.8424 TrainAcc 0.8400 TestAcc 0.5531 0.7400
epoch 800 LossPred 0.3653 LossAtt 0.7781 TrainAcc 0.8900 TestAcc 0.5490 0.7350
epoch 900 LossPred 0.3302 LossAtt 0.6913 TrainAcc 0.9000 TestAcc 0.5523 0.7300
epoch 1000 LossPred 0.2827 LossAtt 0.6874 TrainAcc 0.9500 TestAcc 0.5440 0.7350
epoch 1100 LossPred 0.3226 LossAtt 0.6974 TrainAcc 0.9300 TestAcc 0.5400 0.7400
epoch 1200 LossPred 0.2475 LossAtt 0.7139 TrainAcc 0.9500 TestAcc 0.5480 0.7600
epoch 1300 LossPred 0.2819 LossAtt 0.6954 TrainAcc 0.9200 TestAcc 0.5373 0.7700
epoch 1400 LossPred 0.1971 LossAtt 0.6615 TrainAcc 0.9700 TestAcc 0.5333 0.7650
epoch 1500 LossPred 0.1985 LossAtt 0.6479 TrainAcc 0.9700 TestAcc 0.5325 0.7450
epoch 1600 LossPred 0.1678 LossAtt 0.6494 TrainAcc 0.9600 TestAcc 0.5345 0.7750
epoch 1700 LossPred 0.1881 LossAtt 0.6811 TrainAcc 0.9800 TestAcc 0.5358 0.7900
epoch 1800 LossPred 0.2221 LossAtt 0.6594 TrainAcc 0.9400 TestAcc 0.5430 0.8050
epoch 1900 LossPred 0.1673 LossAtt 0.6434 TrainAcc 0.9600 TestAcc 0.5473 0.7850
epoch 2000 LossPred 0.1410 LossAtt 0.6456 TrainAcc 0.9800 TestAcc 0.5415 0.8000
epoch 2100 LossPred 0.1724 LossAtt 0.6377 TrainAcc 0.9500 TestAcc 0.5490 0.8100
epoch 2200 LossPred 0.1403 LossAtt 0.6470 TrainAcc 0.9700 TestAcc 0.5546 0.7900
epoch 2300 LossPred 0.1274 LossAtt 0.6325 TrainAcc 0.9800 TestAcc 0.5443 0.7500
epoch 2400 LossPred 0.3765 LossAtt 0.7222 TrainAcc 0.8800 TestAcc 0.5448 0.8000
epoch 2500 LossPred 0.1376 LossAtt 0.6290 TrainAcc 0.9600 TestAcc 0.5533 0.8050
Optimization Finished!
********** replication  96  **********
epoch   0 LossPred 1.0282 LossAtt 1.0169 TrainAcc 0.5000 TestAcc 0.4672 0.5050
epoch 100 LossPred 0.8202 LossAtt 0.7360 TrainAcc 0.6700 TestAcc 0.5988 0.6700
epoch 200 LossPred 0.3387 LossAtt 0.5696 TrainAcc 0.9200 TestAcc 0.8343 0.8650
epoch 300 LossPred 0.2229 LossAtt 0.4895 TrainAcc 0.9400 TestAcc 0.8433 0.8950
epoch 400 LossPred 0.2775 LossAtt 0.5219 TrainAcc 0.9100 TestAcc 0.8138 0.8750
epoch 500 LossPred 0.1736 LossAtt 0.4912 TrainAcc 0.9700 TestAcc 0.8391 0.8750
epoch 600 LossPred 0.1530 LossAtt 0.4814 TrainAcc 0.9700 TestAcc 0.8423 0.8950
epoch 700 LossPred 0.1369 LossAtt 0.4638 TrainAcc 0.9700 TestAcc 0.8331 0.9150
epoch 800 LossPred 0.1528 LossAtt 0.4788 TrainAcc 0.9500 TestAcc 0.8128 0.9200
epoch 900 LossPred 0.3052 LossAtt 0.4976 TrainAcc 0.9100 TestAcc 0.7818 0.8400
epoch 1000 LossPred 0.0949 LossAtt 0.4615 TrainAcc 0.9900 TestAcc 0.7985 0.9300
epoch 1100 LossPred 0.1017 LossAtt 0.4327 TrainAcc 0.9600 TestAcc 0.8148 0.9300
epoch 1200 LossPred 0.0839 LossAtt 0.4055 TrainAcc 0.9800 TestAcc 0.8093 0.9400
epoch 1300 LossPred 0.2849 LossAtt 0.4142 TrainAcc 0.9200 TestAcc 0.8068 0.9200
epoch 1400 LossPred 0.1133 LossAtt 0.4087 TrainAcc 0.9700 TestAcc 0.8073 0.9600
epoch 1500 LossPred 1.5862 LossAtt 0.4294 TrainAcc 0.5900 TestAcc 0.5758 0.5900
epoch 1600 LossPred 0.2381 LossAtt 0.3530 TrainAcc 0.9300 TestAcc 0.7893 0.9300
epoch 1700 LossPred 0.0859 LossAtt 0.3683 TrainAcc 0.9900 TestAcc 0.7935 0.9450
epoch 1800 LossPred 0.1192 LossAtt 0.3557 TrainAcc 0.9700 TestAcc 0.7995 0.9650
epoch 1900 LossPred 0.2152 LossAtt 0.3785 TrainAcc 0.9300 TestAcc 0.7820 0.9300
epoch 2000 LossPred 0.0970 LossAtt 0.3682 TrainAcc 0.9700 TestAcc 0.7920 0.9500
epoch 2100 LossPred 0.1778 LossAtt 0.3902 TrainAcc 0.9300 TestAcc 0.7813 0.9400
epoch 2200 LossPred 0.1889 LossAtt 0.3421 TrainAcc 0.9400 TestAcc 0.7843 0.9350
epoch 2300 LossPred 0.1103 LossAtt 0.3365 TrainAcc 0.9900 TestAcc 0.7928 0.9550
epoch 2400 LossPred 0.3343 LossAtt 0.4049 TrainAcc 0.9000 TestAcc 0.7492 0.8900
epoch 2500 LossPred 0.5496 LossAtt 0.3730 TrainAcc 0.8200 TestAcc 0.7345 0.8050
Optimization Finished!
********** replication  97  **********
epoch   0 LossPred 1.0494 LossAtt 1.0536 TrainAcc 0.3800 TestAcc 0.4752 0.3950
epoch 100 LossPred 0.8673 LossAtt 0.8192 TrainAcc 0.7000 TestAcc 0.5708 0.6500
epoch 200 LossPred 0.7371 LossAtt 1.0120 TrainAcc 0.7500 TestAcc 0.5948 0.7300
epoch 300 LossPred 0.5903 LossAtt 0.9042 TrainAcc 0.8200 TestAcc 0.6094 0.7600
epoch 400 LossPred 0.6088 LossAtt 0.7717 TrainAcc 0.8000 TestAcc 0.6024 0.7800
epoch 500 LossPred 0.5161 LossAtt 0.7310 TrainAcc 0.8200 TestAcc 0.6854 0.7750
epoch 600 LossPred 0.3346 LossAtt 0.6105 TrainAcc 0.9300 TestAcc 0.7700 0.8550
epoch 700 LossPred 0.5111 LossAtt 0.6123 TrainAcc 0.8200 TestAcc 0.6937 0.7950
epoch 800 LossPred 0.2466 LossAtt 0.5835 TrainAcc 0.9500 TestAcc 0.7808 0.8400
epoch 900 LossPred 0.2305 LossAtt 0.5799 TrainAcc 0.9500 TestAcc 0.7943 0.8500
epoch 1000 LossPred 0.2750 LossAtt 0.6075 TrainAcc 0.9200 TestAcc 0.7695 0.8550
epoch 1100 LossPred 0.1964 LossAtt 0.5933 TrainAcc 0.9600 TestAcc 0.8048 0.8750
epoch 1200 LossPred 0.2453 LossAtt 0.5817 TrainAcc 0.9300 TestAcc 0.7885 0.8850
epoch 1300 LossPred 0.2251 LossAtt 0.6368 TrainAcc 0.9400 TestAcc 0.8091 0.8900
epoch 1400 LossPred 0.1876 LossAtt 0.5872 TrainAcc 0.9500 TestAcc 0.8243 0.9000
epoch 1500 LossPred 0.2799 LossAtt 0.6342 TrainAcc 0.9000 TestAcc 0.8278 0.8850
epoch 1600 LossPred 0.0984 LossAtt 0.5895 TrainAcc 0.9800 TestAcc 0.7973 0.8850
epoch 1700 LossPred 0.1650 LossAtt 0.6115 TrainAcc 0.9500 TestAcc 0.7803 0.8600
epoch 1800 LossPred 0.0740 LossAtt 0.5788 TrainAcc 0.9800 TestAcc 0.8083 0.8900
epoch 1900 LossPred 0.0598 LossAtt 0.5711 TrainAcc 0.9800 TestAcc 0.8198 0.8950
epoch 2000 LossPred 0.0156 LossAtt 0.5693 TrainAcc 1.0000 TestAcc 0.8493 0.8950
Optimization Finished!
********** replication  98  **********
epoch   0 LossPred 0.9611 LossAtt 1.0561 TrainAcc 0.6200 TestAcc 0.5643 0.6350
epoch 100 LossPred 0.8442 LossAtt 0.5486 TrainAcc 0.6700 TestAcc 0.5303 0.7000
epoch 200 LossPred 0.7737 LossAtt 0.7387 TrainAcc 0.7100 TestAcc 0.5663 0.7000
epoch 300 LossPred 0.4207 LossAtt 0.9183 TrainAcc 0.8400 TestAcc 0.7480 0.8350
epoch 400 LossPred 0.1882 LossAtt 0.5992 TrainAcc 0.9300 TestAcc 0.8261 0.9200
epoch 500 LossPred 0.1301 LossAtt 0.5424 TrainAcc 0.9800 TestAcc 0.8498 0.9150
epoch 600 LossPred 0.0968 LossAtt 0.5219 TrainAcc 0.9800 TestAcc 0.8564 0.9000
epoch 700 LossPred 0.3815 LossAtt 0.5402 TrainAcc 0.8700 TestAcc 0.7768 0.8500
epoch 800 LossPred 0.1652 LossAtt 0.4926 TrainAcc 0.9400 TestAcc 0.8436 0.8850
epoch 900 LossPred 0.1422 LossAtt 0.5014 TrainAcc 0.9600 TestAcc 0.8228 0.9000
epoch 1000 LossPred 0.0827 LossAtt 0.4637 TrainAcc 0.9800 TestAcc 0.8659 0.9050
epoch 1100 LossPred 0.0816 LossAtt 0.4662 TrainAcc 0.9800 TestAcc 0.8606 0.9050
epoch 1200 LossPred 0.1098 LossAtt 0.4953 TrainAcc 0.9800 TestAcc 0.8443 0.9300
epoch 1300 LossPred 0.0857 LossAtt 0.4590 TrainAcc 0.9800 TestAcc 0.8478 0.9450
epoch 1400 LossPred 0.0793 LossAtt 0.4427 TrainAcc 0.9800 TestAcc 0.8521 0.9250
epoch 1500 LossPred 0.0492 LossAtt 0.4591 TrainAcc 0.9900 TestAcc 0.8644 0.9300
epoch 1600 LossPred 0.0472 LossAtt 0.4730 TrainAcc 0.9900 TestAcc 0.8571 0.9550
epoch 1700 LossPred 0.0664 LossAtt 0.4720 TrainAcc 0.9900 TestAcc 0.8441 0.9700
epoch 1800 LossPred 0.0369 LossAtt 0.4440 TrainAcc 0.9900 TestAcc 0.8388 0.9700
epoch 1900 LossPred 0.0209 LossAtt 0.4606 TrainAcc 0.9900 TestAcc 0.8408 0.9750
epoch 2000 LossPred 0.0479 LossAtt 0.5164 TrainAcc 0.9900 TestAcc 0.8238 0.9450
epoch 2100 LossPred 0.0383 LossAtt 0.5056 TrainAcc 0.9800 TestAcc 0.8043 0.9600
epoch 2200 LossPred 0.0151 LossAtt 0.4611 TrainAcc 1.0000 TestAcc 0.8078 0.9500
Optimization Finished!
********** replication  99  **********
epoch   0 LossPred 1.0576 LossAtt 1.0076 TrainAcc 0.4900 TestAcc 0.5025 0.4850
epoch 100 LossPred 0.9273 LossAtt 0.6634 TrainAcc 0.6100 TestAcc 0.5363 0.6100
epoch 200 LossPred 0.5856 LossAtt 0.8605 TrainAcc 0.8400 TestAcc 0.7705 0.8300
epoch 300 LossPred 0.2378 LossAtt 0.6019 TrainAcc 0.9600 TestAcc 0.8423 0.8800
epoch 400 LossPred 0.1699 LossAtt 0.5469 TrainAcc 0.9800 TestAcc 0.8426 0.9000
epoch 500 LossPred 0.1342 LossAtt 0.5425 TrainAcc 0.9800 TestAcc 0.8438 0.9200
epoch 600 LossPred 0.1765 LossAtt 0.5783 TrainAcc 0.9600 TestAcc 0.8368 0.9050
epoch 700 LossPred 0.0800 LossAtt 0.4935 TrainAcc 0.9900 TestAcc 0.8391 0.9100
epoch 800 LossPred 0.0809 LossAtt 0.4801 TrainAcc 0.9900 TestAcc 0.8351 0.9000
epoch 900 LossPred 0.0663 LossAtt 0.4728 TrainAcc 0.9900 TestAcc 0.8348 0.9200
epoch 1000 LossPred 0.0654 LossAtt 0.4592 TrainAcc 0.9900 TestAcc 0.8393 0.9200
epoch 1100 LossPred 0.0636 LossAtt 0.4549 TrainAcc 0.9900 TestAcc 0.8453 0.9350
epoch 1200 LossPred 0.0592 LossAtt 0.4471 TrainAcc 0.9900 TestAcc 0.8366 0.9350
epoch 1300 LossPred 0.0560 LossAtt 0.4984 TrainAcc 0.9800 TestAcc 0.8346 0.9550
epoch 1400 LossPred 0.0278 LossAtt 0.4524 TrainAcc 1.0000 TestAcc 0.8408 0.9300
Optimization Finished!
********************************************************************
Namespace(arch='tanh', batch_size=256, display_epoch=100, early_stop=True, input_noise_level=0.15, latent_attractor_space=True, loss_switch_frequency=0, lrate_attractor=0.002, lrate_prediction=0.002, lrate_wt_penalty=0.0, n_attractor_hidden=20, n_attractor_steps=5, n_hidden=10, n_replications=100, noise_level=0.25, report_best_train_performance=True, seq_len=30, task='majority', train_attr_weights_on_prediction=True, training_epochs=2500)
********************************************************************
mean train accuracy 0.9736999
indiv runs  [0.94, 0.94, 1.0, 1.0, 1.0, 0.95, 0.95, 0.97, 1.0, 0.96, 1.0, 0.99, 1.0, 0.98, 0.99, 0.97, 0.97, 0.91, 0.97, 0.93, 0.99, 0.95, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 0.96, 0.92, 0.98, 0.97, 1.0, 0.94, 0.99, 0.96, 0.97, 0.93, 1.0, 0.99, 0.98, 0.99, 0.94, 0.99, 0.92, 0.95, 0.99, 1.0, 0.97, 0.94, 0.97, 0.98, 0.84, 0.98, 1.0, 0.99, 0.96, 0.98, 0.96, 1.0, 1.0, 0.95, 0.99, 0.97, 0.99, 0.96, 0.95, 1.0, 1.0, 1.0, 1.0, 0.99, 0.97, 0.94, 0.93, 0.98, 0.99, 0.98, 0.97, 1.0, 0.92, 0.97, 0.98, 1.0, 0.99, 0.99, 0.93, 0.97, 1.0, 0.88, 0.99, 0.99, 0.99, 0.98, 0.97, 0.98, 0.99, 1.0, 1.0, 1.0]
mean epoch 1515.81481481
indiv epochs  [1801, 1401, 2001, 1301, 1301, 901, 1401, 801, 1101, 2301, 501, 901, 1301, 1301, 601, 2001, 1501, 1901, 2501, 1101, 2501, 801, 2301, 1801, 2001, 2201, 1401]
test1 accuracy mean  0.7644771  median  0.8337087
test2 accuracy mean  0.89245  median  0.9025
test1 indiv runs  [0.5415415, 0.8038038, 0.8611111, 0.8165666, 0.495996, 0.5650651, 0.8513514, 0.8150651, 0.8413413, 0.8173173, 0.9364364, 0.6063564, 0.8876376, 0.8828829, 0.7735235, 0.8330831, 0.8586086, 0.49324325, 0.8485986, 0.8443443, 0.9071572, 0.8518519, 0.8666166, 0.8320821, 0.5325325, 0.8678679, 0.8343343, 0.8380881, 0.5092593, 0.8541041, 0.8988989, 0.5322823, 0.8413413, 0.7324825, 0.8886386, 0.8118118, 0.5287788, 0.547047, 0.8616116, 0.8438438, 0.5620621, 0.8623624, 0.5427928, 0.8573574, 0.5482983, 0.779029, 0.7152152, 0.8791291, 0.8611111, 0.8290791, 0.8223223, 0.8646146, 0.773023, 0.8693694, 0.8693694, 0.8786286, 0.8591091, 0.5950951, 0.8430931, 0.9534535, 0.8538539, 0.5715716, 0.8168168, 0.5015015, 0.6058559, 0.8478478, 0.5025025, 0.6008509, 0.6861862, 0.782032, 0.8843844, 0.5315315, 0.5500501, 0.8250751, 0.8345846, 0.8593594, 0.8613614, 0.8596096, 0.8428428, 0.8443443, 0.7464965, 0.9061562, 0.8668669, 0.8358358, 0.8586086, 0.5670671, 0.8686186, 0.8275776, 0.5095095, 0.8095596, 0.5312813, 0.8976476, 0.8523524, 0.8260761, 0.5277778, 0.5442943, 0.7927928, 0.8493493, 0.8078078, 0.8408408]
test2 indiv runs  [0.8, 0.88, 0.94, 0.955, 0.84, 0.85, 0.915, 0.875, 0.91, 0.91, 0.935, 0.895, 0.925, 0.93, 0.95, 0.93, 0.94, 0.78, 0.885, 0.875, 0.94, 0.88, 0.94, 0.94, 0.82, 0.945, 0.94, 0.93, 0.87, 0.885, 0.935, 0.855, 0.88, 0.88, 0.895, 0.885, 0.825, 0.85, 0.95, 0.93, 0.8, 0.945, 0.82, 0.955, 0.805, 0.9, 0.87, 0.925, 0.84, 0.885, 0.93, 0.935, 0.77, 0.9, 0.91, 0.92, 0.855, 0.85, 0.885, 0.975, 0.97, 0.79, 0.97, 0.77, 0.83, 0.91, 0.815, 0.895, 0.88, 0.96, 0.96, 0.89, 0.84, 0.91, 0.855, 0.91, 0.945, 0.945, 0.9, 0.905, 0.86, 0.94, 0.9, 0.925, 0.945, 0.925, 0.91, 0.905, 0.82, 0.83, 0.8, 0.92, 0.91, 0.91, 0.845, 0.75, 0.955, 0.895, 0.95, 0.93]
