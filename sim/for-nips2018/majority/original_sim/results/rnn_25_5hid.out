Namespace(arch='tanh', batch_size=256, display_epoch=100, input_noise_level=0.15, latent_attractor_space=True, loss_switch_frequency=0, lrate_attractor=0.002, lrate_prediction=0.002, lrate_wt_penalty=0.0, n_attractor_hidden=10, n_attractor_steps=0, n_hidden=5, n_replications=100, noise_level=0.5, report_best_train_performance=True, seq_len=25, task='majority', train_attr_weights_on_prediction=False, training_epochs=2500)
TRAINING ON 100 EXAMPLES, TESTING ON 3996
********** replication  0  **********
epoch   0 LossPred 1.0870 LossAtt 1.0000 TrainAcc 0.4800 TestAcc 0.5263 0.5350
epoch 100 LossPred 0.9047 LossAtt 1.0000 TrainAcc 0.5900 TestAcc 0.5821 0.5900
epoch 200 LossPred 0.8094 LossAtt 1.0000 TrainAcc 0.7000 TestAcc 0.6064 0.6700
epoch 300 LossPred 0.5123 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.7638 0.8150
epoch 400 LossPred 0.3774 LossAtt 1.0000 TrainAcc 0.8600 TestAcc 0.8016 0.8450
epoch 500 LossPred 0.3128 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8341 0.8600
epoch 600 LossPred 0.2249 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8744 0.8700
epoch 700 LossPred 0.1862 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8881 0.9000
epoch 800 LossPred 0.1584 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8824 0.9050
epoch 900 LossPred 0.1421 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8791 0.9050
epoch 1000 LossPred 0.1340 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8756 0.9100
epoch 1100 LossPred 0.1279 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8716 0.9050
epoch 1200 LossPred 0.1218 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8684 0.9100
epoch 1300 LossPred 0.1129 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8621 0.9150
epoch 1400 LossPred 0.0869 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8526 0.9150
epoch 1500 LossPred 0.0664 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8493 0.9300
epoch 1600 LossPred 0.0555 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8411 0.9400
epoch 1700 LossPred 0.0501 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8373 0.9300
epoch 1800 LossPred 0.0470 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8336 0.9200
epoch 1900 LossPred 0.0452 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8346 0.9200
epoch 2000 LossPred 0.0438 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8323 0.9150
epoch 2100 LossPred 0.0428 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8298 0.9100
epoch 2200 LossPred 0.0420 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8276 0.9150
epoch 2300 LossPred 0.0412 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8248 0.9200
epoch 2400 LossPred 0.0406 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8238 0.9150
epoch 2500 LossPred 0.0399 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8238 0.9100
Optimization Finished!
********** replication  1  **********
epoch   0 LossPred 1.1361 LossAtt 1.0000 TrainAcc 0.5500 TestAcc 0.4710 0.5550
epoch 100 LossPred 0.9871 LossAtt 1.0000 TrainAcc 0.5900 TestAcc 0.5040 0.5850
epoch 200 LossPred 0.9522 LossAtt 1.0000 TrainAcc 0.5900 TestAcc 0.5040 0.5900
epoch 300 LossPred 0.7627 LossAtt 1.0000 TrainAcc 0.7400 TestAcc 0.6774 0.7050
epoch 400 LossPred 0.3231 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.8243 0.8250
epoch 500 LossPred 0.2586 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8326 0.8450
epoch 600 LossPred 0.1984 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8353 0.8600
epoch 700 LossPred 0.1820 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8413 0.8750
epoch 800 LossPred 0.1704 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8413 0.8900
epoch 900 LossPred 0.1630 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8373 0.8900
epoch 1000 LossPred 0.1561 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8336 0.8900
epoch 1100 LossPred 0.1483 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8338 0.8850
epoch 1200 LossPred 0.1403 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8363 0.8900
epoch 1300 LossPred 0.1290 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8376 0.8950
epoch 1400 LossPred 0.1174 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8401 0.9050
epoch 1500 LossPred 0.1084 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8396 0.8800
epoch 1600 LossPred 0.1009 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8411 0.8850
epoch 1700 LossPred 0.0941 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8418 0.8900
epoch 1800 LossPred 0.0878 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8416 0.8950
epoch 1900 LossPred 0.0819 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8423 0.9050
epoch 2000 LossPred 0.0767 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8431 0.9100
epoch 2100 LossPred 0.0722 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8413 0.9100
epoch 2200 LossPred 0.0683 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8401 0.9100
epoch 2300 LossPred 0.0650 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8378 0.9100
epoch 2400 LossPred 0.0622 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8368 0.9150
epoch 2500 LossPred 0.0596 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8361 0.9100
Optimization Finished!
********** replication  2  **********
epoch   0 LossPred 1.1509 LossAtt 1.0000 TrainAcc 0.4200 TestAcc 0.4237 0.4200
epoch 100 LossPred 0.9667 LossAtt 1.0000 TrainAcc 0.6300 TestAcc 0.5783 0.6100
epoch 200 LossPred 0.9108 LossAtt 1.0000 TrainAcc 0.6300 TestAcc 0.5783 0.6300
epoch 300 LossPred 0.6292 LossAtt 1.0000 TrainAcc 0.7800 TestAcc 0.8286 0.7750
epoch 400 LossPred 0.4681 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.8504 0.8100
epoch 500 LossPred 0.3922 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.8661 0.8150
epoch 600 LossPred 0.3687 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.8734 0.8100
epoch 700 LossPred 0.3567 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.8801 0.8100
epoch 800 LossPred 0.3186 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.8869 0.8200
epoch 900 LossPred 0.3092 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.8879 0.8250
epoch 1000 LossPred 0.2997 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.8904 0.8350
epoch 1100 LossPred 0.2781 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.8959 0.8300
epoch 1200 LossPred 0.2379 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.9084 0.8300
epoch 1300 LossPred 0.1933 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.9127 0.8450
epoch 1400 LossPred 0.1583 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.9177 0.8650
epoch 1500 LossPred 0.1397 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.9234 0.8750
epoch 1600 LossPred 0.1073 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.9412 0.8850
epoch 1700 LossPred 0.0809 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.9379 0.8800
epoch 1800 LossPred 0.0683 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.9384 0.8850
epoch 1900 LossPred 0.0608 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.9379 0.8850
epoch 2000 LossPred 0.0555 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.9369 0.8850
epoch 2100 LossPred 0.0519 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.9372 0.8850
epoch 2200 LossPred 0.0493 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.9362 0.8850
epoch 2300 LossPred 0.0474 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.9357 0.8850
epoch 2400 LossPred 0.0459 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.9367 0.8850
epoch 2500 LossPred 0.0448 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.9354 0.8850
Optimization Finished!
********** replication  3  **********
epoch   0 LossPred 1.0941 LossAtt 1.0000 TrainAcc 0.4500 TestAcc 0.4139 0.4650
epoch 100 LossPred 0.9690 LossAtt 1.0000 TrainAcc 0.6000 TestAcc 0.5901 0.5800
epoch 200 LossPred 0.5729 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.7820 0.8300
epoch 300 LossPred 0.4659 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.8161 0.8450
epoch 400 LossPred 0.4464 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.8161 0.8750
epoch 500 LossPred 0.3999 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.8071 0.8450
epoch 600 LossPred 0.4284 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.8156 0.8400
epoch 700 LossPred 0.3803 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.8006 0.8600
epoch 800 LossPred 0.3659 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.8011 0.8500
epoch 900 LossPred 0.3513 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.8103 0.8500
epoch 1000 LossPred 0.3354 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8108 0.8550
epoch 1100 LossPred 0.3284 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8091 0.8600
epoch 1200 LossPred 0.3237 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8093 0.8650
epoch 1300 LossPred 0.3199 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8086 0.8650
epoch 1400 LossPred 0.3167 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8091 0.8600
epoch 1500 LossPred 0.3139 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8088 0.8550
epoch 1600 LossPred 0.3854 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.7913 0.8500
epoch 1700 LossPred 0.3462 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.8226 0.8650
epoch 1800 LossPred 0.3284 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8226 0.8750
epoch 1900 LossPred 0.3121 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8263 0.8900
epoch 2000 LossPred 0.2757 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8213 0.9050
epoch 2100 LossPred 0.2607 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8191 0.9050
epoch 2200 LossPred 0.2532 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8196 0.9050
epoch 2300 LossPred 0.2383 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8221 0.9000
epoch 2400 LossPred 0.3171 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8241 0.9100
epoch 2500 LossPred 0.2003 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8173 0.9150
Optimization Finished!
********** replication  4  **********
epoch   0 LossPred 1.3162 LossAtt 1.0000 TrainAcc 0.4400 TestAcc 0.4187 0.4600
epoch 100 LossPred 1.0020 LossAtt 1.0000 TrainAcc 0.4800 TestAcc 0.4867 0.5000
epoch 200 LossPred 0.8521 LossAtt 1.0000 TrainAcc 0.6800 TestAcc 0.6239 0.6750
epoch 300 LossPred 0.3477 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8458 0.8750
epoch 400 LossPred 0.2998 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8378 0.8850
epoch 500 LossPred 0.2823 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8371 0.8850
epoch 600 LossPred 0.2691 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8363 0.8950
epoch 700 LossPred 0.2338 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8353 0.8900
epoch 800 LossPred 0.1929 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8408 0.8850
epoch 900 LossPred 0.1833 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8363 0.8950
epoch 1000 LossPred 0.1763 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8331 0.9050
epoch 1100 LossPred 0.1695 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8301 0.9100
epoch 1200 LossPred 0.1634 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8276 0.9000
epoch 1300 LossPred 0.1587 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8226 0.9000
epoch 1400 LossPred 0.1614 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8228 0.8950
epoch 1500 LossPred 0.1520 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8243 0.9050
epoch 1600 LossPred 0.1679 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8333 0.8900
epoch 1700 LossPred 0.1375 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8258 0.9000
epoch 1800 LossPred 0.1301 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8268 0.9050
epoch 1900 LossPred 0.1276 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8263 0.9000
epoch 2000 LossPred 0.1255 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8266 0.9000
epoch 2100 LossPred 0.1235 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8261 0.9000
epoch 2200 LossPred 0.1217 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8273 0.9050
epoch 2300 LossPred 0.1197 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8286 0.9050
epoch 2400 LossPred 0.1177 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8281 0.9050
epoch 2500 LossPred 0.1154 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8291 0.9050
Optimization Finished!
********** replication  5  **********
epoch   0 LossPred 1.0189 LossAtt 1.0000 TrainAcc 0.5700 TestAcc 0.5385 0.5600
epoch 100 LossPred 0.9401 LossAtt 1.0000 TrainAcc 0.6200 TestAcc 0.5548 0.6250
epoch 200 LossPred 0.9256 LossAtt 1.0000 TrainAcc 0.5900 TestAcc 0.5395 0.6100
epoch 300 LossPred 0.8679 LossAtt 1.0000 TrainAcc 0.6700 TestAcc 0.5598 0.6350
epoch 400 LossPred 0.8044 LossAtt 1.0000 TrainAcc 0.7200 TestAcc 0.5561 0.6800
epoch 500 LossPred 0.6681 LossAtt 1.0000 TrainAcc 0.7400 TestAcc 0.5483 0.6600
epoch 600 LossPred 0.6151 LossAtt 1.0000 TrainAcc 0.7700 TestAcc 0.5478 0.7100
epoch 700 LossPred 0.5884 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.5488 0.7100
epoch 800 LossPred 0.5693 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.5398 0.7300
epoch 900 LossPred 0.5555 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.5408 0.7400
epoch 1000 LossPred 0.5451 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5485 0.7350
epoch 1100 LossPred 0.5358 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5468 0.7350
epoch 1200 LossPred 0.5268 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5495 0.7300
epoch 1300 LossPred 0.5183 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5531 0.7200
epoch 1400 LossPred 0.5092 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5521 0.7300
epoch 1500 LossPred 0.4992 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5516 0.7300
epoch 1600 LossPred 0.4875 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.5493 0.7350
epoch 1700 LossPred 0.4770 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.5470 0.7250
epoch 1800 LossPred 0.4681 LossAtt 1.0000 TrainAcc 0.8600 TestAcc 0.5490 0.7150
epoch 1900 LossPred 0.4600 LossAtt 1.0000 TrainAcc 0.8600 TestAcc 0.5521 0.7150
epoch 2000 LossPred 0.4523 LossAtt 1.0000 TrainAcc 0.8600 TestAcc 0.5506 0.7100
epoch 2100 LossPred 0.4455 LossAtt 1.0000 TrainAcc 0.8600 TestAcc 0.5521 0.7000
epoch 2200 LossPred 0.4384 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.5503 0.6950
epoch 2300 LossPred 0.5051 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.5533 0.7150
epoch 2400 LossPred 0.4678 LossAtt 1.0000 TrainAcc 0.8600 TestAcc 0.5493 0.7150
epoch 2500 LossPred 0.4598 LossAtt 1.0000 TrainAcc 0.8600 TestAcc 0.5516 0.7100
Optimization Finished!
********** replication  6  **********
epoch   0 LossPred 1.0240 LossAtt 1.0000 TrainAcc 0.4800 TestAcc 0.4652 0.4950
epoch 100 LossPred 0.9098 LossAtt 1.0000 TrainAcc 0.6400 TestAcc 0.5343 0.6150
epoch 200 LossPred 0.8346 LossAtt 1.0000 TrainAcc 0.6700 TestAcc 0.5596 0.6450
epoch 300 LossPred 0.6709 LossAtt 1.0000 TrainAcc 0.7900 TestAcc 0.6191 0.7400
epoch 400 LossPred 0.5760 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.6502 0.8050
epoch 500 LossPred 0.5356 LossAtt 1.0000 TrainAcc 0.8600 TestAcc 0.6542 0.8050
epoch 600 LossPred 0.5009 LossAtt 1.0000 TrainAcc 0.8600 TestAcc 0.6496 0.7950
epoch 700 LossPred 0.4889 LossAtt 1.0000 TrainAcc 0.8600 TestAcc 0.6466 0.7850
epoch 800 LossPred 0.4749 LossAtt 1.0000 TrainAcc 0.8600 TestAcc 0.6471 0.7750
epoch 900 LossPred 0.4616 LossAtt 1.0000 TrainAcc 0.8600 TestAcc 0.6469 0.7750
epoch 1000 LossPred 0.4536 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.6461 0.7800
epoch 1100 LossPred 0.4464 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.6389 0.8000
epoch 1200 LossPred 0.4398 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.6406 0.7950
epoch 1300 LossPred 0.4347 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.6441 0.7950
epoch 1400 LossPred 0.4276 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.6434 0.7950
epoch 1500 LossPred 0.4164 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.6449 0.8050
epoch 1600 LossPred 0.4491 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.6449 0.7900
epoch 1700 LossPred 0.4105 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.6522 0.8050
epoch 1800 LossPred 0.4213 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.6499 0.8150
epoch 1900 LossPred 0.4009 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.6607 0.7950
epoch 2000 LossPred 0.3935 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.6572 0.7900
epoch 2100 LossPred 0.3900 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.6589 0.7900
epoch 2200 LossPred 0.3879 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.6619 0.7850
epoch 2300 LossPred 0.3830 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.6622 0.7850
epoch 2400 LossPred 0.3809 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.6617 0.7700
epoch 2500 LossPred 0.3785 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.6584 0.7700
Optimization Finished!
********** replication  7  **********
epoch   0 LossPred 1.0369 LossAtt 1.0000 TrainAcc 0.5300 TestAcc 0.5636 0.5200
epoch 100 LossPred 0.9571 LossAtt 1.0000 TrainAcc 0.6100 TestAcc 0.5180 0.5950
epoch 200 LossPred 0.8821 LossAtt 1.0000 TrainAcc 0.5800 TestAcc 0.6109 0.5800
epoch 300 LossPred 0.3094 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8181 0.8800
epoch 400 LossPred 0.2365 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8158 0.8900
epoch 500 LossPred 0.1980 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8118 0.8850
epoch 600 LossPred 0.1611 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8081 0.9050
epoch 700 LossPred 0.1387 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8086 0.9000
epoch 800 LossPred 0.1257 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8128 0.9000
epoch 900 LossPred 0.1129 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8003 0.8800
epoch 1000 LossPred 0.0990 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.7898 0.8800
epoch 1100 LossPred 0.1399 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8158 0.8600
epoch 1200 LossPred 0.0911 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.7998 0.8800
epoch 1300 LossPred 0.0827 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.7908 0.8950
epoch 1400 LossPred 0.0742 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.7903 0.9050
epoch 1500 LossPred 0.0698 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.7875 0.9100
epoch 1600 LossPred 0.0661 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.7840 0.9100
epoch 1700 LossPred 0.0628 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.7860 0.9050
epoch 1800 LossPred 0.0597 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.7838 0.9000
epoch 1900 LossPred 0.0569 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.7830 0.9000
epoch 2000 LossPred 0.0546 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.7843 0.8900
epoch 2100 LossPred 0.0526 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.7845 0.8950
epoch 2200 LossPred 0.0506 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.7830 0.8800
epoch 2300 LossPred 0.0485 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.7825 0.8800
epoch 2400 LossPred 0.0460 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.7855 0.8750
epoch 2500 LossPred 0.0431 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.7855 0.8700
Optimization Finished!
********** replication  8  **********
epoch   0 LossPred 1.0634 LossAtt 1.0000 TrainAcc 0.5700 TestAcc 0.4920 0.5700
epoch 100 LossPred 0.8933 LossAtt 1.0000 TrainAcc 0.6300 TestAcc 0.5618 0.6250
epoch 200 LossPred 0.7148 LossAtt 1.0000 TrainAcc 0.7700 TestAcc 0.6837 0.7500
epoch 300 LossPred 0.3796 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.8203 0.8800
epoch 400 LossPred 0.2880 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8203 0.8700
epoch 500 LossPred 0.2666 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8271 0.8800
epoch 600 LossPred 0.2482 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8323 0.8650
epoch 700 LossPred 0.2190 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8348 0.8800
epoch 800 LossPred 0.2075 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8391 0.8850
epoch 900 LossPred 0.2013 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8473 0.8900
epoch 1000 LossPred 0.1417 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8731 0.9050
epoch 1100 LossPred 0.1337 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8709 0.9100
epoch 1200 LossPred 0.1291 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8709 0.9200
epoch 1300 LossPred 0.1254 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8701 0.9200
epoch 1400 LossPred 0.0927 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8686 0.9300
epoch 1500 LossPred 0.0872 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8686 0.9300
epoch 1600 LossPred 0.0843 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8656 0.9300
epoch 1700 LossPred 0.0818 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8656 0.9400
epoch 1800 LossPred 0.0791 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8646 0.9450
epoch 1900 LossPred 0.0761 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8626 0.9300
epoch 2000 LossPred 0.0739 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8611 0.9350
epoch 2100 LossPred 0.0726 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8624 0.9350
epoch 2200 LossPred 0.0715 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8631 0.9350
epoch 2300 LossPred 0.0707 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8626 0.9350
epoch 2400 LossPred 0.0699 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8621 0.9350
epoch 2500 LossPred 0.0692 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8624 0.9300
Optimization Finished!
********** replication  9  **********
epoch   0 LossPred 0.9695 LossAtt 1.0000 TrainAcc 0.5800 TestAcc 0.5473 0.5650
epoch 100 LossPred 0.9244 LossAtt 1.0000 TrainAcc 0.6300 TestAcc 0.5370 0.5850
epoch 200 LossPred 0.8738 LossAtt 1.0000 TrainAcc 0.6600 TestAcc 0.5638 0.6400
epoch 300 LossPred 0.7532 LossAtt 1.0000 TrainAcc 0.7200 TestAcc 0.6699 0.6950
epoch 400 LossPred 0.3100 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.7995 0.8500
epoch 500 LossPred 0.2627 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8038 0.8750
epoch 600 LossPred 0.2395 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8028 0.8700
epoch 700 LossPred 0.2224 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.7988 0.8700
epoch 800 LossPred 0.2108 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.7953 0.8700
epoch 900 LossPred 0.2028 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.7918 0.8600
epoch 1000 LossPred 0.1969 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.7888 0.8550
epoch 1100 LossPred 0.1925 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.7853 0.8550
epoch 1200 LossPred 0.1890 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.7823 0.8500
epoch 1300 LossPred 0.1861 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.7818 0.8500
epoch 1400 LossPred 0.1836 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.7800 0.8500
epoch 1500 LossPred 0.1708 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.7838 0.8600
epoch 1600 LossPred 0.1632 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.7878 0.8850
epoch 1700 LossPred 0.1498 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.7875 0.8750
epoch 1800 LossPred 0.1460 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.7885 0.8700
epoch 1900 LossPred 0.1425 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.7870 0.8650
epoch 2000 LossPred 0.1395 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.7865 0.8700
epoch 2100 LossPred 0.1369 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.7868 0.8700
epoch 2200 LossPred 0.1348 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.7865 0.8700
epoch 2300 LossPred 0.1328 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.7858 0.8700
epoch 2400 LossPred 0.1309 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.7850 0.8700
epoch 2500 LossPred 0.1292 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.7830 0.8700
Optimization Finished!
********** replication  10  **********
epoch   0 LossPred 1.1260 LossAtt 1.0000 TrainAcc 0.5500 TestAcc 0.5801 0.5500
epoch 100 LossPred 0.8227 LossAtt 1.0000 TrainAcc 0.7200 TestAcc 0.6309 0.6750
epoch 200 LossPred 0.4498 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.8046 0.7950
epoch 300 LossPred 0.3972 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.8083 0.7950
epoch 400 LossPred 0.3762 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.8088 0.8100
epoch 500 LossPred 0.3646 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.8096 0.8000
epoch 600 LossPred 0.3567 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.8091 0.8050
epoch 700 LossPred 0.3508 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.8091 0.8150
epoch 800 LossPred 0.3458 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.8106 0.8150
epoch 900 LossPred 0.3413 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.8086 0.8150
epoch 1000 LossPred 0.3370 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.8073 0.8150
epoch 1100 LossPred 0.3326 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8063 0.8100
epoch 1200 LossPred 0.3278 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8053 0.8100
epoch 1300 LossPred 0.3221 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8041 0.8100
epoch 1400 LossPred 0.3145 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8018 0.8150
epoch 1500 LossPred 0.3047 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.7958 0.7950
epoch 1600 LossPred 0.2972 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.7940 0.8050
epoch 1700 LossPred 0.3321 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.8223 0.8250
epoch 1800 LossPred 0.3092 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.8141 0.8300
epoch 1900 LossPred 0.2892 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8151 0.8350
epoch 2000 LossPred 0.2705 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8153 0.8350
epoch 2100 LossPred 0.2640 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8138 0.8300
epoch 2200 LossPred 0.2559 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8108 0.8500
epoch 2300 LossPred 0.2508 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8093 0.8500
epoch 2400 LossPred 0.2464 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8083 0.8500
epoch 2500 LossPred 0.2423 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8071 0.8600
Optimization Finished!
********** replication  11  **********
epoch   0 LossPred 1.2440 LossAtt 1.0000 TrainAcc 0.4800 TestAcc 0.5048 0.4750
epoch 100 LossPred 0.9756 LossAtt 1.0000 TrainAcc 0.5900 TestAcc 0.5118 0.5550
epoch 200 LossPred 0.9217 LossAtt 1.0000 TrainAcc 0.6300 TestAcc 0.5596 0.6350
epoch 300 LossPred 0.5295 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.7643 0.8550
epoch 400 LossPred 0.3385 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.8401 0.8950
epoch 500 LossPred 0.2699 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8451 0.9100
epoch 600 LossPred 0.2389 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8564 0.9300
epoch 700 LossPred 0.1831 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8639 0.9250
epoch 800 LossPred 0.1582 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8599 0.9450
epoch 900 LossPred 0.1428 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8636 0.9400
epoch 1000 LossPred 0.1306 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8644 0.9400
epoch 1100 LossPred 0.1162 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8666 0.9450
epoch 1200 LossPred 0.0957 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8689 0.9300
epoch 1300 LossPred 0.0771 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8694 0.9300
epoch 1400 LossPred 0.2216 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8554 0.8950
epoch 1500 LossPred 0.0626 LossAtt 1.0000 TrainAcc 1.0000 TestAcc 0.8671 0.9500
Optimization Finished!
********** replication  12  **********
epoch   0 LossPred 1.2415 LossAtt 1.0000 TrainAcc 0.5100 TestAcc 0.5425 0.5200
epoch 100 LossPred 0.9544 LossAtt 1.0000 TrainAcc 0.6000 TestAcc 0.5638 0.6050
epoch 200 LossPred 0.8671 LossAtt 1.0000 TrainAcc 0.6500 TestAcc 0.5358 0.6800
epoch 300 LossPred 0.8241 LossAtt 1.0000 TrainAcc 0.6700 TestAcc 0.5405 0.7050
epoch 400 LossPred 0.7744 LossAtt 1.0000 TrainAcc 0.7100 TestAcc 0.5390 0.7350
epoch 500 LossPred 0.7103 LossAtt 1.0000 TrainAcc 0.7500 TestAcc 0.5248 0.7550
epoch 600 LossPred 0.6759 LossAtt 1.0000 TrainAcc 0.7900 TestAcc 0.5293 0.7500
epoch 700 LossPred 0.6656 LossAtt 1.0000 TrainAcc 0.7900 TestAcc 0.5280 0.7500
epoch 800 LossPred 0.6550 LossAtt 1.0000 TrainAcc 0.7900 TestAcc 0.5248 0.7550
epoch 900 LossPred 0.6456 LossAtt 1.0000 TrainAcc 0.7800 TestAcc 0.5208 0.7600
epoch 1000 LossPred 0.6369 LossAtt 1.0000 TrainAcc 0.7800 TestAcc 0.5200 0.7500
epoch 1100 LossPred 0.6285 LossAtt 1.0000 TrainAcc 0.7800 TestAcc 0.5215 0.7500
epoch 1200 LossPred 0.6234 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.5235 0.7400
epoch 1300 LossPred 0.6133 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.5215 0.7400
epoch 1400 LossPred 0.6051 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.5245 0.7400
epoch 1500 LossPred 0.5755 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.5238 0.7550
epoch 1600 LossPred 0.5598 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.5250 0.7550
epoch 1700 LossPred 0.5344 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5238 0.7500
epoch 1800 LossPred 0.5215 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5255 0.7350
epoch 1900 LossPred 0.5137 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5225 0.7300
epoch 2000 LossPred 0.5083 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5218 0.7350
epoch 2100 LossPred 0.5039 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5205 0.7450
epoch 2200 LossPred 0.4965 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5178 0.7400
epoch 2300 LossPred 0.6530 LossAtt 1.0000 TrainAcc 0.7800 TestAcc 0.5153 0.7200
epoch 2400 LossPred 0.5377 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.5115 0.7200
epoch 2500 LossPred 0.5298 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5130 0.7200
Optimization Finished!
********** replication  13  **********
epoch   0 LossPred 1.0582 LossAtt 1.0000 TrainAcc 0.5300 TestAcc 0.5315 0.5550
epoch 100 LossPred 0.8840 LossAtt 1.0000 TrainAcc 0.6600 TestAcc 0.5613 0.6550
epoch 200 LossPred 0.7844 LossAtt 1.0000 TrainAcc 0.7400 TestAcc 0.5956 0.7100
epoch 300 LossPred 0.2894 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8468 0.9000
epoch 400 LossPred 0.1689 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8596 0.9200
epoch 500 LossPred 0.1281 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8611 0.9250
epoch 600 LossPred 0.1049 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8639 0.9400
epoch 700 LossPred 0.0921 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8654 0.9500
epoch 800 LossPred 0.0829 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8674 0.9500
epoch 900 LossPred 0.0730 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8711 0.9450
epoch 1000 LossPred 0.0582 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8709 0.9500
epoch 1100 LossPred 0.0407 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8649 0.9400
epoch 1200 LossPred 0.0299 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8636 0.9350
epoch 1300 LossPred 0.0227 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8611 0.9300
epoch 1400 LossPred 0.0179 LossAtt 1.0000 TrainAcc 1.0000 TestAcc 0.8599 0.9350
Optimization Finished!
********** replication  14  **********
epoch   0 LossPred 1.0235 LossAtt 1.0000 TrainAcc 0.5700 TestAcc 0.5298 0.5700
epoch 100 LossPred 0.8641 LossAtt 1.0000 TrainAcc 0.6700 TestAcc 0.6481 0.6700
epoch 200 LossPred 0.3960 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8724 0.8850
epoch 300 LossPred 0.2835 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8576 0.8900
epoch 400 LossPred 0.2158 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8448 0.9000
epoch 500 LossPred 0.1784 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8423 0.9050
epoch 600 LossPred 0.1576 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8461 0.9100
epoch 700 LossPred 0.1423 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8531 0.9200
epoch 800 LossPred 0.1296 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8569 0.9200
epoch 900 LossPred 0.1179 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8634 0.9150
epoch 1000 LossPred 0.1062 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8679 0.9000
epoch 1100 LossPred 0.0813 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8844 0.9000
epoch 1200 LossPred 0.0674 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8816 0.9100
epoch 1300 LossPred 0.0586 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8771 0.9100
epoch 1400 LossPred 0.0512 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8759 0.9100
epoch 1500 LossPred 0.0430 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8691 0.9100
epoch 1600 LossPred 0.0343 LossAtt 1.0000 TrainAcc 1.0000 TestAcc 0.8636 0.9100
Optimization Finished!
********** replication  15  **********
epoch   0 LossPred 0.9850 LossAtt 1.0000 TrainAcc 0.5600 TestAcc 0.5488 0.5700
epoch 100 LossPred 0.8768 LossAtt 1.0000 TrainAcc 0.6400 TestAcc 0.5726 0.6200
epoch 200 LossPred 0.7306 LossAtt 1.0000 TrainAcc 0.7600 TestAcc 0.6869 0.7050
epoch 300 LossPred 0.3858 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.8546 0.8700
epoch 400 LossPred 0.3494 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.8596 0.8800
epoch 500 LossPred 0.3179 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.8629 0.8800
epoch 600 LossPred 0.2213 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.9154 0.8900
epoch 700 LossPred 0.0693 LossAtt 1.0000 TrainAcc 1.0000 TestAcc 0.9567 0.8950
Optimization Finished!
********** replication  16  **********
epoch   0 LossPred 1.0279 LossAtt 1.0000 TrainAcc 0.5400 TestAcc 0.5173 0.5500
epoch 100 LossPred 0.9157 LossAtt 1.0000 TrainAcc 0.6000 TestAcc 0.5030 0.6100
epoch 200 LossPred 0.8696 LossAtt 1.0000 TrainAcc 0.6500 TestAcc 0.5153 0.6600
epoch 300 LossPred 0.7284 LossAtt 1.0000 TrainAcc 0.7500 TestAcc 0.5801 0.7250
epoch 400 LossPred 0.6102 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.5711 0.7150
epoch 500 LossPred 0.5399 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.5841 0.7100
epoch 600 LossPred 0.4951 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5916 0.7550
epoch 700 LossPred 0.4724 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.5906 0.7550
epoch 800 LossPred 0.4497 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.5921 0.7600
epoch 900 LossPred 0.4332 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.5943 0.7550
epoch 1000 LossPred 0.4217 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.6001 0.7500
epoch 1100 LossPred 0.4115 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.6034 0.7550
epoch 1200 LossPred 0.3993 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.6034 0.7500
epoch 1300 LossPred 0.3931 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.6011 0.7650
epoch 1400 LossPred 0.4075 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.6031 0.7800
epoch 1500 LossPred 0.3858 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.5968 0.8000
epoch 1600 LossPred 0.3735 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.5926 0.7900
epoch 1700 LossPred 0.3644 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.5933 0.7900
epoch 1800 LossPred 0.3547 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.5938 0.7850
epoch 1900 LossPred 0.3658 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.5926 0.7750
epoch 2000 LossPred 0.3409 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.5948 0.7650
epoch 2100 LossPred 0.3163 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.5931 0.7600
epoch 2200 LossPred 0.3106 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.5951 0.7500
epoch 2300 LossPred 0.3316 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.5936 0.7400
epoch 2400 LossPred 0.3164 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.5883 0.7550
epoch 2500 LossPred 0.3435 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.5881 0.7550
Optimization Finished!
********** replication  17  **********
epoch   0 LossPred 1.0777 LossAtt 1.0000 TrainAcc 0.5400 TestAcc 0.5721 0.5450
epoch 100 LossPred 0.9415 LossAtt 1.0000 TrainAcc 0.6100 TestAcc 0.5551 0.6100
epoch 200 LossPred 0.8385 LossAtt 1.0000 TrainAcc 0.6900 TestAcc 0.6151 0.6700
epoch 300 LossPred 0.5249 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.6984 0.7450
epoch 400 LossPred 0.4572 LossAtt 1.0000 TrainAcc 0.8600 TestAcc 0.7135 0.7800
epoch 500 LossPred 0.4265 LossAtt 1.0000 TrainAcc 0.8600 TestAcc 0.7145 0.7900
epoch 600 LossPred 0.4099 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.7185 0.7850
epoch 700 LossPred 0.3962 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.7187 0.7900
epoch 800 LossPred 0.3842 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.7192 0.7850
epoch 900 LossPred 0.3569 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.7272 0.7950
epoch 1000 LossPred 0.3387 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.7305 0.8050
epoch 1100 LossPred 0.3372 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.7315 0.8300
epoch 1200 LossPred 0.3244 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.7295 0.8150
epoch 1300 LossPred 0.3174 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.7255 0.8200
epoch 1400 LossPred 0.3122 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.7245 0.8200
epoch 1500 LossPred 0.3075 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.7260 0.8100
epoch 1600 LossPred 0.3031 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.7270 0.8050
epoch 1700 LossPred 0.2990 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.7272 0.8050
epoch 1800 LossPred 0.2951 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.7277 0.8050
epoch 1900 LossPred 0.2914 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.7262 0.8000
epoch 2000 LossPred 0.2879 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.7247 0.8000
epoch 2100 LossPred 0.2844 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.7275 0.8050
epoch 2200 LossPred 0.2810 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.7290 0.7900
epoch 2300 LossPred 0.2773 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.7305 0.7750
epoch 2400 LossPred 0.5110 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.7045 0.7950
epoch 2500 LossPred 0.4338 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.7080 0.8000
Optimization Finished!
********** replication  18  **********
epoch   0 LossPred 1.2248 LossAtt 1.0000 TrainAcc 0.4800 TestAcc 0.5215 0.5000
epoch 100 LossPred 0.9901 LossAtt 1.0000 TrainAcc 0.5800 TestAcc 0.5611 0.5650
epoch 200 LossPred 0.9405 LossAtt 1.0000 TrainAcc 0.6000 TestAcc 0.5363 0.5900
epoch 300 LossPred 0.9152 LossAtt 1.0000 TrainAcc 0.6100 TestAcc 0.5556 0.5800
epoch 400 LossPred 0.8767 LossAtt 1.0000 TrainAcc 0.6200 TestAcc 0.5576 0.6200
epoch 500 LossPred 0.8362 LossAtt 1.0000 TrainAcc 0.7000 TestAcc 0.5428 0.6700
epoch 600 LossPred 0.7774 LossAtt 1.0000 TrainAcc 0.7500 TestAcc 0.5318 0.7350
epoch 700 LossPred 0.6593 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.5230 0.7200
epoch 800 LossPred 0.6217 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.5230 0.7250
epoch 900 LossPred 0.6064 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.5215 0.7300
epoch 1000 LossPred 0.5972 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.5210 0.7400
epoch 1100 LossPred 0.5906 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.5218 0.7300
epoch 1200 LossPred 0.6000 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.5233 0.7300
epoch 1300 LossPred 0.5893 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.5238 0.7050
epoch 1400 LossPred 0.5819 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.5243 0.7250
epoch 1500 LossPred 0.5767 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.5248 0.7250
epoch 1600 LossPred 0.5707 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.5223 0.7100
epoch 1700 LossPred 0.6167 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.5188 0.7150
epoch 1800 LossPred 0.5734 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.5240 0.7200
epoch 1900 LossPred 0.5677 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.5255 0.7150
epoch 2000 LossPred 0.5632 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.5250 0.7150
epoch 2100 LossPred 0.5592 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.5268 0.7050
epoch 2200 LossPred 0.5549 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.5235 0.7100
epoch 2300 LossPred 0.5504 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.5233 0.7050
epoch 2400 LossPred 0.5460 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.5238 0.7050
epoch 2500 LossPred 0.6871 LossAtt 1.0000 TrainAcc 0.7800 TestAcc 0.5218 0.7250
Optimization Finished!
********** replication  19  **********
epoch   0 LossPred 0.9540 LossAtt 1.0000 TrainAcc 0.5800 TestAcc 0.5358 0.5850
epoch 100 LossPred 0.6520 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.6974 0.7700
epoch 200 LossPred 0.2865 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8644 0.8850
epoch 300 LossPred 0.1758 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8689 0.8650
epoch 400 LossPred 0.1347 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8674 0.8700
epoch 500 LossPred 0.1129 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8679 0.8750
epoch 600 LossPred 0.0986 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8694 0.8850
epoch 700 LossPred 0.0884 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8694 0.8900
epoch 800 LossPred 0.0810 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8699 0.8900
epoch 900 LossPred 0.0753 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8696 0.8900
epoch 1000 LossPred 0.0707 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8679 0.9000
epoch 1100 LossPred 0.0668 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8659 0.9000
epoch 1200 LossPred 0.0636 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8631 0.9050
epoch 1300 LossPred 0.0609 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8601 0.9000
epoch 1400 LossPred 0.0585 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8596 0.9000
epoch 1500 LossPred 0.0564 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8579 0.9000
epoch 1600 LossPred 0.0545 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8549 0.8950
epoch 1700 LossPred 0.0527 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8546 0.8950
epoch 1800 LossPred 0.0510 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8536 0.8900
epoch 1900 LossPred 0.0493 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8541 0.8900
epoch 2000 LossPred 0.0477 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8521 0.9100
epoch 2100 LossPred 0.0453 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8534 0.9100
epoch 2200 LossPred 0.0332 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8569 0.9150
epoch 2300 LossPred 0.0331 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8639 0.9250
epoch 2400 LossPred 0.0272 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8614 0.9350
epoch 2500 LossPred 0.0230 LossAtt 1.0000 TrainAcc 1.0000 TestAcc 0.8596 0.9250
Optimization Finished!
********** replication  20  **********
epoch   0 LossPred 1.2311 LossAtt 1.0000 TrainAcc 0.4800 TestAcc 0.5345 0.4800
epoch 100 LossPred 0.9599 LossAtt 1.0000 TrainAcc 0.5600 TestAcc 0.5460 0.5700
epoch 200 LossPred 0.8901 LossAtt 1.0000 TrainAcc 0.6600 TestAcc 0.6144 0.6600
epoch 300 LossPred 0.6234 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.7663 0.8050
epoch 400 LossPred 0.5543 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.7870 0.8100
epoch 500 LossPred 0.4885 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.7890 0.8300
epoch 600 LossPred 0.4734 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.7710 0.8150
epoch 700 LossPred 0.4912 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.7823 0.8200
epoch 800 LossPred 0.4618 LossAtt 1.0000 TrainAcc 0.8600 TestAcc 0.7845 0.8200
epoch 900 LossPred 0.3683 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.8271 0.8200
epoch 1000 LossPred 0.3509 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.8333 0.8350
epoch 1100 LossPred 0.3437 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.8356 0.8350
epoch 1200 LossPred 0.3376 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.8388 0.8400
epoch 1300 LossPred 0.3320 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8416 0.8450
epoch 1400 LossPred 0.3272 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8446 0.8550
epoch 1500 LossPred 0.3234 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8451 0.8550
epoch 1600 LossPred 0.3202 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8473 0.8550
epoch 1700 LossPred 0.3172 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8476 0.8500
epoch 1800 LossPred 0.3043 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8453 0.8500
epoch 1900 LossPred 0.3240 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.8466 0.8650
epoch 2000 LossPred 0.2779 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8413 0.8450
epoch 2100 LossPred 0.2706 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8466 0.8400
epoch 2200 LossPred 0.2641 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8496 0.8450
epoch 2300 LossPred 0.2589 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8501 0.8450
epoch 2400 LossPred 0.2552 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8514 0.8400
epoch 2500 LossPred 0.2522 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8534 0.8500
Optimization Finished!
********** replication  21  **********
epoch   0 LossPred 0.9814 LossAtt 1.0000 TrainAcc 0.5200 TestAcc 0.5128 0.5300
epoch 100 LossPred 0.8769 LossAtt 1.0000 TrainAcc 0.6600 TestAcc 0.5751 0.6600
epoch 200 LossPred 0.4846 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.8391 0.8600
epoch 300 LossPred 0.2493 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8438 0.9000
epoch 400 LossPred 0.2217 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8466 0.9050
epoch 500 LossPred 0.2085 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8506 0.9050
epoch 600 LossPred 0.1999 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8526 0.9000
epoch 700 LossPred 0.1932 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8536 0.9000
epoch 800 LossPred 0.1839 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8564 0.9050
epoch 900 LossPred 0.1752 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8629 0.9200
epoch 1000 LossPred 0.1649 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8659 0.9100
epoch 1100 LossPred 0.2026 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8639 0.8900
epoch 1200 LossPred 0.1552 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8684 0.9100
epoch 1300 LossPred 0.1478 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8711 0.9100
epoch 1400 LossPred 0.1319 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8699 0.8950
epoch 1500 LossPred 0.1270 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8711 0.8900
epoch 1600 LossPred 0.1253 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8719 0.8850
epoch 1700 LossPred 0.1240 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8719 0.8850
epoch 1800 LossPred 0.1229 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8721 0.8850
epoch 1900 LossPred 0.1220 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8726 0.8850
epoch 2000 LossPred 0.1212 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8734 0.8850
epoch 2100 LossPred 0.1206 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8741 0.8800
epoch 2200 LossPred 0.1197 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8739 0.8850
epoch 2300 LossPred 0.2475 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8483 0.8750
epoch 2400 LossPred 0.1197 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8709 0.8750
epoch 2500 LossPred 0.0911 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8714 0.8700
Optimization Finished!
********** replication  22  **********
epoch   0 LossPred 1.1825 LossAtt 1.0000 TrainAcc 0.5300 TestAcc 0.5005 0.5400
epoch 100 LossPred 0.9307 LossAtt 1.0000 TrainAcc 0.6100 TestAcc 0.5631 0.6200
epoch 200 LossPred 0.9006 LossAtt 1.0000 TrainAcc 0.6500 TestAcc 0.5766 0.6350
epoch 300 LossPred 0.8567 LossAtt 1.0000 TrainAcc 0.6700 TestAcc 0.5923 0.6550
epoch 400 LossPred 0.8256 LossAtt 1.0000 TrainAcc 0.6800 TestAcc 0.5993 0.6650
epoch 500 LossPred 0.7416 LossAtt 1.0000 TrainAcc 0.7600 TestAcc 0.6249 0.6950
epoch 600 LossPred 0.5673 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.7225 0.7450
epoch 700 LossPred 0.4007 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.8056 0.8250
epoch 800 LossPred 0.3113 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8013 0.8350
epoch 900 LossPred 0.2900 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8033 0.8350
epoch 1000 LossPred 0.2425 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8028 0.8550
epoch 1100 LossPred 0.2308 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8041 0.8500
epoch 1200 LossPred 0.2238 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8036 0.8650
epoch 1300 LossPred 0.2195 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8031 0.8650
epoch 1400 LossPred 0.2163 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8023 0.8600
epoch 1500 LossPred 0.2137 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8008 0.8700
epoch 1600 LossPred 0.2116 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.7993 0.8700
epoch 1700 LossPred 0.2096 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.7980 0.8850
epoch 1800 LossPred 0.2079 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.7970 0.8850
epoch 1900 LossPred 0.3090 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8036 0.8700
epoch 2000 LossPred 0.3215 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.8016 0.8400
epoch 2100 LossPred 0.2107 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.7925 0.9000
epoch 2200 LossPred 0.2075 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.7910 0.8900
epoch 2300 LossPred 0.2048 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.7910 0.8900
epoch 2400 LossPred 0.2026 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.7910 0.8900
epoch 2500 LossPred 0.2014 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.7913 0.8900
Optimization Finished!
********** replication  23  **********
epoch   0 LossPred 1.1602 LossAtt 1.0000 TrainAcc 0.5300 TestAcc 0.4364 0.5250
epoch 100 LossPred 0.9777 LossAtt 1.0000 TrainAcc 0.4900 TestAcc 0.4660 0.5100
epoch 200 LossPred 0.9311 LossAtt 1.0000 TrainAcc 0.6400 TestAcc 0.5721 0.6150
epoch 300 LossPred 0.7540 LossAtt 1.0000 TrainAcc 0.7800 TestAcc 0.7615 0.7550
epoch 400 LossPred 0.6706 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.7860 0.7850
epoch 500 LossPred 0.6182 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.8061 0.7900
epoch 600 LossPred 0.5394 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.8218 0.7850
epoch 700 LossPred 0.8522 LossAtt 1.0000 TrainAcc 0.7200 TestAcc 0.6902 0.7200
epoch 800 LossPred 0.7866 LossAtt 1.0000 TrainAcc 0.7000 TestAcc 0.7237 0.7500
epoch 900 LossPred 0.5944 LossAtt 1.0000 TrainAcc 0.7900 TestAcc 0.7520 0.7750
epoch 1000 LossPred 0.5412 LossAtt 1.0000 TrainAcc 0.7900 TestAcc 0.7515 0.7750
epoch 1100 LossPred 0.5053 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.7918 0.7800
epoch 1200 LossPred 0.4754 LossAtt 1.0000 TrainAcc 0.8600 TestAcc 0.8018 0.7750
epoch 1300 LossPred 0.4555 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.8043 0.7750
epoch 1400 LossPred 0.4402 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.8111 0.7650
epoch 1500 LossPred 0.4257 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.8158 0.7700
epoch 1600 LossPred 0.4109 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.8208 0.7800
epoch 1700 LossPred 0.4009 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.8213 0.7800
epoch 1800 LossPred 0.3935 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.8196 0.7950
epoch 1900 LossPred 0.3887 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.8196 0.8100
epoch 2000 LossPred 0.3854 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.8191 0.8100
epoch 2100 LossPred 0.3827 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.8183 0.8100
epoch 2200 LossPred 0.3803 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.8181 0.8150
epoch 2300 LossPred 0.3781 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.8181 0.8150
epoch 2400 LossPred 0.3760 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.8178 0.8200
epoch 2500 LossPred 0.3086 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.8136 0.8250
Optimization Finished!
********** replication  24  **********
epoch   0 LossPred 1.2810 LossAtt 1.0000 TrainAcc 0.4200 TestAcc 0.4647 0.4850
epoch 100 LossPred 0.9886 LossAtt 1.0000 TrainAcc 0.5200 TestAcc 0.4737 0.5100
epoch 200 LossPred 0.7048 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.8266 0.8400
epoch 300 LossPred 0.4848 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.8236 0.8600
epoch 400 LossPred 0.3373 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8501 0.8650
epoch 500 LossPred 0.2835 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8604 0.8700
epoch 600 LossPred 0.2591 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8634 0.8700
epoch 700 LossPred 0.2457 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8679 0.8700
epoch 800 LossPred 0.2366 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8754 0.8650
epoch 900 LossPred 0.2282 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8834 0.8650
epoch 1000 LossPred 0.2089 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.9024 0.8750
epoch 1100 LossPred 0.1654 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.9049 0.8800
epoch 1200 LossPred 0.1358 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8931 0.9000
epoch 1300 LossPred 0.1122 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8876 0.9200
epoch 1400 LossPred 0.1045 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8806 0.9350
epoch 1500 LossPred 0.1005 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8781 0.9350
epoch 1600 LossPred 0.0972 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8764 0.9350
epoch 1700 LossPred 0.0943 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8749 0.9250
epoch 1800 LossPred 0.0912 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8749 0.9250
epoch 1900 LossPred 0.0879 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8746 0.9250
epoch 2000 LossPred 0.0840 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8714 0.9300
epoch 2100 LossPred 0.0855 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8769 0.9400
epoch 2200 LossPred 0.0428 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8739 0.9350
epoch 2300 LossPred 0.0369 LossAtt 1.0000 TrainAcc 1.0000 TestAcc 0.8684 0.9450
Optimization Finished!
********** replication  25  **********
epoch   0 LossPred 1.1725 LossAtt 1.0000 TrainAcc 0.4600 TestAcc 0.4712 0.4500
epoch 100 LossPred 0.9135 LossAtt 1.0000 TrainAcc 0.6400 TestAcc 0.5420 0.6500
epoch 200 LossPred 0.7978 LossAtt 1.0000 TrainAcc 0.7000 TestAcc 0.5475 0.6600
epoch 300 LossPred 0.3740 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8278 0.8550
epoch 400 LossPred 0.2301 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8423 0.8750
epoch 500 LossPred 0.1616 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8391 0.8750
epoch 600 LossPred 0.1267 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8378 0.8850
epoch 700 LossPred 0.1131 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8366 0.8900
epoch 800 LossPred 0.1046 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8356 0.8850
epoch 900 LossPred 0.0983 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8363 0.8850
epoch 1000 LossPred 0.0936 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8381 0.8900
epoch 1100 LossPred 0.0902 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8378 0.8900
epoch 1200 LossPred 0.0876 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8371 0.8900
epoch 1300 LossPred 0.0856 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8346 0.8950
epoch 1400 LossPred 0.0840 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8328 0.8950
epoch 1500 LossPred 0.0827 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8328 0.8950
epoch 1600 LossPred 0.0817 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8331 0.8950
epoch 1700 LossPred 0.0809 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8318 0.8950
epoch 1800 LossPred 0.0802 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8321 0.8900
epoch 1900 LossPred 0.0796 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8321 0.8850
epoch 2000 LossPred 0.0791 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8308 0.8850
epoch 2100 LossPred 0.0786 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8311 0.8900
epoch 2200 LossPred 0.0782 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8318 0.8900
epoch 2300 LossPred 0.0779 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8313 0.8900
epoch 2400 LossPred 0.0776 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8306 0.8900
epoch 2500 LossPred 0.0773 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8301 0.8900
Optimization Finished!
********** replication  26  **********
epoch   0 LossPred 1.0593 LossAtt 1.0000 TrainAcc 0.4300 TestAcc 0.4620 0.4400
epoch 100 LossPred 0.9628 LossAtt 1.0000 TrainAcc 0.5900 TestAcc 0.5228 0.5950
epoch 200 LossPred 0.9293 LossAtt 1.0000 TrainAcc 0.6200 TestAcc 0.5355 0.6200
epoch 300 LossPred 0.8984 LossAtt 1.0000 TrainAcc 0.6600 TestAcc 0.5263 0.6450
epoch 400 LossPred 0.8525 LossAtt 1.0000 TrainAcc 0.6800 TestAcc 0.5388 0.6900
epoch 500 LossPred 0.7846 LossAtt 1.0000 TrainAcc 0.7000 TestAcc 0.5365 0.6850
epoch 600 LossPred 0.7126 LossAtt 1.0000 TrainAcc 0.7600 TestAcc 0.5335 0.7250
epoch 700 LossPred 0.6796 LossAtt 1.0000 TrainAcc 0.7800 TestAcc 0.5378 0.7100
epoch 800 LossPred 0.6236 LossAtt 1.0000 TrainAcc 0.7700 TestAcc 0.5370 0.7000
epoch 900 LossPred 0.5876 LossAtt 1.0000 TrainAcc 0.7800 TestAcc 0.5318 0.7050
epoch 1000 LossPred 0.6024 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.5290 0.7100
epoch 1100 LossPred 0.5837 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.5255 0.7100
epoch 1200 LossPred 0.5688 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.5308 0.7050
epoch 1300 LossPred 0.5554 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5330 0.7050
epoch 1400 LossPred 0.5625 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5385 0.6800
epoch 1500 LossPred 0.5471 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5368 0.6950
epoch 1600 LossPred 0.5401 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.5385 0.7000
epoch 1700 LossPred 0.5297 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5383 0.7100
epoch 1800 LossPred 0.5186 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5405 0.7150
epoch 1900 LossPred 0.5094 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5403 0.7250
epoch 2000 LossPred 0.5016 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5405 0.7100
epoch 2100 LossPred 0.4948 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5365 0.7100
epoch 2200 LossPred 0.4887 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5330 0.7200
epoch 2300 LossPred 0.4829 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5328 0.7250
epoch 2400 LossPred 0.4773 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.5343 0.7250
epoch 2500 LossPred 0.4628 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.5338 0.7250
Optimization Finished!
********** replication  27  **********
epoch   0 LossPred 1.0660 LossAtt 1.0000 TrainAcc 0.5800 TestAcc 0.5918 0.5700
epoch 100 LossPred 0.9402 LossAtt 1.0000 TrainAcc 0.6000 TestAcc 0.6271 0.5900
epoch 200 LossPred 0.9234 LossAtt 1.0000 TrainAcc 0.6200 TestAcc 0.6376 0.6150
epoch 300 LossPred 0.8470 LossAtt 1.0000 TrainAcc 0.6500 TestAcc 0.7050 0.6400
epoch 400 LossPred 0.3481 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8511 0.8800
epoch 500 LossPred 0.2974 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8383 0.8700
epoch 600 LossPred 0.2778 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8378 0.8700
epoch 700 LossPred 0.2657 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8348 0.8600
epoch 800 LossPred 0.2565 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8351 0.8600
epoch 900 LossPred 0.2486 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8331 0.8650
epoch 1000 LossPred 0.2416 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8338 0.8700
epoch 1100 LossPred 0.2369 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8308 0.8600
epoch 1200 LossPred 0.2343 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8318 0.8600
epoch 1300 LossPred 0.2320 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8288 0.8650
epoch 1400 LossPred 0.2297 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8288 0.8600
epoch 1500 LossPred 0.2271 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8288 0.8600
epoch 1600 LossPred 0.2240 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8291 0.8600
epoch 1700 LossPred 0.2176 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8296 0.8650
epoch 1800 LossPred 0.1716 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8226 0.8600
epoch 1900 LossPred 0.1565 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8251 0.8550
epoch 2000 LossPred 0.1509 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8266 0.8550
epoch 2100 LossPred 0.1468 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8241 0.8500
epoch 2200 LossPred 0.1435 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8231 0.8500
epoch 2300 LossPred 0.1406 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8223 0.8500
epoch 2400 LossPred 0.1379 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8221 0.8500
epoch 2500 LossPred 0.1355 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8223 0.8500
Optimization Finished!
********** replication  28  **********
epoch   0 LossPred 1.4902 LossAtt 1.0000 TrainAcc 0.4100 TestAcc 0.4607 0.4150
epoch 100 LossPred 1.0885 LossAtt 1.0000 TrainAcc 0.4300 TestAcc 0.4752 0.4150
epoch 200 LossPred 0.9576 LossAtt 1.0000 TrainAcc 0.6300 TestAcc 0.5936 0.6300
epoch 300 LossPred 0.9170 LossAtt 1.0000 TrainAcc 0.6300 TestAcc 0.5936 0.6300
epoch 400 LossPred 0.8725 LossAtt 1.0000 TrainAcc 0.6500 TestAcc 0.6194 0.6350
epoch 500 LossPred 0.5605 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.8251 0.8350
epoch 600 LossPred 0.4749 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.8081 0.8450
epoch 700 LossPred 0.4355 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.8121 0.8450
epoch 800 LossPred 0.4087 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.8281 0.8550
epoch 900 LossPred 0.3909 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.8303 0.8500
epoch 1000 LossPred 0.3781 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.8333 0.8450
epoch 1100 LossPred 0.3185 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8661 0.8600
epoch 1200 LossPred 0.2471 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8816 0.8900
epoch 1300 LossPred 0.2324 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8811 0.9100
epoch 1400 LossPred 0.2250 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8819 0.9050
epoch 1500 LossPred 0.2048 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8856 0.9000
epoch 1600 LossPred 0.3029 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.8779 0.8900
epoch 1700 LossPred 0.2077 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8856 0.9000
epoch 1800 LossPred 0.1810 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8869 0.8900
epoch 1900 LossPred 0.1685 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8901 0.8900
epoch 2000 LossPred 0.1570 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8934 0.8900
epoch 2100 LossPred 0.1426 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8896 0.8650
epoch 2200 LossPred 0.1347 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8866 0.8650
epoch 2300 LossPred 0.1265 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8866 0.8750
epoch 2400 LossPred 0.1206 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8884 0.8800
epoch 2500 LossPred 0.1147 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8869 0.8750
Optimization Finished!
********** replication  29  **********
epoch   0 LossPred 1.1328 LossAtt 1.0000 TrainAcc 0.5100 TestAcc 0.5158 0.4950
epoch 100 LossPred 0.9652 LossAtt 1.0000 TrainAcc 0.5400 TestAcc 0.5916 0.5450
epoch 200 LossPred 0.8280 LossAtt 1.0000 TrainAcc 0.7400 TestAcc 0.7017 0.7050
epoch 300 LossPred 0.6308 LossAtt 1.0000 TrainAcc 0.7800 TestAcc 0.7670 0.8000
epoch 400 LossPred 0.4025 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8191 0.8750
epoch 500 LossPred 0.3258 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8043 0.8750
epoch 600 LossPred 0.2913 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8041 0.8750
epoch 700 LossPred 0.2582 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8023 0.8800
epoch 800 LossPred 0.2370 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.7998 0.8800
epoch 900 LossPred 0.2213 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8128 0.8900
epoch 1000 LossPred 0.1947 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8138 0.8750
epoch 1100 LossPred 0.1741 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8081 0.8600
epoch 1200 LossPred 0.1591 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.7980 0.8600
epoch 1300 LossPred 0.1288 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.7960 0.8700
epoch 1400 LossPred 0.1201 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.7910 0.8600
epoch 1500 LossPred 0.1141 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.7903 0.8600
epoch 1600 LossPred 0.1092 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.7890 0.8650
epoch 1700 LossPred 0.1049 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.7868 0.8750
epoch 1800 LossPred 0.1011 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.7858 0.8750
epoch 1900 LossPred 0.0978 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.7853 0.8600
epoch 2000 LossPred 0.0951 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.7825 0.8600
epoch 2100 LossPred 0.0927 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.7805 0.8650
epoch 2200 LossPred 0.0907 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.7798 0.8750
epoch 2300 LossPred 0.0889 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.7800 0.8750
epoch 2400 LossPred 0.0873 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.7798 0.8700
epoch 2500 LossPred 0.0861 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.7773 0.8700
Optimization Finished!
********** replication  30  **********
epoch   0 LossPred 1.4896 LossAtt 1.0000 TrainAcc 0.4400 TestAcc 0.5233 0.4600
epoch 100 LossPred 1.1096 LossAtt 1.0000 TrainAcc 0.5100 TestAcc 0.5826 0.4900
epoch 200 LossPred 0.8731 LossAtt 1.0000 TrainAcc 0.7700 TestAcc 0.7200 0.7800
epoch 300 LossPred 0.7514 LossAtt 1.0000 TrainAcc 0.7900 TestAcc 0.6379 0.8000
epoch 400 LossPred 0.7127 LossAtt 1.0000 TrainAcc 0.7700 TestAcc 0.6161 0.7950
epoch 500 LossPred 0.6408 LossAtt 1.0000 TrainAcc 0.7800 TestAcc 0.6049 0.7750
epoch 600 LossPred 0.5972 LossAtt 1.0000 TrainAcc 0.7800 TestAcc 0.6199 0.7850
epoch 700 LossPred 0.5701 LossAtt 1.0000 TrainAcc 0.7800 TestAcc 0.6166 0.7950
epoch 800 LossPred 0.5503 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.6381 0.7900
epoch 900 LossPred 0.5851 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.6499 0.7750
epoch 1000 LossPred 0.5302 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.6977 0.8050
epoch 1100 LossPred 0.4854 LossAtt 1.0000 TrainAcc 0.8600 TestAcc 0.6834 0.7900
epoch 1200 LossPred 0.4740 LossAtt 1.0000 TrainAcc 0.8600 TestAcc 0.6824 0.8000
epoch 1300 LossPred 0.4660 LossAtt 1.0000 TrainAcc 0.8600 TestAcc 0.6879 0.8050
epoch 1400 LossPred 0.4597 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.7070 0.8000
epoch 1500 LossPred 0.4543 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.7087 0.8100
epoch 1600 LossPred 0.4497 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.7070 0.8050
epoch 1700 LossPred 0.4456 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.7015 0.8200
epoch 1800 LossPred 0.4419 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.7022 0.8150
epoch 1900 LossPred 0.4385 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.7050 0.8200
epoch 2000 LossPred 0.5928 LossAtt 1.0000 TrainAcc 0.7900 TestAcc 0.6679 0.7900
epoch 2100 LossPred 0.5313 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.6717 0.7750
epoch 2200 LossPred 0.5260 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.6742 0.7800
epoch 2300 LossPred 0.5217 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.6762 0.7850
epoch 2400 LossPred 0.5175 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.6799 0.7900
epoch 2500 LossPred 0.5131 LossAtt 1.0000 TrainAcc 0.7900 TestAcc 0.6779 0.7950
Optimization Finished!
********** replication  31  **********
epoch   0 LossPred 1.1284 LossAtt 1.0000 TrainAcc 0.5300 TestAcc 0.5618 0.5350
epoch 100 LossPred 0.8616 LossAtt 1.0000 TrainAcc 0.6700 TestAcc 0.6614 0.6600
epoch 200 LossPred 0.5656 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.7765 0.8000
epoch 300 LossPred 0.4383 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.7968 0.8450
epoch 400 LossPred 0.3037 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8136 0.8850
epoch 500 LossPred 0.2748 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8183 0.8850
epoch 600 LossPred 0.2564 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8228 0.8900
epoch 700 LossPred 0.2417 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8273 0.8750
epoch 800 LossPred 0.2276 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8313 0.8700
epoch 900 LossPred 0.2110 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8316 0.8800
epoch 1000 LossPred 0.1963 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8306 0.8850
epoch 1100 LossPred 0.1780 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8358 0.8800
epoch 1200 LossPred 0.1086 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8519 0.9250
epoch 1300 LossPred 0.1012 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8546 0.9150
epoch 1400 LossPred 0.0963 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8549 0.9150
epoch 1500 LossPred 0.0911 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8534 0.9050
epoch 1600 LossPred 0.0822 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8496 0.8900
epoch 1700 LossPred 0.0711 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8453 0.8800
epoch 1800 LossPred 0.0603 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8316 0.8750
epoch 1900 LossPred 0.0495 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8216 0.8850
epoch 2000 LossPred 0.0387 LossAtt 1.0000 TrainAcc 1.0000 TestAcc 0.8126 0.8950
Optimization Finished!
********** replication  32  **********
epoch   0 LossPred 1.1656 LossAtt 1.0000 TrainAcc 0.4800 TestAcc 0.5153 0.5350
epoch 100 LossPred 0.9802 LossAtt 1.0000 TrainAcc 0.5900 TestAcc 0.5736 0.5900
epoch 200 LossPred 0.9153 LossAtt 1.0000 TrainAcc 0.6200 TestAcc 0.5653 0.6300
epoch 300 LossPred 0.8606 LossAtt 1.0000 TrainAcc 0.6600 TestAcc 0.5806 0.6700
epoch 400 LossPred 0.8265 LossAtt 1.0000 TrainAcc 0.6800 TestAcc 0.5891 0.6750
epoch 500 LossPred 0.7939 LossAtt 1.0000 TrainAcc 0.7300 TestAcc 0.5856 0.6800
epoch 600 LossPred 0.7630 LossAtt 1.0000 TrainAcc 0.7300 TestAcc 0.5956 0.6900
epoch 700 LossPred 0.7392 LossAtt 1.0000 TrainAcc 0.7400 TestAcc 0.5948 0.6650
epoch 800 LossPred 0.7226 LossAtt 1.0000 TrainAcc 0.7500 TestAcc 0.5936 0.6600
epoch 900 LossPred 0.7062 LossAtt 1.0000 TrainAcc 0.7600 TestAcc 0.5906 0.6750
epoch 1000 LossPred 0.6652 LossAtt 1.0000 TrainAcc 0.7900 TestAcc 0.5993 0.6850
epoch 1100 LossPred 0.6319 LossAtt 1.0000 TrainAcc 0.7900 TestAcc 0.5916 0.6950
epoch 1200 LossPred 0.6163 LossAtt 1.0000 TrainAcc 0.7900 TestAcc 0.5916 0.6900
epoch 1300 LossPred 0.6024 LossAtt 1.0000 TrainAcc 0.7900 TestAcc 0.5916 0.6900
epoch 1400 LossPred 0.5872 LossAtt 1.0000 TrainAcc 0.7900 TestAcc 0.5931 0.7050
epoch 1500 LossPred 0.5679 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.6029 0.7100
epoch 1600 LossPred 0.5556 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.6024 0.7100
epoch 1700 LossPred 0.5411 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.6051 0.7150
epoch 1800 LossPred 0.5312 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.6041 0.7150
epoch 1900 LossPred 0.5227 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.6051 0.7150
epoch 2000 LossPred 0.5150 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.6049 0.7200
epoch 2100 LossPred 0.5080 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.6044 0.7050
epoch 2200 LossPred 0.5018 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.6019 0.7000
epoch 2300 LossPred 0.5806 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.6014 0.6800
epoch 2400 LossPred 0.5739 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.5996 0.7000
epoch 2500 LossPred 0.5702 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.5978 0.6950
Optimization Finished!
********** replication  33  **********
epoch   0 LossPred 1.0390 LossAtt 1.0000 TrainAcc 0.5600 TestAcc 0.5573 0.5350
epoch 100 LossPred 0.9488 LossAtt 1.0000 TrainAcc 0.5700 TestAcc 0.5193 0.5650
epoch 200 LossPred 0.9289 LossAtt 1.0000 TrainAcc 0.6200 TestAcc 0.5235 0.6100
epoch 300 LossPred 0.7907 LossAtt 1.0000 TrainAcc 0.7300 TestAcc 0.5993 0.7250
epoch 400 LossPred 0.5380 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.7190 0.7850
epoch 500 LossPred 0.4558 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.7360 0.7950
epoch 600 LossPred 0.4233 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.7410 0.8050
epoch 700 LossPred 0.4005 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.7447 0.8050
epoch 800 LossPred 0.3813 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.7480 0.8000
epoch 900 LossPred 0.3650 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.7503 0.7900
epoch 1000 LossPred 0.3790 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.7412 0.8050
epoch 1100 LossPred 0.3314 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.7680 0.8100
epoch 1200 LossPred 0.3165 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.7693 0.8200
epoch 1300 LossPred 0.3083 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.7700 0.8350
epoch 1400 LossPred 0.3010 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.7733 0.8350
epoch 1500 LossPred 0.2945 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.7763 0.8350
epoch 1600 LossPred 0.2760 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.7813 0.8400
epoch 1700 LossPred 0.2544 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.7760 0.8450
epoch 1800 LossPred 0.2484 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.7765 0.8450
epoch 1900 LossPred 0.2432 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.7765 0.8450
epoch 2000 LossPred 0.2385 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.7768 0.8450
epoch 2100 LossPred 0.2342 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.7785 0.8450
epoch 2200 LossPred 0.2302 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.7800 0.8450
epoch 2300 LossPred 0.2261 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.7808 0.8500
epoch 2400 LossPred 0.2067 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.7843 0.8600
epoch 2500 LossPred 0.2013 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.7880 0.8550
Optimization Finished!
********** replication  34  **********
epoch   0 LossPred 1.1539 LossAtt 1.0000 TrainAcc 0.4300 TestAcc 0.5045 0.4300
epoch 100 LossPred 0.8933 LossAtt 1.0000 TrainAcc 0.6700 TestAcc 0.5758 0.6450
epoch 200 LossPred 0.7400 LossAtt 1.0000 TrainAcc 0.7100 TestAcc 0.6469 0.7450
epoch 300 LossPred 0.2836 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8654 0.8850
epoch 400 LossPred 0.2262 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8649 0.8900
epoch 500 LossPred 0.1943 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8641 0.9050
epoch 600 LossPred 0.1684 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8571 0.9000
epoch 700 LossPred 0.1494 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8539 0.9050
epoch 800 LossPred 0.1369 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8546 0.9050
epoch 900 LossPred 0.1284 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8546 0.9050
epoch 1000 LossPred 0.1220 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8554 0.9100
epoch 1100 LossPred 0.1168 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8539 0.9050
epoch 1200 LossPred 0.1513 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8524 0.9050
epoch 1300 LossPred 0.1472 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8511 0.9100
epoch 1400 LossPred 0.1432 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8498 0.9150
epoch 1500 LossPred 0.1389 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8461 0.9200
epoch 1600 LossPred 0.1341 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8423 0.9200
epoch 1700 LossPred 0.1293 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8381 0.9150
epoch 1800 LossPred 0.1250 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8358 0.9100
epoch 1900 LossPred 0.1214 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8328 0.8950
epoch 2000 LossPred 0.1182 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8316 0.9000
epoch 2100 LossPred 0.1370 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8481 0.9200
epoch 2200 LossPred 0.1199 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8318 0.9050
epoch 2300 LossPred 0.1172 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8316 0.9000
epoch 2400 LossPred 0.1154 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8318 0.8950
epoch 2500 LossPred 0.1141 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8291 0.9000
Optimization Finished!
********** replication  35  **********
epoch   0 LossPred 1.2752 LossAtt 1.0000 TrainAcc 0.5300 TestAcc 0.4547 0.5000
epoch 100 LossPred 1.0071 LossAtt 1.0000 TrainAcc 0.5800 TestAcc 0.4830 0.5850
epoch 200 LossPred 0.9440 LossAtt 1.0000 TrainAcc 0.5800 TestAcc 0.4830 0.5800
epoch 300 LossPred 0.8861 LossAtt 1.0000 TrainAcc 0.6300 TestAcc 0.5636 0.6250
epoch 400 LossPred 0.5951 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.7795 0.8100
epoch 500 LossPred 0.4971 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.7765 0.8050
epoch 600 LossPred 0.4586 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.7778 0.8050
epoch 700 LossPred 0.4464 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.7875 0.8050
epoch 800 LossPred 0.4338 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.7943 0.8100
epoch 900 LossPred 0.3634 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.8153 0.8250
epoch 1000 LossPred 0.3111 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8278 0.8450
epoch 1100 LossPred 0.2437 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8333 0.8800
epoch 1200 LossPred 0.2042 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8256 0.8900
epoch 1300 LossPred 0.1817 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8216 0.9000
epoch 1400 LossPred 0.1365 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8123 0.9050
epoch 1500 LossPred 0.1194 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8148 0.9000
epoch 1600 LossPred 0.1099 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8211 0.9150
epoch 1700 LossPred 0.1032 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8181 0.9150
epoch 1800 LossPred 0.0983 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8123 0.9200
epoch 1900 LossPred 0.0950 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8086 0.9200
epoch 2000 LossPred 0.0925 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8061 0.9250
epoch 2100 LossPred 0.0905 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8023 0.9250
epoch 2200 LossPred 0.0888 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8016 0.9250
epoch 2300 LossPred 0.0874 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8013 0.9200
epoch 2400 LossPred 0.0861 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8026 0.9150
epoch 2500 LossPred 0.0850 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8026 0.9100
Optimization Finished!
********** replication  36  **********
epoch   0 LossPred 1.1095 LossAtt 1.0000 TrainAcc 0.5600 TestAcc 0.5656 0.5600
epoch 100 LossPred 0.9340 LossAtt 1.0000 TrainAcc 0.6100 TestAcc 0.5866 0.6050
epoch 200 LossPred 0.8837 LossAtt 1.0000 TrainAcc 0.6400 TestAcc 0.5733 0.6550
epoch 300 LossPred 0.8217 LossAtt 1.0000 TrainAcc 0.6800 TestAcc 0.5798 0.6550
epoch 400 LossPred 0.7229 LossAtt 1.0000 TrainAcc 0.7200 TestAcc 0.5616 0.6750
epoch 500 LossPred 0.6293 LossAtt 1.0000 TrainAcc 0.7800 TestAcc 0.5696 0.7150
epoch 600 LossPred 0.5708 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5638 0.7400
epoch 700 LossPred 0.5402 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5591 0.7450
epoch 800 LossPred 0.5131 LossAtt 1.0000 TrainAcc 0.8600 TestAcc 0.5603 0.7500
epoch 900 LossPred 0.4857 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.5553 0.7600
epoch 1000 LossPred 0.4600 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.5586 0.7500
epoch 1100 LossPred 0.4491 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.5578 0.7550
epoch 1200 LossPred 0.4354 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.5591 0.7400
epoch 1300 LossPred 0.4226 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.5638 0.7500
epoch 1400 LossPred 0.4562 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.5633 0.7450
epoch 1500 LossPred 0.4200 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.5616 0.7400
epoch 1600 LossPred 0.4156 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.5623 0.7500
epoch 1700 LossPred 0.5046 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.5766 0.7500
epoch 1800 LossPred 0.4274 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.5681 0.7500
epoch 1900 LossPred 0.4180 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.5726 0.7600
epoch 2000 LossPred 0.4120 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.5723 0.7600
epoch 2100 LossPred 0.4073 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.5728 0.7700
epoch 2200 LossPred 0.4034 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.5738 0.7650
epoch 2300 LossPred 0.3998 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.5733 0.7700
epoch 2400 LossPred 0.3956 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.5743 0.7800
epoch 2500 LossPred 0.3917 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.5738 0.7750
Optimization Finished!
********** replication  37  **********
epoch   0 LossPred 1.1744 LossAtt 1.0000 TrainAcc 0.4500 TestAcc 0.4952 0.4500
epoch 100 LossPred 0.9427 LossAtt 1.0000 TrainAcc 0.6100 TestAcc 0.5736 0.6100
epoch 200 LossPred 0.9316 LossAtt 1.0000 TrainAcc 0.6100 TestAcc 0.5736 0.6100
epoch 300 LossPred 0.9090 LossAtt 1.0000 TrainAcc 0.6100 TestAcc 0.5981 0.6450
epoch 400 LossPred 0.5783 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.8363 0.8500
epoch 500 LossPred 0.3350 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8398 0.8700
epoch 600 LossPred 0.2772 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8466 0.8650
epoch 700 LossPred 0.2465 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8466 0.8800
epoch 800 LossPred 0.2291 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8488 0.9050
epoch 900 LossPred 0.2171 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8514 0.9100
epoch 1000 LossPred 0.2084 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8539 0.9100
epoch 1100 LossPred 0.2017 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8549 0.9050
epoch 1200 LossPred 0.1963 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8541 0.9050
epoch 1300 LossPred 0.1918 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8539 0.9000
epoch 1400 LossPred 0.1878 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8551 0.9000
epoch 1500 LossPred 0.1842 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8561 0.8950
epoch 1600 LossPred 0.1805 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8596 0.8950
epoch 1700 LossPred 0.1769 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8599 0.9000
epoch 1800 LossPred 0.1734 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8631 0.9050
epoch 1900 LossPred 0.1704 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8641 0.9000
epoch 2000 LossPred 0.1677 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8676 0.9050
epoch 2100 LossPred 0.1653 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8704 0.9100
epoch 2200 LossPred 0.1630 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8714 0.9050
epoch 2300 LossPred 0.1604 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8749 0.9050
epoch 2400 LossPred 0.1568 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8826 0.9000
epoch 2500 LossPred 0.0934 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.9077 0.9250
Optimization Finished!
********** replication  38  **********
epoch   0 LossPred 1.1184 LossAtt 1.0000 TrainAcc 0.5200 TestAcc 0.5288 0.5250
epoch 100 LossPred 0.9081 LossAtt 1.0000 TrainAcc 0.6200 TestAcc 0.5721 0.6250
epoch 200 LossPred 0.8046 LossAtt 1.0000 TrainAcc 0.7300 TestAcc 0.5928 0.7000
epoch 300 LossPred 0.6982 LossAtt 1.0000 TrainAcc 0.7700 TestAcc 0.5651 0.7350
epoch 400 LossPred 0.6574 LossAtt 1.0000 TrainAcc 0.7700 TestAcc 0.5643 0.7400
epoch 500 LossPred 0.6298 LossAtt 1.0000 TrainAcc 0.7700 TestAcc 0.5658 0.7400
epoch 600 LossPred 0.6030 LossAtt 1.0000 TrainAcc 0.7800 TestAcc 0.5576 0.7200
epoch 700 LossPred 0.5898 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.5516 0.7250
epoch 800 LossPred 0.5793 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.5495 0.7400
epoch 900 LossPred 0.5688 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.5541 0.7400
epoch 1000 LossPred 0.5647 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.5541 0.7400
epoch 1100 LossPred 0.5871 LossAtt 1.0000 TrainAcc 0.7900 TestAcc 0.5636 0.7450
epoch 1200 LossPred 0.5479 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.5648 0.7550
epoch 1300 LossPred 0.5344 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.5653 0.7550
epoch 1400 LossPred 0.5200 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.5646 0.7450
epoch 1500 LossPred 0.5069 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5676 0.7400
epoch 1600 LossPred 0.4961 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5698 0.7500
epoch 1700 LossPred 0.4838 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5673 0.7400
epoch 1800 LossPred 0.4761 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5648 0.7500
epoch 1900 LossPred 0.4696 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.5663 0.7400
epoch 2000 LossPred 0.4645 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.5681 0.7500
epoch 2100 LossPred 0.4600 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.5688 0.7500
epoch 2200 LossPred 0.4540 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.5698 0.7500
epoch 2300 LossPred 0.4833 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.5686 0.7500
epoch 2400 LossPred 0.4415 LossAtt 1.0000 TrainAcc 0.8600 TestAcc 0.5701 0.7700
epoch 2500 LossPred 0.4294 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.5683 0.7700
Optimization Finished!
********** replication  39  **********
epoch   0 LossPred 1.2612 LossAtt 1.0000 TrainAcc 0.4600 TestAcc 0.4277 0.4450
epoch 100 LossPred 0.8724 LossAtt 1.0000 TrainAcc 0.6300 TestAcc 0.6286 0.6750
epoch 200 LossPred 0.3875 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8428 0.8400
epoch 300 LossPred 0.3111 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8624 0.8650
epoch 400 LossPred 0.2377 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8739 0.8950
epoch 500 LossPred 0.1745 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8739 0.9100
epoch 600 LossPred 0.1187 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8894 0.9150
epoch 700 LossPred 0.0763 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8776 0.9250
epoch 800 LossPred 0.0666 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8791 0.9250
epoch 900 LossPred 0.0599 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8791 0.9200
epoch 1000 LossPred 0.0535 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8791 0.9100
epoch 1100 LossPred 0.0529 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8816 0.9200
epoch 1200 LossPred 0.0818 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8874 0.9050
epoch 1300 LossPred 0.0718 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8746 0.9150
epoch 1400 LossPred 0.0494 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8816 0.9100
epoch 1500 LossPred 0.0253 LossAtt 1.0000 TrainAcc 1.0000 TestAcc 0.8871 0.9000
Optimization Finished!
********** replication  40  **********
epoch   0 LossPred 1.1924 LossAtt 1.0000 TrainAcc 0.5100 TestAcc 0.5826 0.5100
epoch 100 LossPred 0.9600 LossAtt 1.0000 TrainAcc 0.5700 TestAcc 0.5828 0.5900
epoch 200 LossPred 0.5360 LossAtt 1.0000 TrainAcc 0.8600 TestAcc 0.8646 0.8400
epoch 300 LossPred 0.3604 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.8556 0.8450
epoch 400 LossPred 0.2519 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8824 0.8850
epoch 500 LossPred 0.1973 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8831 0.8900
epoch 600 LossPred 0.1438 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8889 0.9050
epoch 700 LossPred 0.1055 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8879 0.9200
epoch 800 LossPred 0.0875 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8871 0.9150
epoch 900 LossPred 0.0713 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8876 0.9200
epoch 1000 LossPred 0.0640 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8884 0.9200
epoch 1100 LossPred 0.0595 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8889 0.9200
epoch 1200 LossPred 0.0563 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8886 0.9200
epoch 1300 LossPred 0.0539 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8899 0.9200
epoch 1400 LossPred 0.0519 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8886 0.9200
epoch 1500 LossPred 0.0504 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8876 0.9200
epoch 1600 LossPred 0.0491 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8876 0.9200
epoch 1700 LossPred 0.0480 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8869 0.9200
epoch 1800 LossPred 0.0471 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8871 0.9200
epoch 1900 LossPred 0.0463 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8866 0.9200
epoch 2000 LossPred 0.0456 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8869 0.9150
epoch 2100 LossPred 0.0450 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8874 0.9150
epoch 2200 LossPred 0.0445 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8876 0.9150
epoch 2300 LossPred 0.0440 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8879 0.9150
epoch 2400 LossPred 0.0436 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8879 0.9150
epoch 2500 LossPred 0.0432 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8879 0.9150
Optimization Finished!
********** replication  41  **********
epoch   0 LossPred 1.3124 LossAtt 1.0000 TrainAcc 0.4800 TestAcc 0.5125 0.4800
epoch 100 LossPred 0.9649 LossAtt 1.0000 TrainAcc 0.5700 TestAcc 0.5951 0.5500
epoch 200 LossPred 0.9314 LossAtt 1.0000 TrainAcc 0.6100 TestAcc 0.6399 0.6500
epoch 300 LossPred 0.4784 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.8509 0.8500
epoch 400 LossPred 0.3393 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8569 0.8450
epoch 500 LossPred 0.2833 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8601 0.8400
epoch 600 LossPred 0.2248 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8694 0.8600
epoch 700 LossPred 0.1833 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8724 0.8750
epoch 800 LossPred 0.1635 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8731 0.8800
epoch 900 LossPred 0.1471 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8731 0.8950
epoch 1000 LossPred 0.1334 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8681 0.8950
epoch 1100 LossPred 0.1237 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8684 0.8850
epoch 1200 LossPred 0.1151 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8646 0.8750
epoch 1300 LossPred 0.0948 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8569 0.8900
epoch 1400 LossPred 0.0731 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8656 0.8800
epoch 1500 LossPred 0.0670 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8666 0.8800
epoch 1600 LossPred 0.0627 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8676 0.8750
epoch 1700 LossPred 0.0594 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8674 0.8750
epoch 1800 LossPred 0.0568 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8666 0.8650
epoch 1900 LossPred 0.0547 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8666 0.8650
epoch 2000 LossPred 0.0528 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8689 0.8800
epoch 2100 LossPred 0.0511 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8686 0.8800
epoch 2200 LossPred 0.0496 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8674 0.8800
epoch 2300 LossPred 0.0482 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8666 0.8800
epoch 2400 LossPred 0.0470 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8664 0.8750
epoch 2500 LossPred 0.0460 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8691 0.8750
Optimization Finished!
********** replication  42  **********
epoch   0 LossPred 1.0104 LossAtt 1.0000 TrainAcc 0.4900 TestAcc 0.4389 0.4900
epoch 100 LossPred 0.9223 LossAtt 1.0000 TrainAcc 0.5700 TestAcc 0.5861 0.5750
epoch 200 LossPred 0.5762 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.8313 0.8150
epoch 300 LossPred 0.3434 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.8318 0.8150
epoch 400 LossPred 0.2769 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8341 0.8350
epoch 500 LossPred 0.2183 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8398 0.8450
epoch 600 LossPred 0.1954 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8428 0.8550
epoch 700 LossPred 0.1789 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8476 0.8600
epoch 800 LossPred 0.1631 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8519 0.8550
epoch 900 LossPred 0.1425 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8561 0.8600
epoch 1000 LossPred 0.1643 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8691 0.8750
epoch 1100 LossPred 0.1201 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8619 0.8750
epoch 1200 LossPred 0.1047 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8659 0.8750
epoch 1300 LossPred 0.0862 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8656 0.8650
epoch 1400 LossPred 0.0775 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8649 0.8600
epoch 1500 LossPred 0.0713 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8641 0.8600
epoch 1600 LossPred 0.0666 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8646 0.8600
epoch 1700 LossPred 0.0628 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8646 0.8600
epoch 1800 LossPred 0.0598 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8634 0.8600
epoch 1900 LossPred 0.0572 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8636 0.8600
epoch 2000 LossPred 0.0551 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8631 0.8600
epoch 2100 LossPred 0.0532 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8626 0.8600
epoch 2200 LossPred 0.0516 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8634 0.8600
epoch 2300 LossPred 0.0502 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8639 0.8600
epoch 2400 LossPred 0.0489 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8624 0.8600
epoch 2500 LossPred 0.0478 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8629 0.8550
Optimization Finished!
********** replication  43  **********
epoch   0 LossPred 1.0681 LossAtt 1.0000 TrainAcc 0.5100 TestAcc 0.5370 0.5100
epoch 100 LossPred 0.8492 LossAtt 1.0000 TrainAcc 0.6500 TestAcc 0.5641 0.6500
epoch 200 LossPred 0.7061 LossAtt 1.0000 TrainAcc 0.7300 TestAcc 0.6947 0.7600
epoch 300 LossPred 0.4318 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.8388 0.8400
epoch 400 LossPred 0.2398 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8711 0.8950
epoch 500 LossPred 0.1767 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8634 0.9100
epoch 600 LossPred 0.1364 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8691 0.9250
epoch 700 LossPred 0.0977 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8699 0.9350
epoch 800 LossPred 0.0618 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8731 0.9400
epoch 900 LossPred 0.0459 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8711 0.9400
epoch 1000 LossPred 0.0360 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8726 0.9350
epoch 1100 LossPred 0.0277 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8719 0.9300
epoch 1200 LossPred 0.0209 LossAtt 1.0000 TrainAcc 1.0000 TestAcc 0.8754 0.9350
Optimization Finished!
********** replication  44  **********
epoch   0 LossPred 1.0487 LossAtt 1.0000 TrainAcc 0.5600 TestAcc 0.5340 0.5500
epoch 100 LossPred 0.9335 LossAtt 1.0000 TrainAcc 0.6400 TestAcc 0.5490 0.6350
epoch 200 LossPred 0.9141 LossAtt 1.0000 TrainAcc 0.6300 TestAcc 0.5606 0.6300
epoch 300 LossPred 0.8845 LossAtt 1.0000 TrainAcc 0.6400 TestAcc 0.5420 0.6400
epoch 400 LossPred 0.8425 LossAtt 1.0000 TrainAcc 0.6700 TestAcc 0.5390 0.6450
epoch 500 LossPred 0.7967 LossAtt 1.0000 TrainAcc 0.6900 TestAcc 0.5483 0.6650
epoch 600 LossPred 0.7649 LossAtt 1.0000 TrainAcc 0.7000 TestAcc 0.5523 0.6300
epoch 700 LossPred 0.7471 LossAtt 1.0000 TrainAcc 0.7100 TestAcc 0.5450 0.6500
epoch 800 LossPred 0.7064 LossAtt 1.0000 TrainAcc 0.7600 TestAcc 0.5485 0.6600
epoch 900 LossPred 0.6506 LossAtt 1.0000 TrainAcc 0.7900 TestAcc 0.5495 0.6700
epoch 1000 LossPred 0.6065 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.5495 0.6900
epoch 1100 LossPred 0.5980 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.5478 0.7050
epoch 1200 LossPred 0.5933 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.5485 0.7000
epoch 1300 LossPred 0.5898 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.5475 0.7000
epoch 1400 LossPred 0.5867 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.5478 0.7000
epoch 1500 LossPred 0.5823 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.5493 0.7000
epoch 1600 LossPred 0.5795 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.5488 0.7000
epoch 1700 LossPred 0.5768 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5488 0.6900
epoch 1800 LossPred 0.5746 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5498 0.6950
epoch 1900 LossPred 0.5725 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5493 0.6850
epoch 2000 LossPred 0.5703 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5483 0.6800
epoch 2100 LossPred 0.5680 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5473 0.6800
epoch 2200 LossPred 0.5653 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5475 0.6850
epoch 2300 LossPred 0.5625 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5488 0.6850
epoch 2400 LossPred 0.5600 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5478 0.6850
epoch 2500 LossPred 0.5577 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5470 0.6950
Optimization Finished!
********** replication  45  **********
epoch   0 LossPred 1.0776 LossAtt 1.0000 TrainAcc 0.5600 TestAcc 0.5170 0.5850
epoch 100 LossPred 0.8958 LossAtt 1.0000 TrainAcc 0.6300 TestAcc 0.6014 0.6600
epoch 200 LossPred 0.2914 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8278 0.9250
epoch 300 LossPred 0.2189 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8193 0.9100
epoch 400 LossPred 0.1895 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8118 0.9150
epoch 500 LossPred 0.1725 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8153 0.9000
epoch 600 LossPred 0.1589 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8126 0.9000
epoch 700 LossPred 0.1473 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8088 0.9050
epoch 800 LossPred 0.1326 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8046 0.9000
epoch 900 LossPred 0.0847 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8281 0.9150
epoch 1000 LossPred 0.0719 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8361 0.9200
epoch 1100 LossPred 0.0310 LossAtt 1.0000 TrainAcc 1.0000 TestAcc 0.8564 0.9400
Optimization Finished!
********** replication  46  **********
epoch   0 LossPred 1.0168 LossAtt 1.0000 TrainAcc 0.5600 TestAcc 0.4975 0.5550
epoch 100 LossPred 0.9676 LossAtt 1.0000 TrainAcc 0.5600 TestAcc 0.4975 0.5600
epoch 200 LossPred 0.9024 LossAtt 1.0000 TrainAcc 0.6600 TestAcc 0.5791 0.6350
epoch 300 LossPred 0.5833 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.7107 0.8100
epoch 400 LossPred 0.3927 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.7583 0.8200
epoch 500 LossPred 0.2940 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.7830 0.8400
epoch 600 LossPred 0.2294 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.7798 0.8050
epoch 700 LossPred 0.2043 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.7763 0.8250
epoch 800 LossPred 0.1847 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.7765 0.8200
epoch 900 LossPred 0.1710 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.7703 0.8250
epoch 1000 LossPred 0.1931 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.7585 0.8300
epoch 1100 LossPred 0.1296 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.7570 0.8450
epoch 1200 LossPred 0.1197 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.7568 0.8500
epoch 1300 LossPred 0.1122 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.7575 0.8500
epoch 1400 LossPred 0.1055 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.7565 0.8400
epoch 1500 LossPred 0.0996 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.7570 0.8350
epoch 1600 LossPred 0.0944 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.7548 0.8300
epoch 1700 LossPred 0.0897 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.7573 0.8200
epoch 1800 LossPred 0.0855 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.7573 0.8150
epoch 1900 LossPred 0.0815 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.7553 0.8100
epoch 2000 LossPred 0.0778 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.7545 0.8100
epoch 2100 LossPred 0.0740 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.7535 0.8000
epoch 2200 LossPred 0.1405 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.7375 0.8100
epoch 2300 LossPred 0.1340 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.7367 0.8050
epoch 2400 LossPred 0.1307 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.7365 0.8000
epoch 2500 LossPred 0.1281 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.7367 0.8050
Optimization Finished!
********** replication  47  **********
epoch   0 LossPred 1.1156 LossAtt 1.0000 TrainAcc 0.4800 TestAcc 0.4454 0.4600
epoch 100 LossPred 0.9868 LossAtt 1.0000 TrainAcc 0.5500 TestAcc 0.5038 0.5500
epoch 200 LossPred 0.9750 LossAtt 1.0000 TrainAcc 0.5500 TestAcc 0.5038 0.5650
epoch 300 LossPred 0.9618 LossAtt 1.0000 TrainAcc 0.5900 TestAcc 0.5551 0.5850
epoch 400 LossPred 0.5508 LossAtt 1.0000 TrainAcc 0.8600 TestAcc 0.8038 0.8600
epoch 500 LossPred 0.3975 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.7923 0.8350
epoch 600 LossPred 0.3735 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.7928 0.8200
epoch 700 LossPred 0.3633 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.7910 0.8250
epoch 800 LossPred 0.3574 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.7908 0.8250
epoch 900 LossPred 0.3526 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.7928 0.8300
epoch 1000 LossPred 0.3481 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.7945 0.8450
epoch 1100 LossPred 0.3431 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.7940 0.8550
epoch 1200 LossPred 0.3367 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.7970 0.8550
epoch 1300 LossPred 0.3272 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8046 0.8600
epoch 1400 LossPred 0.3006 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8171 0.8750
epoch 1500 LossPred 0.2766 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8178 0.8750
epoch 1600 LossPred 0.2616 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8211 0.8950
epoch 1700 LossPred 0.2110 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8193 0.9050
epoch 1800 LossPred 0.1957 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8138 0.8950
epoch 1900 LossPred 0.1858 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8108 0.8900
epoch 2000 LossPred 0.1782 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8073 0.8850
epoch 2100 LossPred 0.1719 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8076 0.8850
epoch 2200 LossPred 0.1666 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8063 0.8750
epoch 2300 LossPred 0.1622 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8058 0.8750
epoch 2400 LossPred 0.1584 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8038 0.8700
epoch 2500 LossPred 0.1548 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8006 0.8700
Optimization Finished!
********** replication  48  **********
epoch   0 LossPred 1.0535 LossAtt 1.0000 TrainAcc 0.5500 TestAcc 0.5398 0.5550
epoch 100 LossPred 0.8666 LossAtt 1.0000 TrainAcc 0.6800 TestAcc 0.5743 0.6600
epoch 200 LossPred 0.5737 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.7300 0.7950
epoch 300 LossPred 0.3365 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8001 0.8500
epoch 400 LossPred 0.2506 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8246 0.8850
epoch 500 LossPred 0.2092 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8313 0.8750
epoch 600 LossPred 0.1882 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8313 0.8700
epoch 700 LossPred 0.1721 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8336 0.8800
epoch 800 LossPred 0.1556 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8323 0.8700
epoch 900 LossPred 0.1387 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8308 0.8800
epoch 1000 LossPred 0.1123 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8313 0.8750
epoch 1100 LossPred 0.0924 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8286 0.8750
epoch 1200 LossPred 0.0750 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8311 0.8700
epoch 1300 LossPred 0.0608 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8248 0.8850
epoch 1400 LossPred 0.0509 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8231 0.8800
epoch 1500 LossPred 0.0430 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8146 0.8800
epoch 1600 LossPred 0.0360 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8088 0.8800
epoch 1700 LossPred 0.0300 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8018 0.8900
epoch 1800 LossPred 0.0246 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.7985 0.9000
epoch 1900 LossPred 0.0199 LossAtt 1.0000 TrainAcc 1.0000 TestAcc 0.7955 0.9300
Optimization Finished!
********** replication  49  **********
epoch   0 LossPred 1.0313 LossAtt 1.0000 TrainAcc 0.5200 TestAcc 0.4717 0.5200
epoch 100 LossPred 0.8286 LossAtt 1.0000 TrainAcc 0.6700 TestAcc 0.5921 0.6900
epoch 200 LossPred 0.6058 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.6922 0.8050
epoch 300 LossPred 0.2218 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8341 0.8950
epoch 400 LossPred 0.1738 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8438 0.8850
epoch 500 LossPred 0.1258 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8451 0.9050
epoch 600 LossPred 0.1012 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8426 0.9000
epoch 700 LossPred 0.0616 LossAtt 1.0000 TrainAcc 1.0000 TestAcc 0.8496 0.9050
Optimization Finished!
********** replication  50  **********
epoch   0 LossPred 1.0519 LossAtt 1.0000 TrainAcc 0.4400 TestAcc 0.5463 0.4400
epoch 100 LossPred 0.9485 LossAtt 1.0000 TrainAcc 0.6100 TestAcc 0.4392 0.5950
epoch 200 LossPred 0.9275 LossAtt 1.0000 TrainAcc 0.6200 TestAcc 0.4432 0.6150
epoch 300 LossPred 0.8900 LossAtt 1.0000 TrainAcc 0.6400 TestAcc 0.4474 0.6200
epoch 400 LossPred 0.8356 LossAtt 1.0000 TrainAcc 0.6600 TestAcc 0.4429 0.6350
epoch 500 LossPred 0.7761 LossAtt 1.0000 TrainAcc 0.6300 TestAcc 0.4374 0.6050
epoch 600 LossPred 0.7551 LossAtt 1.0000 TrainAcc 0.6400 TestAcc 0.4565 0.5950
epoch 700 LossPred 0.7392 LossAtt 1.0000 TrainAcc 0.6400 TestAcc 0.4537 0.5800
epoch 800 LossPred 0.7213 LossAtt 1.0000 TrainAcc 0.6700 TestAcc 0.4720 0.6100
epoch 900 LossPred 0.7362 LossAtt 1.0000 TrainAcc 0.7000 TestAcc 0.4810 0.6200
epoch 1000 LossPred 0.7184 LossAtt 1.0000 TrainAcc 0.6900 TestAcc 0.5038 0.6200
epoch 1100 LossPred 0.7025 LossAtt 1.0000 TrainAcc 0.7000 TestAcc 0.5103 0.6250
epoch 1200 LossPred 0.6848 LossAtt 1.0000 TrainAcc 0.7200 TestAcc 0.5150 0.6300
epoch 1300 LossPred 0.6670 LossAtt 1.0000 TrainAcc 0.7400 TestAcc 0.5195 0.6650
epoch 1400 LossPred 0.6501 LossAtt 1.0000 TrainAcc 0.7700 TestAcc 0.5378 0.6700
epoch 1500 LossPred 0.6373 LossAtt 1.0000 TrainAcc 0.7600 TestAcc 0.5373 0.6800
epoch 1600 LossPred 0.6082 LossAtt 1.0000 TrainAcc 0.7700 TestAcc 0.5365 0.6800
epoch 1700 LossPred 0.5920 LossAtt 1.0000 TrainAcc 0.7800 TestAcc 0.5440 0.6750
epoch 1800 LossPred 0.5703 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.5561 0.6750
epoch 1900 LossPred 0.5614 LossAtt 1.0000 TrainAcc 0.7900 TestAcc 0.5548 0.6800
epoch 2000 LossPred 0.5759 LossAtt 1.0000 TrainAcc 0.7900 TestAcc 0.5596 0.6800
epoch 2100 LossPred 0.6542 LossAtt 1.0000 TrainAcc 0.7400 TestAcc 0.5185 0.6450
epoch 2200 LossPred 0.5583 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.5568 0.6750
epoch 2300 LossPred 0.5517 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.5568 0.6850
epoch 2400 LossPred 0.5506 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.5576 0.6900
epoch 2500 LossPred 0.5490 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.5506 0.6800
Optimization Finished!
********** replication  51  **********
epoch   0 LossPred 1.1248 LossAtt 1.0000 TrainAcc 0.4500 TestAcc 0.4449 0.4750
epoch 100 LossPred 0.9439 LossAtt 1.0000 TrainAcc 0.6000 TestAcc 0.4607 0.5800
epoch 200 LossPred 0.8344 LossAtt 1.0000 TrainAcc 0.7500 TestAcc 0.5438 0.7050
epoch 300 LossPred 0.7671 LossAtt 1.0000 TrainAcc 0.7300 TestAcc 0.5623 0.6850
epoch 400 LossPred 0.7069 LossAtt 1.0000 TrainAcc 0.7000 TestAcc 0.5768 0.6650
epoch 500 LossPred 0.6614 LossAtt 1.0000 TrainAcc 0.7600 TestAcc 0.5826 0.7050
epoch 600 LossPred 0.6067 LossAtt 1.0000 TrainAcc 0.7700 TestAcc 0.5916 0.7100
epoch 700 LossPred 0.4959 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.6744 0.7550
epoch 800 LossPred 0.4644 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.6867 0.7500
epoch 900 LossPred 0.4949 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.6794 0.7500
epoch 1000 LossPred 0.4397 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.6919 0.7400
epoch 1100 LossPred 0.4184 LossAtt 1.0000 TrainAcc 0.8600 TestAcc 0.6969 0.7250
epoch 1200 LossPred 0.4180 LossAtt 1.0000 TrainAcc 0.8600 TestAcc 0.6969 0.7250
epoch 1300 LossPred 0.4042 LossAtt 1.0000 TrainAcc 0.8600 TestAcc 0.7017 0.7300
epoch 1400 LossPred 0.3991 LossAtt 1.0000 TrainAcc 0.8600 TestAcc 0.7022 0.7350
epoch 1500 LossPred 0.3946 LossAtt 1.0000 TrainAcc 0.8600 TestAcc 0.7022 0.7350
epoch 1600 LossPred 0.3904 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.7015 0.7500
epoch 1700 LossPred 0.3861 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.7002 0.7550
epoch 1800 LossPred 0.3815 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.6987 0.7500
epoch 1900 LossPred 0.3766 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.6997 0.7500
epoch 2000 LossPred 0.4371 LossAtt 1.0000 TrainAcc 0.8600 TestAcc 0.6769 0.7400
epoch 2100 LossPred 0.3847 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.6982 0.7500
epoch 2200 LossPred 0.3765 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.6947 0.7500
epoch 2300 LossPred 0.3712 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.6969 0.7400
epoch 2400 LossPred 0.3670 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.6984 0.7450
epoch 2500 LossPred 0.3630 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.6984 0.7450
Optimization Finished!
********** replication  52  **********
epoch   0 LossPred 0.9581 LossAtt 1.0000 TrainAcc 0.6000 TestAcc 0.5453 0.5950
epoch 100 LossPred 0.8947 LossAtt 1.0000 TrainAcc 0.6100 TestAcc 0.5771 0.5950
epoch 200 LossPred 0.8049 LossAtt 1.0000 TrainAcc 0.7200 TestAcc 0.6136 0.7100
epoch 300 LossPred 0.3752 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.8491 0.8700
epoch 400 LossPred 0.2876 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.8361 0.8750
epoch 500 LossPred 0.2478 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8363 0.8700
epoch 600 LossPred 0.2383 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8368 0.8650
epoch 700 LossPred 0.2330 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8361 0.8600
epoch 800 LossPred 0.2283 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8351 0.8600
epoch 900 LossPred 0.2233 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8346 0.8650
epoch 1000 LossPred 0.2176 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8341 0.8550
epoch 1100 LossPred 0.3783 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.8366 0.8250
epoch 1200 LossPred 0.2936 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.8609 0.8650
epoch 1300 LossPred 0.2378 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8681 0.8700
epoch 1400 LossPred 0.2193 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8721 0.8700
epoch 1500 LossPred 0.1713 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8681 0.8900
epoch 1600 LossPred 0.1502 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8684 0.9050
epoch 1700 LossPred 0.1396 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8731 0.9050
epoch 1800 LossPred 0.1341 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8741 0.9050
epoch 1900 LossPred 0.1289 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8751 0.9100
epoch 2000 LossPred 0.1279 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8804 0.9100
epoch 2100 LossPred 0.1036 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8759 0.9050
epoch 2200 LossPred 0.0838 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8699 0.9050
epoch 2300 LossPred 0.0666 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8694 0.9100
epoch 2400 LossPred 0.0465 LossAtt 1.0000 TrainAcc 1.0000 TestAcc 0.8729 0.9100
Optimization Finished!
********** replication  53  **********
epoch   0 LossPred 0.9389 LossAtt 1.0000 TrainAcc 0.5000 TestAcc 0.4625 0.5550
epoch 100 LossPred 0.8588 LossAtt 1.0000 TrainAcc 0.6900 TestAcc 0.5883 0.6700
epoch 200 LossPred 0.8207 LossAtt 1.0000 TrainAcc 0.7000 TestAcc 0.5831 0.7000
epoch 300 LossPred 0.7968 LossAtt 1.0000 TrainAcc 0.7100 TestAcc 0.5758 0.7050
epoch 400 LossPred 0.7543 LossAtt 1.0000 TrainAcc 0.7700 TestAcc 0.5838 0.7150
epoch 500 LossPred 0.6973 LossAtt 1.0000 TrainAcc 0.7800 TestAcc 0.5696 0.7250
epoch 600 LossPred 0.6638 LossAtt 1.0000 TrainAcc 0.7900 TestAcc 0.5741 0.7300
epoch 700 LossPred 0.6225 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.5736 0.7400
epoch 800 LossPred 0.5768 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5648 0.7100
epoch 900 LossPred 0.5578 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5573 0.7150
epoch 1000 LossPred 0.5669 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5558 0.6700
epoch 1100 LossPred 0.5104 LossAtt 1.0000 TrainAcc 0.8600 TestAcc 0.5578 0.6950
epoch 1200 LossPred 0.6512 LossAtt 1.0000 TrainAcc 0.7800 TestAcc 0.5300 0.6650
epoch 1300 LossPred 0.6580 LossAtt 1.0000 TrainAcc 0.7700 TestAcc 0.5651 0.6500
epoch 1400 LossPred 0.5951 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.5616 0.6400
epoch 1500 LossPred 0.5878 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.5588 0.6500
epoch 1600 LossPred 0.5824 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.5631 0.6600
epoch 1700 LossPred 0.5772 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5636 0.6450
epoch 1800 LossPred 0.5697 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5601 0.6400
epoch 1900 LossPred 0.5622 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5541 0.6450
epoch 2000 LossPred 0.5532 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5536 0.6600
epoch 2100 LossPred 0.5477 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.5533 0.6600
epoch 2200 LossPred 0.5440 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5511 0.6450
epoch 2300 LossPred 0.5407 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5508 0.6650
epoch 2400 LossPred 0.5377 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5526 0.6650
epoch 2500 LossPred 0.5351 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5518 0.6700
Optimization Finished!
********** replication  54  **********
epoch   0 LossPred 1.0093 LossAtt 1.0000 TrainAcc 0.5400 TestAcc 0.5418 0.5250
epoch 100 LossPred 0.9158 LossAtt 1.0000 TrainAcc 0.6400 TestAcc 0.5793 0.6550
epoch 200 LossPred 0.8833 LossAtt 1.0000 TrainAcc 0.6400 TestAcc 0.5793 0.6700
epoch 300 LossPred 0.8541 LossAtt 1.0000 TrainAcc 0.6500 TestAcc 0.5733 0.6900
epoch 400 LossPred 0.8164 LossAtt 1.0000 TrainAcc 0.6900 TestAcc 0.5808 0.6850
epoch 500 LossPred 0.7417 LossAtt 1.0000 TrainAcc 0.7200 TestAcc 0.5826 0.7050
epoch 600 LossPred 0.6624 LossAtt 1.0000 TrainAcc 0.7800 TestAcc 0.5773 0.7150
epoch 700 LossPred 0.6366 LossAtt 1.0000 TrainAcc 0.7800 TestAcc 0.5791 0.7200
epoch 800 LossPred 0.6241 LossAtt 1.0000 TrainAcc 0.7800 TestAcc 0.5793 0.7200
epoch 900 LossPred 0.6161 LossAtt 1.0000 TrainAcc 0.7800 TestAcc 0.5763 0.7250
epoch 1000 LossPred 0.6096 LossAtt 1.0000 TrainAcc 0.7700 TestAcc 0.5721 0.7250
epoch 1100 LossPred 0.6031 LossAtt 1.0000 TrainAcc 0.7700 TestAcc 0.5693 0.7300
epoch 1200 LossPred 0.5944 LossAtt 1.0000 TrainAcc 0.7600 TestAcc 0.5648 0.7100
epoch 1300 LossPred 0.5838 LossAtt 1.0000 TrainAcc 0.7700 TestAcc 0.5566 0.6800
epoch 1400 LossPred 0.5800 LossAtt 1.0000 TrainAcc 0.7700 TestAcc 0.5578 0.6700
epoch 1500 LossPred 0.5772 LossAtt 1.0000 TrainAcc 0.7700 TestAcc 0.5591 0.6600
epoch 1600 LossPred 0.5753 LossAtt 1.0000 TrainAcc 0.7700 TestAcc 0.5583 0.6550
epoch 1700 LossPred 0.5734 LossAtt 1.0000 TrainAcc 0.7700 TestAcc 0.5583 0.6600
epoch 1800 LossPred 0.5712 LossAtt 1.0000 TrainAcc 0.7800 TestAcc 0.5571 0.6650
epoch 1900 LossPred 0.5681 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.5588 0.6700
epoch 2000 LossPred 0.5636 LossAtt 1.0000 TrainAcc 0.7700 TestAcc 0.5318 0.6750
epoch 2100 LossPred 0.5570 LossAtt 1.0000 TrainAcc 0.7800 TestAcc 0.5168 0.6850
epoch 2200 LossPred 0.5479 LossAtt 1.0000 TrainAcc 0.7900 TestAcc 0.5090 0.6750
epoch 2300 LossPred 0.5384 LossAtt 1.0000 TrainAcc 0.7700 TestAcc 0.5048 0.6550
epoch 2400 LossPred 0.5281 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.5138 0.6350
epoch 2500 LossPred 0.5180 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.5155 0.6350
Optimization Finished!
********** replication  55  **********
epoch   0 LossPred 1.0488 LossAtt 1.0000 TrainAcc 0.4100 TestAcc 0.4124 0.4100
epoch 100 LossPred 0.9233 LossAtt 1.0000 TrainAcc 0.6200 TestAcc 0.5771 0.6200
epoch 200 LossPred 0.5770 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.7523 0.8300
epoch 300 LossPred 0.3415 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8644 0.8700
epoch 400 LossPred 0.2825 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8861 0.8950
epoch 500 LossPred 0.1962 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.9014 0.8950
epoch 600 LossPred 0.1721 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.9104 0.9000
epoch 700 LossPred 0.1548 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.9142 0.9150
epoch 800 LossPred 0.1412 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.9159 0.9200
epoch 900 LossPred 0.1298 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.9199 0.9150
epoch 1000 LossPred 0.1195 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.9244 0.9150
epoch 1100 LossPred 0.1096 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.9339 0.9200
epoch 1200 LossPred 0.0716 LossAtt 1.0000 TrainAcc 1.0000 TestAcc 0.9527 0.9250
Optimization Finished!
********** replication  56  **********
epoch   0 LossPred 1.1746 LossAtt 1.0000 TrainAcc 0.4600 TestAcc 0.4640 0.4350
epoch 100 LossPred 0.8848 LossAtt 1.0000 TrainAcc 0.7000 TestAcc 0.5841 0.7000
epoch 200 LossPred 0.8420 LossAtt 1.0000 TrainAcc 0.7000 TestAcc 0.5841 0.7000
epoch 300 LossPred 0.8249 LossAtt 1.0000 TrainAcc 0.7000 TestAcc 0.5841 0.7000
epoch 400 LossPred 0.7090 LossAtt 1.0000 TrainAcc 0.6900 TestAcc 0.6224 0.7100
epoch 500 LossPred 0.5788 LossAtt 1.0000 TrainAcc 0.7800 TestAcc 0.7863 0.7950
epoch 600 LossPred 0.5299 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.7943 0.8200
epoch 700 LossPred 0.5204 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.7943 0.8250
epoch 800 LossPred 0.5145 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.7910 0.8200
epoch 900 LossPred 0.5101 LossAtt 1.0000 TrainAcc 0.7900 TestAcc 0.7793 0.8250
epoch 1000 LossPred 0.5070 LossAtt 1.0000 TrainAcc 0.7900 TestAcc 0.7795 0.8300
epoch 1100 LossPred 0.5044 LossAtt 1.0000 TrainAcc 0.7900 TestAcc 0.7800 0.8300
epoch 1200 LossPred 0.5022 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.7780 0.8250
epoch 1300 LossPred 0.4999 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.7773 0.8250
epoch 1400 LossPred 0.4972 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.7748 0.8250
epoch 1500 LossPred 0.4933 LossAtt 1.0000 TrainAcc 0.7900 TestAcc 0.7740 0.8300
epoch 1600 LossPred 0.4834 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.7678 0.8250
epoch 1700 LossPred 0.3552 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.7985 0.8650
epoch 1800 LossPred 0.2994 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8514 0.8450
epoch 1900 LossPred 0.2470 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8611 0.9050
epoch 2000 LossPred 0.1760 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8996 0.9150
epoch 2100 LossPred 0.1039 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.9122 0.8950
epoch 2200 LossPred 0.0849 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.9252 0.9000
epoch 2300 LossPred 0.0663 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.9292 0.9000
epoch 2400 LossPred 0.0870 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.9337 0.9100
epoch 2500 LossPred 0.0487 LossAtt 1.0000 TrainAcc 1.0000 TestAcc 0.9359 0.9200
Optimization Finished!
********** replication  57  **********
epoch   0 LossPred 1.0242 LossAtt 1.0000 TrainAcc 0.5400 TestAcc 0.5741 0.5400
epoch 100 LossPred 0.8759 LossAtt 1.0000 TrainAcc 0.6900 TestAcc 0.6394 0.6950
epoch 200 LossPred 0.4657 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.8281 0.8600
epoch 300 LossPred 0.3385 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8198 0.8350
epoch 400 LossPred 0.2975 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8188 0.8350
epoch 500 LossPred 0.2754 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8226 0.8250
epoch 600 LossPred 0.2541 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8408 0.8450
epoch 700 LossPred 0.2335 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8534 0.8700
epoch 800 LossPred 0.1594 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8644 0.8750
epoch 900 LossPred 0.1402 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8674 0.8750
epoch 1000 LossPred 0.1045 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8729 0.8700
epoch 1100 LossPred 0.0648 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8734 0.8800
epoch 1200 LossPred 0.0508 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8699 0.8900
epoch 1300 LossPred 0.0354 LossAtt 1.0000 TrainAcc 1.0000 TestAcc 0.8759 0.8750
Optimization Finished!
********** replication  58  **********
epoch   0 LossPred 1.1970 LossAtt 1.0000 TrainAcc 0.4600 TestAcc 0.5495 0.4350
epoch 100 LossPred 0.9195 LossAtt 1.0000 TrainAcc 0.6900 TestAcc 0.5798 0.6350
epoch 200 LossPred 0.8065 LossAtt 1.0000 TrainAcc 0.6900 TestAcc 0.6069 0.6750
epoch 300 LossPred 0.4580 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.8146 0.8400
epoch 400 LossPred 0.4004 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.8333 0.8400
epoch 500 LossPred 0.3270 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.8661 0.8450
epoch 600 LossPred 0.2957 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8779 0.8400
epoch 700 LossPred 0.2424 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8834 0.8500
epoch 800 LossPred 0.2288 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8866 0.8700
epoch 900 LossPred 0.2167 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8899 0.8700
epoch 1000 LossPred 0.2017 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8951 0.8650
epoch 1100 LossPred 0.1646 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.9027 0.8650
epoch 1200 LossPred 0.1458 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.9122 0.8950
epoch 1300 LossPred 0.0899 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.9254 0.9200
epoch 1400 LossPred 0.0726 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.9249 0.9100
epoch 1500 LossPred 0.0592 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.9289 0.9100
epoch 1600 LossPred 0.0445 LossAtt 1.0000 TrainAcc 1.0000 TestAcc 0.9307 0.9200
Optimization Finished!
********** replication  59  **********
epoch   0 LossPred 1.2228 LossAtt 1.0000 TrainAcc 0.4100 TestAcc 0.4502 0.4150
epoch 100 LossPred 0.9406 LossAtt 1.0000 TrainAcc 0.6200 TestAcc 0.5841 0.6200
epoch 200 LossPred 0.9019 LossAtt 1.0000 TrainAcc 0.6200 TestAcc 0.5841 0.6250
epoch 300 LossPred 0.5488 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.8143 0.8450
epoch 400 LossPred 0.4402 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.8206 0.8550
epoch 500 LossPred 0.3119 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8368 0.8800
epoch 600 LossPred 0.2269 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8496 0.8900
epoch 700 LossPred 0.1923 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8571 0.8650
epoch 800 LossPred 0.1756 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8566 0.8650
epoch 900 LossPred 0.1636 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8559 0.8650
epoch 1000 LossPred 0.1544 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8549 0.8750
epoch 1100 LossPred 0.1468 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8559 0.8750
epoch 1200 LossPred 0.1401 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8569 0.8750
epoch 1300 LossPred 0.1341 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8574 0.8750
epoch 1400 LossPred 0.1284 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8564 0.8750
epoch 1500 LossPred 0.1225 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8564 0.8800
epoch 1600 LossPred 0.1157 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8584 0.8750
epoch 1700 LossPred 0.1055 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8551 0.8900
epoch 1800 LossPred 0.0913 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8529 0.9000
epoch 1900 LossPred 0.1126 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8561 0.9000
epoch 2000 LossPred 0.0816 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8571 0.9100
epoch 2100 LossPred 0.0754 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8561 0.9050
epoch 2200 LossPred 0.0712 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8554 0.9050
epoch 2300 LossPred 0.0675 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8556 0.9000
epoch 2400 LossPred 0.0641 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8551 0.8950
epoch 2500 LossPred 0.0610 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8541 0.8950
Optimization Finished!
********** replication  60  **********
epoch   0 LossPred 1.0155 LossAtt 1.0000 TrainAcc 0.4600 TestAcc 0.4885 0.4550
epoch 100 LossPred 0.9675 LossAtt 1.0000 TrainAcc 0.5700 TestAcc 0.5833 0.5400
epoch 200 LossPred 0.8052 LossAtt 1.0000 TrainAcc 0.7000 TestAcc 0.7140 0.6900
epoch 300 LossPred 0.6105 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.8028 0.7700
epoch 400 LossPred 0.5612 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.8071 0.7750
epoch 500 LossPred 0.5381 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.8103 0.7900
epoch 600 LossPred 0.5248 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.8111 0.7950
epoch 700 LossPred 0.5105 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.8106 0.8050
epoch 800 LossPred 0.5173 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.8116 0.8150
epoch 900 LossPred 0.5408 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.7858 0.8150
epoch 1000 LossPred 0.5388 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.7868 0.8200
epoch 1100 LossPred 0.5356 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.7885 0.8250
epoch 1200 LossPred 0.5327 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.7880 0.8250
epoch 1300 LossPred 0.6515 LossAtt 1.0000 TrainAcc 0.7700 TestAcc 0.7623 0.7450
epoch 1400 LossPred 0.5444 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.7950 0.7900
epoch 1500 LossPred 0.5189 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.7963 0.8100
epoch 1600 LossPred 0.5167 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.7963 0.8050
epoch 1700 LossPred 0.5132 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.7958 0.7950
epoch 1800 LossPred 0.5104 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.7913 0.7850
epoch 1900 LossPred 0.5085 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.7875 0.7950
epoch 2000 LossPred 0.5074 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.7863 0.7900
epoch 2100 LossPred 0.5067 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.7880 0.7950
epoch 2200 LossPred 0.5060 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.7873 0.7950
epoch 2300 LossPred 0.5053 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.7865 0.8000
epoch 2400 LossPred 0.5045 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.7870 0.7950
epoch 2500 LossPred 0.5037 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.7865 0.7900
Optimization Finished!
********** replication  61  **********
epoch   0 LossPred 1.0188 LossAtt 1.0000 TrainAcc 0.5400 TestAcc 0.5180 0.5350
epoch 100 LossPred 0.9091 LossAtt 1.0000 TrainAcc 0.6200 TestAcc 0.5803 0.6350
epoch 200 LossPred 0.5803 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.7840 0.7950
epoch 300 LossPred 0.2571 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8061 0.8950
epoch 400 LossPred 0.2093 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.7913 0.9050
epoch 500 LossPred 0.1505 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8128 0.9400
epoch 600 LossPred 0.1225 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8338 0.9300
epoch 700 LossPred 0.1011 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8258 0.9150
epoch 800 LossPred 0.0898 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8203 0.9100
epoch 900 LossPred 0.0822 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8186 0.9000
epoch 1000 LossPred 0.0761 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8153 0.9050
epoch 1100 LossPred 0.0700 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8171 0.9000
epoch 1200 LossPred 0.0602 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8296 0.8800
epoch 1300 LossPred 0.0474 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8366 0.8800
epoch 1400 LossPred 0.0376 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8351 0.8950
epoch 1500 LossPred 0.0294 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8316 0.9000
epoch 1600 LossPred 0.0228 LossAtt 1.0000 TrainAcc 1.0000 TestAcc 0.8268 0.8900
Optimization Finished!
********** replication  62  **********
epoch   0 LossPred 1.2874 LossAtt 1.0000 TrainAcc 0.3600 TestAcc 0.4474 0.3700
epoch 100 LossPred 0.9682 LossAtt 1.0000 TrainAcc 0.6400 TestAcc 0.5741 0.6600
epoch 200 LossPred 0.8935 LossAtt 1.0000 TrainAcc 0.6400 TestAcc 0.5688 0.6350
epoch 300 LossPred 0.3677 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8636 0.8850
epoch 400 LossPred 0.2594 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8791 0.8950
epoch 500 LossPred 0.2222 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8884 0.8900
epoch 600 LossPred 0.1985 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8941 0.8750
epoch 700 LossPred 0.6292 LossAtt 1.0000 TrainAcc 0.7700 TestAcc 0.7638 0.7850
epoch 800 LossPred 0.1395 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.9024 0.8900
epoch 900 LossPred 0.1301 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.9004 0.8900
epoch 1000 LossPred 0.1225 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.9009 0.8900
epoch 1100 LossPred 0.1156 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.9019 0.8950
epoch 1200 LossPred 0.1092 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.9029 0.9050
epoch 1300 LossPred 0.1032 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.9047 0.9100
epoch 1400 LossPred 0.0976 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.9077 0.9100
epoch 1500 LossPred 0.0923 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.9087 0.9150
epoch 1600 LossPred 0.0870 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.9112 0.9250
epoch 1700 LossPred 0.0814 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.9144 0.9300
epoch 1800 LossPred 0.0754 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.9147 0.9250
epoch 1900 LossPred 0.0689 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.9187 0.9250
epoch 2000 LossPred 0.0620 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.9192 0.9250
epoch 2100 LossPred 0.0548 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.9192 0.9250
epoch 2200 LossPred 0.0458 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.9109 0.9300
epoch 2300 LossPred 0.0374 LossAtt 1.0000 TrainAcc 1.0000 TestAcc 0.9047 0.9300
Optimization Finished!
********** replication  63  **********
epoch   0 LossPred 1.1135 LossAtt 1.0000 TrainAcc 0.4500 TestAcc 0.4842 0.4450
epoch 100 LossPred 0.9355 LossAtt 1.0000 TrainAcc 0.6100 TestAcc 0.5683 0.5900
epoch 200 LossPred 0.8735 LossAtt 1.0000 TrainAcc 0.6400 TestAcc 0.5766 0.6500
epoch 300 LossPred 0.6732 LossAtt 1.0000 TrainAcc 0.7700 TestAcc 0.7262 0.7700
epoch 400 LossPred 0.2086 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8211 0.8900
epoch 500 LossPred 0.1358 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8216 0.9350
epoch 600 LossPred 0.1116 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8218 0.9200
epoch 700 LossPred 0.0987 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8203 0.9050
epoch 800 LossPred 0.0900 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8181 0.9100
epoch 900 LossPred 0.0835 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8203 0.9000
epoch 1000 LossPred 0.0780 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8213 0.9050
epoch 1100 LossPred 0.0716 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8263 0.9050
epoch 1200 LossPred 0.0582 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8273 0.9150
epoch 1300 LossPred 0.0447 LossAtt 1.0000 TrainAcc 1.0000 TestAcc 0.8263 0.9150
Optimization Finished!
********** replication  64  **********
epoch   0 LossPred 1.1825 LossAtt 1.0000 TrainAcc 0.4400 TestAcc 0.4670 0.4350
epoch 100 LossPred 0.8890 LossAtt 1.0000 TrainAcc 0.6900 TestAcc 0.5858 0.6900
epoch 200 LossPred 0.8030 LossAtt 1.0000 TrainAcc 0.6900 TestAcc 0.5946 0.6750
epoch 300 LossPred 0.6804 LossAtt 1.0000 TrainAcc 0.7900 TestAcc 0.6524 0.7850
epoch 400 LossPred 0.3929 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8063 0.8700
epoch 500 LossPred 0.3631 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8121 0.8700
epoch 600 LossPred 0.3242 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8071 0.8750
epoch 700 LossPred 0.2696 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8068 0.8650
epoch 800 LossPred 0.2427 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8053 0.8550
epoch 900 LossPred 0.2248 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8021 0.8550
epoch 1000 LossPred 0.2113 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8013 0.8500
epoch 1100 LossPred 0.2018 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8011 0.8500
epoch 1200 LossPred 0.1954 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8026 0.8550
epoch 1300 LossPred 0.1907 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8021 0.8550
epoch 1400 LossPred 0.1869 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.7980 0.8550
epoch 1500 LossPred 0.1834 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.7953 0.8650
epoch 1600 LossPred 0.1794 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.7918 0.8550
epoch 1700 LossPred 0.1739 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.7875 0.8500
epoch 1800 LossPred 0.7224 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.6707 0.8050
epoch 1900 LossPred 0.4571 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.7042 0.8350
epoch 2000 LossPred 0.3315 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.7543 0.8600
epoch 2100 LossPred 0.3183 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.7548 0.8650
epoch 2200 LossPred 0.3092 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.7588 0.8600
epoch 2300 LossPred 0.2711 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.7588 0.8550
epoch 2400 LossPred 0.2648 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.7578 0.8500
epoch 2500 LossPred 0.2585 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.7568 0.8500
Optimization Finished!
********** replication  65  **********
epoch   0 LossPred 1.2105 LossAtt 1.0000 TrainAcc 0.4000 TestAcc 0.4775 0.4100
epoch 100 LossPred 0.8694 LossAtt 1.0000 TrainAcc 0.6800 TestAcc 0.5716 0.6600
epoch 200 LossPred 0.8140 LossAtt 1.0000 TrainAcc 0.7000 TestAcc 0.5836 0.6750
epoch 300 LossPred 0.8050 LossAtt 1.0000 TrainAcc 0.7000 TestAcc 0.5958 0.6750
epoch 400 LossPred 0.5909 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.7442 0.7950
epoch 500 LossPred 0.4013 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.8013 0.8550
epoch 600 LossPred 0.3587 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.7963 0.8700
epoch 700 LossPred 0.3465 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.7940 0.8550
epoch 800 LossPred 0.3397 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.7888 0.8550
epoch 900 LossPred 0.3341 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.7858 0.8550
epoch 1000 LossPred 0.3301 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.7900 0.8700
epoch 1100 LossPred 0.3270 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.7913 0.8700
epoch 1200 LossPred 0.3237 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.7925 0.8750
epoch 1300 LossPred 0.3211 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.7935 0.8700
epoch 1400 LossPred 0.3188 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.7940 0.8750
epoch 1500 LossPred 0.3150 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.7978 0.8850
epoch 1600 LossPred 0.2744 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8008 0.9000
epoch 1700 LossPred 0.2710 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8048 0.9000
epoch 1800 LossPred 0.2645 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8071 0.9100
epoch 1900 LossPred 0.2496 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8066 0.9100
epoch 2000 LossPred 0.2414 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8101 0.9200
epoch 2100 LossPred 0.2366 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8128 0.9100
epoch 2200 LossPred 0.2334 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8148 0.9100
epoch 2300 LossPred 0.2311 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8216 0.9000
epoch 2400 LossPred 0.2295 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8236 0.9050
epoch 2500 LossPred 0.2273 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8236 0.9000
Optimization Finished!
********** replication  66  **********
epoch   0 LossPred 1.1216 LossAtt 1.0000 TrainAcc 0.4500 TestAcc 0.4212 0.4550
epoch 100 LossPred 0.8061 LossAtt 1.0000 TrainAcc 0.7200 TestAcc 0.5633 0.7200
epoch 200 LossPred 0.5091 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.7865 0.8650
epoch 300 LossPred 0.3963 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.7958 0.8550
epoch 400 LossPred 0.3309 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8271 0.8750
epoch 500 LossPred 0.3230 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8634 0.8850
epoch 600 LossPred 0.2656 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8739 0.8900
epoch 700 LossPred 0.2241 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8849 0.8950
epoch 800 LossPred 0.2083 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8921 0.9000
epoch 900 LossPred 0.1947 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8999 0.9150
epoch 1000 LossPred 0.1775 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.9142 0.9100
epoch 1100 LossPred 0.1601 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.9209 0.9100
epoch 1200 LossPred 0.1436 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.9239 0.9050
epoch 1300 LossPred 0.1293 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.9222 0.9100
epoch 1400 LossPred 0.1182 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.9194 0.9100
epoch 1500 LossPred 0.1095 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.9149 0.9200
epoch 1600 LossPred 0.1020 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.9109 0.9250
epoch 1700 LossPred 0.0973 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.9082 0.9200
epoch 1800 LossPred 0.0938 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.9034 0.9150
epoch 1900 LossPred 0.0908 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.9017 0.9150
epoch 2000 LossPred 0.0881 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8991 0.9150
epoch 2100 LossPred 0.0814 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8989 0.9000
epoch 2200 LossPred 0.0647 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.9112 0.8800
epoch 2300 LossPred 0.0611 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.9107 0.8850
epoch 2400 LossPred 0.0582 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.9112 0.8850
epoch 2500 LossPred 0.0557 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.9082 0.8900
Optimization Finished!
********** replication  67  **********
epoch   0 LossPred 0.9880 LossAtt 1.0000 TrainAcc 0.5400 TestAcc 0.5370 0.5500
epoch 100 LossPred 0.9306 LossAtt 1.0000 TrainAcc 0.6000 TestAcc 0.5608 0.6000
epoch 200 LossPred 0.8830 LossAtt 1.0000 TrainAcc 0.6700 TestAcc 0.5746 0.6450
epoch 300 LossPred 0.7822 LossAtt 1.0000 TrainAcc 0.7100 TestAcc 0.5748 0.6900
epoch 400 LossPred 0.7343 LossAtt 1.0000 TrainAcc 0.7500 TestAcc 0.5713 0.7050
epoch 500 LossPred 0.6896 LossAtt 1.0000 TrainAcc 0.7600 TestAcc 0.5633 0.7100
epoch 600 LossPred 0.6279 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.5581 0.7250
epoch 700 LossPred 0.5795 LossAtt 1.0000 TrainAcc 0.7900 TestAcc 0.5475 0.7200
epoch 800 LossPred 0.5333 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5470 0.7050
epoch 900 LossPred 0.5434 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5455 0.7050
epoch 1000 LossPred 0.5134 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5435 0.7200
epoch 1100 LossPred 0.5037 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5450 0.7200
epoch 1200 LossPred 0.4956 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.5470 0.7200
epoch 1300 LossPred 0.4885 LossAtt 1.0000 TrainAcc 0.8600 TestAcc 0.5470 0.7150
epoch 1400 LossPred 0.4803 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.5465 0.7100
epoch 1500 LossPred 0.4754 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.5448 0.7100
epoch 1600 LossPred 0.4712 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.5450 0.7050
epoch 1700 LossPred 0.4672 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.5463 0.6950
epoch 1800 LossPred 0.4628 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.5475 0.7050
epoch 1900 LossPred 0.5139 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.5445 0.7100
epoch 2000 LossPred 0.4586 LossAtt 1.0000 TrainAcc 0.8600 TestAcc 0.5453 0.6950
epoch 2100 LossPred 0.4496 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.5460 0.6950
epoch 2200 LossPred 0.4434 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.5470 0.6950
epoch 2300 LossPred 0.4383 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.5465 0.6950
epoch 2400 LossPred 0.4337 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.5465 0.6850
epoch 2500 LossPred 0.4294 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.5475 0.6850
Optimization Finished!
********** replication  68  **********
epoch   0 LossPred 1.0823 LossAtt 1.0000 TrainAcc 0.5500 TestAcc 0.5758 0.5500
epoch 100 LossPred 0.9662 LossAtt 1.0000 TrainAcc 0.5900 TestAcc 0.5666 0.5750
epoch 200 LossPred 0.8919 LossAtt 1.0000 TrainAcc 0.6300 TestAcc 0.5846 0.6500
epoch 300 LossPred 0.8319 LossAtt 1.0000 TrainAcc 0.6800 TestAcc 0.5766 0.6700
epoch 400 LossPred 0.7820 LossAtt 1.0000 TrainAcc 0.7500 TestAcc 0.5393 0.7250
epoch 500 LossPred 0.7351 LossAtt 1.0000 TrainAcc 0.7600 TestAcc 0.5423 0.7250
epoch 600 LossPred 0.6675 LossAtt 1.0000 TrainAcc 0.7900 TestAcc 0.5513 0.7400
epoch 700 LossPred 0.6063 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.5608 0.7400
epoch 800 LossPred 0.5742 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.5608 0.7700
epoch 900 LossPred 0.5585 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5583 0.7600
epoch 1000 LossPred 0.5499 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5558 0.7550
epoch 1100 LossPred 0.5435 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5531 0.7500
epoch 1200 LossPred 0.5388 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5518 0.7500
epoch 1300 LossPred 0.5397 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5475 0.7350
epoch 1400 LossPred 0.5328 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5440 0.7200
epoch 1500 LossPred 0.5278 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5420 0.7150
epoch 1600 LossPred 0.5200 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5410 0.7150
epoch 1700 LossPred 0.5367 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5428 0.6900
epoch 1800 LossPred 0.5222 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5453 0.6900
epoch 1900 LossPred 0.5161 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5443 0.6800
epoch 2000 LossPred 0.5108 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5450 0.6750
epoch 2100 LossPred 0.5063 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5465 0.6850
epoch 2200 LossPred 0.5039 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5438 0.6850
epoch 2300 LossPred 0.4996 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5448 0.6850
epoch 2400 LossPred 0.4999 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5405 0.6900
epoch 2500 LossPred 0.4954 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5423 0.6950
Optimization Finished!
********** replication  69  **********
epoch   0 LossPred 1.4043 LossAtt 1.0000 TrainAcc 0.4400 TestAcc 0.4702 0.4350
epoch 100 LossPred 1.0233 LossAtt 1.0000 TrainAcc 0.5300 TestAcc 0.4975 0.5600
epoch 200 LossPred 0.9156 LossAtt 1.0000 TrainAcc 0.6100 TestAcc 0.5208 0.6000
epoch 300 LossPred 0.8529 LossAtt 1.0000 TrainAcc 0.6300 TestAcc 0.5095 0.6050
epoch 400 LossPred 0.8283 LossAtt 1.0000 TrainAcc 0.6800 TestAcc 0.5165 0.6150
epoch 500 LossPred 0.8062 LossAtt 1.0000 TrainAcc 0.6800 TestAcc 0.5558 0.5850
epoch 600 LossPred 0.7721 LossAtt 1.0000 TrainAcc 0.7100 TestAcc 0.5623 0.6150
epoch 700 LossPred 0.7396 LossAtt 1.0000 TrainAcc 0.7200 TestAcc 0.5673 0.6200
epoch 800 LossPred 0.7237 LossAtt 1.0000 TrainAcc 0.7400 TestAcc 0.5798 0.6450
epoch 900 LossPred 0.7110 LossAtt 1.0000 TrainAcc 0.7400 TestAcc 0.5848 0.6550
epoch 1000 LossPred 0.7015 LossAtt 1.0000 TrainAcc 0.7400 TestAcc 0.5906 0.6550
epoch 1100 LossPred 0.6969 LossAtt 1.0000 TrainAcc 0.7400 TestAcc 0.5921 0.6650
epoch 1200 LossPred 0.6882 LossAtt 1.0000 TrainAcc 0.7500 TestAcc 0.5903 0.6500
epoch 1300 LossPred 0.6809 LossAtt 1.0000 TrainAcc 0.7500 TestAcc 0.5848 0.6550
epoch 1400 LossPred 0.6741 LossAtt 1.0000 TrainAcc 0.7700 TestAcc 0.5878 0.6600
epoch 1500 LossPred 0.6673 LossAtt 1.0000 TrainAcc 0.7800 TestAcc 0.5848 0.6650
epoch 1600 LossPred 0.6604 LossAtt 1.0000 TrainAcc 0.7700 TestAcc 0.5923 0.6650
epoch 1700 LossPred 0.6541 LossAtt 1.0000 TrainAcc 0.7600 TestAcc 0.5908 0.6600
epoch 1800 LossPred 0.6485 LossAtt 1.0000 TrainAcc 0.7600 TestAcc 0.5871 0.6650
epoch 1900 LossPred 0.6371 LossAtt 1.0000 TrainAcc 0.7600 TestAcc 0.5838 0.6750
epoch 2000 LossPred 0.6210 LossAtt 1.0000 TrainAcc 0.7600 TestAcc 0.5801 0.6700
epoch 2100 LossPred 0.5983 LossAtt 1.0000 TrainAcc 0.7800 TestAcc 0.5866 0.6400
epoch 2200 LossPred 0.5775 LossAtt 1.0000 TrainAcc 0.7900 TestAcc 0.5846 0.6450
epoch 2300 LossPred 0.6153 LossAtt 1.0000 TrainAcc 0.7500 TestAcc 0.5886 0.6350
epoch 2400 LossPred 0.5741 LossAtt 1.0000 TrainAcc 0.7700 TestAcc 0.5871 0.6300
epoch 2500 LossPred 0.5850 LossAtt 1.0000 TrainAcc 0.7500 TestAcc 0.5898 0.6600
Optimization Finished!
********** replication  70  **********
epoch   0 LossPred 1.0743 LossAtt 1.0000 TrainAcc 0.6000 TestAcc 0.5458 0.5850
epoch 100 LossPred 0.9267 LossAtt 1.0000 TrainAcc 0.6500 TestAcc 0.5495 0.6350
epoch 200 LossPred 0.8929 LossAtt 1.0000 TrainAcc 0.6400 TestAcc 0.5748 0.6450
epoch 300 LossPred 0.7090 LossAtt 1.0000 TrainAcc 0.7600 TestAcc 0.6747 0.7600
epoch 400 LossPred 0.3341 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.7968 0.8700
epoch 500 LossPred 0.2710 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8056 0.8700
epoch 600 LossPred 0.2082 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8053 0.8650
epoch 700 LossPred 0.1823 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8026 0.8750
epoch 800 LossPred 0.1666 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8006 0.8750
epoch 900 LossPred 0.1541 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.7963 0.8750
epoch 1000 LossPred 0.1350 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.7853 0.8750
epoch 1100 LossPred 0.1175 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.7833 0.8950
epoch 1200 LossPred 0.0987 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.7878 0.8850
epoch 1300 LossPred 0.1951 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.7823 0.8700
epoch 1400 LossPred 0.1710 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.7803 0.8550
epoch 1500 LossPred 0.1604 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.7888 0.8550
epoch 1600 LossPred 0.1532 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.7878 0.8750
epoch 1700 LossPred 0.1471 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.7840 0.8500
epoch 1800 LossPred 0.1425 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.7828 0.8550
epoch 1900 LossPred 0.1382 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.7788 0.8600
epoch 2000 LossPred 0.1341 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.7768 0.8500
epoch 2100 LossPred 0.1302 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.7763 0.8400
epoch 2200 LossPred 0.1264 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.7783 0.8400
epoch 2300 LossPred 0.1229 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.7803 0.8400
epoch 2400 LossPred 0.1192 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.7790 0.8350
epoch 2500 LossPred 0.1142 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.7778 0.8500
Optimization Finished!
********** replication  71  **********
epoch   0 LossPred 1.0689 LossAtt 1.0000 TrainAcc 0.5500 TestAcc 0.5418 0.5600
epoch 100 LossPred 0.9660 LossAtt 1.0000 TrainAcc 0.6000 TestAcc 0.5676 0.5850
epoch 200 LossPred 0.7546 LossAtt 1.0000 TrainAcc 0.7500 TestAcc 0.7402 0.7350
epoch 300 LossPred 0.2889 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8851 0.9000
epoch 400 LossPred 0.2018 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8649 0.8850
epoch 500 LossPred 0.1521 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8541 0.8900
epoch 600 LossPred 0.1328 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8506 0.9050
epoch 700 LossPred 0.1219 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8509 0.9150
epoch 800 LossPred 0.1150 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8564 0.9150
epoch 900 LossPred 0.1080 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8549 0.9150
epoch 1000 LossPred 0.1039 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8559 0.9150
epoch 1100 LossPred 0.0995 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8574 0.9150
epoch 1200 LossPred 0.0958 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8566 0.9150
epoch 1300 LossPred 0.0925 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8569 0.9150
epoch 1400 LossPred 0.0894 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8551 0.9100
epoch 1500 LossPred 0.0893 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8571 0.9150
epoch 1600 LossPred 0.0912 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8481 0.9050
epoch 1700 LossPred 0.0829 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8561 0.9100
epoch 1800 LossPred 0.0819 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8501 0.9000
epoch 1900 LossPred 0.0786 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8504 0.9050
epoch 2000 LossPred 0.0771 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8561 0.9100
epoch 2100 LossPred 0.0730 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8529 0.9100
epoch 2200 LossPred 0.0700 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8504 0.9000
epoch 2300 LossPred 0.0672 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8514 0.9000
epoch 2400 LossPred 0.0647 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8514 0.9050
epoch 2500 LossPred 0.0625 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8519 0.9100
Optimization Finished!
********** replication  72  **********
epoch   0 LossPred 1.0146 LossAtt 1.0000 TrainAcc 0.5400 TestAcc 0.5651 0.5150
epoch 100 LossPred 0.8755 LossAtt 1.0000 TrainAcc 0.6600 TestAcc 0.5771 0.6500
epoch 200 LossPred 0.3668 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8721 0.8600
epoch 300 LossPred 0.2692 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8664 0.8550
epoch 400 LossPred 0.2308 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8599 0.8650
epoch 500 LossPred 0.2080 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8589 0.8650
epoch 600 LossPred 0.1912 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8559 0.8700
epoch 700 LossPred 0.1779 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8556 0.8750
epoch 800 LossPred 0.1671 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8556 0.8650
epoch 900 LossPred 0.1574 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8606 0.8700
epoch 1000 LossPred 0.1500 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8614 0.8750
epoch 1100 LossPred 0.1420 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8649 0.8750
epoch 1200 LossPred 0.1337 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8666 0.8800
epoch 1300 LossPred 0.1263 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8679 0.8900
epoch 1400 LossPred 0.1181 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8671 0.8900
epoch 1500 LossPred 0.1084 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8669 0.8850
epoch 1600 LossPred 0.0975 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8671 0.8750
epoch 1700 LossPred 0.0868 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8646 0.8800
epoch 1800 LossPred 0.0774 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8621 0.8750
epoch 1900 LossPred 0.0695 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8639 0.8700
epoch 2000 LossPred 0.0630 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8626 0.8800
epoch 2100 LossPred 0.0577 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8619 0.8850
epoch 2200 LossPred 0.0532 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8594 0.8850
epoch 2300 LossPred 0.0492 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8584 0.8900
epoch 2400 LossPred 0.0457 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8584 0.8950
epoch 2500 LossPred 0.0425 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8591 0.8950
Optimization Finished!
********** replication  73  **********
epoch   0 LossPred 1.0246 LossAtt 1.0000 TrainAcc 0.5700 TestAcc 0.5468 0.5750
epoch 100 LossPred 0.9044 LossAtt 1.0000 TrainAcc 0.6100 TestAcc 0.5536 0.6050
epoch 200 LossPred 0.8491 LossAtt 1.0000 TrainAcc 0.6800 TestAcc 0.6046 0.6900
epoch 300 LossPred 0.3899 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8148 0.8950
epoch 400 LossPred 0.2175 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8421 0.9150
epoch 500 LossPred 0.1710 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8443 0.9150
epoch 600 LossPred 0.1063 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8524 0.9050
epoch 700 LossPred 0.0553 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8556 0.9100
epoch 800 LossPred 0.0335 LossAtt 1.0000 TrainAcc 1.0000 TestAcc 0.8526 0.9300
Optimization Finished!
********** replication  74  **********
epoch   0 LossPred 1.1432 LossAtt 1.0000 TrainAcc 0.3900 TestAcc 0.4815 0.4000
epoch 100 LossPred 0.8938 LossAtt 1.0000 TrainAcc 0.6400 TestAcc 0.5788 0.6350
epoch 200 LossPred 0.8036 LossAtt 1.0000 TrainAcc 0.7000 TestAcc 0.5773 0.7000
epoch 300 LossPred 0.7299 LossAtt 1.0000 TrainAcc 0.7000 TestAcc 0.5768 0.7000
epoch 400 LossPred 0.5785 LossAtt 1.0000 TrainAcc 0.7800 TestAcc 0.7037 0.7700
epoch 500 LossPred 0.5299 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.7312 0.7950
epoch 600 LossPred 0.2576 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8176 0.8650
epoch 700 LossPred 0.1679 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8333 0.8950
epoch 800 LossPred 0.1426 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8358 0.9050
epoch 900 LossPred 0.1220 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8361 0.9100
epoch 1000 LossPred 0.1048 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8366 0.9100
epoch 1100 LossPred 0.0943 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8358 0.9100
epoch 1200 LossPred 0.0869 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8383 0.9050
epoch 1300 LossPred 0.0809 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8368 0.9100
epoch 1400 LossPred 0.0759 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8358 0.9150
epoch 1500 LossPred 0.0716 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8333 0.9100
epoch 1600 LossPred 0.0677 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8333 0.9050
epoch 1700 LossPred 0.0597 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8346 0.9150
epoch 1800 LossPred 0.0447 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8301 0.8950
epoch 1900 LossPred 0.0355 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8258 0.9050
epoch 2000 LossPred 0.0284 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8256 0.9000
epoch 2100 LossPred 0.0228 LossAtt 1.0000 TrainAcc 1.0000 TestAcc 0.8288 0.9100
Optimization Finished!
********** replication  75  **********
epoch   0 LossPred 1.2479 LossAtt 1.0000 TrainAcc 0.5800 TestAcc 0.4985 0.5500
epoch 100 LossPred 1.0137 LossAtt 1.0000 TrainAcc 0.5800 TestAcc 0.4985 0.5800
epoch 200 LossPred 0.9498 LossAtt 1.0000 TrainAcc 0.5800 TestAcc 0.4985 0.5800
epoch 300 LossPred 0.5319 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8028 0.8750
epoch 400 LossPred 0.3540 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8058 0.8950
epoch 500 LossPred 0.2475 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8171 0.8950
epoch 600 LossPred 0.1979 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8356 0.9050
epoch 700 LossPred 0.1308 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8376 0.9000
epoch 800 LossPred 0.1129 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8406 0.9050
epoch 900 LossPred 0.1035 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8391 0.9050
epoch 1000 LossPred 0.0971 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8368 0.9100
epoch 1100 LossPred 0.0925 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8348 0.9100
epoch 1200 LossPred 0.0890 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8356 0.9100
epoch 1300 LossPred 0.0858 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8336 0.9100
epoch 1400 LossPred 0.0837 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8318 0.9050
epoch 1500 LossPred 0.0819 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8311 0.9050
epoch 1600 LossPred 0.0805 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8318 0.9050
epoch 1700 LossPred 0.0791 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8313 0.9000
epoch 1800 LossPred 0.0779 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8301 0.9000
epoch 1900 LossPred 0.1295 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8336 0.9000
epoch 2000 LossPred 0.0388 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8341 0.8850
epoch 2100 LossPred 0.0377 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8358 0.9000
epoch 2200 LossPred 0.0369 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8366 0.9000
epoch 2300 LossPred 0.0362 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8383 0.9000
epoch 2400 LossPred 0.0355 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8383 0.9000
epoch 2500 LossPred 0.0348 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8391 0.9000
Optimization Finished!
********** replication  76  **********
epoch   0 LossPred 1.0056 LossAtt 1.0000 TrainAcc 0.5500 TestAcc 0.5428 0.5400
epoch 100 LossPred 0.8678 LossAtt 1.0000 TrainAcc 0.6600 TestAcc 0.5716 0.6750
epoch 200 LossPred 0.7736 LossAtt 1.0000 TrainAcc 0.7200 TestAcc 0.5793 0.7450
epoch 300 LossPred 0.6359 LossAtt 1.0000 TrainAcc 0.7800 TestAcc 0.6244 0.7650
epoch 400 LossPred 0.5097 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.6139 0.7800
epoch 500 LossPred 0.4626 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.6324 0.7600
epoch 600 LossPred 0.4264 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.6299 0.7650
epoch 700 LossPred 0.4100 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.6294 0.7550
epoch 800 LossPred 0.3983 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.6296 0.7550
epoch 900 LossPred 0.3867 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.6324 0.7600
epoch 1000 LossPred 0.4395 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.6481 0.7800
epoch 1100 LossPred 0.4222 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.6341 0.7850
epoch 1200 LossPred 0.3660 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.6411 0.7650
epoch 1300 LossPred 0.3565 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.6444 0.7700
epoch 1400 LossPred 0.3430 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.6454 0.7700
epoch 1500 LossPred 0.3317 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.6484 0.7800
epoch 1600 LossPred 0.3246 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.6426 0.7800
epoch 1700 LossPred 0.3199 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.6429 0.7850
epoch 1800 LossPred 0.3161 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.6431 0.7850
epoch 1900 LossPred 0.3127 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.6434 0.7850
epoch 2000 LossPred 0.3095 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.6434 0.7750
epoch 2100 LossPred 0.3064 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.6436 0.7800
epoch 2200 LossPred 0.5137 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.6461 0.7900
epoch 2300 LossPred 0.3590 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.6752 0.8150
epoch 2400 LossPred 0.5926 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.6649 0.7500
epoch 2500 LossPred 0.6360 LossAtt 1.0000 TrainAcc 0.7700 TestAcc 0.6226 0.7300
Optimization Finished!
********** replication  77  **********
epoch   0 LossPred 0.9939 LossAtt 1.0000 TrainAcc 0.5900 TestAcc 0.5636 0.5600
epoch 100 LossPred 0.8690 LossAtt 1.0000 TrainAcc 0.6400 TestAcc 0.5803 0.6450
epoch 200 LossPred 0.8004 LossAtt 1.0000 TrainAcc 0.6800 TestAcc 0.5793 0.6800
epoch 300 LossPred 0.4456 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.7620 0.8000
epoch 400 LossPred 0.3326 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.7865 0.8100
epoch 500 LossPred 0.3066 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.7838 0.7800
epoch 600 LossPred 0.2868 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.7765 0.7650
epoch 700 LossPred 0.2777 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.7740 0.7600
epoch 800 LossPred 0.2719 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.7730 0.7600
epoch 900 LossPred 0.2671 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.7693 0.7550
epoch 1000 LossPred 0.2633 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.7698 0.7600
epoch 1100 LossPred 0.2598 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.7675 0.7600
epoch 1200 LossPred 0.2565 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.7685 0.7550
epoch 1300 LossPred 0.2534 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.7668 0.7600
epoch 1400 LossPred 0.2507 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.7678 0.7600
epoch 1500 LossPred 0.2454 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.7673 0.7350
epoch 1600 LossPred 0.2390 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.7715 0.7450
epoch 1700 LossPred 0.2344 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.7755 0.7450
epoch 1800 LossPred 0.2306 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.7760 0.7400
epoch 1900 LossPred 0.2274 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.7788 0.7500
epoch 2000 LossPred 0.2247 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.7765 0.7450
epoch 2100 LossPred 0.2223 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.7760 0.7450
epoch 2200 LossPred 0.2203 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.7748 0.7450
epoch 2300 LossPred 0.2186 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.7760 0.7500
epoch 2400 LossPred 0.2171 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.7745 0.7500
epoch 2500 LossPred 0.2157 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.7743 0.7450
Optimization Finished!
********** replication  78  **********
epoch   0 LossPred 1.0237 LossAtt 1.0000 TrainAcc 0.5500 TestAcc 0.5673 0.5300
epoch 100 LossPred 0.8765 LossAtt 1.0000 TrainAcc 0.6500 TestAcc 0.6424 0.6400
epoch 200 LossPred 0.4466 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.8071 0.8450
epoch 300 LossPred 0.4077 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.8081 0.8400
epoch 400 LossPred 0.3867 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.8093 0.8450
epoch 500 LossPred 0.3695 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.8143 0.8400
epoch 600 LossPred 0.3503 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.8251 0.8450
epoch 700 LossPred 0.8193 LossAtt 1.0000 TrainAcc 0.7500 TestAcc 0.7272 0.7250
epoch 800 LossPred 0.3342 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8358 0.8900
epoch 900 LossPred 0.3040 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.8551 0.9000
epoch 1000 LossPred 0.2225 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8609 0.8800
epoch 1100 LossPred 0.2130 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8641 0.8700
epoch 1200 LossPred 0.2053 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8679 0.8750
epoch 1300 LossPred 0.1987 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8699 0.8800
epoch 1400 LossPred 0.1929 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8764 0.8800
epoch 1500 LossPred 0.1786 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8834 0.9000
epoch 1600 LossPred 0.1505 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8846 0.9050
epoch 1700 LossPred 0.1409 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8899 0.9150
epoch 1800 LossPred 0.1358 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8884 0.9050
epoch 1900 LossPred 0.1328 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8861 0.9100
epoch 2000 LossPred 0.1302 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8851 0.9050
epoch 2100 LossPred 0.1278 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8846 0.9050
epoch 2200 LossPred 0.1253 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8816 0.9050
epoch 2300 LossPred 0.1222 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8759 0.9000
epoch 2400 LossPred 0.2185 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8679 0.9000
epoch 2500 LossPred 0.1279 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8844 0.9150
Optimization Finished!
********** replication  79  **********
epoch   0 LossPred 1.1695 LossAtt 1.0000 TrainAcc 0.4500 TestAcc 0.4905 0.4700
epoch 100 LossPred 0.9690 LossAtt 1.0000 TrainAcc 0.5700 TestAcc 0.5508 0.5850
epoch 200 LossPred 0.9164 LossAtt 1.0000 TrainAcc 0.5800 TestAcc 0.5783 0.6550
epoch 300 LossPred 0.8783 LossAtt 1.0000 TrainAcc 0.6400 TestAcc 0.6496 0.6300
epoch 400 LossPred 0.8568 LossAtt 1.0000 TrainAcc 0.6600 TestAcc 0.6517 0.6250
epoch 500 LossPred 0.8414 LossAtt 1.0000 TrainAcc 0.6700 TestAcc 0.6484 0.6650
epoch 600 LossPred 0.8251 LossAtt 1.0000 TrainAcc 0.6800 TestAcc 0.6504 0.6600
epoch 700 LossPred 0.8069 LossAtt 1.0000 TrainAcc 0.6700 TestAcc 0.6351 0.6600
epoch 800 LossPred 0.7839 LossAtt 1.0000 TrainAcc 0.6800 TestAcc 0.6234 0.6700
epoch 900 LossPred 0.7716 LossAtt 1.0000 TrainAcc 0.6900 TestAcc 0.6209 0.6800
epoch 1000 LossPred 0.7615 LossAtt 1.0000 TrainAcc 0.6900 TestAcc 0.6129 0.6750
epoch 1100 LossPred 0.7520 LossAtt 1.0000 TrainAcc 0.7200 TestAcc 0.6041 0.6700
epoch 1200 LossPred 0.7359 LossAtt 1.0000 TrainAcc 0.7300 TestAcc 0.5971 0.6600
epoch 1300 LossPred 0.7042 LossAtt 1.0000 TrainAcc 0.7300 TestAcc 0.5951 0.6550
epoch 1400 LossPred 0.6777 LossAtt 1.0000 TrainAcc 0.7400 TestAcc 0.5796 0.6650
epoch 1500 LossPred 0.6488 LossAtt 1.0000 TrainAcc 0.7200 TestAcc 0.5863 0.6650
epoch 1600 LossPred 0.6266 LossAtt 1.0000 TrainAcc 0.7700 TestAcc 0.5836 0.6650
epoch 1700 LossPred 0.6088 LossAtt 1.0000 TrainAcc 0.7800 TestAcc 0.5826 0.6850
epoch 1800 LossPred 0.5946 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.5768 0.6800
epoch 1900 LossPred 0.5861 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.5753 0.6850
epoch 2000 LossPred 0.5715 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.5751 0.6800
epoch 2100 LossPred 0.6905 LossAtt 1.0000 TrainAcc 0.7500 TestAcc 0.5771 0.6700
epoch 2200 LossPred 0.6179 LossAtt 1.0000 TrainAcc 0.7800 TestAcc 0.5838 0.6600
epoch 2300 LossPred 0.6140 LossAtt 1.0000 TrainAcc 0.7900 TestAcc 0.5808 0.6700
epoch 2400 LossPred 0.6118 LossAtt 1.0000 TrainAcc 0.7900 TestAcc 0.5798 0.6750
epoch 2500 LossPred 0.6097 LossAtt 1.0000 TrainAcc 0.7900 TestAcc 0.5803 0.6750
Optimization Finished!
********** replication  80  **********
epoch   0 LossPred 1.0865 LossAtt 1.0000 TrainAcc 0.5700 TestAcc 0.4627 0.5600
epoch 100 LossPred 0.9628 LossAtt 1.0000 TrainAcc 0.6200 TestAcc 0.5518 0.6250
epoch 200 LossPred 0.7213 LossAtt 1.0000 TrainAcc 0.7600 TestAcc 0.6446 0.7450
epoch 300 LossPred 0.3438 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8544 0.8650
epoch 400 LossPred 0.2260 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8661 0.8750
epoch 500 LossPred 0.2003 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8644 0.8800
epoch 600 LossPred 0.1866 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8646 0.8850
epoch 700 LossPred 0.1746 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8699 0.8950
epoch 800 LossPred 0.1592 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8719 0.8950
epoch 900 LossPred 0.1203 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8831 0.8900
epoch 1000 LossPred 0.1035 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8831 0.9050
epoch 1100 LossPred 0.0972 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8826 0.9100
epoch 1200 LossPred 0.1444 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8816 0.9100
epoch 1300 LossPred 0.0345 LossAtt 1.0000 TrainAcc 1.0000 TestAcc 0.8779 0.9250
Optimization Finished!
********** replication  81  **********
epoch   0 LossPred 1.0761 LossAtt 1.0000 TrainAcc 0.5400 TestAcc 0.4690 0.4900
epoch 100 LossPred 0.9052 LossAtt 1.0000 TrainAcc 0.6200 TestAcc 0.5821 0.5950
epoch 200 LossPred 0.8748 LossAtt 1.0000 TrainAcc 0.6600 TestAcc 0.5886 0.5900
epoch 300 LossPred 0.8590 LossAtt 1.0000 TrainAcc 0.5900 TestAcc 0.6109 0.6150
epoch 400 LossPred 0.5636 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.8081 0.8600
epoch 500 LossPred 0.3769 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8699 0.8950
epoch 600 LossPred 0.2836 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8926 0.8850
epoch 700 LossPred 0.2209 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.9017 0.8800
epoch 800 LossPred 0.1905 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.9154 0.8800
epoch 900 LossPred 0.1406 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.9322 0.9050
epoch 1000 LossPred 0.1211 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.9309 0.9000
epoch 1100 LossPred 0.1052 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.9327 0.9000
epoch 1200 LossPred 0.0914 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.9332 0.9000
epoch 1300 LossPred 0.0798 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.9342 0.8900
epoch 1400 LossPred 0.0703 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.9344 0.8900
epoch 1500 LossPred 0.0625 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.9344 0.8850
epoch 1600 LossPred 0.0559 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.9354 0.8800
epoch 1700 LossPred 0.0499 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.9357 0.8750
epoch 1800 LossPred 0.0439 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.9372 0.8800
epoch 1900 LossPred 0.0537 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.9374 0.8750
epoch 2000 LossPred 0.0348 LossAtt 1.0000 TrainAcc 1.0000 TestAcc 0.9377 0.8850
Optimization Finished!
********** replication  82  **********
epoch   0 LossPred 1.1580 LossAtt 1.0000 TrainAcc 0.4700 TestAcc 0.5118 0.4750
epoch 100 LossPred 0.9186 LossAtt 1.0000 TrainAcc 0.6300 TestAcc 0.5881 0.6250
epoch 200 LossPred 0.9091 LossAtt 1.0000 TrainAcc 0.6300 TestAcc 0.5978 0.6250
epoch 300 LossPred 0.7711 LossAtt 1.0000 TrainAcc 0.7200 TestAcc 0.7105 0.7200
epoch 400 LossPred 0.3954 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.8669 0.8400
epoch 500 LossPred 0.3602 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.8664 0.8450
epoch 600 LossPred 0.3365 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.8679 0.8500
epoch 700 LossPred 0.3113 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8696 0.8250
epoch 800 LossPred 0.2872 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8654 0.8350
epoch 900 LossPred 0.2716 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8641 0.8300
epoch 1000 LossPred 0.2276 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8971 0.8500
epoch 1100 LossPred 0.1297 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.9097 0.8700
epoch 1200 LossPred 0.1128 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.9104 0.8600
epoch 1300 LossPred 0.0985 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.9109 0.8650
epoch 1400 LossPred 0.0856 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.9112 0.8600
epoch 1500 LossPred 0.0734 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.9102 0.8650
epoch 1600 LossPred 0.0621 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.9099 0.8600
epoch 1700 LossPred 0.0520 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.9097 0.8600
epoch 1800 LossPred 0.0435 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.9052 0.8600
epoch 1900 LossPred 0.0367 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.9039 0.8650
epoch 2000 LossPred 0.0315 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.9002 0.8700
epoch 2100 LossPred 0.0275 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8979 0.8700
epoch 2200 LossPred 0.0242 LossAtt 1.0000 TrainAcc 1.0000 TestAcc 0.8986 0.8600
Optimization Finished!
********** replication  83  **********
epoch   0 LossPred 0.9555 LossAtt 1.0000 TrainAcc 0.6400 TestAcc 0.5608 0.6150
epoch 100 LossPred 0.8705 LossAtt 1.0000 TrainAcc 0.6600 TestAcc 0.5628 0.6700
epoch 200 LossPred 0.5162 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.7492 0.8400
epoch 300 LossPred 0.1581 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8681 0.9300
epoch 400 LossPred 0.0774 LossAtt 1.0000 TrainAcc 1.0000 TestAcc 0.8651 0.9500
Optimization Finished!
********** replication  84  **********
epoch   0 LossPred 1.1529 LossAtt 1.0000 TrainAcc 0.4500 TestAcc 0.4560 0.4500
epoch 100 LossPred 0.9672 LossAtt 1.0000 TrainAcc 0.5700 TestAcc 0.5713 0.5750
epoch 200 LossPred 0.9235 LossAtt 1.0000 TrainAcc 0.6400 TestAcc 0.5741 0.5900
epoch 300 LossPred 0.8798 LossAtt 1.0000 TrainAcc 0.6800 TestAcc 0.5738 0.6600
epoch 400 LossPred 0.8461 LossAtt 1.0000 TrainAcc 0.7000 TestAcc 0.5603 0.6900
epoch 500 LossPred 0.8095 LossAtt 1.0000 TrainAcc 0.7100 TestAcc 0.5523 0.6800
epoch 600 LossPred 0.7528 LossAtt 1.0000 TrainAcc 0.7300 TestAcc 0.5603 0.7000
epoch 700 LossPred 0.6486 LossAtt 1.0000 TrainAcc 0.7600 TestAcc 0.5693 0.7050
epoch 800 LossPred 0.6016 LossAtt 1.0000 TrainAcc 0.7800 TestAcc 0.5465 0.7150
epoch 900 LossPred 0.5606 LossAtt 1.0000 TrainAcc 0.7800 TestAcc 0.5383 0.7200
epoch 1000 LossPred 0.5361 LossAtt 1.0000 TrainAcc 0.7900 TestAcc 0.5400 0.7100
epoch 1100 LossPred 0.5143 LossAtt 1.0000 TrainAcc 0.7900 TestAcc 0.5390 0.7150
epoch 1200 LossPred 0.5613 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.5508 0.7450
epoch 1300 LossPred 0.5093 LossAtt 1.0000 TrainAcc 0.8600 TestAcc 0.5738 0.7350
epoch 1400 LossPred 0.5933 LossAtt 1.0000 TrainAcc 0.7800 TestAcc 0.5270 0.7200
epoch 1500 LossPred 0.5489 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.5213 0.7400
epoch 1600 LossPred 0.5448 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.5153 0.7300
epoch 1700 LossPred 0.5284 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.5248 0.7150
epoch 1800 LossPred 0.5171 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.5263 0.7250
epoch 1900 LossPred 0.5075 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.5333 0.7200
epoch 2000 LossPred 0.4968 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5313 0.7250
epoch 2100 LossPred 0.4864 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.5305 0.7400
epoch 2200 LossPred 0.4790 LossAtt 1.0000 TrainAcc 0.8600 TestAcc 0.5263 0.7300
epoch 2300 LossPred 0.4711 LossAtt 1.0000 TrainAcc 0.8600 TestAcc 0.5248 0.7150
epoch 2400 LossPred 0.4414 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.5330 0.7200
epoch 2500 LossPred 0.4152 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.5350 0.7150
Optimization Finished!
********** replication  85  **********
epoch   0 LossPred 1.2071 LossAtt 1.0000 TrainAcc 0.3900 TestAcc 0.4857 0.3700
epoch 100 LossPred 0.9166 LossAtt 1.0000 TrainAcc 0.6200 TestAcc 0.5178 0.6350
epoch 200 LossPred 0.8992 LossAtt 1.0000 TrainAcc 0.6400 TestAcc 0.5503 0.6000
epoch 300 LossPred 0.8907 LossAtt 1.0000 TrainAcc 0.6400 TestAcc 0.5728 0.6250
epoch 400 LossPred 0.8596 LossAtt 1.0000 TrainAcc 0.6600 TestAcc 0.5588 0.6500
epoch 500 LossPred 0.7607 LossAtt 1.0000 TrainAcc 0.7600 TestAcc 0.5816 0.7300
epoch 600 LossPred 0.7191 LossAtt 1.0000 TrainAcc 0.7500 TestAcc 0.5786 0.7200
epoch 700 LossPred 0.6975 LossAtt 1.0000 TrainAcc 0.7500 TestAcc 0.5761 0.7300
epoch 800 LossPred 0.6577 LossAtt 1.0000 TrainAcc 0.7500 TestAcc 0.5711 0.7200
epoch 900 LossPred 0.6224 LossAtt 1.0000 TrainAcc 0.7800 TestAcc 0.5676 0.7150
epoch 1000 LossPred 0.6093 LossAtt 1.0000 TrainAcc 0.7900 TestAcc 0.5681 0.7300
epoch 1100 LossPred 0.5979 LossAtt 1.0000 TrainAcc 0.7800 TestAcc 0.5688 0.7200
epoch 1200 LossPred 0.5817 LossAtt 1.0000 TrainAcc 0.7900 TestAcc 0.5696 0.7150
epoch 1300 LossPred 0.5666 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.5706 0.7200
epoch 1400 LossPred 0.5433 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.5636 0.7200
epoch 1500 LossPred 0.5207 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.5616 0.7350
epoch 1600 LossPred 0.5008 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5616 0.7400
epoch 1700 LossPred 0.4964 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.5598 0.7250
epoch 1800 LossPred 0.4779 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.5573 0.7250
epoch 1900 LossPred 0.4679 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.5583 0.7150
epoch 2000 LossPred 0.4581 LossAtt 1.0000 TrainAcc 0.8600 TestAcc 0.5601 0.7150
epoch 2100 LossPred 0.4479 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.5608 0.7300
epoch 2200 LossPred 0.4867 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.5618 0.7600
epoch 2300 LossPred 0.9520 LossAtt 1.0000 TrainAcc 0.7200 TestAcc 0.5691 0.6800
epoch 2400 LossPred 0.8824 LossAtt 1.0000 TrainAcc 0.7300 TestAcc 0.5666 0.6750
epoch 2500 LossPred 0.8528 LossAtt 1.0000 TrainAcc 0.7300 TestAcc 0.5673 0.6800
Optimization Finished!
********** replication  86  **********
epoch   0 LossPred 1.0976 LossAtt 1.0000 TrainAcc 0.4300 TestAcc 0.4202 0.4300
epoch 100 LossPred 0.9453 LossAtt 1.0000 TrainAcc 0.6000 TestAcc 0.5831 0.5850
epoch 200 LossPred 0.5377 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.8178 0.8250
epoch 300 LossPred 0.3554 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8156 0.8350
epoch 400 LossPred 0.3200 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.8143 0.8400
epoch 500 LossPred 0.3103 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.8136 0.8450
epoch 600 LossPred 0.3045 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8126 0.8500
epoch 700 LossPred 0.3000 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8098 0.8600
epoch 800 LossPred 0.2959 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8088 0.8550
epoch 900 LossPred 0.2919 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8081 0.8500
epoch 1000 LossPred 0.2880 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8076 0.8500
epoch 1100 LossPred 0.2842 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8053 0.8500
epoch 1200 LossPred 0.3483 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.7973 0.8450
epoch 1300 LossPred 0.3722 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.8203 0.8600
epoch 1400 LossPred 0.3166 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8028 0.8550
epoch 1500 LossPred 0.2787 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8111 0.8600
epoch 1600 LossPred 0.2762 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8076 0.8550
epoch 1700 LossPred 0.2741 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8066 0.8600
epoch 1800 LossPred 0.2721 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8058 0.8650
epoch 1900 LossPred 0.2701 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8061 0.8650
epoch 2000 LossPred 0.2682 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8058 0.8650
epoch 2100 LossPred 0.2664 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8048 0.8650
epoch 2200 LossPred 0.2645 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8041 0.8650
epoch 2300 LossPred 0.2627 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8036 0.8650
epoch 2400 LossPred 0.2609 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8023 0.8650
epoch 2500 LossPred 0.2592 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8018 0.8650
Optimization Finished!
********** replication  87  **********
epoch   0 LossPred 1.2402 LossAtt 1.0000 TrainAcc 0.4900 TestAcc 0.5298 0.4800
epoch 100 LossPred 0.8900 LossAtt 1.0000 TrainAcc 0.6400 TestAcc 0.5806 0.6450
epoch 200 LossPred 0.8253 LossAtt 1.0000 TrainAcc 0.7300 TestAcc 0.5843 0.6900
epoch 300 LossPred 0.7590 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.5863 0.7450
epoch 400 LossPred 0.7113 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.5793 0.7550
epoch 500 LossPred 0.6894 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.5768 0.7300
epoch 600 LossPred 0.6749 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.5808 0.7450
epoch 700 LossPred 0.6634 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.5801 0.7450
epoch 800 LossPred 0.6568 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.5781 0.7450
epoch 900 LossPred 0.6477 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.5771 0.7450
epoch 1000 LossPred 0.6404 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.5773 0.7400
epoch 1100 LossPred 0.6326 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.5781 0.7450
epoch 1200 LossPred 0.6246 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5771 0.7450
epoch 1300 LossPred 0.6301 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.5748 0.7400
epoch 1400 LossPred 0.6169 LossAtt 1.0000 TrainAcc 0.7900 TestAcc 0.5743 0.7400
epoch 1500 LossPred 0.6105 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.5716 0.7400
epoch 1600 LossPred 0.6046 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.5711 0.7450
epoch 1700 LossPred 0.6218 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.5723 0.7550
epoch 1800 LossPred 0.6078 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.5771 0.7550
epoch 1900 LossPred 0.6033 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.5746 0.7650
epoch 2000 LossPred 0.5988 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5786 0.7700
epoch 2100 LossPred 0.5932 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5833 0.7600
epoch 2200 LossPred 0.5864 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5856 0.7600
epoch 2300 LossPred 0.5809 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5876 0.7600
epoch 2400 LossPred 0.5758 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5891 0.7450
epoch 2500 LossPred 0.5708 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5901 0.7500
Optimization Finished!
********** replication  88  **********
epoch   0 LossPred 1.2340 LossAtt 1.0000 TrainAcc 0.4700 TestAcc 0.4182 0.4950
epoch 100 LossPred 1.0126 LossAtt 1.0000 TrainAcc 0.5000 TestAcc 0.4610 0.5400
epoch 200 LossPred 0.9667 LossAtt 1.0000 TrainAcc 0.5800 TestAcc 0.5308 0.5650
epoch 300 LossPred 0.9324 LossAtt 1.0000 TrainAcc 0.6700 TestAcc 0.5828 0.6500
epoch 400 LossPred 0.5121 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.8168 0.8400
epoch 500 LossPred 0.2968 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8216 0.8800
epoch 600 LossPred 0.2555 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8241 0.8850
epoch 700 LossPred 0.2390 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8246 0.8750
epoch 800 LossPred 0.2273 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8211 0.8700
epoch 900 LossPred 0.2186 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8178 0.8700
epoch 1000 LossPred 0.2117 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8168 0.8750
epoch 1100 LossPred 0.2059 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8176 0.8850
epoch 1200 LossPred 0.2006 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8166 0.8800
epoch 1300 LossPred 0.1966 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8131 0.8750
epoch 1400 LossPred 0.1929 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8118 0.8750
epoch 1500 LossPred 0.1896 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8108 0.8750
epoch 1600 LossPred 0.1863 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8086 0.8700
epoch 1700 LossPred 0.1829 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8068 0.8700
epoch 1800 LossPred 0.1793 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8011 0.8700
epoch 1900 LossPred 0.1760 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.7993 0.8700
epoch 2000 LossPred 0.1730 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8001 0.8800
epoch 2100 LossPred 0.1707 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8006 0.8900
epoch 2200 LossPred 0.1687 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8011 0.8800
epoch 2300 LossPred 0.1670 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8003 0.8800
epoch 2400 LossPred 0.1654 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8001 0.8750
epoch 2500 LossPred 0.1638 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.7983 0.8750
Optimization Finished!
********** replication  89  **********
epoch   0 LossPred 0.9767 LossAtt 1.0000 TrainAcc 0.5800 TestAcc 0.4905 0.5200
epoch 100 LossPred 0.7538 LossAtt 1.0000 TrainAcc 0.7900 TestAcc 0.6384 0.7550
epoch 200 LossPred 0.5631 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.6919 0.7950
epoch 300 LossPred 0.2426 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8576 0.8700
epoch 400 LossPred 0.1503 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8771 0.8900
epoch 500 LossPred 0.1208 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8909 0.8850
epoch 600 LossPred 0.1082 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8914 0.8900
epoch 700 LossPred 0.0967 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8876 0.8900
epoch 800 LossPred 0.0917 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8851 0.8900
epoch 900 LossPred 0.0888 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8849 0.8950
epoch 1000 LossPred 0.0868 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8844 0.8950
epoch 1100 LossPred 0.0852 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8854 0.8950
epoch 1200 LossPred 0.0840 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8854 0.8950
epoch 1300 LossPred 0.0830 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8844 0.8950
epoch 1400 LossPred 0.0822 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8841 0.8950
epoch 1500 LossPred 0.0814 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8831 0.8950
epoch 1600 LossPred 0.0807 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8819 0.8800
epoch 1700 LossPred 0.0801 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8816 0.8800
epoch 1800 LossPred 0.0795 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8801 0.8700
epoch 1900 LossPred 0.0790 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8754 0.8700
epoch 2000 LossPred 0.0785 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8734 0.8650
epoch 2100 LossPred 0.0781 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8721 0.8600
epoch 2200 LossPred 0.0777 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8709 0.8600
epoch 2300 LossPred 0.0774 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8694 0.8550
epoch 2400 LossPred 0.0770 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8671 0.8500
epoch 2500 LossPred 0.0766 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8634 0.8450
Optimization Finished!
********** replication  90  **********
epoch   0 LossPred 1.3479 LossAtt 1.0000 TrainAcc 0.4000 TestAcc 0.4489 0.4050
epoch 100 LossPred 0.9643 LossAtt 1.0000 TrainAcc 0.4900 TestAcc 0.4630 0.5250
epoch 200 LossPred 0.8470 LossAtt 1.0000 TrainAcc 0.7000 TestAcc 0.5538 0.6850
epoch 300 LossPred 0.7739 LossAtt 1.0000 TrainAcc 0.7200 TestAcc 0.5531 0.7100
epoch 400 LossPred 0.7271 LossAtt 1.0000 TrainAcc 0.7100 TestAcc 0.5543 0.7050
epoch 500 LossPred 0.6977 LossAtt 1.0000 TrainAcc 0.7500 TestAcc 0.5288 0.7250
epoch 600 LossPred 0.6655 LossAtt 1.0000 TrainAcc 0.7600 TestAcc 0.5328 0.7250
epoch 700 LossPred 0.6431 LossAtt 1.0000 TrainAcc 0.7700 TestAcc 0.5318 0.7450
epoch 800 LossPred 0.6301 LossAtt 1.0000 TrainAcc 0.7800 TestAcc 0.5298 0.7350
epoch 900 LossPred 0.6216 LossAtt 1.0000 TrainAcc 0.7900 TestAcc 0.5335 0.7350
epoch 1000 LossPred 0.6131 LossAtt 1.0000 TrainAcc 0.7900 TestAcc 0.5355 0.7500
epoch 1100 LossPred 0.6369 LossAtt 1.0000 TrainAcc 0.7700 TestAcc 0.5368 0.7400
epoch 1200 LossPred 0.6053 LossAtt 1.0000 TrainAcc 0.7700 TestAcc 0.5435 0.7250
epoch 1300 LossPred 0.6047 LossAtt 1.0000 TrainAcc 0.7900 TestAcc 0.5458 0.7650
epoch 1400 LossPred 0.5625 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.5465 0.7700
epoch 1500 LossPred 0.5502 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.5501 0.7700
epoch 1600 LossPred 0.5419 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.5501 0.7600
epoch 1700 LossPred 0.5359 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.5521 0.7650
epoch 1800 LossPred 0.5308 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.5521 0.7600
epoch 1900 LossPred 0.5263 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.5521 0.7550
epoch 2000 LossPred 0.5224 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.5518 0.7500
epoch 2100 LossPred 0.5187 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.5518 0.7550
epoch 2200 LossPred 0.5150 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.5528 0.7600
epoch 2300 LossPred 0.5112 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5526 0.7500
epoch 2400 LossPred 0.5075 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5536 0.7550
epoch 2500 LossPred 0.5038 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5536 0.7600
Optimization Finished!
********** replication  91  **********
epoch   0 LossPred 1.0547 LossAtt 1.0000 TrainAcc 0.5100 TestAcc 0.4985 0.4800
epoch 100 LossPred 0.9556 LossAtt 1.0000 TrainAcc 0.5300 TestAcc 0.5691 0.5400
epoch 200 LossPred 0.9387 LossAtt 1.0000 TrainAcc 0.5900 TestAcc 0.5693 0.5600
epoch 300 LossPred 0.8731 LossAtt 1.0000 TrainAcc 0.6600 TestAcc 0.5871 0.6650
epoch 400 LossPred 0.8028 LossAtt 1.0000 TrainAcc 0.7000 TestAcc 0.6001 0.6850
epoch 500 LossPred 0.7837 LossAtt 1.0000 TrainAcc 0.7100 TestAcc 0.5963 0.6950
epoch 600 LossPred 0.7705 LossAtt 1.0000 TrainAcc 0.7200 TestAcc 0.5913 0.7100
epoch 700 LossPred 0.7569 LossAtt 1.0000 TrainAcc 0.7100 TestAcc 0.5881 0.7150
epoch 800 LossPred 0.7452 LossAtt 1.0000 TrainAcc 0.7400 TestAcc 0.5841 0.7100
epoch 900 LossPred 0.7242 LossAtt 1.0000 TrainAcc 0.7400 TestAcc 0.5833 0.7250
epoch 1000 LossPred 0.6819 LossAtt 1.0000 TrainAcc 0.7700 TestAcc 0.5766 0.7050
epoch 1100 LossPred 0.6637 LossAtt 1.0000 TrainAcc 0.7600 TestAcc 0.5783 0.7000
epoch 1200 LossPred 0.6553 LossAtt 1.0000 TrainAcc 0.7700 TestAcc 0.5803 0.7050
epoch 1300 LossPred 0.6507 LossAtt 1.0000 TrainAcc 0.7700 TestAcc 0.5788 0.7100
epoch 1400 LossPred 0.6473 LossAtt 1.0000 TrainAcc 0.7700 TestAcc 0.5811 0.7200
epoch 1500 LossPred 0.6443 LossAtt 1.0000 TrainAcc 0.7800 TestAcc 0.5811 0.7200
epoch 1600 LossPred 0.6403 LossAtt 1.0000 TrainAcc 0.7900 TestAcc 0.5786 0.7250
epoch 1700 LossPred 0.6367 LossAtt 1.0000 TrainAcc 0.7900 TestAcc 0.5778 0.7300
epoch 1800 LossPred 0.5716 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.5818 0.7450
epoch 1900 LossPred 0.5348 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.5828 0.7550
epoch 2000 LossPred 0.5228 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.5791 0.7650
epoch 2100 LossPred 0.5159 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.5793 0.7650
epoch 2200 LossPred 0.5098 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5796 0.7650
epoch 2300 LossPred 0.5055 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5798 0.7600
epoch 2400 LossPred 0.5018 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5783 0.7550
epoch 2500 LossPred 0.4987 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5796 0.7450
Optimization Finished!
********** replication  92  **********
epoch   0 LossPred 1.2164 LossAtt 1.0000 TrainAcc 0.5000 TestAcc 0.4690 0.5100
epoch 100 LossPred 0.9493 LossAtt 1.0000 TrainAcc 0.5800 TestAcc 0.5143 0.5800
epoch 200 LossPred 0.6507 LossAtt 1.0000 TrainAcc 0.7600 TestAcc 0.6869 0.7250
epoch 300 LossPred 0.5584 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.7425 0.7600
epoch 400 LossPred 0.4960 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.7715 0.7850
epoch 500 LossPred 0.4622 LossAtt 1.0000 TrainAcc 0.8600 TestAcc 0.7893 0.8050
epoch 600 LossPred 0.4362 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.7970 0.8200
epoch 700 LossPred 0.3934 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.8083 0.8300
epoch 800 LossPred 0.3618 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.8106 0.8450
epoch 900 LossPred 0.3176 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.8096 0.8650
epoch 1000 LossPred 0.2645 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8131 0.8900
epoch 1100 LossPred 0.2374 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8181 0.8800
epoch 1200 LossPred 0.2138 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8273 0.8900
epoch 1300 LossPred 0.1851 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8376 0.8800
epoch 1400 LossPred 0.1466 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8498 0.8900
epoch 1500 LossPred 0.1302 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8566 0.8900
epoch 1600 LossPred 0.1167 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8619 0.8850
epoch 1700 LossPred 0.1066 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8659 0.8850
epoch 1800 LossPred 0.0991 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8666 0.8900
epoch 1900 LossPred 0.0926 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8699 0.8900
epoch 2000 LossPred 0.0869 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8706 0.9000
epoch 2100 LossPred 0.0817 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8719 0.9000
epoch 2200 LossPred 0.0768 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8721 0.9000
epoch 2300 LossPred 0.0721 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8736 0.9000
epoch 2400 LossPred 0.0674 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8734 0.9050
epoch 2500 LossPred 0.0625 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8749 0.9100
Optimization Finished!
********** replication  93  **********
epoch   0 LossPred 1.0454 LossAtt 1.0000 TrainAcc 0.5900 TestAcc 0.5378 0.5950
epoch 100 LossPred 0.9447 LossAtt 1.0000 TrainAcc 0.6100 TestAcc 0.5518 0.6150
epoch 200 LossPred 0.8630 LossAtt 1.0000 TrainAcc 0.6600 TestAcc 0.5606 0.6800
epoch 300 LossPred 0.7639 LossAtt 1.0000 TrainAcc 0.7200 TestAcc 0.5711 0.6800
epoch 400 LossPred 0.6771 LossAtt 1.0000 TrainAcc 0.7900 TestAcc 0.5808 0.7200
epoch 500 LossPred 0.5588 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.5838 0.7450
epoch 600 LossPred 0.5008 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.5936 0.7900
epoch 700 LossPred 0.4737 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.5903 0.7500
epoch 800 LossPred 0.4637 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.5926 0.7300
epoch 900 LossPred 0.4516 LossAtt 1.0000 TrainAcc 0.8700 TestAcc 0.5903 0.7350
epoch 1000 LossPred 0.4434 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.5843 0.7300
epoch 1100 LossPred 0.4369 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.5861 0.7250
epoch 1200 LossPred 0.4232 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.5868 0.7400
epoch 1300 LossPred 0.4448 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.5838 0.7400
epoch 1400 LossPred 0.4012 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.5913 0.7100
epoch 1500 LossPred 0.3931 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.5866 0.7100
epoch 1600 LossPred 0.3898 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.5871 0.7050
epoch 1700 LossPred 0.3875 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.5901 0.7050
epoch 1800 LossPred 0.3857 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.5891 0.7100
epoch 1900 LossPred 0.3839 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.5893 0.7100
epoch 2000 LossPred 0.3822 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.5896 0.7100
epoch 2100 LossPred 0.3804 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.5906 0.7050
epoch 2200 LossPred 0.5234 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.5866 0.7250
epoch 2300 LossPred 0.4663 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.5926 0.7300
epoch 2400 LossPred 0.4550 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.5896 0.7350
epoch 2500 LossPred 0.4430 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.5916 0.7350
Optimization Finished!
********** replication  94  **********
epoch   0 LossPred 1.0987 LossAtt 1.0000 TrainAcc 0.4200 TestAcc 0.4747 0.3750
epoch 100 LossPred 0.9328 LossAtt 1.0000 TrainAcc 0.6200 TestAcc 0.5881 0.6300
epoch 200 LossPred 0.5396 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.8584 0.8350
epoch 300 LossPred 0.4035 LossAtt 1.0000 TrainAcc 0.8800 TestAcc 0.8619 0.8400
epoch 400 LossPred 0.3392 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.8634 0.8550
epoch 500 LossPred 0.2580 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8791 0.8550
epoch 600 LossPred 0.2088 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8831 0.8750
epoch 700 LossPred 0.1847 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8796 0.8650
epoch 800 LossPred 0.1631 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8794 0.8650
epoch 900 LossPred 0.1467 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8799 0.8650
epoch 1000 LossPred 0.1373 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8781 0.8700
epoch 1100 LossPred 0.1318 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8794 0.8700
epoch 1200 LossPred 0.1277 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8791 0.8650
epoch 1300 LossPred 0.1359 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8871 0.8700
epoch 1400 LossPred 0.1057 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8914 0.8700
epoch 1500 LossPred 0.0733 LossAtt 1.0000 TrainAcc 0.9900 TestAcc 0.8971 0.8550
epoch 1600 LossPred 0.0610 LossAtt 1.0000 TrainAcc 1.0000 TestAcc 0.9007 0.8700
Optimization Finished!
********** replication  95  **********
epoch   0 LossPred 1.0724 LossAtt 1.0000 TrainAcc 0.4800 TestAcc 0.4615 0.4850
epoch 100 LossPred 0.9247 LossAtt 1.0000 TrainAcc 0.6200 TestAcc 0.5726 0.5950
epoch 200 LossPred 0.8498 LossAtt 1.0000 TrainAcc 0.6800 TestAcc 0.6199 0.6500
epoch 300 LossPred 0.4470 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.8446 0.8100
epoch 400 LossPred 0.3274 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8559 0.8250
epoch 500 LossPred 0.2911 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.8541 0.8250
epoch 600 LossPred 0.2734 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8531 0.8400
epoch 700 LossPred 0.2593 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8541 0.8400
epoch 800 LossPred 0.2417 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8521 0.8500
epoch 900 LossPred 0.1935 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8481 0.8650
epoch 1000 LossPred 0.1834 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8483 0.8650
epoch 1100 LossPred 0.1758 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8511 0.8750
epoch 1200 LossPred 0.1690 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8488 0.8700
epoch 1300 LossPred 0.1625 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8453 0.8650
epoch 1400 LossPred 0.1562 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8458 0.8600
epoch 1500 LossPred 0.1504 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8441 0.8600
epoch 1600 LossPred 0.1448 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8403 0.8650
epoch 1700 LossPred 0.1393 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8401 0.8700
epoch 1800 LossPred 0.1335 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8376 0.8650
epoch 1900 LossPred 0.1274 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8343 0.8600
epoch 2000 LossPred 0.2120 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8313 0.8700
epoch 2100 LossPred 0.1241 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8401 0.8650
epoch 2200 LossPred 0.1191 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8378 0.8650
epoch 2300 LossPred 0.1154 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8333 0.8700
epoch 2400 LossPred 0.1122 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8321 0.8750
epoch 2500 LossPred 0.1093 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8323 0.8800
Optimization Finished!
********** replication  96  **********
epoch   0 LossPred 1.0953 LossAtt 1.0000 TrainAcc 0.5100 TestAcc 0.4990 0.5250
epoch 100 LossPred 0.9351 LossAtt 1.0000 TrainAcc 0.5700 TestAcc 0.5568 0.5550
epoch 200 LossPred 0.7694 LossAtt 1.0000 TrainAcc 0.7100 TestAcc 0.6559 0.6650
epoch 300 LossPred 0.3855 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.8243 0.8700
epoch 400 LossPred 0.2975 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8268 0.8800
epoch 500 LossPred 0.2698 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8303 0.8650
epoch 600 LossPred 0.2542 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8298 0.8650
epoch 700 LossPred 0.2435 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8313 0.8600
epoch 800 LossPred 0.2351 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8328 0.8600
epoch 900 LossPred 0.2283 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8341 0.8550
epoch 1000 LossPred 0.2180 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8346 0.8500
epoch 1100 LossPred 0.2087 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8328 0.8550
epoch 1200 LossPred 0.2080 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8388 0.8750
epoch 1300 LossPred 0.1844 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8381 0.8700
epoch 1400 LossPred 0.1746 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8373 0.8750
epoch 1500 LossPred 0.1655 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8351 0.8600
epoch 1600 LossPred 0.1578 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8348 0.8700
epoch 1700 LossPred 0.1511 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8353 0.8850
epoch 1800 LossPred 0.1437 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8361 0.8950
epoch 1900 LossPred 0.1274 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8396 0.8850
epoch 2000 LossPred 0.1324 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8498 0.9150
epoch 2100 LossPred 0.1153 LossAtt 1.0000 TrainAcc 0.9700 TestAcc 0.8451 0.9000
epoch 2200 LossPred 0.0849 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8453 0.8950
epoch 2300 LossPred 0.0950 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8468 0.9150
epoch 2400 LossPred 0.0785 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8473 0.9100
epoch 2500 LossPred 0.0763 LossAtt 1.0000 TrainAcc 0.9800 TestAcc 0.8473 0.9150
Optimization Finished!
********** replication  97  **********
epoch   0 LossPred 0.9966 LossAtt 1.0000 TrainAcc 0.5300 TestAcc 0.5235 0.5150
epoch 100 LossPred 0.9477 LossAtt 1.0000 TrainAcc 0.6600 TestAcc 0.4967 0.6050
epoch 200 LossPred 0.8852 LossAtt 1.0000 TrainAcc 0.6800 TestAcc 0.5325 0.6450
epoch 300 LossPred 0.7915 LossAtt 1.0000 TrainAcc 0.7500 TestAcc 0.5408 0.7000
epoch 400 LossPred 0.7151 LossAtt 1.0000 TrainAcc 0.7600 TestAcc 0.5501 0.7250
epoch 500 LossPred 0.6590 LossAtt 1.0000 TrainAcc 0.7900 TestAcc 0.5613 0.7400
epoch 600 LossPred 0.6112 LossAtt 1.0000 TrainAcc 0.7800 TestAcc 0.6029 0.7050
epoch 700 LossPred 0.5948 LossAtt 1.0000 TrainAcc 0.7800 TestAcc 0.6146 0.6900
epoch 800 LossPred 0.5215 LossAtt 1.0000 TrainAcc 0.8100 TestAcc 0.6386 0.6900
epoch 900 LossPred 0.4659 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.6524 0.7050
epoch 1000 LossPred 0.4154 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.6764 0.7100
epoch 1100 LossPred 0.3211 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.6934 0.7450
epoch 1200 LossPred 0.3037 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.7017 0.7450
epoch 1300 LossPred 0.2972 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.6984 0.7450
epoch 1400 LossPred 0.2931 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.6982 0.7350
epoch 1500 LossPred 0.2902 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.7005 0.7350
epoch 1600 LossPred 0.2880 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.7030 0.7350
epoch 1700 LossPred 0.2862 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.7030 0.7400
epoch 1800 LossPred 0.2848 LossAtt 1.0000 TrainAcc 0.9100 TestAcc 0.7027 0.7450
epoch 1900 LossPred 0.3381 LossAtt 1.0000 TrainAcc 0.8900 TestAcc 0.7150 0.7450
epoch 2000 LossPred 0.2621 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.7160 0.7400
epoch 2100 LossPred 0.2554 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.7202 0.7350
epoch 2200 LossPred 0.2519 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.7212 0.7350
epoch 2300 LossPred 0.2490 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.7220 0.7300
epoch 2400 LossPred 0.2466 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.7217 0.7350
epoch 2500 LossPred 0.2445 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.7205 0.7400
Optimization Finished!
********** replication  98  **********
epoch   0 LossPred 1.2015 LossAtt 1.0000 TrainAcc 0.4700 TestAcc 0.4982 0.4550
epoch 100 LossPred 0.9782 LossAtt 1.0000 TrainAcc 0.5700 TestAcc 0.5833 0.5750
epoch 200 LossPred 0.9212 LossAtt 1.0000 TrainAcc 0.5700 TestAcc 0.5646 0.6050
epoch 300 LossPred 0.8682 LossAtt 1.0000 TrainAcc 0.6300 TestAcc 0.5706 0.6400
epoch 400 LossPred 0.8302 LossAtt 1.0000 TrainAcc 0.6600 TestAcc 0.5395 0.6300
epoch 500 LossPred 0.7730 LossAtt 1.0000 TrainAcc 0.7200 TestAcc 0.5325 0.6650
epoch 600 LossPred 0.7138 LossAtt 1.0000 TrainAcc 0.7500 TestAcc 0.5573 0.7350
epoch 700 LossPred 0.6385 LossAtt 1.0000 TrainAcc 0.8000 TestAcc 0.5470 0.7550
epoch 800 LossPred 0.5958 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.5400 0.7500
epoch 900 LossPred 0.6012 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5403 0.7600
epoch 1000 LossPred 0.5883 LossAtt 1.0000 TrainAcc 0.8200 TestAcc 0.5395 0.7500
epoch 1100 LossPred 0.5960 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5418 0.7550
epoch 1200 LossPred 0.5659 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5368 0.7450
epoch 1300 LossPred 0.5578 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5383 0.7500
epoch 1400 LossPred 0.5532 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5398 0.7450
epoch 1500 LossPred 0.5493 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5380 0.7400
epoch 1600 LossPred 0.5455 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5370 0.7350
epoch 1700 LossPred 0.5411 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5370 0.7350
epoch 1800 LossPred 0.5429 LossAtt 1.0000 TrainAcc 0.8400 TestAcc 0.5390 0.7400
epoch 1900 LossPred 0.5668 LossAtt 1.0000 TrainAcc 0.8300 TestAcc 0.5335 0.7500
epoch 2000 LossPred 0.5518 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.5323 0.7500
epoch 2100 LossPred 0.5481 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.5298 0.7500
epoch 2200 LossPred 0.5450 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.5305 0.7400
epoch 2300 LossPred 0.5424 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.5323 0.7350
epoch 2400 LossPred 0.5402 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.5318 0.7350
epoch 2500 LossPred 0.5380 LossAtt 1.0000 TrainAcc 0.8500 TestAcc 0.5310 0.7200
Optimization Finished!
********** replication  99  **********
epoch   0 LossPred 1.1015 LossAtt 1.0000 TrainAcc 0.4700 TestAcc 0.4997 0.4900
epoch 100 LossPred 0.9771 LossAtt 1.0000 TrainAcc 0.6000 TestAcc 0.5868 0.5600
epoch 200 LossPred 0.8732 LossAtt 1.0000 TrainAcc 0.7000 TestAcc 0.7152 0.6850
epoch 300 LossPred 0.3931 LossAtt 1.0000 TrainAcc 0.9000 TestAcc 0.8541 0.8450
epoch 400 LossPred 0.3026 LossAtt 1.0000 TrainAcc 0.9200 TestAcc 0.8609 0.8250
epoch 500 LossPred 0.2714 LossAtt 1.0000 TrainAcc 0.9300 TestAcc 0.8661 0.8500
epoch 600 LossPred 0.2372 LossAtt 1.0000 TrainAcc 0.9400 TestAcc 0.8691 0.8550
epoch 700 LossPred 0.2210 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8671 0.8700
epoch 800 LossPred 0.2093 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8634 0.8750
epoch 900 LossPred 0.1956 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8569 0.8800
epoch 1000 LossPred 0.1901 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8544 0.8800
epoch 1100 LossPred 0.1862 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8534 0.8850
epoch 1200 LossPred 0.1828 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8491 0.8850
epoch 1300 LossPred 0.1796 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8483 0.8900
epoch 1400 LossPred 0.1763 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8476 0.8750
epoch 1500 LossPred 0.1732 LossAtt 1.0000 TrainAcc 0.9500 TestAcc 0.8451 0.8700
epoch 1600 LossPred 0.1702 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8446 0.8650
epoch 1700 LossPred 0.1675 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8421 0.8650
epoch 1800 LossPred 0.1652 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8406 0.8600
epoch 1900 LossPred 0.1632 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8393 0.8600
epoch 2000 LossPred 0.1613 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8386 0.8600
epoch 2100 LossPred 0.1595 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8378 0.8600
epoch 2200 LossPred 0.1580 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8376 0.8550
epoch 2300 LossPred 0.1567 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8366 0.8550
epoch 2400 LossPred 0.1555 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8351 0.8550
epoch 2500 LossPred 0.1543 LossAtt 1.0000 TrainAcc 0.9600 TestAcc 0.8346 0.8600
Optimization Finished!
********************************************************************
Namespace(arch='tanh', batch_size=256, display_epoch=100, input_noise_level=0.15, latent_attractor_space=True, loss_switch_frequency=0, lrate_attractor=0.002, lrate_prediction=0.002, lrate_wt_penalty=0.0, n_attractor_hidden=10, n_attractor_steps=0, n_hidden=5, n_replications=100, noise_level=0.5, report_best_train_performance=True, seq_len=25, task='majority', train_attr_weights_on_prediction=False, training_epochs=2500)
********************************************************************
mean train accuracy 0.94530004
indiv runs  [0.99, 0.98, 0.99, 0.95, 0.97, 0.87, 0.9, 0.99, 0.98, 0.97, 0.94, 1.0, 0.84, 1.0, 1.0, 1.0, 0.92, 0.92, 0.82, 1.0, 0.93, 0.98, 0.95, 0.89, 1.0, 0.98, 0.87, 0.97, 0.96, 0.98, 0.86, 1.0, 0.83, 0.95, 0.97, 0.98, 0.89, 0.99, 0.87, 1.0, 0.99, 0.99, 0.99, 1.0, 0.84, 1.0, 0.99, 0.96, 1.0, 1.0, 0.82, 0.9, 1.0, 0.86, 0.8, 1.0, 1.0, 1.0, 1.0, 0.99, 0.85, 1.0, 1.0, 1.0, 0.95, 0.94, 0.99, 0.88, 0.84, 0.79, 0.98, 0.99, 0.99, 1.0, 1.0, 0.99, 0.9, 0.93, 0.96, 0.81, 1.0, 1.0, 1.0, 1.0, 0.87, 0.87, 0.93, 0.84, 0.95, 0.98, 0.84, 0.84, 0.99, 0.91, 1.0, 0.98, 0.98, 0.94, 0.85, 0.96]
mean epoch 1593.59259259
indiv epochs  [1501, 1401, 1601, 701, 2501, 2301, 2001, 1501, 1201, 1101, 1901, 701, 2401, 1201, 2501, 1301, 1601, 1601, 2301, 1301, 801, 2101, 1301, 2001, 2201, 401, 1601]
test1 accuracy mean  0.77446944  median  0.8243243
test2 accuracy mean  0.8439999  median  0.8825
test1 indiv runs  [0.8493493, 0.8423423, 0.9411912, 0.8173173, 0.8268268, 0.5503003, 0.6606607, 0.7907908, 0.8686186, 0.7877878, 0.8093093, 0.8671171, 0.5237738, 0.8598599, 0.8636136, 0.9567067, 0.5935936, 0.7274775, 0.5242743, 0.8596096, 0.8501001, 0.8713714, 0.8040541, 0.8135636, 0.8683684, 0.8378378, 0.5337838, 0.8223223, 0.8933934, 0.796046, 0.6834334, 0.8125626, 0.6028529, 0.7767768, 0.8571071, 0.8148148, 0.5578078, 0.9076577, 0.5688188, 0.8871371, 0.8871371, 0.8568569, 0.8648649, 0.8753754, 0.5477978, 0.8563564, 0.7572573, 0.8108108, 0.7955455, 0.8495996, 0.5568068, 0.6946947, 0.8728729, 0.5578078, 0.5588088, 0.9527027, 0.9359359, 0.8758759, 0.9306807, 0.8528529, 0.7875375, 0.8268268, 0.9046547, 0.8263263, 0.8053053, 0.8065566, 0.9111612, 0.5475475, 0.5442943, 0.5845846, 0.7832833, 0.8513514, 0.8618619, 0.8526026, 0.8288288, 0.8340841, 0.6426426, 0.774024, 0.8898899, 0.5750751, 0.8778779, 0.9376877, 0.8986486, 0.8651151, 0.535035, 0.5608108, 0.8040541, 0.5833333, 0.8085586, 0.8908909, 0.5525526, 0.5795796, 0.8658659, 0.5890891, 0.9006507, 0.8375876, 0.8453453, 0.7202202, 0.54004, 0.8445946]
test2 indiv runs  [0.93, 0.905, 0.885, 0.915, 0.905, 0.695, 0.795, 0.895, 0.93, 0.885, 0.85, 0.95, 0.75, 0.935, 0.91, 0.895, 0.74, 0.805, 0.725, 0.925, 0.845, 0.87, 0.85, 0.825, 0.945, 0.885, 0.725, 0.85, 0.89, 0.87, 0.79, 0.895, 0.71, 0.845, 0.9, 0.9, 0.755, 0.925, 0.75, 0.9, 0.915, 0.89, 0.86, 0.935, 0.685, 0.94, 0.82, 0.89, 0.93, 0.905, 0.675, 0.75, 0.91, 0.695, 0.67, 0.925, 0.92, 0.875, 0.92, 0.9, 0.795, 0.89, 0.93, 0.915, 0.855, 0.91, 0.88, 0.685, 0.68, 0.645, 0.895, 0.9, 0.885, 0.93, 0.91, 0.885, 0.78, 0.76, 0.915, 0.68, 0.925, 0.885, 0.86, 0.95, 0.715, 0.73, 0.865, 0.76, 0.87, 0.885, 0.75, 0.745, 0.885, 0.71, 0.87, 0.865, 0.895, 0.735, 0.75, 0.865]
