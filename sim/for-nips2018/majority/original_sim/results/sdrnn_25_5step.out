Namespace(arch='tanh', batch_size=256, display_epoch=100, input_noise_level=0.15, latent_attractor_space=True, loss_switch_frequency=0, lrate_attractor=0.002, lrate_prediction=0.002, lrate_wt_penalty=0.0, n_attractor_hidden=10, n_attractor_steps=5, n_hidden=5, n_replications=100, noise_level=0.5, report_best_train_performance=True, seq_len=25, task='majority', train_attr_weights_on_prediction=False, training_epochs=2500)
TRAINING ON 100 EXAMPLES, TESTING ON 3996
********** replication  0  **********
epoch   0 LossPred 1.0830 LossAtt 1.0314 TrainAcc 0.4800 TestAcc 0.5283 0.5450
epoch 100 LossPred 0.9173 LossAtt 0.4606 TrainAcc 0.5900 TestAcc 0.5821 0.5900
epoch 200 LossPred 0.8723 LossAtt 0.4185 TrainAcc 0.6400 TestAcc 0.5823 0.6450
epoch 300 LossPred 0.8521 LossAtt 0.4009 TrainAcc 0.6600 TestAcc 0.5953 0.6350
epoch 400 LossPred 0.8490 LossAtt 0.3469 TrainAcc 0.6500 TestAcc 0.5978 0.6500
epoch 500 LossPred 0.8496 LossAtt 0.2898 TrainAcc 0.6500 TestAcc 0.5978 0.6500
epoch 600 LossPred 0.8457 LossAtt 0.3109 TrainAcc 0.6700 TestAcc 0.5991 0.6550
epoch 700 LossPred 0.8404 LossAtt 0.3233 TrainAcc 0.6600 TestAcc 0.6234 0.6450
epoch 800 LossPred 0.8052 LossAtt 0.4291 TrainAcc 0.7000 TestAcc 0.7085 0.7000
epoch 900 LossPred 0.6592 LossAtt 0.3600 TrainAcc 0.7400 TestAcc 0.7633 0.7250
epoch 1000 LossPred 0.5401 LossAtt 0.3810 TrainAcc 0.7900 TestAcc 0.8456 0.7950
epoch 1100 LossPred 0.5267 LossAtt 0.3777 TrainAcc 0.8400 TestAcc 0.8463 0.8200
epoch 1200 LossPred 0.3957 LossAtt 0.3821 TrainAcc 0.8800 TestAcc 0.8621 0.8300
epoch 1300 LossPred 0.4501 LossAtt 0.3400 TrainAcc 0.8500 TestAcc 0.8153 0.7800
epoch 1400 LossPred 0.3814 LossAtt 0.3502 TrainAcc 0.8400 TestAcc 0.8619 0.8200
epoch 1500 LossPred 0.4967 LossAtt 0.3537 TrainAcc 0.8100 TestAcc 0.8158 0.7850
epoch 1600 LossPred 0.8596 LossAtt 0.3473 TrainAcc 0.7100 TestAcc 0.7300 0.7100
epoch 1700 LossPred 0.3281 LossAtt 0.3258 TrainAcc 0.9100 TestAcc 0.8831 0.8600
epoch 1800 LossPred 0.5497 LossAtt 0.3188 TrainAcc 0.7900 TestAcc 0.8386 0.8100
epoch 1900 LossPred 0.4617 LossAtt 0.3202 TrainAcc 0.8400 TestAcc 0.8551 0.8400
epoch 2000 LossPred 0.3846 LossAtt 0.3451 TrainAcc 0.8800 TestAcc 0.8599 0.8700
epoch 2100 LossPred 0.4022 LossAtt 0.3040 TrainAcc 0.8700 TestAcc 0.8566 0.8500
epoch 2200 LossPred 0.4137 LossAtt 0.3063 TrainAcc 0.8600 TestAcc 0.8596 0.8650
epoch 2300 LossPred 0.3211 LossAtt 0.3239 TrainAcc 0.9000 TestAcc 0.8939 0.8450
epoch 2400 LossPred 0.4006 LossAtt 0.3370 TrainAcc 0.8800 TestAcc 0.8606 0.8650
epoch 2500 LossPred 0.4802 LossAtt 0.3096 TrainAcc 0.8100 TestAcc 0.8116 0.7850
Optimization Finished!
********** replication  1  **********
epoch   0 LossPred 1.1337 LossAtt 0.9982 TrainAcc 0.5500 TestAcc 0.4710 0.5550
epoch 100 LossPred 0.9985 LossAtt 0.3025 TrainAcc 0.5900 TestAcc 0.5040 0.5550
epoch 200 LossPred 0.9541 LossAtt 0.3204 TrainAcc 0.5900 TestAcc 0.5040 0.5900
epoch 300 LossPred 0.8951 LossAtt 0.4382 TrainAcc 0.6500 TestAcc 0.6176 0.6600
epoch 400 LossPred 0.4366 LossAtt 0.4538 TrainAcc 0.8600 TestAcc 0.8116 0.8250
epoch 500 LossPred 0.4175 LossAtt 0.4468 TrainAcc 0.8400 TestAcc 0.8108 0.8200
epoch 600 LossPred 0.3857 LossAtt 0.4328 TrainAcc 0.8600 TestAcc 0.8153 0.8150
epoch 700 LossPred 0.3494 LossAtt 0.4417 TrainAcc 0.8800 TestAcc 0.8176 0.8250
epoch 800 LossPred 0.3248 LossAtt 0.4266 TrainAcc 0.9000 TestAcc 0.8133 0.8450
epoch 900 LossPred 0.3373 LossAtt 0.4374 TrainAcc 0.8900 TestAcc 0.8163 0.8300
epoch 1000 LossPred 0.3256 LossAtt 0.4225 TrainAcc 0.8800 TestAcc 0.8111 0.8400
epoch 1100 LossPred 0.3402 LossAtt 0.4287 TrainAcc 0.8800 TestAcc 0.8211 0.8200
epoch 1200 LossPred 0.3802 LossAtt 0.4139 TrainAcc 0.8700 TestAcc 0.7993 0.8300
epoch 1300 LossPred 0.3897 LossAtt 0.4328 TrainAcc 0.8800 TestAcc 0.7998 0.8250
epoch 1400 LossPred 0.4127 LossAtt 0.4235 TrainAcc 0.8700 TestAcc 0.7933 0.8300
epoch 1500 LossPred 0.4096 LossAtt 0.4260 TrainAcc 0.8600 TestAcc 0.7928 0.8250
epoch 1600 LossPred 0.3788 LossAtt 0.4289 TrainAcc 0.8700 TestAcc 0.8166 0.8150
epoch 1700 LossPred 0.4122 LossAtt 0.4071 TrainAcc 0.8600 TestAcc 0.7915 0.8200
epoch 1800 LossPred 0.9858 LossAtt 0.3676 TrainAcc 0.6900 TestAcc 0.7022 0.6850
epoch 1900 LossPred 0.4173 LossAtt 0.3847 TrainAcc 0.8800 TestAcc 0.7818 0.8250
epoch 2000 LossPred 0.3827 LossAtt 0.3898 TrainAcc 0.8600 TestAcc 0.8051 0.8350
epoch 2100 LossPred 0.3349 LossAtt 0.3890 TrainAcc 0.8800 TestAcc 0.8221 0.8350
epoch 2200 LossPred 0.4016 LossAtt 0.4026 TrainAcc 0.8600 TestAcc 0.8163 0.8400
epoch 2300 LossPred 0.3635 LossAtt 0.3804 TrainAcc 0.8800 TestAcc 0.8031 0.8400
epoch 2400 LossPred 0.3749 LossAtt 0.4093 TrainAcc 0.8800 TestAcc 0.8256 0.8250
epoch 2500 LossPred 0.3279 LossAtt 0.3707 TrainAcc 0.8900 TestAcc 0.8031 0.8350
Optimization Finished!
********** replication  2  **********
epoch   0 LossPred 1.1526 LossAtt 1.0279 TrainAcc 0.4200 TestAcc 0.4237 0.4150
epoch 100 LossPred 0.9672 LossAtt 0.2916 TrainAcc 0.6300 TestAcc 0.5783 0.6300
epoch 200 LossPred 0.9376 LossAtt 0.1897 TrainAcc 0.6300 TestAcc 0.5783 0.6300
epoch 300 LossPred 0.9312 LossAtt 0.2924 TrainAcc 0.6300 TestAcc 0.5783 0.6300
epoch 400 LossPred 0.9215 LossAtt 0.3912 TrainAcc 0.6300 TestAcc 0.5783 0.6250
epoch 500 LossPred 0.8876 LossAtt 0.4068 TrainAcc 0.6700 TestAcc 0.5673 0.6550
epoch 600 LossPred 0.8624 LossAtt 0.3475 TrainAcc 0.6600 TestAcc 0.5370 0.6600
epoch 700 LossPred 0.8017 LossAtt 0.3428 TrainAcc 0.6800 TestAcc 0.5373 0.6350
epoch 800 LossPred 0.7672 LossAtt 0.3575 TrainAcc 0.7200 TestAcc 0.5218 0.6650
epoch 900 LossPred 0.7580 LossAtt 0.3391 TrainAcc 0.7400 TestAcc 0.5158 0.6700
epoch 1000 LossPred 0.8136 LossAtt 0.3799 TrainAcc 0.7200 TestAcc 0.5075 0.6700
epoch 1100 LossPred 0.7449 LossAtt 0.3653 TrainAcc 0.7100 TestAcc 0.5165 0.6650
epoch 1200 LossPred 0.7489 LossAtt 0.3427 TrainAcc 0.7200 TestAcc 0.5065 0.6600
epoch 1300 LossPred 0.7572 LossAtt 0.3227 TrainAcc 0.7100 TestAcc 0.5060 0.6550
epoch 1400 LossPred 0.7507 LossAtt 0.3325 TrainAcc 0.7100 TestAcc 0.5033 0.6600
epoch 1500 LossPred 0.7447 LossAtt 0.3419 TrainAcc 0.7200 TestAcc 0.5065 0.6650
epoch 1600 LossPred 0.7443 LossAtt 0.3331 TrainAcc 0.7200 TestAcc 0.5168 0.6700
epoch 1700 LossPred 0.7310 LossAtt 0.3210 TrainAcc 0.7300 TestAcc 0.5165 0.6650
epoch 1800 LossPred 0.7857 LossAtt 0.3339 TrainAcc 0.6900 TestAcc 0.4970 0.6750
epoch 1900 LossPred 0.7377 LossAtt 0.3204 TrainAcc 0.7300 TestAcc 0.5160 0.6600
epoch 2000 LossPred 0.7501 LossAtt 0.3308 TrainAcc 0.7100 TestAcc 0.5225 0.6700
epoch 2100 LossPred 0.7487 LossAtt 0.3401 TrainAcc 0.7100 TestAcc 0.5305 0.6650
epoch 2200 LossPred 0.7635 LossAtt 0.3014 TrainAcc 0.6900 TestAcc 0.5318 0.6650
epoch 2300 LossPred 0.7392 LossAtt 0.3108 TrainAcc 0.7200 TestAcc 0.5305 0.6500
epoch 2400 LossPred 0.7434 LossAtt 0.3069 TrainAcc 0.7200 TestAcc 0.5223 0.6500
epoch 2500 LossPred 0.7934 LossAtt 0.3156 TrainAcc 0.6900 TestAcc 0.5138 0.6750
Optimization Finished!
********** replication  3  **********
epoch   0 LossPred 1.0964 LossAtt 1.0159 TrainAcc 0.4400 TestAcc 0.3979 0.4600
epoch 100 LossPred 0.9911 LossAtt 0.2681 TrainAcc 0.5400 TestAcc 0.5105 0.5400
epoch 200 LossPred 0.9831 LossAtt 0.2106 TrainAcc 0.5600 TestAcc 0.6021 0.5650
epoch 300 LossPred 0.9816 LossAtt 0.2429 TrainAcc 0.5600 TestAcc 0.6021 0.5600
epoch 400 LossPred 0.7437 LossAtt 0.5708 TrainAcc 0.7800 TestAcc 0.7530 0.7400
epoch 500 LossPred 0.4904 LossAtt 0.4483 TrainAcc 0.8500 TestAcc 0.8046 0.8300
epoch 600 LossPred 0.3546 LossAtt 0.3899 TrainAcc 0.8700 TestAcc 0.8283 0.8750
epoch 700 LossPred 0.3958 LossAtt 0.3880 TrainAcc 0.8700 TestAcc 0.8336 0.8750
epoch 800 LossPred 0.3234 LossAtt 0.3490 TrainAcc 0.9000 TestAcc 0.8256 0.8700
epoch 900 LossPred 0.4008 LossAtt 0.3855 TrainAcc 0.8700 TestAcc 0.8366 0.8750
epoch 1000 LossPred 0.4002 LossAtt 0.3639 TrainAcc 0.8800 TestAcc 0.8318 0.8700
epoch 1100 LossPred 0.3972 LossAtt 0.3251 TrainAcc 0.8900 TestAcc 0.8246 0.8400
epoch 1200 LossPred 0.3203 LossAtt 0.3512 TrainAcc 0.9000 TestAcc 0.8278 0.8900
epoch 1300 LossPred 0.3292 LossAtt 0.3437 TrainAcc 0.8900 TestAcc 0.8261 0.8800
epoch 1400 LossPred 0.4688 LossAtt 0.3669 TrainAcc 0.8300 TestAcc 0.8198 0.8450
epoch 1500 LossPred 0.3609 LossAtt 0.3360 TrainAcc 0.9000 TestAcc 0.8163 0.8800
epoch 1600 LossPred 0.4973 LossAtt 0.3305 TrainAcc 0.8100 TestAcc 0.8176 0.8600
epoch 1700 LossPred 0.4131 LossAtt 0.3438 TrainAcc 0.8500 TestAcc 0.8251 0.8600
epoch 1800 LossPred 0.3536 LossAtt 0.3265 TrainAcc 0.8800 TestAcc 0.8286 0.8700
epoch 1900 LossPred 0.3531 LossAtt 0.3314 TrainAcc 0.8900 TestAcc 0.8268 0.8900
epoch 2000 LossPred 0.3174 LossAtt 0.3316 TrainAcc 0.9100 TestAcc 0.8276 0.8850
epoch 2100 LossPred 0.3942 LossAtt 0.3427 TrainAcc 0.8800 TestAcc 0.8286 0.8750
epoch 2200 LossPred 0.4216 LossAtt 0.3388 TrainAcc 0.8600 TestAcc 0.8251 0.8550
epoch 2300 LossPred 0.4565 LossAtt 0.3400 TrainAcc 0.8600 TestAcc 0.8036 0.8450
epoch 2400 LossPred 0.3347 LossAtt 0.3141 TrainAcc 0.9000 TestAcc 0.8251 0.8800
epoch 2500 LossPred 0.3685 LossAtt 0.3095 TrainAcc 0.8800 TestAcc 0.8228 0.9000
Optimization Finished!
********** replication  4  **********
epoch   0 LossPred 1.3185 LossAtt 1.0052 TrainAcc 0.4400 TestAcc 0.4184 0.4700
epoch 100 LossPred 1.0438 LossAtt 0.4945 TrainAcc 0.3900 TestAcc 0.4179 0.3850
epoch 200 LossPred 0.9928 LossAtt 0.4983 TrainAcc 0.5700 TestAcc 0.5455 0.5800
epoch 300 LossPred 0.9166 LossAtt 0.5331 TrainAcc 0.6300 TestAcc 0.5270 0.6400
epoch 400 LossPred 0.8685 LossAtt 0.4887 TrainAcc 0.6200 TestAcc 0.5423 0.6650
epoch 500 LossPred 0.7974 LossAtt 0.5291 TrainAcc 0.7000 TestAcc 0.6321 0.6900
epoch 600 LossPred 0.7527 LossAtt 0.4954 TrainAcc 0.7000 TestAcc 0.6191 0.6750
epoch 700 LossPred 0.7245 LossAtt 0.4559 TrainAcc 0.7200 TestAcc 0.6404 0.7200
epoch 800 LossPred 0.7676 LossAtt 0.4063 TrainAcc 0.7200 TestAcc 0.6171 0.6850
epoch 900 LossPred 0.7600 LossAtt 0.4210 TrainAcc 0.6800 TestAcc 0.6391 0.6900
epoch 1000 LossPred 0.7718 LossAtt 0.4039 TrainAcc 0.6800 TestAcc 0.6294 0.6850
epoch 1100 LossPred 0.7041 LossAtt 0.4347 TrainAcc 0.7400 TestAcc 0.6992 0.7600
epoch 1200 LossPred 0.7261 LossAtt 0.3837 TrainAcc 0.7400 TestAcc 0.6959 0.7600
epoch 1300 LossPred 0.6693 LossAtt 0.4183 TrainAcc 0.7700 TestAcc 0.7095 0.7600
epoch 1400 LossPred 0.6039 LossAtt 0.3897 TrainAcc 0.8000 TestAcc 0.7220 0.7950
epoch 1500 LossPred 0.7124 LossAtt 0.3935 TrainAcc 0.7600 TestAcc 0.7080 0.7500
epoch 1600 LossPred 0.7845 LossAtt 0.3686 TrainAcc 0.7200 TestAcc 0.6441 0.7200
epoch 1700 LossPred 0.6752 LossAtt 0.3616 TrainAcc 0.7600 TestAcc 0.7005 0.7350
epoch 1800 LossPred 0.5515 LossAtt 0.3470 TrainAcc 0.8300 TestAcc 0.7513 0.7950
epoch 1900 LossPred 0.6381 LossAtt 0.3416 TrainAcc 0.7600 TestAcc 0.7167 0.7550
epoch 2000 LossPred 0.6020 LossAtt 0.3527 TrainAcc 0.7800 TestAcc 0.7337 0.7750
epoch 2100 LossPred 0.5774 LossAtt 0.3372 TrainAcc 0.7900 TestAcc 0.7332 0.7650
epoch 2200 LossPred 0.5545 LossAtt 0.3610 TrainAcc 0.7900 TestAcc 0.7410 0.7550
epoch 2300 LossPred 0.5548 LossAtt 0.3512 TrainAcc 0.8000 TestAcc 0.7362 0.7900
epoch 2400 LossPred 0.5699 LossAtt 0.3689 TrainAcc 0.7900 TestAcc 0.7427 0.7800
epoch 2500 LossPred 0.5556 LossAtt 0.3279 TrainAcc 0.8000 TestAcc 0.7362 0.7850
Optimization Finished!
********** replication  5  **********
epoch   0 LossPred 1.0208 LossAtt 1.0038 TrainAcc 0.5800 TestAcc 0.5355 0.5500
epoch 100 LossPred 0.9464 LossAtt 0.4434 TrainAcc 0.6100 TestAcc 0.5653 0.6150
epoch 200 LossPred 0.9400 LossAtt 0.3872 TrainAcc 0.6100 TestAcc 0.5653 0.6150
epoch 300 LossPred 0.9343 LossAtt 0.3719 TrainAcc 0.6100 TestAcc 0.5653 0.6100
epoch 400 LossPred 0.8811 LossAtt 0.4454 TrainAcc 0.6400 TestAcc 0.6099 0.6400
epoch 500 LossPred 0.3447 LossAtt 0.3946 TrainAcc 0.8900 TestAcc 0.7895 0.8700
epoch 600 LossPred 0.3128 LossAtt 0.3695 TrainAcc 0.9000 TestAcc 0.7938 0.8650
epoch 700 LossPred 0.2205 LossAtt 0.3585 TrainAcc 0.9400 TestAcc 0.7673 0.8750
epoch 800 LossPred 0.2195 LossAtt 0.3732 TrainAcc 0.9300 TestAcc 0.7810 0.8650
epoch 900 LossPred 0.8536 LossAtt 0.3402 TrainAcc 0.6700 TestAcc 0.6507 0.7000
epoch 1000 LossPred 0.7697 LossAtt 0.3347 TrainAcc 0.6900 TestAcc 0.6899 0.7100
epoch 1100 LossPred 0.4885 LossAtt 0.3614 TrainAcc 0.8600 TestAcc 0.7270 0.8400
epoch 1200 LossPred 0.2317 LossAtt 0.3819 TrainAcc 0.9400 TestAcc 0.7658 0.9100
epoch 1300 LossPred 0.5531 LossAtt 0.4188 TrainAcc 0.8000 TestAcc 0.7888 0.7950
epoch 1400 LossPred 0.3536 LossAtt 0.4149 TrainAcc 0.8900 TestAcc 0.8103 0.8400
epoch 1500 LossPred 0.2758 LossAtt 0.4036 TrainAcc 0.9100 TestAcc 0.8286 0.8650
epoch 1600 LossPred 0.2568 LossAtt 0.3880 TrainAcc 0.9100 TestAcc 0.8031 0.8800
epoch 1700 LossPred 0.2587 LossAtt 0.4003 TrainAcc 0.9100 TestAcc 0.8026 0.8700
epoch 1800 LossPred 0.2550 LossAtt 0.3908 TrainAcc 0.9100 TestAcc 0.7888 0.9000
epoch 1900 LossPred 0.1985 LossAtt 0.3935 TrainAcc 0.9400 TestAcc 0.7673 0.9050
epoch 2000 LossPred 0.2194 LossAtt 0.3849 TrainAcc 0.9300 TestAcc 0.7770 0.8700
epoch 2100 LossPred 0.1976 LossAtt 0.3832 TrainAcc 0.9400 TestAcc 0.7703 0.8850
epoch 2200 LossPred 0.2096 LossAtt 0.3805 TrainAcc 0.9500 TestAcc 0.7658 0.9050
epoch 2300 LossPred 0.1828 LossAtt 0.3785 TrainAcc 0.9500 TestAcc 0.7758 0.9050
epoch 2400 LossPred 0.2303 LossAtt 0.3789 TrainAcc 0.9300 TestAcc 0.7813 0.9050
epoch 2500 LossPred 0.2693 LossAtt 0.3804 TrainAcc 0.9300 TestAcc 0.7735 0.9100
Optimization Finished!
********** replication  6  **********
epoch   0 LossPred 1.0220 LossAtt 1.0119 TrainAcc 0.4900 TestAcc 0.4757 0.5100
epoch 100 LossPred 0.9396 LossAtt 0.4132 TrainAcc 0.6200 TestAcc 0.5250 0.6200
epoch 200 LossPred 0.9386 LossAtt 0.3956 TrainAcc 0.6200 TestAcc 0.5258 0.6200
epoch 300 LossPred 0.9345 LossAtt 0.3821 TrainAcc 0.6200 TestAcc 0.5253 0.6200
epoch 400 LossPred 0.9310 LossAtt 0.3556 TrainAcc 0.6200 TestAcc 0.5258 0.6200
epoch 500 LossPred 0.9224 LossAtt 0.3638 TrainAcc 0.6200 TestAcc 0.5253 0.6200
epoch 600 LossPred 0.9129 LossAtt 0.3930 TrainAcc 0.6200 TestAcc 0.5260 0.6200
epoch 700 LossPred 0.9104 LossAtt 0.3794 TrainAcc 0.6300 TestAcc 0.5208 0.6150
epoch 800 LossPred 0.9031 LossAtt 0.3538 TrainAcc 0.6300 TestAcc 0.5183 0.6250
epoch 900 LossPred 0.8961 LossAtt 0.3367 TrainAcc 0.6300 TestAcc 0.5213 0.6250
epoch 1000 LossPred 0.8946 LossAtt 0.2929 TrainAcc 0.6400 TestAcc 0.5218 0.6200
epoch 1100 LossPred 0.8993 LossAtt 0.2971 TrainAcc 0.6300 TestAcc 0.5238 0.6300
epoch 1200 LossPred 0.8930 LossAtt 0.3096 TrainAcc 0.6200 TestAcc 0.5253 0.6200
epoch 1300 LossPred 0.8864 LossAtt 0.3219 TrainAcc 0.6200 TestAcc 0.5320 0.6200
epoch 1400 LossPred 0.8844 LossAtt 0.3044 TrainAcc 0.6100 TestAcc 0.5365 0.6350
epoch 1500 LossPred 0.8867 LossAtt 0.2843 TrainAcc 0.6200 TestAcc 0.5345 0.6400
epoch 1600 LossPred 0.8909 LossAtt 0.2941 TrainAcc 0.6100 TestAcc 0.5455 0.6200
epoch 1700 LossPred 0.8938 LossAtt 0.2892 TrainAcc 0.6000 TestAcc 0.5370 0.6250
epoch 1800 LossPred 0.8932 LossAtt 0.3369 TrainAcc 0.6300 TestAcc 0.5410 0.6250
epoch 1900 LossPred 0.8646 LossAtt 0.3506 TrainAcc 0.6500 TestAcc 0.5323 0.6500
epoch 2000 LossPred 0.8323 LossAtt 0.3406 TrainAcc 0.6600 TestAcc 0.5230 0.6550
epoch 2100 LossPred 0.7950 LossAtt 0.3912 TrainAcc 0.6600 TestAcc 0.5423 0.6400
epoch 2200 LossPred 0.7719 LossAtt 0.3496 TrainAcc 0.6600 TestAcc 0.5458 0.6700
epoch 2300 LossPred 0.7345 LossAtt 0.3906 TrainAcc 0.7600 TestAcc 0.5828 0.7250
epoch 2400 LossPred 0.7505 LossAtt 0.3802 TrainAcc 0.7200 TestAcc 0.5818 0.6900
epoch 2500 LossPred 0.7573 LossAtt 0.3722 TrainAcc 0.7000 TestAcc 0.5586 0.6900
Optimization Finished!
********** replication  7  **********
epoch   0 LossPred 1.0362 LossAtt 1.0049 TrainAcc 0.5300 TestAcc 0.5638 0.5250
epoch 100 LossPred 0.9664 LossAtt 0.4509 TrainAcc 0.5800 TestAcc 0.4957 0.5800
epoch 200 LossPred 0.9653 LossAtt 0.4166 TrainAcc 0.5700 TestAcc 0.4997 0.5850
epoch 300 LossPred 0.9640 LossAtt 0.3835 TrainAcc 0.5700 TestAcc 0.4997 0.5900
epoch 400 LossPred 0.9494 LossAtt 0.3548 TrainAcc 0.6100 TestAcc 0.5175 0.5550
epoch 500 LossPred 0.9304 LossAtt 0.4306 TrainAcc 0.6100 TestAcc 0.5791 0.5600
epoch 600 LossPred 0.9182 LossAtt 0.4251 TrainAcc 0.6600 TestAcc 0.5833 0.6450
epoch 700 LossPred 0.7597 LossAtt 0.5527 TrainAcc 0.7600 TestAcc 0.7367 0.7350
epoch 800 LossPred 0.8826 LossAtt 0.5939 TrainAcc 0.6600 TestAcc 0.6181 0.6550
epoch 900 LossPred 0.8517 LossAtt 0.6193 TrainAcc 0.6600 TestAcc 0.6794 0.6700
epoch 1000 LossPred 0.7740 LossAtt 0.5600 TrainAcc 0.6900 TestAcc 0.7525 0.7100
epoch 1100 LossPred 0.9112 LossAtt 0.5353 TrainAcc 0.6500 TestAcc 0.6802 0.6450
epoch 1200 LossPred 0.8254 LossAtt 0.5518 TrainAcc 0.7100 TestAcc 0.7307 0.6900
epoch 1300 LossPred 0.7389 LossAtt 0.5636 TrainAcc 0.7200 TestAcc 0.7340 0.7250
epoch 1400 LossPred 0.6517 LossAtt 0.5800 TrainAcc 0.7500 TestAcc 0.7755 0.7100
epoch 1500 LossPred 0.6424 LossAtt 0.5652 TrainAcc 0.7500 TestAcc 0.8171 0.7250
epoch 1600 LossPred 0.6982 LossAtt 0.4899 TrainAcc 0.7300 TestAcc 0.7658 0.7450
epoch 1700 LossPred 0.6548 LossAtt 0.5591 TrainAcc 0.7400 TestAcc 0.8113 0.7200
epoch 1800 LossPred 0.6704 LossAtt 0.5340 TrainAcc 0.7500 TestAcc 0.8143 0.7350
epoch 1900 LossPred 0.6312 LossAtt 0.4601 TrainAcc 0.7700 TestAcc 0.7900 0.7400
epoch 2000 LossPred 0.6061 LossAtt 0.4881 TrainAcc 0.7700 TestAcc 0.8078 0.7700
epoch 2100 LossPred 0.6620 LossAtt 0.5378 TrainAcc 0.7900 TestAcc 0.8018 0.7600
epoch 2200 LossPred 0.5565 LossAtt 0.4942 TrainAcc 0.7800 TestAcc 0.8133 0.7900
epoch 2300 LossPred 0.5167 LossAtt 0.5019 TrainAcc 0.8200 TestAcc 0.8128 0.7650
epoch 2400 LossPred 0.7597 LossAtt 0.4517 TrainAcc 0.6800 TestAcc 0.7235 0.6750
epoch 2500 LossPred 0.6990 LossAtt 0.4494 TrainAcc 0.7200 TestAcc 0.7275 0.6600
Optimization Finished!
********** replication  8  **********
epoch   0 LossPred 1.0631 LossAtt 1.0214 TrainAcc 0.5700 TestAcc 0.4920 0.5700
epoch 100 LossPred 0.9439 LossAtt 0.4263 TrainAcc 0.5700 TestAcc 0.4920 0.5700
epoch 200 LossPred 0.8773 LossAtt 0.3618 TrainAcc 0.6600 TestAcc 0.6051 0.6350
epoch 300 LossPred 0.8131 LossAtt 0.4120 TrainAcc 0.6900 TestAcc 0.6019 0.6950
epoch 400 LossPred 0.4558 LossAtt 0.4770 TrainAcc 0.8700 TestAcc 0.8173 0.8400
epoch 500 LossPred 0.3407 LossAtt 0.4569 TrainAcc 0.9100 TestAcc 0.8113 0.8800
epoch 600 LossPred 0.3222 LossAtt 0.4369 TrainAcc 0.9000 TestAcc 0.8053 0.9100
epoch 700 LossPred 0.3328 LossAtt 0.4109 TrainAcc 0.8800 TestAcc 0.8158 0.8950
epoch 800 LossPred 0.3322 LossAtt 0.4023 TrainAcc 0.8900 TestAcc 0.8333 0.9050
epoch 900 LossPred 0.5715 LossAtt 0.3917 TrainAcc 0.7900 TestAcc 0.7415 0.8050
epoch 1000 LossPred 0.3542 LossAtt 0.3889 TrainAcc 0.8800 TestAcc 0.8213 0.8600
epoch 1100 LossPred 0.4170 LossAtt 0.3682 TrainAcc 0.8300 TestAcc 0.7900 0.8400
epoch 1200 LossPred 0.4550 LossAtt 0.3820 TrainAcc 0.8600 TestAcc 0.7930 0.8450
epoch 1300 LossPred 0.3962 LossAtt 0.3586 TrainAcc 0.8600 TestAcc 0.7970 0.8450
epoch 1400 LossPred 0.3378 LossAtt 0.3588 TrainAcc 0.8900 TestAcc 0.8238 0.8750
epoch 1500 LossPred 0.2753 LossAtt 0.3545 TrainAcc 0.9100 TestAcc 0.8476 0.8800
epoch 1600 LossPred 0.3124 LossAtt 0.3510 TrainAcc 0.9000 TestAcc 0.8286 0.9250
epoch 1700 LossPred 0.5242 LossAtt 0.3592 TrainAcc 0.8200 TestAcc 0.7585 0.8450
epoch 1800 LossPred 0.3171 LossAtt 0.3817 TrainAcc 0.8800 TestAcc 0.8443 0.8700
epoch 1900 LossPred 0.3459 LossAtt 0.3677 TrainAcc 0.8600 TestAcc 0.8396 0.8600
epoch 2000 LossPred 0.3168 LossAtt 0.3524 TrainAcc 0.8800 TestAcc 0.8418 0.8750
epoch 2100 LossPred 0.2986 LossAtt 0.3445 TrainAcc 0.8900 TestAcc 0.8388 0.8750
epoch 2200 LossPred 0.3579 LossAtt 0.3545 TrainAcc 0.8700 TestAcc 0.8016 0.8750
epoch 2300 LossPred 0.3907 LossAtt 0.3923 TrainAcc 0.8700 TestAcc 0.8343 0.8600
epoch 2400 LossPred 0.3232 LossAtt 0.3706 TrainAcc 0.8900 TestAcc 0.8181 0.8700
epoch 2500 LossPred 0.3088 LossAtt 0.3821 TrainAcc 0.8900 TestAcc 0.8328 0.8750
Optimization Finished!
********** replication  9  **********
epoch   0 LossPred 0.9693 LossAtt 1.0037 TrainAcc 0.5800 TestAcc 0.5473 0.5650
epoch 100 LossPred 0.9397 LossAtt 0.4570 TrainAcc 0.5800 TestAcc 0.5583 0.5650
epoch 200 LossPred 0.9357 LossAtt 0.4079 TrainAcc 0.5800 TestAcc 0.5583 0.5700
epoch 300 LossPred 0.9324 LossAtt 0.3664 TrainAcc 0.5800 TestAcc 0.5583 0.5650
epoch 400 LossPred 0.9262 LossAtt 0.2999 TrainAcc 0.6300 TestAcc 0.5806 0.6150
epoch 500 LossPred 0.8895 LossAtt 0.3724 TrainAcc 0.6500 TestAcc 0.5548 0.6300
epoch 600 LossPred 0.8431 LossAtt 0.3504 TrainAcc 0.6800 TestAcc 0.5661 0.6700
epoch 700 LossPred 0.8468 LossAtt 0.3544 TrainAcc 0.6700 TestAcc 0.5703 0.6650
epoch 800 LossPred 0.8657 LossAtt 0.3070 TrainAcc 0.6700 TestAcc 0.5703 0.6350
epoch 900 LossPred 0.8625 LossAtt 0.2933 TrainAcc 0.6800 TestAcc 0.5656 0.6550
epoch 1000 LossPred 0.9149 LossAtt 0.3163 TrainAcc 0.5400 TestAcc 0.5293 0.5950
epoch 1100 LossPred 0.8837 LossAtt 0.4101 TrainAcc 0.6800 TestAcc 0.5768 0.6450
epoch 1200 LossPred 0.8697 LossAtt 0.3757 TrainAcc 0.6900 TestAcc 0.5813 0.6850
epoch 1300 LossPred 0.8622 LossAtt 0.3420 TrainAcc 0.6900 TestAcc 0.5916 0.6700
epoch 1400 LossPred 0.8690 LossAtt 0.3396 TrainAcc 0.6900 TestAcc 0.5773 0.6650
epoch 1500 LossPred 0.8431 LossAtt 0.3047 TrainAcc 0.6600 TestAcc 0.5688 0.6650
epoch 1600 LossPred 0.8325 LossAtt 0.2929 TrainAcc 0.6700 TestAcc 0.5701 0.6600
epoch 1700 LossPred 0.8266 LossAtt 0.2910 TrainAcc 0.6700 TestAcc 0.5778 0.6550
epoch 1800 LossPred 0.8244 LossAtt 0.2994 TrainAcc 0.6800 TestAcc 0.5806 0.6500
epoch 1900 LossPred 0.8286 LossAtt 0.3154 TrainAcc 0.6600 TestAcc 0.5876 0.6450
epoch 2000 LossPred 0.8193 LossAtt 0.2852 TrainAcc 0.6800 TestAcc 0.5978 0.6750
epoch 2100 LossPred 0.8187 LossAtt 0.2877 TrainAcc 0.6800 TestAcc 0.5941 0.6800
epoch 2200 LossPred 0.8155 LossAtt 0.2601 TrainAcc 0.6800 TestAcc 0.5956 0.6800
epoch 2300 LossPred 0.8123 LossAtt 0.2906 TrainAcc 0.6700 TestAcc 0.5881 0.6950
epoch 2400 LossPred 0.8035 LossAtt 0.3054 TrainAcc 0.6900 TestAcc 0.5881 0.7000
epoch 2500 LossPred 0.7952 LossAtt 0.3493 TrainAcc 0.7000 TestAcc 0.5931 0.6900
Optimization Finished!
********** replication  10  **********
epoch   0 LossPred 1.1283 LossAtt 1.0386 TrainAcc 0.5500 TestAcc 0.5818 0.5500
epoch 100 LossPred 0.9091 LossAtt 0.5010 TrainAcc 0.6300 TestAcc 0.6141 0.6700
epoch 200 LossPred 0.6537 LossAtt 0.5501 TrainAcc 0.8100 TestAcc 0.7590 0.8150
epoch 300 LossPred 0.9931 LossAtt 0.4492 TrainAcc 0.6500 TestAcc 0.5180 0.6500
epoch 400 LossPred 0.5227 LossAtt 0.5146 TrainAcc 0.8700 TestAcc 0.8011 0.8300
epoch 500 LossPred 0.5946 LossAtt 0.5259 TrainAcc 0.7900 TestAcc 0.8218 0.7700
epoch 600 LossPred 0.4249 LossAtt 0.4915 TrainAcc 0.8600 TestAcc 0.8358 0.8400
epoch 700 LossPred 0.4160 LossAtt 0.4667 TrainAcc 0.8700 TestAcc 0.8031 0.8300
epoch 800 LossPred 0.4143 LossAtt 0.5069 TrainAcc 0.8700 TestAcc 0.8231 0.8500
epoch 900 LossPred 0.4805 LossAtt 0.4787 TrainAcc 0.8500 TestAcc 0.7873 0.8450
epoch 1000 LossPred 0.3919 LossAtt 0.4718 TrainAcc 0.8800 TestAcc 0.8038 0.8500
epoch 1100 LossPred 0.3932 LossAtt 0.4677 TrainAcc 0.8800 TestAcc 0.7988 0.8450
epoch 1200 LossPred 0.3835 LossAtt 0.4590 TrainAcc 0.8800 TestAcc 0.7975 0.8350
epoch 1300 LossPred 0.4947 LossAtt 0.4427 TrainAcc 0.8400 TestAcc 0.7565 0.8150
epoch 1400 LossPred 0.3931 LossAtt 0.4632 TrainAcc 0.8800 TestAcc 0.7938 0.8450
epoch 1500 LossPred 0.3964 LossAtt 0.4620 TrainAcc 0.8800 TestAcc 0.7848 0.8350
epoch 1600 LossPred 0.4248 LossAtt 0.4632 TrainAcc 0.8700 TestAcc 0.7853 0.8150
epoch 1700 LossPred 0.4625 LossAtt 0.4650 TrainAcc 0.8600 TestAcc 0.7605 0.8550
epoch 1800 LossPred 0.3667 LossAtt 0.4549 TrainAcc 0.8800 TestAcc 0.7803 0.8350
epoch 1900 LossPred 0.3905 LossAtt 0.4646 TrainAcc 0.8800 TestAcc 0.7948 0.8450
epoch 2000 LossPred 0.3782 LossAtt 0.4383 TrainAcc 0.8800 TestAcc 0.7890 0.8500
epoch 2100 LossPred 0.3964 LossAtt 0.4547 TrainAcc 0.8700 TestAcc 0.7993 0.8400
epoch 2200 LossPred 0.3858 LossAtt 0.4414 TrainAcc 0.8800 TestAcc 0.7905 0.8250
epoch 2300 LossPred 0.3657 LossAtt 0.4509 TrainAcc 0.8900 TestAcc 0.7993 0.8500
epoch 2400 LossPred 0.3516 LossAtt 0.4375 TrainAcc 0.8900 TestAcc 0.8033 0.8450
epoch 2500 LossPred 0.3602 LossAtt 0.4410 TrainAcc 0.8800 TestAcc 0.8013 0.8300
Optimization Finished!
********** replication  11  **********
epoch   0 LossPred 1.2361 LossAtt 1.0045 TrainAcc 0.4800 TestAcc 0.5048 0.4800
epoch 100 LossPred 0.9907 LossAtt 0.5254 TrainAcc 0.5400 TestAcc 0.5015 0.5300
epoch 200 LossPred 0.9542 LossAtt 0.4444 TrainAcc 0.6000 TestAcc 0.5786 0.5950
epoch 300 LossPred 0.8273 LossAtt 0.5364 TrainAcc 0.6800 TestAcc 0.6857 0.6800
epoch 400 LossPred 0.3593 LossAtt 0.5231 TrainAcc 0.9000 TestAcc 0.8496 0.8650
epoch 500 LossPred 0.3636 LossAtt 0.5084 TrainAcc 0.8900 TestAcc 0.8629 0.8800
epoch 600 LossPred 0.3250 LossAtt 0.5130 TrainAcc 0.9100 TestAcc 0.8761 0.9100
epoch 700 LossPred 0.2633 LossAtt 0.4907 TrainAcc 0.9200 TestAcc 0.8589 0.9000
epoch 800 LossPred 0.2913 LossAtt 0.4761 TrainAcc 0.9100 TestAcc 0.8674 0.9000
epoch 900 LossPred 0.3228 LossAtt 0.4630 TrainAcc 0.8900 TestAcc 0.8671 0.8950
epoch 1000 LossPred 0.3120 LossAtt 0.4555 TrainAcc 0.9000 TestAcc 0.8491 0.8850
epoch 1100 LossPred 0.3525 LossAtt 0.4406 TrainAcc 0.8900 TestAcc 0.8406 0.8600
epoch 1200 LossPred 0.3861 LossAtt 0.4215 TrainAcc 0.8700 TestAcc 0.8321 0.8500
epoch 1300 LossPred 0.3253 LossAtt 0.4403 TrainAcc 0.9000 TestAcc 0.8368 0.8900
epoch 1400 LossPred 0.3739 LossAtt 0.4441 TrainAcc 0.8700 TestAcc 0.8331 0.8550
epoch 1500 LossPred 0.3026 LossAtt 0.4367 TrainAcc 0.9000 TestAcc 0.8411 0.8850
epoch 1600 LossPred 0.3016 LossAtt 0.4335 TrainAcc 0.9000 TestAcc 0.8483 0.8850
epoch 1700 LossPred 0.2772 LossAtt 0.4394 TrainAcc 0.9000 TestAcc 0.8616 0.9050
epoch 1800 LossPred 0.2514 LossAtt 0.4386 TrainAcc 0.9300 TestAcc 0.8761 0.8950
epoch 1900 LossPred 0.2598 LossAtt 0.4279 TrainAcc 0.9300 TestAcc 0.8313 0.9100
epoch 2000 LossPred 0.2486 LossAtt 0.4418 TrainAcc 0.9100 TestAcc 0.8606 0.8950
epoch 2100 LossPred 0.4065 LossAtt 0.4472 TrainAcc 0.8700 TestAcc 0.8216 0.8500
epoch 2200 LossPred 0.8886 LossAtt 0.4273 TrainAcc 0.7200 TestAcc 0.7137 0.7200
epoch 2300 LossPred 0.2839 LossAtt 0.4246 TrainAcc 0.9100 TestAcc 0.8569 0.9050
epoch 2400 LossPred 0.5174 LossAtt 0.4105 TrainAcc 0.8200 TestAcc 0.8166 0.8400
epoch 2500 LossPred 0.2632 LossAtt 0.4059 TrainAcc 0.9100 TestAcc 0.8694 0.8950
Optimization Finished!
********** replication  12  **********
epoch   0 LossPred 1.0268 LossAtt 1.0087 TrainAcc 0.6400 TestAcc 0.5325 0.6500
epoch 100 LossPred 0.8589 LossAtt 0.5292 TrainAcc 0.6600 TestAcc 0.5511 0.6750
epoch 200 LossPred 0.8216 LossAtt 0.5747 TrainAcc 0.7000 TestAcc 0.5450 0.6850
epoch 300 LossPred 0.7601 LossAtt 0.5850 TrainAcc 0.7300 TestAcc 0.5415 0.7100
epoch 400 LossPred 0.7559 LossAtt 0.5455 TrainAcc 0.7200 TestAcc 0.5420 0.7000
epoch 500 LossPred 0.7431 LossAtt 0.5300 TrainAcc 0.7500 TestAcc 0.5470 0.7150
epoch 600 LossPred 0.7404 LossAtt 0.4892 TrainAcc 0.7400 TestAcc 0.5463 0.7200
epoch 700 LossPred 0.7505 LossAtt 0.5149 TrainAcc 0.7200 TestAcc 0.5323 0.6900
epoch 800 LossPred 0.7316 LossAtt 0.5079 TrainAcc 0.7500 TestAcc 0.5360 0.6950
epoch 900 LossPred 0.7051 LossAtt 0.4705 TrainAcc 0.7400 TestAcc 0.5458 0.7000
epoch 1000 LossPred 0.6871 LossAtt 0.4775 TrainAcc 0.7800 TestAcc 0.5468 0.7000
epoch 1100 LossPred 0.6814 LossAtt 0.4683 TrainAcc 0.7700 TestAcc 0.5475 0.7200
epoch 1200 LossPred 0.6697 LossAtt 0.4445 TrainAcc 0.7800 TestAcc 0.5403 0.7100
epoch 1300 LossPred 0.6737 LossAtt 0.4464 TrainAcc 0.7800 TestAcc 0.5330 0.6950
epoch 1400 LossPred 0.6701 LossAtt 0.4606 TrainAcc 0.7500 TestAcc 0.5303 0.7000
epoch 1500 LossPred 0.6716 LossAtt 0.4716 TrainAcc 0.7600 TestAcc 0.5318 0.7100
epoch 1600 LossPred 0.6736 LossAtt 0.4218 TrainAcc 0.7400 TestAcc 0.5290 0.6750
epoch 1700 LossPred 0.6765 LossAtt 0.4223 TrainAcc 0.7600 TestAcc 0.5310 0.7050
epoch 1800 LossPred 0.6855 LossAtt 0.3920 TrainAcc 0.7200 TestAcc 0.5280 0.6850
epoch 1900 LossPred 0.6895 LossAtt 0.3805 TrainAcc 0.7700 TestAcc 0.5433 0.6850
epoch 2000 LossPred 0.7512 LossAtt 0.3712 TrainAcc 0.7100 TestAcc 0.5501 0.7150
epoch 2100 LossPred 0.7379 LossAtt 0.3594 TrainAcc 0.7200 TestAcc 0.5465 0.7050
epoch 2200 LossPred 0.7298 LossAtt 0.3738 TrainAcc 0.7300 TestAcc 0.5458 0.7200
epoch 2300 LossPred 0.7272 LossAtt 0.3706 TrainAcc 0.7400 TestAcc 0.5528 0.7250
epoch 2400 LossPred 0.7326 LossAtt 0.3564 TrainAcc 0.7300 TestAcc 0.5488 0.7150
epoch 2500 LossPred 0.7386 LossAtt 0.3441 TrainAcc 0.7300 TestAcc 0.5498 0.7000
Optimization Finished!
********** replication  13  **********
epoch   0 LossPred 1.0989 LossAtt 1.0292 TrainAcc 0.5000 TestAcc 0.5400 0.5000
epoch 100 LossPred 0.9571 LossAtt 0.4324 TrainAcc 0.6200 TestAcc 0.5521 0.6000
epoch 200 LossPred 0.9233 LossAtt 0.4228 TrainAcc 0.6200 TestAcc 0.5318 0.6150
epoch 300 LossPred 0.8979 LossAtt 0.4159 TrainAcc 0.6200 TestAcc 0.5410 0.6150
epoch 400 LossPred 0.8830 LossAtt 0.4891 TrainAcc 0.6500 TestAcc 0.5498 0.6750
epoch 500 LossPred 0.7691 LossAtt 0.5589 TrainAcc 0.7400 TestAcc 0.6254 0.7400
epoch 600 LossPred 0.5324 LossAtt 0.5319 TrainAcc 0.8100 TestAcc 0.8218 0.8050
epoch 700 LossPred 0.4375 LossAtt 0.5132 TrainAcc 0.8600 TestAcc 0.8291 0.8600
epoch 800 LossPred 0.5498 LossAtt 0.5243 TrainAcc 0.8300 TestAcc 0.7915 0.8200
epoch 900 LossPred 0.4243 LossAtt 0.4895 TrainAcc 0.8400 TestAcc 0.8203 0.8700
epoch 1000 LossPred 0.3980 LossAtt 0.4879 TrainAcc 0.8700 TestAcc 0.8138 0.8800
epoch 1100 LossPred 0.3863 LossAtt 0.4911 TrainAcc 0.8800 TestAcc 0.8168 0.8850
epoch 1200 LossPred 0.3973 LossAtt 0.4726 TrainAcc 0.8800 TestAcc 0.7983 0.8800
epoch 1300 LossPred 0.4009 LossAtt 0.4762 TrainAcc 0.8800 TestAcc 0.7993 0.8750
epoch 1400 LossPred 0.3808 LossAtt 0.4832 TrainAcc 0.8800 TestAcc 0.8078 0.8850
epoch 1500 LossPred 0.3853 LossAtt 0.4793 TrainAcc 0.8900 TestAcc 0.8068 0.8850
epoch 1600 LossPred 0.3913 LossAtt 0.4807 TrainAcc 0.8900 TestAcc 0.8183 0.9000
epoch 1700 LossPred 0.3946 LossAtt 0.4650 TrainAcc 0.8700 TestAcc 0.8231 0.8800
epoch 1800 LossPred 0.3994 LossAtt 0.4606 TrainAcc 0.8600 TestAcc 0.8211 0.8700
epoch 1900 LossPred 0.3947 LossAtt 0.4498 TrainAcc 0.8700 TestAcc 0.8131 0.8700
epoch 2000 LossPred 0.4232 LossAtt 0.4511 TrainAcc 0.8600 TestAcc 0.8038 0.8600
epoch 2100 LossPred 0.4104 LossAtt 0.4519 TrainAcc 0.8600 TestAcc 0.8171 0.8700
epoch 2200 LossPred 0.3957 LossAtt 0.4418 TrainAcc 0.8700 TestAcc 0.8028 0.8700
epoch 2300 LossPred 0.4413 LossAtt 0.4466 TrainAcc 0.8500 TestAcc 0.8098 0.8550
epoch 2400 LossPred 0.3858 LossAtt 0.4479 TrainAcc 0.8900 TestAcc 0.8041 0.8850
epoch 2500 LossPred 0.3948 LossAtt 0.4130 TrainAcc 0.8800 TestAcc 0.8031 0.8700
Optimization Finished!
********** replication  14  **********
epoch   0 LossPred 1.0654 LossAtt 1.0254 TrainAcc 0.5500 TestAcc 0.5163 0.5500
epoch 100 LossPred 0.9490 LossAtt 0.4244 TrainAcc 0.6000 TestAcc 0.5846 0.6000
epoch 200 LossPred 0.9431 LossAtt 0.3266 TrainAcc 0.6000 TestAcc 0.5846 0.6000
epoch 300 LossPred 0.9372 LossAtt 0.3216 TrainAcc 0.6000 TestAcc 0.5846 0.6000
epoch 400 LossPred 0.9268 LossAtt 0.3678 TrainAcc 0.6000 TestAcc 0.5846 0.6000
epoch 500 LossPred 0.8724 LossAtt 0.3968 TrainAcc 0.6500 TestAcc 0.6569 0.6450
epoch 600 LossPred 0.6074 LossAtt 0.5034 TrainAcc 0.8000 TestAcc 0.7005 0.8050
epoch 700 LossPred 0.3305 LossAtt 0.5236 TrainAcc 0.9000 TestAcc 0.8436 0.9000
epoch 800 LossPred 0.3092 LossAtt 0.4777 TrainAcc 0.9100 TestAcc 0.8576 0.9100
epoch 900 LossPred 0.2673 LossAtt 0.4569 TrainAcc 0.9300 TestAcc 0.8659 0.9100
epoch 1000 LossPred 0.2884 LossAtt 0.4100 TrainAcc 0.9100 TestAcc 0.8418 0.8950
epoch 1100 LossPred 0.2784 LossAtt 0.3902 TrainAcc 0.9200 TestAcc 0.8711 0.8850
epoch 1200 LossPred 0.2967 LossAtt 0.3641 TrainAcc 0.9000 TestAcc 0.8316 0.8800
epoch 1300 LossPred 0.2674 LossAtt 0.3657 TrainAcc 0.9200 TestAcc 0.8516 0.9100
epoch 1400 LossPred 0.3306 LossAtt 0.3326 TrainAcc 0.9100 TestAcc 0.8226 0.8800
epoch 1500 LossPred 0.2691 LossAtt 0.3163 TrainAcc 0.9100 TestAcc 0.8544 0.9050
epoch 1600 LossPred 0.2346 LossAtt 0.3152 TrainAcc 0.9300 TestAcc 0.8681 0.9250
epoch 1700 LossPred 0.2398 LossAtt 0.3144 TrainAcc 0.9400 TestAcc 0.8686 0.9250
epoch 1800 LossPred 0.2363 LossAtt 0.3110 TrainAcc 0.9300 TestAcc 0.8704 0.9250
epoch 1900 LossPred 0.2357 LossAtt 0.3013 TrainAcc 0.9300 TestAcc 0.8704 0.9150
epoch 2000 LossPred 0.2501 LossAtt 0.3076 TrainAcc 0.9200 TestAcc 0.8624 0.9300
epoch 2100 LossPred 0.2956 LossAtt 0.3147 TrainAcc 0.8800 TestAcc 0.8311 0.8950
epoch 2200 LossPred 0.2556 LossAtt 0.3035 TrainAcc 0.9200 TestAcc 0.8559 0.9250
epoch 2300 LossPred 0.3496 LossAtt 0.2928 TrainAcc 0.8800 TestAcc 0.8393 0.8850
epoch 2400 LossPred 0.3594 LossAtt 0.3123 TrainAcc 0.8700 TestAcc 0.8006 0.8750
epoch 2500 LossPred 0.2411 LossAtt 0.3102 TrainAcc 0.9200 TestAcc 0.8654 0.9300
Optimization Finished!
********** replication  15  **********
epoch   0 LossPred 1.0068 LossAtt 1.0486 TrainAcc 0.5400 TestAcc 0.5428 0.5350
epoch 100 LossPred 0.9128 LossAtt 0.4096 TrainAcc 0.6700 TestAcc 0.5766 0.6500
epoch 200 LossPred 0.8847 LossAtt 0.2862 TrainAcc 0.6700 TestAcc 0.5766 0.6700
epoch 300 LossPred 0.8807 LossAtt 0.2060 TrainAcc 0.6700 TestAcc 0.5766 0.6700
epoch 400 LossPred 0.8816 LossAtt 0.1557 TrainAcc 0.6700 TestAcc 0.5766 0.6700
epoch 500 LossPred 0.9505 LossAtt 0.1236 TrainAcc 0.6700 TestAcc 0.5766 0.6550
epoch 600 LossPred 0.9264 LossAtt 0.2901 TrainAcc 0.6200 TestAcc 0.6024 0.6350
epoch 700 LossPred 0.7440 LossAtt 0.5368 TrainAcc 0.7000 TestAcc 0.6341 0.6800
epoch 800 LossPred 0.5960 LossAtt 0.3470 TrainAcc 0.7900 TestAcc 0.7828 0.7950
epoch 900 LossPred 0.5667 LossAtt 0.3819 TrainAcc 0.7900 TestAcc 0.7755 0.7650
epoch 1000 LossPred 0.5147 LossAtt 0.3591 TrainAcc 0.8300 TestAcc 0.8101 0.7900
epoch 1100 LossPred 0.4818 LossAtt 0.3586 TrainAcc 0.8400 TestAcc 0.8088 0.7850
epoch 1200 LossPred 0.5227 LossAtt 0.3610 TrainAcc 0.8300 TestAcc 0.8218 0.8250
epoch 1300 LossPred 0.5184 LossAtt 0.3664 TrainAcc 0.8200 TestAcc 0.7865 0.7550
epoch 1400 LossPred 0.5013 LossAtt 0.3664 TrainAcc 0.8500 TestAcc 0.8238 0.8100
epoch 1500 LossPred 0.5035 LossAtt 0.3771 TrainAcc 0.8200 TestAcc 0.8126 0.8350
epoch 1600 LossPred 0.5288 LossAtt 0.3850 TrainAcc 0.8200 TestAcc 0.8108 0.8050
epoch 1700 LossPred 0.5796 LossAtt 0.3931 TrainAcc 0.7900 TestAcc 0.7760 0.8100
epoch 1800 LossPred 0.5075 LossAtt 0.4278 TrainAcc 0.8300 TestAcc 0.7748 0.8100
epoch 1900 LossPred 0.5224 LossAtt 0.3951 TrainAcc 0.8200 TestAcc 0.7925 0.8000
epoch 2000 LossPred 0.5127 LossAtt 0.4157 TrainAcc 0.8200 TestAcc 0.7993 0.8100
epoch 2100 LossPred 0.5175 LossAtt 0.3991 TrainAcc 0.8000 TestAcc 0.7833 0.7900
epoch 2200 LossPred 0.4887 LossAtt 0.4050 TrainAcc 0.8400 TestAcc 0.8116 0.8200
epoch 2300 LossPred 0.5133 LossAtt 0.3593 TrainAcc 0.8300 TestAcc 0.8311 0.8500
epoch 2400 LossPred 0.6464 LossAtt 0.3796 TrainAcc 0.7900 TestAcc 0.7310 0.7650
epoch 2500 LossPred 0.4225 LossAtt 0.3692 TrainAcc 0.8800 TestAcc 0.8569 0.8700
Optimization Finished!
********** replication  16  **********
epoch   0 LossPred 1.0647 LossAtt 1.0066 TrainAcc 0.4300 TestAcc 0.5220 0.4350
epoch 100 LossPred 0.9670 LossAtt 0.3895 TrainAcc 0.5700 TestAcc 0.4960 0.5750
epoch 200 LossPred 0.9676 LossAtt 0.2618 TrainAcc 0.5700 TestAcc 0.4870 0.5450
epoch 300 LossPred 0.9671 LossAtt 0.2243 TrainAcc 0.5700 TestAcc 0.4870 0.5600
epoch 400 LossPred 0.9663 LossAtt 0.2301 TrainAcc 0.5700 TestAcc 0.4870 0.5700
epoch 500 LossPred 0.9640 LossAtt 0.2614 TrainAcc 0.5700 TestAcc 0.4870 0.5700
epoch 600 LossPred 0.9531 LossAtt 0.3582 TrainAcc 0.5900 TestAcc 0.5155 0.5800
epoch 700 LossPred 0.9229 LossAtt 0.4148 TrainAcc 0.6500 TestAcc 0.5380 0.6500
epoch 800 LossPred 0.9013 LossAtt 0.3806 TrainAcc 0.6500 TestAcc 0.5435 0.6450
epoch 900 LossPred 0.8816 LossAtt 0.3683 TrainAcc 0.6600 TestAcc 0.5448 0.6400
epoch 1000 LossPred 0.8916 LossAtt 0.3500 TrainAcc 0.6300 TestAcc 0.5758 0.6050
epoch 1100 LossPred 0.9393 LossAtt 0.3120 TrainAcc 0.5800 TestAcc 0.5198 0.5900
epoch 1200 LossPred 0.9248 LossAtt 0.2787 TrainAcc 0.6400 TestAcc 0.5198 0.5900
epoch 1300 LossPred 0.9231 LossAtt 0.2546 TrainAcc 0.6400 TestAcc 0.5263 0.6200
epoch 1400 LossPred 0.9210 LossAtt 0.2424 TrainAcc 0.6400 TestAcc 0.5263 0.6350
epoch 1500 LossPred 0.9190 LossAtt 0.2714 TrainAcc 0.6500 TestAcc 0.5283 0.6300
epoch 1600 LossPred 0.9186 LossAtt 0.2764 TrainAcc 0.6400 TestAcc 0.5325 0.6300
epoch 1700 LossPred 0.9179 LossAtt 0.3065 TrainAcc 0.6400 TestAcc 0.5621 0.6250
epoch 1800 LossPred 0.9117 LossAtt 0.3092 TrainAcc 0.6500 TestAcc 0.5528 0.6250
epoch 1900 LossPred 0.8964 LossAtt 0.3323 TrainAcc 0.6500 TestAcc 0.5448 0.6400
epoch 2000 LossPred 0.8808 LossAtt 0.3824 TrainAcc 0.6400 TestAcc 0.5458 0.6350
epoch 2100 LossPred 0.8116 LossAtt 0.4360 TrainAcc 0.7100 TestAcc 0.5460 0.6700
epoch 2200 LossPred 0.7863 LossAtt 0.4427 TrainAcc 0.7100 TestAcc 0.5458 0.7000
epoch 2300 LossPred 0.7530 LossAtt 0.4272 TrainAcc 0.7400 TestAcc 0.5435 0.6950
epoch 2400 LossPred 0.7671 LossAtt 0.4453 TrainAcc 0.7500 TestAcc 0.5531 0.7100
epoch 2500 LossPred 0.7503 LossAtt 0.4406 TrainAcc 0.7700 TestAcc 0.5435 0.7050
Optimization Finished!
********** replication  17  **********
epoch   0 LossPred 1.2050 LossAtt 1.0157 TrainAcc 0.5600 TestAcc 0.5503 0.5450
epoch 100 LossPred 0.9169 LossAtt 0.4511 TrainAcc 0.6200 TestAcc 0.5731 0.6200
epoch 200 LossPred 0.8412 LossAtt 0.4926 TrainAcc 0.6400 TestAcc 0.5863 0.6550
epoch 300 LossPred 0.4319 LossAtt 0.4699 TrainAcc 0.8900 TestAcc 0.8601 0.8550
epoch 400 LossPred 0.3498 LossAtt 0.4396 TrainAcc 0.8900 TestAcc 0.8691 0.8450
epoch 500 LossPred 0.4237 LossAtt 0.4655 TrainAcc 0.8600 TestAcc 0.8408 0.8300
epoch 600 LossPred 0.5585 LossAtt 0.5045 TrainAcc 0.7900 TestAcc 0.7893 0.7950
epoch 700 LossPred 0.5874 LossAtt 0.4767 TrainAcc 0.7800 TestAcc 0.7540 0.7800
epoch 800 LossPred 0.6994 LossAtt 0.4628 TrainAcc 0.7500 TestAcc 0.7042 0.7450
epoch 900 LossPred 0.4485 LossAtt 0.4550 TrainAcc 0.8700 TestAcc 0.8341 0.8600
epoch 1000 LossPred 0.4020 LossAtt 0.4685 TrainAcc 0.8700 TestAcc 0.8536 0.8550
epoch 1100 LossPred 0.3960 LossAtt 0.4534 TrainAcc 0.8500 TestAcc 0.8686 0.8600
epoch 1200 LossPred 0.3643 LossAtt 0.4492 TrainAcc 0.8900 TestAcc 0.8669 0.8500
epoch 1300 LossPred 0.3439 LossAtt 0.4659 TrainAcc 0.8800 TestAcc 0.8674 0.8550
epoch 1400 LossPred 0.4186 LossAtt 0.4192 TrainAcc 0.8500 TestAcc 0.8631 0.8600
epoch 1500 LossPred 0.5013 LossAtt 0.4680 TrainAcc 0.8300 TestAcc 0.8519 0.8050
epoch 1600 LossPred 0.4234 LossAtt 0.4260 TrainAcc 0.8300 TestAcc 0.8368 0.8200
epoch 1700 LossPred 0.3847 LossAtt 0.4525 TrainAcc 0.8900 TestAcc 0.8739 0.8700
epoch 1800 LossPred 0.6046 LossAtt 0.4360 TrainAcc 0.8200 TestAcc 0.7748 0.7650
epoch 1900 LossPred 0.4063 LossAtt 0.3991 TrainAcc 0.8400 TestAcc 0.8411 0.8250
epoch 2000 LossPred 0.3203 LossAtt 0.4000 TrainAcc 0.9000 TestAcc 0.8351 0.8850
epoch 2100 LossPred 0.3171 LossAtt 0.3895 TrainAcc 0.9200 TestAcc 0.8456 0.8800
epoch 2200 LossPred 0.3926 LossAtt 0.3928 TrainAcc 0.8500 TestAcc 0.8078 0.8650
epoch 2300 LossPred 0.4120 LossAtt 0.3766 TrainAcc 0.8800 TestAcc 0.8018 0.8750
epoch 2400 LossPred 0.3733 LossAtt 0.3858 TrainAcc 0.8600 TestAcc 0.8188 0.8650
epoch 2500 LossPred 0.3318 LossAtt 0.3725 TrainAcc 0.8900 TestAcc 0.8196 0.8950
Optimization Finished!
********** replication  18  **********
epoch   0 LossPred 1.0798 LossAtt 1.0165 TrainAcc 0.5700 TestAcc 0.5460 0.5900
epoch 100 LossPred 0.9748 LossAtt 0.4077 TrainAcc 0.6000 TestAcc 0.5938 0.6000
epoch 200 LossPred 0.9631 LossAtt 0.3147 TrainAcc 0.6000 TestAcc 0.5938 0.6000
epoch 300 LossPred 0.9625 LossAtt 0.2762 TrainAcc 0.6000 TestAcc 0.5938 0.6000
epoch 400 LossPred 0.9613 LossAtt 0.2176 TrainAcc 0.6000 TestAcc 0.5938 0.6000
epoch 500 LossPred 0.9610 LossAtt 0.2114 TrainAcc 0.6000 TestAcc 0.5938 0.6000
epoch 600 LossPred 0.9623 LossAtt 0.1013 TrainAcc 0.6000 TestAcc 0.5938 0.6000
epoch 700 LossPred 0.9759 LossAtt 0.0534 TrainAcc 0.6000 TestAcc 0.5938 0.6000
epoch 800 LossPred 0.9885 LossAtt 0.0692 TrainAcc 0.5200 TestAcc 0.4917 0.5200
epoch 900 LossPred 0.9908 LossAtt 0.0741 TrainAcc 0.5200 TestAcc 0.4917 0.5200
epoch 1000 LossPred 0.9927 LossAtt 0.0395 TrainAcc 0.5200 TestAcc 0.4917 0.5200
epoch 1100 LossPred 0.9931 LossAtt 0.0491 TrainAcc 0.5200 TestAcc 0.4917 0.5200
epoch 1200 LossPred 0.9939 LossAtt 0.0218 TrainAcc 0.5200 TestAcc 0.4917 0.5200
epoch 1300 LossPred 0.9930 LossAtt 0.0132 TrainAcc 0.5200 TestAcc 0.4917 0.5200
epoch 1400 LossPred 0.9927 LossAtt 0.0121 TrainAcc 0.5200 TestAcc 0.4917 0.5200
epoch 1500 LossPred 0.9914 LossAtt 0.0135 TrainAcc 0.5200 TestAcc 0.4917 0.5200
epoch 1600 LossPred 0.9911 LossAtt 0.0096 TrainAcc 0.5200 TestAcc 0.4917 0.5200
epoch 1700 LossPred 0.9906 LossAtt 0.0133 TrainAcc 0.5200 TestAcc 0.4917 0.5200
epoch 1800 LossPred 0.9928 LossAtt 0.0070 TrainAcc 0.5200 TestAcc 0.4917 0.5200
epoch 1900 LossPred 0.9941 LossAtt 0.0060 TrainAcc 0.5200 TestAcc 0.4917 0.5200
epoch 2000 LossPred 0.9948 LossAtt 0.0045 TrainAcc 0.5200 TestAcc 0.4917 0.5200
epoch 2100 LossPred 0.9954 LossAtt 0.0045 TrainAcc 0.5200 TestAcc 0.4917 0.5200
epoch 2200 LossPred 0.9958 LossAtt 0.0032 TrainAcc 0.5200 TestAcc 0.4917 0.5200
epoch 2300 LossPred 0.9962 LossAtt 0.0022 TrainAcc 0.5200 TestAcc 0.4917 0.5200
epoch 2400 LossPred 0.9964 LossAtt 0.0025 TrainAcc 0.5200 TestAcc 0.4917 0.5200
epoch 2500 LossPred 0.9967 LossAtt 0.0018 TrainAcc 0.5200 TestAcc 0.4917 0.5200
Optimization Finished!
********** replication  19  **********
epoch   0 LossPred 1.0453 LossAtt 0.9981 TrainAcc 0.4800 TestAcc 0.5298 0.4700
epoch 100 LossPred 0.9476 LossAtt 0.4508 TrainAcc 0.6000 TestAcc 0.6166 0.6050
epoch 200 LossPred 0.9451 LossAtt 0.3872 TrainAcc 0.6000 TestAcc 0.5916 0.5800
epoch 300 LossPred 0.9452 LossAtt 0.2686 TrainAcc 0.5800 TestAcc 0.5646 0.5850
epoch 400 LossPred 0.9445 LossAtt 0.2087 TrainAcc 0.5900 TestAcc 0.5621 0.5800
epoch 500 LossPred 0.9416 LossAtt 0.2034 TrainAcc 0.6000 TestAcc 0.5663 0.6050
epoch 600 LossPred 0.9325 LossAtt 0.2165 TrainAcc 0.6000 TestAcc 0.5606 0.5900
epoch 700 LossPred 0.8809 LossAtt 0.4020 TrainAcc 0.6600 TestAcc 0.6669 0.6400
epoch 800 LossPred 0.6890 LossAtt 0.4335 TrainAcc 0.7800 TestAcc 0.6309 0.7950
epoch 900 LossPred 0.6072 LossAtt 0.3922 TrainAcc 0.7800 TestAcc 0.8243 0.7600
epoch 1000 LossPred 0.4332 LossAtt 0.3304 TrainAcc 0.8700 TestAcc 0.7928 0.8600
epoch 1100 LossPred 0.5233 LossAtt 0.3178 TrainAcc 0.8500 TestAcc 0.7185 0.8400
epoch 1200 LossPred 0.7621 LossAtt 0.3027 TrainAcc 0.7200 TestAcc 0.7883 0.7250
epoch 1300 LossPred 0.4062 LossAtt 0.3185 TrainAcc 0.8700 TestAcc 0.7763 0.8650
epoch 1400 LossPred 0.5585 LossAtt 0.2839 TrainAcc 0.8300 TestAcc 0.7072 0.8450
epoch 1500 LossPred 0.5854 LossAtt 0.2882 TrainAcc 0.8200 TestAcc 0.6887 0.8400
epoch 1600 LossPred 0.4150 LossAtt 0.2877 TrainAcc 0.8600 TestAcc 0.8061 0.8650
epoch 1700 LossPred 0.4233 LossAtt 0.2741 TrainAcc 0.8700 TestAcc 0.7633 0.8600
epoch 1800 LossPred 0.4077 LossAtt 0.2742 TrainAcc 0.8600 TestAcc 0.8081 0.8650
epoch 1900 LossPred 0.3413 LossAtt 0.2761 TrainAcc 0.8900 TestAcc 0.8106 0.8700
epoch 2000 LossPred 0.3490 LossAtt 0.2772 TrainAcc 0.8700 TestAcc 0.8118 0.8750
epoch 2100 LossPred 0.3838 LossAtt 0.2744 TrainAcc 0.8800 TestAcc 0.8283 0.8650
epoch 2200 LossPred 0.3024 LossAtt 0.2804 TrainAcc 0.9100 TestAcc 0.8161 0.8700
epoch 2300 LossPred 0.3560 LossAtt 0.2653 TrainAcc 0.9000 TestAcc 0.7945 0.8650
epoch 2400 LossPred 0.3154 LossAtt 0.2608 TrainAcc 0.9100 TestAcc 0.8196 0.8700
epoch 2500 LossPred 0.7677 LossAtt 0.2659 TrainAcc 0.7600 TestAcc 0.5918 0.7400
Optimization Finished!
********** replication  20  **********
epoch   0 LossPred 1.1638 LossAtt 1.0101 TrainAcc 0.5100 TestAcc 0.5363 0.5100
epoch 100 LossPred 0.9604 LossAtt 0.4809 TrainAcc 0.5400 TestAcc 0.4850 0.5500
epoch 200 LossPred 0.9494 LossAtt 0.4287 TrainAcc 0.5500 TestAcc 0.5223 0.5500
epoch 300 LossPred 0.9369 LossAtt 0.3997 TrainAcc 0.5900 TestAcc 0.5803 0.5750
epoch 400 LossPred 0.7709 LossAtt 0.4381 TrainAcc 0.7500 TestAcc 0.7185 0.7250
epoch 500 LossPred 0.8730 LossAtt 0.3587 TrainAcc 0.5800 TestAcc 0.5365 0.5900
epoch 600 LossPred 0.8977 LossAtt 0.3671 TrainAcc 0.6900 TestAcc 0.6436 0.7000
epoch 700 LossPred 0.7963 LossAtt 0.3137 TrainAcc 0.7300 TestAcc 0.6697 0.6850
epoch 800 LossPred 0.5412 LossAtt 0.2942 TrainAcc 0.8500 TestAcc 0.7808 0.8250
epoch 900 LossPred 0.4992 LossAtt 0.3023 TrainAcc 0.8700 TestAcc 0.7960 0.8550
epoch 1000 LossPred 0.5960 LossAtt 0.2838 TrainAcc 0.8200 TestAcc 0.7945 0.8000
epoch 1100 LossPred 0.4969 LossAtt 0.2429 TrainAcc 0.8700 TestAcc 0.7933 0.8250
epoch 1200 LossPred 0.5812 LossAtt 0.2609 TrainAcc 0.8200 TestAcc 0.7913 0.8100
epoch 1300 LossPred 0.5358 LossAtt 0.2271 TrainAcc 0.8200 TestAcc 0.7605 0.8350
epoch 1400 LossPred 0.4664 LossAtt 0.2537 TrainAcc 0.8700 TestAcc 0.7880 0.8400
epoch 1500 LossPred 0.6234 LossAtt 0.2048 TrainAcc 0.7800 TestAcc 0.7295 0.7650
epoch 1600 LossPred 0.4662 LossAtt 0.2266 TrainAcc 0.8600 TestAcc 0.7935 0.8450
epoch 1700 LossPred 0.5626 LossAtt 0.2339 TrainAcc 0.8400 TestAcc 0.7933 0.8150
epoch 1800 LossPred 0.4722 LossAtt 0.2302 TrainAcc 0.8600 TestAcc 0.7805 0.8450
epoch 1900 LossPred 0.4376 LossAtt 0.2391 TrainAcc 0.8800 TestAcc 0.7878 0.8450
epoch 2000 LossPred 0.4790 LossAtt 0.2428 TrainAcc 0.8500 TestAcc 0.7980 0.8400
epoch 2100 LossPred 0.4671 LossAtt 0.2205 TrainAcc 0.8400 TestAcc 0.7930 0.8200
epoch 2200 LossPred 0.4577 LossAtt 0.2267 TrainAcc 0.8700 TestAcc 0.7900 0.8500
epoch 2300 LossPred 0.4876 LossAtt 0.2320 TrainAcc 0.8500 TestAcc 0.7918 0.8100
epoch 2400 LossPred 0.6151 LossAtt 0.2468 TrainAcc 0.8100 TestAcc 0.7860 0.8150
epoch 2500 LossPred 0.4842 LossAtt 0.2291 TrainAcc 0.8500 TestAcc 0.7820 0.8250
Optimization Finished!
********** replication  21  **********
epoch   0 LossPred 1.0059 LossAtt 0.9932 TrainAcc 0.5000 TestAcc 0.5065 0.5250
epoch 100 LossPred 0.9416 LossAtt 0.4248 TrainAcc 0.5900 TestAcc 0.5678 0.5900
epoch 200 LossPred 0.8814 LossAtt 0.4308 TrainAcc 0.6200 TestAcc 0.5480 0.6150
epoch 300 LossPred 0.8721 LossAtt 0.4148 TrainAcc 0.6200 TestAcc 0.5493 0.6350
epoch 400 LossPred 0.8623 LossAtt 0.4139 TrainAcc 0.6300 TestAcc 0.5420 0.6050
epoch 500 LossPred 0.8274 LossAtt 0.4618 TrainAcc 0.6600 TestAcc 0.5781 0.6450
epoch 600 LossPred 0.9106 LossAtt 0.4933 TrainAcc 0.6400 TestAcc 0.5290 0.6400
epoch 700 LossPred 0.7947 LossAtt 0.4611 TrainAcc 0.7300 TestAcc 0.5731 0.6950
epoch 800 LossPred 0.6833 LossAtt 0.4774 TrainAcc 0.7700 TestAcc 0.7485 0.7750
epoch 900 LossPred 0.4714 LossAtt 0.4842 TrainAcc 0.8300 TestAcc 0.7803 0.8500
epoch 1000 LossPred 1.2337 LossAtt 0.4967 TrainAcc 0.5800 TestAcc 0.6179 0.5900
epoch 1100 LossPred 0.9099 LossAtt 0.4910 TrainAcc 0.6600 TestAcc 0.6121 0.6500
epoch 1200 LossPred 0.6822 LossAtt 0.4804 TrainAcc 0.7700 TestAcc 0.7047 0.7300
epoch 1300 LossPred 0.5688 LossAtt 0.4989 TrainAcc 0.8000 TestAcc 0.7720 0.8050
epoch 1400 LossPred 0.5705 LossAtt 0.5143 TrainAcc 0.8200 TestAcc 0.7558 0.8300
epoch 1500 LossPred 0.5541 LossAtt 0.5036 TrainAcc 0.8200 TestAcc 0.7793 0.8150
epoch 1600 LossPred 0.4795 LossAtt 0.4935 TrainAcc 0.8700 TestAcc 0.7950 0.8650
epoch 1700 LossPred 0.7525 LossAtt 0.4983 TrainAcc 0.7200 TestAcc 0.7125 0.7400
epoch 1800 LossPred 0.4603 LossAtt 0.5046 TrainAcc 0.8800 TestAcc 0.7905 0.8450
epoch 1900 LossPred 0.5500 LossAtt 0.4922 TrainAcc 0.8200 TestAcc 0.7855 0.8100
epoch 2000 LossPred 0.5921 LossAtt 0.5152 TrainAcc 0.8000 TestAcc 0.7818 0.8100
epoch 2100 LossPred 0.4553 LossAtt 0.4866 TrainAcc 0.8800 TestAcc 0.8013 0.8400
epoch 2200 LossPred 0.4013 LossAtt 0.4931 TrainAcc 0.8900 TestAcc 0.8023 0.8750
epoch 2300 LossPred 0.6685 LossAtt 0.4858 TrainAcc 0.7700 TestAcc 0.7442 0.7700
epoch 2400 LossPred 0.6112 LossAtt 0.4825 TrainAcc 0.8100 TestAcc 0.7570 0.7850
epoch 2500 LossPred 0.4073 LossAtt 0.4754 TrainAcc 0.8900 TestAcc 0.8098 0.8850
Optimization Finished!
********** replication  22  **********
epoch   0 LossPred 1.2307 LossAtt 1.0261 TrainAcc 0.5200 TestAcc 0.5105 0.5200
epoch 100 LossPred 0.9833 LossAtt 0.3576 TrainAcc 0.5500 TestAcc 0.5608 0.5550
epoch 200 LossPred 0.9705 LossAtt 0.3381 TrainAcc 0.5700 TestAcc 0.5831 0.5650
epoch 300 LossPred 0.9396 LossAtt 0.3583 TrainAcc 0.6300 TestAcc 0.6016 0.6100
epoch 400 LossPred 0.8589 LossAtt 0.3711 TrainAcc 0.6700 TestAcc 0.6391 0.6500
epoch 500 LossPred 0.4218 LossAtt 0.3629 TrainAcc 0.8500 TestAcc 0.8468 0.8450
epoch 600 LossPred 0.3952 LossAtt 0.3563 TrainAcc 0.8500 TestAcc 0.8544 0.8400
epoch 700 LossPred 0.3896 LossAtt 0.3579 TrainAcc 0.8600 TestAcc 0.8576 0.8350
epoch 800 LossPred 0.3869 LossAtt 0.3565 TrainAcc 0.8500 TestAcc 0.8579 0.8450
epoch 900 LossPred 0.3879 LossAtt 0.3654 TrainAcc 0.8500 TestAcc 0.8569 0.8300
epoch 1000 LossPred 0.3971 LossAtt 0.3439 TrainAcc 0.8500 TestAcc 0.8586 0.8450
epoch 1100 LossPred 0.3848 LossAtt 0.3534 TrainAcc 0.8700 TestAcc 0.8589 0.8350
epoch 1200 LossPred 0.3866 LossAtt 0.3503 TrainAcc 0.8600 TestAcc 0.8639 0.8450
epoch 1300 LossPred 0.4015 LossAtt 0.3490 TrainAcc 0.8400 TestAcc 0.8714 0.8500
epoch 1400 LossPred 0.4156 LossAtt 0.3483 TrainAcc 0.8400 TestAcc 0.8674 0.8150
epoch 1500 LossPred 0.3776 LossAtt 0.3545 TrainAcc 0.8700 TestAcc 0.8751 0.8500
epoch 1600 LossPred 0.4092 LossAtt 0.3681 TrainAcc 0.8700 TestAcc 0.8674 0.8400
epoch 1700 LossPred 0.3855 LossAtt 0.3546 TrainAcc 0.8600 TestAcc 0.8706 0.8350
epoch 1800 LossPred 0.3828 LossAtt 0.3512 TrainAcc 0.8500 TestAcc 0.8719 0.8350
epoch 1900 LossPred 0.3927 LossAtt 0.3620 TrainAcc 0.8600 TestAcc 0.8709 0.8450
epoch 2000 LossPred 0.4238 LossAtt 0.3749 TrainAcc 0.8600 TestAcc 0.8641 0.8400
epoch 2100 LossPred 0.3710 LossAtt 0.3503 TrainAcc 0.8700 TestAcc 0.8799 0.8500
epoch 2200 LossPred 0.3885 LossAtt 0.3371 TrainAcc 0.8500 TestAcc 0.8726 0.8450
epoch 2300 LossPred 0.3889 LossAtt 0.3544 TrainAcc 0.8600 TestAcc 0.8764 0.8600
epoch 2400 LossPred 0.3691 LossAtt 0.3443 TrainAcc 0.8700 TestAcc 0.8726 0.8550
epoch 2500 LossPred 0.3814 LossAtt 0.3422 TrainAcc 0.8500 TestAcc 0.8706 0.8450
Optimization Finished!
********** replication  23  **********
epoch   0 LossPred 1.2898 LossAtt 1.0021 TrainAcc 0.3900 TestAcc 0.4317 0.4050
epoch 100 LossPred 1.0356 LossAtt 0.4533 TrainAcc 0.4400 TestAcc 0.5185 0.4450
epoch 200 LossPred 0.9688 LossAtt 0.4189 TrainAcc 0.5800 TestAcc 0.5886 0.5800
epoch 300 LossPred 0.9487 LossAtt 0.3363 TrainAcc 0.6000 TestAcc 0.5823 0.6050
epoch 400 LossPred 0.9456 LossAtt 0.2990 TrainAcc 0.6000 TestAcc 0.5823 0.6000
epoch 500 LossPred 0.9431 LossAtt 0.2928 TrainAcc 0.6000 TestAcc 0.5823 0.6100
epoch 600 LossPred 0.7288 LossAtt 0.3837 TrainAcc 0.7400 TestAcc 0.7245 0.7450
epoch 700 LossPred 0.5205 LossAtt 0.3336 TrainAcc 0.8300 TestAcc 0.8183 0.8250
epoch 800 LossPred 0.4671 LossAtt 0.3339 TrainAcc 0.8500 TestAcc 0.8176 0.8000
epoch 900 LossPred 0.4887 LossAtt 0.3298 TrainAcc 0.8700 TestAcc 0.8076 0.8300
epoch 1000 LossPred 0.4354 LossAtt 0.3225 TrainAcc 0.8900 TestAcc 0.7865 0.8500
epoch 1100 LossPred 0.6014 LossAtt 0.3254 TrainAcc 0.8400 TestAcc 0.7302 0.8050
epoch 1200 LossPred 0.4299 LossAtt 0.3111 TrainAcc 0.8900 TestAcc 0.7905 0.8550
epoch 1300 LossPred 0.3891 LossAtt 0.2927 TrainAcc 0.8900 TestAcc 0.8021 0.8700
epoch 1400 LossPred 0.3765 LossAtt 0.3051 TrainAcc 0.9000 TestAcc 0.7905 0.8700
epoch 1500 LossPred 0.4425 LossAtt 0.3095 TrainAcc 0.8700 TestAcc 0.8196 0.8600
epoch 1600 LossPred 0.4023 LossAtt 0.3034 TrainAcc 0.8800 TestAcc 0.7945 0.8700
epoch 1700 LossPred 0.4590 LossAtt 0.3098 TrainAcc 0.8500 TestAcc 0.8041 0.8500
epoch 1800 LossPred 0.4433 LossAtt 0.3097 TrainAcc 0.8700 TestAcc 0.8208 0.8600
epoch 1900 LossPred 0.4091 LossAtt 0.2947 TrainAcc 0.8600 TestAcc 0.7705 0.8550
epoch 2000 LossPred 0.4720 LossAtt 0.3203 TrainAcc 0.8300 TestAcc 0.8193 0.8200
epoch 2100 LossPred 0.4909 LossAtt 0.2853 TrainAcc 0.8700 TestAcc 0.7570 0.8500
epoch 2200 LossPred 0.3895 LossAtt 0.2931 TrainAcc 0.8900 TestAcc 0.8006 0.8700
epoch 2300 LossPred 0.4183 LossAtt 0.3136 TrainAcc 0.8800 TestAcc 0.8053 0.8550
epoch 2400 LossPred 0.4900 LossAtt 0.3190 TrainAcc 0.8600 TestAcc 0.7523 0.8350
epoch 2500 LossPred 0.4351 LossAtt 0.2970 TrainAcc 0.8800 TestAcc 0.7635 0.8650
Optimization Finished!
********** replication  24  **********
epoch   0 LossPred 1.3096 LossAtt 1.0195 TrainAcc 0.4300 TestAcc 0.4922 0.4350
epoch 100 LossPred 1.0247 LossAtt 0.3425 TrainAcc 0.5100 TestAcc 0.4777 0.4850
epoch 200 LossPred 0.9765 LossAtt 0.1997 TrainAcc 0.5400 TestAcc 0.5010 0.5400
epoch 300 LossPred 0.9633 LossAtt 0.2396 TrainAcc 0.6100 TestAcc 0.5501 0.6100
epoch 400 LossPred 0.9439 LossAtt 0.2921 TrainAcc 0.6200 TestAcc 0.5766 0.6200
epoch 500 LossPred 0.7527 LossAtt 0.4979 TrainAcc 0.7600 TestAcc 0.7285 0.7200
epoch 600 LossPred 0.8376 LossAtt 0.3925 TrainAcc 0.6800 TestAcc 0.6059 0.6650
epoch 700 LossPred 0.6313 LossAtt 0.4210 TrainAcc 0.7900 TestAcc 0.7032 0.7700
epoch 800 LossPred 0.6232 LossAtt 0.3997 TrainAcc 0.8000 TestAcc 0.6974 0.7650
epoch 900 LossPred 0.7494 LossAtt 0.3743 TrainAcc 0.7400 TestAcc 0.6797 0.7350
epoch 1000 LossPred 0.5496 LossAtt 0.3943 TrainAcc 0.8200 TestAcc 0.7913 0.8000
epoch 1100 LossPred 0.5568 LossAtt 0.3566 TrainAcc 0.8200 TestAcc 0.7848 0.8150
epoch 1200 LossPred 0.5849 LossAtt 0.3465 TrainAcc 0.8100 TestAcc 0.7265 0.7900
epoch 1300 LossPred 0.5885 LossAtt 0.3575 TrainAcc 0.7900 TestAcc 0.7237 0.7950
epoch 1400 LossPred 0.4176 LossAtt 0.3761 TrainAcc 0.8700 TestAcc 0.8081 0.8250
epoch 1500 LossPred 0.3412 LossAtt 0.3740 TrainAcc 0.9000 TestAcc 0.8221 0.8400
epoch 1600 LossPred 0.4475 LossAtt 0.4071 TrainAcc 0.8600 TestAcc 0.8296 0.8400
epoch 1700 LossPred 0.3689 LossAtt 0.3830 TrainAcc 0.8900 TestAcc 0.8158 0.8400
epoch 1800 LossPred 0.3303 LossAtt 0.4004 TrainAcc 0.8800 TestAcc 0.8544 0.8800
epoch 1900 LossPred 0.5411 LossAtt 0.3733 TrainAcc 0.8300 TestAcc 0.7485 0.8000
epoch 2000 LossPred 0.3649 LossAtt 0.3703 TrainAcc 0.8800 TestAcc 0.8126 0.8450
epoch 2100 LossPred 0.3243 LossAtt 0.3906 TrainAcc 0.9000 TestAcc 0.8258 0.8650
epoch 2200 LossPred 0.3388 LossAtt 0.4063 TrainAcc 0.9000 TestAcc 0.8584 0.8750
epoch 2300 LossPred 0.3358 LossAtt 0.3783 TrainAcc 0.9000 TestAcc 0.8491 0.8700
epoch 2400 LossPred 0.5582 LossAtt 0.3958 TrainAcc 0.8300 TestAcc 0.7435 0.8050
epoch 2500 LossPred 0.5612 LossAtt 0.4459 TrainAcc 0.8000 TestAcc 0.8223 0.8050
Optimization Finished!
********** replication  25  **********
epoch   0 LossPred 1.2079 LossAtt 1.0238 TrainAcc 0.4400 TestAcc 0.4622 0.4400
epoch 100 LossPred 0.9544 LossAtt 0.5197 TrainAcc 0.6300 TestAcc 0.5956 0.6250
epoch 200 LossPred 0.8996 LossAtt 0.4854 TrainAcc 0.6400 TestAcc 0.6001 0.6300
epoch 300 LossPred 0.8043 LossAtt 0.4944 TrainAcc 0.7000 TestAcc 0.6369 0.6700
epoch 400 LossPred 0.6084 LossAtt 0.4573 TrainAcc 0.7900 TestAcc 0.7800 0.7650
epoch 500 LossPred 0.6001 LossAtt 0.4462 TrainAcc 0.8000 TestAcc 0.7783 0.8150
epoch 600 LossPred 0.6309 LossAtt 0.4477 TrainAcc 0.7300 TestAcc 0.7405 0.7550
epoch 700 LossPred 0.5172 LossAtt 0.4286 TrainAcc 0.8200 TestAcc 0.8121 0.8100
epoch 800 LossPred 0.5855 LossAtt 0.4463 TrainAcc 0.7800 TestAcc 0.7628 0.7700
epoch 900 LossPred 0.5398 LossAtt 0.4237 TrainAcc 0.8000 TestAcc 0.8096 0.7600
epoch 1000 LossPred 0.5354 LossAtt 0.4384 TrainAcc 0.8000 TestAcc 0.7788 0.8100
epoch 1100 LossPred 0.4871 LossAtt 0.4091 TrainAcc 0.8400 TestAcc 0.8061 0.8150
epoch 1200 LossPred 0.5404 LossAtt 0.3994 TrainAcc 0.8000 TestAcc 0.7665 0.7900
epoch 1300 LossPred 0.5626 LossAtt 0.4278 TrainAcc 0.8200 TestAcc 0.7613 0.7900
epoch 1400 LossPred 0.8623 LossAtt 0.4366 TrainAcc 0.7000 TestAcc 0.7282 0.6950
epoch 1500 LossPred 0.6765 LossAtt 0.4274 TrainAcc 0.7500 TestAcc 0.7895 0.7500
epoch 1600 LossPred 0.6423 LossAtt 0.4221 TrainAcc 0.7500 TestAcc 0.8026 0.7700
epoch 1700 LossPred 0.5556 LossAtt 0.4213 TrainAcc 0.7900 TestAcc 0.8168 0.7950
epoch 1800 LossPred 0.5215 LossAtt 0.4058 TrainAcc 0.8200 TestAcc 0.8181 0.8100
epoch 1900 LossPred 0.4814 LossAtt 0.4178 TrainAcc 0.8200 TestAcc 0.8196 0.7900
epoch 2000 LossPred 0.4758 LossAtt 0.4020 TrainAcc 0.8300 TestAcc 0.8211 0.7900
epoch 2100 LossPred 0.4785 LossAtt 0.4055 TrainAcc 0.8400 TestAcc 0.8188 0.7900
epoch 2200 LossPred 0.4778 LossAtt 0.3974 TrainAcc 0.8500 TestAcc 0.8206 0.8150
epoch 2300 LossPred 0.5200 LossAtt 0.4123 TrainAcc 0.8100 TestAcc 0.8156 0.7750
epoch 2400 LossPred 0.4957 LossAtt 0.4084 TrainAcc 0.8500 TestAcc 0.8103 0.7800
epoch 2500 LossPred 0.4732 LossAtt 0.4033 TrainAcc 0.8700 TestAcc 0.8161 0.8200
Optimization Finished!
********** replication  26  **********
epoch   0 LossPred 0.9999 LossAtt 0.9853 TrainAcc 0.5400 TestAcc 0.4882 0.5100
epoch 100 LossPred 0.9696 LossAtt 0.4202 TrainAcc 0.5200 TestAcc 0.5458 0.5450
epoch 200 LossPred 0.9633 LossAtt 0.3725 TrainAcc 0.5400 TestAcc 0.5463 0.5400
epoch 300 LossPred 0.9621 LossAtt 0.3085 TrainAcc 0.5500 TestAcc 0.5553 0.5250
epoch 400 LossPred 0.9581 LossAtt 0.3199 TrainAcc 0.5400 TestAcc 0.5435 0.5550
epoch 500 LossPred 0.9396 LossAtt 0.3390 TrainAcc 0.5600 TestAcc 0.5458 0.5600
epoch 600 LossPred 0.9328 LossAtt 0.3485 TrainAcc 0.5800 TestAcc 0.5748 0.5600
epoch 700 LossPred 0.9305 LossAtt 0.3448 TrainAcc 0.5300 TestAcc 0.5413 0.5800
epoch 800 LossPred 0.9357 LossAtt 0.3060 TrainAcc 0.5800 TestAcc 0.5345 0.5750
epoch 900 LossPred 0.9403 LossAtt 0.3053 TrainAcc 0.5700 TestAcc 0.5378 0.5550
epoch 1000 LossPred 0.9597 LossAtt 0.2616 TrainAcc 0.5500 TestAcc 0.5498 0.5450
epoch 1100 LossPred 0.9549 LossAtt 0.2732 TrainAcc 0.5300 TestAcc 0.5355 0.5550
epoch 1200 LossPred 0.9528 LossAtt 0.2663 TrainAcc 0.5600 TestAcc 0.5398 0.5550
epoch 1300 LossPred 0.9609 LossAtt 0.2453 TrainAcc 0.5500 TestAcc 0.5521 0.5450
epoch 1400 LossPred 0.9744 LossAtt 0.1782 TrainAcc 0.5500 TestAcc 0.5618 0.5500
epoch 1500 LossPred 0.9733 LossAtt 0.1781 TrainAcc 0.5500 TestAcc 0.5618 0.5500
epoch 1600 LossPred 0.9693 LossAtt 0.1952 TrainAcc 0.5500 TestAcc 0.5618 0.5500
epoch 1700 LossPred 0.9338 LossAtt 0.3168 TrainAcc 0.5900 TestAcc 0.5298 0.5800
epoch 1800 LossPred 0.9772 LossAtt 0.1366 TrainAcc 0.5500 TestAcc 0.5618 0.5500
epoch 1900 LossPred 0.9773 LossAtt 0.1312 TrainAcc 0.5500 TestAcc 0.5618 0.5500
epoch 2000 LossPred 0.9778 LossAtt 0.1262 TrainAcc 0.5500 TestAcc 0.5618 0.5500
epoch 2100 LossPred 0.9782 LossAtt 0.1248 TrainAcc 0.5500 TestAcc 0.5618 0.5500
epoch 2200 LossPred 0.9788 LossAtt 0.1281 TrainAcc 0.5500 TestAcc 0.5618 0.5500
epoch 2300 LossPred 0.9795 LossAtt 0.1222 TrainAcc 0.5500 TestAcc 0.5618 0.5500
epoch 2400 LossPred 0.9795 LossAtt 0.1162 TrainAcc 0.5500 TestAcc 0.5618 0.5500
epoch 2500 LossPred 0.9799 LossAtt 0.1142 TrainAcc 0.5500 TestAcc 0.5618 0.5500
Optimization Finished!
********** replication  27  **********
epoch   0 LossPred 1.0882 LossAtt 1.0502 TrainAcc 0.6300 TestAcc 0.5793 0.5650
epoch 100 LossPred 0.8798 LossAtt 0.4628 TrainAcc 0.6600 TestAcc 0.5283 0.6350
epoch 200 LossPred 0.8840 LossAtt 0.3945 TrainAcc 0.6300 TestAcc 0.4997 0.6300
epoch 300 LossPred 0.8644 LossAtt 0.3434 TrainAcc 0.6300 TestAcc 0.4997 0.6300
epoch 400 LossPred 0.8545 LossAtt 0.3509 TrainAcc 0.6300 TestAcc 0.4997 0.6300
epoch 500 LossPred 0.8373 LossAtt 0.3603 TrainAcc 0.6500 TestAcc 0.5235 0.6500
epoch 600 LossPred 0.8091 LossAtt 0.3895 TrainAcc 0.6700 TestAcc 0.5483 0.6700
epoch 700 LossPred 0.7867 LossAtt 0.4080 TrainAcc 0.6700 TestAcc 0.5493 0.6650
epoch 800 LossPred 0.7555 LossAtt 0.4028 TrainAcc 0.7100 TestAcc 0.5673 0.6900
epoch 900 LossPred 0.7366 LossAtt 0.4650 TrainAcc 0.7300 TestAcc 0.5848 0.7200
epoch 1000 LossPred 0.7321 LossAtt 0.5274 TrainAcc 0.7200 TestAcc 0.5821 0.7100
epoch 1100 LossPred 0.7005 LossAtt 0.5851 TrainAcc 0.7700 TestAcc 0.5531 0.7400
epoch 1200 LossPred 0.6821 LossAtt 0.5048 TrainAcc 0.7500 TestAcc 0.5465 0.7250
epoch 1300 LossPred 0.6793 LossAtt 0.4898 TrainAcc 0.7400 TestAcc 0.5558 0.7350
epoch 1400 LossPred 0.6481 LossAtt 0.5085 TrainAcc 0.7700 TestAcc 0.5526 0.7500
epoch 1500 LossPred 0.6453 LossAtt 0.5095 TrainAcc 0.7700 TestAcc 0.5488 0.7450
epoch 1600 LossPred 0.6480 LossAtt 0.5395 TrainAcc 0.7700 TestAcc 0.5561 0.7300
epoch 1700 LossPred 0.6047 LossAtt 0.5583 TrainAcc 0.7900 TestAcc 0.5586 0.7700
epoch 1800 LossPred 0.5669 LossAtt 0.5617 TrainAcc 0.8200 TestAcc 0.5786 0.7800
epoch 1900 LossPred 0.5838 LossAtt 0.5695 TrainAcc 0.7600 TestAcc 0.5723 0.7450
epoch 2000 LossPred 0.5451 LossAtt 0.6294 TrainAcc 0.8200 TestAcc 0.5581 0.7450
epoch 2100 LossPred 0.5240 LossAtt 0.6409 TrainAcc 0.8500 TestAcc 0.5578 0.7800
epoch 2200 LossPred 0.5064 LossAtt 0.6145 TrainAcc 0.8400 TestAcc 0.5538 0.8100
epoch 2300 LossPred 0.5006 LossAtt 0.6494 TrainAcc 0.8500 TestAcc 0.5606 0.7900
epoch 2400 LossPred 0.5992 LossAtt 0.6361 TrainAcc 0.7400 TestAcc 0.5713 0.7800
epoch 2500 LossPred 0.5182 LossAtt 0.6287 TrainAcc 0.8200 TestAcc 0.5498 0.8050
Optimization Finished!
********** replication  28  **********
epoch   0 LossPred 1.4284 LossAtt 0.9936 TrainAcc 0.4200 TestAcc 0.4707 0.4450
epoch 100 LossPred 1.0641 LossAtt 0.3892 TrainAcc 0.4100 TestAcc 0.4232 0.4150
epoch 200 LossPred 0.9989 LossAtt 0.2877 TrainAcc 0.4700 TestAcc 0.5128 0.4950
epoch 300 LossPred 0.9976 LossAtt 0.2172 TrainAcc 0.5500 TestAcc 0.5696 0.5200
epoch 400 LossPred 0.9897 LossAtt 0.1236 TrainAcc 0.5500 TestAcc 0.5881 0.5500
epoch 500 LossPred 0.9862 LossAtt 0.1594 TrainAcc 0.5500 TestAcc 0.5881 0.5500
epoch 600 LossPred 0.9879 LossAtt 0.2179 TrainAcc 0.5500 TestAcc 0.5881 0.5500
epoch 700 LossPred 0.9443 LossAtt 0.3090 TrainAcc 0.5900 TestAcc 0.5583 0.5950
epoch 800 LossPred 0.8522 LossAtt 0.4438 TrainAcc 0.7300 TestAcc 0.7267 0.7100
epoch 900 LossPred 0.7329 LossAtt 0.4363 TrainAcc 0.7400 TestAcc 0.7753 0.7650
epoch 1000 LossPred 0.5556 LossAtt 0.4566 TrainAcc 0.8000 TestAcc 0.8091 0.7800
epoch 1100 LossPred 0.4719 LossAtt 0.4084 TrainAcc 0.8400 TestAcc 0.8208 0.8350
epoch 1200 LossPred 0.4562 LossAtt 0.4073 TrainAcc 0.8600 TestAcc 0.8206 0.7950
epoch 1300 LossPred 0.6002 LossAtt 0.3484 TrainAcc 0.7800 TestAcc 0.8001 0.8150
epoch 1400 LossPred 0.8423 LossAtt 0.3021 TrainAcc 0.7300 TestAcc 0.7190 0.7450
epoch 1500 LossPred 0.7003 LossAtt 0.2866 TrainAcc 0.7700 TestAcc 0.7445 0.7600
epoch 1600 LossPred 0.5581 LossAtt 0.3285 TrainAcc 0.8000 TestAcc 0.8046 0.8000
epoch 1700 LossPred 0.4507 LossAtt 0.3047 TrainAcc 0.8600 TestAcc 0.8458 0.8650
epoch 1800 LossPred 0.4462 LossAtt 0.3062 TrainAcc 0.8300 TestAcc 0.8053 0.8350
epoch 1900 LossPred 0.6181 LossAtt 0.2790 TrainAcc 0.7800 TestAcc 0.7590 0.7850
epoch 2000 LossPred 0.3841 LossAtt 0.2804 TrainAcc 0.8800 TestAcc 0.8428 0.8800
epoch 2100 LossPred 0.4431 LossAtt 0.2906 TrainAcc 0.8600 TestAcc 0.8401 0.8650
epoch 2200 LossPred 0.5419 LossAtt 0.3018 TrainAcc 0.8000 TestAcc 0.7995 0.8100
epoch 2300 LossPred 0.7146 LossAtt 0.2717 TrainAcc 0.7600 TestAcc 0.7260 0.7650
epoch 2400 LossPred 0.3758 LossAtt 0.2905 TrainAcc 0.8700 TestAcc 0.8438 0.8700
epoch 2500 LossPred 0.4792 LossAtt 0.2938 TrainAcc 0.8700 TestAcc 0.7775 0.8400
Optimization Finished!
********** replication  29  **********
epoch   0 LossPred 1.2153 LossAtt 1.0197 TrainAcc 0.5000 TestAcc 0.5225 0.4750
epoch 100 LossPred 0.9595 LossAtt 0.4588 TrainAcc 0.6100 TestAcc 0.5928 0.6150
epoch 200 LossPred 0.9260 LossAtt 0.3852 TrainAcc 0.6100 TestAcc 0.5928 0.6100
epoch 300 LossPred 0.9130 LossAtt 0.3317 TrainAcc 0.6100 TestAcc 0.5961 0.6200
epoch 400 LossPred 0.9079 LossAtt 0.3030 TrainAcc 0.6300 TestAcc 0.5921 0.6250
epoch 500 LossPred 0.9041 LossAtt 0.2949 TrainAcc 0.6300 TestAcc 0.5921 0.6150
epoch 600 LossPred 0.9007 LossAtt 0.2821 TrainAcc 0.6500 TestAcc 0.6104 0.6500
epoch 700 LossPred 0.7886 LossAtt 0.5581 TrainAcc 0.7400 TestAcc 0.6807 0.7200
epoch 800 LossPred 0.9081 LossAtt 0.4854 TrainAcc 0.6400 TestAcc 0.5911 0.6250
epoch 900 LossPred 0.8275 LossAtt 0.5897 TrainAcc 0.6900 TestAcc 0.6336 0.7150
epoch 1000 LossPred 0.3644 LossAtt 0.5408 TrainAcc 0.8800 TestAcc 0.7988 0.8850
epoch 1100 LossPred 0.2899 LossAtt 0.5064 TrainAcc 0.9200 TestAcc 0.7968 0.9050
epoch 1200 LossPred 0.2191 LossAtt 0.4729 TrainAcc 0.9300 TestAcc 0.8306 0.9100
epoch 1300 LossPred 0.2082 LossAtt 0.4569 TrainAcc 0.9500 TestAcc 0.8226 0.9300
epoch 1400 LossPred 0.2250 LossAtt 0.4626 TrainAcc 0.9100 TestAcc 0.8266 0.9050
epoch 1500 LossPred 0.5295 LossAtt 0.5004 TrainAcc 0.8000 TestAcc 0.7525 0.8050
epoch 1600 LossPred 0.2162 LossAtt 0.4675 TrainAcc 0.9300 TestAcc 0.8346 0.9300
epoch 1700 LossPred 0.2347 LossAtt 0.4709 TrainAcc 0.9200 TestAcc 0.8293 0.9200
epoch 1800 LossPred 0.7359 LossAtt 0.5179 TrainAcc 0.7500 TestAcc 0.7280 0.7450
epoch 1900 LossPred 0.2370 LossAtt 0.4936 TrainAcc 0.9400 TestAcc 0.8096 0.9150
epoch 2000 LossPred 0.2127 LossAtt 0.4681 TrainAcc 0.9400 TestAcc 0.8176 0.9150
epoch 2100 LossPred 0.7583 LossAtt 0.4592 TrainAcc 0.7900 TestAcc 0.6774 0.7900
epoch 2200 LossPred 0.2954 LossAtt 0.4544 TrainAcc 0.9000 TestAcc 0.8248 0.8950
epoch 2300 LossPred 0.2580 LossAtt 0.4757 TrainAcc 0.9200 TestAcc 0.8371 0.9000
epoch 2400 LossPred 0.3612 LossAtt 0.4495 TrainAcc 0.8800 TestAcc 0.7853 0.8800
epoch 2500 LossPred 0.2674 LossAtt 0.4507 TrainAcc 0.9200 TestAcc 0.8148 0.9200
Optimization Finished!
********** replication  30  **********
epoch   0 LossPred 1.1385 LossAtt 1.0152 TrainAcc 0.5400 TestAcc 0.5173 0.5200
epoch 100 LossPred 0.9280 LossAtt 0.4902 TrainAcc 0.6700 TestAcc 0.5813 0.6300
epoch 200 LossPred 0.8314 LossAtt 0.5075 TrainAcc 0.7300 TestAcc 0.6076 0.7200
epoch 300 LossPred 0.6826 LossAtt 0.5831 TrainAcc 0.7800 TestAcc 0.6707 0.7650
epoch 400 LossPred 0.4746 LossAtt 0.5702 TrainAcc 0.8500 TestAcc 0.8283 0.8300
epoch 500 LossPred 0.4037 LossAtt 0.5330 TrainAcc 0.8800 TestAcc 0.8298 0.8300
epoch 600 LossPred 0.4115 LossAtt 0.5147 TrainAcc 0.8600 TestAcc 0.8348 0.8300
epoch 700 LossPred 0.3976 LossAtt 0.5166 TrainAcc 0.8700 TestAcc 0.8303 0.8250
epoch 800 LossPred 0.4109 LossAtt 0.5021 TrainAcc 0.8600 TestAcc 0.8356 0.8350
epoch 900 LossPred 0.4188 LossAtt 0.5131 TrainAcc 0.8600 TestAcc 0.8353 0.8350
epoch 1000 LossPred 0.4114 LossAtt 0.5094 TrainAcc 0.8600 TestAcc 0.8346 0.8300
epoch 1100 LossPred 0.4272 LossAtt 0.4970 TrainAcc 0.8600 TestAcc 0.8248 0.8400
epoch 1200 LossPred 0.4729 LossAtt 0.4981 TrainAcc 0.8400 TestAcc 0.8106 0.8000
epoch 1300 LossPred 0.4040 LossAtt 0.4898 TrainAcc 0.8500 TestAcc 0.8203 0.8500
epoch 1400 LossPred 0.4135 LossAtt 0.5094 TrainAcc 0.8900 TestAcc 0.8243 0.8450
epoch 1500 LossPred 0.5266 LossAtt 0.5014 TrainAcc 0.8200 TestAcc 0.8016 0.8250
epoch 1600 LossPred 0.4482 LossAtt 0.4683 TrainAcc 0.8500 TestAcc 0.8226 0.8200
epoch 1700 LossPred 0.4756 LossAtt 0.4671 TrainAcc 0.8200 TestAcc 0.8223 0.8300
epoch 1800 LossPred 0.4491 LossAtt 0.4521 TrainAcc 0.8500 TestAcc 0.8183 0.8150
epoch 1900 LossPred 0.4254 LossAtt 0.4782 TrainAcc 0.8800 TestAcc 0.8311 0.8350
epoch 2000 LossPred 0.4195 LossAtt 0.4680 TrainAcc 0.8500 TestAcc 0.8261 0.8500
epoch 2100 LossPred 0.3964 LossAtt 0.4281 TrainAcc 0.8800 TestAcc 0.8328 0.8350
epoch 2200 LossPred 0.3896 LossAtt 0.4472 TrainAcc 0.8800 TestAcc 0.8301 0.8500
epoch 2300 LossPred 0.4347 LossAtt 0.4248 TrainAcc 0.8600 TestAcc 0.8316 0.8200
epoch 2400 LossPred 0.4144 LossAtt 0.4239 TrainAcc 0.8600 TestAcc 0.8371 0.8300
epoch 2500 LossPred 0.3981 LossAtt 0.4310 TrainAcc 0.8700 TestAcc 0.8336 0.8150
Optimization Finished!
********** replication  31  **********
epoch   0 LossPred 1.1985 LossAtt 1.0069 TrainAcc 0.5200 TestAcc 0.5498 0.5100
epoch 100 LossPred 0.9920 LossAtt 0.3872 TrainAcc 0.5400 TestAcc 0.5475 0.5250
epoch 200 LossPred 0.9654 LossAtt 0.4385 TrainAcc 0.6000 TestAcc 0.5268 0.5850
epoch 300 LossPred 0.9053 LossAtt 0.4784 TrainAcc 0.6000 TestAcc 0.4992 0.6400
epoch 400 LossPred 0.8316 LossAtt 0.4693 TrainAcc 0.6700 TestAcc 0.5133 0.6950
epoch 500 LossPred 0.8076 LossAtt 0.4178 TrainAcc 0.7000 TestAcc 0.5150 0.7150
epoch 600 LossPred 0.8172 LossAtt 0.3853 TrainAcc 0.7200 TestAcc 0.5278 0.7250
epoch 700 LossPred 0.7915 LossAtt 0.3826 TrainAcc 0.7300 TestAcc 0.5178 0.7000
epoch 800 LossPred 0.7937 LossAtt 0.4047 TrainAcc 0.7200 TestAcc 0.5198 0.7150
epoch 900 LossPred 0.7959 LossAtt 0.3767 TrainAcc 0.7000 TestAcc 0.5110 0.6750
epoch 1000 LossPred 0.7822 LossAtt 0.3596 TrainAcc 0.7000 TestAcc 0.5160 0.6900
epoch 1100 LossPred 0.7766 LossAtt 0.3635 TrainAcc 0.6900 TestAcc 0.5218 0.6800
epoch 1200 LossPred 0.7729 LossAtt 0.3651 TrainAcc 0.7100 TestAcc 0.5335 0.6800
epoch 1300 LossPred 0.7805 LossAtt 0.3537 TrainAcc 0.7000 TestAcc 0.5330 0.6600
epoch 1400 LossPred 0.7602 LossAtt 0.3592 TrainAcc 0.7000 TestAcc 0.5353 0.6750
epoch 1500 LossPred 0.7564 LossAtt 0.3579 TrainAcc 0.7100 TestAcc 0.5333 0.6800
epoch 1600 LossPred 0.7489 LossAtt 0.3755 TrainAcc 0.7000 TestAcc 0.5335 0.6850
epoch 1700 LossPred 0.7439 LossAtt 0.3761 TrainAcc 0.7000 TestAcc 0.5315 0.6850
epoch 1800 LossPred 0.7338 LossAtt 0.3866 TrainAcc 0.7200 TestAcc 0.5353 0.6950
epoch 1900 LossPred 0.7315 LossAtt 0.3924 TrainAcc 0.7300 TestAcc 0.5375 0.6950
epoch 2000 LossPred 0.7325 LossAtt 0.4094 TrainAcc 0.7300 TestAcc 0.5370 0.6950
epoch 2100 LossPred 0.7241 LossAtt 0.3942 TrainAcc 0.7200 TestAcc 0.5400 0.6950
epoch 2200 LossPred 0.7057 LossAtt 0.4263 TrainAcc 0.7600 TestAcc 0.5506 0.6850
epoch 2300 LossPred 0.6952 LossAtt 0.4243 TrainAcc 0.7400 TestAcc 0.5463 0.7000
epoch 2400 LossPred 0.6896 LossAtt 0.4399 TrainAcc 0.7400 TestAcc 0.5531 0.7200
epoch 2500 LossPred 0.7137 LossAtt 0.4878 TrainAcc 0.7700 TestAcc 0.5683 0.7350
Optimization Finished!
********** replication  32  **********
epoch   0 LossPred 1.2413 LossAtt 1.0223 TrainAcc 0.4700 TestAcc 0.5168 0.5050
epoch 100 LossPred 0.9764 LossAtt 0.3890 TrainAcc 0.5700 TestAcc 0.5158 0.5850
epoch 200 LossPred 0.9516 LossAtt 0.3678 TrainAcc 0.6000 TestAcc 0.5388 0.6000
epoch 300 LossPred 0.9447 LossAtt 0.3739 TrainAcc 0.6100 TestAcc 0.5235 0.5750
epoch 400 LossPred 0.9132 LossAtt 0.4959 TrainAcc 0.6700 TestAcc 0.5238 0.6450
epoch 500 LossPred 0.8698 LossAtt 0.5611 TrainAcc 0.6700 TestAcc 0.5365 0.6150
epoch 600 LossPred 0.8475 LossAtt 0.5700 TrainAcc 0.6600 TestAcc 0.5480 0.6450
epoch 700 LossPred 0.8449 LossAtt 0.5762 TrainAcc 0.6600 TestAcc 0.5518 0.6400
epoch 800 LossPred 0.8447 LossAtt 0.5516 TrainAcc 0.6600 TestAcc 0.5531 0.6500
epoch 900 LossPred 0.8427 LossAtt 0.5613 TrainAcc 0.6600 TestAcc 0.5533 0.6500
epoch 1000 LossPred 0.8405 LossAtt 0.5631 TrainAcc 0.6600 TestAcc 0.5553 0.6450
epoch 1100 LossPred 0.8389 LossAtt 0.5609 TrainAcc 0.6700 TestAcc 0.5558 0.6550
epoch 1200 LossPred 0.8369 LossAtt 0.5482 TrainAcc 0.6800 TestAcc 0.5558 0.6600
epoch 1300 LossPred 0.8234 LossAtt 0.5600 TrainAcc 0.6900 TestAcc 0.5553 0.6500
epoch 1400 LossPred 0.8347 LossAtt 0.5538 TrainAcc 0.6600 TestAcc 0.5538 0.6600
epoch 1500 LossPred 0.8081 LossAtt 0.5699 TrainAcc 0.6900 TestAcc 0.5551 0.6650
epoch 1600 LossPred 0.8119 LossAtt 0.5613 TrainAcc 0.6700 TestAcc 0.5598 0.6900
epoch 1700 LossPred 0.8032 LossAtt 0.5829 TrainAcc 0.6600 TestAcc 0.5661 0.6750
epoch 1800 LossPred 0.7982 LossAtt 0.5647 TrainAcc 0.7000 TestAcc 0.5586 0.6900
epoch 1900 LossPred 0.7683 LossAtt 0.5683 TrainAcc 0.6800 TestAcc 0.5653 0.6850
epoch 2000 LossPred 0.7603 LossAtt 0.5542 TrainAcc 0.7000 TestAcc 0.5663 0.6800
epoch 2100 LossPred 0.7576 LossAtt 0.5582 TrainAcc 0.7100 TestAcc 0.5651 0.6700
epoch 2200 LossPred 0.7691 LossAtt 0.5546 TrainAcc 0.7000 TestAcc 0.5688 0.6700
epoch 2300 LossPred 0.7778 LossAtt 0.5410 TrainAcc 0.7000 TestAcc 0.5661 0.6600
epoch 2400 LossPred 0.8067 LossAtt 0.5276 TrainAcc 0.7000 TestAcc 0.5656 0.6450
epoch 2500 LossPred 0.8059 LossAtt 0.5171 TrainAcc 0.6800 TestAcc 0.5621 0.6600
Optimization Finished!
********** replication  33  **********
epoch   0 LossPred 1.2443 LossAtt 1.0109 TrainAcc 0.4800 TestAcc 0.5671 0.4850
epoch 100 LossPred 1.0340 LossAtt 0.4638 TrainAcc 0.5300 TestAcc 0.5953 0.5250
epoch 200 LossPred 1.0039 LossAtt 0.5119 TrainAcc 0.5300 TestAcc 0.5681 0.5300
epoch 300 LossPred 0.9864 LossAtt 0.4984 TrainAcc 0.5500 TestAcc 0.5628 0.5600
epoch 400 LossPred 0.5105 LossAtt 0.5662 TrainAcc 0.9000 TestAcc 0.8018 0.8600
epoch 500 LossPred 0.2919 LossAtt 0.5409 TrainAcc 0.9300 TestAcc 0.8161 0.8650
epoch 600 LossPred 0.2622 LossAtt 0.5220 TrainAcc 0.9300 TestAcc 0.8181 0.8700
epoch 700 LossPred 0.2466 LossAtt 0.5126 TrainAcc 0.9300 TestAcc 0.8196 0.8900
epoch 800 LossPred 0.3798 LossAtt 0.5207 TrainAcc 0.8800 TestAcc 0.7860 0.8350
epoch 900 LossPred 0.3143 LossAtt 0.5158 TrainAcc 0.9000 TestAcc 0.8053 0.8850
epoch 1000 LossPred 0.3298 LossAtt 0.5029 TrainAcc 0.9000 TestAcc 0.8053 0.8900
epoch 1100 LossPred 0.2467 LossAtt 0.5001 TrainAcc 0.9200 TestAcc 0.8128 0.8750
epoch 1200 LossPred 0.2104 LossAtt 0.4998 TrainAcc 0.9300 TestAcc 0.7958 0.8900
epoch 1300 LossPred 0.2496 LossAtt 0.5137 TrainAcc 0.9200 TestAcc 0.8008 0.8750
epoch 1400 LossPred 0.3117 LossAtt 0.5192 TrainAcc 0.8900 TestAcc 0.8156 0.8700
epoch 1500 LossPred 0.2184 LossAtt 0.5132 TrainAcc 0.9300 TestAcc 0.8016 0.8850
epoch 1600 LossPred 0.2825 LossAtt 0.5442 TrainAcc 0.9000 TestAcc 0.7908 0.8700
epoch 1700 LossPred 0.2375 LossAtt 0.5113 TrainAcc 0.9500 TestAcc 0.8133 0.8950
epoch 1800 LossPred 0.2493 LossAtt 0.5316 TrainAcc 0.9300 TestAcc 0.8158 0.8850
epoch 1900 LossPred 0.2738 LossAtt 0.5082 TrainAcc 0.9200 TestAcc 0.7990 0.8800
epoch 2000 LossPred 0.1793 LossAtt 0.5082 TrainAcc 0.9500 TestAcc 0.8176 0.8900
epoch 2100 LossPred 0.1595 LossAtt 0.5182 TrainAcc 0.9600 TestAcc 0.8128 0.8950
epoch 2200 LossPred 0.2106 LossAtt 0.5126 TrainAcc 0.9400 TestAcc 0.7760 0.8850
epoch 2300 LossPred 0.1632 LossAtt 0.5148 TrainAcc 0.9600 TestAcc 0.8021 0.9000
epoch 2400 LossPred 0.1940 LossAtt 0.5272 TrainAcc 0.9500 TestAcc 0.8058 0.9000
epoch 2500 LossPred 0.2057 LossAtt 0.5165 TrainAcc 0.9400 TestAcc 0.7940 0.9000
Optimization Finished!
********** replication  34  **********
epoch   0 LossPred 1.0162 LossAtt 1.0005 TrainAcc 0.5300 TestAcc 0.5148 0.5300
epoch 100 LossPred 0.9101 LossAtt 0.2692 TrainAcc 0.6400 TestAcc 0.5921 0.6400
epoch 200 LossPred 0.8930 LossAtt 0.2883 TrainAcc 0.6400 TestAcc 0.5921 0.6550
epoch 300 LossPred 0.7207 LossAtt 0.4279 TrainAcc 0.7600 TestAcc 0.7432 0.7450
epoch 400 LossPred 0.6547 LossAtt 0.4259 TrainAcc 0.7600 TestAcc 0.7693 0.7850
epoch 500 LossPred 0.4608 LossAtt 0.3952 TrainAcc 0.8500 TestAcc 0.8348 0.8100
epoch 600 LossPred 0.5071 LossAtt 0.4108 TrainAcc 0.8000 TestAcc 0.8093 0.8100
epoch 700 LossPred 0.4488 LossAtt 0.3809 TrainAcc 0.8400 TestAcc 0.8476 0.8300
epoch 800 LossPred 0.5484 LossAtt 0.3831 TrainAcc 0.8000 TestAcc 0.8413 0.7550
epoch 900 LossPred 0.4841 LossAtt 0.3708 TrainAcc 0.8300 TestAcc 0.8478 0.8200
epoch 1000 LossPred 0.5037 LossAtt 0.4030 TrainAcc 0.8200 TestAcc 0.8206 0.8150
epoch 1100 LossPred 0.4721 LossAtt 0.3628 TrainAcc 0.8300 TestAcc 0.8629 0.8150
epoch 1200 LossPred 0.4160 LossAtt 0.3820 TrainAcc 0.8600 TestAcc 0.8569 0.8450
epoch 1300 LossPred 0.5111 LossAtt 0.3693 TrainAcc 0.8100 TestAcc 0.8559 0.8150
epoch 1400 LossPred 0.3865 LossAtt 0.3620 TrainAcc 0.9000 TestAcc 0.8741 0.8700
epoch 1500 LossPred 0.3880 LossAtt 0.3608 TrainAcc 0.8600 TestAcc 0.8478 0.8700
epoch 1600 LossPred 0.3160 LossAtt 0.3476 TrainAcc 0.9300 TestAcc 0.8814 0.9000
epoch 1700 LossPred 0.4748 LossAtt 0.3504 TrainAcc 0.8300 TestAcc 0.8158 0.8350
epoch 1800 LossPred 0.3072 LossAtt 0.3675 TrainAcc 0.9400 TestAcc 0.8694 0.9150
epoch 1900 LossPred 0.2933 LossAtt 0.3553 TrainAcc 0.9400 TestAcc 0.8746 0.9150
epoch 2000 LossPred 0.2716 LossAtt 0.3562 TrainAcc 0.9400 TestAcc 0.8771 0.9100
epoch 2100 LossPred 0.3798 LossAtt 0.3581 TrainAcc 0.8700 TestAcc 0.8664 0.8350
epoch 2200 LossPred 0.2411 LossAtt 0.3673 TrainAcc 0.9500 TestAcc 0.8806 0.9150
epoch 2300 LossPred 0.2095 LossAtt 0.3558 TrainAcc 0.9400 TestAcc 0.9002 0.9100
epoch 2400 LossPred 0.2004 LossAtt 0.3585 TrainAcc 0.9300 TestAcc 0.9007 0.9100
epoch 2500 LossPred 0.2338 LossAtt 0.3606 TrainAcc 0.9400 TestAcc 0.8994 0.9050
Optimization Finished!
********** replication  35  **********
epoch   0 LossPred 1.2517 LossAtt 1.0298 TrainAcc 0.5100 TestAcc 0.4537 0.5350
epoch 100 LossPred 1.0130 LossAtt 0.3548 TrainAcc 0.5900 TestAcc 0.5053 0.5900
epoch 200 LossPred 0.9860 LossAtt 0.3728 TrainAcc 0.5900 TestAcc 0.5053 0.5900
epoch 300 LossPred 0.9453 LossAtt 0.2730 TrainAcc 0.5900 TestAcc 0.5053 0.5900
epoch 400 LossPred 0.9283 LossAtt 0.2257 TrainAcc 0.6400 TestAcc 0.6006 0.6250
epoch 500 LossPred 0.9227 LossAtt 0.2590 TrainAcc 0.6100 TestAcc 0.5828 0.6050
epoch 600 LossPred 0.8915 LossAtt 0.3913 TrainAcc 0.7200 TestAcc 0.6199 0.7000
epoch 700 LossPred 0.9099 LossAtt 0.3788 TrainAcc 0.6200 TestAcc 0.6552 0.6050
epoch 800 LossPred 0.7952 LossAtt 0.4236 TrainAcc 0.6800 TestAcc 0.6864 0.7100
epoch 900 LossPred 0.6125 LossAtt 0.4173 TrainAcc 0.8000 TestAcc 0.7660 0.7800
epoch 1000 LossPred 0.5043 LossAtt 0.4432 TrainAcc 0.8900 TestAcc 0.8013 0.8200
epoch 1100 LossPred 0.5915 LossAtt 0.4353 TrainAcc 0.8200 TestAcc 0.7785 0.7550
epoch 1200 LossPred 0.5656 LossAtt 0.4285 TrainAcc 0.7800 TestAcc 0.7913 0.8000
epoch 1300 LossPred 0.4623 LossAtt 0.4304 TrainAcc 0.8500 TestAcc 0.7910 0.8350
epoch 1400 LossPred 0.5627 LossAtt 0.4296 TrainAcc 0.7900 TestAcc 0.7828 0.7800
epoch 1500 LossPred 0.4514 LossAtt 0.4191 TrainAcc 0.8600 TestAcc 0.8061 0.8100
epoch 1600 LossPred 0.4493 LossAtt 0.4293 TrainAcc 0.8500 TestAcc 0.8011 0.8150
epoch 1700 LossPred 0.5325 LossAtt 0.4193 TrainAcc 0.8200 TestAcc 0.7730 0.8150
epoch 1800 LossPred 0.5555 LossAtt 0.4227 TrainAcc 0.8100 TestAcc 0.7820 0.7900
epoch 1900 LossPred 0.4826 LossAtt 0.3836 TrainAcc 0.8400 TestAcc 0.8031 0.8100
epoch 2000 LossPred 0.6198 LossAtt 0.4079 TrainAcc 0.7900 TestAcc 0.7833 0.7900
epoch 2100 LossPred 1.0792 LossAtt 0.3708 TrainAcc 0.6500 TestAcc 0.6054 0.6600
epoch 2200 LossPred 0.8942 LossAtt 0.3381 TrainAcc 0.6800 TestAcc 0.5748 0.6900
epoch 2300 LossPred 0.8492 LossAtt 0.3457 TrainAcc 0.6500 TestAcc 0.5971 0.6550
epoch 2400 LossPred 0.8553 LossAtt 0.3309 TrainAcc 0.6600 TestAcc 0.5851 0.6650
epoch 2500 LossPred 0.8376 LossAtt 0.3501 TrainAcc 0.6700 TestAcc 0.6014 0.6850
Optimization Finished!
********** replication  36  **********
epoch   0 LossPred 1.0951 LossAtt 1.0356 TrainAcc 0.5900 TestAcc 0.5671 0.5900
epoch 100 LossPred 0.9139 LossAtt 0.3954 TrainAcc 0.6000 TestAcc 0.5831 0.6200
epoch 200 LossPred 0.8880 LossAtt 0.4083 TrainAcc 0.6600 TestAcc 0.5931 0.6600
epoch 300 LossPred 0.8719 LossAtt 0.3961 TrainAcc 0.6600 TestAcc 0.6026 0.6600
epoch 400 LossPred 0.8603 LossAtt 0.4138 TrainAcc 0.6600 TestAcc 0.6016 0.6550
epoch 500 LossPred 0.6092 LossAtt 0.4689 TrainAcc 0.7800 TestAcc 0.7830 0.7900
epoch 600 LossPred 0.2645 LossAtt 0.3605 TrainAcc 0.9300 TestAcc 0.8909 0.9150
epoch 700 LossPred 0.2292 LossAtt 0.3568 TrainAcc 0.9200 TestAcc 0.8994 0.9200
epoch 800 LossPred 0.2019 LossAtt 0.3363 TrainAcc 0.9100 TestAcc 0.9137 0.9250
epoch 900 LossPred 0.1627 LossAtt 0.3266 TrainAcc 0.9400 TestAcc 0.9289 0.9450
epoch 1000 LossPred 0.1905 LossAtt 0.3206 TrainAcc 0.9600 TestAcc 0.9207 0.9600
epoch 1100 LossPred 0.1434 LossAtt 0.3055 TrainAcc 0.9700 TestAcc 0.9349 0.9650
epoch 1200 LossPred 0.1359 LossAtt 0.3085 TrainAcc 0.9400 TestAcc 0.9387 0.9500
epoch 1300 LossPred 0.1334 LossAtt 0.3023 TrainAcc 0.9600 TestAcc 0.9322 0.9650
epoch 1400 LossPred 0.1657 LossAtt 0.2946 TrainAcc 0.9200 TestAcc 0.9102 0.9350
epoch 1500 LossPred 0.6121 LossAtt 0.3113 TrainAcc 0.7800 TestAcc 0.8093 0.7800
epoch 1600 LossPred 0.6415 LossAtt 0.3100 TrainAcc 0.8200 TestAcc 0.7730 0.8200
epoch 1700 LossPred 0.2789 LossAtt 0.3334 TrainAcc 0.8900 TestAcc 0.8486 0.8900
epoch 1800 LossPred 0.1809 LossAtt 0.3540 TrainAcc 0.9300 TestAcc 0.9017 0.9150
epoch 1900 LossPred 0.1472 LossAtt 0.3706 TrainAcc 0.9300 TestAcc 0.9157 0.9300
epoch 2000 LossPred 0.1592 LossAtt 0.3769 TrainAcc 0.9400 TestAcc 0.9194 0.9500
epoch 2100 LossPred 0.2269 LossAtt 0.3907 TrainAcc 0.9400 TestAcc 0.9004 0.9350
epoch 2200 LossPred 0.1515 LossAtt 0.3799 TrainAcc 0.9500 TestAcc 0.9242 0.9500
epoch 2300 LossPred 0.2332 LossAtt 0.3880 TrainAcc 0.9200 TestAcc 0.8441 0.9150
epoch 2400 LossPred 0.1437 LossAtt 0.3944 TrainAcc 0.9600 TestAcc 0.9229 0.9550
epoch 2500 LossPred 0.1301 LossAtt 0.3907 TrainAcc 0.9600 TestAcc 0.9242 0.9400
Optimization Finished!
********** replication  37  **********
epoch   0 LossPred 1.1243 LossAtt 1.0048 TrainAcc 0.4800 TestAcc 0.5098 0.4800
epoch 100 LossPred 0.9405 LossAtt 0.4066 TrainAcc 0.5900 TestAcc 0.5913 0.5950
epoch 200 LossPred 0.8604 LossAtt 0.4277 TrainAcc 0.7100 TestAcc 0.6481 0.6950
epoch 300 LossPred 0.5885 LossAtt 0.4316 TrainAcc 0.8200 TestAcc 0.7940 0.8150
epoch 400 LossPred 0.5538 LossAtt 0.4150 TrainAcc 0.8000 TestAcc 0.7680 0.7950
epoch 500 LossPred 0.5585 LossAtt 0.3558 TrainAcc 0.8100 TestAcc 0.7560 0.7950
epoch 600 LossPred 0.5454 LossAtt 0.3428 TrainAcc 0.8200 TestAcc 0.7655 0.8100
epoch 700 LossPred 0.5446 LossAtt 0.3416 TrainAcc 0.8200 TestAcc 0.7608 0.8050
epoch 800 LossPred 0.5432 LossAtt 0.3617 TrainAcc 0.8300 TestAcc 0.7638 0.8000
epoch 900 LossPred 0.5424 LossAtt 0.3317 TrainAcc 0.8300 TestAcc 0.7618 0.8050
epoch 1000 LossPred 0.5421 LossAtt 0.3308 TrainAcc 0.8300 TestAcc 0.7620 0.8050
epoch 1100 LossPred 0.5414 LossAtt 0.3394 TrainAcc 0.8200 TestAcc 0.7660 0.8100
epoch 1200 LossPred 0.5409 LossAtt 0.3144 TrainAcc 0.8200 TestAcc 0.7615 0.8000
epoch 1300 LossPred 0.5408 LossAtt 0.3540 TrainAcc 0.8300 TestAcc 0.7665 0.8050
epoch 1400 LossPred 0.5413 LossAtt 0.3435 TrainAcc 0.8100 TestAcc 0.7685 0.8000
epoch 1500 LossPred 0.5404 LossAtt 0.3428 TrainAcc 0.8300 TestAcc 0.7640 0.8050
epoch 1600 LossPred 0.5396 LossAtt 0.3398 TrainAcc 0.8100 TestAcc 0.7675 0.8000
epoch 1700 LossPred 0.5383 LossAtt 0.3481 TrainAcc 0.8100 TestAcc 0.7673 0.8000
epoch 1800 LossPred 0.5399 LossAtt 0.3459 TrainAcc 0.8200 TestAcc 0.7553 0.8050
epoch 1900 LossPred 0.5226 LossAtt 0.3650 TrainAcc 0.8100 TestAcc 0.7437 0.7900
epoch 2000 LossPred 0.5119 LossAtt 0.3260 TrainAcc 0.8300 TestAcc 0.7573 0.8050
epoch 2100 LossPred 0.4980 LossAtt 0.3729 TrainAcc 0.8400 TestAcc 0.7635 0.8150
epoch 2200 LossPred 0.4849 LossAtt 0.3595 TrainAcc 0.8400 TestAcc 0.7665 0.8150
epoch 2300 LossPred 0.4995 LossAtt 0.3785 TrainAcc 0.8300 TestAcc 0.7675 0.8300
epoch 2400 LossPred 0.4528 LossAtt 0.3564 TrainAcc 0.8500 TestAcc 0.7775 0.8400
epoch 2500 LossPred 0.4519 LossAtt 0.3659 TrainAcc 0.8700 TestAcc 0.7803 0.8200
Optimization Finished!
********** replication  38  **********
epoch   0 LossPred 1.1416 LossAtt 1.0107 TrainAcc 0.4800 TestAcc 0.5323 0.4950
epoch 100 LossPred 0.9090 LossAtt 0.3294 TrainAcc 0.6600 TestAcc 0.5818 0.6600
epoch 200 LossPred 0.8978 LossAtt 0.2837 TrainAcc 0.6600 TestAcc 0.5818 0.6600
epoch 300 LossPred 0.8959 LossAtt 0.1903 TrainAcc 0.6600 TestAcc 0.5818 0.6600
epoch 400 LossPred 0.8943 LossAtt 0.1708 TrainAcc 0.6600 TestAcc 0.5818 0.6600
epoch 500 LossPred 0.8901 LossAtt 0.1717 TrainAcc 0.6600 TestAcc 0.5818 0.6600
epoch 600 LossPred 0.8810 LossAtt 0.1965 TrainAcc 0.6600 TestAcc 0.5818 0.6600
epoch 700 LossPred 0.8722 LossAtt 0.1634 TrainAcc 0.7000 TestAcc 0.5996 0.6850
epoch 800 LossPred 0.8759 LossAtt 0.2007 TrainAcc 0.7000 TestAcc 0.5976 0.6850
epoch 900 LossPred 0.6378 LossAtt 0.3209 TrainAcc 0.7800 TestAcc 0.7450 0.7800
epoch 1000 LossPred 0.8481 LossAtt 0.2643 TrainAcc 0.6700 TestAcc 0.6827 0.6650
epoch 1100 LossPred 0.5704 LossAtt 0.2860 TrainAcc 0.8000 TestAcc 0.8173 0.8050
epoch 1200 LossPred 0.5638 LossAtt 0.2865 TrainAcc 0.8300 TestAcc 0.8081 0.8250
epoch 1300 LossPred 0.4541 LossAtt 0.3001 TrainAcc 0.8500 TestAcc 0.8206 0.8450
epoch 1400 LossPred 0.5324 LossAtt 0.2805 TrainAcc 0.7900 TestAcc 0.8226 0.8050
epoch 1500 LossPred 0.4875 LossAtt 0.2737 TrainAcc 0.8600 TestAcc 0.8271 0.8350
epoch 1600 LossPred 0.4846 LossAtt 0.2801 TrainAcc 0.8300 TestAcc 0.8118 0.8050
epoch 1700 LossPred 0.5049 LossAtt 0.2680 TrainAcc 0.8500 TestAcc 0.8073 0.8450
epoch 1800 LossPred 0.4763 LossAtt 0.2782 TrainAcc 0.8200 TestAcc 0.8211 0.8150
epoch 1900 LossPred 0.5415 LossAtt 0.2623 TrainAcc 0.8300 TestAcc 0.7828 0.8300
epoch 2000 LossPred 0.4713 LossAtt 0.2580 TrainAcc 0.8400 TestAcc 0.8151 0.7950
epoch 2100 LossPred 0.5201 LossAtt 0.2625 TrainAcc 0.8400 TestAcc 0.7848 0.8400
epoch 2200 LossPred 0.5393 LossAtt 0.2619 TrainAcc 0.8200 TestAcc 0.7940 0.7950
epoch 2300 LossPred 0.4484 LossAtt 0.2630 TrainAcc 0.8500 TestAcc 0.8106 0.8400
epoch 2400 LossPred 0.5779 LossAtt 0.2696 TrainAcc 0.7800 TestAcc 0.8078 0.7900
epoch 2500 LossPred 0.4942 LossAtt 0.2395 TrainAcc 0.8400 TestAcc 0.7970 0.8400
Optimization Finished!
********** replication  39  **********
epoch   0 LossPred 1.2267 LossAtt 0.9913 TrainAcc 0.4700 TestAcc 0.4454 0.4600
epoch 100 LossPred 0.9905 LossAtt 0.3519 TrainAcc 0.5000 TestAcc 0.4520 0.5500
epoch 200 LossPred 0.9663 LossAtt 0.3842 TrainAcc 0.6600 TestAcc 0.5348 0.6550
epoch 300 LossPred 0.8851 LossAtt 0.4909 TrainAcc 0.6300 TestAcc 0.6166 0.6300
epoch 400 LossPred 0.2968 LossAtt 0.4907 TrainAcc 0.9500 TestAcc 0.8586 0.9300
epoch 500 LossPred 0.2589 LossAtt 0.4883 TrainAcc 0.9300 TestAcc 0.8641 0.9200
epoch 600 LossPred 0.2570 LossAtt 0.4633 TrainAcc 0.9300 TestAcc 0.8634 0.9150
epoch 700 LossPred 0.3932 LossAtt 0.4685 TrainAcc 0.8600 TestAcc 0.8358 0.8750
epoch 800 LossPred 0.2581 LossAtt 0.4683 TrainAcc 0.9200 TestAcc 0.8574 0.8850
epoch 900 LossPred 0.3400 LossAtt 0.4178 TrainAcc 0.9000 TestAcc 0.8198 0.8650
epoch 1000 LossPred 0.4351 LossAtt 0.4060 TrainAcc 0.8700 TestAcc 0.8091 0.8500
epoch 1100 LossPred 0.3282 LossAtt 0.4303 TrainAcc 0.8800 TestAcc 0.8443 0.8850
epoch 1200 LossPred 0.3045 LossAtt 0.4249 TrainAcc 0.8900 TestAcc 0.8411 0.8850
epoch 1300 LossPred 0.4424 LossAtt 0.4210 TrainAcc 0.8300 TestAcc 0.8228 0.8300
epoch 1400 LossPred 0.6103 LossAtt 0.4091 TrainAcc 0.7700 TestAcc 0.7730 0.7900
epoch 1500 LossPred 0.4334 LossAtt 0.4464 TrainAcc 0.8600 TestAcc 0.8308 0.8700
epoch 1600 LossPred 0.5739 LossAtt 0.4246 TrainAcc 0.8300 TestAcc 0.8186 0.8150
epoch 1700 LossPred 0.5153 LossAtt 0.3986 TrainAcc 0.8200 TestAcc 0.8126 0.8300
epoch 1800 LossPred 0.4256 LossAtt 0.4225 TrainAcc 0.8800 TestAcc 0.8338 0.8550
epoch 1900 LossPred 0.4490 LossAtt 0.4262 TrainAcc 0.8500 TestAcc 0.8263 0.8600
epoch 2000 LossPred 0.3731 LossAtt 0.4002 TrainAcc 0.8700 TestAcc 0.8366 0.8450
epoch 2100 LossPred 0.3631 LossAtt 0.4119 TrainAcc 0.8800 TestAcc 0.8303 0.8650
epoch 2200 LossPred 0.3781 LossAtt 0.4063 TrainAcc 0.8700 TestAcc 0.8288 0.8550
epoch 2300 LossPred 0.3927 LossAtt 0.4255 TrainAcc 0.8800 TestAcc 0.8241 0.8500
epoch 2400 LossPred 0.5861 LossAtt 0.3891 TrainAcc 0.8100 TestAcc 0.7825 0.8050
epoch 2500 LossPred 0.3783 LossAtt 0.3936 TrainAcc 0.8900 TestAcc 0.8268 0.8650
Optimization Finished!
********** replication  40  **********
epoch   0 LossPred 1.1041 LossAtt 1.0189 TrainAcc 0.5900 TestAcc 0.5821 0.5850
epoch 100 LossPred 0.8772 LossAtt 0.3901 TrainAcc 0.6400 TestAcc 0.6249 0.6550
epoch 200 LossPred 0.5869 LossAtt 0.3298 TrainAcc 0.8400 TestAcc 0.7875 0.7900
epoch 300 LossPred 0.6472 LossAtt 0.3212 TrainAcc 0.7700 TestAcc 0.7595 0.7700
epoch 400 LossPred 0.7005 LossAtt 0.2642 TrainAcc 0.7400 TestAcc 0.7187 0.7550
epoch 500 LossPred 0.6393 LossAtt 0.3087 TrainAcc 0.7900 TestAcc 0.7432 0.7800
epoch 600 LossPred 0.6035 LossAtt 0.3019 TrainAcc 0.7900 TestAcc 0.7620 0.7900
epoch 700 LossPred 1.0248 LossAtt 0.2481 TrainAcc 0.6000 TestAcc 0.6126 0.6050
epoch 800 LossPred 0.7969 LossAtt 0.2670 TrainAcc 0.6800 TestAcc 0.6221 0.6800
epoch 900 LossPred 0.6043 LossAtt 0.2423 TrainAcc 0.8000 TestAcc 0.7875 0.8100
epoch 1000 LossPred 0.5931 LossAtt 0.2419 TrainAcc 0.7900 TestAcc 0.8026 0.8350
epoch 1100 LossPred 0.5288 LossAtt 0.2388 TrainAcc 0.8300 TestAcc 0.7963 0.8250
epoch 1200 LossPred 0.5527 LossAtt 0.2395 TrainAcc 0.8200 TestAcc 0.7853 0.8200
epoch 1300 LossPred 0.5999 LossAtt 0.2416 TrainAcc 0.7800 TestAcc 0.8048 0.8000
epoch 1400 LossPred 0.5569 LossAtt 0.2510 TrainAcc 0.8100 TestAcc 0.7753 0.8250
epoch 1500 LossPred 0.5509 LossAtt 0.2419 TrainAcc 0.8400 TestAcc 0.8121 0.8050
epoch 1600 LossPred 0.5527 LossAtt 0.2393 TrainAcc 0.8100 TestAcc 0.7978 0.8400
epoch 1700 LossPred 0.5164 LossAtt 0.2358 TrainAcc 0.8200 TestAcc 0.7963 0.8200
epoch 1800 LossPred 0.6144 LossAtt 0.2545 TrainAcc 0.8000 TestAcc 0.7653 0.7900
epoch 1900 LossPred 0.5164 LossAtt 0.2481 TrainAcc 0.8400 TestAcc 0.8041 0.8400
epoch 2000 LossPred 0.5845 LossAtt 0.2483 TrainAcc 0.8200 TestAcc 0.7540 0.7900
epoch 2100 LossPred 0.5716 LossAtt 0.2528 TrainAcc 0.8100 TestAcc 0.7460 0.7950
epoch 2200 LossPred 0.5286 LossAtt 0.2400 TrainAcc 0.8300 TestAcc 0.8016 0.8350
epoch 2300 LossPred 0.6888 LossAtt 0.2546 TrainAcc 0.7600 TestAcc 0.7050 0.7550
epoch 2400 LossPred 0.5940 LossAtt 0.2571 TrainAcc 0.7900 TestAcc 0.7733 0.8150
epoch 2500 LossPred 0.6204 LossAtt 0.2352 TrainAcc 0.7800 TestAcc 0.7345 0.7900
Optimization Finished!
********** replication  41  **********
epoch   0 LossPred 1.1706 LossAtt 0.9994 TrainAcc 0.5300 TestAcc 0.4895 0.5300
epoch 100 LossPred 0.9695 LossAtt 0.4764 TrainAcc 0.5600 TestAcc 0.5886 0.5600
epoch 200 LossPred 0.9512 LossAtt 0.4441 TrainAcc 0.5600 TestAcc 0.5886 0.5600
epoch 300 LossPred 0.9142 LossAtt 0.4586 TrainAcc 0.6100 TestAcc 0.6159 0.5950
epoch 400 LossPred 0.8897 LossAtt 0.4726 TrainAcc 0.6100 TestAcc 0.6789 0.6250
epoch 500 LossPred 0.6781 LossAtt 0.4610 TrainAcc 0.7500 TestAcc 0.7570 0.7350
epoch 600 LossPred 0.4668 LossAtt 0.4538 TrainAcc 0.8600 TestAcc 0.8481 0.8400
epoch 700 LossPred 0.3749 LossAtt 0.4437 TrainAcc 0.8900 TestAcc 0.8594 0.8500
epoch 800 LossPred 0.3353 LossAtt 0.4211 TrainAcc 0.8900 TestAcc 0.8774 0.8800
epoch 900 LossPred 0.5439 LossAtt 0.4354 TrainAcc 0.8000 TestAcc 0.8338 0.8250
epoch 1000 LossPred 0.3997 LossAtt 0.4212 TrainAcc 0.8400 TestAcc 0.8699 0.8750
epoch 1100 LossPred 0.3452 LossAtt 0.4444 TrainAcc 0.9000 TestAcc 0.8659 0.8850
epoch 1200 LossPred 0.4837 LossAtt 0.4133 TrainAcc 0.8500 TestAcc 0.8256 0.8200
epoch 1300 LossPred 0.3878 LossAtt 0.4201 TrainAcc 0.8700 TestAcc 0.8413 0.8300
epoch 1400 LossPred 0.3140 LossAtt 0.4065 TrainAcc 0.8900 TestAcc 0.8729 0.8900
epoch 1500 LossPred 0.5352 LossAtt 0.4069 TrainAcc 0.7900 TestAcc 0.8176 0.8150
epoch 1600 LossPred 0.3170 LossAtt 0.4068 TrainAcc 0.8900 TestAcc 0.8676 0.8950
epoch 1700 LossPred 0.3400 LossAtt 0.4185 TrainAcc 0.8800 TestAcc 0.8686 0.8800
epoch 1800 LossPred 0.3267 LossAtt 0.4037 TrainAcc 0.9000 TestAcc 0.8586 0.8800
epoch 1900 LossPred 0.4214 LossAtt 0.4034 TrainAcc 0.8300 TestAcc 0.8556 0.8550
epoch 2000 LossPred 0.3355 LossAtt 0.3967 TrainAcc 0.8800 TestAcc 0.8581 0.8550
epoch 2100 LossPred 0.3512 LossAtt 0.3913 TrainAcc 0.9000 TestAcc 0.8551 0.8800
epoch 2200 LossPred 0.3485 LossAtt 0.3982 TrainAcc 0.8800 TestAcc 0.8536 0.8600
epoch 2300 LossPred 0.3543 LossAtt 0.4081 TrainAcc 0.8900 TestAcc 0.8493 0.8700
epoch 2400 LossPred 0.4599 LossAtt 0.3814 TrainAcc 0.8300 TestAcc 0.8338 0.8350
epoch 2500 LossPred 0.3121 LossAtt 0.3875 TrainAcc 0.8800 TestAcc 0.8649 0.8700
Optimization Finished!
********** replication  42  **********
epoch   0 LossPred 1.0266 LossAtt 0.9653 TrainAcc 0.4200 TestAcc 0.4212 0.4250
epoch 100 LossPred 0.9686 LossAtt 0.4613 TrainAcc 0.5800 TestAcc 0.5788 0.5750
epoch 200 LossPred 0.8953 LossAtt 0.4297 TrainAcc 0.6400 TestAcc 0.5733 0.6350
epoch 300 LossPred 0.6350 LossAtt 0.5416 TrainAcc 0.7400 TestAcc 0.7455 0.7550
epoch 400 LossPred 0.5558 LossAtt 0.5569 TrainAcc 0.7700 TestAcc 0.7513 0.7850
epoch 500 LossPred 0.5877 LossAtt 0.5188 TrainAcc 0.8000 TestAcc 0.7835 0.8050
epoch 600 LossPred 0.4178 LossAtt 0.4842 TrainAcc 0.8800 TestAcc 0.8386 0.8400
epoch 700 LossPred 0.2742 LossAtt 0.4671 TrainAcc 0.9300 TestAcc 0.8679 0.9000
epoch 800 LossPred 0.2861 LossAtt 0.4441 TrainAcc 0.9100 TestAcc 0.8739 0.9000
epoch 900 LossPred 0.2422 LossAtt 0.4735 TrainAcc 0.9300 TestAcc 0.8764 0.9100
epoch 1000 LossPred 0.2265 LossAtt 0.4481 TrainAcc 0.9400 TestAcc 0.8884 0.9300
epoch 1100 LossPred 0.2666 LossAtt 0.4543 TrainAcc 0.9300 TestAcc 0.8591 0.9200
epoch 1200 LossPred 0.3319 LossAtt 0.4472 TrainAcc 0.8900 TestAcc 0.8641 0.8750
epoch 1300 LossPred 0.2398 LossAtt 0.4374 TrainAcc 0.9300 TestAcc 0.8826 0.9200
epoch 1400 LossPred 0.2257 LossAtt 0.4432 TrainAcc 0.9400 TestAcc 0.8894 0.9300
epoch 1500 LossPred 0.2437 LossAtt 0.4546 TrainAcc 0.9300 TestAcc 0.8904 0.9050
epoch 1600 LossPred 0.2996 LossAtt 0.4832 TrainAcc 0.9200 TestAcc 0.8566 0.9050
epoch 1700 LossPred 0.3617 LossAtt 0.4488 TrainAcc 0.8700 TestAcc 0.8468 0.8650
epoch 1800 LossPred 0.2833 LossAtt 0.4621 TrainAcc 0.8900 TestAcc 0.8686 0.8950
epoch 1900 LossPred 0.5425 LossAtt 0.4679 TrainAcc 0.8000 TestAcc 0.7553 0.8100
epoch 2000 LossPred 0.2144 LossAtt 0.4796 TrainAcc 0.9100 TestAcc 0.8826 0.9200
epoch 2100 LossPred 0.2186 LossAtt 0.4606 TrainAcc 0.9200 TestAcc 0.8959 0.9300
epoch 2200 LossPred 0.4260 LossAtt 0.4867 TrainAcc 0.8700 TestAcc 0.8281 0.8350
epoch 2300 LossPred 0.2449 LossAtt 0.4767 TrainAcc 0.9100 TestAcc 0.8866 0.9200
epoch 2400 LossPred 0.1307 LossAtt 0.4839 TrainAcc 0.9600 TestAcc 0.8829 0.9300
epoch 2500 LossPred 0.1308 LossAtt 0.4664 TrainAcc 0.9700 TestAcc 0.8886 0.9500
Optimization Finished!
********** replication  43  **********
epoch   0 LossPred 1.0682 LossAtt 1.0324 TrainAcc 0.5300 TestAcc 0.5295 0.5100
epoch 100 LossPred 0.9144 LossAtt 0.5237 TrainAcc 0.5900 TestAcc 0.5090 0.5900
epoch 200 LossPred 0.7885 LossAtt 0.5246 TrainAcc 0.7300 TestAcc 0.5658 0.7150
epoch 300 LossPred 0.3761 LossAtt 0.5938 TrainAcc 0.8700 TestAcc 0.8206 0.8650
epoch 400 LossPred 0.2395 LossAtt 0.5907 TrainAcc 0.9200 TestAcc 0.8358 0.9200
epoch 500 LossPred 0.2171 LossAtt 0.5007 TrainAcc 0.9400 TestAcc 0.8521 0.9250
epoch 600 LossPred 0.2089 LossAtt 0.4614 TrainAcc 0.9500 TestAcc 0.8536 0.9450
epoch 700 LossPred 0.2035 LossAtt 0.4813 TrainAcc 0.9400 TestAcc 0.8549 0.9400
epoch 800 LossPred 0.1963 LossAtt 0.4879 TrainAcc 0.9500 TestAcc 0.8559 0.9400
epoch 900 LossPred 0.2789 LossAtt 0.4326 TrainAcc 0.9000 TestAcc 0.8093 0.9100
epoch 1000 LossPred 0.2120 LossAtt 0.4432 TrainAcc 0.9400 TestAcc 0.8724 0.9300
epoch 1100 LossPred 0.2328 LossAtt 0.4623 TrainAcc 0.9100 TestAcc 0.8701 0.9150
epoch 1200 LossPred 0.2253 LossAtt 0.4505 TrainAcc 0.9300 TestAcc 0.8729 0.9250
epoch 1300 LossPred 0.2308 LossAtt 0.4065 TrainAcc 0.9200 TestAcc 0.8308 0.9200
epoch 1400 LossPred 0.1928 LossAtt 0.4164 TrainAcc 0.9600 TestAcc 0.8581 0.9600
epoch 1500 LossPred 0.1981 LossAtt 0.4205 TrainAcc 0.9500 TestAcc 0.8594 0.9450
epoch 1600 LossPred 0.2254 LossAtt 0.3945 TrainAcc 0.9200 TestAcc 0.8721 0.9100
epoch 1700 LossPred 0.1984 LossAtt 0.4058 TrainAcc 0.9400 TestAcc 0.8614 0.9500
epoch 1800 LossPred 0.2220 LossAtt 0.3812 TrainAcc 0.9300 TestAcc 0.8784 0.9200
epoch 1900 LossPred 0.2196 LossAtt 0.3912 TrainAcc 0.9300 TestAcc 0.8801 0.9250
epoch 2000 LossPred 0.2194 LossAtt 0.3755 TrainAcc 0.9300 TestAcc 0.8831 0.9300
epoch 2100 LossPred 0.2258 LossAtt 0.3774 TrainAcc 0.9200 TestAcc 0.8699 0.9200
epoch 2200 LossPred 0.2041 LossAtt 0.3991 TrainAcc 0.9400 TestAcc 0.8719 0.9350
epoch 2300 LossPred 0.2159 LossAtt 0.4021 TrainAcc 0.9300 TestAcc 0.8814 0.9200
epoch 2400 LossPred 0.2066 LossAtt 0.3655 TrainAcc 0.9400 TestAcc 0.8413 0.9300
epoch 2500 LossPred 0.1898 LossAtt 0.3795 TrainAcc 0.9600 TestAcc 0.8734 0.9500
Optimization Finished!
********** replication  44  **********
epoch   0 LossPred 1.1438 LossAtt 1.0193 TrainAcc 0.5800 TestAcc 0.5440 0.5800
epoch 100 LossPred 0.9788 LossAtt 0.4611 TrainAcc 0.5900 TestAcc 0.5611 0.5850
epoch 200 LossPred 0.9266 LossAtt 0.4430 TrainAcc 0.6300 TestAcc 0.5671 0.6200
epoch 300 LossPred 0.8793 LossAtt 0.4694 TrainAcc 0.6400 TestAcc 0.5838 0.6450
epoch 400 LossPred 0.8551 LossAtt 0.4900 TrainAcc 0.6700 TestAcc 0.5921 0.6500
epoch 500 LossPred 0.8241 LossAtt 0.5289 TrainAcc 0.7100 TestAcc 0.5971 0.6950
epoch 600 LossPred 0.8040 LossAtt 0.5307 TrainAcc 0.7000 TestAcc 0.5821 0.7000
epoch 700 LossPred 0.7711 LossAtt 0.5402 TrainAcc 0.7200 TestAcc 0.5701 0.7200
epoch 800 LossPred 0.7341 LossAtt 0.5938 TrainAcc 0.7000 TestAcc 0.5586 0.7250
epoch 900 LossPred 0.6903 LossAtt 0.5900 TrainAcc 0.7600 TestAcc 0.5528 0.7300
epoch 1000 LossPred 0.6892 LossAtt 0.5758 TrainAcc 0.7600 TestAcc 0.5548 0.7400
epoch 1100 LossPred 0.6609 LossAtt 0.5855 TrainAcc 0.7800 TestAcc 0.5480 0.7450
epoch 1200 LossPred 0.6754 LossAtt 0.5701 TrainAcc 0.7800 TestAcc 0.5578 0.7300
epoch 1300 LossPred 0.6792 LossAtt 0.5879 TrainAcc 0.7600 TestAcc 0.5543 0.7200
epoch 1400 LossPred 0.6533 LossAtt 0.5752 TrainAcc 0.7800 TestAcc 0.5548 0.7350
epoch 1500 LossPred 0.6579 LossAtt 0.5704 TrainAcc 0.7600 TestAcc 0.5588 0.7200
epoch 1600 LossPred 0.6447 LossAtt 0.5722 TrainAcc 0.7800 TestAcc 0.5606 0.7150
epoch 1700 LossPred 0.6627 LossAtt 0.5416 TrainAcc 0.7700 TestAcc 0.5586 0.7100
epoch 1800 LossPred 0.6657 LossAtt 0.5552 TrainAcc 0.7700 TestAcc 0.5628 0.7150
epoch 1900 LossPred 0.6848 LossAtt 0.5377 TrainAcc 0.7500 TestAcc 0.5593 0.7200
epoch 2000 LossPred 0.6991 LossAtt 0.5416 TrainAcc 0.7400 TestAcc 0.5593 0.7250
epoch 2100 LossPred 0.6626 LossAtt 0.5458 TrainAcc 0.7400 TestAcc 0.5613 0.7400
epoch 2200 LossPred 0.6596 LossAtt 0.5142 TrainAcc 0.7600 TestAcc 0.5628 0.7250
epoch 2300 LossPred 0.6689 LossAtt 0.5206 TrainAcc 0.7700 TestAcc 0.5603 0.7200
epoch 2400 LossPred 0.6372 LossAtt 0.4911 TrainAcc 0.7700 TestAcc 0.5596 0.7400
epoch 2500 LossPred 0.6329 LossAtt 0.4841 TrainAcc 0.7900 TestAcc 0.5588 0.7350
Optimization Finished!
********** replication  45  **********
epoch   0 LossPred 1.1799 LossAtt 0.9956 TrainAcc 0.5000 TestAcc 0.5250 0.4900
epoch 100 LossPred 0.9433 LossAtt 0.3868 TrainAcc 0.6000 TestAcc 0.5898 0.6000
epoch 200 LossPred 0.9150 LossAtt 0.3646 TrainAcc 0.6000 TestAcc 0.5898 0.6000
epoch 300 LossPred 0.8910 LossAtt 0.3202 TrainAcc 0.6400 TestAcc 0.6274 0.5700
epoch 400 LossPred 0.5284 LossAtt 0.4122 TrainAcc 0.8000 TestAcc 0.7920 0.8100
epoch 500 LossPred 0.3714 LossAtt 0.3846 TrainAcc 0.8900 TestAcc 0.8539 0.8450
epoch 600 LossPred 0.4615 LossAtt 0.3716 TrainAcc 0.8200 TestAcc 0.8026 0.8200
epoch 700 LossPred 0.3816 LossAtt 0.3258 TrainAcc 0.8700 TestAcc 0.8238 0.8650
epoch 800 LossPred 0.4358 LossAtt 0.3440 TrainAcc 0.8400 TestAcc 0.8126 0.8500
epoch 900 LossPred 0.3687 LossAtt 0.3443 TrainAcc 0.8800 TestAcc 0.8421 0.8650
epoch 1000 LossPred 0.6028 LossAtt 0.3487 TrainAcc 0.7800 TestAcc 0.8023 0.7900
epoch 1100 LossPred 0.5711 LossAtt 0.3068 TrainAcc 0.8200 TestAcc 0.7575 0.8150
epoch 1200 LossPred 0.3694 LossAtt 0.3456 TrainAcc 0.8700 TestAcc 0.8411 0.8750
epoch 1300 LossPred 0.3884 LossAtt 0.3383 TrainAcc 0.8700 TestAcc 0.8198 0.8500
epoch 1400 LossPred 0.4303 LossAtt 0.3448 TrainAcc 0.8000 TestAcc 0.8436 0.8350
epoch 1500 LossPred 0.5990 LossAtt 0.3363 TrainAcc 0.8100 TestAcc 0.7422 0.8150
epoch 1600 LossPred 0.4007 LossAtt 0.3778 TrainAcc 0.8500 TestAcc 0.8351 0.8650
epoch 1700 LossPred 0.4001 LossAtt 0.3953 TrainAcc 0.8500 TestAcc 0.8328 0.8500
epoch 1800 LossPred 0.5813 LossAtt 0.3822 TrainAcc 0.8000 TestAcc 0.7287 0.8000
epoch 1900 LossPred 0.4740 LossAtt 0.3753 TrainAcc 0.8200 TestAcc 0.7670 0.8250
epoch 2000 LossPred 0.4289 LossAtt 0.3972 TrainAcc 0.8300 TestAcc 0.8438 0.8150
epoch 2100 LossPred 0.4228 LossAtt 0.3915 TrainAcc 0.8400 TestAcc 0.7825 0.8500
epoch 2200 LossPred 0.2782 LossAtt 0.4049 TrainAcc 0.9000 TestAcc 0.8554 0.8850
epoch 2300 LossPred 0.3427 LossAtt 0.4221 TrainAcc 0.8700 TestAcc 0.8661 0.8700
epoch 2400 LossPred 0.2699 LossAtt 0.4246 TrainAcc 0.9000 TestAcc 0.8496 0.8800
epoch 2500 LossPred 0.3459 LossAtt 0.4555 TrainAcc 0.8500 TestAcc 0.8614 0.8400
Optimization Finished!
********** replication  46  **********
epoch   0 LossPred 1.1341 LossAtt 1.0355 TrainAcc 0.4100 TestAcc 0.4907 0.4000
epoch 100 LossPred 0.8969 LossAtt 0.3630 TrainAcc 0.6800 TestAcc 0.5791 0.6800
epoch 200 LossPred 0.8567 LossAtt 0.3063 TrainAcc 0.6800 TestAcc 0.5791 0.6800
epoch 300 LossPred 0.8468 LossAtt 0.2405 TrainAcc 0.6800 TestAcc 0.5791 0.6800
epoch 400 LossPred 0.8475 LossAtt 0.2095 TrainAcc 0.6800 TestAcc 0.5791 0.6750
epoch 500 LossPred 0.8256 LossAtt 0.2147 TrainAcc 0.6800 TestAcc 0.5896 0.6750
epoch 600 LossPred 0.3428 LossAtt 0.2519 TrainAcc 0.9000 TestAcc 0.8128 0.8950
epoch 700 LossPred 0.2995 LossAtt 0.2246 TrainAcc 0.9100 TestAcc 0.7960 0.8800
epoch 800 LossPred 0.3103 LossAtt 0.2241 TrainAcc 0.8900 TestAcc 0.8031 0.8900
epoch 900 LossPred 0.2892 LossAtt 0.2164 TrainAcc 0.9000 TestAcc 0.8001 0.8850
epoch 1000 LossPred 0.2983 LossAtt 0.2169 TrainAcc 0.9000 TestAcc 0.8021 0.8950
epoch 1100 LossPred 0.2946 LossAtt 0.2267 TrainAcc 0.9000 TestAcc 0.8053 0.8850
epoch 1200 LossPred 0.2787 LossAtt 0.2224 TrainAcc 0.8900 TestAcc 0.7990 0.8900
epoch 1300 LossPred 0.2703 LossAtt 0.2097 TrainAcc 0.9000 TestAcc 0.8066 0.8900
epoch 1400 LossPred 0.2827 LossAtt 0.2123 TrainAcc 0.8900 TestAcc 0.8001 0.8850
epoch 1500 LossPred 0.2629 LossAtt 0.2054 TrainAcc 0.9100 TestAcc 0.8068 0.8950
epoch 1600 LossPred 0.2693 LossAtt 0.2038 TrainAcc 0.9000 TestAcc 0.8048 0.8850
epoch 1700 LossPred 0.2271 LossAtt 0.2083 TrainAcc 0.9200 TestAcc 0.8026 0.9050
epoch 1800 LossPred 0.2329 LossAtt 0.2158 TrainAcc 0.9200 TestAcc 0.8006 0.9100
epoch 1900 LossPred 0.2521 LossAtt 0.2128 TrainAcc 0.9200 TestAcc 0.7995 0.8900
epoch 2000 LossPred 0.2127 LossAtt 0.2089 TrainAcc 0.9200 TestAcc 0.8093 0.9050
epoch 2100 LossPred 0.2062 LossAtt 0.2083 TrainAcc 0.9300 TestAcc 0.8138 0.9000
epoch 2200 LossPred 0.3786 LossAtt 0.2048 TrainAcc 0.8700 TestAcc 0.7725 0.8750
epoch 2300 LossPred 0.2346 LossAtt 0.2001 TrainAcc 0.9200 TestAcc 0.8168 0.8950
epoch 2400 LossPred 0.2440 LossAtt 0.2058 TrainAcc 0.9100 TestAcc 0.8073 0.8900
epoch 2500 LossPred 0.2292 LossAtt 0.2149 TrainAcc 0.9200 TestAcc 0.8283 0.9150
Optimization Finished!
********** replication  47  **********
epoch   0 LossPred 1.2017 LossAtt 1.0087 TrainAcc 0.3800 TestAcc 0.4530 0.3750
epoch 100 LossPred 0.9425 LossAtt 0.2964 TrainAcc 0.6000 TestAcc 0.5058 0.6050
epoch 200 LossPred 0.9301 LossAtt 0.2218 TrainAcc 0.6200 TestAcc 0.5148 0.6100
epoch 300 LossPred 0.9277 LossAtt 0.2623 TrainAcc 0.6000 TestAcc 0.5543 0.6100
epoch 400 LossPred 0.9246 LossAtt 0.2673 TrainAcc 0.6300 TestAcc 0.5691 0.6300
epoch 500 LossPred 0.9225 LossAtt 0.2603 TrainAcc 0.6300 TestAcc 0.5691 0.6400
epoch 600 LossPred 0.9221 LossAtt 0.2544 TrainAcc 0.6500 TestAcc 0.5485 0.6400
epoch 700 LossPred 0.9217 LossAtt 0.2633 TrainAcc 0.6200 TestAcc 0.5338 0.6350
epoch 800 LossPred 0.9181 LossAtt 0.2799 TrainAcc 0.6500 TestAcc 0.5485 0.6550
epoch 900 LossPred 0.9096 LossAtt 0.2811 TrainAcc 0.6400 TestAcc 0.5863 0.6400
epoch 1000 LossPred 0.7634 LossAtt 0.3534 TrainAcc 0.7300 TestAcc 0.6862 0.7450
epoch 1100 LossPred 0.8791 LossAtt 0.2821 TrainAcc 0.6400 TestAcc 0.5868 0.6500
epoch 1200 LossPred 0.8873 LossAtt 0.2656 TrainAcc 0.6300 TestAcc 0.5851 0.6350
epoch 1300 LossPred 0.8695 LossAtt 0.2503 TrainAcc 0.6600 TestAcc 0.5956 0.6600
epoch 1400 LossPred 0.7403 LossAtt 0.2515 TrainAcc 0.7200 TestAcc 0.6296 0.7200
epoch 1500 LossPred 0.6911 LossAtt 0.2691 TrainAcc 0.7300 TestAcc 0.6659 0.7300
epoch 1600 LossPred 0.6532 LossAtt 0.2491 TrainAcc 0.7400 TestAcc 0.6844 0.7300
epoch 1700 LossPred 0.6480 LossAtt 0.2436 TrainAcc 0.7400 TestAcc 0.6917 0.7400
epoch 1800 LossPred 0.7709 LossAtt 0.2268 TrainAcc 0.6600 TestAcc 0.6439 0.6500
epoch 1900 LossPred 0.7223 LossAtt 0.2279 TrainAcc 0.7200 TestAcc 0.6276 0.7150
epoch 2000 LossPred 0.7181 LossAtt 0.2213 TrainAcc 0.7200 TestAcc 0.6281 0.7150
epoch 2100 LossPred 0.6527 LossAtt 0.2365 TrainAcc 0.7300 TestAcc 0.6789 0.7650
epoch 2200 LossPred 0.4655 LossAtt 0.2542 TrainAcc 0.8600 TestAcc 0.7680 0.8400
epoch 2300 LossPred 0.4393 LossAtt 0.2356 TrainAcc 0.8700 TestAcc 0.7523 0.8550
epoch 2400 LossPred 0.4674 LossAtt 0.2459 TrainAcc 0.8700 TestAcc 0.7515 0.8900
epoch 2500 LossPred 0.4651 LossAtt 0.2459 TrainAcc 0.8700 TestAcc 0.7740 0.8750
Optimization Finished!
********** replication  48  **********
epoch   0 LossPred 1.1474 LossAtt 1.0096 TrainAcc 0.4800 TestAcc 0.5473 0.4750
epoch 100 LossPred 0.9630 LossAtt 0.4949 TrainAcc 0.5900 TestAcc 0.5726 0.5850
epoch 200 LossPred 0.9427 LossAtt 0.5209 TrainAcc 0.6100 TestAcc 0.5746 0.6150
epoch 300 LossPred 0.9147 LossAtt 0.4473 TrainAcc 0.6500 TestAcc 0.5953 0.6400
epoch 400 LossPred 0.8927 LossAtt 0.4125 TrainAcc 0.6500 TestAcc 0.5926 0.6400
epoch 500 LossPred 0.8672 LossAtt 0.4313 TrainAcc 0.6700 TestAcc 0.5816 0.6300
epoch 600 LossPred 0.8438 LossAtt 0.4192 TrainAcc 0.7000 TestAcc 0.5833 0.6550
epoch 700 LossPred 0.8318 LossAtt 0.3728 TrainAcc 0.7100 TestAcc 0.5783 0.6550
epoch 800 LossPred 0.8236 LossAtt 0.4162 TrainAcc 0.7100 TestAcc 0.5888 0.7050
epoch 900 LossPred 0.8210 LossAtt 0.4386 TrainAcc 0.7200 TestAcc 0.5908 0.7200
epoch 1000 LossPred 0.8117 LossAtt 0.4363 TrainAcc 0.7100 TestAcc 0.5911 0.7100
epoch 1100 LossPred 0.8097 LossAtt 0.4072 TrainAcc 0.7100 TestAcc 0.5928 0.7100
epoch 1200 LossPred 0.8226 LossAtt 0.4083 TrainAcc 0.7100 TestAcc 0.5931 0.7000
epoch 1300 LossPred 0.8091 LossAtt 0.4083 TrainAcc 0.7100 TestAcc 0.5946 0.7050
epoch 1400 LossPred 0.8178 LossAtt 0.3999 TrainAcc 0.7100 TestAcc 0.5956 0.6900
epoch 1500 LossPred 0.8158 LossAtt 0.4054 TrainAcc 0.7000 TestAcc 0.5958 0.6900
epoch 1600 LossPred 0.8177 LossAtt 0.3863 TrainAcc 0.7100 TestAcc 0.5941 0.6950
epoch 1700 LossPred 0.8351 LossAtt 0.4012 TrainAcc 0.7000 TestAcc 0.5908 0.6950
epoch 1800 LossPred 0.8079 LossAtt 0.3769 TrainAcc 0.7200 TestAcc 0.5958 0.7100
epoch 1900 LossPred 0.8302 LossAtt 0.4003 TrainAcc 0.7000 TestAcc 0.5931 0.7000
epoch 2000 LossPred 0.8232 LossAtt 0.3931 TrainAcc 0.7000 TestAcc 0.5953 0.6950
epoch 2100 LossPred 0.8205 LossAtt 0.3715 TrainAcc 0.7000 TestAcc 0.5908 0.7050
epoch 2200 LossPred 0.8164 LossAtt 0.3827 TrainAcc 0.7100 TestAcc 0.5898 0.7050
epoch 2300 LossPred 0.8174 LossAtt 0.3820 TrainAcc 0.7200 TestAcc 0.5851 0.7050
epoch 2400 LossPred 0.8064 LossAtt 0.3691 TrainAcc 0.6900 TestAcc 0.5861 0.7050
epoch 2500 LossPred 0.8063 LossAtt 0.3702 TrainAcc 0.6800 TestAcc 0.5836 0.7200
Optimization Finished!
********** replication  49  **********
epoch   0 LossPred 1.1841 LossAtt 1.0126 TrainAcc 0.3800 TestAcc 0.4612 0.3750
epoch 100 LossPred 0.8703 LossAtt 0.4124 TrainAcc 0.6900 TestAcc 0.5868 0.6900
epoch 200 LossPred 0.8497 LossAtt 0.2506 TrainAcc 0.6900 TestAcc 0.5868 0.6900
epoch 300 LossPred 0.8454 LossAtt 0.1676 TrainAcc 0.6900 TestAcc 0.5868 0.6900
epoch 400 LossPred 0.8406 LossAtt 0.1698 TrainAcc 0.6900 TestAcc 0.5868 0.6900
epoch 500 LossPred 0.8377 LossAtt 0.1814 TrainAcc 0.6900 TestAcc 0.5868 0.6900
epoch 600 LossPred 0.8234 LossAtt 0.2365 TrainAcc 0.6900 TestAcc 0.5868 0.6800
epoch 700 LossPred 1.1819 LossAtt 0.3945 TrainAcc 0.5200 TestAcc 0.5330 0.5150
epoch 800 LossPred 0.6672 LossAtt 0.3107 TrainAcc 0.7400 TestAcc 0.7638 0.7300
epoch 900 LossPred 0.5357 LossAtt 0.2915 TrainAcc 0.8200 TestAcc 0.7930 0.7750
epoch 1000 LossPred 0.7134 LossAtt 0.2752 TrainAcc 0.7100 TestAcc 0.6812 0.7200
epoch 1100 LossPred 0.5810 LossAtt 0.2717 TrainAcc 0.8100 TestAcc 0.7305 0.8050
epoch 1200 LossPred 0.5696 LossAtt 0.2647 TrainAcc 0.8000 TestAcc 0.7295 0.7950
epoch 1300 LossPred 0.5781 LossAtt 0.2424 TrainAcc 0.7900 TestAcc 0.7290 0.7950
epoch 1400 LossPred 0.5850 LossAtt 0.2503 TrainAcc 0.8000 TestAcc 0.7435 0.8100
epoch 1500 LossPred 0.5718 LossAtt 0.2481 TrainAcc 0.8000 TestAcc 0.7107 0.8100
epoch 1600 LossPred 0.5709 LossAtt 0.2431 TrainAcc 0.8000 TestAcc 0.7325 0.8200
epoch 1700 LossPred 0.5753 LossAtt 0.2484 TrainAcc 0.8100 TestAcc 0.7177 0.8100
epoch 1800 LossPred 0.5781 LossAtt 0.2382 TrainAcc 0.8200 TestAcc 0.6997 0.8150
epoch 1900 LossPred 0.5754 LossAtt 0.2515 TrainAcc 0.7800 TestAcc 0.7277 0.8150
epoch 2000 LossPred 0.5672 LossAtt 0.2415 TrainAcc 0.8100 TestAcc 0.7172 0.8050
epoch 2100 LossPred 0.5741 LossAtt 0.2282 TrainAcc 0.8100 TestAcc 0.6994 0.8000
epoch 2200 LossPred 0.5667 LossAtt 0.2559 TrainAcc 0.7800 TestAcc 0.6674 0.7850
epoch 2300 LossPred 0.5677 LossAtt 0.2410 TrainAcc 0.8200 TestAcc 0.6997 0.8250
epoch 2400 LossPred 0.5721 LossAtt 0.2465 TrainAcc 0.8000 TestAcc 0.7132 0.8200
epoch 2500 LossPred 0.5776 LossAtt 0.2519 TrainAcc 0.7900 TestAcc 0.7125 0.8200
Optimization Finished!
********** replication  50  **********
epoch   0 LossPred 1.0088 LossAtt 1.0006 TrainAcc 0.5400 TestAcc 0.5495 0.5450
epoch 100 LossPred 0.9355 LossAtt 0.3873 TrainAcc 0.6100 TestAcc 0.5823 0.6100
epoch 200 LossPred 0.9117 LossAtt 0.3975 TrainAcc 0.6100 TestAcc 0.5823 0.6200
epoch 300 LossPred 0.8768 LossAtt 0.4582 TrainAcc 0.6600 TestAcc 0.5908 0.6550
epoch 400 LossPred 0.6501 LossAtt 0.4530 TrainAcc 0.7800 TestAcc 0.7472 0.7950
epoch 500 LossPred 0.5085 LossAtt 0.4536 TrainAcc 0.8500 TestAcc 0.8368 0.8350
epoch 600 LossPred 0.4512 LossAtt 0.4305 TrainAcc 0.8600 TestAcc 0.8281 0.8200
epoch 700 LossPred 0.4448 LossAtt 0.4263 TrainAcc 0.8600 TestAcc 0.8281 0.8200
epoch 800 LossPred 0.4742 LossAtt 0.4046 TrainAcc 0.8400 TestAcc 0.8051 0.8150
epoch 900 LossPred 0.8531 LossAtt 0.4015 TrainAcc 0.6700 TestAcc 0.6707 0.6850
epoch 1000 LossPred 0.8625 LossAtt 0.3599 TrainAcc 0.6500 TestAcc 0.6409 0.6550
epoch 1100 LossPred 0.9513 LossAtt 0.3676 TrainAcc 0.6300 TestAcc 0.6051 0.6300
epoch 1200 LossPred 0.9079 LossAtt 0.3850 TrainAcc 0.6400 TestAcc 0.6239 0.6500
epoch 1300 LossPred 0.8586 LossAtt 0.3987 TrainAcc 0.6600 TestAcc 0.6384 0.6650
epoch 1400 LossPred 0.8564 LossAtt 0.3935 TrainAcc 0.6600 TestAcc 0.6416 0.6750
epoch 1500 LossPred 0.8400 LossAtt 0.4028 TrainAcc 0.6700 TestAcc 0.6507 0.6950
epoch 1600 LossPred 0.7927 LossAtt 0.4039 TrainAcc 0.6900 TestAcc 0.6634 0.6900
epoch 1700 LossPred 0.7537 LossAtt 0.4128 TrainAcc 0.7200 TestAcc 0.6957 0.7450
epoch 1800 LossPred 0.7928 LossAtt 0.4249 TrainAcc 0.7100 TestAcc 0.6767 0.7150
epoch 1900 LossPred 0.9101 LossAtt 0.3932 TrainAcc 0.6200 TestAcc 0.6089 0.6350
epoch 2000 LossPred 0.8839 LossAtt 0.3767 TrainAcc 0.6400 TestAcc 0.6089 0.6500
epoch 2100 LossPred 0.8400 LossAtt 0.4010 TrainAcc 0.6500 TestAcc 0.6296 0.6800
epoch 2200 LossPred 0.7993 LossAtt 0.3975 TrainAcc 0.6800 TestAcc 0.6371 0.6800
epoch 2300 LossPred 0.7323 LossAtt 0.3967 TrainAcc 0.7300 TestAcc 0.6687 0.7200
epoch 2400 LossPred 0.7283 LossAtt 0.4017 TrainAcc 0.7300 TestAcc 0.6702 0.7200
epoch 2500 LossPred 0.7017 LossAtt 0.4040 TrainAcc 0.7200 TestAcc 0.6919 0.7450
Optimization Finished!
********** replication  51  **********
epoch   0 LossPred 1.1366 LossAtt 1.0096 TrainAcc 0.4600 TestAcc 0.4520 0.4750
epoch 100 LossPred 0.9732 LossAtt 0.5376 TrainAcc 0.5200 TestAcc 0.4655 0.5350
epoch 200 LossPred 0.9422 LossAtt 0.4508 TrainAcc 0.6100 TestAcc 0.5756 0.6050
epoch 300 LossPred 0.9291 LossAtt 0.3652 TrainAcc 0.5800 TestAcc 0.5485 0.5850
epoch 400 LossPred 0.9239 LossAtt 0.3265 TrainAcc 0.6000 TestAcc 0.5768 0.5950
epoch 500 LossPred 0.9203 LossAtt 0.3008 TrainAcc 0.6000 TestAcc 0.5768 0.5950
epoch 600 LossPred 0.9180 LossAtt 0.2958 TrainAcc 0.6000 TestAcc 0.5768 0.6000
epoch 700 LossPred 0.9136 LossAtt 0.3111 TrainAcc 0.6100 TestAcc 0.5878 0.6050
epoch 800 LossPred 0.9068 LossAtt 0.3092 TrainAcc 0.6200 TestAcc 0.5941 0.5950
epoch 900 LossPred 0.9091 LossAtt 0.3945 TrainAcc 0.6100 TestAcc 0.5891 0.6150
epoch 1000 LossPred 0.8696 LossAtt 0.4295 TrainAcc 0.6600 TestAcc 0.5931 0.6450
epoch 1100 LossPred 0.8250 LossAtt 0.5629 TrainAcc 0.6800 TestAcc 0.5566 0.6550
epoch 1200 LossPred 0.7499 LossAtt 0.5521 TrainAcc 0.7100 TestAcc 0.5586 0.6750
epoch 1300 LossPred 0.6751 LossAtt 0.6030 TrainAcc 0.7500 TestAcc 0.5470 0.7450
epoch 1400 LossPred 0.6316 LossAtt 0.5837 TrainAcc 0.7700 TestAcc 0.5516 0.7400
epoch 1500 LossPred 0.6140 LossAtt 0.5684 TrainAcc 0.7900 TestAcc 0.5536 0.7600
epoch 1600 LossPred 0.5838 LossAtt 0.5800 TrainAcc 0.8100 TestAcc 0.5618 0.7700
epoch 1700 LossPred 0.5908 LossAtt 0.5949 TrainAcc 0.7800 TestAcc 0.5643 0.7600
epoch 1800 LossPred 0.5613 LossAtt 0.5987 TrainAcc 0.8000 TestAcc 0.5666 0.7550
epoch 1900 LossPred 0.5395 LossAtt 0.5979 TrainAcc 0.8200 TestAcc 0.5646 0.7800
epoch 2000 LossPred 0.5538 LossAtt 0.5766 TrainAcc 0.7900 TestAcc 0.5728 0.7900
epoch 2100 LossPred 0.5051 LossAtt 0.5786 TrainAcc 0.8700 TestAcc 0.5676 0.7600
epoch 2200 LossPred 0.5222 LossAtt 0.5695 TrainAcc 0.8100 TestAcc 0.5731 0.7550
epoch 2300 LossPred 0.5083 LossAtt 0.5738 TrainAcc 0.8500 TestAcc 0.5741 0.7400
epoch 2400 LossPred 0.5207 LossAtt 0.5742 TrainAcc 0.8300 TestAcc 0.5718 0.7550
epoch 2500 LossPred 0.5419 LossAtt 0.5668 TrainAcc 0.8300 TestAcc 0.5718 0.7350
Optimization Finished!
********** replication  52  **********
epoch   0 LossPred 0.9622 LossAtt 1.0232 TrainAcc 0.6100 TestAcc 0.5616 0.5800
epoch 100 LossPred 0.9058 LossAtt 0.4000 TrainAcc 0.6500 TestAcc 0.5926 0.6500
epoch 200 LossPred 0.8991 LossAtt 0.3241 TrainAcc 0.6500 TestAcc 0.5926 0.6500
epoch 300 LossPred 0.8965 LossAtt 0.3864 TrainAcc 0.6500 TestAcc 0.5926 0.6500
epoch 400 LossPred 0.8983 LossAtt 0.3639 TrainAcc 0.6500 TestAcc 0.5926 0.6500
epoch 500 LossPred 0.8939 LossAtt 0.4118 TrainAcc 0.6500 TestAcc 0.5926 0.6500
epoch 600 LossPred 0.8444 LossAtt 0.5389 TrainAcc 0.7000 TestAcc 0.5956 0.6850
epoch 700 LossPred 0.8742 LossAtt 0.4531 TrainAcc 0.6500 TestAcc 0.5886 0.6400
epoch 800 LossPred 0.7875 LossAtt 0.4177 TrainAcc 0.7100 TestAcc 0.6246 0.6900
epoch 900 LossPred 0.7998 LossAtt 0.3853 TrainAcc 0.7000 TestAcc 0.6271 0.6850
epoch 1000 LossPred 0.7889 LossAtt 0.3988 TrainAcc 0.7000 TestAcc 0.6434 0.6950
epoch 1100 LossPred 0.7838 LossAtt 0.4017 TrainAcc 0.7300 TestAcc 0.6051 0.6900
epoch 1200 LossPred 0.8367 LossAtt 0.3887 TrainAcc 0.6800 TestAcc 0.5681 0.6650
epoch 1300 LossPred 0.7600 LossAtt 0.3827 TrainAcc 0.7200 TestAcc 0.6051 0.7200
epoch 1400 LossPred 0.7419 LossAtt 0.3566 TrainAcc 0.7200 TestAcc 0.6024 0.7100
epoch 1500 LossPred 0.7325 LossAtt 0.3585 TrainAcc 0.7300 TestAcc 0.6056 0.7250
epoch 1600 LossPred 0.7369 LossAtt 0.3595 TrainAcc 0.7100 TestAcc 0.6084 0.7300
epoch 1700 LossPred 0.7212 LossAtt 0.3372 TrainAcc 0.7200 TestAcc 0.6086 0.7300
epoch 1800 LossPred 0.7168 LossAtt 0.3476 TrainAcc 0.7200 TestAcc 0.6166 0.7300
epoch 1900 LossPred 0.7136 LossAtt 0.3592 TrainAcc 0.7200 TestAcc 0.6229 0.7250
epoch 2000 LossPred 0.7172 LossAtt 0.3706 TrainAcc 0.7600 TestAcc 0.6597 0.7350
epoch 2100 LossPred 0.8274 LossAtt 0.3718 TrainAcc 0.6800 TestAcc 0.6166 0.6850
epoch 2200 LossPred 0.7179 LossAtt 0.3619 TrainAcc 0.7500 TestAcc 0.6529 0.7250
epoch 2300 LossPred 0.7102 LossAtt 0.3354 TrainAcc 0.7600 TestAcc 0.6502 0.7450
epoch 2400 LossPred 0.7300 LossAtt 0.3595 TrainAcc 0.7500 TestAcc 0.6309 0.7250
epoch 2500 LossPred 0.7296 LossAtt 0.3672 TrainAcc 0.7400 TestAcc 0.6406 0.7400
Optimization Finished!
********** replication  53  **********
epoch   0 LossPred 1.1342 LossAtt 0.9981 TrainAcc 0.4100 TestAcc 0.4372 0.4100
epoch 100 LossPred 0.9436 LossAtt 0.4710 TrainAcc 0.6100 TestAcc 0.5891 0.5900
epoch 200 LossPred 0.9196 LossAtt 0.4400 TrainAcc 0.6300 TestAcc 0.5866 0.6300
epoch 300 LossPred 0.9109 LossAtt 0.4278 TrainAcc 0.6300 TestAcc 0.5866 0.6300
epoch 400 LossPred 0.8950 LossAtt 0.4495 TrainAcc 0.6300 TestAcc 0.5866 0.6300
epoch 500 LossPred 0.8923 LossAtt 0.4133 TrainAcc 0.6400 TestAcc 0.5843 0.6400
epoch 600 LossPred 0.8598 LossAtt 0.4647 TrainAcc 0.6500 TestAcc 0.5858 0.6450
epoch 700 LossPred 0.7674 LossAtt 0.5401 TrainAcc 0.7100 TestAcc 0.5991 0.6850
epoch 800 LossPred 0.4129 LossAtt 0.5540 TrainAcc 0.8400 TestAcc 0.7910 0.8250
epoch 900 LossPred 0.3558 LossAtt 0.4974 TrainAcc 0.8800 TestAcc 0.8126 0.8800
epoch 1000 LossPred 0.8899 LossAtt 0.4480 TrainAcc 0.6800 TestAcc 0.6842 0.7200
epoch 1100 LossPred 0.2866 LossAtt 0.3944 TrainAcc 0.9000 TestAcc 0.8213 0.8950
epoch 1200 LossPred 0.2958 LossAtt 0.3781 TrainAcc 0.8900 TestAcc 0.8143 0.8850
epoch 1300 LossPred 0.2797 LossAtt 0.3354 TrainAcc 0.8900 TestAcc 0.8126 0.8950
epoch 1400 LossPred 0.2796 LossAtt 0.3446 TrainAcc 0.8900 TestAcc 0.8131 0.8800
epoch 1500 LossPred 0.3952 LossAtt 0.3365 TrainAcc 0.8700 TestAcc 0.8056 0.8900
epoch 1600 LossPred 0.3717 LossAtt 0.3107 TrainAcc 0.8700 TestAcc 0.8071 0.8750
epoch 1700 LossPred 0.2979 LossAtt 0.2997 TrainAcc 0.8800 TestAcc 0.8088 0.8800
epoch 1800 LossPred 0.3043 LossAtt 0.3084 TrainAcc 0.8800 TestAcc 0.8113 0.8900
epoch 1900 LossPred 0.3029 LossAtt 0.2984 TrainAcc 0.8800 TestAcc 0.8163 0.8800
epoch 2000 LossPred 0.2644 LossAtt 0.2917 TrainAcc 0.9100 TestAcc 0.8253 0.8900
epoch 2100 LossPred 0.2647 LossAtt 0.3237 TrainAcc 0.9000 TestAcc 0.8143 0.9100
epoch 2200 LossPred 0.2601 LossAtt 0.3203 TrainAcc 0.8900 TestAcc 0.8171 0.8800
epoch 2300 LossPred 0.2733 LossAtt 0.3134 TrainAcc 0.8900 TestAcc 0.8131 0.8800
epoch 2400 LossPred 0.3322 LossAtt 0.3172 TrainAcc 0.9100 TestAcc 0.8118 0.8900
epoch 2500 LossPred 0.3221 LossAtt 0.3211 TrainAcc 0.9000 TestAcc 0.8163 0.8950
Optimization Finished!
********** replication  54  **********
epoch   0 LossPred 1.0133 LossAtt 0.9957 TrainAcc 0.5100 TestAcc 0.5373 0.4900
epoch 100 LossPred 0.9394 LossAtt 0.2666 TrainAcc 0.6200 TestAcc 0.5821 0.6200
epoch 200 LossPred 0.9222 LossAtt 0.0890 TrainAcc 0.6200 TestAcc 0.5821 0.6200
epoch 300 LossPred 0.9304 LossAtt 0.0881 TrainAcc 0.6200 TestAcc 0.5821 0.6200
epoch 400 LossPred 0.9437 LossAtt 0.1091 TrainAcc 0.5700 TestAcc 0.5013 0.5700
epoch 500 LossPred 0.9461 LossAtt 0.0976 TrainAcc 0.5700 TestAcc 0.5013 0.5700
epoch 600 LossPred 0.9424 LossAtt 0.0904 TrainAcc 0.5700 TestAcc 0.5013 0.5700
epoch 700 LossPred 0.9428 LossAtt 0.1127 TrainAcc 0.5700 TestAcc 0.5013 0.5700
epoch 800 LossPred 0.9454 LossAtt 0.1092 TrainAcc 0.5700 TestAcc 0.5013 0.5700
epoch 900 LossPred 0.9553 LossAtt 0.1131 TrainAcc 0.5700 TestAcc 0.5013 0.5700
epoch 1000 LossPred 0.9615 LossAtt 0.1224 TrainAcc 0.5700 TestAcc 0.5013 0.5700
epoch 1100 LossPred 0.9684 LossAtt 0.1145 TrainAcc 0.5700 TestAcc 0.5013 0.5700
epoch 1200 LossPred 0.9676 LossAtt 0.0779 TrainAcc 0.5700 TestAcc 0.5013 0.5700
epoch 1300 LossPred 0.9630 LossAtt 0.0838 TrainAcc 0.5700 TestAcc 0.5013 0.5700
epoch 1400 LossPred 0.9543 LossAtt 0.0552 TrainAcc 0.5700 TestAcc 0.5013 0.5700
epoch 1500 LossPred 0.9410 LossAtt 0.0311 TrainAcc 0.5700 TestAcc 0.5013 0.5700
epoch 1600 LossPred 0.9431 LossAtt 0.0203 TrainAcc 0.5700 TestAcc 0.5013 0.5700
epoch 1700 LossPred 0.9594 LossAtt 0.0170 TrainAcc 0.5700 TestAcc 0.5013 0.5700
epoch 1800 LossPred 0.9690 LossAtt 0.0179 TrainAcc 0.5700 TestAcc 0.5013 0.5700
epoch 1900 LossPred 0.9715 LossAtt 0.0313 TrainAcc 0.5700 TestAcc 0.5013 0.5700
epoch 2000 LossPred 0.9726 LossAtt 0.0348 TrainAcc 0.5700 TestAcc 0.5013 0.5700
epoch 2100 LossPred 0.9739 LossAtt 0.0445 TrainAcc 0.5700 TestAcc 0.5013 0.5700
epoch 2200 LossPred 0.9751 LossAtt 0.0622 TrainAcc 0.5700 TestAcc 0.5013 0.5700
epoch 2300 LossPred 0.9738 LossAtt 0.1090 TrainAcc 0.5700 TestAcc 0.5013 0.5700
epoch 2400 LossPred 0.9038 LossAtt 0.1435 TrainAcc 0.6200 TestAcc 0.5821 0.6200
epoch 2500 LossPred 0.8692 LossAtt 0.2254 TrainAcc 0.6200 TestAcc 0.5821 0.6200
Optimization Finished!
********** replication  55  **********
epoch   0 LossPred 1.0876 LossAtt 1.0008 TrainAcc 0.3600 TestAcc 0.4234 0.3600
epoch 100 LossPred 0.9252 LossAtt 0.3292 TrainAcc 0.6400 TestAcc 0.5766 0.6400
epoch 200 LossPred 0.9300 LossAtt 0.1593 TrainAcc 0.6400 TestAcc 0.5766 0.6400
epoch 300 LossPred 0.9314 LossAtt 0.1206 TrainAcc 0.6400 TestAcc 0.5766 0.6400
epoch 400 LossPred 0.9550 LossAtt 0.1112 TrainAcc 0.6400 TestAcc 0.5766 0.6400
epoch 500 LossPred 0.9872 LossAtt 0.0992 TrainAcc 0.6400 TestAcc 0.5766 0.6400
epoch 600 LossPred 0.9985 LossAtt 0.0947 TrainAcc 0.5200 TestAcc 0.4922 0.5200
epoch 700 LossPred 0.9938 LossAtt 0.1230 TrainAcc 0.5200 TestAcc 0.4922 0.5200
epoch 800 LossPred 0.9492 LossAtt 0.2814 TrainAcc 0.6400 TestAcc 0.5766 0.6400
epoch 900 LossPred 0.9189 LossAtt 0.1446 TrainAcc 0.6400 TestAcc 0.5766 0.6400
epoch 1000 LossPred 0.9033 LossAtt 0.1913 TrainAcc 0.6400 TestAcc 0.5766 0.6400
epoch 1100 LossPred 0.9433 LossAtt 0.2231 TrainAcc 0.6200 TestAcc 0.5776 0.6250
epoch 1200 LossPred 0.6742 LossAtt 0.2325 TrainAcc 0.7800 TestAcc 0.8011 0.7950
epoch 1300 LossPred 0.7430 LossAtt 0.2359 TrainAcc 0.7200 TestAcc 0.7460 0.7150
epoch 1400 LossPred 0.9326 LossAtt 0.2219 TrainAcc 0.6200 TestAcc 0.6096 0.6350
epoch 1500 LossPred 0.5810 LossAtt 0.2074 TrainAcc 0.7800 TestAcc 0.8326 0.8050
epoch 1600 LossPred 0.6249 LossAtt 0.2181 TrainAcc 0.7800 TestAcc 0.8193 0.7800
epoch 1700 LossPred 0.6448 LossAtt 0.2119 TrainAcc 0.7800 TestAcc 0.8036 0.8100
epoch 1800 LossPred 0.6681 LossAtt 0.2175 TrainAcc 0.7800 TestAcc 0.8006 0.7900
epoch 1900 LossPred 0.9448 LossAtt 0.1993 TrainAcc 0.6700 TestAcc 0.7022 0.7050
epoch 2000 LossPred 0.7757 LossAtt 0.1621 TrainAcc 0.7100 TestAcc 0.6614 0.7150
epoch 2100 LossPred 0.7658 LossAtt 0.1697 TrainAcc 0.7100 TestAcc 0.6674 0.7050
epoch 2200 LossPred 0.8314 LossAtt 0.1686 TrainAcc 0.6600 TestAcc 0.6449 0.6800
epoch 2300 LossPred 0.8259 LossAtt 0.1626 TrainAcc 0.6800 TestAcc 0.6644 0.7250
epoch 2400 LossPred 0.7751 LossAtt 0.1704 TrainAcc 0.7000 TestAcc 0.6719 0.7300
epoch 2500 LossPred 0.7342 LossAtt 0.1798 TrainAcc 0.7200 TestAcc 0.6704 0.6950
Optimization Finished!
********** replication  56  **********
epoch   0 LossPred 1.0731 LossAtt 1.0112 TrainAcc 0.5400 TestAcc 0.4730 0.5200
epoch 100 LossPred 0.9518 LossAtt 0.2502 TrainAcc 0.5800 TestAcc 0.5013 0.5800
epoch 200 LossPred 0.9486 LossAtt 0.1676 TrainAcc 0.5800 TestAcc 0.5013 0.5800
epoch 300 LossPred 0.9438 LossAtt 0.1631 TrainAcc 0.5800 TestAcc 0.5013 0.5800
epoch 400 LossPred 0.9413 LossAtt 0.1607 TrainAcc 0.5800 TestAcc 0.5013 0.5800
epoch 500 LossPred 0.9395 LossAtt 0.1987 TrainAcc 0.5800 TestAcc 0.5013 0.5800
epoch 600 LossPred 0.9358 LossAtt 0.2695 TrainAcc 0.6000 TestAcc 0.5696 0.5800
epoch 700 LossPred 0.6822 LossAtt 0.3764 TrainAcc 0.7800 TestAcc 0.7720 0.7750
epoch 800 LossPred 0.6226 LossAtt 0.3737 TrainAcc 0.7900 TestAcc 0.8138 0.7600
epoch 900 LossPred 0.5811 LossAtt 0.3500 TrainAcc 0.8100 TestAcc 0.8231 0.7750
epoch 1000 LossPred 0.5928 LossAtt 0.3458 TrainAcc 0.8100 TestAcc 0.7815 0.7800
epoch 1100 LossPred 0.8364 LossAtt 0.3402 TrainAcc 0.7000 TestAcc 0.7838 0.7400
epoch 1200 LossPred 0.4905 LossAtt 0.3483 TrainAcc 0.8400 TestAcc 0.8196 0.8100
epoch 1300 LossPred 0.8729 LossAtt 0.3553 TrainAcc 0.6900 TestAcc 0.6737 0.6850
epoch 1400 LossPred 0.8560 LossAtt 0.3347 TrainAcc 0.7000 TestAcc 0.7718 0.7350
epoch 1500 LossPred 0.5085 LossAtt 0.3538 TrainAcc 0.8400 TestAcc 0.8278 0.8200
epoch 1600 LossPred 0.5601 LossAtt 0.3315 TrainAcc 0.8000 TestAcc 0.8148 0.8000
epoch 1700 LossPred 0.5040 LossAtt 0.3423 TrainAcc 0.8400 TestAcc 0.8148 0.7950
epoch 1800 LossPred 0.5485 LossAtt 0.3200 TrainAcc 0.7900 TestAcc 0.8258 0.7800
epoch 1900 LossPred 0.6195 LossAtt 0.3339 TrainAcc 0.7800 TestAcc 0.8283 0.7800
epoch 2000 LossPred 0.6909 LossAtt 0.3297 TrainAcc 0.7600 TestAcc 0.7202 0.7450
epoch 2100 LossPred 0.5574 LossAtt 0.3314 TrainAcc 0.7900 TestAcc 0.7993 0.8050
epoch 2200 LossPred 0.6902 LossAtt 0.3240 TrainAcc 0.7900 TestAcc 0.8193 0.7700
epoch 2300 LossPred 1.0581 LossAtt 0.2943 TrainAcc 0.6300 TestAcc 0.5891 0.6300
epoch 2400 LossPred 0.6905 LossAtt 0.3235 TrainAcc 0.7600 TestAcc 0.8088 0.7600
epoch 2500 LossPred 0.6356 LossAtt 0.2994 TrainAcc 0.7800 TestAcc 0.7565 0.7550
Optimization Finished!
********** replication  57  **********
epoch   0 LossPred 0.9371 LossAtt 1.0191 TrainAcc 0.6000 TestAcc 0.5546 0.6250
epoch 100 LossPred 0.8738 LossAtt 0.3182 TrainAcc 0.6500 TestAcc 0.5811 0.6500
epoch 200 LossPred 0.7749 LossAtt 0.4475 TrainAcc 0.7000 TestAcc 0.6159 0.7150
epoch 300 LossPred 0.7227 LossAtt 0.4024 TrainAcc 0.7500 TestAcc 0.7668 0.7350
epoch 400 LossPred 0.6406 LossAtt 0.3553 TrainAcc 0.7800 TestAcc 0.6887 0.7400
epoch 500 LossPred 0.6444 LossAtt 0.3149 TrainAcc 0.7500 TestAcc 0.6997 0.7650
epoch 600 LossPred 0.6337 LossAtt 0.3046 TrainAcc 0.7500 TestAcc 0.7177 0.7650
epoch 700 LossPred 0.5454 LossAtt 0.3106 TrainAcc 0.8200 TestAcc 0.7553 0.7800
epoch 800 LossPred 0.5874 LossAtt 0.3050 TrainAcc 0.8000 TestAcc 0.7375 0.7550
epoch 900 LossPred 0.5687 LossAtt 0.3007 TrainAcc 0.8000 TestAcc 0.8006 0.7700
epoch 1000 LossPred 0.5255 LossAtt 0.2960 TrainAcc 0.8100 TestAcc 0.7845 0.7800
epoch 1100 LossPred 0.5935 LossAtt 0.3107 TrainAcc 0.7800 TestAcc 0.8066 0.7650
epoch 1200 LossPred 0.5194 LossAtt 0.2944 TrainAcc 0.8100 TestAcc 0.7785 0.7850
epoch 1300 LossPred 0.5866 LossAtt 0.3053 TrainAcc 0.7800 TestAcc 0.8068 0.7750
epoch 1400 LossPred 0.5720 LossAtt 0.2974 TrainAcc 0.7900 TestAcc 0.7963 0.7700
epoch 1500 LossPred 0.5537 LossAtt 0.3035 TrainAcc 0.7900 TestAcc 0.7648 0.7800
epoch 1600 LossPred 0.5499 LossAtt 0.3191 TrainAcc 0.8000 TestAcc 0.7843 0.7750
epoch 1700 LossPred 0.6812 LossAtt 0.3134 TrainAcc 0.7300 TestAcc 0.7122 0.7550
epoch 1800 LossPred 0.7659 LossAtt 0.3486 TrainAcc 0.7400 TestAcc 0.6259 0.7200
epoch 1900 LossPred 0.6514 LossAtt 0.3412 TrainAcc 0.8000 TestAcc 0.6799 0.7700
epoch 2000 LossPred 0.6301 LossAtt 0.3353 TrainAcc 0.7800 TestAcc 0.7302 0.7850
epoch 2100 LossPred 0.6071 LossAtt 0.3326 TrainAcc 0.8000 TestAcc 0.7830 0.8000
epoch 2200 LossPred 0.6779 LossAtt 0.3123 TrainAcc 0.7400 TestAcc 0.6954 0.7450
epoch 2300 LossPred 0.7803 LossAtt 0.3437 TrainAcc 0.7200 TestAcc 0.7415 0.6950
epoch 2400 LossPred 0.6139 LossAtt 0.3336 TrainAcc 0.7800 TestAcc 0.7080 0.7700
epoch 2500 LossPred 0.7381 LossAtt 0.3241 TrainAcc 0.7200 TestAcc 0.6466 0.7300
Optimization Finished!
********** replication  58  **********
epoch   0 LossPred 0.9655 LossAtt 0.9919 TrainAcc 0.5900 TestAcc 0.5355 0.6050
epoch 100 LossPred 0.9019 LossAtt 0.4045 TrainAcc 0.6200 TestAcc 0.5723 0.6300
epoch 200 LossPred 0.8854 LossAtt 0.3841 TrainAcc 0.6600 TestAcc 0.5868 0.6750
epoch 300 LossPred 0.5421 LossAtt 0.4877 TrainAcc 0.8300 TestAcc 0.7685 0.8300
epoch 400 LossPred 0.6647 LossAtt 0.4714 TrainAcc 0.7700 TestAcc 0.7490 0.7700
epoch 500 LossPred 0.3936 LossAtt 0.4395 TrainAcc 0.8600 TestAcc 0.7705 0.8500
epoch 600 LossPred 0.3406 LossAtt 0.4418 TrainAcc 0.8900 TestAcc 0.8226 0.8750
epoch 700 LossPred 0.3175 LossAtt 0.4412 TrainAcc 0.9200 TestAcc 0.7865 0.8750
epoch 800 LossPred 0.3612 LossAtt 0.4268 TrainAcc 0.8800 TestAcc 0.8581 0.8650
epoch 900 LossPred 0.3258 LossAtt 0.4262 TrainAcc 0.9200 TestAcc 0.8616 0.9100
epoch 1000 LossPred 0.2810 LossAtt 0.4208 TrainAcc 0.9300 TestAcc 0.8346 0.9050
epoch 1100 LossPred 0.3215 LossAtt 0.4503 TrainAcc 0.8900 TestAcc 0.8451 0.9050
epoch 1200 LossPred 0.2802 LossAtt 0.4311 TrainAcc 0.9300 TestAcc 0.8441 0.9200
epoch 1300 LossPred 0.3073 LossAtt 0.4316 TrainAcc 0.9200 TestAcc 0.8506 0.9150
epoch 1400 LossPred 0.2568 LossAtt 0.4360 TrainAcc 0.9300 TestAcc 0.8451 0.9100
epoch 1500 LossPred 0.3031 LossAtt 0.4196 TrainAcc 0.8900 TestAcc 0.8426 0.9050
epoch 1600 LossPred 0.3592 LossAtt 0.4385 TrainAcc 0.8900 TestAcc 0.7738 0.8800
epoch 1700 LossPred 0.3544 LossAtt 0.4171 TrainAcc 0.8900 TestAcc 0.8519 0.8950
epoch 1800 LossPred 0.2585 LossAtt 0.4180 TrainAcc 0.9000 TestAcc 0.8163 0.9000
epoch 1900 LossPred 0.2629 LossAtt 0.4173 TrainAcc 0.9300 TestAcc 0.8388 0.9200
epoch 2000 LossPred 0.3944 LossAtt 0.4000 TrainAcc 0.8700 TestAcc 0.7665 0.8650
epoch 2100 LossPred 0.3222 LossAtt 0.4257 TrainAcc 0.9100 TestAcc 0.8529 0.9150
epoch 2200 LossPred 0.3492 LossAtt 0.4071 TrainAcc 0.8900 TestAcc 0.7583 0.8600
epoch 2300 LossPred 0.2061 LossAtt 0.4132 TrainAcc 0.9500 TestAcc 0.8373 0.9150
epoch 2400 LossPred 0.2592 LossAtt 0.4046 TrainAcc 0.9300 TestAcc 0.8451 0.8950
epoch 2500 LossPred 0.3124 LossAtt 0.3984 TrainAcc 0.9200 TestAcc 0.7893 0.8950
Optimization Finished!
********** replication  59  **********
epoch   0 LossPred 1.3225 LossAtt 1.0008 TrainAcc 0.4500 TestAcc 0.4660 0.4150
epoch 100 LossPred 0.9667 LossAtt 0.3117 TrainAcc 0.6400 TestAcc 0.5796 0.6300
epoch 200 LossPred 0.9123 LossAtt 0.3255 TrainAcc 0.6300 TestAcc 0.5473 0.6300
epoch 300 LossPred 0.9103 LossAtt 0.2251 TrainAcc 0.6300 TestAcc 0.5473 0.6300
epoch 400 LossPred 0.9068 LossAtt 0.1705 TrainAcc 0.6300 TestAcc 0.5473 0.6300
epoch 500 LossPred 0.9014 LossAtt 0.1688 TrainAcc 0.6300 TestAcc 0.5473 0.6300
epoch 600 LossPred 0.8951 LossAtt 0.1914 TrainAcc 0.6300 TestAcc 0.5473 0.6300
epoch 700 LossPred 0.8910 LossAtt 0.2044 TrainAcc 0.6300 TestAcc 0.5473 0.6250
epoch 800 LossPred 0.8812 LossAtt 0.2458 TrainAcc 0.6600 TestAcc 0.5741 0.6500
epoch 900 LossPred 0.8762 LossAtt 0.2774 TrainAcc 0.6600 TestAcc 0.5668 0.6600
epoch 1000 LossPred 0.8740 LossAtt 0.2771 TrainAcc 0.6600 TestAcc 0.5668 0.6600
epoch 1100 LossPred 0.8685 LossAtt 0.2941 TrainAcc 0.6600 TestAcc 0.5668 0.6600
epoch 1200 LossPred 0.7347 LossAtt 0.5097 TrainAcc 0.7200 TestAcc 0.6169 0.7250
epoch 1300 LossPred 0.7597 LossAtt 0.4271 TrainAcc 0.7400 TestAcc 0.6224 0.7450
epoch 1400 LossPred 0.7368 LossAtt 0.4024 TrainAcc 0.7400 TestAcc 0.6361 0.7400
epoch 1500 LossPred 0.7326 LossAtt 0.3783 TrainAcc 0.7300 TestAcc 0.6289 0.7450
epoch 1600 LossPred 0.7288 LossAtt 0.3583 TrainAcc 0.7400 TestAcc 0.6329 0.7500
epoch 1700 LossPred 0.8736 LossAtt 0.3225 TrainAcc 0.6700 TestAcc 0.5746 0.6650
epoch 1800 LossPred 0.8078 LossAtt 0.3171 TrainAcc 0.7000 TestAcc 0.5873 0.7000
epoch 1900 LossPred 0.7885 LossAtt 0.3200 TrainAcc 0.7000 TestAcc 0.6034 0.7100
epoch 2000 LossPred 0.7869 LossAtt 0.3244 TrainAcc 0.7000 TestAcc 0.6069 0.7000
epoch 2100 LossPred 0.7229 LossAtt 0.3169 TrainAcc 0.7500 TestAcc 0.6186 0.7450
epoch 2200 LossPred 0.7215 LossAtt 0.3286 TrainAcc 0.7400 TestAcc 0.6557 0.7350
epoch 2300 LossPred 0.7242 LossAtt 0.3236 TrainAcc 0.7400 TestAcc 0.6246 0.7400
epoch 2400 LossPred 0.7232 LossAtt 0.3115 TrainAcc 0.7300 TestAcc 0.6451 0.7400
epoch 2500 LossPred 0.7425 LossAtt 0.3132 TrainAcc 0.7300 TestAcc 0.6271 0.7250
Optimization Finished!
********** replication  60  **********
epoch   0 LossPred 1.0201 LossAtt 0.9785 TrainAcc 0.4600 TestAcc 0.4970 0.4650
epoch 100 LossPred 0.9412 LossAtt 0.4395 TrainAcc 0.5900 TestAcc 0.5726 0.6050
epoch 200 LossPred 0.8223 LossAtt 0.5478 TrainAcc 0.7200 TestAcc 0.6637 0.7050
epoch 300 LossPred 0.5474 LossAtt 0.5756 TrainAcc 0.8500 TestAcc 0.8308 0.8100
epoch 400 LossPred 0.4990 LossAtt 0.5777 TrainAcc 0.8300 TestAcc 0.7963 0.7950
epoch 500 LossPred 0.3382 LossAtt 0.5496 TrainAcc 0.8900 TestAcc 0.8871 0.8850
epoch 600 LossPred 0.2863 LossAtt 0.5257 TrainAcc 0.9200 TestAcc 0.8829 0.8800
epoch 700 LossPred 0.2304 LossAtt 0.5199 TrainAcc 0.9200 TestAcc 0.9089 0.9150
epoch 800 LossPred 0.1843 LossAtt 0.5131 TrainAcc 0.9600 TestAcc 0.9172 0.9200
epoch 900 LossPred 0.1843 LossAtt 0.5176 TrainAcc 0.9500 TestAcc 0.8891 0.9200
epoch 1000 LossPred 0.1713 LossAtt 0.5012 TrainAcc 0.9400 TestAcc 0.9194 0.9300
epoch 1100 LossPred 0.1409 LossAtt 0.5011 TrainAcc 0.9300 TestAcc 0.9187 0.9250
epoch 1200 LossPred 0.1749 LossAtt 0.4835 TrainAcc 0.9400 TestAcc 0.8951 0.9250
epoch 1300 LossPred 0.1432 LossAtt 0.4967 TrainAcc 0.9500 TestAcc 0.9269 0.9300
epoch 1400 LossPred 0.1304 LossAtt 0.4854 TrainAcc 0.9500 TestAcc 0.9229 0.9400
epoch 1500 LossPred 0.1265 LossAtt 0.4863 TrainAcc 0.9500 TestAcc 0.9284 0.9400
epoch 1600 LossPred 0.1193 LossAtt 0.4728 TrainAcc 0.9600 TestAcc 0.9157 0.9250
epoch 1700 LossPred 0.1404 LossAtt 0.4834 TrainAcc 0.9400 TestAcc 0.9264 0.9300
epoch 1800 LossPred 0.1122 LossAtt 0.4656 TrainAcc 0.9500 TestAcc 0.9229 0.9300
epoch 1900 LossPred 0.1166 LossAtt 0.4835 TrainAcc 0.9700 TestAcc 0.9237 0.9500
epoch 2000 LossPred 0.2419 LossAtt 0.4861 TrainAcc 0.9000 TestAcc 0.8556 0.9000
epoch 2100 LossPred 0.2773 LossAtt 0.4791 TrainAcc 0.9000 TestAcc 0.8426 0.8950
epoch 2200 LossPred 0.0953 LossAtt 0.4746 TrainAcc 0.9800 TestAcc 0.9212 0.9550
epoch 2300 LossPred 0.1319 LossAtt 0.4938 TrainAcc 0.9700 TestAcc 0.9314 0.9350
epoch 2400 LossPred 0.1173 LossAtt 0.4767 TrainAcc 0.9600 TestAcc 0.8874 0.9400
epoch 2500 LossPred 0.0892 LossAtt 0.4784 TrainAcc 0.9800 TestAcc 0.9089 0.9550
Optimization Finished!
********** replication  61  **********
epoch   0 LossPred 1.1292 LossAtt 1.0153 TrainAcc 0.4900 TestAcc 0.5158 0.4950
epoch 100 LossPred 0.9877 LossAtt 0.3615 TrainAcc 0.5600 TestAcc 0.5008 0.5600
epoch 200 LossPred 0.9740 LossAtt 0.3697 TrainAcc 0.5600 TestAcc 0.5203 0.5400
epoch 300 LossPred 0.9545 LossAtt 0.3909 TrainAcc 0.6000 TestAcc 0.5438 0.5950
epoch 400 LossPred 0.9209 LossAtt 0.4979 TrainAcc 0.6400 TestAcc 0.5418 0.6400
epoch 500 LossPred 0.8566 LossAtt 0.6037 TrainAcc 0.6900 TestAcc 0.5953 0.6700
epoch 600 LossPred 0.5925 LossAtt 0.5848 TrainAcc 0.8200 TestAcc 0.7315 0.8000
epoch 700 LossPred 0.5624 LossAtt 0.5926 TrainAcc 0.8100 TestAcc 0.7317 0.8050
epoch 800 LossPred 0.3932 LossAtt 0.5474 TrainAcc 0.8600 TestAcc 0.8286 0.8450
epoch 900 LossPred 0.4192 LossAtt 0.5914 TrainAcc 0.8800 TestAcc 0.7963 0.8650
epoch 1000 LossPred 0.4416 LossAtt 0.5514 TrainAcc 0.8500 TestAcc 0.7653 0.8500
epoch 1100 LossPred 0.2843 LossAtt 0.5600 TrainAcc 0.9300 TestAcc 0.8108 0.8900
epoch 1200 LossPred 0.3407 LossAtt 0.5468 TrainAcc 0.8900 TestAcc 0.8028 0.8700
epoch 1300 LossPred 0.2340 LossAtt 0.5576 TrainAcc 0.9400 TestAcc 0.8316 0.9100
epoch 1400 LossPred 0.3087 LossAtt 0.5525 TrainAcc 0.9100 TestAcc 0.8243 0.9000
epoch 1500 LossPred 0.4165 LossAtt 0.5398 TrainAcc 0.8600 TestAcc 0.7635 0.8450
epoch 1600 LossPred 0.1522 LossAtt 0.5489 TrainAcc 0.9600 TestAcc 0.8431 0.9100
epoch 1700 LossPred 0.1890 LossAtt 0.5531 TrainAcc 0.9400 TestAcc 0.8456 0.9000
epoch 1800 LossPred 0.3231 LossAtt 0.5240 TrainAcc 0.9000 TestAcc 0.7975 0.8750
epoch 1900 LossPred 0.1741 LossAtt 0.5349 TrainAcc 0.9500 TestAcc 0.8321 0.8850
epoch 2000 LossPred 0.1451 LossAtt 0.5326 TrainAcc 0.9400 TestAcc 0.8436 0.9150
epoch 2100 LossPred 0.1244 LossAtt 0.5349 TrainAcc 0.9500 TestAcc 0.8524 0.9000
epoch 2200 LossPred 0.1308 LossAtt 0.5064 TrainAcc 0.9700 TestAcc 0.8408 0.9150
epoch 2300 LossPred 0.2198 LossAtt 0.5381 TrainAcc 0.9400 TestAcc 0.8248 0.9250
epoch 2400 LossPred 0.2672 LossAtt 0.5241 TrainAcc 0.9200 TestAcc 0.8238 0.9050
epoch 2500 LossPred 0.1878 LossAtt 0.5300 TrainAcc 0.9600 TestAcc 0.8171 0.9050
Optimization Finished!
********** replication  62  **********
epoch   0 LossPred 1.2237 LossAtt 1.0438 TrainAcc 0.4600 TestAcc 0.4449 0.4550
epoch 100 LossPred 0.9865 LossAtt 0.5177 TrainAcc 0.5300 TestAcc 0.4862 0.5300
epoch 200 LossPred 0.9528 LossAtt 0.5249 TrainAcc 0.5700 TestAcc 0.4847 0.5800
epoch 300 LossPred 0.9196 LossAtt 0.5155 TrainAcc 0.5900 TestAcc 0.5420 0.6000
epoch 400 LossPred 0.8817 LossAtt 0.5467 TrainAcc 0.7100 TestAcc 0.5781 0.6900
epoch 500 LossPred 0.8287 LossAtt 0.5872 TrainAcc 0.7000 TestAcc 0.6221 0.6800
epoch 600 LossPred 0.5731 LossAtt 0.5758 TrainAcc 0.8200 TestAcc 0.8338 0.8100
epoch 700 LossPred 0.5216 LossAtt 0.4934 TrainAcc 0.8200 TestAcc 0.7955 0.8050
epoch 800 LossPred 0.3456 LossAtt 0.4973 TrainAcc 0.9000 TestAcc 0.8238 0.8800
epoch 900 LossPred 0.3175 LossAtt 0.4840 TrainAcc 0.8900 TestAcc 0.8411 0.8850
epoch 1000 LossPred 0.2526 LossAtt 0.4642 TrainAcc 0.9000 TestAcc 0.8443 0.9050
epoch 1100 LossPred 0.2042 LossAtt 0.4478 TrainAcc 0.9500 TestAcc 0.8418 0.9300
epoch 1200 LossPred 0.2033 LossAtt 0.4347 TrainAcc 0.9400 TestAcc 0.8368 0.9300
epoch 1300 LossPred 0.1833 LossAtt 0.4008 TrainAcc 0.9400 TestAcc 0.8468 0.9450
epoch 1400 LossPred 0.1839 LossAtt 0.3730 TrainAcc 0.9500 TestAcc 0.8328 0.9400
epoch 1500 LossPred 0.1909 LossAtt 0.3843 TrainAcc 0.9400 TestAcc 0.8441 0.9350
epoch 1600 LossPred 0.1815 LossAtt 0.3954 TrainAcc 0.9400 TestAcc 0.8413 0.9350
epoch 1700 LossPred 0.1981 LossAtt 0.3670 TrainAcc 0.9400 TestAcc 0.8486 0.9250
epoch 1800 LossPred 0.2335 LossAtt 0.3882 TrainAcc 0.9200 TestAcc 0.8451 0.9100
epoch 1900 LossPred 0.4195 LossAtt 0.3511 TrainAcc 0.8600 TestAcc 0.7878 0.8600
epoch 2000 LossPred 0.1798 LossAtt 0.3588 TrainAcc 0.9300 TestAcc 0.8471 0.9300
epoch 2100 LossPred 0.2359 LossAtt 0.3548 TrainAcc 0.9200 TestAcc 0.8549 0.9100
epoch 2200 LossPred 0.1788 LossAtt 0.3589 TrainAcc 0.9500 TestAcc 0.8368 0.9400
epoch 2300 LossPred 0.1798 LossAtt 0.3552 TrainAcc 0.9300 TestAcc 0.8453 0.9300
epoch 2400 LossPred 0.1796 LossAtt 0.3585 TrainAcc 0.9300 TestAcc 0.8448 0.9250
epoch 2500 LossPred 0.1957 LossAtt 0.3395 TrainAcc 0.9400 TestAcc 0.8346 0.9350
Optimization Finished!
********** replication  63  **********
epoch   0 LossPred 1.1640 LossAtt 1.0106 TrainAcc 0.4400 TestAcc 0.4622 0.3950
epoch 100 LossPred 0.9135 LossAtt 0.4700 TrainAcc 0.6500 TestAcc 0.5703 0.6750
epoch 200 LossPred 0.8566 LossAtt 0.5169 TrainAcc 0.6800 TestAcc 0.5683 0.6650
epoch 300 LossPred 0.7620 LossAtt 0.4897 TrainAcc 0.7200 TestAcc 0.6346 0.7250
epoch 400 LossPred 0.4557 LossAtt 0.4363 TrainAcc 0.8700 TestAcc 0.7658 0.8450
epoch 500 LossPred 0.4543 LossAtt 0.4226 TrainAcc 0.8700 TestAcc 0.7347 0.8450
epoch 600 LossPred 0.3377 LossAtt 0.4244 TrainAcc 0.9100 TestAcc 0.8123 0.8850
epoch 700 LossPred 0.3999 LossAtt 0.4326 TrainAcc 0.8700 TestAcc 0.8196 0.8650
epoch 800 LossPred 0.4059 LossAtt 0.4297 TrainAcc 0.9000 TestAcc 0.7603 0.8400
epoch 900 LossPred 0.4512 LossAtt 0.4492 TrainAcc 0.8700 TestAcc 0.7297 0.8400
epoch 1000 LossPred 0.4048 LossAtt 0.4163 TrainAcc 0.8600 TestAcc 0.8118 0.8600
epoch 1100 LossPred 0.3831 LossAtt 0.3833 TrainAcc 0.9000 TestAcc 0.7833 0.8850
epoch 1200 LossPred 0.3718 LossAtt 0.3642 TrainAcc 0.8900 TestAcc 0.7990 0.8850
epoch 1300 LossPred 0.3494 LossAtt 0.3681 TrainAcc 0.8900 TestAcc 0.8096 0.8900
epoch 1400 LossPred 0.3121 LossAtt 0.3560 TrainAcc 0.9000 TestAcc 0.8101 0.8750
epoch 1500 LossPred 0.2641 LossAtt 0.3391 TrainAcc 0.9300 TestAcc 0.8388 0.8900
epoch 1600 LossPred 0.2742 LossAtt 0.3307 TrainAcc 0.9100 TestAcc 0.8711 0.9050
epoch 1700 LossPred 0.2309 LossAtt 0.3444 TrainAcc 0.9300 TestAcc 0.8529 0.9050
epoch 1800 LossPred 0.2671 LossAtt 0.3444 TrainAcc 0.9000 TestAcc 0.8258 0.9100
epoch 1900 LossPred 0.2260 LossAtt 0.3484 TrainAcc 0.9300 TestAcc 0.8466 0.9200
epoch 2000 LossPred 0.2170 LossAtt 0.3677 TrainAcc 0.9200 TestAcc 0.8606 0.9250
epoch 2100 LossPred 0.2572 LossAtt 0.3541 TrainAcc 0.9100 TestAcc 0.8799 0.9000
epoch 2200 LossPred 0.2935 LossAtt 0.3753 TrainAcc 0.9000 TestAcc 0.8694 0.8850
epoch 2300 LossPred 0.1700 LossAtt 0.3845 TrainAcc 0.9500 TestAcc 0.8874 0.9250
epoch 2400 LossPred 0.2049 LossAtt 0.3933 TrainAcc 0.9300 TestAcc 0.8914 0.8850
epoch 2500 LossPred 0.4898 LossAtt 0.3930 TrainAcc 0.8400 TestAcc 0.7873 0.8400
Optimization Finished!
********** replication  64  **********
epoch   0 LossPred 1.1471 LossAtt 0.9984 TrainAcc 0.4500 TestAcc 0.4680 0.4600
epoch 100 LossPred 0.9531 LossAtt 0.4119 TrainAcc 0.6200 TestAcc 0.5713 0.6250
epoch 200 LossPred 0.9307 LossAtt 0.4061 TrainAcc 0.6000 TestAcc 0.5651 0.6050
epoch 300 LossPred 0.9182 LossAtt 0.3979 TrainAcc 0.6300 TestAcc 0.5848 0.6200
epoch 400 LossPred 0.7304 LossAtt 0.4286 TrainAcc 0.7500 TestAcc 0.7305 0.7650
epoch 500 LossPred 0.4347 LossAtt 0.4271 TrainAcc 0.8700 TestAcc 0.8046 0.8450
epoch 600 LossPred 0.4941 LossAtt 0.4413 TrainAcc 0.8400 TestAcc 0.7690 0.7750
epoch 700 LossPred 0.3914 LossAtt 0.4160 TrainAcc 0.8800 TestAcc 0.8178 0.8550
epoch 800 LossPred 0.4398 LossAtt 0.4193 TrainAcc 0.8400 TestAcc 0.8051 0.8500
epoch 900 LossPred 0.4232 LossAtt 0.4086 TrainAcc 0.8700 TestAcc 0.8191 0.8450
epoch 1000 LossPred 0.4493 LossAtt 0.3928 TrainAcc 0.8400 TestAcc 0.8021 0.8400
epoch 1100 LossPred 0.4389 LossAtt 0.3942 TrainAcc 0.8600 TestAcc 0.8196 0.8500
epoch 1200 LossPred 0.4401 LossAtt 0.3785 TrainAcc 0.8500 TestAcc 0.8161 0.8600
epoch 1300 LossPred 0.4195 LossAtt 0.3786 TrainAcc 0.8600 TestAcc 0.8123 0.8650
epoch 1400 LossPred 0.4758 LossAtt 0.3789 TrainAcc 0.8300 TestAcc 0.8003 0.8550
epoch 1500 LossPred 0.4362 LossAtt 0.4048 TrainAcc 0.8500 TestAcc 0.8193 0.8650
epoch 1600 LossPred 0.4328 LossAtt 0.4066 TrainAcc 0.8500 TestAcc 0.7998 0.8650
epoch 1700 LossPred 0.4069 LossAtt 0.4104 TrainAcc 0.8500 TestAcc 0.8081 0.8700
epoch 1800 LossPred 0.4141 LossAtt 0.4000 TrainAcc 0.8600 TestAcc 0.8168 0.8650
epoch 1900 LossPred 0.4580 LossAtt 0.4182 TrainAcc 0.8400 TestAcc 0.8136 0.8600
epoch 2000 LossPred 0.4107 LossAtt 0.4188 TrainAcc 0.8500 TestAcc 0.7975 0.8800
epoch 2100 LossPred 0.4735 LossAtt 0.4177 TrainAcc 0.8400 TestAcc 0.8203 0.8700
epoch 2200 LossPred 0.4656 LossAtt 0.4038 TrainAcc 0.8400 TestAcc 0.7878 0.8500
epoch 2300 LossPred 0.3464 LossAtt 0.4375 TrainAcc 0.8900 TestAcc 0.8063 0.8900
epoch 2400 LossPred 0.4579 LossAtt 0.4210 TrainAcc 0.8400 TestAcc 0.7565 0.8400
epoch 2500 LossPred 0.3506 LossAtt 0.3977 TrainAcc 0.8900 TestAcc 0.8116 0.8950
Optimization Finished!
********** replication  65  **********
epoch   0 LossPred 1.1588 LossAtt 0.9986 TrainAcc 0.5000 TestAcc 0.4630 0.5000
epoch 100 LossPred 0.9505 LossAtt 0.4103 TrainAcc 0.6000 TestAcc 0.5813 0.5850
epoch 200 LossPred 0.9446 LossAtt 0.3569 TrainAcc 0.6000 TestAcc 0.5813 0.5950
epoch 300 LossPred 0.9422 LossAtt 0.2942 TrainAcc 0.6000 TestAcc 0.5813 0.6000
epoch 400 LossPred 0.9375 LossAtt 0.2669 TrainAcc 0.6400 TestAcc 0.5813 0.6450
epoch 500 LossPred 0.9259 LossAtt 0.3157 TrainAcc 0.6100 TestAcc 0.5561 0.6100
epoch 600 LossPred 0.9250 LossAtt 0.2935 TrainAcc 0.6000 TestAcc 0.5353 0.6200
epoch 700 LossPred 0.9245 LossAtt 0.3004 TrainAcc 0.6000 TestAcc 0.5353 0.6200
epoch 800 LossPred 0.9216 LossAtt 0.3045 TrainAcc 0.6100 TestAcc 0.5363 0.6150
epoch 900 LossPred 0.9184 LossAtt 0.3141 TrainAcc 0.6100 TestAcc 0.5343 0.6200
epoch 1000 LossPred 0.8995 LossAtt 0.4371 TrainAcc 0.6700 TestAcc 0.5918 0.6550
epoch 1100 LossPred 0.8929 LossAtt 0.4437 TrainAcc 0.6800 TestAcc 0.5626 0.6500
epoch 1200 LossPred 0.8993 LossAtt 0.4448 TrainAcc 0.6400 TestAcc 0.5463 0.6350
epoch 1300 LossPred 0.8545 LossAtt 0.4568 TrainAcc 0.6700 TestAcc 0.5806 0.6700
epoch 1400 LossPred 0.8340 LossAtt 0.4940 TrainAcc 0.6800 TestAcc 0.6239 0.6750
epoch 1500 LossPred 0.7996 LossAtt 0.5070 TrainAcc 0.6700 TestAcc 0.6794 0.6700
epoch 1600 LossPred 0.8081 LossAtt 0.4851 TrainAcc 0.6800 TestAcc 0.6061 0.6950
epoch 1700 LossPred 0.5574 LossAtt 0.4221 TrainAcc 0.8300 TestAcc 0.7695 0.8250
epoch 1800 LossPred 0.5488 LossAtt 0.4202 TrainAcc 0.8200 TestAcc 0.7900 0.7900
epoch 1900 LossPred 0.7501 LossAtt 0.4079 TrainAcc 0.7200 TestAcc 0.6481 0.7200
epoch 2000 LossPred 0.4004 LossAtt 0.4141 TrainAcc 0.8800 TestAcc 0.8171 0.8550
epoch 2100 LossPred 0.4535 LossAtt 0.4560 TrainAcc 0.8600 TestAcc 0.7795 0.8350
epoch 2200 LossPred 0.4248 LossAtt 0.4402 TrainAcc 0.8700 TestAcc 0.7963 0.8400
epoch 2300 LossPred 0.4105 LossAtt 0.4744 TrainAcc 0.8700 TestAcc 0.8316 0.8500
epoch 2400 LossPred 0.3388 LossAtt 0.4701 TrainAcc 0.9000 TestAcc 0.8246 0.8700
epoch 2500 LossPred 0.3058 LossAtt 0.4616 TrainAcc 0.9200 TestAcc 0.8333 0.8750
Optimization Finished!
********** replication  66  **********
epoch   0 LossPred 1.1636 LossAtt 1.0094 TrainAcc 0.3700 TestAcc 0.4134 0.3750
epoch 100 LossPred 0.9043 LossAtt 0.3361 TrainAcc 0.6300 TestAcc 0.5866 0.6350
epoch 200 LossPred 0.8245 LossAtt 0.3105 TrainAcc 0.7100 TestAcc 0.6597 0.7000
epoch 300 LossPred 0.6830 LossAtt 0.3871 TrainAcc 0.7300 TestAcc 0.7533 0.7200
epoch 400 LossPred 0.5634 LossAtt 0.3484 TrainAcc 0.8200 TestAcc 0.8076 0.7850
epoch 500 LossPred 0.4652 LossAtt 0.3452 TrainAcc 0.8800 TestAcc 0.8328 0.8450
epoch 600 LossPred 0.4741 LossAtt 0.3556 TrainAcc 0.8700 TestAcc 0.8371 0.8400
epoch 700 LossPred 0.5602 LossAtt 0.3636 TrainAcc 0.8200 TestAcc 0.7918 0.7900
epoch 800 LossPred 0.4642 LossAtt 0.3682 TrainAcc 0.8600 TestAcc 0.8416 0.8300
epoch 900 LossPred 0.4474 LossAtt 0.3492 TrainAcc 0.8700 TestAcc 0.8293 0.8250
epoch 1000 LossPred 0.4750 LossAtt 0.3580 TrainAcc 0.8300 TestAcc 0.8263 0.8050
epoch 1100 LossPred 0.4683 LossAtt 0.3629 TrainAcc 0.8400 TestAcc 0.8301 0.8100
epoch 1200 LossPred 0.4413 LossAtt 0.3506 TrainAcc 0.8800 TestAcc 0.8346 0.8350
epoch 1300 LossPred 0.4457 LossAtt 0.3525 TrainAcc 0.8600 TestAcc 0.8263 0.8200
epoch 1400 LossPred 0.4424 LossAtt 0.3445 TrainAcc 0.8500 TestAcc 0.8321 0.8350
epoch 1500 LossPred 0.4507 LossAtt 0.3686 TrainAcc 0.8400 TestAcc 0.8421 0.8250
epoch 1600 LossPred 0.3897 LossAtt 0.3612 TrainAcc 0.8600 TestAcc 0.8388 0.8600
epoch 1700 LossPred 0.3453 LossAtt 0.3831 TrainAcc 0.8800 TestAcc 0.8496 0.8700
epoch 1800 LossPred 0.3186 LossAtt 0.3948 TrainAcc 0.9000 TestAcc 0.8576 0.8850
epoch 1900 LossPred 0.3059 LossAtt 0.3738 TrainAcc 0.9000 TestAcc 0.8566 0.9000
epoch 2000 LossPred 0.3086 LossAtt 0.3861 TrainAcc 0.9100 TestAcc 0.8541 0.8800
epoch 2100 LossPred 0.2711 LossAtt 0.3485 TrainAcc 0.9100 TestAcc 0.8731 0.9000
epoch 2200 LossPred 0.2501 LossAtt 0.3503 TrainAcc 0.9200 TestAcc 0.8831 0.9200
epoch 2300 LossPred 0.2519 LossAtt 0.3437 TrainAcc 0.9100 TestAcc 0.8824 0.9050
epoch 2400 LossPred 0.2334 LossAtt 0.3615 TrainAcc 0.9200 TestAcc 0.8879 0.9200
epoch 2500 LossPred 0.2426 LossAtt 0.3608 TrainAcc 0.9200 TestAcc 0.8844 0.9000
Optimization Finished!
********** replication  67  **********
epoch   0 LossPred 1.0491 LossAtt 1.0111 TrainAcc 0.5300 TestAcc 0.5473 0.5300
epoch 100 LossPred 0.9799 LossAtt 0.3294 TrainAcc 0.5800 TestAcc 0.5688 0.5650
epoch 200 LossPred 0.9761 LossAtt 0.2297 TrainAcc 0.5800 TestAcc 0.5688 0.5800
epoch 300 LossPred 0.9747 LossAtt 0.1837 TrainAcc 0.5800 TestAcc 0.5688 0.5800
epoch 400 LossPred 0.9735 LossAtt 0.1525 TrainAcc 0.5800 TestAcc 0.5688 0.5800
epoch 500 LossPred 0.9711 LossAtt 0.1313 TrainAcc 0.5800 TestAcc 0.5688 0.5800
epoch 600 LossPred 0.9712 LossAtt 0.1746 TrainAcc 0.5800 TestAcc 0.5688 0.5700
epoch 700 LossPred 0.9730 LossAtt 0.2692 TrainAcc 0.5500 TestAcc 0.5961 0.5600
epoch 800 LossPred 0.8136 LossAtt 0.3855 TrainAcc 0.7200 TestAcc 0.7212 0.6950
epoch 900 LossPred 0.4735 LossAtt 0.2939 TrainAcc 0.8200 TestAcc 0.8704 0.8000
epoch 1000 LossPred 0.4445 LossAtt 0.3033 TrainAcc 0.8700 TestAcc 0.8854 0.8450
epoch 1100 LossPred 0.6830 LossAtt 0.2873 TrainAcc 0.7300 TestAcc 0.7322 0.7400
epoch 1200 LossPred 0.7922 LossAtt 0.2736 TrainAcc 0.7200 TestAcc 0.6794 0.6950
epoch 1300 LossPred 0.5596 LossAtt 0.2962 TrainAcc 0.7900 TestAcc 0.8559 0.7700
epoch 1400 LossPred 0.5974 LossAtt 0.2735 TrainAcc 0.7600 TestAcc 0.8358 0.7700
epoch 1500 LossPred 0.4621 LossAtt 0.2612 TrainAcc 0.8600 TestAcc 0.8821 0.8450
epoch 1600 LossPred 0.4355 LossAtt 0.2710 TrainAcc 0.8600 TestAcc 0.8656 0.8350
epoch 1700 LossPred 0.6530 LossAtt 0.2670 TrainAcc 0.7600 TestAcc 0.7713 0.7750
epoch 1800 LossPred 0.5925 LossAtt 0.2698 TrainAcc 0.7800 TestAcc 0.7888 0.7850
epoch 1900 LossPred 0.6118 LossAtt 0.2628 TrainAcc 0.7700 TestAcc 0.8028 0.7850
epoch 2000 LossPred 0.4687 LossAtt 0.2585 TrainAcc 0.8300 TestAcc 0.8526 0.8150
epoch 2100 LossPred 0.6025 LossAtt 0.2542 TrainAcc 0.7900 TestAcc 0.7868 0.7850
epoch 2200 LossPred 0.4915 LossAtt 0.2505 TrainAcc 0.8100 TestAcc 0.8368 0.8050
epoch 2300 LossPred 0.4260 LossAtt 0.2496 TrainAcc 0.8600 TestAcc 0.8819 0.8450
epoch 2400 LossPred 0.4377 LossAtt 0.2436 TrainAcc 0.8400 TestAcc 0.8831 0.8550
epoch 2500 LossPred 0.4843 LossAtt 0.2423 TrainAcc 0.8000 TestAcc 0.8431 0.8100
Optimization Finished!
********** replication  68  **********
epoch   0 LossPred 0.8950 LossAtt 0.9940 TrainAcc 0.7200 TestAcc 0.5796 0.7100
epoch 100 LossPred 0.7853 LossAtt 0.4552 TrainAcc 0.7200 TestAcc 0.5886 0.7200
epoch 200 LossPred 0.7304 LossAtt 0.4503 TrainAcc 0.7200 TestAcc 0.5886 0.7200
epoch 300 LossPred 0.6974 LossAtt 0.3845 TrainAcc 0.7800 TestAcc 0.6016 0.7650
epoch 400 LossPred 0.6791 LossAtt 0.3249 TrainAcc 0.7800 TestAcc 0.6016 0.7800
epoch 500 LossPred 0.6632 LossAtt 0.2931 TrainAcc 0.7800 TestAcc 0.6016 0.7750
epoch 600 LossPred 0.6493 LossAtt 0.3038 TrainAcc 0.7800 TestAcc 0.5971 0.7850
epoch 700 LossPred 0.6338 LossAtt 0.2935 TrainAcc 0.7800 TestAcc 0.5771 0.7800
epoch 800 LossPred 0.6248 LossAtt 0.3169 TrainAcc 0.7900 TestAcc 0.5836 0.8000
epoch 900 LossPred 0.6157 LossAtt 0.2747 TrainAcc 0.7900 TestAcc 0.5826 0.7950
epoch 1000 LossPred 0.6102 LossAtt 0.2973 TrainAcc 0.8000 TestAcc 0.5728 0.8000
epoch 1100 LossPred 0.6076 LossAtt 0.2930 TrainAcc 0.8000 TestAcc 0.5748 0.8000
epoch 1200 LossPred 0.6064 LossAtt 0.2871 TrainAcc 0.8000 TestAcc 0.5746 0.7950
epoch 1300 LossPred 0.6105 LossAtt 0.2929 TrainAcc 0.8100 TestAcc 0.5748 0.7900
epoch 1400 LossPred 0.6171 LossAtt 0.3048 TrainAcc 0.7800 TestAcc 0.5733 0.7900
epoch 1500 LossPred 0.6124 LossAtt 0.2965 TrainAcc 0.7900 TestAcc 0.5786 0.7950
epoch 1600 LossPred 0.6038 LossAtt 0.3094 TrainAcc 0.8100 TestAcc 0.5738 0.8000
epoch 1700 LossPred 0.5980 LossAtt 0.3247 TrainAcc 0.8100 TestAcc 0.5783 0.8000
epoch 1800 LossPred 0.6095 LossAtt 0.3566 TrainAcc 0.7800 TestAcc 0.5831 0.7850
epoch 1900 LossPred 0.5724 LossAtt 0.3773 TrainAcc 0.8100 TestAcc 0.5778 0.8200
epoch 2000 LossPred 0.6223 LossAtt 0.3800 TrainAcc 0.7900 TestAcc 0.5816 0.7850
epoch 2100 LossPred 0.5782 LossAtt 0.3423 TrainAcc 0.8000 TestAcc 0.5693 0.8050
epoch 2200 LossPred 0.5711 LossAtt 0.3302 TrainAcc 0.8200 TestAcc 0.5816 0.8150
epoch 2300 LossPred 0.5704 LossAtt 0.3222 TrainAcc 0.8100 TestAcc 0.5693 0.7950
epoch 2400 LossPred 0.5646 LossAtt 0.3242 TrainAcc 0.8100 TestAcc 0.5771 0.8000
epoch 2500 LossPred 0.5712 LossAtt 0.3389 TrainAcc 0.8200 TestAcc 0.5821 0.8150
Optimization Finished!
********** replication  69  **********
epoch   0 LossPred 1.3777 LossAtt 1.0383 TrainAcc 0.4600 TestAcc 0.4595 0.4500
epoch 100 LossPred 1.0892 LossAtt 0.4347 TrainAcc 0.4600 TestAcc 0.4550 0.4750
epoch 200 LossPred 0.9800 LossAtt 0.3517 TrainAcc 0.6000 TestAcc 0.5265 0.5850
epoch 300 LossPred 0.9318 LossAtt 0.3590 TrainAcc 0.5900 TestAcc 0.5548 0.5950
epoch 400 LossPred 0.9069 LossAtt 0.3568 TrainAcc 0.6600 TestAcc 0.6174 0.6800
epoch 500 LossPred 0.8916 LossAtt 0.3695 TrainAcc 0.6600 TestAcc 0.6229 0.6800
epoch 600 LossPred 0.8876 LossAtt 0.4030 TrainAcc 0.6500 TestAcc 0.6234 0.6550
epoch 700 LossPred 0.8757 LossAtt 0.3867 TrainAcc 0.6500 TestAcc 0.6199 0.6750
epoch 800 LossPred 0.8546 LossAtt 0.3881 TrainAcc 0.6800 TestAcc 0.6286 0.6700
epoch 900 LossPred 0.8422 LossAtt 0.3409 TrainAcc 0.6800 TestAcc 0.6306 0.6750
epoch 1000 LossPred 0.8169 LossAtt 0.4056 TrainAcc 0.6800 TestAcc 0.6309 0.6850
epoch 1100 LossPred 0.7302 LossAtt 0.4375 TrainAcc 0.7500 TestAcc 0.6667 0.7450
epoch 1200 LossPred 0.6667 LossAtt 0.4722 TrainAcc 0.7400 TestAcc 0.7062 0.7650
epoch 1300 LossPred 0.6430 LossAtt 0.5028 TrainAcc 0.7600 TestAcc 0.7392 0.7900
epoch 1400 LossPred 0.3832 LossAtt 0.5104 TrainAcc 0.8600 TestAcc 0.7978 0.8500
epoch 1500 LossPred 0.4604 LossAtt 0.5068 TrainAcc 0.8400 TestAcc 0.7700 0.8500
epoch 1600 LossPred 0.5835 LossAtt 0.4971 TrainAcc 0.7700 TestAcc 0.7330 0.7900
epoch 1700 LossPred 0.4510 LossAtt 0.4949 TrainAcc 0.8200 TestAcc 0.7875 0.8500
epoch 1800 LossPred 0.3736 LossAtt 0.4966 TrainAcc 0.8500 TestAcc 0.7885 0.8500
epoch 1900 LossPred 0.3978 LossAtt 0.4831 TrainAcc 0.8400 TestAcc 0.7790 0.8550
epoch 2000 LossPred 0.5703 LossAtt 0.4735 TrainAcc 0.7900 TestAcc 0.7513 0.8000
epoch 2100 LossPred 0.4641 LossAtt 0.4960 TrainAcc 0.8200 TestAcc 0.7970 0.8450
epoch 2200 LossPred 0.4078 LossAtt 0.4763 TrainAcc 0.8400 TestAcc 0.7903 0.8550
epoch 2300 LossPred 0.3416 LossAtt 0.4868 TrainAcc 0.8700 TestAcc 0.7923 0.8700
epoch 2400 LossPred 0.4308 LossAtt 0.5031 TrainAcc 0.8300 TestAcc 0.7835 0.8750
epoch 2500 LossPred 0.3627 LossAtt 0.4796 TrainAcc 0.8600 TestAcc 0.8003 0.8500
Optimization Finished!
********** replication  70  **********
epoch   0 LossPred 1.1213 LossAtt 1.0177 TrainAcc 0.5600 TestAcc 0.5385 0.5600
epoch 100 LossPred 0.9485 LossAtt 0.4938 TrainAcc 0.5900 TestAcc 0.5533 0.5950
epoch 200 LossPred 0.9167 LossAtt 0.4273 TrainAcc 0.6400 TestAcc 0.5756 0.6400
epoch 300 LossPred 0.8927 LossAtt 0.4334 TrainAcc 0.6400 TestAcc 0.5756 0.6400
epoch 400 LossPred 0.7989 LossAtt 0.4844 TrainAcc 0.7400 TestAcc 0.6649 0.7000
epoch 500 LossPred 0.7963 LossAtt 0.4720 TrainAcc 0.6900 TestAcc 0.6254 0.7050
epoch 600 LossPred 0.5314 LossAtt 0.3887 TrainAcc 0.8400 TestAcc 0.7920 0.8100
epoch 700 LossPred 0.4334 LossAtt 0.3781 TrainAcc 0.8500 TestAcc 0.8176 0.8600
epoch 800 LossPred 0.4000 LossAtt 0.3743 TrainAcc 0.8800 TestAcc 0.8338 0.8500
epoch 900 LossPred 0.3821 LossAtt 0.3712 TrainAcc 0.8500 TestAcc 0.8293 0.8650
epoch 1000 LossPred 0.3980 LossAtt 0.3725 TrainAcc 0.8800 TestAcc 0.8248 0.8500
epoch 1100 LossPred 0.3704 LossAtt 0.3568 TrainAcc 0.9000 TestAcc 0.8206 0.8500
epoch 1200 LossPred 0.3630 LossAtt 0.3706 TrainAcc 0.8700 TestAcc 0.8358 0.8800
epoch 1300 LossPred 0.3493 LossAtt 0.3705 TrainAcc 0.8700 TestAcc 0.8381 0.8750
epoch 1400 LossPred 0.3659 LossAtt 0.3538 TrainAcc 0.8700 TestAcc 0.8293 0.8700
epoch 1500 LossPred 0.3820 LossAtt 0.3614 TrainAcc 0.8800 TestAcc 0.8383 0.8450
epoch 1600 LossPred 0.5276 LossAtt 0.3751 TrainAcc 0.8200 TestAcc 0.8133 0.8250
epoch 1700 LossPred 0.4542 LossAtt 0.3546 TrainAcc 0.8300 TestAcc 0.7933 0.8150
epoch 1800 LossPred 0.4010 LossAtt 0.3613 TrainAcc 0.8500 TestAcc 0.8271 0.8550
epoch 1900 LossPred 0.4098 LossAtt 0.3440 TrainAcc 0.8700 TestAcc 0.8346 0.8550
epoch 2000 LossPred 0.4587 LossAtt 0.3262 TrainAcc 0.8500 TestAcc 0.7870 0.8200
epoch 2100 LossPred 0.3485 LossAtt 0.3392 TrainAcc 0.8800 TestAcc 0.8106 0.8600
epoch 2200 LossPred 0.3603 LossAtt 0.3590 TrainAcc 0.8700 TestAcc 0.8161 0.8600
epoch 2300 LossPred 0.6048 LossAtt 0.3496 TrainAcc 0.8000 TestAcc 0.7573 0.7800
epoch 2400 LossPred 0.4869 LossAtt 0.3386 TrainAcc 0.8500 TestAcc 0.8008 0.8300
epoch 2500 LossPred 0.3644 LossAtt 0.3462 TrainAcc 0.8600 TestAcc 0.8246 0.8650
Optimization Finished!
********** replication  71  **********
epoch   0 LossPred 1.1580 LossAtt 0.9975 TrainAcc 0.5000 TestAcc 0.5343 0.4850
epoch 100 LossPred 0.9830 LossAtt 0.4085 TrainAcc 0.5900 TestAcc 0.5110 0.5800
epoch 200 LossPred 0.9741 LossAtt 0.2769 TrainAcc 0.5900 TestAcc 0.5110 0.5950
epoch 300 LossPred 0.9651 LossAtt 0.2550 TrainAcc 0.5900 TestAcc 0.5110 0.5900
epoch 400 LossPred 0.9470 LossAtt 0.2817 TrainAcc 0.5900 TestAcc 0.5110 0.5900
epoch 500 LossPred 0.9067 LossAtt 0.4200 TrainAcc 0.6600 TestAcc 0.5343 0.6550
epoch 600 LossPred 0.8082 LossAtt 0.5659 TrainAcc 0.7100 TestAcc 0.5323 0.7050
epoch 700 LossPred 0.7488 LossAtt 0.5762 TrainAcc 0.7200 TestAcc 0.5238 0.7250
epoch 800 LossPred 0.7359 LossAtt 0.6018 TrainAcc 0.7200 TestAcc 0.5265 0.7150
epoch 900 LossPred 0.6980 LossAtt 0.5904 TrainAcc 0.7200 TestAcc 0.5443 0.7100
epoch 1000 LossPred 0.6809 LossAtt 0.5956 TrainAcc 0.7700 TestAcc 0.5428 0.7100
epoch 1100 LossPred 0.6691 LossAtt 0.5874 TrainAcc 0.7700 TestAcc 0.5475 0.7200
epoch 1200 LossPred 0.6679 LossAtt 0.5839 TrainAcc 0.7600 TestAcc 0.5711 0.7200
epoch 1300 LossPred 0.7272 LossAtt 0.5801 TrainAcc 0.7400 TestAcc 0.5450 0.7100
epoch 1400 LossPred 0.6839 LossAtt 0.5861 TrainAcc 0.7600 TestAcc 0.5516 0.7300
epoch 1500 LossPred 0.6597 LossAtt 0.5806 TrainAcc 0.7400 TestAcc 0.5503 0.7200
epoch 1600 LossPred 0.6513 LossAtt 0.5769 TrainAcc 0.7600 TestAcc 0.5561 0.7450
epoch 1700 LossPred 0.6906 LossAtt 0.5855 TrainAcc 0.7400 TestAcc 0.5538 0.7350
epoch 1800 LossPred 0.6875 LossAtt 0.5826 TrainAcc 0.7500 TestAcc 0.6009 0.7400
epoch 1900 LossPred 0.7176 LossAtt 0.5739 TrainAcc 0.7200 TestAcc 0.5801 0.7400
epoch 2000 LossPred 0.6818 LossAtt 0.5781 TrainAcc 0.7800 TestAcc 0.5951 0.7350
epoch 2100 LossPred 0.6705 LossAtt 0.5442 TrainAcc 0.7400 TestAcc 0.5666 0.7150
epoch 2200 LossPred 0.6760 LossAtt 0.5649 TrainAcc 0.7600 TestAcc 0.5643 0.7250
epoch 2300 LossPred 0.6879 LossAtt 0.5921 TrainAcc 0.7600 TestAcc 0.5468 0.7200
epoch 2400 LossPred 0.6627 LossAtt 0.5770 TrainAcc 0.7300 TestAcc 0.5503 0.7200
epoch 2500 LossPred 0.6481 LossAtt 0.5769 TrainAcc 0.7400 TestAcc 0.5453 0.7200
Optimization Finished!
********** replication  72  **********
epoch   0 LossPred 0.9655 LossAtt 0.9839 TrainAcc 0.6200 TestAcc 0.5398 0.6000
epoch 100 LossPred 0.8338 LossAtt 0.3819 TrainAcc 0.6900 TestAcc 0.5726 0.6900
epoch 200 LossPred 0.8112 LossAtt 0.2710 TrainAcc 0.6900 TestAcc 0.5726 0.6900
epoch 300 LossPred 0.7921 LossAtt 0.3071 TrainAcc 0.6900 TestAcc 0.5726 0.6900
epoch 400 LossPred 0.7195 LossAtt 0.3905 TrainAcc 0.7300 TestAcc 0.6847 0.7250
epoch 500 LossPred 0.4732 LossAtt 0.3516 TrainAcc 0.8200 TestAcc 0.7960 0.8150
epoch 600 LossPred 0.4738 LossAtt 0.3555 TrainAcc 0.8500 TestAcc 0.7295 0.8100
epoch 700 LossPred 0.5009 LossAtt 0.3438 TrainAcc 0.8200 TestAcc 0.7925 0.8100
epoch 800 LossPred 0.4370 LossAtt 0.3518 TrainAcc 0.8200 TestAcc 0.7823 0.8350
epoch 900 LossPred 0.6591 LossAtt 0.3738 TrainAcc 0.7600 TestAcc 0.7130 0.7500
epoch 1000 LossPred 0.4947 LossAtt 0.3630 TrainAcc 0.8100 TestAcc 0.8063 0.8150
epoch 1100 LossPred 0.4264 LossAtt 0.3838 TrainAcc 0.8600 TestAcc 0.7628 0.8550
epoch 1200 LossPred 0.8256 LossAtt 0.3820 TrainAcc 0.6900 TestAcc 0.6662 0.6800
epoch 1300 LossPred 0.7079 LossAtt 0.3549 TrainAcc 0.7300 TestAcc 0.6719 0.7550
epoch 1400 LossPred 0.6147 LossAtt 0.3887 TrainAcc 0.8000 TestAcc 0.6954 0.7750
epoch 1500 LossPred 0.5879 LossAtt 0.4025 TrainAcc 0.8100 TestAcc 0.7055 0.7950
epoch 1600 LossPred 0.5505 LossAtt 0.3986 TrainAcc 0.8300 TestAcc 0.7255 0.8050
epoch 1700 LossPred 0.4900 LossAtt 0.4071 TrainAcc 0.8200 TestAcc 0.7830 0.8600
epoch 1800 LossPred 0.4248 LossAtt 0.4213 TrainAcc 0.8400 TestAcc 0.7955 0.8650
epoch 1900 LossPred 0.4539 LossAtt 0.4134 TrainAcc 0.8400 TestAcc 0.7868 0.8550
epoch 2000 LossPred 0.4653 LossAtt 0.4349 TrainAcc 0.8200 TestAcc 0.7943 0.8600
epoch 2100 LossPred 0.4186 LossAtt 0.4409 TrainAcc 0.8200 TestAcc 0.8078 0.8600
epoch 2200 LossPred 0.4172 LossAtt 0.4618 TrainAcc 0.8400 TestAcc 0.7965 0.8500
epoch 2300 LossPred 0.3986 LossAtt 0.4536 TrainAcc 0.8800 TestAcc 0.8436 0.8550
epoch 2400 LossPred 0.4045 LossAtt 0.4693 TrainAcc 0.8700 TestAcc 0.8118 0.8600
epoch 2500 LossPred 0.3573 LossAtt 0.4770 TrainAcc 0.8800 TestAcc 0.8636 0.8400
Optimization Finished!
********** replication  73  **********
epoch   0 LossPred 0.9906 LossAtt 1.0061 TrainAcc 0.5600 TestAcc 0.5596 0.5800
epoch 100 LossPred 0.8917 LossAtt 0.2931 TrainAcc 0.6500 TestAcc 0.4932 0.6500
epoch 200 LossPred 0.8888 LossAtt 0.1629 TrainAcc 0.6500 TestAcc 0.4932 0.6500
epoch 300 LossPred 0.8848 LossAtt 0.1875 TrainAcc 0.6500 TestAcc 0.4932 0.6500
epoch 400 LossPred 0.8547 LossAtt 0.3077 TrainAcc 0.6500 TestAcc 0.5400 0.6550
epoch 500 LossPred 0.3786 LossAtt 0.2574 TrainAcc 0.8600 TestAcc 0.8594 0.8750
epoch 600 LossPred 0.3923 LossAtt 0.2598 TrainAcc 0.8700 TestAcc 0.8509 0.8600
epoch 700 LossPred 0.3861 LossAtt 0.2306 TrainAcc 0.8600 TestAcc 0.8448 0.8550
epoch 800 LossPred 0.4549 LossAtt 0.2399 TrainAcc 0.8400 TestAcc 0.8173 0.8400
epoch 900 LossPred 0.3802 LossAtt 0.2400 TrainAcc 0.8800 TestAcc 0.8599 0.8800
epoch 1000 LossPred 0.5743 LossAtt 0.2406 TrainAcc 0.7800 TestAcc 0.7820 0.7550
epoch 1100 LossPred 0.6319 LossAtt 0.2355 TrainAcc 0.8000 TestAcc 0.7067 0.8000
epoch 1200 LossPred 0.4034 LossAtt 0.2394 TrainAcc 0.8400 TestAcc 0.8639 0.8550
epoch 1300 LossPred 0.3931 LossAtt 0.2304 TrainAcc 0.8500 TestAcc 0.8606 0.8450
epoch 1400 LossPred 0.3805 LossAtt 0.2218 TrainAcc 0.8900 TestAcc 0.8363 0.8650
epoch 1500 LossPred 0.3797 LossAtt 0.2247 TrainAcc 0.8800 TestAcc 0.8774 0.8600
epoch 1600 LossPred 0.3892 LossAtt 0.2033 TrainAcc 0.8700 TestAcc 0.8483 0.8700
epoch 1700 LossPred 0.4096 LossAtt 0.2179 TrainAcc 0.8700 TestAcc 0.8564 0.8750
epoch 1800 LossPred 0.8766 LossAtt 0.2130 TrainAcc 0.7200 TestAcc 0.5748 0.7050
epoch 1900 LossPred 0.4858 LossAtt 0.2170 TrainAcc 0.8500 TestAcc 0.8076 0.8400
epoch 2000 LossPred 0.4560 LossAtt 0.2167 TrainAcc 0.8400 TestAcc 0.8551 0.8450
epoch 2100 LossPred 0.4170 LossAtt 0.2058 TrainAcc 0.8400 TestAcc 0.8571 0.8650
epoch 2200 LossPred 0.4052 LossAtt 0.1966 TrainAcc 0.8700 TestAcc 0.8173 0.8500
epoch 2300 LossPred 0.3959 LossAtt 0.1994 TrainAcc 0.8600 TestAcc 0.8559 0.8850
epoch 2400 LossPred 0.4199 LossAtt 0.1937 TrainAcc 0.8800 TestAcc 0.8468 0.8600
epoch 2500 LossPred 0.4194 LossAtt 0.2065 TrainAcc 0.8400 TestAcc 0.8483 0.8650
Optimization Finished!
********** replication  74  **********
epoch   0 LossPred 1.1000 LossAtt 0.9914 TrainAcc 0.4000 TestAcc 0.4717 0.4150
epoch 100 LossPred 0.9587 LossAtt 0.3867 TrainAcc 0.5700 TestAcc 0.5093 0.5700
epoch 200 LossPred 0.9386 LossAtt 0.4156 TrainAcc 0.5900 TestAcc 0.5393 0.6000
epoch 300 LossPred 0.9356 LossAtt 0.4116 TrainAcc 0.5800 TestAcc 0.5360 0.5850
epoch 400 LossPred 0.9197 LossAtt 0.4473 TrainAcc 0.5700 TestAcc 0.5483 0.5800
epoch 500 LossPred 0.5411 LossAtt 0.4725 TrainAcc 0.8500 TestAcc 0.7738 0.8600
epoch 600 LossPred 0.3541 LossAtt 0.4174 TrainAcc 0.9300 TestAcc 0.7983 0.9150
epoch 700 LossPred 0.3855 LossAtt 0.4023 TrainAcc 0.9000 TestAcc 0.7953 0.9000
epoch 800 LossPred 0.4850 LossAtt 0.4298 TrainAcc 0.8600 TestAcc 0.7623 0.8750
epoch 900 LossPred 0.3377 LossAtt 0.4101 TrainAcc 0.8900 TestAcc 0.7998 0.8850
epoch 1000 LossPred 0.6127 LossAtt 0.4120 TrainAcc 0.8100 TestAcc 0.6944 0.8150
epoch 1100 LossPred 0.3568 LossAtt 0.4051 TrainAcc 0.8900 TestAcc 0.7755 0.8900
epoch 1200 LossPred 0.3458 LossAtt 0.4166 TrainAcc 0.9100 TestAcc 0.7845 0.8950
epoch 1300 LossPred 0.3698 LossAtt 0.3892 TrainAcc 0.9000 TestAcc 0.7868 0.9050
epoch 1400 LossPred 0.2871 LossAtt 0.4065 TrainAcc 0.9300 TestAcc 0.7895 0.9150
epoch 1500 LossPred 0.4361 LossAtt 0.4078 TrainAcc 0.8800 TestAcc 0.7565 0.8800
epoch 1600 LossPred 0.2831 LossAtt 0.3975 TrainAcc 0.9200 TestAcc 0.7858 0.8950
epoch 1700 LossPred 0.3715 LossAtt 0.4034 TrainAcc 0.8700 TestAcc 0.7960 0.8600
epoch 1800 LossPred 0.5540 LossAtt 0.3942 TrainAcc 0.8300 TestAcc 0.7005 0.8300
epoch 1900 LossPred 0.2576 LossAtt 0.3908 TrainAcc 0.9300 TestAcc 0.7908 0.9250
epoch 2000 LossPred 0.3153 LossAtt 0.3860 TrainAcc 0.9200 TestAcc 0.7910 0.9100
epoch 2100 LossPred 0.3206 LossAtt 0.3786 TrainAcc 0.9200 TestAcc 0.7850 0.9050
epoch 2200 LossPred 0.3916 LossAtt 0.3985 TrainAcc 0.8700 TestAcc 0.7710 0.8750
epoch 2300 LossPred 0.2595 LossAtt 0.3836 TrainAcc 0.9400 TestAcc 0.7905 0.9200
epoch 2400 LossPred 0.2504 LossAtt 0.3970 TrainAcc 0.9300 TestAcc 0.7898 0.9200
epoch 2500 LossPred 0.2805 LossAtt 0.3984 TrainAcc 0.9200 TestAcc 0.7860 0.9150
Optimization Finished!
********** replication  75  **********
epoch   0 LossPred 1.3594 LossAtt 1.0094 TrainAcc 0.4400 TestAcc 0.5018 0.4200
epoch 100 LossPred 1.0400 LossAtt 0.4822 TrainAcc 0.5200 TestAcc 0.4094 0.5000
epoch 200 LossPred 0.9702 LossAtt 0.5008 TrainAcc 0.6100 TestAcc 0.4319 0.5850
epoch 300 LossPred 0.9304 LossAtt 0.5101 TrainAcc 0.6500 TestAcc 0.4927 0.6400
epoch 400 LossPred 0.9018 LossAtt 0.4975 TrainAcc 0.6700 TestAcc 0.5073 0.6500
epoch 500 LossPred 0.8814 LossAtt 0.4489 TrainAcc 0.6700 TestAcc 0.5218 0.6650
epoch 600 LossPred 0.8684 LossAtt 0.3758 TrainAcc 0.6800 TestAcc 0.5335 0.6750
epoch 700 LossPred 0.8536 LossAtt 0.3602 TrainAcc 0.6800 TestAcc 0.5335 0.6800
epoch 800 LossPred 0.8418 LossAtt 0.3532 TrainAcc 0.6800 TestAcc 0.5333 0.6800
epoch 900 LossPred 0.8360 LossAtt 0.3513 TrainAcc 0.6800 TestAcc 0.5345 0.6600
epoch 1000 LossPred 0.8232 LossAtt 0.4046 TrainAcc 0.6800 TestAcc 0.5343 0.6700
epoch 1100 LossPred 0.8083 LossAtt 0.4561 TrainAcc 0.6800 TestAcc 0.5335 0.6750
epoch 1200 LossPred 0.7926 LossAtt 0.4972 TrainAcc 0.6900 TestAcc 0.5621 0.6950
epoch 1300 LossPred 0.7784 LossAtt 0.5599 TrainAcc 0.6900 TestAcc 0.5551 0.6850
epoch 1400 LossPred 0.7607 LossAtt 0.5388 TrainAcc 0.7200 TestAcc 0.5543 0.6950
epoch 1500 LossPred 0.7438 LossAtt 0.5321 TrainAcc 0.7100 TestAcc 0.5566 0.6950
epoch 1600 LossPred 0.7293 LossAtt 0.5436 TrainAcc 0.7300 TestAcc 0.5335 0.7100
epoch 1700 LossPred 0.7001 LossAtt 0.5684 TrainAcc 0.7200 TestAcc 0.5435 0.7200
epoch 1800 LossPred 0.6757 LossAtt 0.5887 TrainAcc 0.7500 TestAcc 0.5285 0.7600
epoch 1900 LossPred 0.6673 LossAtt 0.5420 TrainAcc 0.8000 TestAcc 0.5245 0.7700
epoch 2000 LossPred 0.6577 LossAtt 0.5418 TrainAcc 0.8100 TestAcc 0.5280 0.7600
epoch 2100 LossPred 0.6711 LossAtt 0.5302 TrainAcc 0.8100 TestAcc 0.5345 0.7650
epoch 2200 LossPred 0.6631 LossAtt 0.5194 TrainAcc 0.8200 TestAcc 0.5290 0.7600
epoch 2300 LossPred 0.6617 LossAtt 0.5023 TrainAcc 0.8000 TestAcc 0.5313 0.7350
epoch 2400 LossPred 0.6572 LossAtt 0.4997 TrainAcc 0.7800 TestAcc 0.5295 0.7650
epoch 2500 LossPred 0.6544 LossAtt 0.5115 TrainAcc 0.8000 TestAcc 0.5248 0.7600
Optimization Finished!
********** replication  76  **********
epoch   0 LossPred 0.9987 LossAtt 0.9674 TrainAcc 0.6000 TestAcc 0.5548 0.5550
epoch 100 LossPred 0.9103 LossAtt 0.5381 TrainAcc 0.6100 TestAcc 0.5858 0.6250
epoch 200 LossPred 0.8861 LossAtt 0.5107 TrainAcc 0.6200 TestAcc 0.5996 0.6300
epoch 300 LossPred 0.8153 LossAtt 0.4482 TrainAcc 0.6900 TestAcc 0.6589 0.6450
epoch 400 LossPred 0.5360 LossAtt 0.3360 TrainAcc 0.8400 TestAcc 0.8083 0.7950
epoch 500 LossPred 0.4614 LossAtt 0.3545 TrainAcc 0.8400 TestAcc 0.7973 0.7850
epoch 600 LossPred 0.5877 LossAtt 0.3157 TrainAcc 0.8100 TestAcc 0.7955 0.7750
epoch 700 LossPred 0.5758 LossAtt 0.3156 TrainAcc 0.8200 TestAcc 0.8028 0.7850
epoch 800 LossPred 0.5924 LossAtt 0.2868 TrainAcc 0.8100 TestAcc 0.7898 0.7750
epoch 900 LossPred 0.6485 LossAtt 0.3064 TrainAcc 0.7800 TestAcc 0.7695 0.7550
epoch 1000 LossPred 0.5529 LossAtt 0.3013 TrainAcc 0.8200 TestAcc 0.8053 0.7950
epoch 1100 LossPred 0.5597 LossAtt 0.3126 TrainAcc 0.8300 TestAcc 0.7993 0.7900
epoch 1200 LossPred 0.5644 LossAtt 0.2920 TrainAcc 0.8000 TestAcc 0.7998 0.7750
epoch 1300 LossPred 0.7193 LossAtt 0.3095 TrainAcc 0.7400 TestAcc 0.7310 0.6950
epoch 1400 LossPred 0.6936 LossAtt 0.3030 TrainAcc 0.7700 TestAcc 0.7518 0.7200
epoch 1500 LossPred 0.6129 LossAtt 0.3164 TrainAcc 0.8000 TestAcc 0.7765 0.7550
epoch 1600 LossPred 0.5941 LossAtt 0.3139 TrainAcc 0.8100 TestAcc 0.7893 0.7650
epoch 1700 LossPred 0.6147 LossAtt 0.3071 TrainAcc 0.8100 TestAcc 0.7930 0.7500
epoch 1800 LossPred 0.5898 LossAtt 0.3029 TrainAcc 0.8100 TestAcc 0.7863 0.7900
epoch 1900 LossPred 0.5994 LossAtt 0.3243 TrainAcc 0.8100 TestAcc 0.7785 0.7800
epoch 2000 LossPred 0.5806 LossAtt 0.3098 TrainAcc 0.8300 TestAcc 0.7913 0.7450
epoch 2100 LossPred 0.5239 LossAtt 0.3123 TrainAcc 0.8600 TestAcc 0.8018 0.8100
epoch 2200 LossPred 0.5763 LossAtt 0.3351 TrainAcc 0.8300 TestAcc 0.8038 0.8000
epoch 2300 LossPred 0.4767 LossAtt 0.3626 TrainAcc 0.8800 TestAcc 0.8018 0.8050
epoch 2400 LossPred 0.4603 LossAtt 0.3780 TrainAcc 0.8600 TestAcc 0.8078 0.7900
epoch 2500 LossPred 0.5245 LossAtt 0.3791 TrainAcc 0.8700 TestAcc 0.7908 0.7950
Optimization Finished!
********** replication  77  **********
epoch   0 LossPred 0.9548 LossAtt 0.9997 TrainAcc 0.6000 TestAcc 0.5658 0.6000
epoch 100 LossPred 0.8782 LossAtt 0.5105 TrainAcc 0.6600 TestAcc 0.5803 0.6800
epoch 200 LossPred 0.8564 LossAtt 0.5113 TrainAcc 0.6600 TestAcc 0.5803 0.6700
epoch 300 LossPred 0.6158 LossAtt 0.5913 TrainAcc 0.8100 TestAcc 0.7447 0.7950
epoch 400 LossPred 0.4954 LossAtt 0.5389 TrainAcc 0.8200 TestAcc 0.8043 0.8300
epoch 500 LossPred 0.3972 LossAtt 0.5218 TrainAcc 0.8800 TestAcc 0.8559 0.9000
epoch 600 LossPred 0.3422 LossAtt 0.4431 TrainAcc 0.8900 TestAcc 0.8629 0.8950
epoch 700 LossPred 0.3298 LossAtt 0.4231 TrainAcc 0.8900 TestAcc 0.8438 0.8900
epoch 800 LossPred 0.3212 LossAtt 0.4305 TrainAcc 0.9000 TestAcc 0.8806 0.9050
epoch 900 LossPred 0.5028 LossAtt 0.4222 TrainAcc 0.8300 TestAcc 0.7575 0.8300
epoch 1000 LossPred 0.5300 LossAtt 0.4349 TrainAcc 0.8200 TestAcc 0.7673 0.8100
epoch 1100 LossPred 0.4493 LossAtt 0.4130 TrainAcc 0.8700 TestAcc 0.8058 0.8700
epoch 1200 LossPred 0.4749 LossAtt 0.4283 TrainAcc 0.8300 TestAcc 0.7830 0.8250
epoch 1300 LossPred 0.3694 LossAtt 0.4236 TrainAcc 0.8900 TestAcc 0.8473 0.9000
epoch 1400 LossPred 0.3449 LossAtt 0.4080 TrainAcc 0.9000 TestAcc 0.8669 0.9050
epoch 1500 LossPred 0.3968 LossAtt 0.4111 TrainAcc 0.8600 TestAcc 0.8321 0.8800
epoch 1600 LossPred 0.4702 LossAtt 0.4075 TrainAcc 0.8500 TestAcc 0.7878 0.8550
epoch 1700 LossPred 0.3545 LossAtt 0.3972 TrainAcc 0.8800 TestAcc 0.8576 0.8750
epoch 1800 LossPred 0.5396 LossAtt 0.4147 TrainAcc 0.8300 TestAcc 0.7595 0.8250
epoch 1900 LossPred 0.5959 LossAtt 0.3769 TrainAcc 0.8100 TestAcc 0.7492 0.7900
epoch 2000 LossPred 0.4867 LossAtt 0.3977 TrainAcc 0.8400 TestAcc 0.7853 0.8450
epoch 2100 LossPred 0.4271 LossAtt 0.3972 TrainAcc 0.8500 TestAcc 0.8001 0.8600
epoch 2200 LossPred 0.3368 LossAtt 0.4146 TrainAcc 0.8900 TestAcc 0.8266 0.8800
epoch 2300 LossPred 0.4589 LossAtt 0.4043 TrainAcc 0.8400 TestAcc 0.7828 0.8400
epoch 2400 LossPred 0.5647 LossAtt 0.4050 TrainAcc 0.8000 TestAcc 0.7528 0.8050
epoch 2500 LossPred 0.3096 LossAtt 0.4211 TrainAcc 0.9200 TestAcc 0.8373 0.8950
Optimization Finished!
********** replication  78  **********
epoch   0 LossPred 1.0238 LossAtt 0.9819 TrainAcc 0.5600 TestAcc 0.5528 0.5800
epoch 100 LossPred 0.8974 LossAtt 0.3996 TrainAcc 0.6600 TestAcc 0.5936 0.6750
epoch 200 LossPred 0.8383 LossAtt 0.3629 TrainAcc 0.7000 TestAcc 0.6236 0.7250
epoch 300 LossPred 0.7657 LossAtt 0.2782 TrainAcc 0.7200 TestAcc 0.7072 0.7100
epoch 400 LossPred 0.6900 LossAtt 0.2696 TrainAcc 0.7700 TestAcc 0.7375 0.7750
epoch 500 LossPred 0.6658 LossAtt 0.2489 TrainAcc 0.8000 TestAcc 0.7520 0.8300
epoch 600 LossPred 0.5622 LossAtt 0.2757 TrainAcc 0.8200 TestAcc 0.8033 0.8200
epoch 700 LossPred 0.6913 LossAtt 0.2905 TrainAcc 0.7500 TestAcc 0.7360 0.7100
epoch 800 LossPred 0.6060 LossAtt 0.2652 TrainAcc 0.7800 TestAcc 0.7665 0.7750
epoch 900 LossPred 0.6318 LossAtt 0.2745 TrainAcc 0.7500 TestAcc 0.7550 0.7600
epoch 1000 LossPred 0.6245 LossAtt 0.2706 TrainAcc 0.7600 TestAcc 0.7583 0.7550
epoch 1100 LossPred 0.6265 LossAtt 0.2647 TrainAcc 0.7600 TestAcc 0.7703 0.7450
epoch 1200 LossPred 0.6326 LossAtt 0.2635 TrainAcc 0.7400 TestAcc 0.7765 0.8050
epoch 1300 LossPred 0.5930 LossAtt 0.2565 TrainAcc 0.8200 TestAcc 0.8038 0.8300
epoch 1400 LossPred 0.7977 LossAtt 0.2547 TrainAcc 0.7100 TestAcc 0.7347 0.7000
epoch 1500 LossPred 0.6299 LossAtt 0.2460 TrainAcc 0.7900 TestAcc 0.7723 0.7800
epoch 1600 LossPred 0.6876 LossAtt 0.2650 TrainAcc 0.7300 TestAcc 0.7875 0.7150
epoch 1700 LossPred 0.6681 LossAtt 0.2526 TrainAcc 0.7400 TestAcc 0.7990 0.7550
epoch 1800 LossPred 0.6274 LossAtt 0.2628 TrainAcc 0.7700 TestAcc 0.7845 0.7800
epoch 1900 LossPred 0.6320 LossAtt 0.2667 TrainAcc 0.7600 TestAcc 0.7723 0.7500
epoch 2000 LossPred 0.6216 LossAtt 0.2826 TrainAcc 0.7600 TestAcc 0.7640 0.7400
epoch 2100 LossPred 0.8057 LossAtt 0.2307 TrainAcc 0.6800 TestAcc 0.6577 0.7050
epoch 2200 LossPred 0.7037 LossAtt 0.2485 TrainAcc 0.7100 TestAcc 0.6869 0.7050
epoch 2300 LossPred 0.6624 LossAtt 0.2355 TrainAcc 0.7700 TestAcc 0.7127 0.7500
epoch 2400 LossPred 0.6707 LossAtt 0.2381 TrainAcc 0.7400 TestAcc 0.7040 0.7200
epoch 2500 LossPred 0.6700 LossAtt 0.2372 TrainAcc 0.7400 TestAcc 0.7012 0.7200
Optimization Finished!
********** replication  79  **********
epoch   0 LossPred 1.1715 LossAtt 1.0308 TrainAcc 0.4400 TestAcc 0.4855 0.4600
epoch 100 LossPred 0.9418 LossAtt 0.4121 TrainAcc 0.6500 TestAcc 0.5901 0.6450
epoch 200 LossPred 0.8881 LossAtt 0.4281 TrainAcc 0.6000 TestAcc 0.5766 0.6450
epoch 300 LossPred 0.4696 LossAtt 0.4866 TrainAcc 0.8500 TestAcc 0.8416 0.8300
epoch 400 LossPred 0.4048 LossAtt 0.4430 TrainAcc 0.8600 TestAcc 0.8373 0.8500
epoch 500 LossPred 0.3415 LossAtt 0.3887 TrainAcc 0.9000 TestAcc 0.8486 0.8900
epoch 600 LossPred 0.4144 LossAtt 0.3801 TrainAcc 0.8400 TestAcc 0.8308 0.8550
epoch 700 LossPred 0.4605 LossAtt 0.3696 TrainAcc 0.8400 TestAcc 0.8123 0.8250
epoch 800 LossPred 0.3030 LossAtt 0.3744 TrainAcc 0.9100 TestAcc 0.8488 0.8700
epoch 900 LossPred 0.2787 LossAtt 0.3444 TrainAcc 0.9100 TestAcc 0.8483 0.8850
epoch 1000 LossPred 0.4031 LossAtt 0.3564 TrainAcc 0.8800 TestAcc 0.8326 0.8500
epoch 1100 LossPred 0.2847 LossAtt 0.3670 TrainAcc 0.9100 TestAcc 0.8509 0.8950
epoch 1200 LossPred 0.4764 LossAtt 0.3666 TrainAcc 0.8400 TestAcc 0.8126 0.8450
epoch 1300 LossPred 0.2951 LossAtt 0.3589 TrainAcc 0.9100 TestAcc 0.8453 0.8800
epoch 1400 LossPred 0.4077 LossAtt 0.3388 TrainAcc 0.8600 TestAcc 0.8298 0.8500
epoch 1500 LossPred 0.3053 LossAtt 0.3684 TrainAcc 0.9200 TestAcc 0.8436 0.8800
epoch 1600 LossPred 0.3421 LossAtt 0.3452 TrainAcc 0.9000 TestAcc 0.8423 0.8850
epoch 1700 LossPred 0.2857 LossAtt 0.3526 TrainAcc 0.9100 TestAcc 0.8473 0.8800
epoch 1800 LossPred 0.3360 LossAtt 0.3495 TrainAcc 0.8900 TestAcc 0.8408 0.9000
epoch 1900 LossPred 0.3007 LossAtt 0.3416 TrainAcc 0.9000 TestAcc 0.8443 0.8700
epoch 2000 LossPred 0.3842 LossAtt 0.3487 TrainAcc 0.8900 TestAcc 0.8308 0.8600
epoch 2100 LossPred 0.3133 LossAtt 0.3489 TrainAcc 0.9000 TestAcc 0.8433 0.8800
epoch 2200 LossPred 0.3931 LossAtt 0.3389 TrainAcc 0.8500 TestAcc 0.8316 0.8550
epoch 2300 LossPred 0.3300 LossAtt 0.3510 TrainAcc 0.9000 TestAcc 0.8398 0.8700
epoch 2400 LossPred 0.3026 LossAtt 0.3419 TrainAcc 0.8900 TestAcc 0.8431 0.8750
epoch 2500 LossPred 0.2819 LossAtt 0.3651 TrainAcc 0.9000 TestAcc 0.8496 0.8800
Optimization Finished!
********** replication  80  **********
epoch   0 LossPred 1.1405 LossAtt 1.0128 TrainAcc 0.4900 TestAcc 0.4447 0.4550
epoch 100 LossPred 0.9941 LossAtt 0.4782 TrainAcc 0.5000 TestAcc 0.4449 0.4950
epoch 200 LossPred 0.9361 LossAtt 0.4500 TrainAcc 0.5900 TestAcc 0.5168 0.5750
epoch 300 LossPred 0.9126 LossAtt 0.3729 TrainAcc 0.6200 TestAcc 0.5876 0.6200
epoch 400 LossPred 0.9008 LossAtt 0.2694 TrainAcc 0.6200 TestAcc 0.5876 0.6150
epoch 500 LossPred 0.8903 LossAtt 0.2179 TrainAcc 0.6200 TestAcc 0.5638 0.6500
epoch 600 LossPred 0.8886 LossAtt 0.1957 TrainAcc 0.6200 TestAcc 0.5638 0.6500
epoch 700 LossPred 0.8879 LossAtt 0.1618 TrainAcc 0.6200 TestAcc 0.5638 0.6300
epoch 800 LossPred 0.8874 LossAtt 0.1091 TrainAcc 0.6200 TestAcc 0.5638 0.6250
epoch 900 LossPred 0.8863 LossAtt 0.1365 TrainAcc 0.6200 TestAcc 0.5926 0.6300
epoch 1000 LossPred 0.8825 LossAtt 0.1782 TrainAcc 0.6200 TestAcc 0.5876 0.6250
epoch 1100 LossPred 0.8815 LossAtt 0.1752 TrainAcc 0.6200 TestAcc 0.5876 0.6350
epoch 1200 LossPred 0.8804 LossAtt 0.1930 TrainAcc 0.6200 TestAcc 0.5876 0.6200
epoch 1300 LossPred 0.9011 LossAtt 0.4687 TrainAcc 0.5800 TestAcc 0.6161 0.5800
epoch 1400 LossPred 0.6392 LossAtt 0.3589 TrainAcc 0.8100 TestAcc 0.7823 0.8100
epoch 1500 LossPred 0.5929 LossAtt 0.3245 TrainAcc 0.8100 TestAcc 0.7775 0.8150
epoch 1600 LossPred 0.5706 LossAtt 0.3236 TrainAcc 0.7900 TestAcc 0.7808 0.8250
epoch 1700 LossPred 0.5188 LossAtt 0.3379 TrainAcc 0.8400 TestAcc 0.8046 0.8000
epoch 1800 LossPred 0.5154 LossAtt 0.3313 TrainAcc 0.8200 TestAcc 0.8121 0.8000
epoch 1900 LossPred 0.5224 LossAtt 0.3058 TrainAcc 0.8200 TestAcc 0.8121 0.8100
epoch 2000 LossPred 0.5530 LossAtt 0.3232 TrainAcc 0.8100 TestAcc 0.8373 0.7900
epoch 2100 LossPred 0.5708 LossAtt 0.3138 TrainAcc 0.7800 TestAcc 0.8486 0.7900
epoch 2200 LossPred 0.5790 LossAtt 0.3121 TrainAcc 0.8000 TestAcc 0.7778 0.8100
epoch 2300 LossPred 0.4346 LossAtt 0.3446 TrainAcc 0.8400 TestAcc 0.8701 0.8200
epoch 2400 LossPred 0.8320 LossAtt 0.3846 TrainAcc 0.7300 TestAcc 0.7563 0.7150
epoch 2500 LossPred 0.5739 LossAtt 0.3130 TrainAcc 0.8100 TestAcc 0.7643 0.7950
Optimization Finished!
********** replication  81  **********
epoch   0 LossPred 1.2798 LossAtt 1.0052 TrainAcc 0.3700 TestAcc 0.4595 0.3700
epoch 100 LossPred 0.9240 LossAtt 0.4039 TrainAcc 0.5700 TestAcc 0.5000 0.5900
epoch 200 LossPred 0.9076 LossAtt 0.2163 TrainAcc 0.6100 TestAcc 0.5078 0.6100
epoch 300 LossPred 0.9039 LossAtt 0.1048 TrainAcc 0.6100 TestAcc 0.5078 0.6100
epoch 400 LossPred 0.9036 LossAtt 0.0573 TrainAcc 0.6100 TestAcc 0.5078 0.6100
epoch 500 LossPred 0.9015 LossAtt 0.0386 TrainAcc 0.6100 TestAcc 0.5078 0.6100
epoch 600 LossPred 0.9001 LossAtt 0.0244 TrainAcc 0.6100 TestAcc 0.5078 0.6100
epoch 700 LossPred 0.8997 LossAtt 0.0218 TrainAcc 0.6100 TestAcc 0.5078 0.6100
epoch 800 LossPred 0.8994 LossAtt 0.0213 TrainAcc 0.6100 TestAcc 0.5078 0.6100
epoch 900 LossPred 0.8992 LossAtt 0.0256 TrainAcc 0.6100 TestAcc 0.5078 0.6150
epoch 1000 LossPred 0.8990 LossAtt 0.0356 TrainAcc 0.6100 TestAcc 0.5078 0.5900
epoch 1100 LossPred 0.8985 LossAtt 0.0464 TrainAcc 0.6100 TestAcc 0.5078 0.5900
epoch 1200 LossPred 0.8985 LossAtt 0.0652 TrainAcc 0.6100 TestAcc 0.5673 0.5800
epoch 1300 LossPred 0.8982 LossAtt 0.0834 TrainAcc 0.6100 TestAcc 0.5816 0.5950
epoch 1400 LossPred 0.8983 LossAtt 0.1018 TrainAcc 0.6100 TestAcc 0.5816 0.5900
epoch 1500 LossPred 0.8975 LossAtt 0.1195 TrainAcc 0.6100 TestAcc 0.5816 0.5950
epoch 1600 LossPred 0.8954 LossAtt 0.1720 TrainAcc 0.6100 TestAcc 0.5816 0.6000
epoch 1700 LossPred 0.8813 LossAtt 0.2544 TrainAcc 0.6100 TestAcc 0.5816 0.6100
epoch 1800 LossPred 0.8432 LossAtt 0.3057 TrainAcc 0.6500 TestAcc 0.5893 0.6500
epoch 1900 LossPred 0.7991 LossAtt 0.3107 TrainAcc 0.6900 TestAcc 0.5480 0.6800
epoch 2000 LossPred 0.7894 LossAtt 0.2932 TrainAcc 0.7500 TestAcc 0.5423 0.7250
epoch 2100 LossPred 0.7637 LossAtt 0.3732 TrainAcc 0.7300 TestAcc 0.5643 0.7000
epoch 2200 LossPred 0.7715 LossAtt 0.3637 TrainAcc 0.7200 TestAcc 0.5598 0.6750
epoch 2300 LossPred 0.7620 LossAtt 0.3564 TrainAcc 0.7400 TestAcc 0.5618 0.6800
epoch 2400 LossPred 0.7144 LossAtt 0.3580 TrainAcc 0.7700 TestAcc 0.5991 0.7150
epoch 2500 LossPred 0.4668 LossAtt 0.3638 TrainAcc 0.8200 TestAcc 0.7948 0.8000
Optimization Finished!
********** replication  82  **********
epoch   0 LossPred 1.1666 LossAtt 0.9962 TrainAcc 0.4700 TestAcc 0.5050 0.4700
epoch 100 LossPred 0.9490 LossAtt 0.2790 TrainAcc 0.6000 TestAcc 0.5808 0.6000
epoch 200 LossPred 0.9495 LossAtt 0.2305 TrainAcc 0.5800 TestAcc 0.5038 0.5900
epoch 300 LossPred 0.9483 LossAtt 0.2355 TrainAcc 0.6000 TestAcc 0.5808 0.6000
epoch 400 LossPred 0.9460 LossAtt 0.2409 TrainAcc 0.6000 TestAcc 0.5808 0.6000
epoch 500 LossPred 0.9449 LossAtt 0.2620 TrainAcc 0.6000 TestAcc 0.5808 0.6000
epoch 600 LossPred 0.9415 LossAtt 0.2822 TrainAcc 0.6000 TestAcc 0.5808 0.6000
epoch 700 LossPred 0.9358 LossAtt 0.3215 TrainAcc 0.6000 TestAcc 0.5808 0.6000
epoch 800 LossPred 0.9203 LossAtt 0.3769 TrainAcc 0.6000 TestAcc 0.6149 0.6300
epoch 900 LossPred 0.6960 LossAtt 0.3609 TrainAcc 0.7600 TestAcc 0.8056 0.7500
epoch 1000 LossPred 0.5425 LossAtt 0.3696 TrainAcc 0.8100 TestAcc 0.8418 0.8000
epoch 1100 LossPred 0.6025 LossAtt 0.3590 TrainAcc 0.7900 TestAcc 0.8468 0.7900
epoch 1200 LossPred 1.3368 LossAtt 0.3243 TrainAcc 0.5300 TestAcc 0.5023 0.5300
epoch 1300 LossPred 0.7190 LossAtt 0.3597 TrainAcc 0.7600 TestAcc 0.7588 0.7500
epoch 1400 LossPred 1.1730 LossAtt 0.3465 TrainAcc 0.5500 TestAcc 0.6226 0.5600
epoch 1500 LossPred 1.0596 LossAtt 0.3035 TrainAcc 0.5300 TestAcc 0.4987 0.5300
epoch 1600 LossPred 0.8718 LossAtt 0.3536 TrainAcc 0.6500 TestAcc 0.6389 0.6550
epoch 1700 LossPred 0.6848 LossAtt 0.3419 TrainAcc 0.7800 TestAcc 0.7805 0.7800
epoch 1800 LossPred 1.0550 LossAtt 0.2295 TrainAcc 0.4800 TestAcc 0.4217 0.4800
epoch 1900 LossPred 0.9977 LossAtt 0.2205 TrainAcc 0.4800 TestAcc 0.4217 0.4750
epoch 2000 LossPred 0.9780 LossAtt 0.2175 TrainAcc 0.5800 TestAcc 0.5038 0.5800
epoch 2100 LossPred 0.9701 LossAtt 0.2338 TrainAcc 0.5800 TestAcc 0.5038 0.5800
epoch 2200 LossPred 0.9640 LossAtt 0.2227 TrainAcc 0.5800 TestAcc 0.5038 0.5800
epoch 2300 LossPred 0.9576 LossAtt 0.2439 TrainAcc 0.5800 TestAcc 0.5038 0.5800
epoch 2400 LossPred 0.9520 LossAtt 0.2636 TrainAcc 0.5800 TestAcc 0.5218 0.5750
epoch 2500 LossPred 0.9480 LossAtt 0.2557 TrainAcc 0.5800 TestAcc 0.5218 0.5750
Optimization Finished!
********** replication  83  **********
epoch   0 LossPred 1.1511 LossAtt 1.0004 TrainAcc 0.5200 TestAcc 0.5666 0.5100
epoch 100 LossPred 0.9790 LossAtt 0.4562 TrainAcc 0.5900 TestAcc 0.5683 0.5900
epoch 200 LossPred 0.9634 LossAtt 0.3406 TrainAcc 0.5900 TestAcc 0.5683 0.5900
epoch 300 LossPred 0.9556 LossAtt 0.2532 TrainAcc 0.5900 TestAcc 0.5683 0.5950
epoch 400 LossPred 0.9228 LossAtt 0.2611 TrainAcc 0.6200 TestAcc 0.5561 0.6200
epoch 500 LossPred 0.9040 LossAtt 0.2763 TrainAcc 0.6200 TestAcc 0.5561 0.6200
epoch 600 LossPred 0.9003 LossAtt 0.2529 TrainAcc 0.6100 TestAcc 0.5611 0.6300
epoch 700 LossPred 0.8988 LossAtt 0.2641 TrainAcc 0.6100 TestAcc 0.5611 0.6150
epoch 800 LossPred 0.8836 LossAtt 0.2380 TrainAcc 0.6200 TestAcc 0.5571 0.6150
epoch 900 LossPred 0.8621 LossAtt 0.4652 TrainAcc 0.6400 TestAcc 0.5440 0.6400
epoch 1000 LossPred 0.8359 LossAtt 0.4504 TrainAcc 0.6600 TestAcc 0.5193 0.6500
epoch 1100 LossPred 0.8151 LossAtt 0.4520 TrainAcc 0.6800 TestAcc 0.5228 0.6750
epoch 1200 LossPred 0.8165 LossAtt 0.4509 TrainAcc 0.6900 TestAcc 0.5250 0.6750
epoch 1300 LossPred 0.7990 LossAtt 0.4577 TrainAcc 0.6800 TestAcc 0.5538 0.6750
epoch 1400 LossPred 0.7992 LossAtt 0.4285 TrainAcc 0.6600 TestAcc 0.5511 0.6750
epoch 1500 LossPred 0.7798 LossAtt 0.4208 TrainAcc 0.6900 TestAcc 0.5448 0.6950
epoch 1600 LossPred 0.7736 LossAtt 0.4415 TrainAcc 0.6900 TestAcc 0.5453 0.6850
epoch 1700 LossPred 0.7694 LossAtt 0.4536 TrainAcc 0.6800 TestAcc 0.5425 0.6700
epoch 1800 LossPred 0.7570 LossAtt 0.4302 TrainAcc 0.7000 TestAcc 0.5453 0.6800
epoch 1900 LossPred 0.7450 LossAtt 0.3935 TrainAcc 0.7100 TestAcc 0.5498 0.7050
epoch 2000 LossPred 0.7362 LossAtt 0.3777 TrainAcc 0.7100 TestAcc 0.5263 0.7000
epoch 2100 LossPred 0.7319 LossAtt 0.3824 TrainAcc 0.7100 TestAcc 0.5208 0.7100
epoch 2200 LossPred 0.7364 LossAtt 0.4190 TrainAcc 0.7200 TestAcc 0.5258 0.7100
epoch 2300 LossPred 0.7319 LossAtt 0.4748 TrainAcc 0.7300 TestAcc 0.4955 0.6900
epoch 2400 LossPred 0.7098 LossAtt 0.4704 TrainAcc 0.7700 TestAcc 0.5153 0.6800
epoch 2500 LossPred 0.6986 LossAtt 0.4858 TrainAcc 0.7700 TestAcc 0.5150 0.6900
Optimization Finished!
********** replication  84  **********
epoch   0 LossPred 1.1947 LossAtt 1.0218 TrainAcc 0.3700 TestAcc 0.4822 0.3800
epoch 100 LossPred 0.9304 LossAtt 0.4126 TrainAcc 0.6400 TestAcc 0.5816 0.6400
epoch 200 LossPred 0.9058 LossAtt 0.3334 TrainAcc 0.6300 TestAcc 0.5556 0.6450
epoch 300 LossPred 0.9035 LossAtt 0.2166 TrainAcc 0.6900 TestAcc 0.5968 0.6600
epoch 400 LossPred 0.8743 LossAtt 0.2338 TrainAcc 0.6600 TestAcc 0.5771 0.6600
epoch 500 LossPred 0.7847 LossAtt 0.3047 TrainAcc 0.7200 TestAcc 0.6131 0.7250
epoch 600 LossPred 0.5308 LossAtt 0.3838 TrainAcc 0.8400 TestAcc 0.8183 0.8150
epoch 700 LossPred 0.4822 LossAtt 0.3567 TrainAcc 0.8400 TestAcc 0.8248 0.8450
epoch 800 LossPred 0.4835 LossAtt 0.3751 TrainAcc 0.8200 TestAcc 0.8218 0.8300
epoch 900 LossPred 0.4690 LossAtt 0.3490 TrainAcc 0.8300 TestAcc 0.8238 0.8400
epoch 1000 LossPred 0.4582 LossAtt 0.3512 TrainAcc 0.8500 TestAcc 0.8298 0.8500
epoch 1100 LossPred 0.4874 LossAtt 0.3176 TrainAcc 0.8300 TestAcc 0.8306 0.8250
epoch 1200 LossPred 0.4761 LossAtt 0.3025 TrainAcc 0.8300 TestAcc 0.8208 0.8250
epoch 1300 LossPred 0.4525 LossAtt 0.3056 TrainAcc 0.8500 TestAcc 0.8316 0.8350
epoch 1400 LossPred 0.4442 LossAtt 0.2899 TrainAcc 0.8500 TestAcc 0.8236 0.8450
epoch 1500 LossPred 0.4872 LossAtt 0.2723 TrainAcc 0.8200 TestAcc 0.8023 0.8500
epoch 1600 LossPred 0.4386 LossAtt 0.2662 TrainAcc 0.8600 TestAcc 0.8353 0.8300
epoch 1700 LossPred 0.4394 LossAtt 0.2718 TrainAcc 0.8600 TestAcc 0.8323 0.8550
epoch 1800 LossPred 0.4482 LossAtt 0.2691 TrainAcc 0.8500 TestAcc 0.8318 0.8450
epoch 1900 LossPred 0.4420 LossAtt 0.2809 TrainAcc 0.8600 TestAcc 0.8371 0.8450
epoch 2000 LossPred 0.4538 LossAtt 0.2549 TrainAcc 0.8500 TestAcc 0.8348 0.8100
epoch 2100 LossPred 0.4483 LossAtt 0.2440 TrainAcc 0.8400 TestAcc 0.8301 0.8650
epoch 2200 LossPred 0.4357 LossAtt 0.2381 TrainAcc 0.8500 TestAcc 0.8378 0.8550
epoch 2300 LossPred 0.4289 LossAtt 0.2478 TrainAcc 0.8600 TestAcc 0.8383 0.8600
epoch 2400 LossPred 0.4329 LossAtt 0.2379 TrainAcc 0.8400 TestAcc 0.8373 0.8100
epoch 2500 LossPred 0.4023 LossAtt 0.2467 TrainAcc 0.8700 TestAcc 0.8531 0.8650
Optimization Finished!
********** replication  85  **********
epoch   0 LossPred 1.2859 LossAtt 1.0614 TrainAcc 0.3600 TestAcc 0.4807 0.3600
epoch 100 LossPred 1.0004 LossAtt 0.3244 TrainAcc 0.5200 TestAcc 0.4900 0.5300
epoch 200 LossPred 0.9975 LossAtt 0.2391 TrainAcc 0.5200 TestAcc 0.4900 0.5200
epoch 300 LossPred 0.9964 LossAtt 0.2229 TrainAcc 0.5200 TestAcc 0.4900 0.5200
epoch 400 LossPred 0.9884 LossAtt 0.2433 TrainAcc 0.5900 TestAcc 0.4962 0.5850
epoch 500 LossPred 0.8757 LossAtt 0.4184 TrainAcc 0.6400 TestAcc 0.5210 0.6300
epoch 600 LossPred 0.8186 LossAtt 0.4211 TrainAcc 0.6700 TestAcc 0.5373 0.6800
epoch 700 LossPred 0.7977 LossAtt 0.4202 TrainAcc 0.7100 TestAcc 0.5388 0.6900
epoch 800 LossPred 0.7841 LossAtt 0.4121 TrainAcc 0.7100 TestAcc 0.5355 0.7000
epoch 900 LossPred 0.7755 LossAtt 0.3941 TrainAcc 0.6900 TestAcc 0.5378 0.7050
epoch 1000 LossPred 0.7695 LossAtt 0.3747 TrainAcc 0.6900 TestAcc 0.5393 0.7000
epoch 1100 LossPred 0.7498 LossAtt 0.4153 TrainAcc 0.7000 TestAcc 0.5531 0.7000
epoch 1200 LossPred 0.4751 LossAtt 0.5117 TrainAcc 0.8400 TestAcc 0.7595 0.8500
epoch 1300 LossPred 0.4367 LossAtt 0.4896 TrainAcc 0.8800 TestAcc 0.7573 0.8350
epoch 1400 LossPred 0.3922 LossAtt 0.4996 TrainAcc 0.8800 TestAcc 0.7625 0.8700
epoch 1500 LossPred 0.4418 LossAtt 0.4880 TrainAcc 0.8800 TestAcc 0.7447 0.8250
epoch 1600 LossPred 0.3946 LossAtt 0.4859 TrainAcc 0.8900 TestAcc 0.7575 0.8650
epoch 1700 LossPred 0.3813 LossAtt 0.4631 TrainAcc 0.8900 TestAcc 0.7452 0.8650
epoch 1800 LossPred 0.3800 LossAtt 0.4640 TrainAcc 0.8900 TestAcc 0.7387 0.8600
epoch 1900 LossPred 0.4136 LossAtt 0.4584 TrainAcc 0.8800 TestAcc 0.7375 0.8350
epoch 2000 LossPred 0.3869 LossAtt 0.4614 TrainAcc 0.8800 TestAcc 0.7390 0.8600
epoch 2100 LossPred 0.4230 LossAtt 0.4605 TrainAcc 0.8700 TestAcc 0.7317 0.8450
epoch 2200 LossPred 0.3945 LossAtt 0.4550 TrainAcc 0.8800 TestAcc 0.7465 0.8600
epoch 2300 LossPred 0.3865 LossAtt 0.4674 TrainAcc 0.8800 TestAcc 0.7392 0.8500
epoch 2400 LossPred 0.4284 LossAtt 0.4371 TrainAcc 0.8600 TestAcc 0.7310 0.8300
epoch 2500 LossPred 0.3883 LossAtt 0.4455 TrainAcc 0.8800 TestAcc 0.7370 0.8450
Optimization Finished!
********** replication  86  **********
epoch   0 LossPred 1.0509 LossAtt 1.0203 TrainAcc 0.5200 TestAcc 0.4249 0.5050
epoch 100 LossPred 0.9265 LossAtt 0.4398 TrainAcc 0.6100 TestAcc 0.5433 0.6000
epoch 200 LossPred 0.9128 LossAtt 0.4049 TrainAcc 0.6300 TestAcc 0.5638 0.6050
epoch 300 LossPred 0.9040 LossAtt 0.3930 TrainAcc 0.6300 TestAcc 0.5638 0.6050
epoch 400 LossPred 0.7177 LossAtt 0.5011 TrainAcc 0.7700 TestAcc 0.7112 0.7500
epoch 500 LossPred 0.4603 LossAtt 0.4550 TrainAcc 0.8300 TestAcc 0.8246 0.8200
epoch 600 LossPred 0.4441 LossAtt 0.3992 TrainAcc 0.8500 TestAcc 0.8043 0.8500
epoch 700 LossPred 0.4200 LossAtt 0.3680 TrainAcc 0.8700 TestAcc 0.8098 0.8600
epoch 800 LossPred 0.4073 LossAtt 0.3913 TrainAcc 0.8900 TestAcc 0.7998 0.8650
epoch 900 LossPred 0.4068 LossAtt 0.4038 TrainAcc 0.8800 TestAcc 0.8033 0.8650
epoch 1000 LossPred 0.4039 LossAtt 0.4172 TrainAcc 0.8800 TestAcc 0.7998 0.8800
epoch 1100 LossPred 0.4011 LossAtt 0.4231 TrainAcc 0.8800 TestAcc 0.8036 0.8800
epoch 1200 LossPred 0.3763 LossAtt 0.4431 TrainAcc 0.8900 TestAcc 0.8073 0.8900
epoch 1300 LossPred 0.4014 LossAtt 0.4554 TrainAcc 0.8800 TestAcc 0.7970 0.8750
epoch 1400 LossPred 0.3600 LossAtt 0.4390 TrainAcc 0.8800 TestAcc 0.8113 0.8700
epoch 1500 LossPred 0.3599 LossAtt 0.4470 TrainAcc 0.8800 TestAcc 0.8131 0.8700
epoch 1600 LossPred 0.3707 LossAtt 0.4321 TrainAcc 0.8700 TestAcc 0.8108 0.8750
epoch 1700 LossPred 0.3476 LossAtt 0.4352 TrainAcc 0.8900 TestAcc 0.8338 0.8700
epoch 1800 LossPred 0.3703 LossAtt 0.4316 TrainAcc 0.8600 TestAcc 0.8331 0.8600
epoch 1900 LossPred 0.3495 LossAtt 0.4741 TrainAcc 0.8800 TestAcc 0.8188 0.8850
epoch 2000 LossPred 0.3034 LossAtt 0.4865 TrainAcc 0.9000 TestAcc 0.8468 0.8950
epoch 2100 LossPred 0.2827 LossAtt 0.4948 TrainAcc 0.9200 TestAcc 0.8589 0.8950
epoch 2200 LossPred 0.2629 LossAtt 0.5087 TrainAcc 0.9100 TestAcc 0.8704 0.9050
epoch 2300 LossPred 0.4638 LossAtt 0.5770 TrainAcc 0.8100 TestAcc 0.8093 0.8050
epoch 2400 LossPred 0.5126 LossAtt 0.5348 TrainAcc 0.8400 TestAcc 0.7575 0.8350
epoch 2500 LossPred 0.2738 LossAtt 0.5531 TrainAcc 0.8900 TestAcc 0.8761 0.8800
Optimization Finished!
********** replication  87  **********
epoch   0 LossPred 0.9915 LossAtt 1.0279 TrainAcc 0.6100 TestAcc 0.5465 0.5850
epoch 100 LossPred 0.8845 LossAtt 0.3616 TrainAcc 0.6500 TestAcc 0.5863 0.6500
epoch 200 LossPred 0.8707 LossAtt 0.2591 TrainAcc 0.6600 TestAcc 0.5861 0.6450
epoch 300 LossPred 0.8639 LossAtt 0.2557 TrainAcc 0.6400 TestAcc 0.5916 0.6500
epoch 400 LossPred 0.8598 LossAtt 0.2501 TrainAcc 0.6400 TestAcc 0.5898 0.6500
epoch 500 LossPred 0.8594 LossAtt 0.2731 TrainAcc 0.6300 TestAcc 0.5856 0.6500
epoch 600 LossPred 0.8570 LossAtt 0.2742 TrainAcc 0.6400 TestAcc 0.5831 0.6500
epoch 700 LossPred 0.8513 LossAtt 0.3030 TrainAcc 0.6300 TestAcc 0.5841 0.6200
epoch 800 LossPred 0.8408 LossAtt 0.4562 TrainAcc 0.6400 TestAcc 0.5863 0.6350
epoch 900 LossPred 0.8146 LossAtt 0.4439 TrainAcc 0.6600 TestAcc 0.5906 0.6250
epoch 1000 LossPred 0.7946 LossAtt 0.4222 TrainAcc 0.6600 TestAcc 0.5851 0.6450
epoch 1100 LossPred 0.7887 LossAtt 0.4099 TrainAcc 0.6700 TestAcc 0.5851 0.6550
epoch 1200 LossPred 0.7831 LossAtt 0.4040 TrainAcc 0.6700 TestAcc 0.5878 0.6500
epoch 1300 LossPred 0.7842 LossAtt 0.3982 TrainAcc 0.6700 TestAcc 0.5838 0.6350
epoch 1400 LossPred 0.7957 LossAtt 0.4255 TrainAcc 0.6500 TestAcc 0.5796 0.6300
epoch 1500 LossPred 0.7916 LossAtt 0.4342 TrainAcc 0.6600 TestAcc 0.5826 0.6250
epoch 1600 LossPred 0.7833 LossAtt 0.4165 TrainAcc 0.6700 TestAcc 0.5821 0.6400
epoch 1700 LossPred 0.7825 LossAtt 0.4421 TrainAcc 0.6600 TestAcc 0.5831 0.6450
epoch 1800 LossPred 0.7729 LossAtt 0.4257 TrainAcc 0.6700 TestAcc 0.5848 0.6450
epoch 1900 LossPred 0.7642 LossAtt 0.4215 TrainAcc 0.6700 TestAcc 0.5833 0.6600
epoch 2000 LossPred 0.7422 LossAtt 0.4112 TrainAcc 0.6900 TestAcc 0.5751 0.6700
epoch 2100 LossPred 0.7379 LossAtt 0.4242 TrainAcc 0.7200 TestAcc 0.5706 0.6950
epoch 2200 LossPred 0.7300 LossAtt 0.4159 TrainAcc 0.7000 TestAcc 0.5713 0.7000
epoch 2300 LossPred 0.7467 LossAtt 0.4172 TrainAcc 0.6900 TestAcc 0.5626 0.6950
epoch 2400 LossPred 0.6968 LossAtt 0.4245 TrainAcc 0.7200 TestAcc 0.5686 0.6950
epoch 2500 LossPred 0.6462 LossAtt 0.4184 TrainAcc 0.7700 TestAcc 0.5851 0.7450
Optimization Finished!
********** replication  88  **********
epoch   0 LossPred 1.3529 LossAtt 1.0092 TrainAcc 0.4000 TestAcc 0.4382 0.3850
epoch 100 LossPred 1.0596 LossAtt 0.4920 TrainAcc 0.4400 TestAcc 0.4572 0.4350
epoch 200 LossPred 0.9704 LossAtt 0.4046 TrainAcc 0.5200 TestAcc 0.5628 0.5500
epoch 300 LossPred 0.9292 LossAtt 0.3554 TrainAcc 0.5500 TestAcc 0.5751 0.5650
epoch 400 LossPred 0.9126 LossAtt 0.3416 TrainAcc 0.6000 TestAcc 0.5931 0.5950
epoch 500 LossPred 0.9068 LossAtt 0.3232 TrainAcc 0.6000 TestAcc 0.5926 0.6050
epoch 600 LossPred 0.9012 LossAtt 0.3213 TrainAcc 0.6000 TestAcc 0.5946 0.6050
epoch 700 LossPred 0.8932 LossAtt 0.3446 TrainAcc 0.6100 TestAcc 0.5998 0.6100
epoch 800 LossPred 0.8880 LossAtt 0.3677 TrainAcc 0.5900 TestAcc 0.6171 0.6250
epoch 900 LossPred 0.8616 LossAtt 0.3819 TrainAcc 0.6000 TestAcc 0.6239 0.5950
epoch 1000 LossPred 0.5144 LossAtt 0.4031 TrainAcc 0.8400 TestAcc 0.7773 0.8400
epoch 1100 LossPred 0.4706 LossAtt 0.3728 TrainAcc 0.8500 TestAcc 0.7640 0.8350
epoch 1200 LossPred 0.4959 LossAtt 0.3649 TrainAcc 0.8500 TestAcc 0.7583 0.8300
epoch 1300 LossPred 0.4218 LossAtt 0.3550 TrainAcc 0.8700 TestAcc 0.7688 0.8250
epoch 1400 LossPred 0.4283 LossAtt 0.3513 TrainAcc 0.8500 TestAcc 0.7770 0.8350
epoch 1500 LossPred 0.3990 LossAtt 0.3820 TrainAcc 0.8500 TestAcc 0.8063 0.8300
epoch 1600 LossPred 0.3580 LossAtt 0.3591 TrainAcc 0.8800 TestAcc 0.8266 0.8850
epoch 1700 LossPred 0.3464 LossAtt 0.3446 TrainAcc 0.8800 TestAcc 0.8318 0.8950
epoch 1800 LossPred 0.3056 LossAtt 0.3586 TrainAcc 0.9000 TestAcc 0.8423 0.8700
epoch 1900 LossPred 0.4074 LossAtt 0.3868 TrainAcc 0.8700 TestAcc 0.8406 0.8750
epoch 2000 LossPred 0.3223 LossAtt 0.3542 TrainAcc 0.8900 TestAcc 0.8353 0.8750
epoch 2100 LossPred 0.2584 LossAtt 0.3608 TrainAcc 0.9200 TestAcc 0.8526 0.9000
epoch 2200 LossPred 0.2580 LossAtt 0.3565 TrainAcc 0.9200 TestAcc 0.8516 0.9100
epoch 2300 LossPred 0.2451 LossAtt 0.3595 TrainAcc 0.9400 TestAcc 0.8493 0.8900
epoch 2400 LossPred 0.2957 LossAtt 0.3329 TrainAcc 0.8900 TestAcc 0.8433 0.8800
epoch 2500 LossPred 0.3500 LossAtt 0.3408 TrainAcc 0.8900 TestAcc 0.8559 0.9050
Optimization Finished!
********** replication  89  **********
epoch   0 LossPred 0.9974 LossAtt 0.9940 TrainAcc 0.4900 TestAcc 0.5173 0.4850
epoch 100 LossPred 0.8486 LossAtt 0.4894 TrainAcc 0.6800 TestAcc 0.5746 0.6850
epoch 200 LossPred 0.7871 LossAtt 0.4848 TrainAcc 0.7400 TestAcc 0.6291 0.7300
epoch 300 LossPred 0.6593 LossAtt 0.4648 TrainAcc 0.7800 TestAcc 0.6982 0.7900
epoch 400 LossPred 0.5298 LossAtt 0.4273 TrainAcc 0.8000 TestAcc 0.8308 0.8200
epoch 500 LossPred 0.5079 LossAtt 0.4289 TrainAcc 0.8100 TestAcc 0.8303 0.8250
epoch 600 LossPred 0.4764 LossAtt 0.3983 TrainAcc 0.8400 TestAcc 0.8338 0.8450
epoch 700 LossPred 0.5240 LossAtt 0.3796 TrainAcc 0.8000 TestAcc 0.8306 0.8050
epoch 800 LossPred 0.4772 LossAtt 0.3564 TrainAcc 0.8500 TestAcc 0.8461 0.8450
epoch 900 LossPred 0.5749 LossAtt 0.3391 TrainAcc 0.7600 TestAcc 0.7965 0.7600
epoch 1000 LossPred 0.5607 LossAtt 0.3104 TrainAcc 0.8000 TestAcc 0.8361 0.8200
epoch 1100 LossPred 0.6022 LossAtt 0.2931 TrainAcc 0.7900 TestAcc 0.8106 0.7850
epoch 1200 LossPred 0.4507 LossAtt 0.2994 TrainAcc 0.8500 TestAcc 0.8326 0.8450
epoch 1300 LossPred 0.4338 LossAtt 0.2868 TrainAcc 0.8700 TestAcc 0.8256 0.8600
epoch 1400 LossPred 0.4357 LossAtt 0.2900 TrainAcc 0.8700 TestAcc 0.8218 0.8650
epoch 1500 LossPred 0.4281 LossAtt 0.2853 TrainAcc 0.8600 TestAcc 0.8256 0.8400
epoch 1600 LossPred 0.5182 LossAtt 0.2783 TrainAcc 0.8100 TestAcc 0.8298 0.8050
epoch 1700 LossPred 0.4759 LossAtt 0.2753 TrainAcc 0.8500 TestAcc 0.8133 0.8550
epoch 1800 LossPred 0.5107 LossAtt 0.2752 TrainAcc 0.8300 TestAcc 0.8023 0.8300
epoch 1900 LossPred 0.4831 LossAtt 0.2596 TrainAcc 0.8500 TestAcc 0.8106 0.8550
epoch 2000 LossPred 0.5128 LossAtt 0.2638 TrainAcc 0.8300 TestAcc 0.8163 0.8400
epoch 2100 LossPred 0.5267 LossAtt 0.2624 TrainAcc 0.8300 TestAcc 0.8246 0.8300
epoch 2200 LossPred 0.4510 LossAtt 0.2717 TrainAcc 0.8600 TestAcc 0.8156 0.8600
epoch 2300 LossPred 0.5693 LossAtt 0.2704 TrainAcc 0.7600 TestAcc 0.7955 0.7700
epoch 2400 LossPred 0.4837 LossAtt 0.2560 TrainAcc 0.8400 TestAcc 0.8201 0.8450
epoch 2500 LossPred 0.4244 LossAtt 0.2577 TrainAcc 0.8600 TestAcc 0.8106 0.8600
Optimization Finished!
********** replication  90  **********
epoch   0 LossPred 1.2677 LossAtt 1.0013 TrainAcc 0.4400 TestAcc 0.4472 0.4650
epoch 100 LossPred 1.0159 LossAtt 0.3821 TrainAcc 0.5100 TestAcc 0.4712 0.5150
epoch 200 LossPred 0.9468 LossAtt 0.4409 TrainAcc 0.6200 TestAcc 0.5783 0.6150
epoch 300 LossPred 0.8175 LossAtt 0.4865 TrainAcc 0.7300 TestAcc 0.6724 0.7200
epoch 400 LossPred 0.6860 LossAtt 0.5614 TrainAcc 0.7600 TestAcc 0.7638 0.7550
epoch 500 LossPred 0.5110 LossAtt 0.5110 TrainAcc 0.8200 TestAcc 0.8281 0.8150
epoch 600 LossPred 0.4244 LossAtt 0.5054 TrainAcc 0.8500 TestAcc 0.8261 0.8000
epoch 700 LossPred 0.6150 LossAtt 0.4814 TrainAcc 0.7800 TestAcc 0.8021 0.8100
epoch 800 LossPred 0.3848 LossAtt 0.4714 TrainAcc 0.8700 TestAcc 0.8378 0.8550
epoch 900 LossPred 0.3836 LossAtt 0.4869 TrainAcc 0.8700 TestAcc 0.8358 0.8400
epoch 1000 LossPred 0.4348 LossAtt 0.4932 TrainAcc 0.8500 TestAcc 0.8403 0.8400
epoch 1100 LossPred 0.3613 LossAtt 0.4866 TrainAcc 0.8900 TestAcc 0.8561 0.8600
epoch 1200 LossPred 0.3377 LossAtt 0.4720 TrainAcc 0.8900 TestAcc 0.8629 0.8750
epoch 1300 LossPred 0.3703 LossAtt 0.4880 TrainAcc 0.8700 TestAcc 0.8531 0.8600
epoch 1400 LossPred 0.2824 LossAtt 0.4665 TrainAcc 0.9200 TestAcc 0.8734 0.8900
epoch 1500 LossPred 0.4170 LossAtt 0.4784 TrainAcc 0.8600 TestAcc 0.8128 0.8450
epoch 1600 LossPred 0.2930 LossAtt 0.4838 TrainAcc 0.9100 TestAcc 0.8689 0.8800
epoch 1700 LossPred 0.3315 LossAtt 0.4707 TrainAcc 0.8900 TestAcc 0.8596 0.8850
epoch 1800 LossPred 0.2579 LossAtt 0.4555 TrainAcc 0.9200 TestAcc 0.8831 0.9300
epoch 1900 LossPred 0.2912 LossAtt 0.4415 TrainAcc 0.9100 TestAcc 0.8656 0.9000
epoch 2000 LossPred 0.3405 LossAtt 0.4420 TrainAcc 0.8900 TestAcc 0.8398 0.8600
epoch 2100 LossPred 0.4557 LossAtt 0.4447 TrainAcc 0.8100 TestAcc 0.8241 0.8400
epoch 2200 LossPred 0.4741 LossAtt 0.4305 TrainAcc 0.8200 TestAcc 0.8041 0.8300
epoch 2300 LossPred 0.5650 LossAtt 0.4358 TrainAcc 0.7800 TestAcc 0.7595 0.7900
epoch 2400 LossPred 0.3580 LossAtt 0.4094 TrainAcc 0.8800 TestAcc 0.8248 0.8700
epoch 2500 LossPred 0.3139 LossAtt 0.4071 TrainAcc 0.8800 TestAcc 0.8521 0.8900
Optimization Finished!
********** replication  91  **********
epoch   0 LossPred 1.0299 LossAtt 0.9871 TrainAcc 0.4500 TestAcc 0.5013 0.4650
epoch 100 LossPred 0.9235 LossAtt 0.4843 TrainAcc 0.6000 TestAcc 0.5808 0.5850
epoch 200 LossPred 0.9033 LossAtt 0.4839 TrainAcc 0.6200 TestAcc 0.6101 0.5950
epoch 300 LossPred 0.8885 LossAtt 0.5336 TrainAcc 0.6200 TestAcc 0.6689 0.5900
epoch 400 LossPred 0.8286 LossAtt 0.5789 TrainAcc 0.7000 TestAcc 0.6939 0.6850
epoch 500 LossPred 0.8010 LossAtt 0.4959 TrainAcc 0.7000 TestAcc 0.7150 0.7250
epoch 600 LossPred 0.8922 LossAtt 0.4620 TrainAcc 0.6300 TestAcc 0.6186 0.6400
epoch 700 LossPred 0.9238 LossAtt 0.4293 TrainAcc 0.6300 TestAcc 0.6116 0.6250
epoch 800 LossPred 0.7403 LossAtt 0.4025 TrainAcc 0.7200 TestAcc 0.7825 0.7500
epoch 900 LossPred 0.6818 LossAtt 0.4287 TrainAcc 0.7700 TestAcc 0.8158 0.7700
epoch 1000 LossPred 0.6682 LossAtt 0.3984 TrainAcc 0.7700 TestAcc 0.8166 0.7650
epoch 1100 LossPred 0.6342 LossAtt 0.4440 TrainAcc 0.7900 TestAcc 0.8263 0.7850
epoch 1200 LossPred 0.6924 LossAtt 0.3888 TrainAcc 0.7300 TestAcc 0.7820 0.7550
epoch 1300 LossPred 0.7037 LossAtt 0.4349 TrainAcc 0.7300 TestAcc 0.7943 0.7550
epoch 1400 LossPred 0.6729 LossAtt 0.4079 TrainAcc 0.7500 TestAcc 0.8051 0.7800
epoch 1500 LossPred 0.6208 LossAtt 0.4046 TrainAcc 0.8000 TestAcc 0.8183 0.7700
epoch 1600 LossPred 0.6484 LossAtt 0.4025 TrainAcc 0.7800 TestAcc 0.8223 0.7600
epoch 1700 LossPred 0.6601 LossAtt 0.3895 TrainAcc 0.7500 TestAcc 0.8078 0.7850
epoch 1800 LossPred 0.6802 LossAtt 0.4176 TrainAcc 0.7600 TestAcc 0.8063 0.7500
epoch 1900 LossPred 0.7696 LossAtt 0.4153 TrainAcc 0.7300 TestAcc 0.8078 0.7700
epoch 2000 LossPred 0.6083 LossAtt 0.4190 TrainAcc 0.7900 TestAcc 0.8238 0.7750
epoch 2100 LossPred 0.6143 LossAtt 0.4198 TrainAcc 0.7900 TestAcc 0.8271 0.7650
epoch 2200 LossPred 0.6044 LossAtt 0.3986 TrainAcc 0.7900 TestAcc 0.8211 0.7650
epoch 2300 LossPred 0.7011 LossAtt 0.4579 TrainAcc 0.7800 TestAcc 0.7985 0.7650
epoch 2400 LossPred 0.8913 LossAtt 0.4470 TrainAcc 0.6500 TestAcc 0.6677 0.6450
epoch 2500 LossPred 0.7044 LossAtt 0.4190 TrainAcc 0.7500 TestAcc 0.7908 0.7300
Optimization Finished!
********** replication  92  **********
epoch   0 LossPred 1.2618 LossAtt 0.9997 TrainAcc 0.4400 TestAcc 0.4482 0.4600
epoch 100 LossPred 0.9852 LossAtt 0.3521 TrainAcc 0.5700 TestAcc 0.4880 0.5750
epoch 200 LossPred 0.9261 LossAtt 0.2953 TrainAcc 0.5700 TestAcc 0.4880 0.5900
epoch 300 LossPred 0.8543 LossAtt 0.3143 TrainAcc 0.7300 TestAcc 0.6011 0.7100
epoch 400 LossPred 0.8550 LossAtt 0.4664 TrainAcc 0.7000 TestAcc 0.7277 0.6700
epoch 500 LossPred 0.8460 LossAtt 0.3928 TrainAcc 0.6500 TestAcc 0.5803 0.6750
epoch 600 LossPred 0.7408 LossAtt 0.4353 TrainAcc 0.7300 TestAcc 0.7713 0.7150
epoch 700 LossPred 0.6988 LossAtt 0.4325 TrainAcc 0.7300 TestAcc 0.6724 0.7400
epoch 800 LossPred 0.6145 LossAtt 0.4207 TrainAcc 0.7800 TestAcc 0.7472 0.7850
epoch 900 LossPred 0.5427 LossAtt 0.3969 TrainAcc 0.8200 TestAcc 0.8223 0.7800
epoch 1000 LossPred 0.5574 LossAtt 0.4198 TrainAcc 0.8000 TestAcc 0.8291 0.7900
epoch 1100 LossPred 0.5489 LossAtt 0.4140 TrainAcc 0.8200 TestAcc 0.8258 0.8050
epoch 1200 LossPred 0.5424 LossAtt 0.4128 TrainAcc 0.8200 TestAcc 0.8166 0.8150
epoch 1300 LossPred 0.6788 LossAtt 0.4314 TrainAcc 0.7500 TestAcc 0.7432 0.7900
epoch 1400 LossPred 0.5721 LossAtt 0.4590 TrainAcc 0.7900 TestAcc 0.7908 0.8150
epoch 1500 LossPred 0.6771 LossAtt 0.4545 TrainAcc 0.7700 TestAcc 0.7495 0.7650
epoch 1600 LossPred 0.4822 LossAtt 0.4621 TrainAcc 0.8200 TestAcc 0.7895 0.8200
epoch 1700 LossPred 0.5093 LossAtt 0.4960 TrainAcc 0.8100 TestAcc 0.8091 0.8000
epoch 1800 LossPred 0.4017 LossAtt 0.4544 TrainAcc 0.8700 TestAcc 0.8111 0.8150
epoch 1900 LossPred 0.4527 LossAtt 0.4600 TrainAcc 0.8300 TestAcc 0.8133 0.8100
epoch 2000 LossPred 0.4397 LossAtt 0.4430 TrainAcc 0.8500 TestAcc 0.7933 0.8350
epoch 2100 LossPred 0.5692 LossAtt 0.4460 TrainAcc 0.8400 TestAcc 0.8093 0.8250
epoch 2200 LossPred 0.4099 LossAtt 0.4320 TrainAcc 0.8600 TestAcc 0.8046 0.8300
epoch 2300 LossPred 0.5150 LossAtt 0.4346 TrainAcc 0.8400 TestAcc 0.8183 0.8600
epoch 2400 LossPred 0.4061 LossAtt 0.4358 TrainAcc 0.8600 TestAcc 0.8018 0.8500
epoch 2500 LossPred 0.3969 LossAtt 0.4289 TrainAcc 0.8700 TestAcc 0.8013 0.8600
Optimization Finished!
********** replication  93  **********
epoch   0 LossPred 1.2172 LossAtt 1.0316 TrainAcc 0.5000 TestAcc 0.5445 0.4750
epoch 100 LossPred 1.0333 LossAtt 0.4889 TrainAcc 0.5100 TestAcc 0.5495 0.4950
epoch 200 LossPred 0.9680 LossAtt 0.4169 TrainAcc 0.5500 TestAcc 0.5413 0.5350
epoch 300 LossPred 0.9399 LossAtt 0.4011 TrainAcc 0.5900 TestAcc 0.5566 0.5900
epoch 400 LossPred 0.9243 LossAtt 0.3898 TrainAcc 0.5900 TestAcc 0.5768 0.5750
epoch 500 LossPred 0.9209 LossAtt 0.3793 TrainAcc 0.5900 TestAcc 0.5648 0.5900
epoch 600 LossPred 0.9099 LossAtt 0.4093 TrainAcc 0.6200 TestAcc 0.5551 0.6200
epoch 700 LossPred 0.8921 LossAtt 0.4368 TrainAcc 0.6300 TestAcc 0.5616 0.6000
epoch 800 LossPred 0.8872 LossAtt 0.3662 TrainAcc 0.5800 TestAcc 0.5663 0.5800
epoch 900 LossPred 0.8456 LossAtt 0.3807 TrainAcc 0.5800 TestAcc 0.5646 0.5950
epoch 1000 LossPred 0.8044 LossAtt 0.4092 TrainAcc 0.6500 TestAcc 0.5596 0.6600
epoch 1100 LossPred 0.7140 LossAtt 0.3283 TrainAcc 0.7500 TestAcc 0.6879 0.7600
epoch 1200 LossPred 0.7083 LossAtt 0.3811 TrainAcc 0.7400 TestAcc 0.6859 0.7400
epoch 1300 LossPred 0.6876 LossAtt 0.3417 TrainAcc 0.7800 TestAcc 0.6644 0.7750
epoch 1400 LossPred 0.6762 LossAtt 0.3383 TrainAcc 0.7700 TestAcc 0.6271 0.7650
epoch 1500 LossPred 0.6750 LossAtt 0.3768 TrainAcc 0.7500 TestAcc 0.6612 0.7250
epoch 1600 LossPred 0.6515 LossAtt 0.3459 TrainAcc 0.7900 TestAcc 0.6459 0.7700
epoch 1700 LossPred 0.6489 LossAtt 0.3476 TrainAcc 0.7900 TestAcc 0.6456 0.7650
epoch 1800 LossPred 0.6737 LossAtt 0.3245 TrainAcc 0.7600 TestAcc 0.6712 0.7800
epoch 1900 LossPred 0.6316 LossAtt 0.3379 TrainAcc 0.7900 TestAcc 0.6574 0.8100
epoch 2000 LossPred 0.5955 LossAtt 0.3224 TrainAcc 0.7700 TestAcc 0.6534 0.7800
epoch 2100 LossPred 0.6133 LossAtt 0.2888 TrainAcc 0.7900 TestAcc 0.6732 0.8050
epoch 2200 LossPred 0.6175 LossAtt 0.2944 TrainAcc 0.7700 TestAcc 0.6789 0.7800
epoch 2300 LossPred 0.5798 LossAtt 0.2931 TrainAcc 0.8100 TestAcc 0.6757 0.7950
epoch 2400 LossPred 0.5779 LossAtt 0.2840 TrainAcc 0.8100 TestAcc 0.6687 0.7950
epoch 2500 LossPred 0.5651 LossAtt 0.2975 TrainAcc 0.8100 TestAcc 0.6772 0.8000
Optimization Finished!
********** replication  94  **********
epoch   0 LossPred 1.0443 LossAtt 0.9836 TrainAcc 0.4900 TestAcc 0.4409 0.4850
epoch 100 LossPred 0.9366 LossAtt 0.4305 TrainAcc 0.5800 TestAcc 0.5058 0.5600
epoch 200 LossPred 0.9076 LossAtt 0.4371 TrainAcc 0.6100 TestAcc 0.5420 0.5950
epoch 300 LossPred 0.8800 LossAtt 0.4497 TrainAcc 0.5900 TestAcc 0.5310 0.5650
epoch 400 LossPred 0.8716 LossAtt 0.3687 TrainAcc 0.6000 TestAcc 0.5320 0.6050
epoch 500 LossPred 0.8636 LossAtt 0.3441 TrainAcc 0.6100 TestAcc 0.5295 0.6100
epoch 600 LossPred 0.8522 LossAtt 0.3713 TrainAcc 0.6300 TestAcc 0.5641 0.6300
epoch 700 LossPred 0.8067 LossAtt 0.4910 TrainAcc 0.6800 TestAcc 0.6204 0.6850
epoch 800 LossPred 0.8282 LossAtt 0.4259 TrainAcc 0.6700 TestAcc 0.5808 0.6650
epoch 900 LossPred 0.6388 LossAtt 0.4504 TrainAcc 0.8100 TestAcc 0.7150 0.8100
epoch 1000 LossPred 0.9332 LossAtt 0.3355 TrainAcc 0.6200 TestAcc 0.5000 0.6150
epoch 1100 LossPred 0.9277 LossAtt 0.3253 TrainAcc 0.6200 TestAcc 0.5003 0.6200
epoch 1200 LossPred 0.9224 LossAtt 0.3248 TrainAcc 0.6000 TestAcc 0.5133 0.6000
epoch 1300 LossPred 0.9143 LossAtt 0.3147 TrainAcc 0.6300 TestAcc 0.5290 0.6300
epoch 1400 LossPred 0.9071 LossAtt 0.3053 TrainAcc 0.5800 TestAcc 0.5330 0.6100
epoch 1500 LossPred 0.8935 LossAtt 0.3100 TrainAcc 0.6200 TestAcc 0.5578 0.6200
epoch 1600 LossPred 0.7178 LossAtt 0.4147 TrainAcc 0.8100 TestAcc 0.7062 0.7900
epoch 1700 LossPred 0.7602 LossAtt 0.4103 TrainAcc 0.7500 TestAcc 0.6729 0.7450
epoch 1800 LossPred 0.9680 LossAtt 0.4254 TrainAcc 0.6100 TestAcc 0.5696 0.6100
epoch 1900 LossPred 0.6506 LossAtt 0.4135 TrainAcc 0.7700 TestAcc 0.6952 0.7550
epoch 2000 LossPred 0.5319 LossAtt 0.4229 TrainAcc 0.8200 TestAcc 0.7500 0.8050
epoch 2100 LossPred 0.6461 LossAtt 0.4205 TrainAcc 0.7700 TestAcc 0.7022 0.7600
epoch 2200 LossPred 0.3859 LossAtt 0.4047 TrainAcc 0.8800 TestAcc 0.7868 0.8450
epoch 2300 LossPred 0.3940 LossAtt 0.4217 TrainAcc 0.8700 TestAcc 0.7860 0.8400
epoch 2400 LossPred 0.4719 LossAtt 0.4144 TrainAcc 0.8500 TestAcc 0.7678 0.8050
epoch 2500 LossPred 0.4992 LossAtt 0.3955 TrainAcc 0.8400 TestAcc 0.7367 0.7950
Optimization Finished!
********** replication  95  **********
epoch   0 LossPred 1.1391 LossAtt 0.9934 TrainAcc 0.3900 TestAcc 0.4720 0.3800
epoch 100 LossPred 0.8906 LossAtt 0.3358 TrainAcc 0.6600 TestAcc 0.5806 0.6650
epoch 200 LossPred 0.8673 LossAtt 0.2679 TrainAcc 0.6600 TestAcc 0.5806 0.6800
epoch 300 LossPred 0.8234 LossAtt 0.3107 TrainAcc 0.6700 TestAcc 0.6119 0.6750
epoch 400 LossPred 0.7237 LossAtt 0.3335 TrainAcc 0.7500 TestAcc 0.6749 0.7400
epoch 500 LossPred 0.8431 LossAtt 0.2621 TrainAcc 0.6800 TestAcc 0.6584 0.7050
epoch 600 LossPred 0.7641 LossAtt 0.2552 TrainAcc 0.7200 TestAcc 0.6574 0.7100
epoch 700 LossPred 0.6008 LossAtt 0.2873 TrainAcc 0.8100 TestAcc 0.8001 0.7900
epoch 800 LossPred 0.7942 LossAtt 0.2964 TrainAcc 0.6400 TestAcc 0.6839 0.6400
epoch 900 LossPred 0.7057 LossAtt 0.3181 TrainAcc 0.7600 TestAcc 0.6659 0.7500
epoch 1000 LossPred 0.7001 LossAtt 0.3009 TrainAcc 0.7500 TestAcc 0.6647 0.7450
epoch 1100 LossPred 0.6786 LossAtt 0.3042 TrainAcc 0.7400 TestAcc 0.6919 0.7550
epoch 1200 LossPred 0.6135 LossAtt 0.3066 TrainAcc 0.7500 TestAcc 0.7973 0.7450
epoch 1300 LossPred 0.6005 LossAtt 0.3194 TrainAcc 0.8000 TestAcc 0.7763 0.7850
epoch 1400 LossPred 0.5776 LossAtt 0.3175 TrainAcc 0.7800 TestAcc 0.7638 0.8000
epoch 1500 LossPred 0.5565 LossAtt 0.3203 TrainAcc 0.8100 TestAcc 0.7768 0.8000
epoch 1600 LossPred 0.6287 LossAtt 0.3316 TrainAcc 0.7300 TestAcc 0.7725 0.7450
epoch 1700 LossPred 1.1122 LossAtt 0.2837 TrainAcc 0.5200 TestAcc 0.5878 0.5350
epoch 1800 LossPred 0.8352 LossAtt 0.2602 TrainAcc 0.7100 TestAcc 0.6266 0.7050
epoch 1900 LossPred 0.8093 LossAtt 0.2701 TrainAcc 0.7100 TestAcc 0.6304 0.7100
epoch 2000 LossPred 0.8057 LossAtt 0.2829 TrainAcc 0.7100 TestAcc 0.6296 0.7050
epoch 2100 LossPred 0.8028 LossAtt 0.2459 TrainAcc 0.7100 TestAcc 0.6316 0.7050
epoch 2200 LossPred 0.7843 LossAtt 0.2576 TrainAcc 0.7100 TestAcc 0.6409 0.7150
epoch 2300 LossPred 0.7923 LossAtt 0.2617 TrainAcc 0.7100 TestAcc 0.6369 0.7100
epoch 2400 LossPred 0.7906 LossAtt 0.2630 TrainAcc 0.7100 TestAcc 0.6359 0.7050
epoch 2500 LossPred 0.7794 LossAtt 0.2473 TrainAcc 0.7100 TestAcc 0.6424 0.7150
Optimization Finished!
********** replication  96  **********
epoch   0 LossPred 1.0779 LossAtt 0.9994 TrainAcc 0.4900 TestAcc 0.5075 0.4950
epoch 100 LossPred 0.9436 LossAtt 0.4378 TrainAcc 0.5800 TestAcc 0.5235 0.6050
epoch 200 LossPred 0.8997 LossAtt 0.4474 TrainAcc 0.6600 TestAcc 0.5556 0.6500
epoch 300 LossPred 0.8703 LossAtt 0.3871 TrainAcc 0.6600 TestAcc 0.5556 0.6600
epoch 400 LossPred 0.8354 LossAtt 0.4121 TrainAcc 0.7200 TestAcc 0.5606 0.6700
epoch 500 LossPred 0.8121 LossAtt 0.4966 TrainAcc 0.6900 TestAcc 0.5408 0.6950
epoch 600 LossPred 0.7825 LossAtt 0.5195 TrainAcc 0.7400 TestAcc 0.5385 0.7150
epoch 700 LossPred 0.7583 LossAtt 0.4756 TrainAcc 0.7200 TestAcc 0.5325 0.7100
epoch 800 LossPred 0.7333 LossAtt 0.4255 TrainAcc 0.7200 TestAcc 0.5380 0.7150
epoch 900 LossPred 0.7096 LossAtt 0.4460 TrainAcc 0.7300 TestAcc 0.5393 0.7250
epoch 1000 LossPred 0.6911 LossAtt 0.5010 TrainAcc 0.7500 TestAcc 0.5395 0.7350
epoch 1100 LossPred 0.6434 LossAtt 0.5031 TrainAcc 0.7800 TestAcc 0.5305 0.7500
epoch 1200 LossPred 0.6118 LossAtt 0.5050 TrainAcc 0.7900 TestAcc 0.5355 0.7600
epoch 1300 LossPred 0.5733 LossAtt 0.4943 TrainAcc 0.8100 TestAcc 0.5388 0.7850
epoch 1400 LossPred 0.5832 LossAtt 0.4868 TrainAcc 0.8100 TestAcc 0.5355 0.7700
epoch 1500 LossPred 0.5874 LossAtt 0.4774 TrainAcc 0.8100 TestAcc 0.5235 0.8050
epoch 1600 LossPred 0.5772 LossAtt 0.4944 TrainAcc 0.8100 TestAcc 0.5318 0.7900
epoch 1700 LossPred 0.5791 LossAtt 0.4804 TrainAcc 0.7900 TestAcc 0.5315 0.7900
epoch 1800 LossPred 0.5662 LossAtt 0.4933 TrainAcc 0.8100 TestAcc 0.5360 0.7750
epoch 1900 LossPred 0.5635 LossAtt 0.4840 TrainAcc 0.8200 TestAcc 0.5328 0.7950
epoch 2000 LossPred 0.5635 LossAtt 0.4918 TrainAcc 0.8100 TestAcc 0.5325 0.7900
epoch 2100 LossPred 0.5715 LossAtt 0.4586 TrainAcc 0.8200 TestAcc 0.5338 0.7750
epoch 2200 LossPred 0.5795 LossAtt 0.4952 TrainAcc 0.8200 TestAcc 0.5293 0.7800
epoch 2300 LossPred 0.5471 LossAtt 0.5187 TrainAcc 0.8400 TestAcc 0.5265 0.7900
epoch 2400 LossPred 0.5572 LossAtt 0.4888 TrainAcc 0.8000 TestAcc 0.5318 0.7550
epoch 2500 LossPred 0.5428 LossAtt 0.5229 TrainAcc 0.8100 TestAcc 0.5340 0.7500
Optimization Finished!
********** replication  97  **********
epoch   0 LossPred 1.0232 LossAtt 0.9963 TrainAcc 0.5500 TestAcc 0.5430 0.5350
epoch 100 LossPred 0.9453 LossAtt 0.3586 TrainAcc 0.5700 TestAcc 0.5638 0.5550
epoch 200 LossPred 0.9292 LossAtt 0.2989 TrainAcc 0.6100 TestAcc 0.5886 0.6000
epoch 300 LossPred 0.9083 LossAtt 0.2659 TrainAcc 0.6400 TestAcc 0.5741 0.6050
epoch 400 LossPred 0.8957 LossAtt 0.2084 TrainAcc 0.6400 TestAcc 0.5741 0.6350
epoch 500 LossPred 0.8990 LossAtt 0.1825 TrainAcc 0.6100 TestAcc 0.5886 0.6150
epoch 600 LossPred 0.8921 LossAtt 0.2115 TrainAcc 0.6400 TestAcc 0.5741 0.6200
epoch 700 LossPred 0.8892 LossAtt 0.1966 TrainAcc 0.6400 TestAcc 0.5741 0.6450
epoch 800 LossPred 0.8920 LossAtt 0.1971 TrainAcc 0.6400 TestAcc 0.5741 0.6400
epoch 900 LossPred 0.8851 LossAtt 0.2484 TrainAcc 0.6200 TestAcc 0.5946 0.6150
epoch 1000 LossPred 0.5088 LossAtt 0.3071 TrainAcc 0.8200 TestAcc 0.7830 0.8350
epoch 1100 LossPred 0.4749 LossAtt 0.2856 TrainAcc 0.8300 TestAcc 0.8071 0.8400
epoch 1200 LossPred 0.4717 LossAtt 0.2789 TrainAcc 0.8400 TestAcc 0.8128 0.8400
epoch 1300 LossPred 0.4603 LossAtt 0.2616 TrainAcc 0.8300 TestAcc 0.7923 0.8350
epoch 1400 LossPred 0.4051 LossAtt 0.2793 TrainAcc 0.8700 TestAcc 0.8186 0.8500
epoch 1500 LossPred 0.3936 LossAtt 0.2937 TrainAcc 0.8800 TestAcc 0.8131 0.8650
epoch 1600 LossPred 0.3547 LossAtt 0.3114 TrainAcc 0.9000 TestAcc 0.8408 0.8700
epoch 1700 LossPred 0.2771 LossAtt 0.3063 TrainAcc 0.9000 TestAcc 0.8824 0.8850
epoch 1800 LossPred 0.4047 LossAtt 0.3213 TrainAcc 0.8800 TestAcc 0.8326 0.8550
epoch 1900 LossPred 0.2776 LossAtt 0.3483 TrainAcc 0.9000 TestAcc 0.8851 0.8950
epoch 2000 LossPred 0.3798 LossAtt 0.3438 TrainAcc 0.8800 TestAcc 0.8296 0.8550
epoch 2100 LossPred 0.2550 LossAtt 0.3442 TrainAcc 0.9200 TestAcc 0.8784 0.9000
epoch 2200 LossPred 0.3585 LossAtt 0.3577 TrainAcc 0.8500 TestAcc 0.8136 0.8450
epoch 2300 LossPred 0.2268 LossAtt 0.3680 TrainAcc 0.9100 TestAcc 0.8926 0.8850
epoch 2400 LossPred 0.2694 LossAtt 0.3670 TrainAcc 0.9000 TestAcc 0.8569 0.8800
epoch 2500 LossPred 0.2648 LossAtt 0.3494 TrainAcc 0.9100 TestAcc 0.8789 0.8950
Optimization Finished!
********** replication  98  **********
epoch   0 LossPred 0.9954 LossAtt 1.0015 TrainAcc 0.6100 TestAcc 0.4915 0.5950
epoch 100 LossPred 0.9187 LossAtt 0.4644 TrainAcc 0.6500 TestAcc 0.5443 0.6400
epoch 200 LossPred 0.9111 LossAtt 0.4598 TrainAcc 0.6400 TestAcc 0.5325 0.6400
epoch 300 LossPred 0.9092 LossAtt 0.4320 TrainAcc 0.6600 TestAcc 0.5340 0.6600
epoch 400 LossPred 0.9042 LossAtt 0.3864 TrainAcc 0.6500 TestAcc 0.5483 0.6600
epoch 500 LossPred 0.8992 LossAtt 0.3743 TrainAcc 0.6500 TestAcc 0.5468 0.6600
epoch 600 LossPred 0.8913 LossAtt 0.3989 TrainAcc 0.6600 TestAcc 0.5448 0.6650
epoch 700 LossPred 0.8721 LossAtt 0.4447 TrainAcc 0.6300 TestAcc 0.5448 0.6700
epoch 800 LossPred 0.8354 LossAtt 0.4811 TrainAcc 0.7000 TestAcc 0.5465 0.6700
epoch 900 LossPred 0.8128 LossAtt 0.4671 TrainAcc 0.6900 TestAcc 0.5541 0.7000
epoch 1000 LossPred 0.7900 LossAtt 0.4812 TrainAcc 0.7200 TestAcc 0.5551 0.7050
epoch 1100 LossPred 0.7824 LossAtt 0.4916 TrainAcc 0.7100 TestAcc 0.5478 0.6950
epoch 1200 LossPred 0.7811 LossAtt 0.4688 TrainAcc 0.7300 TestAcc 0.5501 0.7200
epoch 1300 LossPred 0.7803 LossAtt 0.4618 TrainAcc 0.7200 TestAcc 0.5475 0.7200
epoch 1400 LossPred 0.7727 LossAtt 0.4695 TrainAcc 0.7400 TestAcc 0.5478 0.7200
epoch 1500 LossPred 0.7688 LossAtt 0.4620 TrainAcc 0.7400 TestAcc 0.5423 0.7250
epoch 1600 LossPred 0.7628 LossAtt 0.4827 TrainAcc 0.7400 TestAcc 0.5430 0.7400
epoch 1700 LossPred 0.7568 LossAtt 0.4668 TrainAcc 0.7400 TestAcc 0.5398 0.7300
epoch 1800 LossPred 0.7554 LossAtt 0.4389 TrainAcc 0.7400 TestAcc 0.5398 0.7250
epoch 1900 LossPred 0.7548 LossAtt 0.4320 TrainAcc 0.7400 TestAcc 0.5440 0.7200
epoch 2000 LossPred 0.7505 LossAtt 0.4020 TrainAcc 0.7400 TestAcc 0.5440 0.7050
epoch 2100 LossPred 0.7481 LossAtt 0.3982 TrainAcc 0.7400 TestAcc 0.5410 0.7100
epoch 2200 LossPred 0.7451 LossAtt 0.4058 TrainAcc 0.7400 TestAcc 0.5375 0.6950
epoch 2300 LossPred 0.7500 LossAtt 0.3926 TrainAcc 0.7300 TestAcc 0.5375 0.7000
epoch 2400 LossPred 0.7346 LossAtt 0.3924 TrainAcc 0.7400 TestAcc 0.5370 0.7200
epoch 2500 LossPred 0.7339 LossAtt 0.3930 TrainAcc 0.7300 TestAcc 0.5418 0.7250
Optimization Finished!
********** replication  99  **********
epoch   0 LossPred 1.0069 LossAtt 1.0173 TrainAcc 0.5500 TestAcc 0.4980 0.5400
epoch 100 LossPred 0.9705 LossAtt 0.3003 TrainAcc 0.5700 TestAcc 0.5843 0.5600
epoch 200 LossPred 0.9698 LossAtt 0.2413 TrainAcc 0.5700 TestAcc 0.5843 0.5600
epoch 300 LossPred 0.9705 LossAtt 0.1695 TrainAcc 0.5700 TestAcc 0.5843 0.5550
epoch 400 LossPred 0.9684 LossAtt 0.1811 TrainAcc 0.5700 TestAcc 0.5911 0.5700
epoch 500 LossPred 0.9675 LossAtt 0.1616 TrainAcc 0.5700 TestAcc 0.5911 0.5700
epoch 600 LossPred 0.9658 LossAtt 0.1450 TrainAcc 0.5700 TestAcc 0.5726 0.5600
epoch 700 LossPred 0.9585 LossAtt 0.2392 TrainAcc 0.5800 TestAcc 0.6084 0.5900
epoch 800 LossPred 0.9485 LossAtt 0.2259 TrainAcc 0.5800 TestAcc 0.5663 0.5900
epoch 900 LossPred 0.7579 LossAtt 0.4803 TrainAcc 0.7400 TestAcc 0.6542 0.7350
epoch 1000 LossPred 0.8309 LossAtt 0.4634 TrainAcc 0.6900 TestAcc 0.7588 0.7050
epoch 1100 LossPred 0.4574 LossAtt 0.4583 TrainAcc 0.8600 TestAcc 0.8151 0.8700
epoch 1200 LossPred 0.4870 LossAtt 0.4279 TrainAcc 0.8500 TestAcc 0.7598 0.8350
epoch 1300 LossPred 0.7662 LossAtt 0.4552 TrainAcc 0.7200 TestAcc 0.7803 0.7350
epoch 1400 LossPred 0.7219 LossAtt 0.4106 TrainAcc 0.7500 TestAcc 0.6847 0.7650
epoch 1500 LossPred 0.6554 LossAtt 0.4349 TrainAcc 0.7700 TestAcc 0.6949 0.7700
epoch 1600 LossPred 1.2737 LossAtt 0.4529 TrainAcc 0.5200 TestAcc 0.5681 0.5150
epoch 1700 LossPred 0.7625 LossAtt 0.4136 TrainAcc 0.7100 TestAcc 0.6879 0.7250
epoch 1800 LossPred 0.8072 LossAtt 0.3991 TrainAcc 0.6700 TestAcc 0.7077 0.7050
epoch 1900 LossPred 0.8426 LossAtt 0.3813 TrainAcc 0.6600 TestAcc 0.7142 0.6750
epoch 2000 LossPred 0.7786 LossAtt 0.3843 TrainAcc 0.6600 TestAcc 0.7332 0.6900
epoch 2100 LossPred 0.4611 LossAtt 0.3902 TrainAcc 0.8700 TestAcc 0.8116 0.8800
epoch 2200 LossPred 0.4234 LossAtt 0.3850 TrainAcc 0.8500 TestAcc 0.7743 0.8550
epoch 2300 LossPred 0.5949 LossAtt 0.3884 TrainAcc 0.7800 TestAcc 0.8213 0.8200
epoch 2400 LossPred 0.4246 LossAtt 0.3849 TrainAcc 0.8500 TestAcc 0.8258 0.8700
epoch 2500 LossPred 0.4483 LossAtt 0.3679 TrainAcc 0.8500 TestAcc 0.7815 0.8500
Optimization Finished!
********************************************************************
Namespace(arch='tanh', batch_size=256, display_epoch=100, input_noise_level=0.15, latent_attractor_space=True, loss_switch_frequency=0, lrate_attractor=0.002, lrate_prediction=0.002, lrate_wt_penalty=0.0, n_attractor_hidden=10, n_attractor_steps=5, n_hidden=5, n_replications=100, noise_level=0.5, report_best_train_performance=True, seq_len=25, task='majority', train_attr_weights_on_prediction=False, training_epochs=2500)
********************************************************************
mean train accuracy 0.86050004
indiv runs  [0.91, 0.9, 0.74, 0.91, 0.83, 0.95, 0.76, 0.82, 0.91, 0.7, 0.89, 0.93, 0.78, 0.89, 0.94, 0.88, 0.77, 0.92, 0.6, 0.91, 0.88, 0.89, 0.87, 0.9, 0.9, 0.87, 0.59, 0.85, 0.88, 0.95, 0.89, 0.77, 0.71, 0.96, 0.95, 0.89, 0.97, 0.87, 0.86, 0.95, 0.84, 0.9, 0.97, 0.96, 0.79, 0.9, 0.93, 0.87, 0.72, 0.82, 0.86, 0.87, 0.76, 0.91, 0.62, 0.78, 0.84, 0.82, 0.95, 0.75, 0.98, 0.97, 0.95, 0.95, 0.89, 0.92, 0.92, 0.87, 0.82, 0.87, 0.9, 0.78, 0.88, 0.89, 0.94, 0.82, 0.88, 0.92, 0.82, 0.92, 0.84, 0.82, 0.81, 0.77, 0.87, 0.89, 0.92, 0.77, 0.94, 0.87, 0.92, 0.8, 0.87, 0.81, 0.88, 0.81, 0.84, 0.92, 0.74, 0.87]
mean epoch nan
indiv epochs  []
test1 accuracy mean  0.76643145  median  0.8114364
test2 accuracy mean  0.8293  median  0.845
test1 indiv runs  [0.8831331, 0.8133133, 0.5157658, 0.8275776, 0.7512513, 0.7657658, 0.5828328, 0.8128128, 0.8113113, 0.5930931, 0.7992993, 0.8761261, 0.5467968, 0.8068068, 0.8686186, 0.8568569, 0.5435435, 0.8455956, 0.5938438, 0.8160661, 0.7877878, 0.8023023, 0.8588589, 0.7905405, 0.8220721, 0.8160661, 0.5297798, 0.5578078, 0.8428428, 0.8225726, 0.8243243, 0.5683183, 0.5650651, 0.8128128, 0.8806306, 0.8013013, 0.9349349, 0.7802803, 0.8270771, 0.8586086, 0.7875375, 0.8658659, 0.8886386, 0.8581081, 0.5588088, 0.8553554, 0.8138138, 0.7522523, 0.5908408, 0.793043, 0.8280781, 0.5675676, 0.6596597, 0.8253253, 0.5820821, 0.8010511, 0.8195696, 0.7552553, 0.8373373, 0.6186186, 0.9211712, 0.8408408, 0.8418418, 0.8873874, 0.8063063, 0.8333333, 0.8831331, 0.8853854, 0.5815816, 0.7922923, 0.8205706, 0.5950951, 0.8435936, 0.8363363, 0.7905405, 0.529029, 0.8018018, 0.8373373, 0.8033033, 0.8435936, 0.8045546, 0.7947948, 0.8418418, 0.5152653, 0.8531031, 0.7575075, 0.8588589, 0.5850851, 0.8493493, 0.8255756, 0.8733734, 0.8183183, 0.8110611, 0.6756757, 0.7867868, 0.8000501, 0.5265265, 0.8783784, 0.5477978, 0.8115616]
test2 indiv runs  [0.86, 0.845, 0.67, 0.885, 0.795, 0.905, 0.725, 0.765, 0.88, 0.69, 0.85, 0.895, 0.7, 0.885, 0.925, 0.87, 0.705, 0.88, 0.6, 0.87, 0.845, 0.875, 0.835, 0.87, 0.84, 0.82, 0.58, 0.78, 0.88, 0.93, 0.845, 0.735, 0.67, 0.895, 0.915, 0.82, 0.965, 0.82, 0.835, 0.93, 0.79, 0.885, 0.95, 0.96, 0.735, 0.885, 0.9, 0.855, 0.72, 0.775, 0.82, 0.76, 0.735, 0.89, 0.62, 0.795, 0.81, 0.78, 0.915, 0.745, 0.955, 0.915, 0.93, 0.925, 0.89, 0.875, 0.92, 0.845, 0.815, 0.87, 0.85, 0.735, 0.855, 0.865, 0.92, 0.76, 0.805, 0.895, 0.82, 0.88, 0.8, 0.8, 0.8, 0.68, 0.865, 0.865, 0.895, 0.745, 0.89, 0.86, 0.89, 0.77, 0.815, 0.795, 0.845, 0.79, 0.79, 0.9, 0.72, 0.88]
