Namespace(arch='tanh', batch_size=256, display_epoch=100, input_noise_level=0.15, latent_attractor_space=True, loss_switch_frequency=0, lrate_attractor=0.002, lrate_prediction=0.002, lrate_wt_penalty=0.0, n_attractor_hidden=10, n_attractor_steps=5, n_hidden=5, n_replications=100, noise_level=0.25, report_best_train_performance=True, seq_len=30, task='majority', train_attr_weights_on_prediction=False, training_epochs=2500)
TRAINING ON 100 EXAMPLES, TESTING ON 3996
********** replication  0  **********
epoch   0 LossPred 1.1303 LossAtt 1.0449 TrainAcc 0.5300 TestAcc 0.4662 0.5450
epoch 100 LossPred 0.9764 LossAtt 0.6612 TrainAcc 0.6000 TestAcc 0.4905 0.6050
epoch 200 LossPred 0.8898 LossAtt 0.7041 TrainAcc 0.6800 TestAcc 0.5190 0.6850
epoch 300 LossPred 0.8487 LossAtt 0.7146 TrainAcc 0.6900 TestAcc 0.5278 0.6700
epoch 400 LossPred 0.7789 LossAtt 0.7616 TrainAcc 0.7600 TestAcc 0.5273 0.7100
epoch 500 LossPred 0.7223 LossAtt 0.7805 TrainAcc 0.7700 TestAcc 0.5243 0.7400
epoch 600 LossPred 0.6892 LossAtt 0.7532 TrainAcc 0.8100 TestAcc 0.5223 0.7600
epoch 700 LossPred 0.6531 LossAtt 0.7192 TrainAcc 0.8300 TestAcc 0.5205 0.7650
epoch 800 LossPred 0.6252 LossAtt 0.7244 TrainAcc 0.8100 TestAcc 0.5225 0.7500
epoch 900 LossPred 0.6651 LossAtt 0.7099 TrainAcc 0.7500 TestAcc 0.5220 0.7200
epoch 1000 LossPred 0.6067 LossAtt 0.7048 TrainAcc 0.8000 TestAcc 0.5205 0.7350
epoch 1100 LossPred 0.5922 LossAtt 0.6987 TrainAcc 0.8000 TestAcc 0.5220 0.7250
epoch 1200 LossPred 0.5780 LossAtt 0.7063 TrainAcc 0.7900 TestAcc 0.5183 0.7250
epoch 1300 LossPred 0.5939 LossAtt 0.6950 TrainAcc 0.7800 TestAcc 0.5173 0.6950
epoch 1400 LossPred 0.5583 LossAtt 0.6766 TrainAcc 0.8200 TestAcc 0.5210 0.7150
epoch 1500 LossPred 0.5516 LossAtt 0.6803 TrainAcc 0.8100 TestAcc 0.5188 0.7550
epoch 1600 LossPred 0.5414 LossAtt 0.6653 TrainAcc 0.8300 TestAcc 0.5178 0.7450
epoch 1700 LossPred 0.5371 LossAtt 0.6802 TrainAcc 0.8300 TestAcc 0.5185 0.7350
epoch 1800 LossPred 0.5884 LossAtt 0.6669 TrainAcc 0.8000 TestAcc 0.5085 0.7250
epoch 1900 LossPred 0.5454 LossAtt 0.6626 TrainAcc 0.8100 TestAcc 0.5185 0.7200
epoch 2000 LossPred 0.5406 LossAtt 0.6334 TrainAcc 0.8300 TestAcc 0.5213 0.7100
epoch 2100 LossPred 0.5381 LossAtt 0.6442 TrainAcc 0.8100 TestAcc 0.5150 0.7200
epoch 2200 LossPred 0.5357 LossAtt 0.6296 TrainAcc 0.8300 TestAcc 0.5140 0.7150
epoch 2300 LossPred 0.5257 LossAtt 0.6075 TrainAcc 0.8200 TestAcc 0.5175 0.7150
epoch 2400 LossPred 0.5213 LossAtt 0.6083 TrainAcc 0.8100 TestAcc 0.5188 0.7100
epoch 2500 LossPred 0.5257 LossAtt 0.5991 TrainAcc 0.8400 TestAcc 0.5203 0.7050
Optimization Finished!
********** replication  1  **********
epoch   0 LossPred 1.3374 LossAtt 1.0071 TrainAcc 0.4500 TestAcc 0.4920 0.4500
epoch 100 LossPred 1.0461 LossAtt 0.3545 TrainAcc 0.4900 TestAcc 0.5373 0.4550
epoch 200 LossPred 0.9712 LossAtt 0.2954 TrainAcc 0.5800 TestAcc 0.5796 0.5800
epoch 300 LossPred 0.9671 LossAtt 0.1810 TrainAcc 0.5800 TestAcc 0.5796 0.5800
epoch 400 LossPred 0.9658 LossAtt 0.1794 TrainAcc 0.5800 TestAcc 0.5796 0.5800
epoch 500 LossPred 0.9621 LossAtt 0.2035 TrainAcc 0.5800 TestAcc 0.5796 0.5800
epoch 600 LossPred 0.8233 LossAtt 0.5141 TrainAcc 0.7100 TestAcc 0.7427 0.7550
epoch 700 LossPred 0.6084 LossAtt 0.4702 TrainAcc 0.7800 TestAcc 0.8193 0.7700
epoch 800 LossPred 0.5529 LossAtt 0.4602 TrainAcc 0.7900 TestAcc 0.8068 0.7950
epoch 900 LossPred 0.5409 LossAtt 0.4470 TrainAcc 0.7900 TestAcc 0.8141 0.7950
epoch 1000 LossPred 0.5532 LossAtt 0.4368 TrainAcc 0.7800 TestAcc 0.7993 0.7850
epoch 1100 LossPred 0.5598 LossAtt 0.4413 TrainAcc 0.7900 TestAcc 0.8088 0.7900
epoch 1200 LossPred 0.5640 LossAtt 0.4373 TrainAcc 0.7800 TestAcc 0.8066 0.7900
epoch 1300 LossPred 0.5247 LossAtt 0.4441 TrainAcc 0.8000 TestAcc 0.8126 0.7900
epoch 1400 LossPred 0.5087 LossAtt 0.4388 TrainAcc 0.8300 TestAcc 0.8073 0.7850
epoch 1500 LossPred 0.5318 LossAtt 0.4418 TrainAcc 0.8100 TestAcc 0.8238 0.7850
epoch 1600 LossPred 0.6517 LossAtt 0.4828 TrainAcc 0.7800 TestAcc 0.7750 0.7500
epoch 1700 LossPred 0.4916 LossAtt 0.4673 TrainAcc 0.8400 TestAcc 0.8131 0.8100
epoch 1800 LossPred 0.4937 LossAtt 0.4669 TrainAcc 0.8300 TestAcc 0.8236 0.8100
epoch 1900 LossPred 0.5588 LossAtt 0.4830 TrainAcc 0.8000 TestAcc 0.8136 0.7850
epoch 2000 LossPred 0.6940 LossAtt 0.4836 TrainAcc 0.7600 TestAcc 0.7152 0.7100
epoch 2100 LossPred 0.6293 LossAtt 0.5069 TrainAcc 0.7700 TestAcc 0.7673 0.7450
epoch 2200 LossPred 0.4772 LossAtt 0.4890 TrainAcc 0.8500 TestAcc 0.8131 0.8000
epoch 2300 LossPred 0.5403 LossAtt 0.4654 TrainAcc 0.8200 TestAcc 0.8341 0.8250
epoch 2400 LossPred 0.4660 LossAtt 0.4633 TrainAcc 0.8500 TestAcc 0.8346 0.8650
epoch 2500 LossPred 0.4336 LossAtt 0.4797 TrainAcc 0.8600 TestAcc 0.8353 0.8450
Optimization Finished!
********** replication  2  **********
epoch   0 LossPred 1.0512 LossAtt 1.0314 TrainAcc 0.4800 TestAcc 0.4552 0.4800
epoch 100 LossPred 0.9568 LossAtt 0.4476 TrainAcc 0.5900 TestAcc 0.5603 0.5900
epoch 200 LossPred 0.9457 LossAtt 0.3672 TrainAcc 0.5900 TestAcc 0.5603 0.5900
epoch 300 LossPred 0.9083 LossAtt 0.4858 TrainAcc 0.6600 TestAcc 0.5168 0.6300
epoch 400 LossPred 0.8520 LossAtt 0.5726 TrainAcc 0.6800 TestAcc 0.5168 0.6650
epoch 500 LossPred 0.8418 LossAtt 0.5493 TrainAcc 0.6800 TestAcc 0.5195 0.6750
epoch 600 LossPred 0.8359 LossAtt 0.5220 TrainAcc 0.6700 TestAcc 0.5180 0.6550
epoch 700 LossPred 0.8331 LossAtt 0.5025 TrainAcc 0.6700 TestAcc 0.5163 0.6550
epoch 800 LossPred 0.8300 LossAtt 0.4926 TrainAcc 0.6700 TestAcc 0.5178 0.6600
epoch 900 LossPred 0.8269 LossAtt 0.4900 TrainAcc 0.6700 TestAcc 0.5178 0.6600
epoch 1000 LossPred 0.8249 LossAtt 0.4830 TrainAcc 0.6700 TestAcc 0.5183 0.6500
epoch 1100 LossPred 0.8211 LossAtt 0.4946 TrainAcc 0.6800 TestAcc 0.5190 0.6700
epoch 1200 LossPred 0.8137 LossAtt 0.5228 TrainAcc 0.6900 TestAcc 0.5338 0.6800
epoch 1300 LossPred 0.7886 LossAtt 0.5681 TrainAcc 0.6800 TestAcc 0.5603 0.6750
epoch 1400 LossPred 0.7105 LossAtt 0.5677 TrainAcc 0.7300 TestAcc 0.5896 0.6950
epoch 1500 LossPred 0.6690 LossAtt 0.6172 TrainAcc 0.7400 TestAcc 0.5931 0.7050
epoch 1600 LossPred 0.6021 LossAtt 0.6262 TrainAcc 0.7900 TestAcc 0.6101 0.7250
epoch 1700 LossPred 0.5726 LossAtt 0.6178 TrainAcc 0.8000 TestAcc 0.6151 0.7700
epoch 1800 LossPred 0.5718 LossAtt 0.6418 TrainAcc 0.8000 TestAcc 0.6099 0.7600
epoch 1900 LossPred 0.5672 LossAtt 0.6256 TrainAcc 0.8000 TestAcc 0.6054 0.7650
epoch 2000 LossPred 0.5634 LossAtt 0.6463 TrainAcc 0.8200 TestAcc 0.6086 0.7600
epoch 2100 LossPred 0.5320 LossAtt 0.6266 TrainAcc 0.8200 TestAcc 0.6109 0.7700
epoch 2200 LossPred 0.5195 LossAtt 0.6822 TrainAcc 0.8300 TestAcc 0.6144 0.7750
epoch 2300 LossPred 0.5103 LossAtt 0.6487 TrainAcc 0.8400 TestAcc 0.6176 0.7650
epoch 2400 LossPred 0.5144 LossAtt 0.6165 TrainAcc 0.8400 TestAcc 0.6089 0.7650
epoch 2500 LossPred 0.5051 LossAtt 0.6049 TrainAcc 0.8400 TestAcc 0.6169 0.7650
Optimization Finished!
********** replication  3  **********
epoch   0 LossPred 0.9382 LossAtt 1.0284 TrainAcc 0.5800 TestAcc 0.4615 0.5700
epoch 100 LossPred 0.8656 LossAtt 0.6480 TrainAcc 0.6800 TestAcc 0.5053 0.6750
epoch 200 LossPred 0.7633 LossAtt 0.6877 TrainAcc 0.6900 TestAcc 0.5110 0.7100
epoch 300 LossPred 0.7235 LossAtt 0.7488 TrainAcc 0.7300 TestAcc 0.5168 0.7200
epoch 400 LossPred 0.6754 LossAtt 0.7702 TrainAcc 0.7400 TestAcc 0.5325 0.7350
epoch 500 LossPred 0.6409 LossAtt 0.7441 TrainAcc 0.7500 TestAcc 0.5473 0.7600
epoch 600 LossPred 0.5466 LossAtt 0.7305 TrainAcc 0.7900 TestAcc 0.6316 0.8000
epoch 700 LossPred 0.4869 LossAtt 0.7077 TrainAcc 0.8000 TestAcc 0.7200 0.7800
epoch 800 LossPred 0.5290 LossAtt 0.6844 TrainAcc 0.8300 TestAcc 0.7227 0.8350
epoch 900 LossPred 0.4957 LossAtt 0.6750 TrainAcc 0.8100 TestAcc 0.7072 0.8100
epoch 1000 LossPred 0.4919 LossAtt 0.6663 TrainAcc 0.8300 TestAcc 0.7247 0.8250
epoch 1100 LossPred 0.4308 LossAtt 0.6634 TrainAcc 0.8300 TestAcc 0.7142 0.8200
epoch 1200 LossPred 0.4737 LossAtt 0.6550 TrainAcc 0.8200 TestAcc 0.7352 0.8150
epoch 1300 LossPred 0.5941 LossAtt 0.6765 TrainAcc 0.7700 TestAcc 0.7528 0.7750
epoch 1400 LossPred 0.7094 LossAtt 0.6348 TrainAcc 0.7700 TestAcc 0.6524 0.7550
epoch 1500 LossPred 0.4510 LossAtt 0.6341 TrainAcc 0.8400 TestAcc 0.7462 0.8200
epoch 1600 LossPred 0.4935 LossAtt 0.6519 TrainAcc 0.8100 TestAcc 0.7455 0.8200
epoch 1700 LossPred 0.4680 LossAtt 0.6285 TrainAcc 0.8200 TestAcc 0.7250 0.8150
epoch 1800 LossPred 0.6284 LossAtt 0.6500 TrainAcc 0.7500 TestAcc 0.6374 0.7400
epoch 1900 LossPred 0.4670 LossAtt 0.6185 TrainAcc 0.8200 TestAcc 0.7162 0.8150
epoch 2000 LossPred 0.5332 LossAtt 0.6165 TrainAcc 0.7900 TestAcc 0.7312 0.7950
epoch 2100 LossPred 0.4733 LossAtt 0.6199 TrainAcc 0.8300 TestAcc 0.7355 0.8350
epoch 2200 LossPred 0.5197 LossAtt 0.6265 TrainAcc 0.8400 TestAcc 0.7065 0.8300
epoch 2300 LossPred 0.4773 LossAtt 0.6179 TrainAcc 0.8000 TestAcc 0.7465 0.8350
epoch 2400 LossPred 0.4706 LossAtt 0.6547 TrainAcc 0.8100 TestAcc 0.7212 0.8150
epoch 2500 LossPred 0.4429 LossAtt 0.6336 TrainAcc 0.8100 TestAcc 0.7387 0.8100
Optimization Finished!
********** replication  4  **********
epoch   0 LossPred 1.2466 LossAtt 1.0106 TrainAcc 0.4400 TestAcc 0.4802 0.4500
epoch 100 LossPred 1.0181 LossAtt 0.5296 TrainAcc 0.5200 TestAcc 0.4907 0.5150
epoch 200 LossPred 0.9477 LossAtt 0.4837 TrainAcc 0.6100 TestAcc 0.5581 0.6100
epoch 300 LossPred 0.9277 LossAtt 0.3789 TrainAcc 0.6100 TestAcc 0.5581 0.6100
epoch 400 LossPred 0.9151 LossAtt 0.4217 TrainAcc 0.6400 TestAcc 0.5751 0.6150
epoch 500 LossPred 0.4930 LossAtt 0.5586 TrainAcc 0.8400 TestAcc 0.7975 0.8150
epoch 600 LossPred 0.3955 LossAtt 0.5361 TrainAcc 0.8700 TestAcc 0.8313 0.8000
epoch 700 LossPred 0.3920 LossAtt 0.5321 TrainAcc 0.8700 TestAcc 0.8293 0.8250
epoch 800 LossPred 0.3554 LossAtt 0.4931 TrainAcc 0.8700 TestAcc 0.8241 0.8200
epoch 900 LossPred 0.3968 LossAtt 0.4546 TrainAcc 0.8500 TestAcc 0.8263 0.8400
epoch 1000 LossPred 0.2942 LossAtt 0.4208 TrainAcc 0.9100 TestAcc 0.8328 0.8700
epoch 1100 LossPred 0.2976 LossAtt 0.4001 TrainAcc 0.9100 TestAcc 0.8356 0.8750
epoch 1200 LossPred 0.2991 LossAtt 0.3910 TrainAcc 0.9000 TestAcc 0.8371 0.8700
epoch 1300 LossPred 0.2856 LossAtt 0.3668 TrainAcc 0.9100 TestAcc 0.8353 0.8750
epoch 1400 LossPred 0.2881 LossAtt 0.3663 TrainAcc 0.9000 TestAcc 0.8401 0.8800
epoch 1500 LossPred 0.3000 LossAtt 0.3488 TrainAcc 0.8900 TestAcc 0.8418 0.8800
epoch 1600 LossPred 0.3593 LossAtt 0.3424 TrainAcc 0.8900 TestAcc 0.8196 0.8500
epoch 1700 LossPred 0.3108 LossAtt 0.3450 TrainAcc 0.8900 TestAcc 0.8411 0.8700
epoch 1800 LossPred 0.2965 LossAtt 0.3244 TrainAcc 0.9000 TestAcc 0.8341 0.8700
epoch 1900 LossPred 0.3037 LossAtt 0.3504 TrainAcc 0.8900 TestAcc 0.8351 0.8750
epoch 2000 LossPred 0.2920 LossAtt 0.3382 TrainAcc 0.9000 TestAcc 0.8373 0.8750
epoch 2100 LossPred 0.2884 LossAtt 0.3304 TrainAcc 0.9000 TestAcc 0.8376 0.8800
epoch 2200 LossPred 0.2829 LossAtt 0.3289 TrainAcc 0.9000 TestAcc 0.8396 0.8850
epoch 2300 LossPred 0.3054 LossAtt 0.3645 TrainAcc 0.8900 TestAcc 0.8438 0.8750
epoch 2400 LossPred 0.2842 LossAtt 0.3424 TrainAcc 0.9000 TestAcc 0.8381 0.8850
epoch 2500 LossPred 0.2891 LossAtt 0.3415 TrainAcc 0.9000 TestAcc 0.8408 0.8850
Optimization Finished!
********** replication  5  **********
epoch   0 LossPred 1.0832 LossAtt 1.0102 TrainAcc 0.5100 TestAcc 0.4830 0.5300
epoch 100 LossPred 0.9366 LossAtt 0.4435 TrainAcc 0.6300 TestAcc 0.5818 0.6050
epoch 200 LossPred 0.8822 LossAtt 0.4746 TrainAcc 0.6300 TestAcc 0.5818 0.6400
epoch 300 LossPred 0.8523 LossAtt 0.5220 TrainAcc 0.6700 TestAcc 0.6186 0.6700
epoch 400 LossPred 0.8396 LossAtt 0.5187 TrainAcc 0.6600 TestAcc 0.6241 0.6650
epoch 500 LossPred 0.8219 LossAtt 0.5745 TrainAcc 0.6800 TestAcc 0.6451 0.6900
epoch 600 LossPred 0.6234 LossAtt 0.6658 TrainAcc 0.7800 TestAcc 0.7382 0.7850
epoch 700 LossPred 0.2930 LossAtt 0.5612 TrainAcc 0.9300 TestAcc 0.8243 0.9000
epoch 800 LossPred 0.3299 LossAtt 0.5338 TrainAcc 0.8900 TestAcc 0.7823 0.8750
epoch 900 LossPred 0.2631 LossAtt 0.5476 TrainAcc 0.9100 TestAcc 0.8153 0.8900
epoch 1000 LossPred 0.2089 LossAtt 0.5307 TrainAcc 0.9400 TestAcc 0.8331 0.8950
epoch 1100 LossPred 0.2144 LossAtt 0.5079 TrainAcc 0.9300 TestAcc 0.8231 0.9050
epoch 1200 LossPred 0.1941 LossAtt 0.5151 TrainAcc 0.9600 TestAcc 0.8361 0.8950
epoch 1300 LossPred 0.1964 LossAtt 0.5009 TrainAcc 0.9500 TestAcc 0.8413 0.9000
epoch 1400 LossPred 0.2445 LossAtt 0.4921 TrainAcc 0.9300 TestAcc 0.8108 0.8900
epoch 1500 LossPred 0.1975 LossAtt 0.4899 TrainAcc 0.9500 TestAcc 0.8168 0.9050
epoch 1600 LossPred 0.2077 LossAtt 0.4876 TrainAcc 0.9400 TestAcc 0.8336 0.9050
epoch 1700 LossPred 0.1844 LossAtt 0.5038 TrainAcc 0.9500 TestAcc 0.8333 0.8950
epoch 1800 LossPred 0.1912 LossAtt 0.4730 TrainAcc 0.9600 TestAcc 0.8403 0.9000
epoch 1900 LossPred 0.1751 LossAtt 0.4758 TrainAcc 0.9500 TestAcc 0.8343 0.9050
epoch 2000 LossPred 0.1937 LossAtt 0.4841 TrainAcc 0.9400 TestAcc 0.8388 0.9150
epoch 2100 LossPred 0.1782 LossAtt 0.4593 TrainAcc 0.9600 TestAcc 0.8356 0.9100
epoch 2200 LossPred 0.1986 LossAtt 0.4730 TrainAcc 0.9300 TestAcc 0.8321 0.9150
epoch 2300 LossPred 0.1979 LossAtt 0.4703 TrainAcc 0.9300 TestAcc 0.8296 0.9150
epoch 2400 LossPred 0.3402 LossAtt 0.4665 TrainAcc 0.8800 TestAcc 0.8028 0.8700
epoch 2500 LossPred 0.3051 LossAtt 0.4541 TrainAcc 0.9000 TestAcc 0.8273 0.8950
Optimization Finished!
********** replication  6  **********
epoch   0 LossPred 1.0700 LossAtt 1.0176 TrainAcc 0.4900 TestAcc 0.5075 0.4950
epoch 100 LossPred 0.9621 LossAtt 0.5809 TrainAcc 0.5900 TestAcc 0.5543 0.5600
epoch 200 LossPred 0.9324 LossAtt 0.6527 TrainAcc 0.6600 TestAcc 0.5483 0.6350
epoch 300 LossPred 0.8956 LossAtt 0.7241 TrainAcc 0.6700 TestAcc 0.5450 0.6500
epoch 400 LossPred 0.8219 LossAtt 0.7124 TrainAcc 0.6800 TestAcc 0.5445 0.6650
epoch 500 LossPred 0.8127 LossAtt 0.6788 TrainAcc 0.6800 TestAcc 0.5546 0.6550
epoch 600 LossPred 0.8176 LossAtt 0.6673 TrainAcc 0.6800 TestAcc 0.5528 0.6650
epoch 700 LossPred 0.7854 LossAtt 0.6496 TrainAcc 0.6900 TestAcc 0.5596 0.6500
epoch 800 LossPred 0.7734 LossAtt 0.6319 TrainAcc 0.7000 TestAcc 0.5556 0.6550
epoch 900 LossPred 0.7715 LossAtt 0.6300 TrainAcc 0.7000 TestAcc 0.5556 0.6500
epoch 1000 LossPred 0.7637 LossAtt 0.5854 TrainAcc 0.7200 TestAcc 0.5521 0.6650
epoch 1100 LossPred 0.7764 LossAtt 0.5443 TrainAcc 0.7000 TestAcc 0.5518 0.6550
epoch 1200 LossPred 0.7794 LossAtt 0.5169 TrainAcc 0.7100 TestAcc 0.5460 0.6800
epoch 1300 LossPred 0.7609 LossAtt 0.5002 TrainAcc 0.7200 TestAcc 0.5423 0.6800
epoch 1400 LossPred 0.7590 LossAtt 0.5357 TrainAcc 0.6900 TestAcc 0.5403 0.6750
epoch 1500 LossPred 0.7704 LossAtt 0.4955 TrainAcc 0.7400 TestAcc 0.5428 0.7050
epoch 1600 LossPred 0.7757 LossAtt 0.4920 TrainAcc 0.7100 TestAcc 0.5310 0.6950
epoch 1700 LossPred 0.7748 LossAtt 0.4902 TrainAcc 0.7000 TestAcc 0.5295 0.6800
epoch 1800 LossPred 0.7755 LossAtt 0.5056 TrainAcc 0.7200 TestAcc 0.5198 0.6750
epoch 1900 LossPred 0.7719 LossAtt 0.5235 TrainAcc 0.7100 TestAcc 0.5255 0.6650
epoch 2000 LossPred 0.7775 LossAtt 0.5321 TrainAcc 0.6900 TestAcc 0.5325 0.6850
epoch 2100 LossPred 0.7628 LossAtt 0.5120 TrainAcc 0.7100 TestAcc 0.5213 0.6700
epoch 2200 LossPred 0.7710 LossAtt 0.5119 TrainAcc 0.7100 TestAcc 0.5220 0.6800
epoch 2300 LossPred 0.7679 LossAtt 0.5187 TrainAcc 0.7000 TestAcc 0.5208 0.6850
epoch 2400 LossPred 0.7728 LossAtt 0.5151 TrainAcc 0.6900 TestAcc 0.5253 0.6700
epoch 2500 LossPred 0.7607 LossAtt 0.5279 TrainAcc 0.7200 TestAcc 0.5210 0.6900
Optimization Finished!
********** replication  7  **********
epoch   0 LossPred 1.0292 LossAtt 1.0208 TrainAcc 0.5200 TestAcc 0.5030 0.5150
epoch 100 LossPred 0.9494 LossAtt 0.5495 TrainAcc 0.5700 TestAcc 0.5818 0.5850
epoch 200 LossPred 0.9372 LossAtt 0.5182 TrainAcc 0.5900 TestAcc 0.5631 0.6000
epoch 300 LossPred 0.9301 LossAtt 0.5775 TrainAcc 0.5700 TestAcc 0.5363 0.5800
epoch 400 LossPred 0.8257 LossAtt 0.6985 TrainAcc 0.6600 TestAcc 0.5903 0.6750
epoch 500 LossPred 0.5605 LossAtt 0.7650 TrainAcc 0.8000 TestAcc 0.7995 0.7550
epoch 600 LossPred 0.6087 LossAtt 0.7744 TrainAcc 0.7700 TestAcc 0.7815 0.7450
epoch 700 LossPred 0.4995 LossAtt 0.7497 TrainAcc 0.8100 TestAcc 0.8046 0.7650
epoch 800 LossPred 0.4542 LossAtt 0.7284 TrainAcc 0.8500 TestAcc 0.8066 0.7750
epoch 900 LossPred 0.4816 LossAtt 0.6675 TrainAcc 0.8400 TestAcc 0.8123 0.8000
epoch 1000 LossPred 0.6051 LossAtt 0.6146 TrainAcc 0.8000 TestAcc 0.7688 0.8100
epoch 1100 LossPred 0.5426 LossAtt 0.6151 TrainAcc 0.7900 TestAcc 0.8061 0.7950
epoch 1200 LossPred 0.5960 LossAtt 0.5873 TrainAcc 0.8200 TestAcc 0.7775 0.8100
epoch 1300 LossPred 0.6082 LossAtt 0.5865 TrainAcc 0.8000 TestAcc 0.7773 0.8100
epoch 1400 LossPred 0.7297 LossAtt 0.5299 TrainAcc 0.7500 TestAcc 0.7137 0.7550
epoch 1500 LossPred 0.6604 LossAtt 0.5250 TrainAcc 0.7200 TestAcc 0.7407 0.7350
epoch 1600 LossPred 0.5664 LossAtt 0.5479 TrainAcc 0.8000 TestAcc 0.7738 0.7900
epoch 1700 LossPred 0.4623 LossAtt 0.5996 TrainAcc 0.8500 TestAcc 0.8028 0.8300
epoch 1800 LossPred 0.4751 LossAtt 0.6129 TrainAcc 0.8500 TestAcc 0.7978 0.8650
epoch 1900 LossPred 0.5238 LossAtt 0.5873 TrainAcc 0.8400 TestAcc 0.7990 0.8450
epoch 2000 LossPred 0.6067 LossAtt 0.5867 TrainAcc 0.8000 TestAcc 0.7808 0.8000
epoch 2100 LossPred 0.4839 LossAtt 0.6040 TrainAcc 0.8600 TestAcc 0.7963 0.8650
epoch 2200 LossPred 0.4241 LossAtt 0.6166 TrainAcc 0.8800 TestAcc 0.7955 0.8750
epoch 2300 LossPred 0.4061 LossAtt 0.6184 TrainAcc 0.8800 TestAcc 0.7978 0.8800
epoch 2400 LossPred 0.4127 LossAtt 0.6262 TrainAcc 0.8600 TestAcc 0.7930 0.8600
epoch 2500 LossPred 0.4221 LossAtt 0.5982 TrainAcc 0.8700 TestAcc 0.8061 0.8600
Optimization Finished!
********** replication  8  **********
epoch   0 LossPred 1.2724 LossAtt 1.0433 TrainAcc 0.4200 TestAcc 0.4249 0.4200
epoch 100 LossPred 0.9809 LossAtt 0.4965 TrainAcc 0.5800 TestAcc 0.5751 0.5800
epoch 200 LossPred 0.9536 LossAtt 0.4603 TrainAcc 0.5800 TestAcc 0.5751 0.5900
epoch 300 LossPred 0.9129 LossAtt 0.4538 TrainAcc 0.6000 TestAcc 0.5320 0.6100
epoch 400 LossPred 0.8955 LossAtt 0.3932 TrainAcc 0.6100 TestAcc 0.5686 0.6300
epoch 500 LossPred 0.8825 LossAtt 0.3784 TrainAcc 0.6400 TestAcc 0.6086 0.6450
epoch 600 LossPred 0.8151 LossAtt 0.5347 TrainAcc 0.6800 TestAcc 0.6471 0.6700
epoch 700 LossPred 0.5604 LossAtt 0.6347 TrainAcc 0.8000 TestAcc 0.7868 0.7800
epoch 800 LossPred 0.4815 LossAtt 0.6428 TrainAcc 0.8400 TestAcc 0.8266 0.8350
epoch 900 LossPred 0.4252 LossAtt 0.6483 TrainAcc 0.8500 TestAcc 0.8061 0.8350
epoch 1000 LossPred 0.4012 LossAtt 0.6414 TrainAcc 0.8800 TestAcc 0.8261 0.8500
epoch 1100 LossPred 0.3891 LossAtt 0.6452 TrainAcc 0.9000 TestAcc 0.8481 0.8600
epoch 1200 LossPred 0.5118 LossAtt 0.6436 TrainAcc 0.8600 TestAcc 0.8238 0.8200
epoch 1300 LossPred 0.3613 LossAtt 0.6376 TrainAcc 0.8700 TestAcc 0.8143 0.8350
epoch 1400 LossPred 0.3001 LossAtt 0.6034 TrainAcc 0.9100 TestAcc 0.8328 0.8500
epoch 1500 LossPred 0.4391 LossAtt 0.6069 TrainAcc 0.8600 TestAcc 0.8431 0.8400
epoch 1600 LossPred 0.2599 LossAtt 0.6002 TrainAcc 0.9100 TestAcc 0.8481 0.8900
epoch 1700 LossPred 0.2602 LossAtt 0.6308 TrainAcc 0.9300 TestAcc 0.8403 0.8900
epoch 1800 LossPred 0.3527 LossAtt 0.6153 TrainAcc 0.9100 TestAcc 0.8343 0.8500
epoch 1900 LossPred 0.2223 LossAtt 0.5774 TrainAcc 0.9400 TestAcc 0.8408 0.8850
epoch 2000 LossPred 0.3282 LossAtt 0.6022 TrainAcc 0.9200 TestAcc 0.8288 0.8800
epoch 2100 LossPred 0.1752 LossAtt 0.6196 TrainAcc 0.9500 TestAcc 0.8368 0.9050
epoch 2200 LossPred 0.2869 LossAtt 0.6311 TrainAcc 0.9000 TestAcc 0.8141 0.9000
epoch 2300 LossPred 0.1546 LossAtt 0.6148 TrainAcc 0.9600 TestAcc 0.8283 0.9000
epoch 2400 LossPred 0.2588 LossAtt 0.6582 TrainAcc 0.9200 TestAcc 0.8173 0.9100
epoch 2500 LossPred 0.1853 LossAtt 0.6308 TrainAcc 0.9500 TestAcc 0.8398 0.9200
Optimization Finished!
********** replication  9  **********
epoch   0 LossPred 0.9773 LossAtt 1.0112 TrainAcc 0.5700 TestAcc 0.4892 0.5700
epoch 100 LossPred 0.9631 LossAtt 0.4745 TrainAcc 0.5300 TestAcc 0.5353 0.5650
epoch 200 LossPred 0.9542 LossAtt 0.3968 TrainAcc 0.5600 TestAcc 0.5018 0.5750
epoch 300 LossPred 0.9149 LossAtt 0.5780 TrainAcc 0.6500 TestAcc 0.6279 0.6350
epoch 400 LossPred 0.3093 LossAtt 0.6531 TrainAcc 0.9300 TestAcc 0.8303 0.8350
epoch 500 LossPred 0.3207 LossAtt 0.6231 TrainAcc 0.9200 TestAcc 0.8376 0.8350
epoch 600 LossPred 0.3409 LossAtt 0.5995 TrainAcc 0.9100 TestAcc 0.8273 0.8550
epoch 700 LossPred 0.2643 LossAtt 0.5673 TrainAcc 0.9400 TestAcc 0.8283 0.8400
epoch 800 LossPred 0.3252 LossAtt 0.5448 TrainAcc 0.8900 TestAcc 0.8273 0.8500
epoch 900 LossPred 0.2966 LossAtt 0.5370 TrainAcc 0.9300 TestAcc 0.8268 0.8400
epoch 1000 LossPred 0.2674 LossAtt 0.5144 TrainAcc 0.9200 TestAcc 0.8248 0.8550
epoch 1100 LossPred 0.3235 LossAtt 0.5193 TrainAcc 0.8900 TestAcc 0.8261 0.8450
epoch 1200 LossPred 0.2677 LossAtt 0.4984 TrainAcc 0.9300 TestAcc 0.8233 0.8600
epoch 1300 LossPred 0.3133 LossAtt 0.4898 TrainAcc 0.9000 TestAcc 0.8241 0.8650
epoch 1400 LossPred 0.2848 LossAtt 0.5179 TrainAcc 0.9200 TestAcc 0.8268 0.8700
epoch 1500 LossPred 0.3205 LossAtt 0.5039 TrainAcc 0.9000 TestAcc 0.8278 0.8700
epoch 1600 LossPred 0.2942 LossAtt 0.5176 TrainAcc 0.9100 TestAcc 0.8321 0.8650
epoch 1700 LossPred 0.2657 LossAtt 0.5007 TrainAcc 0.9300 TestAcc 0.8231 0.8800
epoch 1800 LossPred 0.2775 LossAtt 0.5065 TrainAcc 0.9300 TestAcc 0.8206 0.8750
epoch 1900 LossPred 0.3283 LossAtt 0.5132 TrainAcc 0.9000 TestAcc 0.8138 0.8650
epoch 2000 LossPred 0.3685 LossAtt 0.5075 TrainAcc 0.9000 TestAcc 0.8056 0.8450
epoch 2100 LossPred 0.2764 LossAtt 0.4855 TrainAcc 0.9300 TestAcc 0.8206 0.8650
epoch 2200 LossPred 0.3034 LossAtt 0.4939 TrainAcc 0.9100 TestAcc 0.8236 0.8700
epoch 2300 LossPred 0.2602 LossAtt 0.4954 TrainAcc 0.9400 TestAcc 0.8231 0.8800
epoch 2400 LossPred 0.2536 LossAtt 0.5080 TrainAcc 0.9400 TestAcc 0.8256 0.8850
epoch 2500 LossPred 0.2932 LossAtt 0.4724 TrainAcc 0.9300 TestAcc 0.8236 0.8900
Optimization Finished!
********** replication  10  **********
epoch   0 LossPred 0.9678 LossAtt 1.0981 TrainAcc 0.6300 TestAcc 0.5666 0.6300
epoch 100 LossPred 0.8701 LossAtt 0.6813 TrainAcc 0.6600 TestAcc 0.5345 0.6700
epoch 200 LossPred 0.8407 LossAtt 0.6739 TrainAcc 0.6900 TestAcc 0.5220 0.6900
epoch 300 LossPred 0.8071 LossAtt 0.6739 TrainAcc 0.7100 TestAcc 0.5318 0.6900
epoch 400 LossPred 0.7636 LossAtt 0.6728 TrainAcc 0.7300 TestAcc 0.5253 0.7250
epoch 500 LossPred 0.7273 LossAtt 0.7066 TrainAcc 0.7300 TestAcc 0.5283 0.7350
epoch 600 LossPred 0.6977 LossAtt 0.7317 TrainAcc 0.7500 TestAcc 0.5235 0.7350
epoch 700 LossPred 0.6415 LossAtt 0.7249 TrainAcc 0.7800 TestAcc 0.5243 0.7300
epoch 800 LossPred 0.6167 LossAtt 0.6881 TrainAcc 0.7900 TestAcc 0.5218 0.7450
epoch 900 LossPred 0.5891 LossAtt 0.6966 TrainAcc 0.8000 TestAcc 0.5368 0.7600
epoch 1000 LossPred 0.5780 LossAtt 0.6992 TrainAcc 0.8000 TestAcc 0.5443 0.7650
epoch 1100 LossPred 0.5725 LossAtt 0.6749 TrainAcc 0.7900 TestAcc 0.5390 0.7550
epoch 1200 LossPred 0.5669 LossAtt 0.6770 TrainAcc 0.8100 TestAcc 0.5348 0.7700
epoch 1300 LossPred 0.5818 LossAtt 0.6839 TrainAcc 0.7900 TestAcc 0.5385 0.7750
epoch 1400 LossPred 0.5363 LossAtt 0.6455 TrainAcc 0.8300 TestAcc 0.5408 0.7450
epoch 1500 LossPred 0.5455 LossAtt 0.6211 TrainAcc 0.8100 TestAcc 0.5543 0.7850
epoch 1600 LossPred 0.5273 LossAtt 0.6387 TrainAcc 0.8200 TestAcc 0.5526 0.7650
epoch 1700 LossPred 0.5351 LossAtt 0.6226 TrainAcc 0.8300 TestAcc 0.5470 0.7650
epoch 1800 LossPred 0.5183 LossAtt 0.5906 TrainAcc 0.8100 TestAcc 0.5470 0.7750
epoch 1900 LossPred 0.5133 LossAtt 0.6039 TrainAcc 0.8200 TestAcc 0.5516 0.7700
epoch 2000 LossPred 0.5097 LossAtt 0.5882 TrainAcc 0.8000 TestAcc 0.5315 0.7650
epoch 2100 LossPred 0.5300 LossAtt 0.6028 TrainAcc 0.8000 TestAcc 0.5363 0.7850
epoch 2200 LossPred 0.5242 LossAtt 0.5996 TrainAcc 0.8100 TestAcc 0.5518 0.7750
epoch 2300 LossPred 0.5011 LossAtt 0.5929 TrainAcc 0.8300 TestAcc 0.5335 0.7650
epoch 2400 LossPred 0.5621 LossAtt 0.5910 TrainAcc 0.7900 TestAcc 0.5233 0.7800
epoch 2500 LossPred 0.5033 LossAtt 0.5853 TrainAcc 0.8100 TestAcc 0.5445 0.7600
Optimization Finished!
********** replication  11  **********
epoch   0 LossPred 1.1692 LossAtt 1.0223 TrainAcc 0.5600 TestAcc 0.5873 0.5200
epoch 100 LossPred 0.9456 LossAtt 0.5800 TrainAcc 0.5900 TestAcc 0.5358 0.5650
epoch 200 LossPred 0.8733 LossAtt 0.6126 TrainAcc 0.6900 TestAcc 0.5926 0.6850
epoch 300 LossPred 0.7274 LossAtt 0.5719 TrainAcc 0.7600 TestAcc 0.6782 0.6900
epoch 400 LossPred 0.6735 LossAtt 0.5440 TrainAcc 0.7200 TestAcc 0.7292 0.7250
epoch 500 LossPred 0.6388 LossAtt 0.5524 TrainAcc 0.7600 TestAcc 0.7640 0.7150
epoch 600 LossPred 0.8950 LossAtt 0.4806 TrainAcc 0.6800 TestAcc 0.7588 0.7050
epoch 700 LossPred 0.7752 LossAtt 0.4828 TrainAcc 0.7100 TestAcc 0.7503 0.7200
epoch 800 LossPred 0.7550 LossAtt 0.4692 TrainAcc 0.7200 TestAcc 0.7503 0.7050
epoch 900 LossPred 0.8541 LossAtt 0.4621 TrainAcc 0.6400 TestAcc 0.6959 0.6200
epoch 1000 LossPred 0.7155 LossAtt 0.4879 TrainAcc 0.7400 TestAcc 0.8018 0.7300
epoch 1100 LossPred 0.6611 LossAtt 0.4885 TrainAcc 0.7600 TestAcc 0.8021 0.7250
epoch 1200 LossPred 0.6361 LossAtt 0.4792 TrainAcc 0.7500 TestAcc 0.8081 0.7450
epoch 1300 LossPred 0.6288 LossAtt 0.4211 TrainAcc 0.7500 TestAcc 0.8106 0.7350
epoch 1400 LossPred 0.6360 LossAtt 0.4020 TrainAcc 0.7600 TestAcc 0.8041 0.7500
epoch 1500 LossPred 0.6270 LossAtt 0.3882 TrainAcc 0.7600 TestAcc 0.8006 0.7450
epoch 1600 LossPred 0.6521 LossAtt 0.4103 TrainAcc 0.7700 TestAcc 0.8061 0.7600
epoch 1700 LossPred 0.6517 LossAtt 0.4069 TrainAcc 0.7700 TestAcc 0.8053 0.7500
epoch 1800 LossPred 0.6427 LossAtt 0.4079 TrainAcc 0.7500 TestAcc 0.8061 0.7500
epoch 1900 LossPred 0.6336 LossAtt 0.3878 TrainAcc 0.7700 TestAcc 0.7968 0.7350
epoch 2000 LossPred 0.6272 LossAtt 0.4118 TrainAcc 0.7800 TestAcc 0.8018 0.7150
epoch 2100 LossPred 0.6522 LossAtt 0.4292 TrainAcc 0.7700 TestAcc 0.8111 0.7550
epoch 2200 LossPred 0.6372 LossAtt 0.4057 TrainAcc 0.7600 TestAcc 0.8108 0.7450
epoch 2300 LossPred 0.6361 LossAtt 0.4031 TrainAcc 0.7600 TestAcc 0.8168 0.7750
epoch 2400 LossPred 0.6928 LossAtt 0.3832 TrainAcc 0.7400 TestAcc 0.7975 0.7400
epoch 2500 LossPred 0.6178 LossAtt 0.3981 TrainAcc 0.7500 TestAcc 0.7985 0.7400
Optimization Finished!
********** replication  12  **********
epoch   0 LossPred 1.5541 LossAtt 1.0172 TrainAcc 0.4400 TestAcc 0.5235 0.4200
epoch 100 LossPred 1.1175 LossAtt 0.6742 TrainAcc 0.4600 TestAcc 0.5355 0.4500
epoch 200 LossPred 0.9514 LossAtt 0.6652 TrainAcc 0.6200 TestAcc 0.5583 0.6200
epoch 300 LossPred 0.9099 LossAtt 0.6617 TrainAcc 0.6400 TestAcc 0.5543 0.6200
epoch 400 LossPred 0.8866 LossAtt 0.6789 TrainAcc 0.6400 TestAcc 0.5591 0.6000
epoch 500 LossPred 0.8696 LossAtt 0.6616 TrainAcc 0.6600 TestAcc 0.5643 0.6400
epoch 600 LossPred 0.8395 LossAtt 0.6824 TrainAcc 0.6800 TestAcc 0.5728 0.6450
epoch 700 LossPred 0.8329 LossAtt 0.6885 TrainAcc 0.6700 TestAcc 0.5711 0.6150
epoch 800 LossPred 0.7960 LossAtt 0.6862 TrainAcc 0.6800 TestAcc 0.5763 0.6400
epoch 900 LossPred 0.7735 LossAtt 0.6885 TrainAcc 0.7000 TestAcc 0.5796 0.6550
epoch 1000 LossPred 0.7558 LossAtt 0.6866 TrainAcc 0.7300 TestAcc 0.5728 0.6700
epoch 1100 LossPred 0.7343 LossAtt 0.6644 TrainAcc 0.7200 TestAcc 0.5761 0.6500
epoch 1200 LossPred 0.7189 LossAtt 0.6414 TrainAcc 0.7300 TestAcc 0.5726 0.6500
epoch 1300 LossPred 0.7082 LossAtt 0.6353 TrainAcc 0.7500 TestAcc 0.5686 0.6450
epoch 1400 LossPred 0.6977 LossAtt 0.6183 TrainAcc 0.7700 TestAcc 0.5678 0.6550
epoch 1500 LossPred 0.6856 LossAtt 0.6185 TrainAcc 0.7600 TestAcc 0.5628 0.6600
epoch 1600 LossPred 0.6961 LossAtt 0.6208 TrainAcc 0.7700 TestAcc 0.5596 0.6600
epoch 1700 LossPred 0.6732 LossAtt 0.6123 TrainAcc 0.7700 TestAcc 0.5583 0.6700
epoch 1800 LossPred 0.6677 LossAtt 0.6321 TrainAcc 0.7800 TestAcc 0.5558 0.6650
epoch 1900 LossPred 0.6600 LossAtt 0.6168 TrainAcc 0.7800 TestAcc 0.5576 0.6750
epoch 2000 LossPred 0.6475 LossAtt 0.6094 TrainAcc 0.7800 TestAcc 0.5561 0.7000
epoch 2100 LossPred 0.6418 LossAtt 0.5949 TrainAcc 0.7700 TestAcc 0.5623 0.6700
epoch 2200 LossPred 0.6221 LossAtt 0.5992 TrainAcc 0.7500 TestAcc 0.5488 0.6650
epoch 2300 LossPred 0.6102 LossAtt 0.5589 TrainAcc 0.7800 TestAcc 0.5523 0.6700
epoch 2400 LossPred 0.6187 LossAtt 0.5314 TrainAcc 0.7600 TestAcc 0.5470 0.6550
epoch 2500 LossPred 0.6155 LossAtt 0.5534 TrainAcc 0.7700 TestAcc 0.5488 0.6500
Optimization Finished!
********** replication  13  **********
epoch   0 LossPred 1.0966 LossAtt 1.0407 TrainAcc 0.5200 TestAcc 0.4620 0.5200
epoch 100 LossPred 0.8893 LossAtt 0.5024 TrainAcc 0.6300 TestAcc 0.5288 0.6250
epoch 200 LossPred 0.7769 LossAtt 0.6917 TrainAcc 0.7700 TestAcc 0.5706 0.7400
epoch 300 LossPred 0.6354 LossAtt 0.5553 TrainAcc 0.7600 TestAcc 0.6762 0.7450
epoch 400 LossPred 0.4806 LossAtt 0.5728 TrainAcc 0.8500 TestAcc 0.7608 0.8150
epoch 500 LossPred 0.4660 LossAtt 0.5703 TrainAcc 0.8400 TestAcc 0.7673 0.8300
epoch 600 LossPred 0.4180 LossAtt 0.5637 TrainAcc 0.8500 TestAcc 0.7910 0.8250
epoch 700 LossPred 0.4223 LossAtt 0.5643 TrainAcc 0.8600 TestAcc 0.7990 0.8400
epoch 800 LossPred 0.3956 LossAtt 0.5749 TrainAcc 0.8700 TestAcc 0.8021 0.8350
epoch 900 LossPred 0.3806 LossAtt 0.5409 TrainAcc 0.8700 TestAcc 0.8163 0.8300
epoch 1000 LossPred 0.4268 LossAtt 0.5295 TrainAcc 0.8500 TestAcc 0.8028 0.8350
epoch 1100 LossPred 0.3728 LossAtt 0.5018 TrainAcc 0.8900 TestAcc 0.8238 0.8450
epoch 1200 LossPred 0.3798 LossAtt 0.4799 TrainAcc 0.8800 TestAcc 0.8266 0.8550
epoch 1300 LossPred 0.3721 LossAtt 0.4750 TrainAcc 0.8800 TestAcc 0.8358 0.8650
epoch 1400 LossPred 0.3763 LossAtt 0.4541 TrainAcc 0.8700 TestAcc 0.8318 0.8600
epoch 1500 LossPred 0.3931 LossAtt 0.4702 TrainAcc 0.8800 TestAcc 0.8368 0.8650
epoch 1600 LossPred 0.3602 LossAtt 0.4464 TrainAcc 0.8800 TestAcc 0.8356 0.8650
epoch 1700 LossPred 0.3534 LossAtt 0.4539 TrainAcc 0.8800 TestAcc 0.8141 0.8600
epoch 1800 LossPred 0.3357 LossAtt 0.4600 TrainAcc 0.8900 TestAcc 0.8293 0.8650
epoch 1900 LossPred 0.3350 LossAtt 0.4739 TrainAcc 0.8900 TestAcc 0.8198 0.8750
epoch 2000 LossPred 0.3561 LossAtt 0.4475 TrainAcc 0.8600 TestAcc 0.8108 0.8550
epoch 2100 LossPred 0.3315 LossAtt 0.4431 TrainAcc 0.8800 TestAcc 0.8198 0.8700
epoch 2200 LossPred 0.3295 LossAtt 0.4399 TrainAcc 0.8900 TestAcc 0.8266 0.8650
epoch 2300 LossPred 0.3484 LossAtt 0.4511 TrainAcc 0.8700 TestAcc 0.8246 0.8650
epoch 2400 LossPred 0.3448 LossAtt 0.4427 TrainAcc 0.8700 TestAcc 0.8133 0.8550
epoch 2500 LossPred 0.3215 LossAtt 0.4359 TrainAcc 0.8900 TestAcc 0.8293 0.8700
Optimization Finished!
********** replication  14  **********
epoch   0 LossPred 1.2009 LossAtt 1.0252 TrainAcc 0.4500 TestAcc 0.4542 0.4400
epoch 100 LossPred 0.9569 LossAtt 0.5035 TrainAcc 0.5700 TestAcc 0.5983 0.5700
epoch 200 LossPred 0.9351 LossAtt 0.4975 TrainAcc 0.6000 TestAcc 0.5463 0.5700
epoch 300 LossPred 0.9193 LossAtt 0.4839 TrainAcc 0.6100 TestAcc 0.5508 0.6000
epoch 400 LossPred 0.8941 LossAtt 0.5022 TrainAcc 0.6700 TestAcc 0.5578 0.6400
epoch 500 LossPred 0.6140 LossAtt 0.6313 TrainAcc 0.8000 TestAcc 0.7457 0.8150
epoch 600 LossPred 0.5451 LossAtt 0.5548 TrainAcc 0.8400 TestAcc 0.8011 0.8450
epoch 700 LossPred 0.3833 LossAtt 0.5667 TrainAcc 0.8800 TestAcc 0.8241 0.8500
epoch 800 LossPred 0.3591 LossAtt 0.5455 TrainAcc 0.9000 TestAcc 0.8216 0.9000
epoch 900 LossPred 0.3872 LossAtt 0.5436 TrainAcc 0.8900 TestAcc 0.8043 0.8850
epoch 1000 LossPred 0.2160 LossAtt 0.5409 TrainAcc 0.9400 TestAcc 0.8584 0.9350
epoch 1100 LossPred 0.2193 LossAtt 0.5309 TrainAcc 0.9400 TestAcc 0.8631 0.9400
epoch 1200 LossPred 0.2037 LossAtt 0.5274 TrainAcc 0.9400 TestAcc 0.8639 0.9400
epoch 1300 LossPred 0.1979 LossAtt 0.5303 TrainAcc 0.9400 TestAcc 0.8536 0.9450
epoch 1400 LossPred 0.2320 LossAtt 0.5341 TrainAcc 0.9300 TestAcc 0.8398 0.9200
epoch 1500 LossPred 0.1946 LossAtt 0.5554 TrainAcc 0.9400 TestAcc 0.8504 0.9450
epoch 1600 LossPred 0.1955 LossAtt 0.5298 TrainAcc 0.9500 TestAcc 0.8589 0.9500
epoch 1700 LossPred 0.1886 LossAtt 0.5393 TrainAcc 0.9500 TestAcc 0.8589 0.9450
epoch 1800 LossPred 0.3884 LossAtt 0.5693 TrainAcc 0.8800 TestAcc 0.7905 0.8700
epoch 1900 LossPred 0.2808 LossAtt 0.5523 TrainAcc 0.9000 TestAcc 0.8178 0.8950
epoch 2000 LossPred 0.2024 LossAtt 0.5670 TrainAcc 0.9300 TestAcc 0.8473 0.9400
epoch 2100 LossPred 0.1430 LossAtt 0.5703 TrainAcc 0.9600 TestAcc 0.8496 0.9500
epoch 2200 LossPred 0.1738 LossAtt 0.5464 TrainAcc 0.9600 TestAcc 0.8453 0.9500
epoch 2300 LossPred 0.1652 LossAtt 0.5617 TrainAcc 0.9600 TestAcc 0.8306 0.9350
epoch 2400 LossPred 0.1273 LossAtt 0.5645 TrainAcc 0.9700 TestAcc 0.8463 0.9600
epoch 2500 LossPred 0.1403 LossAtt 0.5718 TrainAcc 0.9600 TestAcc 0.8451 0.9600
Optimization Finished!
********** replication  15  **********
epoch   0 LossPred 1.0985 LossAtt 1.0703 TrainAcc 0.4200 TestAcc 0.4955 0.4200
epoch 100 LossPred 0.9668 LossAtt 0.2552 TrainAcc 0.5900 TestAcc 0.5673 0.5900
epoch 200 LossPred 0.9652 LossAtt 0.1984 TrainAcc 0.5900 TestAcc 0.5673 0.5900
epoch 300 LossPred 0.9651 LossAtt 0.1022 TrainAcc 0.5900 TestAcc 0.5673 0.5900
epoch 400 LossPred 0.9651 LossAtt 0.0974 TrainAcc 0.5900 TestAcc 0.5673 0.5900
epoch 500 LossPred 0.9650 LossAtt 0.1080 TrainAcc 0.5900 TestAcc 0.5673 0.5900
epoch 600 LossPred 0.9649 LossAtt 0.1355 TrainAcc 0.5900 TestAcc 0.5673 0.5900
epoch 700 LossPred 0.9647 LossAtt 0.1639 TrainAcc 0.5900 TestAcc 0.5673 0.5900
epoch 800 LossPred 0.9651 LossAtt 0.1787 TrainAcc 0.5900 TestAcc 0.5673 0.5900
epoch 900 LossPred 0.9650 LossAtt 0.2216 TrainAcc 0.5900 TestAcc 0.5673 0.5900
epoch 1000 LossPred 0.9594 LossAtt 0.3137 TrainAcc 0.5900 TestAcc 0.5673 0.5900
epoch 1100 LossPred 0.9394 LossAtt 0.4196 TrainAcc 0.6000 TestAcc 0.5668 0.5800
epoch 1200 LossPred 0.8753 LossAtt 0.5162 TrainAcc 0.6400 TestAcc 0.5363 0.6250
epoch 1300 LossPred 0.8673 LossAtt 0.5491 TrainAcc 0.6200 TestAcc 0.5265 0.5900
epoch 1400 LossPred 0.8450 LossAtt 0.5527 TrainAcc 0.6400 TestAcc 0.5343 0.5950
epoch 1500 LossPred 0.8223 LossAtt 0.5224 TrainAcc 0.6900 TestAcc 0.5340 0.6100
epoch 1600 LossPred 0.8157 LossAtt 0.5374 TrainAcc 0.6800 TestAcc 0.5463 0.6150
epoch 1700 LossPred 0.8141 LossAtt 0.5304 TrainAcc 0.6500 TestAcc 0.5413 0.6200
epoch 1800 LossPred 0.8101 LossAtt 0.5231 TrainAcc 0.6600 TestAcc 0.5415 0.5800
epoch 1900 LossPred 0.8102 LossAtt 0.5144 TrainAcc 0.6800 TestAcc 0.5453 0.6000
epoch 2000 LossPred 0.7997 LossAtt 0.5000 TrainAcc 0.6700 TestAcc 0.5395 0.6050
epoch 2100 LossPred 0.8416 LossAtt 0.5031 TrainAcc 0.6400 TestAcc 0.5465 0.6350
epoch 2200 LossPred 0.8085 LossAtt 0.5167 TrainAcc 0.6400 TestAcc 0.5588 0.6200
epoch 2300 LossPred 0.7838 LossAtt 0.5327 TrainAcc 0.7000 TestAcc 0.5440 0.5650
epoch 2400 LossPred 0.8251 LossAtt 0.5254 TrainAcc 0.6900 TestAcc 0.5601 0.6200
epoch 2500 LossPred 0.8185 LossAtt 0.5250 TrainAcc 0.6600 TestAcc 0.5663 0.6350
Optimization Finished!
********** replication  16  **********
epoch   0 LossPred 1.0766 LossAtt 1.0312 TrainAcc 0.4700 TestAcc 0.4935 0.4850
epoch 100 LossPred 0.9231 LossAtt 0.4678 TrainAcc 0.6400 TestAcc 0.5771 0.6400
epoch 200 LossPred 0.9103 LossAtt 0.4286 TrainAcc 0.6400 TestAcc 0.5771 0.6400
epoch 300 LossPred 0.8965 LossAtt 0.4639 TrainAcc 0.6400 TestAcc 0.5771 0.6400
epoch 400 LossPred 0.8349 LossAtt 0.6110 TrainAcc 0.6900 TestAcc 0.5901 0.6800
epoch 500 LossPred 0.6934 LossAtt 0.5801 TrainAcc 0.7500 TestAcc 0.6919 0.7450
epoch 600 LossPred 0.6528 LossAtt 0.5886 TrainAcc 0.7800 TestAcc 0.7477 0.7800
epoch 700 LossPred 0.6507 LossAtt 0.5432 TrainAcc 0.7700 TestAcc 0.7450 0.7800
epoch 800 LossPred 0.6568 LossAtt 0.5212 TrainAcc 0.7800 TestAcc 0.7447 0.7850
epoch 900 LossPred 0.6547 LossAtt 0.4894 TrainAcc 0.7800 TestAcc 0.7405 0.7700
epoch 1000 LossPred 0.6507 LossAtt 0.4955 TrainAcc 0.7800 TestAcc 0.7460 0.7850
epoch 1100 LossPred 0.6429 LossAtt 0.4896 TrainAcc 0.7700 TestAcc 0.7475 0.7750
epoch 1200 LossPred 0.6443 LossAtt 0.5045 TrainAcc 0.7800 TestAcc 0.7490 0.7750
epoch 1300 LossPred 0.6089 LossAtt 0.5158 TrainAcc 0.8000 TestAcc 0.7863 0.7850
epoch 1400 LossPred 0.6151 LossAtt 0.4880 TrainAcc 0.8000 TestAcc 0.7690 0.7900
epoch 1500 LossPred 0.6939 LossAtt 0.5249 TrainAcc 0.7600 TestAcc 0.7740 0.7900
epoch 1600 LossPred 0.7850 LossAtt 0.4453 TrainAcc 0.7200 TestAcc 0.6897 0.7450
epoch 1700 LossPred 0.6277 LossAtt 0.4691 TrainAcc 0.8100 TestAcc 0.7978 0.8150
epoch 1800 LossPred 0.6038 LossAtt 0.4794 TrainAcc 0.8000 TestAcc 0.7943 0.8000
epoch 1900 LossPred 0.8828 LossAtt 0.4571 TrainAcc 0.5500 TestAcc 0.4907 0.5550
epoch 2000 LossPred 0.7982 LossAtt 0.3842 TrainAcc 0.6200 TestAcc 0.4997 0.6000
epoch 2100 LossPred 0.7942 LossAtt 0.3478 TrainAcc 0.6500 TestAcc 0.5090 0.6400
epoch 2200 LossPred 0.7905 LossAtt 0.3318 TrainAcc 0.6500 TestAcc 0.5105 0.6500
epoch 2300 LossPred 0.7973 LossAtt 0.2991 TrainAcc 0.6500 TestAcc 0.5075 0.6500
epoch 2400 LossPred 0.7964 LossAtt 0.2925 TrainAcc 0.6500 TestAcc 0.5075 0.6500
epoch 2500 LossPred 0.7866 LossAtt 0.2647 TrainAcc 0.6500 TestAcc 0.5105 0.6500
Optimization Finished!
********** replication  17  **********
epoch   0 LossPred 1.2920 LossAtt 1.0321 TrainAcc 0.5500 TestAcc 0.5298 0.5250
epoch 100 LossPred 1.0073 LossAtt 0.5555 TrainAcc 0.5400 TestAcc 0.5648 0.5400
epoch 200 LossPred 0.9552 LossAtt 0.5672 TrainAcc 0.6000 TestAcc 0.5756 0.5950
epoch 300 LossPred 0.9461 LossAtt 0.5881 TrainAcc 0.6400 TestAcc 0.5736 0.5800
epoch 400 LossPred 0.9230 LossAtt 0.6728 TrainAcc 0.6000 TestAcc 0.5641 0.6100
epoch 500 LossPred 0.9045 LossAtt 0.7122 TrainAcc 0.6400 TestAcc 0.5791 0.6300
epoch 600 LossPred 0.8402 LossAtt 0.8205 TrainAcc 0.6900 TestAcc 0.6124 0.6700
epoch 700 LossPred 0.6481 LossAtt 0.8786 TrainAcc 0.7500 TestAcc 0.7615 0.7350
epoch 800 LossPred 0.5495 LossAtt 0.7917 TrainAcc 0.7900 TestAcc 0.7793 0.7700
epoch 900 LossPred 0.4112 LossAtt 0.7741 TrainAcc 0.8900 TestAcc 0.7790 0.8050
epoch 1000 LossPred 0.4433 LossAtt 0.7626 TrainAcc 0.8400 TestAcc 0.7888 0.8100
epoch 1100 LossPred 0.3638 LossAtt 0.7565 TrainAcc 0.9000 TestAcc 0.7860 0.8250
epoch 1200 LossPred 0.3191 LossAtt 0.7776 TrainAcc 0.9100 TestAcc 0.7823 0.8300
epoch 1300 LossPred 0.3164 LossAtt 0.7321 TrainAcc 0.9100 TestAcc 0.7785 0.8400
epoch 1400 LossPred 0.3308 LossAtt 0.7596 TrainAcc 0.9000 TestAcc 0.7838 0.8600
epoch 1500 LossPred 0.2915 LossAtt 0.7501 TrainAcc 0.9200 TestAcc 0.7743 0.8550
epoch 1600 LossPred 0.3227 LossAtt 0.7463 TrainAcc 0.9100 TestAcc 0.7790 0.8500
epoch 1700 LossPred 0.3769 LossAtt 0.7309 TrainAcc 0.8900 TestAcc 0.7725 0.8250
epoch 1800 LossPred 0.2970 LossAtt 0.7259 TrainAcc 0.9100 TestAcc 0.7815 0.8450
epoch 1900 LossPred 0.2480 LossAtt 0.7408 TrainAcc 0.9300 TestAcc 0.7803 0.8550
epoch 2000 LossPred 0.2148 LossAtt 0.7505 TrainAcc 0.9400 TestAcc 0.7798 0.8600
epoch 2100 LossPred 0.2175 LossAtt 0.7576 TrainAcc 0.9300 TestAcc 0.7788 0.8700
epoch 2200 LossPred 0.3570 LossAtt 0.7155 TrainAcc 0.8900 TestAcc 0.7828 0.8450
epoch 2300 LossPred 0.2088 LossAtt 0.7305 TrainAcc 0.9400 TestAcc 0.7805 0.8750
epoch 2400 LossPred 0.2115 LossAtt 0.7233 TrainAcc 0.9400 TestAcc 0.7813 0.8600
epoch 2500 LossPred 0.2020 LossAtt 0.7142 TrainAcc 0.9400 TestAcc 0.7778 0.8650
Optimization Finished!
********** replication  18  **********
epoch   0 LossPred 1.1077 LossAtt 1.0175 TrainAcc 0.5700 TestAcc 0.4842 0.5700
epoch 100 LossPred 0.9052 LossAtt 0.5101 TrainAcc 0.6500 TestAcc 0.5666 0.6500
epoch 200 LossPred 0.8676 LossAtt 0.5370 TrainAcc 0.6500 TestAcc 0.5666 0.6500
epoch 300 LossPred 0.8465 LossAtt 0.5116 TrainAcc 0.6500 TestAcc 0.5666 0.6300
epoch 400 LossPred 0.8252 LossAtt 0.4781 TrainAcc 0.6800 TestAcc 0.6151 0.6550
epoch 500 LossPred 0.4195 LossAtt 0.6773 TrainAcc 0.8700 TestAcc 0.7930 0.8700
epoch 600 LossPred 0.4099 LossAtt 0.6443 TrainAcc 0.8700 TestAcc 0.7990 0.8700
epoch 700 LossPred 0.3233 LossAtt 0.6557 TrainAcc 0.9000 TestAcc 0.8206 0.9000
epoch 800 LossPred 0.3693 LossAtt 0.6453 TrainAcc 0.8900 TestAcc 0.7970 0.8800
epoch 900 LossPred 0.2921 LossAtt 0.6497 TrainAcc 0.9000 TestAcc 0.8481 0.9200
epoch 1000 LossPred 0.2667 LossAtt 0.6309 TrainAcc 0.9100 TestAcc 0.8453 0.9000
epoch 1100 LossPred 0.2620 LossAtt 0.6045 TrainAcc 0.9100 TestAcc 0.8438 0.9100
epoch 1200 LossPred 0.3552 LossAtt 0.5862 TrainAcc 0.8800 TestAcc 0.8136 0.8550
epoch 1300 LossPred 0.4593 LossAtt 0.6143 TrainAcc 0.8300 TestAcc 0.7305 0.8200
epoch 1400 LossPred 0.2430 LossAtt 0.6005 TrainAcc 0.9300 TestAcc 0.8453 0.9050
epoch 1500 LossPred 0.2327 LossAtt 0.5955 TrainAcc 0.9300 TestAcc 0.8421 0.9050
epoch 1600 LossPred 0.2135 LossAtt 0.5876 TrainAcc 0.9200 TestAcc 0.8636 0.9050
epoch 1700 LossPred 0.2076 LossAtt 0.5952 TrainAcc 0.9300 TestAcc 0.8581 0.9100
epoch 1800 LossPred 0.4371 LossAtt 0.6153 TrainAcc 0.8400 TestAcc 0.7893 0.8500
epoch 1900 LossPred 0.3412 LossAtt 0.6451 TrainAcc 0.8800 TestAcc 0.7770 0.8600
epoch 2000 LossPred 0.1881 LossAtt 0.6529 TrainAcc 0.9400 TestAcc 0.8526 0.9250
epoch 2100 LossPred 0.1450 LossAtt 0.6779 TrainAcc 0.9700 TestAcc 0.8401 0.9400
epoch 2200 LossPred 0.0931 LossAtt 0.6671 TrainAcc 0.9800 TestAcc 0.8544 0.9400
epoch 2300 LossPred 0.1204 LossAtt 0.6845 TrainAcc 0.9700 TestAcc 0.8176 0.9500
epoch 2400 LossPred 0.1094 LossAtt 0.6876 TrainAcc 0.9800 TestAcc 0.8211 0.9350
epoch 2500 LossPred 0.0626 LossAtt 0.6773 TrainAcc 0.9900 TestAcc 0.8514 0.9450
Optimization Finished!
********** replication  19  **********
epoch   0 LossPred 1.0448 LossAtt 1.0100 TrainAcc 0.4700 TestAcc 0.4757 0.4750
epoch 100 LossPred 0.9393 LossAtt 0.5129 TrainAcc 0.6100 TestAcc 0.5723 0.6100
epoch 200 LossPred 0.9201 LossAtt 0.4975 TrainAcc 0.6300 TestAcc 0.5903 0.6300
epoch 300 LossPred 0.5199 LossAtt 0.5695 TrainAcc 0.8000 TestAcc 0.8128 0.8100
epoch 400 LossPred 0.4487 LossAtt 0.5392 TrainAcc 0.8200 TestAcc 0.8393 0.8350
epoch 500 LossPred 0.4537 LossAtt 0.5189 TrainAcc 0.8400 TestAcc 0.8458 0.8200
epoch 600 LossPred 0.4747 LossAtt 0.5033 TrainAcc 0.8500 TestAcc 0.8391 0.8400
epoch 700 LossPred 0.3957 LossAtt 0.4992 TrainAcc 0.8800 TestAcc 0.8351 0.8400
epoch 800 LossPred 0.4160 LossAtt 0.4611 TrainAcc 0.8500 TestAcc 0.8296 0.8650
epoch 900 LossPred 0.3280 LossAtt 0.4586 TrainAcc 0.9100 TestAcc 0.8268 0.8800
epoch 1000 LossPred 0.3553 LossAtt 0.4329 TrainAcc 0.8800 TestAcc 0.8311 0.8750
epoch 1100 LossPred 0.3724 LossAtt 0.4708 TrainAcc 0.8900 TestAcc 0.8263 0.8700
epoch 1200 LossPred 0.3376 LossAtt 0.4450 TrainAcc 0.8900 TestAcc 0.8246 0.8650
epoch 1300 LossPred 0.3491 LossAtt 0.4351 TrainAcc 0.8900 TestAcc 0.8043 0.8600
epoch 1400 LossPred 0.3165 LossAtt 0.4482 TrainAcc 0.9000 TestAcc 0.8211 0.8650
epoch 1500 LossPred 0.3538 LossAtt 0.4532 TrainAcc 0.8700 TestAcc 0.8073 0.8650
epoch 1600 LossPred 0.3404 LossAtt 0.4571 TrainAcc 0.8700 TestAcc 0.8086 0.8750
epoch 1700 LossPred 0.5386 LossAtt 0.4252 TrainAcc 0.8100 TestAcc 0.7848 0.8350
epoch 1800 LossPred 0.3052 LossAtt 0.4533 TrainAcc 0.9000 TestAcc 0.8226 0.8600
epoch 1900 LossPred 0.2981 LossAtt 0.4495 TrainAcc 0.9000 TestAcc 0.8208 0.8700
epoch 2000 LossPred 0.3301 LossAtt 0.4289 TrainAcc 0.8800 TestAcc 0.8156 0.8850
epoch 2100 LossPred 0.2937 LossAtt 0.4139 TrainAcc 0.9000 TestAcc 0.8211 0.8750
epoch 2200 LossPred 0.2548 LossAtt 0.4123 TrainAcc 0.9200 TestAcc 0.8141 0.8700
epoch 2300 LossPred 0.2847 LossAtt 0.4188 TrainAcc 0.9100 TestAcc 0.8178 0.8750
epoch 2400 LossPred 0.3487 LossAtt 0.3969 TrainAcc 0.8800 TestAcc 0.8123 0.8600
epoch 2500 LossPred 0.3410 LossAtt 0.4139 TrainAcc 0.8900 TestAcc 0.8078 0.8500
Optimization Finished!
********** replication  20  **********
epoch   0 LossPred 1.2093 LossAtt 1.0329 TrainAcc 0.4500 TestAcc 0.4937 0.4650
epoch 100 LossPred 0.9517 LossAtt 0.5710 TrainAcc 0.6100 TestAcc 0.5858 0.6150
epoch 200 LossPred 0.7293 LossAtt 0.6892 TrainAcc 0.7200 TestAcc 0.6481 0.7000
epoch 300 LossPred 0.6330 LossAtt 0.6643 TrainAcc 0.7700 TestAcc 0.7270 0.7650
epoch 400 LossPred 0.5847 LossAtt 0.6566 TrainAcc 0.8000 TestAcc 0.7320 0.7750
epoch 500 LossPred 0.5795 LossAtt 0.6299 TrainAcc 0.8000 TestAcc 0.7277 0.7600
epoch 600 LossPred 0.5405 LossAtt 0.5874 TrainAcc 0.8300 TestAcc 0.7337 0.7700
epoch 700 LossPred 0.5287 LossAtt 0.5794 TrainAcc 0.8300 TestAcc 0.7360 0.7700
epoch 800 LossPred 0.5315 LossAtt 0.5750 TrainAcc 0.8200 TestAcc 0.7392 0.8050
epoch 900 LossPred 0.5672 LossAtt 0.5544 TrainAcc 0.8000 TestAcc 0.7262 0.7950
epoch 1000 LossPred 0.5142 LossAtt 0.5338 TrainAcc 0.8400 TestAcc 0.7397 0.8200
epoch 1100 LossPred 0.5129 LossAtt 0.5413 TrainAcc 0.8300 TestAcc 0.7400 0.7900
epoch 1200 LossPred 0.5034 LossAtt 0.5241 TrainAcc 0.8400 TestAcc 0.7385 0.7900
epoch 1300 LossPred 0.6063 LossAtt 0.5076 TrainAcc 0.7800 TestAcc 0.7232 0.7850
epoch 1400 LossPred 0.4943 LossAtt 0.5303 TrainAcc 0.8300 TestAcc 0.7397 0.8000
epoch 1500 LossPred 0.5220 LossAtt 0.5204 TrainAcc 0.8100 TestAcc 0.7455 0.7800
epoch 1600 LossPred 0.5367 LossAtt 0.5051 TrainAcc 0.8300 TestAcc 0.7240 0.8000
epoch 1700 LossPred 0.5349 LossAtt 0.5038 TrainAcc 0.8400 TestAcc 0.7307 0.8000
epoch 1800 LossPred 0.6671 LossAtt 0.4962 TrainAcc 0.7400 TestAcc 0.7392 0.7450
epoch 1900 LossPred 0.5109 LossAtt 0.4999 TrainAcc 0.8200 TestAcc 0.7400 0.7850
epoch 2000 LossPred 0.4773 LossAtt 0.5253 TrainAcc 0.8600 TestAcc 0.7467 0.7750
epoch 2100 LossPred 0.4823 LossAtt 0.4979 TrainAcc 0.8400 TestAcc 0.7450 0.7900
epoch 2200 LossPred 0.4817 LossAtt 0.5104 TrainAcc 0.8400 TestAcc 0.7467 0.7850
epoch 2300 LossPred 0.4749 LossAtt 0.5175 TrainAcc 0.8500 TestAcc 0.7440 0.7950
epoch 2400 LossPred 0.4809 LossAtt 0.4902 TrainAcc 0.8500 TestAcc 0.7467 0.7850
epoch 2500 LossPred 0.4776 LossAtt 0.4990 TrainAcc 0.8500 TestAcc 0.7432 0.7850
Optimization Finished!
********** replication  21  **********
epoch   0 LossPred 0.9995 LossAtt 0.9956 TrainAcc 0.4800 TestAcc 0.4922 0.4550
epoch 100 LossPred 0.8721 LossAtt 0.6593 TrainAcc 0.6700 TestAcc 0.5345 0.6750
epoch 200 LossPred 0.8144 LossAtt 0.6263 TrainAcc 0.7100 TestAcc 0.5263 0.7200
epoch 300 LossPred 0.7871 LossAtt 0.5741 TrainAcc 0.7200 TestAcc 0.5340 0.7000
epoch 400 LossPred 0.7876 LossAtt 0.5671 TrainAcc 0.7000 TestAcc 0.5285 0.7000
epoch 500 LossPred 0.7682 LossAtt 0.6021 TrainAcc 0.6800 TestAcc 0.5158 0.7050
epoch 600 LossPred 0.7249 LossAtt 0.6365 TrainAcc 0.7600 TestAcc 0.5323 0.7200
epoch 700 LossPred 0.6970 LossAtt 0.6172 TrainAcc 0.7600 TestAcc 0.5415 0.7300
epoch 800 LossPred 0.6758 LossAtt 0.5664 TrainAcc 0.7700 TestAcc 0.5410 0.7550
epoch 900 LossPred 0.6507 LossAtt 0.5717 TrainAcc 0.7700 TestAcc 0.5368 0.7600
epoch 1000 LossPred 0.6070 LossAtt 0.5775 TrainAcc 0.7900 TestAcc 0.5245 0.7800
epoch 1100 LossPred 0.5767 LossAtt 0.5722 TrainAcc 0.8000 TestAcc 0.5228 0.7500
epoch 1200 LossPred 0.5789 LossAtt 0.6014 TrainAcc 0.8000 TestAcc 0.5225 0.7600
epoch 1300 LossPred 0.5653 LossAtt 0.6117 TrainAcc 0.8100 TestAcc 0.5193 0.7700
epoch 1400 LossPred 0.5607 LossAtt 0.6136 TrainAcc 0.8200 TestAcc 0.5125 0.7700
epoch 1500 LossPred 0.5577 LossAtt 0.6054 TrainAcc 0.8200 TestAcc 0.5138 0.7650
epoch 1600 LossPred 0.5578 LossAtt 0.6246 TrainAcc 0.8200 TestAcc 0.5135 0.7550
epoch 1700 LossPred 0.5533 LossAtt 0.6549 TrainAcc 0.8200 TestAcc 0.5110 0.7600
epoch 1800 LossPred 0.5491 LossAtt 0.6328 TrainAcc 0.8200 TestAcc 0.5135 0.7650
epoch 1900 LossPred 0.5410 LossAtt 0.6327 TrainAcc 0.8200 TestAcc 0.5118 0.7600
epoch 2000 LossPred 0.5180 LossAtt 0.6784 TrainAcc 0.8200 TestAcc 0.5178 0.7700
epoch 2100 LossPred 0.5043 LossAtt 0.6508 TrainAcc 0.8300 TestAcc 0.5153 0.7800
epoch 2200 LossPred 0.4937 LossAtt 0.6627 TrainAcc 0.8300 TestAcc 0.5035 0.7600
epoch 2300 LossPred 0.4902 LossAtt 0.6500 TrainAcc 0.8300 TestAcc 0.5030 0.7500
epoch 2400 LossPred 0.4906 LossAtt 0.6562 TrainAcc 0.8300 TestAcc 0.5060 0.7600
epoch 2500 LossPred 0.4916 LossAtt 0.6501 TrainAcc 0.8200 TestAcc 0.5140 0.7450
Optimization Finished!
********** replication  22  **********
epoch   0 LossPred 1.2996 LossAtt 1.0693 TrainAcc 0.4900 TestAcc 0.4342 0.4900
epoch 100 LossPred 0.9951 LossAtt 0.4263 TrainAcc 0.5100 TestAcc 0.4752 0.5200
epoch 200 LossPred 0.9866 LossAtt 0.4117 TrainAcc 0.5400 TestAcc 0.4732 0.5350
epoch 300 LossPred 0.9810 LossAtt 0.4212 TrainAcc 0.5400 TestAcc 0.4630 0.5350
epoch 400 LossPred 0.9664 LossAtt 0.4914 TrainAcc 0.5600 TestAcc 0.5085 0.5750
epoch 500 LossPred 0.8991 LossAtt 0.5633 TrainAcc 0.6100 TestAcc 0.5946 0.6100
epoch 600 LossPred 0.8712 LossAtt 0.6200 TrainAcc 0.6600 TestAcc 0.5861 0.6350
epoch 700 LossPred 0.8376 LossAtt 0.7069 TrainAcc 0.7000 TestAcc 0.5773 0.6600
epoch 800 LossPred 0.7972 LossAtt 0.7277 TrainAcc 0.6800 TestAcc 0.5653 0.6900
epoch 900 LossPred 0.7783 LossAtt 0.7193 TrainAcc 0.7000 TestAcc 0.5661 0.6650
epoch 1000 LossPred 0.7643 LossAtt 0.7081 TrainAcc 0.7100 TestAcc 0.5536 0.6750
epoch 1100 LossPred 0.7545 LossAtt 0.7061 TrainAcc 0.7100 TestAcc 0.5526 0.6900
epoch 1200 LossPred 0.7449 LossAtt 0.6746 TrainAcc 0.7000 TestAcc 0.5521 0.6900
epoch 1300 LossPred 0.7375 LossAtt 0.6736 TrainAcc 0.7400 TestAcc 0.5601 0.6950
epoch 1400 LossPred 0.7415 LossAtt 0.6681 TrainAcc 0.7200 TestAcc 0.5531 0.7050
epoch 1500 LossPred 0.7375 LossAtt 0.6381 TrainAcc 0.7400 TestAcc 0.5506 0.7000
epoch 1600 LossPred 0.7323 LossAtt 0.6327 TrainAcc 0.7400 TestAcc 0.5493 0.6850
epoch 1700 LossPred 0.7385 LossAtt 0.6187 TrainAcc 0.7300 TestAcc 0.5418 0.6900
epoch 1800 LossPred 0.7260 LossAtt 0.6290 TrainAcc 0.7400 TestAcc 0.5490 0.7000
epoch 1900 LossPred 0.7420 LossAtt 0.6090 TrainAcc 0.7300 TestAcc 0.5415 0.6850
epoch 2000 LossPred 0.7414 LossAtt 0.5963 TrainAcc 0.7000 TestAcc 0.5395 0.6900
epoch 2100 LossPred 0.7322 LossAtt 0.5986 TrainAcc 0.7300 TestAcc 0.5393 0.6850
epoch 2200 LossPred 0.7177 LossAtt 0.5880 TrainAcc 0.7100 TestAcc 0.5468 0.6950
epoch 2300 LossPred 0.7258 LossAtt 0.6049 TrainAcc 0.7200 TestAcc 0.5473 0.6750
epoch 2400 LossPred 0.7232 LossAtt 0.5796 TrainAcc 0.7200 TestAcc 0.5370 0.6750
epoch 2500 LossPred 0.7222 LossAtt 0.5842 TrainAcc 0.7200 TestAcc 0.5445 0.6850
Optimization Finished!
********** replication  23  **********
epoch   0 LossPred 1.1887 LossAtt 1.0238 TrainAcc 0.4800 TestAcc 0.4254 0.4800
epoch 100 LossPred 0.9560 LossAtt 0.6189 TrainAcc 0.6300 TestAcc 0.4985 0.6150
epoch 200 LossPred 0.9283 LossAtt 0.4963 TrainAcc 0.6000 TestAcc 0.5218 0.6150
epoch 300 LossPred 0.9235 LossAtt 0.4868 TrainAcc 0.6100 TestAcc 0.5088 0.6150
epoch 400 LossPred 0.9175 LossAtt 0.4786 TrainAcc 0.6100 TestAcc 0.5105 0.6150
epoch 500 LossPred 0.8996 LossAtt 0.5407 TrainAcc 0.6200 TestAcc 0.5353 0.6250
epoch 600 LossPred 0.8571 LossAtt 0.7089 TrainAcc 0.6300 TestAcc 0.5128 0.6300
epoch 700 LossPred 0.7674 LossAtt 0.7023 TrainAcc 0.7400 TestAcc 0.5325 0.7100
epoch 800 LossPred 0.6594 LossAtt 0.6904 TrainAcc 0.8200 TestAcc 0.5315 0.7200
epoch 900 LossPred 0.6364 LossAtt 0.6642 TrainAcc 0.8300 TestAcc 0.5383 0.7200
epoch 1000 LossPred 0.6138 LossAtt 0.6704 TrainAcc 0.8200 TestAcc 0.5395 0.7250
epoch 1100 LossPred 0.5993 LossAtt 0.6736 TrainAcc 0.8400 TestAcc 0.5385 0.7700
epoch 1200 LossPred 0.5802 LossAtt 0.6481 TrainAcc 0.8400 TestAcc 0.5375 0.7500
epoch 1300 LossPred 0.5890 LossAtt 0.6599 TrainAcc 0.8200 TestAcc 0.5338 0.7650
epoch 1400 LossPred 0.5789 LossAtt 0.6354 TrainAcc 0.8300 TestAcc 0.5328 0.7400
epoch 1500 LossPred 0.6370 LossAtt 0.6346 TrainAcc 0.7700 TestAcc 0.5205 0.7450
epoch 1600 LossPred 0.5562 LossAtt 0.6524 TrainAcc 0.8200 TestAcc 0.5310 0.7500
epoch 1700 LossPred 0.5410 LossAtt 0.6488 TrainAcc 0.8200 TestAcc 0.5228 0.7500
epoch 1800 LossPred 0.6152 LossAtt 0.6556 TrainAcc 0.7900 TestAcc 0.5263 0.7400
epoch 1900 LossPred 0.5373 LossAtt 0.6468 TrainAcc 0.8400 TestAcc 0.5255 0.7750
epoch 2000 LossPred 0.5219 LossAtt 0.6253 TrainAcc 0.8400 TestAcc 0.5238 0.7900
epoch 2100 LossPred 0.5757 LossAtt 0.6387 TrainAcc 0.8100 TestAcc 0.5270 0.7750
epoch 2200 LossPred 0.6111 LossAtt 0.6208 TrainAcc 0.7900 TestAcc 0.5193 0.7900
epoch 2300 LossPred 0.5325 LossAtt 0.6321 TrainAcc 0.8400 TestAcc 0.5320 0.7900
epoch 2400 LossPred 0.5512 LossAtt 0.6399 TrainAcc 0.8300 TestAcc 0.5260 0.7500
epoch 2500 LossPred 0.5677 LossAtt 0.6492 TrainAcc 0.8300 TestAcc 0.5295 0.7600
Optimization Finished!
********** replication  24  **********
epoch   0 LossPred 1.2043 LossAtt 1.0270 TrainAcc 0.5600 TestAcc 0.5716 0.5050
epoch 100 LossPred 0.9514 LossAtt 0.5036 TrainAcc 0.5800 TestAcc 0.5293 0.5950
epoch 200 LossPred 0.9085 LossAtt 0.3642 TrainAcc 0.6100 TestAcc 0.5676 0.6100
epoch 300 LossPred 0.8729 LossAtt 0.4156 TrainAcc 0.6000 TestAcc 0.6226 0.6150
epoch 400 LossPred 0.7305 LossAtt 0.4674 TrainAcc 0.7800 TestAcc 0.7900 0.7750
epoch 500 LossPred 0.6113 LossAtt 0.4506 TrainAcc 0.8200 TestAcc 0.7975 0.8050
epoch 600 LossPred 0.5575 LossAtt 0.4530 TrainAcc 0.8200 TestAcc 0.7973 0.7900
epoch 700 LossPred 0.5345 LossAtt 0.4622 TrainAcc 0.8200 TestAcc 0.7858 0.7700
epoch 800 LossPred 0.5448 LossAtt 0.4486 TrainAcc 0.8100 TestAcc 0.8016 0.7950
epoch 900 LossPred 0.5561 LossAtt 0.4594 TrainAcc 0.8200 TestAcc 0.8131 0.8250
epoch 1000 LossPred 0.4980 LossAtt 0.4573 TrainAcc 0.8500 TestAcc 0.8001 0.8100
epoch 1100 LossPred 0.5948 LossAtt 0.4591 TrainAcc 0.7800 TestAcc 0.7407 0.7550
epoch 1200 LossPred 0.4932 LossAtt 0.4575 TrainAcc 0.8400 TestAcc 0.8021 0.8050
epoch 1300 LossPred 0.5854 LossAtt 0.4484 TrainAcc 0.8100 TestAcc 0.7915 0.8200
epoch 1400 LossPred 0.6533 LossAtt 0.4645 TrainAcc 0.7700 TestAcc 0.7095 0.7400
epoch 1500 LossPred 0.8566 LossAtt 0.3798 TrainAcc 0.6700 TestAcc 0.5961 0.6550
epoch 1600 LossPred 0.8730 LossAtt 0.3670 TrainAcc 0.6100 TestAcc 0.6209 0.6100
epoch 1700 LossPred 0.9461 LossAtt 0.4880 TrainAcc 0.5700 TestAcc 0.6096 0.5800
epoch 1800 LossPred 0.7528 LossAtt 0.5602 TrainAcc 0.7300 TestAcc 0.7287 0.7350
epoch 1900 LossPred 1.3103 LossAtt 0.4622 TrainAcc 0.4500 TestAcc 0.4214 0.4500
epoch 2000 LossPred 0.7407 LossAtt 0.5254 TrainAcc 0.7600 TestAcc 0.7157 0.7950
epoch 2100 LossPred 0.5705 LossAtt 0.5043 TrainAcc 0.8200 TestAcc 0.7928 0.8400
epoch 2200 LossPred 0.5475 LossAtt 0.4834 TrainAcc 0.8300 TestAcc 0.7890 0.8350
epoch 2300 LossPred 0.5244 LossAtt 0.4626 TrainAcc 0.8000 TestAcc 0.8036 0.8400
epoch 2400 LossPred 0.5003 LossAtt 0.4465 TrainAcc 0.8300 TestAcc 0.8043 0.8300
epoch 2500 LossPred 0.5063 LossAtt 0.4453 TrainAcc 0.8200 TestAcc 0.8008 0.8350
Optimization Finished!
********** replication  25  **********
epoch   0 LossPred 1.1800 LossAtt 1.0457 TrainAcc 0.4800 TestAcc 0.4872 0.4500
epoch 100 LossPred 0.9591 LossAtt 0.6785 TrainAcc 0.6400 TestAcc 0.5763 0.6100
epoch 200 LossPred 0.8760 LossAtt 0.7116 TrainAcc 0.6400 TestAcc 0.5948 0.6500
epoch 300 LossPred 0.7353 LossAtt 0.7358 TrainAcc 0.7500 TestAcc 0.6331 0.7650
epoch 400 LossPred 0.2960 LossAtt 0.6888 TrainAcc 0.9000 TestAcc 0.8358 0.8650
epoch 500 LossPred 0.3010 LossAtt 0.6728 TrainAcc 0.8900 TestAcc 0.8308 0.8500
epoch 600 LossPred 0.2413 LossAtt 0.6452 TrainAcc 0.9200 TestAcc 0.8441 0.8700
epoch 700 LossPred 0.2369 LossAtt 0.6422 TrainAcc 0.9200 TestAcc 0.8406 0.8750
epoch 800 LossPred 0.2067 LossAtt 0.5967 TrainAcc 0.9400 TestAcc 0.8468 0.8850
epoch 900 LossPred 0.2216 LossAtt 0.5559 TrainAcc 0.9200 TestAcc 0.8471 0.8750
epoch 1000 LossPred 0.1933 LossAtt 0.5359 TrainAcc 0.9300 TestAcc 0.8471 0.9000
epoch 1100 LossPred 0.1778 LossAtt 0.5626 TrainAcc 0.9400 TestAcc 0.8418 0.8950
epoch 1200 LossPred 0.1784 LossAtt 0.5558 TrainAcc 0.9400 TestAcc 0.8448 0.8850
epoch 1300 LossPred 0.1642 LossAtt 0.5433 TrainAcc 0.9500 TestAcc 0.8438 0.8950
epoch 1400 LossPred 0.1979 LossAtt 0.5425 TrainAcc 0.9400 TestAcc 0.8463 0.8750
epoch 1500 LossPred 0.1633 LossAtt 0.5296 TrainAcc 0.9500 TestAcc 0.8391 0.8850
epoch 1600 LossPred 0.1593 LossAtt 0.5370 TrainAcc 0.9500 TestAcc 0.8438 0.8950
epoch 1700 LossPred 0.1731 LossAtt 0.5692 TrainAcc 0.9600 TestAcc 0.8448 0.8700
epoch 1800 LossPred 0.1592 LossAtt 0.5154 TrainAcc 0.9600 TestAcc 0.8456 0.8700
epoch 1900 LossPred 0.1751 LossAtt 0.5311 TrainAcc 0.9400 TestAcc 0.8416 0.8800
epoch 2000 LossPred 0.1526 LossAtt 0.5028 TrainAcc 0.9600 TestAcc 0.8418 0.8900
epoch 2100 LossPred 0.1523 LossAtt 0.5077 TrainAcc 0.9600 TestAcc 0.8398 0.8800
epoch 2200 LossPred 0.1520 LossAtt 0.5121 TrainAcc 0.9600 TestAcc 0.8433 0.8800
epoch 2300 LossPred 0.1496 LossAtt 0.4930 TrainAcc 0.9500 TestAcc 0.8406 0.9000
epoch 2400 LossPred 0.1561 LossAtt 0.5237 TrainAcc 0.9600 TestAcc 0.8408 0.8850
epoch 2500 LossPred 0.1491 LossAtt 0.5074 TrainAcc 0.9600 TestAcc 0.8388 0.8950
Optimization Finished!
********** replication  26  **********
epoch   0 LossPred 1.0259 LossAtt 0.9990 TrainAcc 0.5200 TestAcc 0.5105 0.5050
epoch 100 LossPred 0.9722 LossAtt 0.4775 TrainAcc 0.5300 TestAcc 0.5050 0.5250
epoch 200 LossPred 0.9323 LossAtt 0.5278 TrainAcc 0.6400 TestAcc 0.5195 0.6200
epoch 300 LossPred 0.9079 LossAtt 0.5334 TrainAcc 0.6600 TestAcc 0.5193 0.6350
epoch 400 LossPred 0.8928 LossAtt 0.5781 TrainAcc 0.6500 TestAcc 0.5185 0.6400
epoch 500 LossPred 0.8780 LossAtt 0.5894 TrainAcc 0.6500 TestAcc 0.5163 0.6150
epoch 600 LossPred 0.8549 LossAtt 0.6444 TrainAcc 0.6500 TestAcc 0.5100 0.6450
epoch 700 LossPred 0.8262 LossAtt 0.6575 TrainAcc 0.6700 TestAcc 0.5065 0.6350
epoch 800 LossPred 0.8141 LossAtt 0.6571 TrainAcc 0.6900 TestAcc 0.5125 0.6400
epoch 900 LossPred 0.7905 LossAtt 0.6515 TrainAcc 0.6900 TestAcc 0.5178 0.6450
epoch 1000 LossPred 0.7850 LossAtt 0.6554 TrainAcc 0.6900 TestAcc 0.5150 0.6600
epoch 1100 LossPred 0.7753 LossAtt 0.6709 TrainAcc 0.7000 TestAcc 0.5120 0.6600
epoch 1200 LossPred 0.7766 LossAtt 0.6609 TrainAcc 0.6800 TestAcc 0.5083 0.6650
epoch 1300 LossPred 0.7628 LossAtt 0.6607 TrainAcc 0.7000 TestAcc 0.5115 0.6800
epoch 1400 LossPred 0.7625 LossAtt 0.6784 TrainAcc 0.6800 TestAcc 0.5100 0.6650
epoch 1500 LossPred 0.7613 LossAtt 0.6851 TrainAcc 0.6700 TestAcc 0.5080 0.6600
epoch 1600 LossPred 0.7748 LossAtt 0.6488 TrainAcc 0.7100 TestAcc 0.5093 0.6550
epoch 1700 LossPred 0.7509 LossAtt 0.6532 TrainAcc 0.7100 TestAcc 0.5208 0.6500
epoch 1800 LossPred 0.7572 LossAtt 0.6742 TrainAcc 0.7400 TestAcc 0.5153 0.6650
epoch 1900 LossPred 0.7470 LossAtt 0.6770 TrainAcc 0.7100 TestAcc 0.5178 0.6500
epoch 2000 LossPred 0.7455 LossAtt 0.6434 TrainAcc 0.7400 TestAcc 0.5185 0.6550
epoch 2100 LossPred 0.7323 LossAtt 0.6383 TrainAcc 0.7400 TestAcc 0.5190 0.6450
epoch 2200 LossPred 0.7411 LossAtt 0.6708 TrainAcc 0.7400 TestAcc 0.5153 0.6500
epoch 2300 LossPred 0.7251 LossAtt 0.6542 TrainAcc 0.7400 TestAcc 0.5145 0.6450
epoch 2400 LossPred 0.7285 LossAtt 0.6297 TrainAcc 0.7100 TestAcc 0.5033 0.6600
epoch 2500 LossPred 0.7200 LossAtt 0.6552 TrainAcc 0.7200 TestAcc 0.5023 0.6800
Optimization Finished!
********** replication  27  **********
epoch   0 LossPred 1.0152 LossAtt 1.1059 TrainAcc 0.6000 TestAcc 0.5728 0.5700
epoch 100 LossPred 0.9303 LossAtt 0.5663 TrainAcc 0.6000 TestAcc 0.5728 0.6000
epoch 200 LossPred 0.8962 LossAtt 0.5656 TrainAcc 0.6400 TestAcc 0.5893 0.6400
epoch 300 LossPred 0.8269 LossAtt 0.6399 TrainAcc 0.6900 TestAcc 0.5470 0.6600
epoch 400 LossPred 0.7866 LossAtt 0.6466 TrainAcc 0.7100 TestAcc 0.5470 0.6800
epoch 500 LossPred 0.7654 LossAtt 0.6395 TrainAcc 0.7500 TestAcc 0.5403 0.6650
epoch 600 LossPred 0.7315 LossAtt 0.6455 TrainAcc 0.7600 TestAcc 0.5298 0.6850
epoch 700 LossPred 0.7147 LossAtt 0.6707 TrainAcc 0.7800 TestAcc 0.5300 0.7000
epoch 800 LossPred 0.6633 LossAtt 0.6627 TrainAcc 0.7800 TestAcc 0.5313 0.6950
epoch 900 LossPred 0.6406 LossAtt 0.6800 TrainAcc 0.7800 TestAcc 0.5348 0.7150
epoch 1000 LossPred 0.6328 LossAtt 0.6746 TrainAcc 0.7700 TestAcc 0.5370 0.7000
epoch 1100 LossPred 0.6190 LossAtt 0.7035 TrainAcc 0.7700 TestAcc 0.5345 0.7150
epoch 1200 LossPred 0.5908 LossAtt 0.7143 TrainAcc 0.8100 TestAcc 0.5170 0.7250
epoch 1300 LossPred 0.5669 LossAtt 0.6889 TrainAcc 0.8000 TestAcc 0.5195 0.7400
epoch 1400 LossPred 0.5770 LossAtt 0.7156 TrainAcc 0.8100 TestAcc 0.5300 0.7350
epoch 1500 LossPred 0.5694 LossAtt 0.6932 TrainAcc 0.8100 TestAcc 0.5293 0.7250
epoch 1600 LossPred 0.5648 LossAtt 0.6839 TrainAcc 0.8100 TestAcc 0.5295 0.7300
epoch 1700 LossPred 0.5865 LossAtt 0.6809 TrainAcc 0.8100 TestAcc 0.5340 0.7150
epoch 1800 LossPred 0.5554 LossAtt 0.6530 TrainAcc 0.8200 TestAcc 0.5355 0.7400
epoch 1900 LossPred 0.5583 LossAtt 0.6562 TrainAcc 0.8200 TestAcc 0.5353 0.7200
epoch 2000 LossPred 0.5603 LossAtt 0.6372 TrainAcc 0.8400 TestAcc 0.5363 0.7250
epoch 2100 LossPred 0.5680 LossAtt 0.6447 TrainAcc 0.8100 TestAcc 0.5358 0.7200
epoch 2200 LossPred 0.5635 LossAtt 0.6215 TrainAcc 0.8200 TestAcc 0.5273 0.7250
epoch 2300 LossPred 0.5633 LossAtt 0.6006 TrainAcc 0.8200 TestAcc 0.5315 0.7450
epoch 2400 LossPred 0.5931 LossAtt 0.6129 TrainAcc 0.8000 TestAcc 0.5398 0.7100
epoch 2500 LossPred 0.5497 LossAtt 0.5916 TrainAcc 0.8200 TestAcc 0.5343 0.7550
Optimization Finished!
********** replication  28  **********
epoch   0 LossPred 1.2494 LossAtt 1.0206 TrainAcc 0.5200 TestAcc 0.5303 0.5300
epoch 100 LossPred 1.0179 LossAtt 0.5809 TrainAcc 0.5600 TestAcc 0.5648 0.5650
epoch 200 LossPred 0.9828 LossAtt 0.3587 TrainAcc 0.5600 TestAcc 0.5648 0.5600
epoch 300 LossPred 0.9691 LossAtt 0.4629 TrainAcc 0.6300 TestAcc 0.6176 0.6300
epoch 400 LossPred 0.9569 LossAtt 0.4882 TrainAcc 0.6300 TestAcc 0.6176 0.6300
epoch 500 LossPred 0.9357 LossAtt 0.4495 TrainAcc 0.6300 TestAcc 0.6176 0.6350
epoch 600 LossPred 0.8856 LossAtt 0.4691 TrainAcc 0.6600 TestAcc 0.6189 0.6600
epoch 700 LossPred 0.3830 LossAtt 0.4125 TrainAcc 0.8600 TestAcc 0.8579 0.8500
epoch 800 LossPred 0.3544 LossAtt 0.3810 TrainAcc 0.8500 TestAcc 0.8586 0.8550
epoch 900 LossPred 0.3376 LossAtt 0.3376 TrainAcc 0.8600 TestAcc 0.8586 0.8450
epoch 1000 LossPred 0.3235 LossAtt 0.3260 TrainAcc 0.9000 TestAcc 0.8706 0.9050
epoch 1100 LossPred 0.2996 LossAtt 0.3198 TrainAcc 0.9100 TestAcc 0.8784 0.9050
epoch 1200 LossPred 0.3058 LossAtt 0.3024 TrainAcc 0.9000 TestAcc 0.8821 0.9050
epoch 1300 LossPred 0.2950 LossAtt 0.3121 TrainAcc 0.9000 TestAcc 0.8741 0.8800
epoch 1400 LossPred 0.2702 LossAtt 0.3170 TrainAcc 0.9300 TestAcc 0.8756 0.9100
epoch 1500 LossPred 0.2409 LossAtt 0.2953 TrainAcc 0.9300 TestAcc 0.8726 0.9200
epoch 1600 LossPred 0.2758 LossAtt 0.3037 TrainAcc 0.9200 TestAcc 0.8871 0.9200
epoch 1700 LossPred 0.2307 LossAtt 0.3036 TrainAcc 0.9300 TestAcc 0.8794 0.9250
epoch 1800 LossPred 0.2391 LossAtt 0.3148 TrainAcc 0.9400 TestAcc 0.8891 0.9350
epoch 1900 LossPred 0.2501 LossAtt 0.3021 TrainAcc 0.9200 TestAcc 0.8896 0.9250
epoch 2000 LossPred 0.3004 LossAtt 0.2942 TrainAcc 0.9300 TestAcc 0.8704 0.9150
epoch 2100 LossPred 0.2122 LossAtt 0.3031 TrainAcc 0.9400 TestAcc 0.8924 0.9350
epoch 2200 LossPred 0.2138 LossAtt 0.2917 TrainAcc 0.9400 TestAcc 0.8891 0.9250
epoch 2300 LossPred 0.2347 LossAtt 0.2919 TrainAcc 0.9400 TestAcc 0.8909 0.9250
epoch 2400 LossPred 0.2829 LossAtt 0.2972 TrainAcc 0.9000 TestAcc 0.8824 0.8850
epoch 2500 LossPred 0.2131 LossAtt 0.2943 TrainAcc 0.9400 TestAcc 0.8926 0.9350
Optimization Finished!
********** replication  29  **********
epoch   0 LossPred 1.2570 LossAtt 1.0309 TrainAcc 0.4700 TestAcc 0.4607 0.4350
epoch 100 LossPred 0.9253 LossAtt 0.5710 TrainAcc 0.5900 TestAcc 0.5553 0.5700
epoch 200 LossPred 0.8524 LossAtt 0.5871 TrainAcc 0.6300 TestAcc 0.5781 0.6350
epoch 300 LossPred 0.7735 LossAtt 0.6678 TrainAcc 0.6900 TestAcc 0.6346 0.6750
epoch 400 LossPred 0.5365 LossAtt 0.6598 TrainAcc 0.8400 TestAcc 0.8008 0.8400
epoch 500 LossPred 0.4658 LossAtt 0.6367 TrainAcc 0.9000 TestAcc 0.8206 0.8850
epoch 600 LossPred 0.3879 LossAtt 0.6255 TrainAcc 0.9000 TestAcc 0.8248 0.8850
epoch 700 LossPred 0.4148 LossAtt 0.6010 TrainAcc 0.8700 TestAcc 0.8091 0.8300
epoch 800 LossPred 0.3462 LossAtt 0.5385 TrainAcc 0.9100 TestAcc 0.8318 0.9050
epoch 900 LossPred 0.3459 LossAtt 0.5223 TrainAcc 0.9100 TestAcc 0.8218 0.9000
epoch 1000 LossPred 0.3468 LossAtt 0.5205 TrainAcc 0.8900 TestAcc 0.8201 0.8950
epoch 1100 LossPred 0.3118 LossAtt 0.5266 TrainAcc 0.9200 TestAcc 0.8226 0.9000
epoch 1200 LossPred 0.3021 LossAtt 0.5093 TrainAcc 0.9200 TestAcc 0.8228 0.9000
epoch 1300 LossPred 0.2988 LossAtt 0.5116 TrainAcc 0.9200 TestAcc 0.8183 0.9050
epoch 1400 LossPred 0.3219 LossAtt 0.5009 TrainAcc 0.9000 TestAcc 0.8133 0.9050
epoch 1500 LossPred 0.2923 LossAtt 0.4768 TrainAcc 0.9200 TestAcc 0.8143 0.9100
epoch 1600 LossPred 0.3116 LossAtt 0.4918 TrainAcc 0.9000 TestAcc 0.8121 0.9050
epoch 1700 LossPred 0.3365 LossAtt 0.5015 TrainAcc 0.9000 TestAcc 0.7963 0.8750
epoch 1800 LossPred 0.2828 LossAtt 0.4795 TrainAcc 0.9200 TestAcc 0.8153 0.9050
epoch 1900 LossPred 0.2958 LossAtt 0.4825 TrainAcc 0.9100 TestAcc 0.8148 0.9000
epoch 2000 LossPred 0.3155 LossAtt 0.4869 TrainAcc 0.8800 TestAcc 0.7995 0.8900
epoch 2100 LossPred 0.3085 LossAtt 0.4787 TrainAcc 0.8800 TestAcc 0.8093 0.8900
epoch 2200 LossPred 0.3307 LossAtt 0.4682 TrainAcc 0.8900 TestAcc 0.7755 0.8900
epoch 2300 LossPred 0.3335 LossAtt 0.5114 TrainAcc 0.8800 TestAcc 0.7953 0.8650
epoch 2400 LossPred 0.3368 LossAtt 0.5143 TrainAcc 0.9000 TestAcc 0.7885 0.8900
epoch 2500 LossPred 0.3530 LossAtt 0.5132 TrainAcc 0.9000 TestAcc 0.7883 0.8800
Optimization Finished!
********** replication  30  **********
epoch   0 LossPred 1.3346 LossAtt 1.0324 TrainAcc 0.4900 TestAcc 0.4499 0.5000
epoch 100 LossPred 1.0486 LossAtt 0.5858 TrainAcc 0.5300 TestAcc 0.5383 0.5150
epoch 200 LossPred 0.9783 LossAtt 0.6214 TrainAcc 0.5600 TestAcc 0.5988 0.5600
epoch 300 LossPred 0.9500 LossAtt 0.6747 TrainAcc 0.6000 TestAcc 0.6111 0.6100
epoch 400 LossPred 0.9264 LossAtt 0.6094 TrainAcc 0.6500 TestAcc 0.6121 0.6300
epoch 500 LossPred 0.9079 LossAtt 0.5479 TrainAcc 0.6500 TestAcc 0.6081 0.6350
epoch 600 LossPred 0.8918 LossAtt 0.5154 TrainAcc 0.6500 TestAcc 0.6129 0.6300
epoch 700 LossPred 0.8725 LossAtt 0.5088 TrainAcc 0.6700 TestAcc 0.6214 0.6350
epoch 800 LossPred 0.6267 LossAtt 0.5731 TrainAcc 0.7800 TestAcc 0.7580 0.7900
epoch 900 LossPred 0.6190 LossAtt 0.5932 TrainAcc 0.7900 TestAcc 0.7628 0.7850
epoch 1000 LossPred 0.7489 LossAtt 0.5823 TrainAcc 0.7100 TestAcc 0.7670 0.7700
epoch 1100 LossPred 0.5411 LossAtt 0.5959 TrainAcc 0.8200 TestAcc 0.7773 0.8150
epoch 1200 LossPred 0.5134 LossAtt 0.5916 TrainAcc 0.8300 TestAcc 0.7708 0.7900
epoch 1300 LossPred 0.5579 LossAtt 0.6013 TrainAcc 0.8200 TestAcc 0.7780 0.8100
epoch 1400 LossPred 0.5346 LossAtt 0.5711 TrainAcc 0.8500 TestAcc 0.7755 0.8350
epoch 1500 LossPred 0.6062 LossAtt 0.5486 TrainAcc 0.8000 TestAcc 0.7588 0.8150
epoch 1600 LossPred 0.5504 LossAtt 0.5255 TrainAcc 0.8100 TestAcc 0.7785 0.8250
epoch 1700 LossPred 0.5348 LossAtt 0.5292 TrainAcc 0.8100 TestAcc 0.7728 0.8150
epoch 1800 LossPred 0.5934 LossAtt 0.5307 TrainAcc 0.8000 TestAcc 0.7800 0.8150
epoch 1900 LossPred 0.5418 LossAtt 0.5450 TrainAcc 0.8300 TestAcc 0.7885 0.8250
epoch 2000 LossPred 0.5687 LossAtt 0.5107 TrainAcc 0.8300 TestAcc 0.7983 0.8350
epoch 2100 LossPred 0.4708 LossAtt 0.5500 TrainAcc 0.8500 TestAcc 0.8161 0.8500
epoch 2200 LossPred 1.2613 LossAtt 0.4555 TrainAcc 0.5500 TestAcc 0.5150 0.5550
epoch 2300 LossPred 0.8765 LossAtt 0.4339 TrainAcc 0.6700 TestAcc 0.6574 0.6500
epoch 2400 LossPred 0.7675 LossAtt 0.4797 TrainAcc 0.6900 TestAcc 0.7142 0.6850
epoch 2500 LossPred 0.5936 LossAtt 0.4928 TrainAcc 0.8100 TestAcc 0.7928 0.7850
Optimization Finished!
********** replication  31  **********
epoch   0 LossPred 1.2428 LossAtt 1.0140 TrainAcc 0.5200 TestAcc 0.5078 0.5000
epoch 100 LossPred 0.9076 LossAtt 0.5946 TrainAcc 0.6100 TestAcc 0.5778 0.5600
epoch 200 LossPred 0.6301 LossAtt 0.6092 TrainAcc 0.8000 TestAcc 0.7510 0.8250
epoch 300 LossPred 0.5772 LossAtt 0.6114 TrainAcc 0.8200 TestAcc 0.7655 0.8200
epoch 400 LossPred 0.3973 LossAtt 0.5724 TrainAcc 0.8800 TestAcc 0.8133 0.8450
epoch 500 LossPred 0.3584 LossAtt 0.5499 TrainAcc 0.8900 TestAcc 0.8018 0.8300
epoch 600 LossPred 0.5117 LossAtt 0.4640 TrainAcc 0.8600 TestAcc 0.7860 0.8300
epoch 700 LossPred 0.3347 LossAtt 0.4495 TrainAcc 0.9000 TestAcc 0.7940 0.8350
epoch 800 LossPred 0.4083 LossAtt 0.4464 TrainAcc 0.8700 TestAcc 0.8063 0.8700
epoch 900 LossPred 0.4107 LossAtt 0.4376 TrainAcc 0.8600 TestAcc 0.7728 0.8150
epoch 1000 LossPred 0.3570 LossAtt 0.4395 TrainAcc 0.8900 TestAcc 0.8036 0.8500
epoch 1100 LossPred 0.4421 LossAtt 0.4111 TrainAcc 0.8800 TestAcc 0.7993 0.8450
epoch 1200 LossPred 0.3592 LossAtt 0.4219 TrainAcc 0.8800 TestAcc 0.7920 0.8500
epoch 1300 LossPred 0.4272 LossAtt 0.4209 TrainAcc 0.8700 TestAcc 0.8006 0.8600
epoch 1400 LossPred 0.3925 LossAtt 0.4080 TrainAcc 0.8700 TestAcc 0.7890 0.8500
epoch 1500 LossPred 0.4120 LossAtt 0.3978 TrainAcc 0.8600 TestAcc 0.7890 0.8500
epoch 1600 LossPred 0.6069 LossAtt 0.4186 TrainAcc 0.8200 TestAcc 0.7750 0.8150
epoch 1700 LossPred 0.4292 LossAtt 0.3749 TrainAcc 0.8400 TestAcc 0.7648 0.8250
epoch 1800 LossPred 0.3647 LossAtt 0.3876 TrainAcc 0.8900 TestAcc 0.7900 0.8500
epoch 1900 LossPred 0.4435 LossAtt 0.3755 TrainAcc 0.8500 TestAcc 0.7788 0.8350
epoch 2000 LossPred 0.5514 LossAtt 0.3804 TrainAcc 0.8300 TestAcc 0.7858 0.8050
epoch 2100 LossPred 0.4142 LossAtt 0.3558 TrainAcc 0.8700 TestAcc 0.7773 0.8350
epoch 2200 LossPred 0.4001 LossAtt 0.3387 TrainAcc 0.8900 TestAcc 0.7850 0.8400
epoch 2300 LossPred 0.4780 LossAtt 0.3375 TrainAcc 0.8200 TestAcc 0.7543 0.8200
epoch 2400 LossPred 0.4391 LossAtt 0.3571 TrainAcc 0.8500 TestAcc 0.7768 0.8400
epoch 2500 LossPred 0.4495 LossAtt 0.3487 TrainAcc 0.8500 TestAcc 0.7783 0.8450
Optimization Finished!
********** replication  32  **********
epoch   0 LossPred 1.1181 LossAtt 1.0259 TrainAcc 0.5100 TestAcc 0.4555 0.4950
epoch 100 LossPred 0.9459 LossAtt 0.4362 TrainAcc 0.6300 TestAcc 0.5378 0.6250
epoch 200 LossPred 0.9238 LossAtt 0.4302 TrainAcc 0.6300 TestAcc 0.5378 0.6300
epoch 300 LossPred 0.9170 LossAtt 0.3692 TrainAcc 0.6400 TestAcc 0.5290 0.6300
epoch 400 LossPred 0.9139 LossAtt 0.3400 TrainAcc 0.6400 TestAcc 0.5288 0.6300
epoch 500 LossPred 0.9125 LossAtt 0.3298 TrainAcc 0.6400 TestAcc 0.5300 0.6350
epoch 600 LossPred 0.9029 LossAtt 0.4994 TrainAcc 0.6400 TestAcc 0.5293 0.6350
epoch 700 LossPred 0.8797 LossAtt 0.7013 TrainAcc 0.6900 TestAcc 0.5215 0.6500
epoch 800 LossPred 0.8510 LossAtt 0.5698 TrainAcc 0.7000 TestAcc 0.5143 0.7000
epoch 900 LossPred 0.8315 LossAtt 0.5661 TrainAcc 0.6900 TestAcc 0.5290 0.6850
epoch 1000 LossPred 0.7960 LossAtt 0.6417 TrainAcc 0.6900 TestAcc 0.5220 0.6600
epoch 1100 LossPred 0.7089 LossAtt 0.6892 TrainAcc 0.7700 TestAcc 0.5295 0.7050
epoch 1200 LossPred 0.6729 LossAtt 0.6533 TrainAcc 0.8000 TestAcc 0.5293 0.7300
epoch 1300 LossPred 0.6089 LossAtt 0.6741 TrainAcc 0.8100 TestAcc 0.5243 0.7300
epoch 1400 LossPred 0.5610 LossAtt 0.6192 TrainAcc 0.8300 TestAcc 0.5295 0.7650
epoch 1500 LossPred 0.5377 LossAtt 0.6310 TrainAcc 0.8100 TestAcc 0.5293 0.7600
epoch 1600 LossPred 0.5192 LossAtt 0.6194 TrainAcc 0.8200 TestAcc 0.5278 0.7600
epoch 1700 LossPred 0.5058 LossAtt 0.6298 TrainAcc 0.8200 TestAcc 0.5275 0.7700
epoch 1800 LossPred 0.4871 LossAtt 0.6081 TrainAcc 0.8300 TestAcc 0.5243 0.7750
epoch 1900 LossPred 0.4879 LossAtt 0.6111 TrainAcc 0.8200 TestAcc 0.5258 0.7700
epoch 2000 LossPred 0.4797 LossAtt 0.6223 TrainAcc 0.8300 TestAcc 0.5273 0.7700
epoch 2100 LossPred 0.4977 LossAtt 0.6244 TrainAcc 0.8300 TestAcc 0.5305 0.7550
epoch 2200 LossPred 0.4663 LossAtt 0.6164 TrainAcc 0.8400 TestAcc 0.5285 0.7600
epoch 2300 LossPred 0.4594 LossAtt 0.5767 TrainAcc 0.8500 TestAcc 0.5300 0.7600
epoch 2400 LossPred 0.4513 LossAtt 0.5715 TrainAcc 0.8500 TestAcc 0.5320 0.7550
epoch 2500 LossPred 0.4874 LossAtt 0.5933 TrainAcc 0.8200 TestAcc 0.5328 0.7800
Optimization Finished!
********** replication  33  **********
epoch   0 LossPred 1.4320 LossAtt 1.0163 TrainAcc 0.4900 TestAcc 0.5508 0.4450
epoch 100 LossPred 1.0842 LossAtt 0.6123 TrainAcc 0.5100 TestAcc 0.5766 0.5050
epoch 200 LossPred 0.9519 LossAtt 0.6139 TrainAcc 0.6300 TestAcc 0.5593 0.6150
epoch 300 LossPred 0.9186 LossAtt 0.6385 TrainAcc 0.6300 TestAcc 0.5593 0.6300
epoch 400 LossPred 0.8958 LossAtt 0.7144 TrainAcc 0.6400 TestAcc 0.5591 0.6200
epoch 500 LossPred 0.8704 LossAtt 0.7213 TrainAcc 0.6200 TestAcc 0.5453 0.6000
epoch 600 LossPred 0.8480 LossAtt 0.6934 TrainAcc 0.6500 TestAcc 0.5511 0.6500
epoch 700 LossPred 0.7995 LossAtt 0.6525 TrainAcc 0.7000 TestAcc 0.5921 0.7000
epoch 800 LossPred 0.7954 LossAtt 0.6121 TrainAcc 0.6900 TestAcc 0.5823 0.6900
epoch 900 LossPred 0.7700 LossAtt 0.5590 TrainAcc 0.7100 TestAcc 0.5876 0.6900
epoch 1000 LossPred 0.7475 LossAtt 0.5442 TrainAcc 0.7300 TestAcc 0.5851 0.6850
epoch 1100 LossPred 0.7215 LossAtt 0.5831 TrainAcc 0.7300 TestAcc 0.5818 0.6850
epoch 1200 LossPred 0.7117 LossAtt 0.5710 TrainAcc 0.7200 TestAcc 0.5783 0.6750
epoch 1300 LossPred 0.6843 LossAtt 0.5672 TrainAcc 0.7300 TestAcc 0.5748 0.6950
epoch 1400 LossPred 0.6710 LossAtt 0.5838 TrainAcc 0.7500 TestAcc 0.5776 0.6950
epoch 1500 LossPred 0.6865 LossAtt 0.5733 TrainAcc 0.7600 TestAcc 0.5788 0.7000
epoch 1600 LossPred 0.6913 LossAtt 0.5396 TrainAcc 0.7600 TestAcc 0.5796 0.6900
epoch 1700 LossPred 0.6601 LossAtt 0.5517 TrainAcc 0.7700 TestAcc 0.5811 0.7150
epoch 1800 LossPred 0.6637 LossAtt 0.5665 TrainAcc 0.7800 TestAcc 0.5808 0.7000
epoch 1900 LossPred 0.6931 LossAtt 0.5461 TrainAcc 0.7500 TestAcc 0.5813 0.7150
epoch 2000 LossPred 0.6497 LossAtt 0.5435 TrainAcc 0.7800 TestAcc 0.5831 0.7050
epoch 2100 LossPred 0.6534 LossAtt 0.5441 TrainAcc 0.7700 TestAcc 0.5846 0.7250
epoch 2200 LossPred 0.6317 LossAtt 0.5424 TrainAcc 0.7800 TestAcc 0.5838 0.7500
epoch 2300 LossPred 0.6247 LossAtt 0.5335 TrainAcc 0.7800 TestAcc 0.5826 0.7250
epoch 2400 LossPred 0.6226 LossAtt 0.5275 TrainAcc 0.7700 TestAcc 0.5833 0.7300
epoch 2500 LossPred 0.6220 LossAtt 0.5433 TrainAcc 0.7700 TestAcc 0.5841 0.7300
Optimization Finished!
********** replication  34  **********
epoch   0 LossPred 0.8426 LossAtt 1.0119 TrainAcc 0.6900 TestAcc 0.5801 0.6900
epoch 100 LossPred 0.7826 LossAtt 0.4144 TrainAcc 0.7200 TestAcc 0.6186 0.7050
epoch 200 LossPred 0.5712 LossAtt 0.6375 TrainAcc 0.7800 TestAcc 0.6969 0.7700
epoch 300 LossPred 0.4277 LossAtt 0.5687 TrainAcc 0.8600 TestAcc 0.8251 0.8450
epoch 400 LossPred 0.3267 LossAtt 0.4995 TrainAcc 0.8900 TestAcc 0.8353 0.8650
epoch 500 LossPred 0.3508 LossAtt 0.4948 TrainAcc 0.8900 TestAcc 0.8546 0.8550
epoch 600 LossPred 0.4213 LossAtt 0.4646 TrainAcc 0.8700 TestAcc 0.8438 0.8200
epoch 700 LossPred 0.3779 LossAtt 0.4319 TrainAcc 0.8700 TestAcc 0.7888 0.8650
epoch 800 LossPred 0.3025 LossAtt 0.5213 TrainAcc 0.9000 TestAcc 0.8556 0.8950
epoch 900 LossPred 0.4018 LossAtt 0.4131 TrainAcc 0.8600 TestAcc 0.7938 0.8550
epoch 1000 LossPred 0.3547 LossAtt 0.4108 TrainAcc 0.8800 TestAcc 0.8256 0.8700
epoch 1100 LossPred 0.4351 LossAtt 0.3848 TrainAcc 0.8500 TestAcc 0.7998 0.8400
epoch 1200 LossPred 0.3366 LossAtt 0.3838 TrainAcc 0.8900 TestAcc 0.8321 0.8800
epoch 1300 LossPred 0.4315 LossAtt 0.4138 TrainAcc 0.8600 TestAcc 0.8163 0.8750
epoch 1400 LossPred 0.6096 LossAtt 0.3649 TrainAcc 0.7900 TestAcc 0.6892 0.7900
epoch 1500 LossPred 0.3901 LossAtt 0.3550 TrainAcc 0.8600 TestAcc 0.8023 0.8450
epoch 1600 LossPred 0.4509 LossAtt 0.4839 TrainAcc 0.8600 TestAcc 0.7960 0.8650
epoch 1700 LossPred 0.4524 LossAtt 0.4178 TrainAcc 0.8600 TestAcc 0.8276 0.8500
epoch 1800 LossPred 0.5360 LossAtt 0.3646 TrainAcc 0.8200 TestAcc 0.7200 0.8050
epoch 1900 LossPred 0.5193 LossAtt 0.3716 TrainAcc 0.8100 TestAcc 0.7440 0.8150
epoch 2000 LossPred 0.5041 LossAtt 0.4165 TrainAcc 0.8500 TestAcc 0.8103 0.8350
epoch 2100 LossPred 0.4843 LossAtt 0.3583 TrainAcc 0.8200 TestAcc 0.7380 0.8200
epoch 2200 LossPred 0.3585 LossAtt 0.4067 TrainAcc 0.8900 TestAcc 0.8296 0.8700
epoch 2300 LossPred 0.6509 LossAtt 0.3537 TrainAcc 0.7700 TestAcc 0.6759 0.7750
epoch 2400 LossPred 0.2816 LossAtt 0.3965 TrainAcc 0.9300 TestAcc 0.8586 0.9200
epoch 2500 LossPred 0.3621 LossAtt 0.3821 TrainAcc 0.8800 TestAcc 0.7863 0.8600
Optimization Finished!
********** replication  35  **********
epoch   0 LossPred 1.4932 LossAtt 1.0479 TrainAcc 0.4100 TestAcc 0.5030 0.4050
epoch 100 LossPred 1.1281 LossAtt 0.5813 TrainAcc 0.4400 TestAcc 0.4307 0.4250
epoch 200 LossPred 1.0140 LossAtt 0.4286 TrainAcc 0.6100 TestAcc 0.4607 0.5400
epoch 300 LossPred 0.9833 LossAtt 0.4574 TrainAcc 0.5600 TestAcc 0.4262 0.5600
epoch 400 LossPred 0.9351 LossAtt 0.4970 TrainAcc 0.5600 TestAcc 0.4324 0.5650
epoch 500 LossPred 0.8195 LossAtt 0.3843 TrainAcc 0.7000 TestAcc 0.7082 0.6900
epoch 600 LossPred 0.6107 LossAtt 0.3809 TrainAcc 0.8100 TestAcc 0.8198 0.7800
epoch 700 LossPred 0.5730 LossAtt 0.3720 TrainAcc 0.8300 TestAcc 0.8211 0.7800
epoch 800 LossPred 0.8034 LossAtt 0.3452 TrainAcc 0.6900 TestAcc 0.6912 0.6850
epoch 900 LossPred 0.7275 LossAtt 0.3127 TrainAcc 0.8100 TestAcc 0.7080 0.8050
epoch 1000 LossPred 0.5620 LossAtt 0.2931 TrainAcc 0.8100 TestAcc 0.7778 0.7950
epoch 1100 LossPred 0.5827 LossAtt 0.2924 TrainAcc 0.8000 TestAcc 0.7813 0.7700
epoch 1200 LossPred 0.5736 LossAtt 0.2898 TrainAcc 0.7900 TestAcc 0.7813 0.8050
epoch 1300 LossPred 0.5496 LossAtt 0.2949 TrainAcc 0.8200 TestAcc 0.7745 0.7900
epoch 1400 LossPred 0.5662 LossAtt 0.2908 TrainAcc 0.7900 TestAcc 0.7658 0.7900
epoch 1500 LossPred 0.5670 LossAtt 0.2689 TrainAcc 0.8100 TestAcc 0.8036 0.8150
epoch 1600 LossPred 0.6537 LossAtt 0.2637 TrainAcc 0.7400 TestAcc 0.6839 0.7750
epoch 1700 LossPred 0.5633 LossAtt 0.2575 TrainAcc 0.8000 TestAcc 0.7115 0.8000
epoch 1800 LossPred 0.5463 LossAtt 0.2591 TrainAcc 0.7900 TestAcc 0.7535 0.8050
epoch 1900 LossPred 0.5147 LossAtt 0.2608 TrainAcc 0.8200 TestAcc 0.7815 0.8100
epoch 2000 LossPred 0.5184 LossAtt 0.2553 TrainAcc 0.8100 TestAcc 0.7860 0.8250
epoch 2100 LossPred 0.5099 LossAtt 0.2599 TrainAcc 0.8300 TestAcc 0.7925 0.8350
epoch 2200 LossPred 0.5052 LossAtt 0.2514 TrainAcc 0.8400 TestAcc 0.7828 0.8300
epoch 2300 LossPred 0.5077 LossAtt 0.2496 TrainAcc 0.8300 TestAcc 0.7845 0.8300
epoch 2400 LossPred 0.5531 LossAtt 0.2485 TrainAcc 0.8000 TestAcc 0.7455 0.8100
epoch 2500 LossPred 0.5190 LossAtt 0.2426 TrainAcc 0.8300 TestAcc 0.7860 0.8100
Optimization Finished!
********** replication  36  **********
epoch   0 LossPred 1.2197 LossAtt 1.0682 TrainAcc 0.4400 TestAcc 0.4937 0.4800
epoch 100 LossPred 0.9144 LossAtt 0.4757 TrainAcc 0.6500 TestAcc 0.5808 0.6550
epoch 200 LossPred 0.8639 LossAtt 0.6212 TrainAcc 0.6500 TestAcc 0.5808 0.6500
epoch 300 LossPred 0.8453 LossAtt 0.6570 TrainAcc 0.6800 TestAcc 0.5791 0.6650
epoch 400 LossPred 0.8201 LossAtt 0.6755 TrainAcc 0.6900 TestAcc 0.5761 0.6850
epoch 500 LossPred 0.7891 LossAtt 0.6848 TrainAcc 0.7200 TestAcc 0.5738 0.7150
epoch 600 LossPred 0.7460 LossAtt 0.6499 TrainAcc 0.7400 TestAcc 0.5818 0.7300
epoch 700 LossPred 0.6834 LossAtt 0.6462 TrainAcc 0.7500 TestAcc 0.5808 0.7400
epoch 800 LossPred 0.6371 LossAtt 0.6846 TrainAcc 0.8200 TestAcc 0.5671 0.7550
epoch 900 LossPred 0.6307 LossAtt 0.6594 TrainAcc 0.7800 TestAcc 0.5688 0.7400
epoch 1000 LossPred 0.5870 LossAtt 0.6578 TrainAcc 0.8100 TestAcc 0.5631 0.7300
epoch 1100 LossPred 0.5861 LossAtt 0.6696 TrainAcc 0.7900 TestAcc 0.5648 0.7250
epoch 1200 LossPred 0.5871 LossAtt 0.6370 TrainAcc 0.8000 TestAcc 0.5628 0.7350
epoch 1300 LossPred 0.5743 LossAtt 0.6524 TrainAcc 0.8000 TestAcc 0.5668 0.7550
epoch 1400 LossPred 0.5759 LossAtt 0.6370 TrainAcc 0.7800 TestAcc 0.5653 0.7500
epoch 1500 LossPred 0.5633 LossAtt 0.6491 TrainAcc 0.8200 TestAcc 0.5663 0.7650
epoch 1600 LossPred 0.5535 LossAtt 0.6227 TrainAcc 0.8200 TestAcc 0.5666 0.7600
epoch 1700 LossPred 0.5502 LossAtt 0.6176 TrainAcc 0.8100 TestAcc 0.5676 0.7650
epoch 1800 LossPred 0.5369 LossAtt 0.5969 TrainAcc 0.8300 TestAcc 0.5676 0.7450
epoch 1900 LossPred 0.5359 LossAtt 0.6009 TrainAcc 0.8300 TestAcc 0.5683 0.7500
epoch 2000 LossPred 0.5328 LossAtt 0.6101 TrainAcc 0.8500 TestAcc 0.5661 0.7500
epoch 2100 LossPred 0.5330 LossAtt 0.6022 TrainAcc 0.8400 TestAcc 0.5606 0.7650
epoch 2200 LossPred 0.5341 LossAtt 0.6050 TrainAcc 0.8100 TestAcc 0.5608 0.7600
epoch 2300 LossPred 0.5453 LossAtt 0.6066 TrainAcc 0.8100 TestAcc 0.5553 0.7450
epoch 2400 LossPred 0.5337 LossAtt 0.5970 TrainAcc 0.8300 TestAcc 0.5543 0.7450
epoch 2500 LossPred 0.5235 LossAtt 0.5934 TrainAcc 0.8300 TestAcc 0.5558 0.7550
Optimization Finished!
********** replication  37  **********
epoch   0 LossPred 1.1095 LossAtt 1.0670 TrainAcc 0.4900 TestAcc 0.4392 0.4900
epoch 100 LossPred 0.9653 LossAtt 0.5382 TrainAcc 0.5900 TestAcc 0.5383 0.5750
epoch 200 LossPred 0.9268 LossAtt 0.6011 TrainAcc 0.6600 TestAcc 0.5248 0.6350
epoch 300 LossPred 0.8675 LossAtt 0.6176 TrainAcc 0.6800 TestAcc 0.5230 0.6550
epoch 400 LossPred 0.8109 LossAtt 0.6423 TrainAcc 0.7000 TestAcc 0.5360 0.6800
epoch 500 LossPred 0.7520 LossAtt 0.6448 TrainAcc 0.7200 TestAcc 0.5556 0.7150
epoch 600 LossPred 0.7197 LossAtt 0.5993 TrainAcc 0.7300 TestAcc 0.5453 0.6850
epoch 700 LossPred 0.6835 LossAtt 0.5702 TrainAcc 0.7600 TestAcc 0.5163 0.7400
epoch 800 LossPred 0.6663 LossAtt 0.5435 TrainAcc 0.7500 TestAcc 0.5003 0.7200
epoch 900 LossPred 0.6446 LossAtt 0.5264 TrainAcc 0.7600 TestAcc 0.4982 0.7250
epoch 1000 LossPred 0.6286 LossAtt 0.5134 TrainAcc 0.7600 TestAcc 0.4852 0.7400
epoch 1100 LossPred 0.6190 LossAtt 0.5105 TrainAcc 0.7800 TestAcc 0.4852 0.7400
epoch 1200 LossPred 0.6249 LossAtt 0.5340 TrainAcc 0.7800 TestAcc 0.4842 0.7350
epoch 1300 LossPred 0.6056 LossAtt 0.5045 TrainAcc 0.7900 TestAcc 0.4840 0.7550
epoch 1400 LossPred 0.5999 LossAtt 0.5218 TrainAcc 0.8000 TestAcc 0.4837 0.7650
epoch 1500 LossPred 0.5955 LossAtt 0.5248 TrainAcc 0.8000 TestAcc 0.4850 0.7550
epoch 1600 LossPred 0.5840 LossAtt 0.5314 TrainAcc 0.8000 TestAcc 0.4875 0.7600
epoch 1700 LossPred 0.5874 LossAtt 0.5185 TrainAcc 0.8000 TestAcc 0.4877 0.7600
epoch 1800 LossPred 0.5757 LossAtt 0.5184 TrainAcc 0.8200 TestAcc 0.4945 0.7850
epoch 1900 LossPred 0.5675 LossAtt 0.5298 TrainAcc 0.8300 TestAcc 0.4972 0.7650
epoch 2000 LossPred 0.5933 LossAtt 0.5377 TrainAcc 0.8000 TestAcc 0.5020 0.7750
epoch 2100 LossPred 0.5610 LossAtt 0.5410 TrainAcc 0.8300 TestAcc 0.5085 0.7950
epoch 2200 LossPred 0.5300 LossAtt 0.5177 TrainAcc 0.8500 TestAcc 0.5133 0.7950
epoch 2300 LossPred 0.5199 LossAtt 0.4905 TrainAcc 0.8500 TestAcc 0.5180 0.7950
epoch 2400 LossPred 0.5092 LossAtt 0.5175 TrainAcc 0.8500 TestAcc 0.5193 0.7950
epoch 2500 LossPred 0.5070 LossAtt 0.5130 TrainAcc 0.8800 TestAcc 0.5243 0.8050
Optimization Finished!
********** replication  38  **********
epoch   0 LossPred 1.1925 LossAtt 1.0179 TrainAcc 0.5000 TestAcc 0.4702 0.4800
epoch 100 LossPred 0.9369 LossAtt 0.5087 TrainAcc 0.6000 TestAcc 0.5706 0.6000
epoch 200 LossPred 0.9080 LossAtt 0.4564 TrainAcc 0.6000 TestAcc 0.5706 0.6000
epoch 300 LossPred 0.8912 LossAtt 0.3333 TrainAcc 0.6000 TestAcc 0.5706 0.6000
epoch 400 LossPred 0.8818 LossAtt 0.2844 TrainAcc 0.6000 TestAcc 0.5706 0.5950
epoch 500 LossPred 0.8744 LossAtt 0.2815 TrainAcc 0.6100 TestAcc 0.5440 0.5950
epoch 600 LossPred 0.8690 LossAtt 0.2937 TrainAcc 0.6100 TestAcc 0.5440 0.6000
epoch 700 LossPred 0.8640 LossAtt 0.2877 TrainAcc 0.6100 TestAcc 0.5440 0.5950
epoch 800 LossPred 0.8569 LossAtt 0.2867 TrainAcc 0.6100 TestAcc 0.5440 0.6000
epoch 900 LossPred 0.8512 LossAtt 0.2427 TrainAcc 0.6100 TestAcc 0.5440 0.5950
epoch 1000 LossPred 0.8494 LossAtt 0.2257 TrainAcc 0.6100 TestAcc 0.5440 0.5950
epoch 1100 LossPred 0.8486 LossAtt 0.1871 TrainAcc 0.6100 TestAcc 0.5440 0.5900
epoch 1200 LossPred 0.8473 LossAtt 0.1598 TrainAcc 0.6100 TestAcc 0.5440 0.6100
epoch 1300 LossPred 0.8400 LossAtt 0.1672 TrainAcc 0.6100 TestAcc 0.5030 0.6100
epoch 1400 LossPred 0.8070 LossAtt 0.3897 TrainAcc 0.6800 TestAcc 0.5203 0.7000
epoch 1500 LossPred 0.6871 LossAtt 0.7238 TrainAcc 0.7500 TestAcc 0.7192 0.7200
epoch 1600 LossPred 0.4748 LossAtt 0.6153 TrainAcc 0.8600 TestAcc 0.7858 0.8000
epoch 1700 LossPred 0.4708 LossAtt 0.6288 TrainAcc 0.8400 TestAcc 0.7763 0.8300
epoch 1800 LossPred 0.4502 LossAtt 0.6090 TrainAcc 0.8300 TestAcc 0.7775 0.8400
epoch 1900 LossPred 0.4286 LossAtt 0.6100 TrainAcc 0.8600 TestAcc 0.7745 0.8500
epoch 2000 LossPred 0.4086 LossAtt 0.5732 TrainAcc 0.8600 TestAcc 0.7588 0.8650
epoch 2100 LossPred 0.4031 LossAtt 0.5705 TrainAcc 0.8500 TestAcc 0.7628 0.8550
epoch 2200 LossPred 0.3898 LossAtt 0.5640 TrainAcc 0.8800 TestAcc 0.7580 0.8600
epoch 2300 LossPred 0.3740 LossAtt 0.5444 TrainAcc 0.8700 TestAcc 0.7595 0.8600
epoch 2400 LossPred 0.3468 LossAtt 0.5264 TrainAcc 0.8900 TestAcc 0.7565 0.8600
epoch 2500 LossPred 0.3803 LossAtt 0.5419 TrainAcc 0.9000 TestAcc 0.7457 0.8650
Optimization Finished!
********** replication  39  **********
epoch   0 LossPred 1.1424 LossAtt 1.0028 TrainAcc 0.5400 TestAcc 0.5315 0.5200
epoch 100 LossPred 0.8785 LossAtt 0.4872 TrainAcc 0.5700 TestAcc 0.5843 0.5700
epoch 200 LossPred 0.6002 LossAtt 0.5367 TrainAcc 0.8300 TestAcc 0.7878 0.8150
epoch 300 LossPred 0.5285 LossAtt 0.5148 TrainAcc 0.8400 TestAcc 0.8071 0.8100
epoch 400 LossPred 0.4656 LossAtt 0.5101 TrainAcc 0.8400 TestAcc 0.8081 0.8300
epoch 500 LossPred 0.4325 LossAtt 0.4903 TrainAcc 0.8700 TestAcc 0.8411 0.8400
epoch 600 LossPred 0.4375 LossAtt 0.4670 TrainAcc 0.8700 TestAcc 0.8158 0.8150
epoch 700 LossPred 0.3914 LossAtt 0.4728 TrainAcc 0.8800 TestAcc 0.8423 0.8400
epoch 800 LossPred 0.4191 LossAtt 0.4682 TrainAcc 0.8400 TestAcc 0.8371 0.8000
epoch 900 LossPred 0.3846 LossAtt 0.4533 TrainAcc 0.8800 TestAcc 0.8393 0.8300
epoch 1000 LossPred 0.3640 LossAtt 0.4478 TrainAcc 0.8800 TestAcc 0.8423 0.8500
epoch 1100 LossPred 0.7115 LossAtt 0.4657 TrainAcc 0.7700 TestAcc 0.7442 0.8150
epoch 1200 LossPred 0.4789 LossAtt 0.4231 TrainAcc 0.8500 TestAcc 0.7700 0.8600
epoch 1300 LossPred 0.5218 LossAtt 0.3991 TrainAcc 0.8600 TestAcc 0.7605 0.8300
epoch 1400 LossPred 0.4312 LossAtt 0.4490 TrainAcc 0.8800 TestAcc 0.8448 0.8250
epoch 1500 LossPred 0.8732 LossAtt 0.4171 TrainAcc 0.7200 TestAcc 0.6999 0.7250
epoch 1600 LossPred 0.4039 LossAtt 0.4237 TrainAcc 0.8700 TestAcc 0.8579 0.8400
epoch 1700 LossPred 0.5401 LossAtt 0.4167 TrainAcc 0.8600 TestAcc 0.7465 0.8300
epoch 1800 LossPred 0.4175 LossAtt 0.4085 TrainAcc 0.8800 TestAcc 0.8201 0.8750
epoch 1900 LossPred 0.6281 LossAtt 0.4023 TrainAcc 0.7700 TestAcc 0.7495 0.7850
epoch 2000 LossPred 0.4657 LossAtt 0.4102 TrainAcc 0.8500 TestAcc 0.8146 0.8600
epoch 2100 LossPred 0.3594 LossAtt 0.4076 TrainAcc 0.8900 TestAcc 0.8391 0.8650
epoch 2200 LossPred 0.3819 LossAtt 0.4150 TrainAcc 0.8800 TestAcc 0.8181 0.8650
epoch 2300 LossPred 0.4544 LossAtt 0.4019 TrainAcc 0.8700 TestAcc 0.8153 0.8550
epoch 2400 LossPred 0.3791 LossAtt 0.4171 TrainAcc 0.8800 TestAcc 0.8496 0.8650
epoch 2500 LossPred 0.4296 LossAtt 0.3869 TrainAcc 0.8500 TestAcc 0.7715 0.8450
Optimization Finished!
********** replication  40  **********
epoch   0 LossPred 1.0815 LossAtt 1.0220 TrainAcc 0.6400 TestAcc 0.5603 0.6300
epoch 100 LossPred 0.8432 LossAtt 0.4495 TrainAcc 0.6400 TestAcc 0.5618 0.6450
epoch 200 LossPred 0.8077 LossAtt 0.4519 TrainAcc 0.7000 TestAcc 0.6034 0.7000
epoch 300 LossPred 0.5981 LossAtt 0.4418 TrainAcc 0.7600 TestAcc 0.7853 0.7700
epoch 400 LossPred 0.5264 LossAtt 0.4024 TrainAcc 0.7900 TestAcc 0.8003 0.8250
epoch 500 LossPred 0.4847 LossAtt 0.3546 TrainAcc 0.8200 TestAcc 0.8001 0.8300
epoch 600 LossPred 0.3880 LossAtt 0.3549 TrainAcc 0.8800 TestAcc 0.7768 0.8300
epoch 700 LossPred 0.4788 LossAtt 0.3463 TrainAcc 0.8600 TestAcc 0.7768 0.8300
epoch 800 LossPred 0.2901 LossAtt 0.3377 TrainAcc 0.9200 TestAcc 0.8008 0.8550
epoch 900 LossPred 0.2918 LossAtt 0.3215 TrainAcc 0.9000 TestAcc 0.8046 0.8550
epoch 1000 LossPred 0.3049 LossAtt 0.3189 TrainAcc 0.8900 TestAcc 0.8026 0.8500
epoch 1100 LossPred 0.2827 LossAtt 0.3330 TrainAcc 0.9200 TestAcc 0.7983 0.8500
epoch 1200 LossPred 0.2859 LossAtt 0.3341 TrainAcc 0.9100 TestAcc 0.8038 0.8450
epoch 1300 LossPred 0.3149 LossAtt 0.3158 TrainAcc 0.9000 TestAcc 0.8018 0.8550
epoch 1400 LossPred 0.3347 LossAtt 0.3267 TrainAcc 0.8600 TestAcc 0.8061 0.8500
epoch 1500 LossPred 0.2981 LossAtt 0.3158 TrainAcc 0.9200 TestAcc 0.7953 0.8650
epoch 1600 LossPred 0.3126 LossAtt 0.3121 TrainAcc 0.9100 TestAcc 0.7953 0.8600
epoch 1700 LossPred 0.3200 LossAtt 0.3044 TrainAcc 0.8900 TestAcc 0.7965 0.8600
epoch 1800 LossPred 0.3064 LossAtt 0.3094 TrainAcc 0.9100 TestAcc 0.7873 0.8600
epoch 1900 LossPred 0.3175 LossAtt 0.2996 TrainAcc 0.9100 TestAcc 0.7843 0.8550
epoch 2000 LossPred 0.3418 LossAtt 0.2973 TrainAcc 0.8900 TestAcc 0.7853 0.8550
epoch 2100 LossPred 0.3388 LossAtt 0.2997 TrainAcc 0.8800 TestAcc 0.7983 0.8600
epoch 2200 LossPred 0.3563 LossAtt 0.3043 TrainAcc 0.9000 TestAcc 0.7828 0.8500
epoch 2300 LossPred 0.4292 LossAtt 0.2978 TrainAcc 0.8500 TestAcc 0.7958 0.8450
epoch 2400 LossPred 0.3632 LossAtt 0.2799 TrainAcc 0.8800 TestAcc 0.7833 0.8450
epoch 2500 LossPred 0.3824 LossAtt 0.2911 TrainAcc 0.8800 TestAcc 0.7848 0.8450
Optimization Finished!
********** replication  41  **********
epoch   0 LossPred 1.4096 LossAtt 1.0094 TrainAcc 0.4100 TestAcc 0.4329 0.4100
epoch 100 LossPred 1.0085 LossAtt 0.5206 TrainAcc 0.5300 TestAcc 0.5853 0.5400
epoch 200 LossPred 0.9366 LossAtt 0.4521 TrainAcc 0.5600 TestAcc 0.5861 0.5850
epoch 300 LossPred 0.9124 LossAtt 0.3967 TrainAcc 0.5600 TestAcc 0.5728 0.5550
epoch 400 LossPred 0.8976 LossAtt 0.4085 TrainAcc 0.5500 TestAcc 0.5728 0.5550
epoch 500 LossPred 0.8772 LossAtt 0.3945 TrainAcc 0.5700 TestAcc 0.5703 0.5850
epoch 600 LossPred 0.8665 LossAtt 0.3549 TrainAcc 0.6100 TestAcc 0.5773 0.6000
epoch 700 LossPred 0.8623 LossAtt 0.3668 TrainAcc 0.6300 TestAcc 0.5763 0.6200
epoch 800 LossPred 0.8595 LossAtt 0.3594 TrainAcc 0.6400 TestAcc 0.5813 0.6200
epoch 900 LossPred 0.8698 LossAtt 0.3636 TrainAcc 0.6200 TestAcc 0.5866 0.6250
epoch 1000 LossPred 0.8597 LossAtt 0.4203 TrainAcc 0.6400 TestAcc 0.5876 0.6100
epoch 1100 LossPred 0.8599 LossAtt 0.4273 TrainAcc 0.6300 TestAcc 0.5958 0.6050
epoch 1200 LossPred 0.8624 LossAtt 0.4583 TrainAcc 0.6400 TestAcc 0.6044 0.6000
epoch 1300 LossPred 0.8548 LossAtt 0.5111 TrainAcc 0.6400 TestAcc 0.6001 0.6050
epoch 1400 LossPred 0.8539 LossAtt 0.4971 TrainAcc 0.6300 TestAcc 0.5991 0.5850
epoch 1500 LossPred 0.8690 LossAtt 0.4653 TrainAcc 0.6500 TestAcc 0.6029 0.6450
epoch 1600 LossPred 0.8488 LossAtt 0.4391 TrainAcc 0.6700 TestAcc 0.6039 0.6050
epoch 1700 LossPred 0.8399 LossAtt 0.4331 TrainAcc 0.6800 TestAcc 0.5978 0.6000
epoch 1800 LossPred 0.8477 LossAtt 0.4349 TrainAcc 0.6600 TestAcc 0.5868 0.6200
epoch 1900 LossPred 0.8212 LossAtt 0.4719 TrainAcc 0.6700 TestAcc 0.6069 0.6350
epoch 2000 LossPred 0.9706 LossAtt 0.4277 TrainAcc 0.6000 TestAcc 0.6056 0.6100
epoch 2100 LossPred 0.9469 LossAtt 0.3991 TrainAcc 0.6000 TestAcc 0.5533 0.5950
epoch 2200 LossPred 0.9499 LossAtt 0.3561 TrainAcc 0.5900 TestAcc 0.5325 0.6050
epoch 2300 LossPred 0.9443 LossAtt 0.3676 TrainAcc 0.5900 TestAcc 0.5320 0.6200
epoch 2400 LossPred 0.9229 LossAtt 0.3555 TrainAcc 0.6100 TestAcc 0.5290 0.6150
epoch 2500 LossPred 0.9345 LossAtt 0.3558 TrainAcc 0.6000 TestAcc 0.5338 0.6100
Optimization Finished!
********** replication  42  **********
epoch   0 LossPred 1.0178 LossAtt 0.9670 TrainAcc 0.4700 TestAcc 0.4670 0.4750
epoch 100 LossPred 0.9313 LossAtt 0.4204 TrainAcc 0.6300 TestAcc 0.5488 0.6300
epoch 200 LossPred 0.8907 LossAtt 0.4524 TrainAcc 0.6500 TestAcc 0.5445 0.6300
epoch 300 LossPred 0.6697 LossAtt 0.7138 TrainAcc 0.7300 TestAcc 0.6567 0.7150
epoch 400 LossPred 0.4401 LossAtt 0.6418 TrainAcc 0.8300 TestAcc 0.7548 0.8200
epoch 500 LossPred 0.4985 LossAtt 0.6298 TrainAcc 0.8100 TestAcc 0.7322 0.7850
epoch 600 LossPred 0.6673 LossAtt 0.6232 TrainAcc 0.7800 TestAcc 0.7475 0.7750
epoch 700 LossPred 0.4257 LossAtt 0.6147 TrainAcc 0.8400 TestAcc 0.7457 0.8300
epoch 800 LossPred 0.6695 LossAtt 0.5942 TrainAcc 0.7800 TestAcc 0.7720 0.7700
epoch 900 LossPred 0.4341 LossAtt 0.6022 TrainAcc 0.8300 TestAcc 0.7540 0.8100
epoch 1000 LossPred 0.4261 LossAtt 0.6008 TrainAcc 0.8300 TestAcc 0.7397 0.8200
epoch 1100 LossPred 0.3845 LossAtt 0.5942 TrainAcc 0.8400 TestAcc 0.7685 0.8350
epoch 1200 LossPred 0.4658 LossAtt 0.6069 TrainAcc 0.8300 TestAcc 0.7385 0.7950
epoch 1300 LossPred 0.3479 LossAtt 0.6021 TrainAcc 0.8700 TestAcc 0.7865 0.8400
epoch 1400 LossPred 0.4515 LossAtt 0.5864 TrainAcc 0.8400 TestAcc 0.7260 0.7900
epoch 1500 LossPred 0.3963 LossAtt 0.5628 TrainAcc 0.8400 TestAcc 0.7590 0.8250
epoch 1600 LossPred 0.3497 LossAtt 0.5720 TrainAcc 0.8700 TestAcc 0.7655 0.8350
epoch 1700 LossPred 0.4264 LossAtt 0.5855 TrainAcc 0.8400 TestAcc 0.7435 0.8150
epoch 1800 LossPred 0.7341 LossAtt 0.5715 TrainAcc 0.7400 TestAcc 0.6336 0.7000
epoch 1900 LossPred 0.3293 LossAtt 0.5606 TrainAcc 0.8800 TestAcc 0.7282 0.8550
epoch 2000 LossPred 0.4624 LossAtt 0.5375 TrainAcc 0.8800 TestAcc 0.7825 0.8700
epoch 2100 LossPred 0.3757 LossAtt 0.5402 TrainAcc 0.8800 TestAcc 0.7810 0.8700
epoch 2200 LossPred 0.4465 LossAtt 0.5602 TrainAcc 0.8800 TestAcc 0.7848 0.8600
epoch 2300 LossPred 0.2552 LossAtt 0.5503 TrainAcc 0.9200 TestAcc 0.7975 0.9000
epoch 2400 LossPred 0.2256 LossAtt 0.5300 TrainAcc 0.9300 TestAcc 0.8033 0.9250
epoch 2500 LossPred 0.2197 LossAtt 0.5496 TrainAcc 0.9400 TestAcc 0.8083 0.9250
Optimization Finished!
********** replication  43  **********
epoch   0 LossPred 0.9978 LossAtt 1.0561 TrainAcc 0.5600 TestAcc 0.5115 0.5650
epoch 100 LossPred 0.8807 LossAtt 0.6149 TrainAcc 0.6700 TestAcc 0.5843 0.6600
epoch 200 LossPred 0.5004 LossAtt 0.6975 TrainAcc 0.8600 TestAcc 0.7663 0.8000
epoch 300 LossPred 0.4329 LossAtt 0.6779 TrainAcc 0.8500 TestAcc 0.8308 0.8400
epoch 400 LossPred 0.3701 LossAtt 0.6474 TrainAcc 0.8800 TestAcc 0.8308 0.8600
epoch 500 LossPred 0.3486 LossAtt 0.5974 TrainAcc 0.9000 TestAcc 0.8163 0.8650
epoch 600 LossPred 0.3350 LossAtt 0.5623 TrainAcc 0.8900 TestAcc 0.8398 0.8550
epoch 700 LossPred 0.3745 LossAtt 0.5551 TrainAcc 0.8900 TestAcc 0.8276 0.8600
epoch 800 LossPred 0.3058 LossAtt 0.5467 TrainAcc 0.9100 TestAcc 0.8463 0.8900
epoch 900 LossPred 0.4068 LossAtt 0.5564 TrainAcc 0.8700 TestAcc 0.7968 0.8650
epoch 1000 LossPred 0.2494 LossAtt 0.5787 TrainAcc 0.9300 TestAcc 0.8471 0.9050
epoch 1100 LossPred 0.2663 LossAtt 0.5485 TrainAcc 0.9300 TestAcc 0.8348 0.9300
epoch 1200 LossPred 0.2074 LossAtt 0.5662 TrainAcc 0.9500 TestAcc 0.8546 0.9200
epoch 1300 LossPred 0.2159 LossAtt 0.5586 TrainAcc 0.9400 TestAcc 0.8456 0.9500
epoch 1400 LossPred 0.2359 LossAtt 0.5704 TrainAcc 0.9400 TestAcc 0.8306 0.8900
epoch 1500 LossPred 0.3054 LossAtt 0.5572 TrainAcc 0.9000 TestAcc 0.8026 0.9050
epoch 1600 LossPred 0.2481 LossAtt 0.5452 TrainAcc 0.9300 TestAcc 0.8226 0.9200
epoch 1700 LossPred 0.2828 LossAtt 0.5580 TrainAcc 0.9000 TestAcc 0.8098 0.8900
epoch 1800 LossPred 0.3084 LossAtt 0.5769 TrainAcc 0.8900 TestAcc 0.8303 0.8750
epoch 1900 LossPred 0.4222 LossAtt 0.5261 TrainAcc 0.8400 TestAcc 0.7745 0.8850
epoch 2000 LossPred 0.2027 LossAtt 0.5546 TrainAcc 0.9400 TestAcc 0.8358 0.9450
epoch 2100 LossPred 0.2883 LossAtt 0.5437 TrainAcc 0.8900 TestAcc 0.7995 0.9100
epoch 2200 LossPred 0.2763 LossAtt 0.5435 TrainAcc 0.9000 TestAcc 0.7983 0.9150
epoch 2300 LossPred 0.1732 LossAtt 0.5302 TrainAcc 0.9400 TestAcc 0.8436 0.9450
epoch 2400 LossPred 0.3051 LossAtt 0.5431 TrainAcc 0.9100 TestAcc 0.7895 0.8950
epoch 2500 LossPred 0.1780 LossAtt 0.5445 TrainAcc 0.9400 TestAcc 0.8351 0.9350
Optimization Finished!
********** replication  44  **********
epoch   0 LossPred 1.1325 LossAtt 1.0385 TrainAcc 0.5200 TestAcc 0.5070 0.5200
epoch 100 LossPred 0.9643 LossAtt 0.4555 TrainAcc 0.5900 TestAcc 0.5773 0.5850
epoch 200 LossPred 0.9542 LossAtt 0.4255 TrainAcc 0.6200 TestAcc 0.5678 0.6050
epoch 300 LossPred 0.9423 LossAtt 0.4800 TrainAcc 0.6200 TestAcc 0.5678 0.5800
epoch 400 LossPred 0.9220 LossAtt 0.4887 TrainAcc 0.6300 TestAcc 0.5556 0.5750
epoch 500 LossPred 0.9147 LossAtt 0.5349 TrainAcc 0.6200 TestAcc 0.5405 0.5900
epoch 600 LossPred 0.9055 LossAtt 0.5561 TrainAcc 0.5900 TestAcc 0.5253 0.6100
epoch 700 LossPred 0.8735 LossAtt 0.6368 TrainAcc 0.6800 TestAcc 0.5851 0.6050
epoch 800 LossPred 0.8261 LossAtt 0.6514 TrainAcc 0.7000 TestAcc 0.5606 0.6650
epoch 900 LossPred 0.7736 LossAtt 0.6523 TrainAcc 0.7200 TestAcc 0.5648 0.6300
epoch 1000 LossPred 0.7333 LossAtt 0.6319 TrainAcc 0.7300 TestAcc 0.5573 0.6150
epoch 1100 LossPred 0.7047 LossAtt 0.6253 TrainAcc 0.7700 TestAcc 0.5485 0.6150
epoch 1200 LossPred 0.7022 LossAtt 0.6206 TrainAcc 0.7500 TestAcc 0.5513 0.6100
epoch 1300 LossPred 0.6644 LossAtt 0.6258 TrainAcc 0.7600 TestAcc 0.5533 0.6350
epoch 1400 LossPred 0.7095 LossAtt 0.6083 TrainAcc 0.7400 TestAcc 0.5581 0.6300
epoch 1500 LossPred 0.6901 LossAtt 0.5860 TrainAcc 0.7600 TestAcc 0.5608 0.6200
epoch 1600 LossPred 0.6741 LossAtt 0.5920 TrainAcc 0.7600 TestAcc 0.5526 0.6200
epoch 1700 LossPred 0.6698 LossAtt 0.5762 TrainAcc 0.7800 TestAcc 0.5528 0.6200
epoch 1800 LossPred 0.6737 LossAtt 0.5748 TrainAcc 0.7600 TestAcc 0.5548 0.6050
epoch 1900 LossPred 0.6864 LossAtt 0.5765 TrainAcc 0.7400 TestAcc 0.5531 0.5950
epoch 2000 LossPred 0.6839 LossAtt 0.5714 TrainAcc 0.7600 TestAcc 0.5566 0.5950
epoch 2100 LossPred 0.7430 LossAtt 0.5536 TrainAcc 0.7300 TestAcc 0.5623 0.6350
epoch 2200 LossPred 0.6828 LossAtt 0.5609 TrainAcc 0.7200 TestAcc 0.5531 0.6050
epoch 2300 LossPred 0.8212 LossAtt 0.5439 TrainAcc 0.6700 TestAcc 0.5583 0.6100
epoch 2400 LossPred 0.7754 LossAtt 0.5815 TrainAcc 0.7000 TestAcc 0.5716 0.6150
epoch 2500 LossPred 0.7091 LossAtt 0.5236 TrainAcc 0.7700 TestAcc 0.5693 0.6250
Optimization Finished!
********** replication  45  **********
epoch   0 LossPred 1.2576 LossAtt 1.0009 TrainAcc 0.4800 TestAcc 0.4925 0.4850
epoch 100 LossPred 1.0007 LossAtt 0.5187 TrainAcc 0.5400 TestAcc 0.4997 0.5400
epoch 200 LossPred 0.8543 LossAtt 0.6041 TrainAcc 0.6900 TestAcc 0.6894 0.7050
epoch 300 LossPred 0.5721 LossAtt 0.5900 TrainAcc 0.8100 TestAcc 0.8534 0.8150
epoch 400 LossPred 0.4793 LossAtt 0.5702 TrainAcc 0.8300 TestAcc 0.8546 0.8100
epoch 500 LossPred 0.4409 LossAtt 0.5570 TrainAcc 0.8400 TestAcc 0.8524 0.7900
epoch 600 LossPred 0.4044 LossAtt 0.5665 TrainAcc 0.8700 TestAcc 0.8724 0.8300
epoch 700 LossPred 0.3567 LossAtt 0.5499 TrainAcc 0.8700 TestAcc 0.8836 0.8250
epoch 800 LossPred 0.3331 LossAtt 0.5534 TrainAcc 0.8900 TestAcc 0.8871 0.8350
epoch 900 LossPred 0.3757 LossAtt 0.5469 TrainAcc 0.8800 TestAcc 0.8756 0.8650
epoch 1000 LossPred 0.3100 LossAtt 0.5434 TrainAcc 0.8900 TestAcc 0.8926 0.8350
epoch 1100 LossPred 0.3462 LossAtt 0.5229 TrainAcc 0.8800 TestAcc 0.8909 0.8300
epoch 1200 LossPred 0.2769 LossAtt 0.5113 TrainAcc 0.9000 TestAcc 0.9054 0.8700
epoch 1300 LossPred 0.3135 LossAtt 0.4980 TrainAcc 0.9100 TestAcc 0.8896 0.8850
epoch 1400 LossPred 0.7046 LossAtt 0.4959 TrainAcc 0.7600 TestAcc 0.7653 0.7500
epoch 1500 LossPred 0.3656 LossAtt 0.4967 TrainAcc 0.8600 TestAcc 0.8721 0.8500
epoch 1600 LossPred 0.2823 LossAtt 0.4802 TrainAcc 0.9000 TestAcc 0.8974 0.8600
epoch 1700 LossPred 0.2793 LossAtt 0.4899 TrainAcc 0.9000 TestAcc 0.8974 0.8800
epoch 1800 LossPred 0.2620 LossAtt 0.5007 TrainAcc 0.9100 TestAcc 0.9049 0.8850
epoch 1900 LossPred 0.2781 LossAtt 0.4948 TrainAcc 0.8900 TestAcc 0.8946 0.8750
epoch 2000 LossPred 0.2972 LossAtt 0.4902 TrainAcc 0.9100 TestAcc 0.8791 0.8750
epoch 2100 LossPred 0.2633 LossAtt 0.4895 TrainAcc 0.9100 TestAcc 0.8984 0.8850
epoch 2200 LossPred 0.3434 LossAtt 0.5071 TrainAcc 0.8700 TestAcc 0.8614 0.8650
epoch 2300 LossPred 0.2537 LossAtt 0.5159 TrainAcc 0.9200 TestAcc 0.8911 0.8950
epoch 2400 LossPred 0.2332 LossAtt 0.5099 TrainAcc 0.9100 TestAcc 0.9122 0.9000
epoch 2500 LossPred 0.2861 LossAtt 0.5167 TrainAcc 0.9100 TestAcc 0.8784 0.8600
Optimization Finished!
********** replication  46  **********
epoch   0 LossPred 0.9899 LossAtt 1.0623 TrainAcc 0.5900 TestAcc 0.5801 0.5750
epoch 100 LossPred 0.9320 LossAtt 0.5256 TrainAcc 0.6200 TestAcc 0.5320 0.6450
epoch 200 LossPred 0.9170 LossAtt 0.4424 TrainAcc 0.6200 TestAcc 0.5320 0.6150
epoch 300 LossPred 0.9136 LossAtt 0.4465 TrainAcc 0.6200 TestAcc 0.5320 0.6350
epoch 400 LossPred 0.9081 LossAtt 0.4495 TrainAcc 0.6200 TestAcc 0.5320 0.6300
epoch 500 LossPred 0.9041 LossAtt 0.4506 TrainAcc 0.6200 TestAcc 0.5320 0.6300
epoch 600 LossPred 0.9026 LossAtt 0.3704 TrainAcc 0.6200 TestAcc 0.5320 0.6250
epoch 700 LossPred 0.9034 LossAtt 0.3390 TrainAcc 0.6200 TestAcc 0.5320 0.6200
epoch 800 LossPred 0.9025 LossAtt 0.2986 TrainAcc 0.6200 TestAcc 0.5320 0.6250
epoch 900 LossPred 0.9010 LossAtt 0.3078 TrainAcc 0.6200 TestAcc 0.5320 0.6200
epoch 1000 LossPred 0.9005 LossAtt 0.3063 TrainAcc 0.6200 TestAcc 0.5320 0.6200
epoch 1100 LossPred 0.9008 LossAtt 0.2985 TrainAcc 0.6200 TestAcc 0.5320 0.6200
epoch 1200 LossPred 0.9010 LossAtt 0.2511 TrainAcc 0.6200 TestAcc 0.5320 0.6200
epoch 1300 LossPred 0.9029 LossAtt 0.2510 TrainAcc 0.6200 TestAcc 0.5320 0.6200
epoch 1400 LossPred 0.9049 LossAtt 0.3082 TrainAcc 0.6200 TestAcc 0.5320 0.6200
epoch 1500 LossPred 0.9043 LossAtt 0.2611 TrainAcc 0.6200 TestAcc 0.5320 0.6200
epoch 1600 LossPred 0.8987 LossAtt 0.3179 TrainAcc 0.6200 TestAcc 0.5320 0.6200
epoch 1700 LossPred 0.8937 LossAtt 0.2520 TrainAcc 0.6200 TestAcc 0.5320 0.6200
epoch 1800 LossPred 0.8945 LossAtt 0.3218 TrainAcc 0.6200 TestAcc 0.5320 0.6200
epoch 1900 LossPred 0.8971 LossAtt 0.3179 TrainAcc 0.6200 TestAcc 0.5320 0.6100
epoch 2000 LossPred 0.8927 LossAtt 0.2021 TrainAcc 0.6200 TestAcc 0.5123 0.6300
epoch 2100 LossPred 0.8919 LossAtt 0.2401 TrainAcc 0.6200 TestAcc 0.5320 0.6200
epoch 2200 LossPred 0.8919 LossAtt 0.3634 TrainAcc 0.6200 TestAcc 0.5123 0.6200
epoch 2300 LossPred 0.9001 LossAtt 0.5760 TrainAcc 0.6200 TestAcc 0.5320 0.6200
epoch 2400 LossPred 0.8970 LossAtt 0.3949 TrainAcc 0.6200 TestAcc 0.5320 0.6150
epoch 2500 LossPred 0.8862 LossAtt 0.5340 TrainAcc 0.6200 TestAcc 0.5143 0.6200
Optimization Finished!
********** replication  47  **********
epoch   0 LossPred 1.0978 LossAtt 1.0310 TrainAcc 0.4100 TestAcc 0.5283 0.4150
epoch 100 LossPred 0.9640 LossAtt 0.3754 TrainAcc 0.6000 TestAcc 0.5856 0.5950
epoch 200 LossPred 0.9602 LossAtt 0.3447 TrainAcc 0.6000 TestAcc 0.5856 0.6000
epoch 300 LossPred 0.9593 LossAtt 0.3394 TrainAcc 0.6000 TestAcc 0.5856 0.6000
epoch 400 LossPred 0.9555 LossAtt 0.3998 TrainAcc 0.6000 TestAcc 0.5856 0.6000
epoch 500 LossPred 0.9267 LossAtt 0.6248 TrainAcc 0.6200 TestAcc 0.5886 0.6250
epoch 600 LossPred 0.6192 LossAtt 0.4129 TrainAcc 0.7600 TestAcc 0.7923 0.7450
epoch 700 LossPred 0.8013 LossAtt 0.3976 TrainAcc 0.7100 TestAcc 0.7492 0.7250
epoch 800 LossPred 0.6141 LossAtt 0.4155 TrainAcc 0.8000 TestAcc 0.7863 0.7800
epoch 900 LossPred 0.6063 LossAtt 0.3860 TrainAcc 0.8100 TestAcc 0.7995 0.7600
epoch 1000 LossPred 0.6128 LossAtt 0.3918 TrainAcc 0.8000 TestAcc 0.8031 0.7500
epoch 1100 LossPred 0.5947 LossAtt 0.3693 TrainAcc 0.8100 TestAcc 0.8006 0.7500
epoch 1200 LossPred 0.5996 LossAtt 0.3987 TrainAcc 0.7900 TestAcc 0.8026 0.7500
epoch 1300 LossPred 0.5959 LossAtt 0.3816 TrainAcc 0.7900 TestAcc 0.8003 0.7600
epoch 1400 LossPred 0.5937 LossAtt 0.3826 TrainAcc 0.8000 TestAcc 0.8071 0.7600
epoch 1500 LossPred 0.5739 LossAtt 0.3568 TrainAcc 0.8200 TestAcc 0.8038 0.7650
epoch 1600 LossPred 0.6291 LossAtt 0.4089 TrainAcc 0.8000 TestAcc 0.7953 0.7850
epoch 1700 LossPred 0.6185 LossAtt 0.3805 TrainAcc 0.7900 TestAcc 0.7763 0.7450
epoch 1800 LossPred 0.6364 LossAtt 0.3833 TrainAcc 0.7600 TestAcc 0.7855 0.7650
epoch 1900 LossPred 0.5874 LossAtt 0.3824 TrainAcc 0.8100 TestAcc 0.8008 0.7600
epoch 2000 LossPred 0.6336 LossAtt 0.3710 TrainAcc 0.8000 TestAcc 0.7960 0.7750
epoch 2100 LossPred 0.5686 LossAtt 0.3792 TrainAcc 0.8100 TestAcc 0.8076 0.7650
epoch 2200 LossPred 0.5725 LossAtt 0.3738 TrainAcc 0.8100 TestAcc 0.8111 0.7650
epoch 2300 LossPred 0.6255 LossAtt 0.3811 TrainAcc 0.7600 TestAcc 0.7895 0.7350
epoch 2400 LossPred 0.5533 LossAtt 0.3848 TrainAcc 0.8200 TestAcc 0.8106 0.7700
epoch 2500 LossPred 0.5635 LossAtt 0.3875 TrainAcc 0.8100 TestAcc 0.8041 0.7550
Optimization Finished!
********** replication  48  **********
epoch   0 LossPred 1.0469 LossAtt 1.0843 TrainAcc 0.5300 TestAcc 0.4772 0.5300
epoch 100 LossPred 0.8548 LossAtt 0.5761 TrainAcc 0.6700 TestAcc 0.5423 0.6600
epoch 200 LossPred 0.7970 LossAtt 0.5231 TrainAcc 0.6900 TestAcc 0.5678 0.6900
epoch 300 LossPred 0.7588 LossAtt 0.6186 TrainAcc 0.7200 TestAcc 0.5948 0.7150
epoch 400 LossPred 0.7223 LossAtt 0.6312 TrainAcc 0.7300 TestAcc 0.5918 0.7250
epoch 500 LossPred 0.7078 LossAtt 0.6278 TrainAcc 0.7300 TestAcc 0.5843 0.7300
epoch 600 LossPred 0.6923 LossAtt 0.5865 TrainAcc 0.7600 TestAcc 0.5846 0.7350
epoch 700 LossPred 0.6836 LossAtt 0.4981 TrainAcc 0.7700 TestAcc 0.5863 0.7450
epoch 800 LossPred 0.6779 LossAtt 0.5030 TrainAcc 0.7500 TestAcc 0.5858 0.7450
epoch 900 LossPred 0.6730 LossAtt 0.5136 TrainAcc 0.7700 TestAcc 0.5811 0.7500
epoch 1000 LossPred 0.6640 LossAtt 0.5231 TrainAcc 0.7800 TestAcc 0.5826 0.7400
epoch 1100 LossPred 0.6627 LossAtt 0.5200 TrainAcc 0.7600 TestAcc 0.5856 0.7450
epoch 1200 LossPred 0.6507 LossAtt 0.4921 TrainAcc 0.7800 TestAcc 0.5838 0.7250
epoch 1300 LossPred 0.6371 LossAtt 0.5120 TrainAcc 0.7800 TestAcc 0.5831 0.7450
epoch 1400 LossPred 0.6306 LossAtt 0.5144 TrainAcc 0.7800 TestAcc 0.5841 0.7450
epoch 1500 LossPred 0.6237 LossAtt 0.5280 TrainAcc 0.7700 TestAcc 0.5853 0.7450
epoch 1600 LossPred 0.6159 LossAtt 0.5167 TrainAcc 0.7900 TestAcc 0.5896 0.7400
epoch 1700 LossPred 0.6178 LossAtt 0.5090 TrainAcc 0.7800 TestAcc 0.5958 0.7550
epoch 1800 LossPred 0.6155 LossAtt 0.5397 TrainAcc 0.7800 TestAcc 0.5951 0.7350
epoch 1900 LossPred 0.6217 LossAtt 0.5208 TrainAcc 0.7700 TestAcc 0.5936 0.7400
epoch 2000 LossPred 0.6090 LossAtt 0.5215 TrainAcc 0.7700 TestAcc 0.5881 0.7300
epoch 2100 LossPred 0.6274 LossAtt 0.5202 TrainAcc 0.7600 TestAcc 0.5838 0.7350
epoch 2200 LossPred 0.6320 LossAtt 0.5176 TrainAcc 0.7700 TestAcc 0.5788 0.7300
epoch 2300 LossPred 0.6071 LossAtt 0.5152 TrainAcc 0.7700 TestAcc 0.5748 0.7250
epoch 2400 LossPred 0.6029 LossAtt 0.5370 TrainAcc 0.7800 TestAcc 0.5733 0.7050
epoch 2500 LossPred 0.6130 LossAtt 0.5344 TrainAcc 0.8000 TestAcc 0.5796 0.7450
Optimization Finished!
********** replication  49  **********
epoch   0 LossPred 1.1200 LossAtt 1.0308 TrainAcc 0.4900 TestAcc 0.4887 0.4850
epoch 100 LossPred 0.9850 LossAtt 0.4992 TrainAcc 0.5500 TestAcc 0.5746 0.5500
epoch 200 LossPred 0.9834 LossAtt 0.2511 TrainAcc 0.5500 TestAcc 0.5746 0.5500
epoch 300 LossPred 0.9833 LossAtt 0.0930 TrainAcc 0.5500 TestAcc 0.5746 0.5500
epoch 400 LossPred 0.9830 LossAtt 0.1079 TrainAcc 0.5500 TestAcc 0.5746 0.5500
epoch 500 LossPred 0.9828 LossAtt 0.1225 TrainAcc 0.5500 TestAcc 0.5746 0.5500
epoch 600 LossPred 0.9820 LossAtt 0.1399 TrainAcc 0.5500 TestAcc 0.5746 0.5550
epoch 700 LossPred 0.9570 LossAtt 0.2791 TrainAcc 0.6100 TestAcc 0.6274 0.6450
epoch 800 LossPred 0.4016 LossAtt 0.4487 TrainAcc 0.8800 TestAcc 0.8471 0.8400
epoch 900 LossPred 0.4083 LossAtt 0.4562 TrainAcc 0.8700 TestAcc 0.8376 0.8600
epoch 1000 LossPred 0.3299 LossAtt 0.4527 TrainAcc 0.8600 TestAcc 0.8579 0.8850
epoch 1100 LossPred 0.3313 LossAtt 0.4498 TrainAcc 0.9000 TestAcc 0.8466 0.8800
epoch 1200 LossPred 0.3153 LossAtt 0.4550 TrainAcc 0.8900 TestAcc 0.8569 0.8750
epoch 1300 LossPred 0.2585 LossAtt 0.4499 TrainAcc 0.9100 TestAcc 0.8626 0.8950
epoch 1400 LossPred 0.2593 LossAtt 0.4652 TrainAcc 0.9300 TestAcc 0.8599 0.9100
epoch 1500 LossPred 0.2596 LossAtt 0.4560 TrainAcc 0.9300 TestAcc 0.8413 0.8900
epoch 1600 LossPred 0.2509 LossAtt 0.4512 TrainAcc 0.9200 TestAcc 0.8521 0.9100
epoch 1700 LossPred 0.2156 LossAtt 0.4209 TrainAcc 0.9200 TestAcc 0.8461 0.8850
epoch 1800 LossPred 0.2300 LossAtt 0.4304 TrainAcc 0.9300 TestAcc 0.8511 0.9150
epoch 1900 LossPred 0.2503 LossAtt 0.4413 TrainAcc 0.9200 TestAcc 0.8493 0.9050
epoch 2000 LossPred 0.2146 LossAtt 0.4147 TrainAcc 0.9300 TestAcc 0.8431 0.8850
epoch 2100 LossPred 0.2219 LossAtt 0.4181 TrainAcc 0.9300 TestAcc 0.8396 0.8850
epoch 2200 LossPred 0.2225 LossAtt 0.4347 TrainAcc 0.9200 TestAcc 0.8516 0.9050
epoch 2300 LossPred 0.2233 LossAtt 0.4163 TrainAcc 0.9400 TestAcc 0.8408 0.8850
epoch 2400 LossPred 0.2129 LossAtt 0.4176 TrainAcc 0.9400 TestAcc 0.8521 0.9100
epoch 2500 LossPred 0.3325 LossAtt 0.4042 TrainAcc 0.8800 TestAcc 0.8256 0.8800
Optimization Finished!
********** replication  50  **********
epoch   0 LossPred 1.0547 LossAtt 0.9983 TrainAcc 0.4900 TestAcc 0.4850 0.4900
epoch 100 LossPred 0.9063 LossAtt 0.4423 TrainAcc 0.6600 TestAcc 0.5843 0.6600
epoch 200 LossPred 0.8762 LossAtt 0.2904 TrainAcc 0.6600 TestAcc 0.5843 0.6600
epoch 300 LossPred 0.8676 LossAtt 0.2241 TrainAcc 0.6600 TestAcc 0.5843 0.6600
epoch 400 LossPred 0.8648 LossAtt 0.0898 TrainAcc 0.6600 TestAcc 0.5843 0.6600
epoch 500 LossPred 0.8639 LossAtt 0.1165 TrainAcc 0.6600 TestAcc 0.5843 0.6600
epoch 600 LossPred 0.8615 LossAtt 0.1802 TrainAcc 0.6600 TestAcc 0.5843 0.6600
epoch 700 LossPred 0.8498 LossAtt 0.2744 TrainAcc 0.6600 TestAcc 0.5843 0.6600
epoch 800 LossPred 0.5825 LossAtt 0.2750 TrainAcc 0.8100 TestAcc 0.7900 0.8300
epoch 900 LossPred 0.5362 LossAtt 0.2205 TrainAcc 0.8200 TestAcc 0.8078 0.8200
epoch 1000 LossPred 0.5067 LossAtt 0.2316 TrainAcc 0.8300 TestAcc 0.8366 0.8150
epoch 1100 LossPred 0.4976 LossAtt 0.2126 TrainAcc 0.8400 TestAcc 0.8421 0.8350
epoch 1200 LossPred 0.4801 LossAtt 0.2183 TrainAcc 0.8400 TestAcc 0.8403 0.8250
epoch 1300 LossPred 0.5038 LossAtt 0.2293 TrainAcc 0.8500 TestAcc 0.8201 0.8250
epoch 1400 LossPred 0.4713 LossAtt 0.2304 TrainAcc 0.8400 TestAcc 0.8456 0.8200
epoch 1500 LossPred 0.4999 LossAtt 0.2319 TrainAcc 0.8200 TestAcc 0.8286 0.8300
epoch 1600 LossPred 0.4789 LossAtt 0.2268 TrainAcc 0.8500 TestAcc 0.8393 0.8200
epoch 1700 LossPred 0.4663 LossAtt 0.2409 TrainAcc 0.8500 TestAcc 0.8436 0.8250
epoch 1800 LossPred 0.4835 LossAtt 0.2333 TrainAcc 0.8400 TestAcc 0.8421 0.8200
epoch 1900 LossPred 0.5129 LossAtt 0.2288 TrainAcc 0.8400 TestAcc 0.8328 0.8150
epoch 2000 LossPred 0.4921 LossAtt 0.2357 TrainAcc 0.8300 TestAcc 0.8381 0.8300
epoch 2100 LossPred 0.4916 LossAtt 0.2298 TrainAcc 0.8300 TestAcc 0.8336 0.8250
epoch 2200 LossPred 0.4836 LossAtt 0.2237 TrainAcc 0.8300 TestAcc 0.8361 0.8150
epoch 2300 LossPred 0.4947 LossAtt 0.2290 TrainAcc 0.8200 TestAcc 0.8358 0.8250
epoch 2400 LossPred 0.4853 LossAtt 0.2434 TrainAcc 0.8300 TestAcc 0.8351 0.8350
epoch 2500 LossPred 0.4801 LossAtt 0.2423 TrainAcc 0.8300 TestAcc 0.8391 0.8200
Optimization Finished!
********** replication  51  **********
epoch   0 LossPred 1.2860 LossAtt 1.0155 TrainAcc 0.3400 TestAcc 0.4720 0.3450
epoch 100 LossPred 0.9777 LossAtt 0.5946 TrainAcc 0.5900 TestAcc 0.5185 0.5800
epoch 200 LossPred 0.8997 LossAtt 0.5708 TrainAcc 0.6700 TestAcc 0.5593 0.6500
epoch 300 LossPred 0.8711 LossAtt 0.5631 TrainAcc 0.6700 TestAcc 0.5598 0.6550
epoch 400 LossPred 0.8064 LossAtt 0.6619 TrainAcc 0.7200 TestAcc 0.5418 0.7100
epoch 500 LossPred 0.7374 LossAtt 0.6631 TrainAcc 0.7400 TestAcc 0.5268 0.6900
epoch 600 LossPred 0.6983 LossAtt 0.6869 TrainAcc 0.7500 TestAcc 0.5313 0.7350
epoch 700 LossPred 0.6738 LossAtt 0.7000 TrainAcc 0.7500 TestAcc 0.5315 0.7300
epoch 800 LossPred 0.6537 LossAtt 0.6738 TrainAcc 0.8000 TestAcc 0.5323 0.7200
epoch 900 LossPred 0.6343 LossAtt 0.6782 TrainAcc 0.8100 TestAcc 0.5283 0.6950
epoch 1000 LossPred 0.6189 LossAtt 0.6897 TrainAcc 0.8300 TestAcc 0.5245 0.6850
epoch 1100 LossPred 0.6234 LossAtt 0.6711 TrainAcc 0.8200 TestAcc 0.5278 0.7050
epoch 1200 LossPred 0.5982 LossAtt 0.6806 TrainAcc 0.8300 TestAcc 0.5245 0.7150
epoch 1300 LossPred 0.6005 LossAtt 0.6583 TrainAcc 0.8300 TestAcc 0.5270 0.7250
epoch 1400 LossPred 0.6138 LossAtt 0.6433 TrainAcc 0.8400 TestAcc 0.5258 0.7300
epoch 1500 LossPred 0.5922 LossAtt 0.6631 TrainAcc 0.8200 TestAcc 0.5205 0.7300
epoch 1600 LossPred 0.6258 LossAtt 0.6320 TrainAcc 0.8200 TestAcc 0.5270 0.7450
epoch 1700 LossPred 0.6297 LossAtt 0.6389 TrainAcc 0.7900 TestAcc 0.5248 0.7200
epoch 1800 LossPred 0.6051 LossAtt 0.6257 TrainAcc 0.8200 TestAcc 0.5253 0.7150
epoch 1900 LossPred 0.6120 LossAtt 0.6163 TrainAcc 0.8000 TestAcc 0.5240 0.7050
epoch 2000 LossPred 0.6413 LossAtt 0.6005 TrainAcc 0.8100 TestAcc 0.5273 0.7400
epoch 2100 LossPred 0.6457 LossAtt 0.6280 TrainAcc 0.7900 TestAcc 0.5255 0.7050
epoch 2200 LossPred 0.6613 LossAtt 0.6101 TrainAcc 0.7800 TestAcc 0.5288 0.6800
epoch 2300 LossPred 0.5797 LossAtt 0.5813 TrainAcc 0.8300 TestAcc 0.5355 0.6800
epoch 2400 LossPred 0.6057 LossAtt 0.5803 TrainAcc 0.8200 TestAcc 0.5350 0.6950
epoch 2500 LossPred 0.6808 LossAtt 0.5884 TrainAcc 0.7800 TestAcc 0.5333 0.7000
Optimization Finished!
********** replication  52  **********
epoch   0 LossPred 0.9894 LossAtt 1.0398 TrainAcc 0.5400 TestAcc 0.5033 0.5200
epoch 100 LossPred 0.9300 LossAtt 0.5584 TrainAcc 0.6200 TestAcc 0.5768 0.5950
epoch 200 LossPred 0.8850 LossAtt 0.6324 TrainAcc 0.6500 TestAcc 0.5838 0.6350
epoch 300 LossPred 0.8149 LossAtt 0.7365 TrainAcc 0.6700 TestAcc 0.5688 0.6650
epoch 400 LossPred 0.7773 LossAtt 0.7739 TrainAcc 0.6800 TestAcc 0.5571 0.6750
epoch 500 LossPred 0.7390 LossAtt 0.7949 TrainAcc 0.7100 TestAcc 0.5470 0.6800
epoch 600 LossPred 0.7039 LossAtt 0.7538 TrainAcc 0.7200 TestAcc 0.5598 0.7150
epoch 700 LossPred 0.6995 LossAtt 0.7228 TrainAcc 0.7200 TestAcc 0.5573 0.6950
epoch 800 LossPred 0.6838 LossAtt 0.7088 TrainAcc 0.7300 TestAcc 0.5563 0.7200
epoch 900 LossPred 0.6666 LossAtt 0.6920 TrainAcc 0.8000 TestAcc 0.5508 0.7800
epoch 1000 LossPred 0.6563 LossAtt 0.6837 TrainAcc 0.8000 TestAcc 0.5478 0.7500
epoch 1100 LossPred 0.6425 LossAtt 0.7134 TrainAcc 0.8000 TestAcc 0.5470 0.7650
epoch 1200 LossPred 0.6312 LossAtt 0.6686 TrainAcc 0.8200 TestAcc 0.5551 0.7950
epoch 1300 LossPred 0.6613 LossAtt 0.6707 TrainAcc 0.7800 TestAcc 0.5523 0.7900
epoch 1400 LossPred 0.6309 LossAtt 0.6440 TrainAcc 0.8100 TestAcc 0.5553 0.7900
epoch 1500 LossPred 0.6335 LossAtt 0.6608 TrainAcc 0.8200 TestAcc 0.5608 0.7500
epoch 1600 LossPred 0.6130 LossAtt 0.6830 TrainAcc 0.8500 TestAcc 0.5753 0.7950
epoch 1700 LossPred 0.5835 LossAtt 0.6671 TrainAcc 0.8400 TestAcc 0.5653 0.8050
epoch 1800 LossPred 0.5795 LossAtt 0.6628 TrainAcc 0.8400 TestAcc 0.5596 0.7950
epoch 1900 LossPred 0.5714 LossAtt 0.6725 TrainAcc 0.8400 TestAcc 0.5598 0.8000
epoch 2000 LossPred 0.5628 LossAtt 0.6747 TrainAcc 0.8500 TestAcc 0.5696 0.7950
epoch 2100 LossPred 0.5397 LossAtt 0.6634 TrainAcc 0.8600 TestAcc 0.5613 0.7950
epoch 2200 LossPred 0.5484 LossAtt 0.6629 TrainAcc 0.8400 TestAcc 0.5696 0.7800
epoch 2300 LossPred 0.5340 LossAtt 0.6561 TrainAcc 0.8300 TestAcc 0.5646 0.7700
epoch 2400 LossPred 0.5336 LossAtt 0.6787 TrainAcc 0.8600 TestAcc 0.5668 0.7750
epoch 2500 LossPred 0.5382 LossAtt 0.6597 TrainAcc 0.8600 TestAcc 0.5636 0.7600
Optimization Finished!
********** replication  53  **********
epoch   0 LossPred 1.1750 LossAtt 1.0190 TrainAcc 0.4100 TestAcc 0.4735 0.3950
epoch 100 LossPred 0.9422 LossAtt 0.5710 TrainAcc 0.5800 TestAcc 0.5668 0.5850
epoch 200 LossPred 0.9023 LossAtt 0.5432 TrainAcc 0.6700 TestAcc 0.5973 0.6650
epoch 300 LossPred 0.8949 LossAtt 0.4749 TrainAcc 0.6400 TestAcc 0.5616 0.6450
epoch 400 LossPred 0.8898 LossAtt 0.3753 TrainAcc 0.6700 TestAcc 0.5973 0.6450
epoch 500 LossPred 0.8877 LossAtt 0.3395 TrainAcc 0.6600 TestAcc 0.6079 0.6550
epoch 600 LossPred 0.8877 LossAtt 0.3096 TrainAcc 0.6600 TestAcc 0.6079 0.6550
epoch 700 LossPred 0.8892 LossAtt 0.3925 TrainAcc 0.6600 TestAcc 0.6079 0.6600
epoch 800 LossPred 0.8944 LossAtt 0.4793 TrainAcc 0.6600 TestAcc 0.6079 0.6600
epoch 900 LossPred 0.8899 LossAtt 0.3683 TrainAcc 0.6600 TestAcc 0.6079 0.6600
epoch 1000 LossPred 0.8982 LossAtt 0.4139 TrainAcc 0.6600 TestAcc 0.6079 0.6650
epoch 1100 LossPred 0.8636 LossAtt 0.5074 TrainAcc 0.6700 TestAcc 0.5916 0.6650
epoch 1200 LossPred 0.8403 LossAtt 0.5060 TrainAcc 0.6900 TestAcc 0.5918 0.6750
epoch 1300 LossPred 0.8228 LossAtt 0.5745 TrainAcc 0.6900 TestAcc 0.5763 0.6800
epoch 1400 LossPred 0.7345 LossAtt 0.6620 TrainAcc 0.7900 TestAcc 0.5686 0.7050
epoch 1500 LossPred 0.6801 LossAtt 0.6308 TrainAcc 0.7800 TestAcc 0.5673 0.7200
epoch 1600 LossPred 0.6759 LossAtt 0.6217 TrainAcc 0.7900 TestAcc 0.5676 0.7000
epoch 1700 LossPred 0.6877 LossAtt 0.6161 TrainAcc 0.7600 TestAcc 0.5756 0.7000
epoch 1800 LossPred 0.7270 LossAtt 0.6506 TrainAcc 0.7200 TestAcc 0.5808 0.7150
epoch 1900 LossPred 0.7493 LossAtt 0.5918 TrainAcc 0.7300 TestAcc 0.5801 0.6950
epoch 2000 LossPred 0.7761 LossAtt 0.5789 TrainAcc 0.7200 TestAcc 0.5813 0.6750
epoch 2100 LossPred 0.8090 LossAtt 0.5364 TrainAcc 0.6800 TestAcc 0.5941 0.6700
epoch 2200 LossPred 0.7966 LossAtt 0.5406 TrainAcc 0.6900 TestAcc 0.5926 0.6650
epoch 2300 LossPred 0.7933 LossAtt 0.5292 TrainAcc 0.6800 TestAcc 0.5923 0.6600
epoch 2400 LossPred 0.7971 LossAtt 0.5409 TrainAcc 0.7100 TestAcc 0.5881 0.6800
epoch 2500 LossPred 0.7919 LossAtt 0.5192 TrainAcc 0.6900 TestAcc 0.5903 0.6900
Optimization Finished!
********** replication  54  **********
epoch   0 LossPred 1.0142 LossAtt 1.0018 TrainAcc 0.4800 TestAcc 0.4622 0.4700
epoch 100 LossPred 0.9622 LossAtt 0.2480 TrainAcc 0.5700 TestAcc 0.5796 0.5700
epoch 200 LossPred 0.9577 LossAtt 0.1255 TrainAcc 0.5800 TestAcc 0.5573 0.5900
epoch 300 LossPred 0.9575 LossAtt 0.0776 TrainAcc 0.5700 TestAcc 0.5796 0.6100
epoch 400 LossPred 0.9638 LossAtt 0.1136 TrainAcc 0.5700 TestAcc 0.5796 0.5700
epoch 500 LossPred 0.9648 LossAtt 0.1349 TrainAcc 0.5700 TestAcc 0.5796 0.5700
epoch 600 LossPred 0.9646 LossAtt 0.1178 TrainAcc 0.5700 TestAcc 0.5796 0.5700
epoch 700 LossPred 0.9644 LossAtt 0.1503 TrainAcc 0.5700 TestAcc 0.5796 0.5700
epoch 800 LossPred 0.9654 LossAtt 0.1483 TrainAcc 0.5700 TestAcc 0.5796 0.5700
epoch 900 LossPred 0.9673 LossAtt 0.1382 TrainAcc 0.5700 TestAcc 0.5796 0.5700
epoch 1000 LossPred 0.9744 LossAtt 0.1672 TrainAcc 0.5700 TestAcc 0.5796 0.5700
epoch 1100 LossPred 0.9809 LossAtt 0.2112 TrainAcc 0.5700 TestAcc 0.5796 0.5700
epoch 1200 LossPred 0.9808 LossAtt 0.1720 TrainAcc 0.5700 TestAcc 0.5796 0.5700
epoch 1300 LossPred 0.9804 LossAtt 0.1753 TrainAcc 0.5700 TestAcc 0.5796 0.5700
epoch 1400 LossPred 0.9790 LossAtt 0.1841 TrainAcc 0.5700 TestAcc 0.5796 0.5700
epoch 1500 LossPred 0.9774 LossAtt 0.2320 TrainAcc 0.5700 TestAcc 0.5796 0.5700
epoch 1600 LossPred 0.9396 LossAtt 0.4951 TrainAcc 0.6400 TestAcc 0.6031 0.6350
epoch 1700 LossPred 1.0276 LossAtt 0.6556 TrainAcc 0.5800 TestAcc 0.5573 0.5900
epoch 1800 LossPred 0.9221 LossAtt 0.4399 TrainAcc 0.5800 TestAcc 0.5573 0.5800
epoch 1900 LossPred 0.9028 LossAtt 0.4265 TrainAcc 0.5800 TestAcc 0.5573 0.5800
epoch 2000 LossPred 0.8568 LossAtt 0.4847 TrainAcc 0.5800 TestAcc 0.5573 0.6000
epoch 2100 LossPred 0.6834 LossAtt 0.5826 TrainAcc 0.7700 TestAcc 0.6962 0.7450
epoch 2200 LossPred 0.7240 LossAtt 0.5867 TrainAcc 0.7800 TestAcc 0.7180 0.7550
epoch 2300 LossPred 0.5925 LossAtt 0.5798 TrainAcc 0.7600 TestAcc 0.7090 0.7900
epoch 2400 LossPred 0.5447 LossAtt 0.5276 TrainAcc 0.8200 TestAcc 0.7457 0.8150
epoch 2500 LossPred 0.5808 LossAtt 0.5344 TrainAcc 0.8300 TestAcc 0.7528 0.8000
Optimization Finished!
********** replication  55  **********
epoch   0 LossPred 1.1039 LossAtt 1.0115 TrainAcc 0.3600 TestAcc 0.4187 0.3600
epoch 100 LossPred 0.9036 LossAtt 0.3360 TrainAcc 0.6400 TestAcc 0.5813 0.6400
epoch 200 LossPred 0.9038 LossAtt 0.2033 TrainAcc 0.6400 TestAcc 0.5813 0.6400
epoch 300 LossPred 0.9036 LossAtt 0.1334 TrainAcc 0.6400 TestAcc 0.5813 0.6400
epoch 400 LossPred 0.9058 LossAtt 0.1062 TrainAcc 0.6400 TestAcc 0.5813 0.6400
epoch 500 LossPred 0.9173 LossAtt 0.0973 TrainAcc 0.6400 TestAcc 0.5813 0.6400
epoch 600 LossPred 0.9470 LossAtt 0.1358 TrainAcc 0.5600 TestAcc 0.5763 0.5600
epoch 700 LossPred 0.9481 LossAtt 0.1349 TrainAcc 0.5600 TestAcc 0.5763 0.5600
epoch 800 LossPred 0.9388 LossAtt 0.0862 TrainAcc 0.5600 TestAcc 0.5763 0.5600
epoch 900 LossPred 0.9452 LossAtt 0.0843 TrainAcc 0.5600 TestAcc 0.5763 0.5600
epoch 1000 LossPred 0.9496 LossAtt 0.0960 TrainAcc 0.5600 TestAcc 0.5763 0.5600
epoch 1100 LossPred 0.9451 LossAtt 0.1192 TrainAcc 0.5600 TestAcc 0.5763 0.5600
epoch 1200 LossPred 0.9240 LossAtt 0.1168 TrainAcc 0.6400 TestAcc 0.5813 0.6400
epoch 1300 LossPred 0.9165 LossAtt 0.1336 TrainAcc 0.6400 TestAcc 0.5813 0.6400
epoch 1400 LossPred 0.9181 LossAtt 0.2275 TrainAcc 0.6400 TestAcc 0.5813 0.6400
epoch 1500 LossPred 0.9011 LossAtt 0.3420 TrainAcc 0.6400 TestAcc 0.5813 0.6400
epoch 1600 LossPred 0.9095 LossAtt 0.3657 TrainAcc 0.6200 TestAcc 0.6261 0.6400
epoch 1700 LossPred 0.5336 LossAtt 0.3732 TrainAcc 0.8300 TestAcc 0.8148 0.8400
epoch 1800 LossPred 0.6410 LossAtt 0.3561 TrainAcc 0.7800 TestAcc 0.7490 0.7600
epoch 1900 LossPred 0.4511 LossAtt 0.3267 TrainAcc 0.8500 TestAcc 0.8123 0.8550
epoch 2000 LossPred 0.4110 LossAtt 0.3076 TrainAcc 0.8500 TestAcc 0.8496 0.8500
epoch 2100 LossPred 0.3926 LossAtt 0.3086 TrainAcc 0.8600 TestAcc 0.8531 0.8800
epoch 2200 LossPred 0.4174 LossAtt 0.3214 TrainAcc 0.8600 TestAcc 0.8241 0.8600
epoch 2300 LossPred 0.3719 LossAtt 0.3398 TrainAcc 0.8800 TestAcc 0.8536 0.8700
epoch 2400 LossPred 0.3285 LossAtt 0.3925 TrainAcc 0.8900 TestAcc 0.8579 0.9050
epoch 2500 LossPred 0.3103 LossAtt 0.4181 TrainAcc 0.8900 TestAcc 0.8724 0.9000
Optimization Finished!
********** replication  56  **********
epoch   0 LossPred 1.0609 LossAtt 1.0159 TrainAcc 0.5200 TestAcc 0.5265 0.5400
epoch 100 LossPred 0.8761 LossAtt 0.3336 TrainAcc 0.6600 TestAcc 0.5666 0.6600
epoch 200 LossPred 0.8591 LossAtt 0.1890 TrainAcc 0.6600 TestAcc 0.5666 0.6600
epoch 300 LossPred 0.8559 LossAtt 0.1358 TrainAcc 0.6600 TestAcc 0.5666 0.6600
epoch 400 LossPred 0.8545 LossAtt 0.1121 TrainAcc 0.6600 TestAcc 0.5666 0.6600
epoch 500 LossPred 0.8536 LossAtt 0.1110 TrainAcc 0.6600 TestAcc 0.5666 0.6600
epoch 600 LossPred 0.8529 LossAtt 0.1290 TrainAcc 0.6600 TestAcc 0.5666 0.6600
epoch 700 LossPred 0.8524 LossAtt 0.1421 TrainAcc 0.6600 TestAcc 0.5666 0.6600
epoch 800 LossPred 0.8522 LossAtt 0.1467 TrainAcc 0.6600 TestAcc 0.5666 0.6600
epoch 900 LossPred 0.8522 LossAtt 0.1397 TrainAcc 0.6600 TestAcc 0.5666 0.6600
epoch 1000 LossPred 0.8522 LossAtt 0.1364 TrainAcc 0.6600 TestAcc 0.5666 0.6600
epoch 1100 LossPred 0.8522 LossAtt 0.1481 TrainAcc 0.6600 TestAcc 0.5666 0.6600
epoch 1200 LossPred 0.8521 LossAtt 0.1548 TrainAcc 0.6600 TestAcc 0.5666 0.6600
epoch 1300 LossPred 0.8521 LossAtt 0.1720 TrainAcc 0.6600 TestAcc 0.5666 0.6600
epoch 1400 LossPred 0.8521 LossAtt 0.1772 TrainAcc 0.6600 TestAcc 0.5666 0.6600
epoch 1500 LossPred 0.8520 LossAtt 0.1693 TrainAcc 0.6600 TestAcc 0.5666 0.6600
epoch 1600 LossPred 0.8519 LossAtt 0.1662 TrainAcc 0.6600 TestAcc 0.5666 0.6600
epoch 1700 LossPred 0.8518 LossAtt 0.1612 TrainAcc 0.6600 TestAcc 0.5666 0.6600
epoch 1800 LossPred 0.8517 LossAtt 0.1631 TrainAcc 0.6600 TestAcc 0.5666 0.6600
epoch 1900 LossPred 0.8515 LossAtt 0.1701 TrainAcc 0.6600 TestAcc 0.5666 0.6600
epoch 2000 LossPred 0.8515 LossAtt 0.1692 TrainAcc 0.6600 TestAcc 0.5666 0.6600
epoch 2100 LossPred 0.8515 LossAtt 0.1405 TrainAcc 0.6600 TestAcc 0.5666 0.6600
epoch 2200 LossPred 0.8515 LossAtt 0.1149 TrainAcc 0.6600 TestAcc 0.5666 0.6600
epoch 2300 LossPred 0.8517 LossAtt 0.1042 TrainAcc 0.6600 TestAcc 0.5666 0.6600
epoch 2400 LossPred 0.8519 LossAtt 0.1040 TrainAcc 0.6600 TestAcc 0.5666 0.6600
epoch 2500 LossPred 0.8522 LossAtt 0.1083 TrainAcc 0.6600 TestAcc 0.5666 0.6600
Optimization Finished!
********** replication  57  **********
epoch   0 LossPred 1.0266 LossAtt 1.0294 TrainAcc 0.5000 TestAcc 0.5410 0.5550
epoch 100 LossPred 0.9542 LossAtt 0.4566 TrainAcc 0.5800 TestAcc 0.5360 0.5750
epoch 200 LossPred 0.8899 LossAtt 0.4320 TrainAcc 0.6400 TestAcc 0.5048 0.6250
epoch 300 LossPred 0.8810 LossAtt 0.5236 TrainAcc 0.6400 TestAcc 0.5038 0.6500
epoch 400 LossPred 0.7768 LossAtt 0.5924 TrainAcc 0.6900 TestAcc 0.5133 0.6900
epoch 500 LossPred 0.5077 LossAtt 0.7062 TrainAcc 0.8200 TestAcc 0.6839 0.8250
epoch 600 LossPred 0.3240 LossAtt 0.6397 TrainAcc 0.9100 TestAcc 0.7545 0.8550
epoch 700 LossPred 0.2708 LossAtt 0.6211 TrainAcc 0.9200 TestAcc 0.7640 0.8800
epoch 800 LossPred 0.2419 LossAtt 0.6051 TrainAcc 0.9300 TestAcc 0.7523 0.8750
epoch 900 LossPred 0.5513 LossAtt 0.6340 TrainAcc 0.8000 TestAcc 0.6569 0.8000
epoch 1000 LossPred 0.3001 LossAtt 0.5916 TrainAcc 0.9100 TestAcc 0.7670 0.8750
epoch 1100 LossPred 0.6249 LossAtt 0.5941 TrainAcc 0.7800 TestAcc 0.5908 0.7500
epoch 1200 LossPred 0.5523 LossAtt 0.5845 TrainAcc 0.8200 TestAcc 0.6176 0.7950
epoch 1300 LossPred 0.5045 LossAtt 0.5847 TrainAcc 0.8100 TestAcc 0.6677 0.8150
epoch 1400 LossPred 0.3068 LossAtt 0.5734 TrainAcc 0.9000 TestAcc 0.7460 0.8750
epoch 1500 LossPred 0.3048 LossAtt 0.5880 TrainAcc 0.9100 TestAcc 0.7250 0.8400
epoch 1600 LossPred 0.2857 LossAtt 0.5650 TrainAcc 0.9000 TestAcc 0.7245 0.8700
epoch 1700 LossPred 0.2369 LossAtt 0.5486 TrainAcc 0.9300 TestAcc 0.7320 0.9000
epoch 1800 LossPred 0.2529 LossAtt 0.5436 TrainAcc 0.9300 TestAcc 0.7503 0.8900
epoch 1900 LossPred 0.2679 LossAtt 0.5504 TrainAcc 0.9200 TestAcc 0.7500 0.8850
epoch 2000 LossPred 0.2162 LossAtt 0.5292 TrainAcc 0.9300 TestAcc 0.7472 0.9050
epoch 2100 LossPred 0.2161 LossAtt 0.5306 TrainAcc 0.9500 TestAcc 0.7337 0.9150
epoch 2200 LossPred 0.2101 LossAtt 0.5264 TrainAcc 0.9400 TestAcc 0.7382 0.8950
epoch 2300 LossPred 0.2089 LossAtt 0.5360 TrainAcc 0.9500 TestAcc 0.7435 0.9050
epoch 2400 LossPred 0.2370 LossAtt 0.5202 TrainAcc 0.9400 TestAcc 0.7540 0.8900
epoch 2500 LossPred 0.2089 LossAtt 0.5262 TrainAcc 0.9400 TestAcc 0.7360 0.9050
Optimization Finished!
********** replication  58  **********
epoch   0 LossPred 1.1115 LossAtt 1.0080 TrainAcc 0.4700 TestAcc 0.5373 0.4800
epoch 100 LossPred 0.9842 LossAtt 0.4344 TrainAcc 0.5000 TestAcc 0.5313 0.5200
epoch 200 LossPred 0.9429 LossAtt 0.4552 TrainAcc 0.5700 TestAcc 0.5966 0.5500
epoch 300 LossPred 0.8109 LossAtt 0.5161 TrainAcc 0.7200 TestAcc 0.6957 0.7250
epoch 400 LossPred 0.6621 LossAtt 0.5257 TrainAcc 0.7600 TestAcc 0.7312 0.7800
epoch 500 LossPred 0.4779 LossAtt 0.5117 TrainAcc 0.8500 TestAcc 0.8063 0.8250
epoch 600 LossPred 0.4928 LossAtt 0.4693 TrainAcc 0.8600 TestAcc 0.8173 0.8500
epoch 700 LossPred 0.4005 LossAtt 0.4705 TrainAcc 0.9000 TestAcc 0.8631 0.8500
epoch 800 LossPred 0.3362 LossAtt 0.4734 TrainAcc 0.9200 TestAcc 0.8604 0.8850
epoch 900 LossPred 0.3170 LossAtt 0.4781 TrainAcc 0.9200 TestAcc 0.8626 0.8700
epoch 1000 LossPred 0.3321 LossAtt 0.4511 TrainAcc 0.9000 TestAcc 0.8554 0.8750
epoch 1100 LossPred 0.3218 LossAtt 0.4412 TrainAcc 0.9100 TestAcc 0.8766 0.8800
epoch 1200 LossPred 0.2791 LossAtt 0.4360 TrainAcc 0.9300 TestAcc 0.8676 0.8800
epoch 1300 LossPred 0.2970 LossAtt 0.4282 TrainAcc 0.9000 TestAcc 0.8751 0.9050
epoch 1400 LossPred 0.3389 LossAtt 0.4317 TrainAcc 0.9100 TestAcc 0.8509 0.9000
epoch 1500 LossPred 0.2614 LossAtt 0.4303 TrainAcc 0.9300 TestAcc 0.8741 0.8800
epoch 1600 LossPred 0.2684 LossAtt 0.4257 TrainAcc 0.9200 TestAcc 0.8786 0.9000
epoch 1700 LossPred 0.2641 LossAtt 0.4511 TrainAcc 0.9300 TestAcc 0.8754 0.8750
epoch 1800 LossPred 0.2429 LossAtt 0.4297 TrainAcc 0.9300 TestAcc 0.8786 0.9050
epoch 1900 LossPred 0.2564 LossAtt 0.4344 TrainAcc 0.9400 TestAcc 0.8719 0.8950
epoch 2000 LossPred 0.2397 LossAtt 0.4258 TrainAcc 0.9300 TestAcc 0.8854 0.8900
epoch 2100 LossPred 0.2396 LossAtt 0.4391 TrainAcc 0.9300 TestAcc 0.8761 0.9100
epoch 2200 LossPred 0.2483 LossAtt 0.4585 TrainAcc 0.9400 TestAcc 0.8734 0.8700
epoch 2300 LossPred 0.2084 LossAtt 0.4505 TrainAcc 0.9500 TestAcc 0.8816 0.9150
epoch 2400 LossPred 0.2476 LossAtt 0.4654 TrainAcc 0.9300 TestAcc 0.8806 0.8950
epoch 2500 LossPred 0.2342 LossAtt 0.4670 TrainAcc 0.9300 TestAcc 0.8731 0.9100
Optimization Finished!
********** replication  59  **********
epoch   0 LossPred 1.1919 LossAtt 1.0050 TrainAcc 0.4700 TestAcc 0.5268 0.4300
epoch 100 LossPred 0.8925 LossAtt 0.4284 TrainAcc 0.7000 TestAcc 0.5703 0.7000
epoch 200 LossPred 0.8477 LossAtt 0.3768 TrainAcc 0.7000 TestAcc 0.5703 0.7000
epoch 300 LossPred 0.8419 LossAtt 0.2786 TrainAcc 0.7000 TestAcc 0.5703 0.7000
epoch 400 LossPred 0.8398 LossAtt 0.1852 TrainAcc 0.7000 TestAcc 0.5703 0.7000
epoch 500 LossPred 0.8387 LossAtt 0.1543 TrainAcc 0.7000 TestAcc 0.5703 0.7000
epoch 600 LossPred 0.8376 LossAtt 0.1846 TrainAcc 0.7000 TestAcc 0.5703 0.7000
epoch 700 LossPred 0.8364 LossAtt 0.1508 TrainAcc 0.7000 TestAcc 0.5703 0.7000
epoch 800 LossPred 0.8237 LossAtt 0.2790 TrainAcc 0.7000 TestAcc 0.5703 0.7000
epoch 900 LossPred 0.5624 LossAtt 0.6197 TrainAcc 0.8000 TestAcc 0.7723 0.8000
epoch 1000 LossPred 0.3623 LossAtt 0.5337 TrainAcc 0.8700 TestAcc 0.8246 0.8650
epoch 1100 LossPred 0.3184 LossAtt 0.5264 TrainAcc 0.9000 TestAcc 0.8441 0.9000
epoch 1200 LossPred 0.2582 LossAtt 0.5278 TrainAcc 0.9200 TestAcc 0.8614 0.8950
epoch 1300 LossPred 0.2807 LossAtt 0.5373 TrainAcc 0.9100 TestAcc 0.8519 0.9000
epoch 1400 LossPred 0.3059 LossAtt 0.5265 TrainAcc 0.9000 TestAcc 0.8431 0.8850
epoch 1500 LossPred 0.2132 LossAtt 0.4970 TrainAcc 0.9300 TestAcc 0.8734 0.9050
epoch 1600 LossPred 0.1906 LossAtt 0.5078 TrainAcc 0.9400 TestAcc 0.8774 0.9100
epoch 1700 LossPred 0.1899 LossAtt 0.4864 TrainAcc 0.9400 TestAcc 0.8821 0.9250
epoch 1800 LossPred 0.2662 LossAtt 0.4906 TrainAcc 0.9100 TestAcc 0.8579 0.8850
epoch 1900 LossPred 0.1797 LossAtt 0.4905 TrainAcc 0.9500 TestAcc 0.8761 0.9150
epoch 2000 LossPred 0.2283 LossAtt 0.5124 TrainAcc 0.9300 TestAcc 0.8686 0.9100
epoch 2100 LossPred 0.1905 LossAtt 0.5075 TrainAcc 0.9400 TestAcc 0.8814 0.9100
epoch 2200 LossPred 0.1653 LossAtt 0.5125 TrainAcc 0.9500 TestAcc 0.8876 0.9300
epoch 2300 LossPred 0.1899 LossAtt 0.5182 TrainAcc 0.9400 TestAcc 0.8834 0.9000
epoch 2400 LossPred 0.1927 LossAtt 0.5148 TrainAcc 0.9500 TestAcc 0.8811 0.9100
epoch 2500 LossPred 0.1557 LossAtt 0.5087 TrainAcc 0.9500 TestAcc 0.8981 0.9100
Optimization Finished!
********** replication  60  **********
epoch   0 LossPred 0.9975 LossAtt 1.0034 TrainAcc 0.5100 TestAcc 0.5651 0.5050
epoch 100 LossPred 0.9125 LossAtt 0.5726 TrainAcc 0.6300 TestAcc 0.5931 0.6100
epoch 200 LossPred 0.7955 LossAtt 0.6183 TrainAcc 0.7200 TestAcc 0.6722 0.6900
epoch 300 LossPred 0.5710 LossAtt 0.6040 TrainAcc 0.8300 TestAcc 0.7553 0.8100
epoch 400 LossPred 0.5375 LossAtt 0.5398 TrainAcc 0.8300 TestAcc 0.7715 0.8200
epoch 500 LossPred 0.5694 LossAtt 0.5399 TrainAcc 0.8200 TestAcc 0.7878 0.8200
epoch 600 LossPred 0.5912 LossAtt 0.5292 TrainAcc 0.8100 TestAcc 0.7855 0.8450
epoch 700 LossPred 0.8315 LossAtt 0.4927 TrainAcc 0.6500 TestAcc 0.5953 0.6550
epoch 800 LossPred 0.5626 LossAtt 0.5035 TrainAcc 0.8200 TestAcc 0.7440 0.8000
epoch 900 LossPred 0.5432 LossAtt 0.4985 TrainAcc 0.8300 TestAcc 0.7793 0.8100
epoch 1000 LossPred 0.5126 LossAtt 0.4811 TrainAcc 0.8400 TestAcc 0.7623 0.7800
epoch 1100 LossPred 0.5163 LossAtt 0.5120 TrainAcc 0.8300 TestAcc 0.7583 0.8000
epoch 1200 LossPred 0.6406 LossAtt 0.4763 TrainAcc 0.8000 TestAcc 0.7508 0.7950
epoch 1300 LossPred 0.5124 LossAtt 0.4340 TrainAcc 0.8400 TestAcc 0.7633 0.8000
epoch 1400 LossPred 0.4500 LossAtt 0.4515 TrainAcc 0.8500 TestAcc 0.7615 0.8250
epoch 1500 LossPred 0.4845 LossAtt 0.4312 TrainAcc 0.8300 TestAcc 0.7508 0.8150
epoch 1600 LossPred 0.4980 LossAtt 0.4347 TrainAcc 0.8500 TestAcc 0.7698 0.8150
epoch 1700 LossPred 0.5527 LossAtt 0.4261 TrainAcc 0.7900 TestAcc 0.7265 0.7650
epoch 1800 LossPred 0.5181 LossAtt 0.4100 TrainAcc 0.8400 TestAcc 0.7770 0.8300
epoch 1900 LossPred 0.4617 LossAtt 0.4100 TrainAcc 0.8600 TestAcc 0.7508 0.8150
epoch 2000 LossPred 0.9477 LossAtt 0.3054 TrainAcc 0.5900 TestAcc 0.5891 0.5950
epoch 2100 LossPred 0.9483 LossAtt 0.2877 TrainAcc 0.5900 TestAcc 0.5898 0.5950
epoch 2200 LossPred 0.9502 LossAtt 0.2792 TrainAcc 0.5900 TestAcc 0.5866 0.5950
epoch 2300 LossPred 0.9507 LossAtt 0.2472 TrainAcc 0.5900 TestAcc 0.5873 0.5950
epoch 2400 LossPred 0.9491 LossAtt 0.2469 TrainAcc 0.5900 TestAcc 0.5886 0.5950
epoch 2500 LossPred 0.9574 LossAtt 0.2465 TrainAcc 0.5900 TestAcc 0.5871 0.5950
Optimization Finished!
********** replication  61  **********
epoch   0 LossPred 1.0924 LossAtt 1.0331 TrainAcc 0.4800 TestAcc 0.4792 0.4850
epoch 100 LossPred 0.9429 LossAtt 0.3871 TrainAcc 0.5900 TestAcc 0.5671 0.5850
epoch 200 LossPred 0.9277 LossAtt 0.3218 TrainAcc 0.5900 TestAcc 0.5671 0.6100
epoch 300 LossPred 0.9192 LossAtt 0.2713 TrainAcc 0.5900 TestAcc 0.5671 0.6100
epoch 400 LossPred 0.9128 LossAtt 0.2005 TrainAcc 0.5900 TestAcc 0.5671 0.6250
epoch 500 LossPred 0.9101 LossAtt 0.2001 TrainAcc 0.6500 TestAcc 0.6059 0.6350
epoch 600 LossPred 0.9038 LossAtt 0.1964 TrainAcc 0.6300 TestAcc 0.6039 0.6300
epoch 700 LossPred 0.8460 LossAtt 0.4124 TrainAcc 0.6300 TestAcc 0.6156 0.6350
epoch 800 LossPred 0.6406 LossAtt 0.4595 TrainAcc 0.7500 TestAcc 0.7840 0.7650
epoch 900 LossPred 0.5401 LossAtt 0.4347 TrainAcc 0.8200 TestAcc 0.8313 0.8300
epoch 1000 LossPred 0.5874 LossAtt 0.4371 TrainAcc 0.7800 TestAcc 0.8241 0.7850
epoch 1100 LossPred 0.5290 LossAtt 0.4469 TrainAcc 0.8400 TestAcc 0.8416 0.8300
epoch 1200 LossPred 0.6496 LossAtt 0.4888 TrainAcc 0.7900 TestAcc 0.8053 0.7900
epoch 1300 LossPred 0.6546 LossAtt 0.4516 TrainAcc 0.7600 TestAcc 0.7993 0.8000
epoch 1400 LossPred 0.5618 LossAtt 0.4531 TrainAcc 0.8000 TestAcc 0.8534 0.8050
epoch 1500 LossPred 0.5172 LossAtt 0.4630 TrainAcc 0.8100 TestAcc 0.8438 0.8100
epoch 1600 LossPred 0.5405 LossAtt 0.4608 TrainAcc 0.8400 TestAcc 0.8418 0.8250
epoch 1700 LossPred 0.5058 LossAtt 0.4563 TrainAcc 0.8300 TestAcc 0.8531 0.8350
epoch 1800 LossPred 0.6799 LossAtt 0.4651 TrainAcc 0.7300 TestAcc 0.7713 0.7200
epoch 1900 LossPred 0.4712 LossAtt 0.5007 TrainAcc 0.8500 TestAcc 0.8631 0.8400
epoch 2000 LossPred 0.6036 LossAtt 0.5104 TrainAcc 0.7600 TestAcc 0.8168 0.7650
epoch 2100 LossPred 0.5183 LossAtt 0.5083 TrainAcc 0.8200 TestAcc 0.8266 0.8050
epoch 2200 LossPred 0.4822 LossAtt 0.5341 TrainAcc 0.8300 TestAcc 0.8448 0.8300
epoch 2300 LossPred 0.5318 LossAtt 0.5130 TrainAcc 0.8000 TestAcc 0.8181 0.8200
epoch 2400 LossPred 0.4242 LossAtt 0.5046 TrainAcc 0.8600 TestAcc 0.8506 0.8250
epoch 2500 LossPred 0.4625 LossAtt 0.5039 TrainAcc 0.8300 TestAcc 0.8498 0.8550
Optimization Finished!
********** replication  62  **********
epoch   0 LossPred 1.0969 LossAtt 1.1123 TrainAcc 0.5200 TestAcc 0.4717 0.5450
epoch 100 LossPred 0.8652 LossAtt 0.6113 TrainAcc 0.7100 TestAcc 0.5746 0.7100
epoch 200 LossPred 0.8076 LossAtt 0.5415 TrainAcc 0.7100 TestAcc 0.5746 0.7100
epoch 300 LossPred 0.7482 LossAtt 0.5707 TrainAcc 0.7300 TestAcc 0.5898 0.7300
epoch 400 LossPred 0.8077 LossAtt 0.6188 TrainAcc 0.6900 TestAcc 0.6794 0.7100
epoch 500 LossPred 0.3440 LossAtt 0.6535 TrainAcc 0.8700 TestAcc 0.8584 0.8700
epoch 600 LossPred 0.2821 LossAtt 0.6116 TrainAcc 0.9200 TestAcc 0.8666 0.8800
epoch 700 LossPred 0.3391 LossAtt 0.5937 TrainAcc 0.8900 TestAcc 0.8328 0.8700
epoch 800 LossPred 0.2505 LossAtt 0.5380 TrainAcc 0.9200 TestAcc 0.8689 0.8900
epoch 900 LossPred 0.3517 LossAtt 0.5276 TrainAcc 0.8900 TestAcc 0.8481 0.8800
epoch 1000 LossPred 0.2433 LossAtt 0.5131 TrainAcc 0.9300 TestAcc 0.8759 0.8900
epoch 1100 LossPred 0.2674 LossAtt 0.5069 TrainAcc 0.9000 TestAcc 0.8936 0.8950
epoch 1200 LossPred 0.3206 LossAtt 0.4983 TrainAcc 0.9000 TestAcc 0.8413 0.8450
epoch 1300 LossPred 0.3393 LossAtt 0.4903 TrainAcc 0.8800 TestAcc 0.8661 0.8600
epoch 1400 LossPred 0.2931 LossAtt 0.4556 TrainAcc 0.9000 TestAcc 0.8581 0.8500
epoch 1500 LossPred 0.2477 LossAtt 0.4469 TrainAcc 0.9200 TestAcc 0.8839 0.8500
epoch 1600 LossPred 0.2376 LossAtt 0.4480 TrainAcc 0.9200 TestAcc 0.8911 0.8650
epoch 1700 LossPred 0.3129 LossAtt 0.4442 TrainAcc 0.9000 TestAcc 0.8811 0.8400
epoch 1800 LossPred 0.2803 LossAtt 0.4397 TrainAcc 0.9000 TestAcc 0.8684 0.8700
epoch 1900 LossPred 0.2510 LossAtt 0.4291 TrainAcc 0.9300 TestAcc 0.8944 0.8700
epoch 2000 LossPred 0.1900 LossAtt 0.4390 TrainAcc 0.9600 TestAcc 0.9004 0.8900
epoch 2100 LossPred 0.1770 LossAtt 0.4449 TrainAcc 0.9400 TestAcc 0.9117 0.8950
epoch 2200 LossPred 0.2389 LossAtt 0.4390 TrainAcc 0.9100 TestAcc 0.8854 0.8600
epoch 2300 LossPred 0.2396 LossAtt 0.4543 TrainAcc 0.9400 TestAcc 0.8916 0.8850
epoch 2400 LossPred 0.2154 LossAtt 0.4566 TrainAcc 0.9300 TestAcc 0.8914 0.8650
epoch 2500 LossPred 0.2091 LossAtt 0.4598 TrainAcc 0.9100 TestAcc 0.8984 0.8800
Optimization Finished!
********** replication  63  **********
epoch   0 LossPred 1.0812 LossAtt 1.0198 TrainAcc 0.5000 TestAcc 0.5345 0.4700
epoch 100 LossPred 0.9167 LossAtt 0.3752 TrainAcc 0.6400 TestAcc 0.5896 0.6400
epoch 200 LossPred 0.8926 LossAtt 0.4120 TrainAcc 0.6700 TestAcc 0.5751 0.6350
epoch 300 LossPred 0.8324 LossAtt 0.6131 TrainAcc 0.7100 TestAcc 0.5643 0.7050
epoch 400 LossPred 0.7724 LossAtt 0.6568 TrainAcc 0.7400 TestAcc 0.5933 0.7200
epoch 500 LossPred 0.7173 LossAtt 0.6812 TrainAcc 0.7400 TestAcc 0.6176 0.7150
epoch 600 LossPred 0.5719 LossAtt 0.6329 TrainAcc 0.8100 TestAcc 0.7112 0.7700
epoch 700 LossPred 0.5983 LossAtt 0.6460 TrainAcc 0.7900 TestAcc 0.7270 0.7700
epoch 800 LossPred 0.5114 LossAtt 0.6625 TrainAcc 0.7800 TestAcc 0.7513 0.7750
epoch 900 LossPred 0.4843 LossAtt 0.6395 TrainAcc 0.8400 TestAcc 0.7610 0.7750
epoch 1000 LossPred 0.5289 LossAtt 0.6336 TrainAcc 0.8200 TestAcc 0.7472 0.7950
epoch 1100 LossPred 0.4860 LossAtt 0.6234 TrainAcc 0.8400 TestAcc 0.7352 0.8050
epoch 1200 LossPred 0.4513 LossAtt 0.6147 TrainAcc 0.8500 TestAcc 0.7410 0.8200
epoch 1300 LossPred 0.5419 LossAtt 0.6384 TrainAcc 0.7800 TestAcc 0.7523 0.7700
epoch 1400 LossPred 0.5409 LossAtt 0.6530 TrainAcc 0.7700 TestAcc 0.7503 0.7750
epoch 1500 LossPred 0.5123 LossAtt 0.6330 TrainAcc 0.7900 TestAcc 0.7655 0.8200
epoch 1600 LossPred 0.4692 LossAtt 0.6179 TrainAcc 0.8600 TestAcc 0.7728 0.8300
epoch 1700 LossPred 0.4373 LossAtt 0.6139 TrainAcc 0.8800 TestAcc 0.7815 0.8400
epoch 1800 LossPred 0.5372 LossAtt 0.6105 TrainAcc 0.8300 TestAcc 0.7565 0.7500
epoch 1900 LossPred 0.4179 LossAtt 0.6267 TrainAcc 0.8500 TestAcc 0.7855 0.8400
epoch 2000 LossPred 0.4528 LossAtt 0.6070 TrainAcc 0.8400 TestAcc 0.7788 0.8200
epoch 2100 LossPred 0.4829 LossAtt 0.5791 TrainAcc 0.8400 TestAcc 0.7760 0.7850
epoch 2200 LossPred 0.4464 LossAtt 0.5829 TrainAcc 0.8500 TestAcc 0.7843 0.8250
epoch 2300 LossPred 0.4389 LossAtt 0.5816 TrainAcc 0.8600 TestAcc 0.7708 0.8050
epoch 2400 LossPred 0.3786 LossAtt 0.5608 TrainAcc 0.8900 TestAcc 0.7808 0.8050
epoch 2500 LossPred 0.5469 LossAtt 0.5724 TrainAcc 0.8100 TestAcc 0.7818 0.8300
Optimization Finished!
********** replication  64  **********
epoch   0 LossPred 1.1327 LossAtt 1.0060 TrainAcc 0.4800 TestAcc 0.5233 0.4800
epoch 100 LossPred 0.9851 LossAtt 0.4639 TrainAcc 0.5600 TestAcc 0.5721 0.5450
epoch 200 LossPred 0.9758 LossAtt 0.4726 TrainAcc 0.5800 TestAcc 0.5753 0.5750
epoch 300 LossPred 0.9527 LossAtt 0.5304 TrainAcc 0.5900 TestAcc 0.5898 0.5700
epoch 400 LossPred 0.5565 LossAtt 0.6329 TrainAcc 0.8300 TestAcc 0.7985 0.8200
epoch 500 LossPred 0.5193 LossAtt 0.6074 TrainAcc 0.8300 TestAcc 0.8121 0.8200
epoch 600 LossPred 0.4866 LossAtt 0.6123 TrainAcc 0.8500 TestAcc 0.8363 0.8150
epoch 700 LossPred 0.4950 LossAtt 0.5900 TrainAcc 0.8500 TestAcc 0.8213 0.8150
epoch 800 LossPred 0.5399 LossAtt 0.6050 TrainAcc 0.8300 TestAcc 0.8298 0.8000
epoch 900 LossPred 0.4799 LossAtt 0.5795 TrainAcc 0.8400 TestAcc 0.8123 0.8300
epoch 1000 LossPred 0.4237 LossAtt 0.5776 TrainAcc 0.8600 TestAcc 0.8306 0.8400
epoch 1100 LossPred 0.4199 LossAtt 0.5704 TrainAcc 0.8700 TestAcc 0.8293 0.8400
epoch 1200 LossPred 0.4262 LossAtt 0.5497 TrainAcc 0.8500 TestAcc 0.8206 0.8300
epoch 1300 LossPred 0.4082 LossAtt 0.5654 TrainAcc 0.8600 TestAcc 0.8256 0.8400
epoch 1400 LossPred 0.4060 LossAtt 0.5670 TrainAcc 0.8800 TestAcc 0.8311 0.8450
epoch 1500 LossPred 0.4363 LossAtt 0.5377 TrainAcc 0.8600 TestAcc 0.8306 0.8450
epoch 1600 LossPred 0.4243 LossAtt 0.5366 TrainAcc 0.8700 TestAcc 0.8311 0.8550
epoch 1700 LossPred 0.4166 LossAtt 0.5549 TrainAcc 0.8700 TestAcc 0.8476 0.8450
epoch 1800 LossPred 0.3702 LossAtt 0.5396 TrainAcc 0.8900 TestAcc 0.8328 0.8650
epoch 1900 LossPred 0.3770 LossAtt 0.5321 TrainAcc 0.8900 TestAcc 0.8346 0.8600
epoch 2000 LossPred 0.3884 LossAtt 0.5413 TrainAcc 0.8800 TestAcc 0.8421 0.8650
epoch 2100 LossPred 0.3830 LossAtt 0.5442 TrainAcc 0.8700 TestAcc 0.8241 0.8350
epoch 2200 LossPred 0.3844 LossAtt 0.5428 TrainAcc 0.8800 TestAcc 0.8306 0.8700
epoch 2300 LossPred 0.3703 LossAtt 0.5463 TrainAcc 0.9000 TestAcc 0.8356 0.8750
epoch 2400 LossPred 0.3487 LossAtt 0.5685 TrainAcc 0.8900 TestAcc 0.8328 0.8700
epoch 2500 LossPred 0.3406 LossAtt 0.5488 TrainAcc 0.8800 TestAcc 0.8308 0.8650
Optimization Finished!
********** replication  65  **********
epoch   0 LossPred 1.1181 LossAtt 1.0101 TrainAcc 0.5300 TestAcc 0.4930 0.5450
epoch 100 LossPred 0.9950 LossAtt 0.5410 TrainAcc 0.4800 TestAcc 0.5663 0.4850
epoch 200 LossPred 0.9824 LossAtt 0.4754 TrainAcc 0.5100 TestAcc 0.5578 0.5150
epoch 300 LossPred 0.9756 LossAtt 0.5044 TrainAcc 0.5100 TestAcc 0.5546 0.5250
epoch 400 LossPred 0.9704 LossAtt 0.4875 TrainAcc 0.5300 TestAcc 0.5686 0.5150
epoch 500 LossPred 0.9804 LossAtt 0.4430 TrainAcc 0.5500 TestAcc 0.5653 0.5200
epoch 600 LossPred 0.9787 LossAtt 0.4906 TrainAcc 0.5000 TestAcc 0.5523 0.5150
epoch 700 LossPred 0.9672 LossAtt 0.6029 TrainAcc 0.5200 TestAcc 0.5511 0.5200
epoch 800 LossPred 0.9601 LossAtt 0.5263 TrainAcc 0.5500 TestAcc 0.5375 0.5150
epoch 900 LossPred 0.9490 LossAtt 0.4056 TrainAcc 0.5300 TestAcc 0.5598 0.5300
epoch 1000 LossPred 0.9435 LossAtt 0.3223 TrainAcc 0.5300 TestAcc 0.5516 0.5350
epoch 1100 LossPred 0.9398 LossAtt 0.3046 TrainAcc 0.5500 TestAcc 0.5546 0.5400
epoch 1200 LossPred 0.9361 LossAtt 0.3167 TrainAcc 0.5500 TestAcc 0.5518 0.5500
epoch 1300 LossPred 0.9327 LossAtt 0.3088 TrainAcc 0.5700 TestAcc 0.5233 0.5600
epoch 1400 LossPred 0.9292 LossAtt 0.3026 TrainAcc 0.5700 TestAcc 0.5230 0.5700
epoch 1500 LossPred 0.9246 LossAtt 0.3015 TrainAcc 0.5700 TestAcc 0.5238 0.5500
epoch 1600 LossPred 0.9131 LossAtt 0.3241 TrainAcc 0.5600 TestAcc 0.5240 0.5300
epoch 1700 LossPred 0.8876 LossAtt 0.3535 TrainAcc 0.5700 TestAcc 0.5288 0.5500
epoch 1800 LossPred 0.8775 LossAtt 0.3174 TrainAcc 0.6200 TestAcc 0.5118 0.6050
epoch 1900 LossPred 0.8658 LossAtt 0.3747 TrainAcc 0.6400 TestAcc 0.4775 0.6100
epoch 2000 LossPred 0.8516 LossAtt 0.4150 TrainAcc 0.6400 TestAcc 0.4770 0.6100
epoch 2100 LossPred 0.8362 LossAtt 0.4260 TrainAcc 0.6500 TestAcc 0.4765 0.6200
epoch 2200 LossPred 0.8308 LossAtt 0.4326 TrainAcc 0.6500 TestAcc 0.4782 0.6200
epoch 2300 LossPred 0.8244 LossAtt 0.4137 TrainAcc 0.6600 TestAcc 0.4877 0.6300
epoch 2400 LossPred 0.8142 LossAtt 0.4133 TrainAcc 0.6600 TestAcc 0.4872 0.6300
epoch 2500 LossPred 0.8142 LossAtt 0.4269 TrainAcc 0.6600 TestAcc 0.4957 0.6350
Optimization Finished!
********** replication  66  **********
epoch   0 LossPred 1.1812 LossAtt 1.0263 TrainAcc 0.4700 TestAcc 0.4449 0.4650
epoch 100 LossPred 0.8586 LossAtt 0.3653 TrainAcc 0.6500 TestAcc 0.5738 0.6500
epoch 200 LossPred 0.7310 LossAtt 0.4300 TrainAcc 0.7500 TestAcc 0.6687 0.7350
epoch 300 LossPred 0.5190 LossAtt 0.3891 TrainAcc 0.8500 TestAcc 0.7910 0.8250
epoch 400 LossPred 0.6344 LossAtt 0.3666 TrainAcc 0.7600 TestAcc 0.7673 0.7500
epoch 500 LossPred 0.5046 LossAtt 0.3703 TrainAcc 0.8500 TestAcc 0.7868 0.8200
epoch 600 LossPred 0.4866 LossAtt 0.3632 TrainAcc 0.8400 TestAcc 0.7858 0.8250
epoch 700 LossPred 1.0813 LossAtt 0.3331 TrainAcc 0.5200 TestAcc 0.6249 0.5250
epoch 800 LossPred 0.4807 LossAtt 0.3569 TrainAcc 0.8500 TestAcc 0.7875 0.8350
epoch 900 LossPred 0.5801 LossAtt 0.3533 TrainAcc 0.7900 TestAcc 0.7773 0.7900
epoch 1000 LossPred 0.4513 LossAtt 0.3513 TrainAcc 0.8600 TestAcc 0.7845 0.8150
epoch 1100 LossPred 0.5466 LossAtt 0.3248 TrainAcc 0.7900 TestAcc 0.7720 0.7700
epoch 1200 LossPred 0.8487 LossAtt 0.3415 TrainAcc 0.7300 TestAcc 0.6762 0.7350
epoch 1300 LossPred 0.6691 LossAtt 0.3418 TrainAcc 0.7100 TestAcc 0.7477 0.7450
epoch 1400 LossPred 0.4824 LossAtt 0.3388 TrainAcc 0.8800 TestAcc 0.7728 0.8450
epoch 1500 LossPred 0.5038 LossAtt 0.3424 TrainAcc 0.8200 TestAcc 0.7833 0.8150
epoch 1600 LossPred 0.4901 LossAtt 0.3338 TrainAcc 0.8300 TestAcc 0.7870 0.8350
epoch 1700 LossPred 0.4669 LossAtt 0.3240 TrainAcc 0.8300 TestAcc 0.7795 0.8300
epoch 1800 LossPred 0.4875 LossAtt 0.3255 TrainAcc 0.8300 TestAcc 0.7848 0.8400
epoch 1900 LossPred 0.4892 LossAtt 0.3155 TrainAcc 0.8300 TestAcc 0.7760 0.8350
epoch 2000 LossPred 0.4915 LossAtt 0.3111 TrainAcc 0.8300 TestAcc 0.7828 0.8450
epoch 2100 LossPred 0.7203 LossAtt 0.3208 TrainAcc 0.7900 TestAcc 0.7447 0.8000
epoch 2200 LossPred 0.8451 LossAtt 0.3054 TrainAcc 0.7500 TestAcc 0.6679 0.7400
epoch 2300 LossPred 0.6689 LossAtt 0.3058 TrainAcc 0.7800 TestAcc 0.6982 0.7550
epoch 2400 LossPred 0.6038 LossAtt 0.3084 TrainAcc 0.8000 TestAcc 0.7292 0.7800
epoch 2500 LossPred 0.5628 LossAtt 0.2906 TrainAcc 0.8300 TestAcc 0.7475 0.8250
Optimization Finished!
********** replication  67  **********
epoch   0 LossPred 1.0231 LossAtt 1.0212 TrainAcc 0.4900 TestAcc 0.5133 0.5050
epoch 100 LossPred 0.9023 LossAtt 0.4340 TrainAcc 0.6000 TestAcc 0.5591 0.6000
epoch 200 LossPred 0.8349 LossAtt 0.5679 TrainAcc 0.6800 TestAcc 0.5521 0.6850
epoch 300 LossPred 0.7771 LossAtt 0.5742 TrainAcc 0.6900 TestAcc 0.5876 0.6850
epoch 400 LossPred 0.6168 LossAtt 0.6214 TrainAcc 0.8100 TestAcc 0.7525 0.8000
epoch 500 LossPred 0.4937 LossAtt 0.5773 TrainAcc 0.8300 TestAcc 0.7783 0.8150
epoch 600 LossPred 0.5244 LossAtt 0.5356 TrainAcc 0.8400 TestAcc 0.7660 0.8350
epoch 700 LossPred 0.5023 LossAtt 0.5016 TrainAcc 0.8500 TestAcc 0.7435 0.8250
epoch 800 LossPred 0.4952 LossAtt 0.4781 TrainAcc 0.8600 TestAcc 0.7583 0.8450
epoch 900 LossPred 0.4850 LossAtt 0.4821 TrainAcc 0.8600 TestAcc 0.7623 0.8500
epoch 1000 LossPred 0.4812 LossAtt 0.4777 TrainAcc 0.8600 TestAcc 0.7655 0.8400
epoch 1100 LossPred 0.4829 LossAtt 0.4603 TrainAcc 0.8600 TestAcc 0.7645 0.8350
epoch 1200 LossPred 0.4732 LossAtt 0.4591 TrainAcc 0.8600 TestAcc 0.7728 0.8300
epoch 1300 LossPred 0.4719 LossAtt 0.4728 TrainAcc 0.8600 TestAcc 0.7698 0.8350
epoch 1400 LossPred 0.4700 LossAtt 0.4747 TrainAcc 0.8500 TestAcc 0.7758 0.8400
epoch 1500 LossPred 0.4665 LossAtt 0.4499 TrainAcc 0.8500 TestAcc 0.7763 0.8450
epoch 1600 LossPred 0.4592 LossAtt 0.4647 TrainAcc 0.8500 TestAcc 0.7888 0.8500
epoch 1700 LossPred 0.3273 LossAtt 0.4274 TrainAcc 0.9000 TestAcc 0.8063 0.8700
epoch 1800 LossPred 0.3183 LossAtt 0.4361 TrainAcc 0.9000 TestAcc 0.8106 0.8750
epoch 1900 LossPred 0.3369 LossAtt 0.4377 TrainAcc 0.8800 TestAcc 0.8176 0.8800
epoch 2000 LossPred 0.2767 LossAtt 0.4633 TrainAcc 0.9100 TestAcc 0.7953 0.9000
epoch 2100 LossPred 0.2575 LossAtt 0.4588 TrainAcc 0.9200 TestAcc 0.8103 0.9050
epoch 2200 LossPred 0.2602 LossAtt 0.4636 TrainAcc 0.9200 TestAcc 0.8153 0.9050
epoch 2300 LossPred 0.2590 LossAtt 0.4678 TrainAcc 0.9300 TestAcc 0.8081 0.9200
epoch 2400 LossPred 0.3703 LossAtt 0.4556 TrainAcc 0.8900 TestAcc 0.8176 0.8800
epoch 2500 LossPred 0.2581 LossAtt 0.4626 TrainAcc 0.9200 TestAcc 0.8108 0.9150
Optimization Finished!
********** replication  68  **********
epoch   0 LossPred 1.0169 LossAtt 1.0034 TrainAcc 0.5300 TestAcc 0.5708 0.5350
epoch 100 LossPred 0.8052 LossAtt 0.6162 TrainAcc 0.7000 TestAcc 0.5651 0.7000
epoch 200 LossPred 0.7680 LossAtt 0.5026 TrainAcc 0.7000 TestAcc 0.5651 0.7000
epoch 300 LossPred 0.7573 LossAtt 0.4285 TrainAcc 0.7000 TestAcc 0.5651 0.7000
epoch 400 LossPred 0.7505 LossAtt 0.3449 TrainAcc 0.7000 TestAcc 0.5651 0.7000
epoch 500 LossPred 0.7425 LossAtt 0.4110 TrainAcc 0.7100 TestAcc 0.5501 0.7150
epoch 600 LossPred 0.7464 LossAtt 0.4239 TrainAcc 0.7200 TestAcc 0.5423 0.7150
epoch 700 LossPred 0.7396 LossAtt 0.4826 TrainAcc 0.7200 TestAcc 0.5428 0.7200
epoch 800 LossPred 0.7278 LossAtt 0.5346 TrainAcc 0.7100 TestAcc 0.5438 0.7150
epoch 900 LossPred 0.6942 LossAtt 0.6033 TrainAcc 0.7400 TestAcc 0.5495 0.7000
epoch 1000 LossPred 0.6675 LossAtt 0.6787 TrainAcc 0.7400 TestAcc 0.5473 0.7400
epoch 1100 LossPred 0.6368 LossAtt 0.6997 TrainAcc 0.7700 TestAcc 0.5493 0.7500
epoch 1200 LossPred 0.6145 LossAtt 0.7437 TrainAcc 0.7900 TestAcc 0.5493 0.7600
epoch 1300 LossPred 0.5594 LossAtt 0.7572 TrainAcc 0.8200 TestAcc 0.5731 0.7800
epoch 1400 LossPred 0.5434 LossAtt 0.7392 TrainAcc 0.8200 TestAcc 0.5716 0.7750
epoch 1500 LossPred 0.5350 LossAtt 0.7433 TrainAcc 0.7800 TestAcc 0.5708 0.7600
epoch 1600 LossPred 0.5241 LossAtt 0.7405 TrainAcc 0.8300 TestAcc 0.5711 0.7900
epoch 1700 LossPred 0.5138 LossAtt 0.7408 TrainAcc 0.8300 TestAcc 0.5706 0.7800
epoch 1800 LossPred 0.4949 LossAtt 0.7282 TrainAcc 0.8300 TestAcc 0.5696 0.8000
epoch 1900 LossPred 0.4904 LossAtt 0.7281 TrainAcc 0.8300 TestAcc 0.5643 0.7950
epoch 2000 LossPred 0.4834 LossAtt 0.6964 TrainAcc 0.8400 TestAcc 0.5676 0.8050
epoch 2100 LossPred 0.4775 LossAtt 0.6862 TrainAcc 0.8300 TestAcc 0.5761 0.7850
epoch 2200 LossPred 0.4649 LossAtt 0.6782 TrainAcc 0.8300 TestAcc 0.5736 0.7950
epoch 2300 LossPred 0.4840 LossAtt 0.6741 TrainAcc 0.8400 TestAcc 0.5676 0.7850
epoch 2400 LossPred 0.4490 LossAtt 0.6747 TrainAcc 0.8400 TestAcc 0.5706 0.7650
epoch 2500 LossPred 0.4594 LossAtt 0.6821 TrainAcc 0.8300 TestAcc 0.5718 0.7800
Optimization Finished!
********** replication  69  **********
epoch   0 LossPred 1.2097 LossAtt 1.0637 TrainAcc 0.5100 TestAcc 0.4930 0.4950
epoch 100 LossPred 0.9832 LossAtt 0.4288 TrainAcc 0.5900 TestAcc 0.5693 0.5900
epoch 200 LossPred 0.9559 LossAtt 0.3500 TrainAcc 0.5900 TestAcc 0.5693 0.5900
epoch 300 LossPred 0.9467 LossAtt 0.3118 TrainAcc 0.5900 TestAcc 0.5693 0.5900
epoch 400 LossPred 0.9332 LossAtt 0.3574 TrainAcc 0.5900 TestAcc 0.5693 0.5900
epoch 500 LossPred 0.9118 LossAtt 0.3771 TrainAcc 0.6200 TestAcc 0.5596 0.6250
epoch 600 LossPred 0.8835 LossAtt 0.4327 TrainAcc 0.6300 TestAcc 0.6331 0.6350
epoch 700 LossPred 0.6090 LossAtt 0.4372 TrainAcc 0.8300 TestAcc 0.7773 0.7700
epoch 800 LossPred 0.5058 LossAtt 0.4029 TrainAcc 0.8300 TestAcc 0.8101 0.8100
epoch 900 LossPred 0.5394 LossAtt 0.4178 TrainAcc 0.8400 TestAcc 0.7925 0.8300
epoch 1000 LossPred 0.5266 LossAtt 0.4101 TrainAcc 0.8500 TestAcc 0.7928 0.8200
epoch 1100 LossPred 0.4843 LossAtt 0.4280 TrainAcc 0.8200 TestAcc 0.8026 0.8200
epoch 1200 LossPred 0.4970 LossAtt 0.4029 TrainAcc 0.8300 TestAcc 0.8166 0.7850
epoch 1300 LossPred 0.4701 LossAtt 0.4075 TrainAcc 0.8400 TestAcc 0.8118 0.8100
epoch 1400 LossPred 0.4199 LossAtt 0.4296 TrainAcc 0.8400 TestAcc 0.8128 0.8250
epoch 1500 LossPred 0.4594 LossAtt 0.4245 TrainAcc 0.8400 TestAcc 0.8116 0.8250
epoch 1600 LossPred 0.4765 LossAtt 0.4301 TrainAcc 0.8200 TestAcc 0.8143 0.8300
epoch 1700 LossPred 0.4668 LossAtt 0.4183 TrainAcc 0.8400 TestAcc 0.8163 0.8200
epoch 1800 LossPred 0.4867 LossAtt 0.4380 TrainAcc 0.8200 TestAcc 0.8168 0.7850
epoch 1900 LossPred 0.4852 LossAtt 0.4334 TrainAcc 0.8400 TestAcc 0.8126 0.8450
epoch 2000 LossPred 0.4020 LossAtt 0.4354 TrainAcc 0.8500 TestAcc 0.8201 0.8300
epoch 2100 LossPred 0.3759 LossAtt 0.4229 TrainAcc 0.8600 TestAcc 0.8213 0.8200
epoch 2200 LossPred 0.4740 LossAtt 0.4123 TrainAcc 0.8500 TestAcc 0.8028 0.8450
epoch 2300 LossPred 0.4768 LossAtt 0.4329 TrainAcc 0.8400 TestAcc 0.8113 0.8650
epoch 2400 LossPred 0.4140 LossAtt 0.4319 TrainAcc 0.8600 TestAcc 0.8193 0.8200
epoch 2500 LossPred 0.3539 LossAtt 0.4244 TrainAcc 0.8800 TestAcc 0.8128 0.8150
Optimization Finished!
********** replication  70  **********
epoch   0 LossPred 1.1274 LossAtt 1.0475 TrainAcc 0.5300 TestAcc 0.4992 0.5350
epoch 100 LossPred 0.9186 LossAtt 0.5910 TrainAcc 0.6200 TestAcc 0.5258 0.5950
epoch 200 LossPred 0.8741 LossAtt 0.5815 TrainAcc 0.6100 TestAcc 0.5593 0.6000
epoch 300 LossPred 0.8539 LossAtt 0.5345 TrainAcc 0.6600 TestAcc 0.5741 0.6300
epoch 400 LossPred 0.8354 LossAtt 0.5069 TrainAcc 0.6700 TestAcc 0.5866 0.6650
epoch 500 LossPred 0.8146 LossAtt 0.5311 TrainAcc 0.7100 TestAcc 0.5818 0.6750
epoch 600 LossPred 0.7955 LossAtt 0.5165 TrainAcc 0.6900 TestAcc 0.5856 0.6750
epoch 700 LossPred 0.7631 LossAtt 0.5518 TrainAcc 0.7600 TestAcc 0.5876 0.7250
epoch 800 LossPred 0.7533 LossAtt 0.6057 TrainAcc 0.7100 TestAcc 0.5916 0.7100
epoch 900 LossPred 0.7027 LossAtt 0.6234 TrainAcc 0.7100 TestAcc 0.5943 0.6600
epoch 1000 LossPred 0.6944 LossAtt 0.5970 TrainAcc 0.7300 TestAcc 0.5951 0.6900
epoch 1100 LossPred 0.6615 LossAtt 0.6076 TrainAcc 0.7500 TestAcc 0.5968 0.6750
epoch 1200 LossPred 0.6504 LossAtt 0.5605 TrainAcc 0.7400 TestAcc 0.5908 0.6650
epoch 1300 LossPred 0.7124 LossAtt 0.5406 TrainAcc 0.7800 TestAcc 0.5968 0.7350
epoch 1400 LossPred 0.6682 LossAtt 0.5380 TrainAcc 0.7700 TestAcc 0.5926 0.6550
epoch 1500 LossPred 0.6473 LossAtt 0.5513 TrainAcc 0.7800 TestAcc 0.5968 0.6650
epoch 1600 LossPred 0.6590 LossAtt 0.5204 TrainAcc 0.7500 TestAcc 0.5998 0.7100
epoch 1700 LossPred 0.6875 LossAtt 0.5059 TrainAcc 0.7600 TestAcc 0.5973 0.7250
epoch 1800 LossPred 0.6567 LossAtt 0.4876 TrainAcc 0.7800 TestAcc 0.6071 0.7100
epoch 1900 LossPred 0.7545 LossAtt 0.4612 TrainAcc 0.7100 TestAcc 0.5906 0.6650
epoch 2000 LossPred 0.6871 LossAtt 0.4721 TrainAcc 0.7400 TestAcc 0.6016 0.6900
epoch 2100 LossPred 0.7858 LossAtt 0.5000 TrainAcc 0.7200 TestAcc 0.5993 0.7000
epoch 2200 LossPred 0.7893 LossAtt 0.4646 TrainAcc 0.7200 TestAcc 0.5956 0.6850
epoch 2300 LossPred 0.7711 LossAtt 0.4362 TrainAcc 0.7200 TestAcc 0.5976 0.6950
epoch 2400 LossPred 0.7359 LossAtt 0.4350 TrainAcc 0.7400 TestAcc 0.6034 0.7000
epoch 2500 LossPred 0.7308 LossAtt 0.4271 TrainAcc 0.7400 TestAcc 0.6079 0.7000
Optimization Finished!
********** replication  71  **********
epoch   0 LossPred 1.1737 LossAtt 1.0078 TrainAcc 0.4700 TestAcc 0.5113 0.5000
epoch 100 LossPred 0.9680 LossAtt 0.5051 TrainAcc 0.5700 TestAcc 0.5691 0.5700
epoch 200 LossPred 0.9117 LossAtt 0.5636 TrainAcc 0.5900 TestAcc 0.5563 0.6050
epoch 300 LossPred 0.8495 LossAtt 0.5874 TrainAcc 0.7000 TestAcc 0.6116 0.7050
epoch 400 LossPred 0.3802 LossAtt 0.5448 TrainAcc 0.9000 TestAcc 0.8363 0.8850
epoch 500 LossPred 0.3366 LossAtt 0.5216 TrainAcc 0.9000 TestAcc 0.8301 0.9000
epoch 600 LossPred 0.3091 LossAtt 0.5241 TrainAcc 0.9200 TestAcc 0.8373 0.9150
epoch 700 LossPred 0.3591 LossAtt 0.5292 TrainAcc 0.8800 TestAcc 0.7943 0.8800
epoch 800 LossPred 0.3017 LossAtt 0.5263 TrainAcc 0.9200 TestAcc 0.8363 0.9100
epoch 900 LossPred 0.2551 LossAtt 0.5259 TrainAcc 0.9400 TestAcc 0.8386 0.8950
epoch 1000 LossPred 0.2588 LossAtt 0.5261 TrainAcc 0.9200 TestAcc 0.8356 0.8900
epoch 1100 LossPred 0.3204 LossAtt 0.5256 TrainAcc 0.8600 TestAcc 0.8113 0.8500
epoch 1200 LossPred 0.2882 LossAtt 0.5054 TrainAcc 0.9100 TestAcc 0.8306 0.9000
epoch 1300 LossPred 0.2004 LossAtt 0.4951 TrainAcc 0.9400 TestAcc 0.8614 0.9150
epoch 1400 LossPred 0.2010 LossAtt 0.4928 TrainAcc 0.9300 TestAcc 0.8601 0.9150
epoch 1500 LossPred 0.2742 LossAtt 0.4762 TrainAcc 0.8900 TestAcc 0.8486 0.9050
epoch 1600 LossPred 0.3550 LossAtt 0.5078 TrainAcc 0.8600 TestAcc 0.8231 0.8600
epoch 1700 LossPred 0.1879 LossAtt 0.4784 TrainAcc 0.9400 TestAcc 0.8714 0.9050
epoch 1800 LossPred 0.1671 LossAtt 0.4652 TrainAcc 0.9500 TestAcc 0.8774 0.9250
epoch 1900 LossPred 0.3463 LossAtt 0.4755 TrainAcc 0.8800 TestAcc 0.8366 0.8650
epoch 2000 LossPred 0.1843 LossAtt 0.4677 TrainAcc 0.9400 TestAcc 0.8891 0.8800
epoch 2100 LossPred 0.1460 LossAtt 0.4741 TrainAcc 0.9400 TestAcc 0.9012 0.9050
epoch 2200 LossPred 0.2128 LossAtt 0.4848 TrainAcc 0.9300 TestAcc 0.8659 0.9100
epoch 2300 LossPred 0.2168 LossAtt 0.4941 TrainAcc 0.9300 TestAcc 0.8936 0.9200
epoch 2400 LossPred 0.1274 LossAtt 0.5094 TrainAcc 0.9700 TestAcc 0.9052 0.9300
epoch 2500 LossPred 0.1425 LossAtt 0.4898 TrainAcc 0.9600 TestAcc 0.9029 0.9300
Optimization Finished!
********** replication  72  **********
epoch   0 LossPred 1.0501 LossAtt 0.9965 TrainAcc 0.5400 TestAcc 0.4950 0.5450
epoch 100 LossPred 0.9052 LossAtt 0.4770 TrainAcc 0.6300 TestAcc 0.5641 0.6300
epoch 200 LossPred 0.8975 LossAtt 0.3760 TrainAcc 0.6300 TestAcc 0.5641 0.6300
epoch 300 LossPred 0.8930 LossAtt 0.3582 TrainAcc 0.6300 TestAcc 0.5641 0.6300
epoch 400 LossPred 0.8901 LossAtt 0.3696 TrainAcc 0.6300 TestAcc 0.5641 0.6300
epoch 500 LossPred 0.8850 LossAtt 0.3402 TrainAcc 0.6300 TestAcc 0.5641 0.6300
epoch 600 LossPred 0.8081 LossAtt 0.4974 TrainAcc 0.6600 TestAcc 0.6174 0.6600
epoch 700 LossPred 0.3516 LossAtt 0.5668 TrainAcc 0.9100 TestAcc 0.8351 0.9000
epoch 800 LossPred 0.3391 LossAtt 0.5405 TrainAcc 0.9100 TestAcc 0.8448 0.8600
epoch 900 LossPred 0.2986 LossAtt 0.4918 TrainAcc 0.9100 TestAcc 0.8524 0.9050
epoch 1000 LossPred 0.2556 LossAtt 0.4904 TrainAcc 0.9200 TestAcc 0.8634 0.9200
epoch 1100 LossPred 0.2243 LossAtt 0.4924 TrainAcc 0.9400 TestAcc 0.8509 0.8750
epoch 1200 LossPred 0.2400 LossAtt 0.4887 TrainAcc 0.9300 TestAcc 0.8438 0.8700
epoch 1300 LossPred 0.2143 LossAtt 0.4673 TrainAcc 0.9200 TestAcc 0.8824 0.9150
epoch 1400 LossPred 0.2057 LossAtt 0.4756 TrainAcc 0.9300 TestAcc 0.8874 0.9250
epoch 1500 LossPred 0.1982 LossAtt 0.4648 TrainAcc 0.9400 TestAcc 0.8886 0.9050
epoch 1600 LossPred 0.2640 LossAtt 0.4703 TrainAcc 0.9100 TestAcc 0.8486 0.8800
epoch 1700 LossPred 0.1557 LossAtt 0.4728 TrainAcc 0.9500 TestAcc 0.9019 0.9350
epoch 1800 LossPred 0.1287 LossAtt 0.4596 TrainAcc 0.9700 TestAcc 0.9092 0.9350
epoch 1900 LossPred 0.1196 LossAtt 0.4587 TrainAcc 0.9700 TestAcc 0.9162 0.9250
epoch 2000 LossPred 0.1676 LossAtt 0.4397 TrainAcc 0.9300 TestAcc 0.8844 0.9100
epoch 2100 LossPred 0.1143 LossAtt 0.4573 TrainAcc 0.9700 TestAcc 0.9172 0.9450
epoch 2200 LossPred 0.2320 LossAtt 0.4390 TrainAcc 0.9100 TestAcc 0.8599 0.8900
epoch 2300 LossPred 0.1040 LossAtt 0.4511 TrainAcc 0.9700 TestAcc 0.9164 0.9300
epoch 2400 LossPred 0.1159 LossAtt 0.4332 TrainAcc 0.9700 TestAcc 0.9057 0.9400
epoch 2500 LossPred 0.1064 LossAtt 0.4422 TrainAcc 0.9700 TestAcc 0.9039 0.9500
Optimization Finished!
********** replication  73  **********
epoch   0 LossPred 1.1490 LossAtt 1.0223 TrainAcc 0.5000 TestAcc 0.5280 0.5000
epoch 100 LossPred 0.9713 LossAtt 0.4730 TrainAcc 0.6200 TestAcc 0.5848 0.5900
epoch 200 LossPred 0.9540 LossAtt 0.5137 TrainAcc 0.5900 TestAcc 0.5858 0.5900
epoch 300 LossPred 0.9308 LossAtt 0.5529 TrainAcc 0.5900 TestAcc 0.5858 0.5900
epoch 400 LossPred 0.9093 LossAtt 0.4972 TrainAcc 0.6300 TestAcc 0.5661 0.6350
epoch 500 LossPred 0.8999 LossAtt 0.4535 TrainAcc 0.6200 TestAcc 0.5946 0.6100
epoch 600 LossPred 0.8979 LossAtt 0.4324 TrainAcc 0.6500 TestAcc 0.5450 0.6300
epoch 700 LossPred 0.8878 LossAtt 0.4508 TrainAcc 0.6500 TestAcc 0.5766 0.6550
epoch 800 LossPred 0.8912 LossAtt 0.4393 TrainAcc 0.6400 TestAcc 0.5786 0.6350
epoch 900 LossPred 0.8696 LossAtt 0.4415 TrainAcc 0.6700 TestAcc 0.5773 0.6550
epoch 1000 LossPred 0.8552 LossAtt 0.4668 TrainAcc 0.6700 TestAcc 0.5731 0.6500
epoch 1100 LossPred 0.8369 LossAtt 0.4994 TrainAcc 0.6800 TestAcc 0.5808 0.6600
epoch 1200 LossPred 0.8434 LossAtt 0.5112 TrainAcc 0.6600 TestAcc 0.5893 0.6600
epoch 1300 LossPred 0.8369 LossAtt 0.5203 TrainAcc 0.6700 TestAcc 0.5803 0.6700
epoch 1400 LossPred 0.8301 LossAtt 0.5470 TrainAcc 0.6600 TestAcc 0.5796 0.6900
epoch 1500 LossPred 0.8228 LossAtt 0.5278 TrainAcc 0.6800 TestAcc 0.5883 0.6850
epoch 1600 LossPred 0.8141 LossAtt 0.6025 TrainAcc 0.6800 TestAcc 0.5873 0.7100
epoch 1700 LossPred 0.7896 LossAtt 0.6026 TrainAcc 0.7200 TestAcc 0.5916 0.7100
epoch 1800 LossPred 0.7289 LossAtt 0.6106 TrainAcc 0.7500 TestAcc 0.6274 0.7350
epoch 1900 LossPred 0.5105 LossAtt 0.7110 TrainAcc 0.8100 TestAcc 0.7645 0.8000
epoch 2000 LossPred 0.3228 LossAtt 0.6411 TrainAcc 0.9000 TestAcc 0.7973 0.8850
epoch 2100 LossPred 0.2931 LossAtt 0.6041 TrainAcc 0.9200 TestAcc 0.7993 0.8850
epoch 2200 LossPred 0.2303 LossAtt 0.6375 TrainAcc 0.9300 TestAcc 0.8313 0.9300
epoch 2300 LossPred 0.2103 LossAtt 0.6186 TrainAcc 0.9400 TestAcc 0.8241 0.9200
epoch 2400 LossPred 0.2559 LossAtt 0.6314 TrainAcc 0.9300 TestAcc 0.7870 0.9000
epoch 2500 LossPred 0.1944 LossAtt 0.6119 TrainAcc 0.9500 TestAcc 0.8133 0.9250
Optimization Finished!
********** replication  74  **********
epoch   0 LossPred 1.0534 LossAtt 0.9971 TrainAcc 0.4800 TestAcc 0.5003 0.4800
epoch 100 LossPred 0.9635 LossAtt 0.6736 TrainAcc 0.6400 TestAcc 0.5868 0.6400
epoch 200 LossPred 0.9148 LossAtt 0.6471 TrainAcc 0.6900 TestAcc 0.5996 0.6500
epoch 300 LossPred 0.5895 LossAtt 0.6781 TrainAcc 0.8300 TestAcc 0.7410 0.8000
epoch 400 LossPred 0.4460 LossAtt 0.5759 TrainAcc 0.8500 TestAcc 0.7845 0.8150
epoch 500 LossPred 0.4241 LossAtt 0.5428 TrainAcc 0.8600 TestAcc 0.7883 0.8350
epoch 600 LossPred 0.4119 LossAtt 0.5196 TrainAcc 0.8600 TestAcc 0.7960 0.8350
epoch 700 LossPred 0.4066 LossAtt 0.4986 TrainAcc 0.8700 TestAcc 0.7895 0.8400
epoch 800 LossPred 0.4218 LossAtt 0.5099 TrainAcc 0.8700 TestAcc 0.7720 0.8450
epoch 900 LossPred 0.3754 LossAtt 0.5295 TrainAcc 0.8600 TestAcc 0.8013 0.8250
epoch 1000 LossPred 0.3310 LossAtt 0.5604 TrainAcc 0.9100 TestAcc 0.8008 0.8500
epoch 1100 LossPred 0.3056 LossAtt 0.5719 TrainAcc 0.9200 TestAcc 0.8031 0.8400
epoch 1200 LossPred 0.4218 LossAtt 0.5678 TrainAcc 0.8500 TestAcc 0.7815 0.8450
epoch 1300 LossPred 0.3296 LossAtt 0.5769 TrainAcc 0.8700 TestAcc 0.7955 0.8500
epoch 1400 LossPred 0.3948 LossAtt 0.5755 TrainAcc 0.8500 TestAcc 0.7983 0.8350
epoch 1500 LossPred 0.2909 LossAtt 0.5692 TrainAcc 0.8900 TestAcc 0.7995 0.8350
epoch 1600 LossPred 0.3444 LossAtt 0.5577 TrainAcc 0.8900 TestAcc 0.7968 0.8500
epoch 1700 LossPred 0.2990 LossAtt 0.5894 TrainAcc 0.9100 TestAcc 0.7930 0.8500
epoch 1800 LossPred 0.2661 LossAtt 0.5652 TrainAcc 0.9100 TestAcc 0.8021 0.8400
epoch 1900 LossPred 0.2678 LossAtt 0.5752 TrainAcc 0.9000 TestAcc 0.8041 0.8600
epoch 2000 LossPred 0.2940 LossAtt 0.5731 TrainAcc 0.8800 TestAcc 0.8001 0.8500
epoch 2100 LossPred 0.2722 LossAtt 0.5556 TrainAcc 0.9000 TestAcc 0.8106 0.8400
epoch 2200 LossPred 0.2516 LossAtt 0.5805 TrainAcc 0.9100 TestAcc 0.8073 0.8400
epoch 2300 LossPred 0.3136 LossAtt 0.5762 TrainAcc 0.9000 TestAcc 0.7805 0.8500
epoch 2400 LossPred 0.2745 LossAtt 0.5631 TrainAcc 0.9000 TestAcc 0.7825 0.8650
epoch 2500 LossPred 0.2762 LossAtt 0.5766 TrainAcc 0.8900 TestAcc 0.7928 0.8500
Optimization Finished!
********** replication  75  **********
epoch   0 LossPred 1.2131 LossAtt 1.0146 TrainAcc 0.5300 TestAcc 0.5741 0.5200
epoch 100 LossPred 1.0046 LossAtt 0.6716 TrainAcc 0.5700 TestAcc 0.5463 0.5650
epoch 200 LossPred 0.9772 LossAtt 0.6769 TrainAcc 0.5500 TestAcc 0.5255 0.5700
epoch 300 LossPred 0.9683 LossAtt 0.5892 TrainAcc 0.5700 TestAcc 0.5400 0.5800
epoch 400 LossPred 0.9406 LossAtt 0.6382 TrainAcc 0.6100 TestAcc 0.5223 0.6100
epoch 500 LossPred 0.8991 LossAtt 0.6190 TrainAcc 0.6500 TestAcc 0.5310 0.6350
epoch 600 LossPred 0.8664 LossAtt 0.6251 TrainAcc 0.6200 TestAcc 0.5155 0.6300
epoch 700 LossPred 0.7917 LossAtt 0.6810 TrainAcc 0.7200 TestAcc 0.5333 0.7200
epoch 800 LossPred 0.7504 LossAtt 0.6377 TrainAcc 0.7200 TestAcc 0.5380 0.7250
epoch 900 LossPred 0.7360 LossAtt 0.6088 TrainAcc 0.7400 TestAcc 0.5305 0.7150
epoch 1000 LossPred 0.7190 LossAtt 0.5913 TrainAcc 0.7300 TestAcc 0.5330 0.7300
epoch 1100 LossPred 0.7100 LossAtt 0.6004 TrainAcc 0.7500 TestAcc 0.5303 0.7250
epoch 1200 LossPred 0.6875 LossAtt 0.5636 TrainAcc 0.7500 TestAcc 0.5310 0.7050
epoch 1300 LossPred 0.6783 LossAtt 0.5554 TrainAcc 0.7400 TestAcc 0.5373 0.7100
epoch 1400 LossPred 0.6610 LossAtt 0.5744 TrainAcc 0.7400 TestAcc 0.5380 0.7200
epoch 1500 LossPred 0.6580 LossAtt 0.5587 TrainAcc 0.7400 TestAcc 0.5390 0.7200
epoch 1600 LossPred 0.6548 LossAtt 0.5509 TrainAcc 0.7500 TestAcc 0.5398 0.7400
epoch 1700 LossPred 0.6455 LossAtt 0.5728 TrainAcc 0.7600 TestAcc 0.5408 0.7300
epoch 1800 LossPred 0.6291 LossAtt 0.5773 TrainAcc 0.7500 TestAcc 0.5395 0.7150
epoch 1900 LossPred 0.6453 LossAtt 0.5622 TrainAcc 0.7700 TestAcc 0.5465 0.7350
epoch 2000 LossPred 0.6240 LossAtt 0.5599 TrainAcc 0.7700 TestAcc 0.5403 0.7300
epoch 2100 LossPred 0.6416 LossAtt 0.5620 TrainAcc 0.7800 TestAcc 0.5443 0.7450
epoch 2200 LossPred 0.6417 LossAtt 0.5413 TrainAcc 0.7600 TestAcc 0.5418 0.7350
epoch 2300 LossPred 0.6150 LossAtt 0.5514 TrainAcc 0.7600 TestAcc 0.5398 0.7250
epoch 2400 LossPred 0.6138 LossAtt 0.5337 TrainAcc 0.7800 TestAcc 0.5398 0.7300
epoch 2500 LossPred 0.6047 LossAtt 0.5396 TrainAcc 0.7900 TestAcc 0.5413 0.7300
Optimization Finished!
********** replication  76  **********
epoch   0 LossPred 1.1841 LossAtt 0.9742 TrainAcc 0.4900 TestAcc 0.4882 0.5350
epoch 100 LossPred 0.9680 LossAtt 0.4854 TrainAcc 0.5600 TestAcc 0.5893 0.5800
epoch 200 LossPred 0.9407 LossAtt 0.4343 TrainAcc 0.5700 TestAcc 0.5873 0.5850
epoch 300 LossPred 0.9306 LossAtt 0.4650 TrainAcc 0.5800 TestAcc 0.5821 0.5800
epoch 400 LossPred 0.9235 LossAtt 0.5170 TrainAcc 0.5700 TestAcc 0.5873 0.6050
epoch 500 LossPred 0.9155 LossAtt 0.5235 TrainAcc 0.6100 TestAcc 0.5873 0.6150
epoch 600 LossPred 0.9065 LossAtt 0.5104 TrainAcc 0.5500 TestAcc 0.5533 0.5900
epoch 700 LossPred 0.9044 LossAtt 0.5268 TrainAcc 0.6100 TestAcc 0.5853 0.6000
epoch 800 LossPred 0.8693 LossAtt 0.6562 TrainAcc 0.7000 TestAcc 0.6006 0.6700
epoch 900 LossPred 0.7606 LossAtt 0.6098 TrainAcc 0.7400 TestAcc 0.6619 0.7200
epoch 1000 LossPred 0.6129 LossAtt 0.6310 TrainAcc 0.7900 TestAcc 0.7242 0.7800
epoch 1100 LossPred 0.6047 LossAtt 0.6055 TrainAcc 0.8100 TestAcc 0.7060 0.7850
epoch 1200 LossPred 0.6425 LossAtt 0.6211 TrainAcc 0.7900 TestAcc 0.7365 0.7700
epoch 1300 LossPred 0.6209 LossAtt 0.5997 TrainAcc 0.7900 TestAcc 0.7300 0.7750
epoch 1400 LossPred 0.8597 LossAtt 0.6110 TrainAcc 0.7000 TestAcc 0.6612 0.6600
epoch 1500 LossPred 0.7781 LossAtt 0.5895 TrainAcc 0.7100 TestAcc 0.6847 0.7150
epoch 1600 LossPred 0.7393 LossAtt 0.6114 TrainAcc 0.7700 TestAcc 0.6944 0.7400
epoch 1700 LossPred 0.6294 LossAtt 0.6102 TrainAcc 0.8000 TestAcc 0.7315 0.7850
epoch 1800 LossPred 0.6378 LossAtt 0.5815 TrainAcc 0.8000 TestAcc 0.7395 0.8050
epoch 1900 LossPred 0.6956 LossAtt 0.5552 TrainAcc 0.7600 TestAcc 0.7317 0.7700
epoch 2000 LossPred 0.6116 LossAtt 0.5674 TrainAcc 0.7900 TestAcc 0.7190 0.7850
epoch 2100 LossPred 0.6215 LossAtt 0.5329 TrainAcc 0.7900 TestAcc 0.7190 0.7850
epoch 2200 LossPred 0.5803 LossAtt 0.5494 TrainAcc 0.8200 TestAcc 0.7297 0.7800
epoch 2300 LossPred 1.1762 LossAtt 0.4828 TrainAcc 0.5800 TestAcc 0.5801 0.5800
epoch 2400 LossPred 1.0131 LossAtt 0.3912 TrainAcc 0.5700 TestAcc 0.5913 0.5850
epoch 2500 LossPred 0.9847 LossAtt 0.3549 TrainAcc 0.5700 TestAcc 0.5943 0.5850
Optimization Finished!
********** replication  77  **********
epoch   0 LossPred 1.0248 LossAtt 1.0066 TrainAcc 0.5400 TestAcc 0.5198 0.5300
epoch 100 LossPred 0.9113 LossAtt 0.5386 TrainAcc 0.5900 TestAcc 0.5646 0.6000
epoch 200 LossPred 0.9079 LossAtt 0.4619 TrainAcc 0.5900 TestAcc 0.5646 0.6150
epoch 300 LossPred 0.9055 LossAtt 0.3796 TrainAcc 0.6000 TestAcc 0.5743 0.6200
epoch 400 LossPred 0.9009 LossAtt 0.3217 TrainAcc 0.6100 TestAcc 0.5788 0.6450
epoch 500 LossPred 0.8985 LossAtt 0.3276 TrainAcc 0.6100 TestAcc 0.5788 0.6300
epoch 600 LossPred 0.8974 LossAtt 0.3444 TrainAcc 0.6200 TestAcc 0.5813 0.6200
epoch 700 LossPred 0.8966 LossAtt 0.3467 TrainAcc 0.6200 TestAcc 0.5808 0.6250
epoch 800 LossPred 0.8954 LossAtt 0.3595 TrainAcc 0.6200 TestAcc 0.5808 0.6400
epoch 900 LossPred 0.8931 LossAtt 0.3739 TrainAcc 0.6200 TestAcc 0.5808 0.6500
epoch 1000 LossPred 0.8862 LossAtt 0.4629 TrainAcc 0.6400 TestAcc 0.5928 0.6600
epoch 1100 LossPred 0.8675 LossAtt 0.4587 TrainAcc 0.6800 TestAcc 0.5706 0.6900
epoch 1200 LossPred 0.8537 LossAtt 0.5328 TrainAcc 0.6700 TestAcc 0.5721 0.6500
epoch 1300 LossPred 0.8156 LossAtt 0.6247 TrainAcc 0.6700 TestAcc 0.5838 0.6500
epoch 1400 LossPred 0.7636 LossAtt 0.6904 TrainAcc 0.6600 TestAcc 0.5891 0.6550
epoch 1500 LossPred 0.7228 LossAtt 0.6699 TrainAcc 0.7400 TestAcc 0.5968 0.6650
epoch 1600 LossPred 0.6732 LossAtt 0.6533 TrainAcc 0.7800 TestAcc 0.5916 0.6800
epoch 1700 LossPred 0.6551 LossAtt 0.6461 TrainAcc 0.7800 TestAcc 0.5816 0.6650
epoch 1800 LossPred 0.6536 LossAtt 0.6537 TrainAcc 0.7800 TestAcc 0.5866 0.6950
epoch 1900 LossPred 0.6760 LossAtt 0.6436 TrainAcc 0.7500 TestAcc 0.5841 0.6950
epoch 2000 LossPred 0.6470 LossAtt 0.6268 TrainAcc 0.8000 TestAcc 0.5768 0.7050
epoch 2100 LossPred 0.6301 LossAtt 0.6377 TrainAcc 0.8100 TestAcc 0.5713 0.6800
epoch 2200 LossPred 0.6401 LossAtt 0.6422 TrainAcc 0.7900 TestAcc 0.5843 0.6800
epoch 2300 LossPred 0.6028 LossAtt 0.6312 TrainAcc 0.8100 TestAcc 0.5821 0.6850
epoch 2400 LossPred 0.6041 LossAtt 0.6279 TrainAcc 0.8100 TestAcc 0.5743 0.6950
epoch 2500 LossPred 0.5854 LossAtt 0.6361 TrainAcc 0.8100 TestAcc 0.5803 0.6850
Optimization Finished!
********** replication  78  **********
epoch   0 LossPred 1.0450 LossAtt 0.9909 TrainAcc 0.5100 TestAcc 0.4965 0.5350
epoch 100 LossPred 0.8867 LossAtt 0.5348 TrainAcc 0.6100 TestAcc 0.5756 0.6200
epoch 200 LossPred 0.8769 LossAtt 0.4330 TrainAcc 0.6400 TestAcc 0.6139 0.6300
epoch 300 LossPred 0.7865 LossAtt 0.4380 TrainAcc 0.7500 TestAcc 0.6644 0.7200
epoch 400 LossPred 0.5012 LossAtt 0.3736 TrainAcc 0.8500 TestAcc 0.7833 0.8500
epoch 500 LossPred 0.5128 LossAtt 0.3711 TrainAcc 0.8300 TestAcc 0.7913 0.8100
epoch 600 LossPred 0.4926 LossAtt 0.3599 TrainAcc 0.8600 TestAcc 0.7848 0.8500
epoch 700 LossPred 0.4825 LossAtt 0.3739 TrainAcc 0.8600 TestAcc 0.7765 0.8450
epoch 800 LossPred 0.6302 LossAtt 0.3781 TrainAcc 0.7800 TestAcc 0.7420 0.8000
epoch 900 LossPred 0.4998 LossAtt 0.3429 TrainAcc 0.8500 TestAcc 0.7800 0.8450
epoch 1000 LossPred 0.4670 LossAtt 0.3534 TrainAcc 0.8500 TestAcc 0.7935 0.8250
epoch 1100 LossPred 0.6668 LossAtt 0.3386 TrainAcc 0.7600 TestAcc 0.6972 0.7500
epoch 1200 LossPred 0.7082 LossAtt 0.3423 TrainAcc 0.7400 TestAcc 0.6639 0.7350
epoch 1300 LossPred 0.6681 LossAtt 0.3381 TrainAcc 0.7700 TestAcc 0.6727 0.7750
epoch 1400 LossPred 0.6657 LossAtt 0.3250 TrainAcc 0.7700 TestAcc 0.6719 0.7700
epoch 1500 LossPred 0.6427 LossAtt 0.3035 TrainAcc 0.7900 TestAcc 0.6927 0.7750
epoch 1600 LossPred 0.6414 LossAtt 0.3141 TrainAcc 0.7900 TestAcc 0.6922 0.7750
epoch 1700 LossPred 0.6169 LossAtt 0.3160 TrainAcc 0.7900 TestAcc 0.7027 0.7800
epoch 1800 LossPred 0.6049 LossAtt 0.3121 TrainAcc 0.8000 TestAcc 0.7025 0.7900
epoch 1900 LossPred 0.5875 LossAtt 0.3011 TrainAcc 0.8200 TestAcc 0.7247 0.8000
epoch 2000 LossPred 0.5812 LossAtt 0.2799 TrainAcc 0.8100 TestAcc 0.7382 0.8100
epoch 2100 LossPred 0.5578 LossAtt 0.2735 TrainAcc 0.8300 TestAcc 0.7432 0.8100
epoch 2200 LossPred 0.5220 LossAtt 0.2894 TrainAcc 0.8300 TestAcc 0.7523 0.8300
epoch 2300 LossPred 0.5376 LossAtt 0.2680 TrainAcc 0.8300 TestAcc 0.7560 0.8350
epoch 2400 LossPred 0.5364 LossAtt 0.2697 TrainAcc 0.8400 TestAcc 0.7603 0.8400
epoch 2500 LossPred 0.5292 LossAtt 0.2680 TrainAcc 0.8300 TestAcc 0.7515 0.8250
Optimization Finished!
********** replication  79  **********
epoch   0 LossPred 1.2182 LossAtt 1.0537 TrainAcc 0.3900 TestAcc 0.4650 0.3900
epoch 100 LossPred 0.9456 LossAtt 0.5078 TrainAcc 0.6100 TestAcc 0.5578 0.5900
epoch 200 LossPred 0.8702 LossAtt 0.5849 TrainAcc 0.6600 TestAcc 0.5268 0.6450
epoch 300 LossPred 0.7371 LossAtt 0.6521 TrainAcc 0.7700 TestAcc 0.5546 0.7500
epoch 400 LossPred 0.6636 LossAtt 0.6324 TrainAcc 0.7600 TestAcc 0.5621 0.7700
epoch 500 LossPred 0.6373 LossAtt 0.6426 TrainAcc 0.7700 TestAcc 0.5578 0.7800
epoch 600 LossPred 0.5893 LossAtt 0.7025 TrainAcc 0.8300 TestAcc 0.5548 0.7850
epoch 700 LossPred 0.5618 LossAtt 0.7044 TrainAcc 0.8300 TestAcc 0.5538 0.7950
epoch 800 LossPred 0.5420 LossAtt 0.7126 TrainAcc 0.8300 TestAcc 0.5563 0.7800
epoch 900 LossPred 0.5348 LossAtt 0.7172 TrainAcc 0.8400 TestAcc 0.5566 0.7750
epoch 1000 LossPred 0.5185 LossAtt 0.7327 TrainAcc 0.8400 TestAcc 0.5541 0.7900
epoch 1100 LossPred 0.5171 LossAtt 0.7237 TrainAcc 0.8400 TestAcc 0.5551 0.7800
epoch 1200 LossPred 0.5110 LossAtt 0.6971 TrainAcc 0.8300 TestAcc 0.5556 0.7850
epoch 1300 LossPred 0.5060 LossAtt 0.6988 TrainAcc 0.8400 TestAcc 0.5568 0.7900
epoch 1400 LossPred 0.5139 LossAtt 0.7143 TrainAcc 0.8200 TestAcc 0.5523 0.7950
epoch 1500 LossPred 0.4963 LossAtt 0.6787 TrainAcc 0.8500 TestAcc 0.5521 0.7900
epoch 1600 LossPred 0.4901 LossAtt 0.6958 TrainAcc 0.8500 TestAcc 0.5531 0.7950
epoch 1700 LossPred 0.4932 LossAtt 0.6968 TrainAcc 0.8300 TestAcc 0.5521 0.7900
epoch 1800 LossPred 0.4892 LossAtt 0.6852 TrainAcc 0.8400 TestAcc 0.5526 0.7850
epoch 1900 LossPred 0.4847 LossAtt 0.6938 TrainAcc 0.8500 TestAcc 0.5553 0.7900
epoch 2000 LossPred 0.4886 LossAtt 0.6963 TrainAcc 0.8500 TestAcc 0.5523 0.7750
epoch 2100 LossPred 0.4835 LossAtt 0.7007 TrainAcc 0.8300 TestAcc 0.5531 0.7800
epoch 2200 LossPred 0.4943 LossAtt 0.7089 TrainAcc 0.8400 TestAcc 0.5521 0.7800
epoch 2300 LossPred 0.4725 LossAtt 0.6964 TrainAcc 0.8500 TestAcc 0.5511 0.7850
epoch 2400 LossPred 0.4675 LossAtt 0.6903 TrainAcc 0.8500 TestAcc 0.5523 0.7900
epoch 2500 LossPred 0.4811 LossAtt 0.6732 TrainAcc 0.8500 TestAcc 0.5538 0.7850
Optimization Finished!
********** replication  80  **********
epoch   0 LossPred 1.1274 LossAtt 1.0258 TrainAcc 0.4600 TestAcc 0.5218 0.4650
epoch 100 LossPred 1.0088 LossAtt 0.6012 TrainAcc 0.4900 TestAcc 0.4867 0.5050
epoch 200 LossPred 0.9410 LossAtt 0.5951 TrainAcc 0.5900 TestAcc 0.5313 0.5950
epoch 300 LossPred 0.8695 LossAtt 0.5525 TrainAcc 0.6200 TestAcc 0.5561 0.6000
epoch 400 LossPred 0.7139 LossAtt 0.7128 TrainAcc 0.7100 TestAcc 0.7085 0.6950
epoch 500 LossPred 0.4254 LossAtt 0.6341 TrainAcc 0.8600 TestAcc 0.8093 0.8150
epoch 600 LossPred 0.4120 LossAtt 0.6152 TrainAcc 0.8700 TestAcc 0.8181 0.8300
epoch 700 LossPred 0.4060 LossAtt 0.6106 TrainAcc 0.8300 TestAcc 0.7860 0.8300
epoch 800 LossPred 0.4674 LossAtt 0.6106 TrainAcc 0.8200 TestAcc 0.7828 0.8100
epoch 900 LossPred 0.3363 LossAtt 0.5625 TrainAcc 0.8900 TestAcc 0.8328 0.8600
epoch 1000 LossPred 0.3433 LossAtt 0.5357 TrainAcc 0.8900 TestAcc 0.7968 0.8300
epoch 1100 LossPred 0.3104 LossAtt 0.4961 TrainAcc 0.9100 TestAcc 0.8201 0.8850
epoch 1200 LossPred 0.3241 LossAtt 0.5263 TrainAcc 0.9000 TestAcc 0.8398 0.8650
epoch 1300 LossPred 0.2785 LossAtt 0.4987 TrainAcc 0.9200 TestAcc 0.8258 0.8800
epoch 1400 LossPred 0.2700 LossAtt 0.5050 TrainAcc 0.8700 TestAcc 0.8301 0.8650
epoch 1500 LossPred 0.2223 LossAtt 0.5036 TrainAcc 0.9300 TestAcc 0.8343 0.8800
epoch 1600 LossPred 0.2313 LossAtt 0.4810 TrainAcc 0.9400 TestAcc 0.8218 0.8800
epoch 1700 LossPred 0.2227 LossAtt 0.4876 TrainAcc 0.9500 TestAcc 0.8186 0.8800
epoch 1800 LossPred 0.2946 LossAtt 0.4728 TrainAcc 0.9300 TestAcc 0.8023 0.8800
epoch 1900 LossPred 0.2984 LossAtt 0.4692 TrainAcc 0.9100 TestAcc 0.8196 0.8800
epoch 2000 LossPred 0.2966 LossAtt 0.4609 TrainAcc 0.9200 TestAcc 0.8153 0.9050
epoch 2100 LossPred 0.2569 LossAtt 0.4591 TrainAcc 0.9400 TestAcc 0.8183 0.9050
epoch 2200 LossPred 0.2031 LossAtt 0.4268 TrainAcc 0.9500 TestAcc 0.8293 0.9000
epoch 2300 LossPred 0.1996 LossAtt 0.4230 TrainAcc 0.9400 TestAcc 0.8333 0.9000
epoch 2400 LossPred 0.2145 LossAtt 0.4256 TrainAcc 0.9200 TestAcc 0.8161 0.9000
epoch 2500 LossPred 0.3220 LossAtt 0.4171 TrainAcc 0.9000 TestAcc 0.8206 0.8750
Optimization Finished!
********** replication  81  **********
epoch   0 LossPred 1.0202 LossAtt 1.0134 TrainAcc 0.5200 TestAcc 0.5390 0.5250
epoch 100 LossPred 0.9320 LossAtt 0.4367 TrainAcc 0.6100 TestAcc 0.5863 0.6100
epoch 200 LossPred 0.9187 LossAtt 0.3881 TrainAcc 0.6100 TestAcc 0.5863 0.6400
epoch 300 LossPred 0.8949 LossAtt 0.3411 TrainAcc 0.6400 TestAcc 0.6274 0.6450
epoch 400 LossPred 0.8871 LossAtt 0.3470 TrainAcc 0.6400 TestAcc 0.6329 0.6550
epoch 500 LossPred 0.8602 LossAtt 0.4239 TrainAcc 0.6900 TestAcc 0.5998 0.6600
epoch 600 LossPred 0.8426 LossAtt 0.4363 TrainAcc 0.6700 TestAcc 0.6176 0.6650
epoch 700 LossPred 0.8399 LossAtt 0.4420 TrainAcc 0.6400 TestAcc 0.6141 0.6400
epoch 800 LossPred 0.8371 LossAtt 0.4299 TrainAcc 0.6700 TestAcc 0.6139 0.6650
epoch 900 LossPred 0.8390 LossAtt 0.3760 TrainAcc 0.6400 TestAcc 0.6154 0.6550
epoch 1000 LossPred 0.8393 LossAtt 0.3918 TrainAcc 0.6800 TestAcc 0.6091 0.6600
epoch 1100 LossPred 0.8378 LossAtt 0.4046 TrainAcc 0.6600 TestAcc 0.6131 0.6550
epoch 1200 LossPred 0.8366 LossAtt 0.4006 TrainAcc 0.6900 TestAcc 0.6079 0.6550
epoch 1300 LossPred 0.8360 LossAtt 0.4036 TrainAcc 0.6800 TestAcc 0.6039 0.6600
epoch 1400 LossPred 0.8343 LossAtt 0.3873 TrainAcc 0.7000 TestAcc 0.6056 0.6550
epoch 1500 LossPred 0.8352 LossAtt 0.4197 TrainAcc 0.6900 TestAcc 0.6004 0.6600
epoch 1600 LossPred 0.8322 LossAtt 0.3525 TrainAcc 0.6900 TestAcc 0.6006 0.6550
epoch 1700 LossPred 0.8317 LossAtt 0.3435 TrainAcc 0.6900 TestAcc 0.6016 0.6550
epoch 1800 LossPred 0.8305 LossAtt 0.3408 TrainAcc 0.6900 TestAcc 0.6039 0.6550
epoch 1900 LossPred 0.8291 LossAtt 0.3252 TrainAcc 0.6900 TestAcc 0.6006 0.6550
epoch 2000 LossPred 0.8297 LossAtt 0.3047 TrainAcc 0.7000 TestAcc 0.6001 0.6600
epoch 2100 LossPred 0.8549 LossAtt 0.3048 TrainAcc 0.6900 TestAcc 0.5986 0.6750
epoch 2200 LossPred 0.8766 LossAtt 0.2967 TrainAcc 0.6500 TestAcc 0.6081 0.6550
epoch 2300 LossPred 0.8752 LossAtt 0.3358 TrainAcc 0.6800 TestAcc 0.6054 0.6600
epoch 2400 LossPred 0.8144 LossAtt 0.5095 TrainAcc 0.6900 TestAcc 0.5988 0.6700
epoch 2500 LossPred 0.8146 LossAtt 0.5087 TrainAcc 0.7000 TestAcc 0.5921 0.6600
Optimization Finished!
********** replication  82  **********
epoch   0 LossPred 1.2398 LossAtt 0.9968 TrainAcc 0.4200 TestAcc 0.4299 0.4250
epoch 100 LossPred 0.8488 LossAtt 0.3774 TrainAcc 0.6900 TestAcc 0.6186 0.6950
epoch 200 LossPred 0.8168 LossAtt 0.3764 TrainAcc 0.6900 TestAcc 0.6186 0.6950
epoch 300 LossPred 0.7746 LossAtt 0.4018 TrainAcc 0.6700 TestAcc 0.6349 0.6550
epoch 400 LossPred 0.7083 LossAtt 0.4184 TrainAcc 0.7400 TestAcc 0.6967 0.7450
epoch 500 LossPred 0.6339 LossAtt 0.5163 TrainAcc 0.7800 TestAcc 0.7475 0.7800
epoch 600 LossPred 0.6140 LossAtt 0.5127 TrainAcc 0.7900 TestAcc 0.7513 0.7800
epoch 700 LossPred 0.6840 LossAtt 0.5200 TrainAcc 0.7500 TestAcc 0.7250 0.7450
epoch 800 LossPred 0.5296 LossAtt 0.5224 TrainAcc 0.8000 TestAcc 0.8473 0.7800
epoch 900 LossPred 0.4457 LossAtt 0.5122 TrainAcc 0.8400 TestAcc 0.8278 0.8150
epoch 1000 LossPred 0.3956 LossAtt 0.5184 TrainAcc 0.8500 TestAcc 0.8539 0.8050
epoch 1100 LossPred 0.3805 LossAtt 0.5319 TrainAcc 0.8400 TestAcc 0.8566 0.8100
epoch 1200 LossPred 0.6342 LossAtt 0.5306 TrainAcc 0.7600 TestAcc 0.8003 0.7050
epoch 1300 LossPred 0.3698 LossAtt 0.5385 TrainAcc 0.8400 TestAcc 0.8606 0.8050
epoch 1400 LossPred 0.3434 LossAtt 0.5488 TrainAcc 0.8700 TestAcc 0.8661 0.8100
epoch 1500 LossPred 0.3744 LossAtt 0.5610 TrainAcc 0.8500 TestAcc 0.8641 0.8100
epoch 1600 LossPred 0.3331 LossAtt 0.5695 TrainAcc 0.8700 TestAcc 0.8684 0.8250
epoch 1700 LossPred 0.3978 LossAtt 0.5532 TrainAcc 0.8300 TestAcc 0.8481 0.8200
epoch 1800 LossPred 0.4291 LossAtt 0.5673 TrainAcc 0.8400 TestAcc 0.8298 0.8150
epoch 1900 LossPred 0.4038 LossAtt 0.5494 TrainAcc 0.8500 TestAcc 0.8526 0.8300
epoch 2000 LossPred 0.4211 LossAtt 0.5692 TrainAcc 0.8300 TestAcc 0.8401 0.8250
epoch 2100 LossPred 0.3886 LossAtt 0.5647 TrainAcc 0.8700 TestAcc 0.8646 0.8300
epoch 2200 LossPred 0.5293 LossAtt 0.5627 TrainAcc 0.8000 TestAcc 0.7983 0.8000
epoch 2300 LossPred 0.4318 LossAtt 0.5779 TrainAcc 0.8300 TestAcc 0.8524 0.8250
epoch 2400 LossPred 0.5173 LossAtt 0.5674 TrainAcc 0.8000 TestAcc 0.8001 0.8100
epoch 2500 LossPred 0.4104 LossAtt 0.5816 TrainAcc 0.8500 TestAcc 0.8446 0.8300
Optimization Finished!
********** replication  83  **********
epoch   0 LossPred 0.9788 LossAtt 1.0128 TrainAcc 0.6300 TestAcc 0.5553 0.6400
epoch 100 LossPred 0.8468 LossAtt 0.5585 TrainAcc 0.6900 TestAcc 0.5408 0.6650
epoch 200 LossPred 0.8306 LossAtt 0.6156 TrainAcc 0.6900 TestAcc 0.5433 0.6900
epoch 300 LossPred 0.8160 LossAtt 0.5921 TrainAcc 0.6900 TestAcc 0.5508 0.6850
epoch 400 LossPred 0.7945 LossAtt 0.6171 TrainAcc 0.7200 TestAcc 0.5558 0.7000
epoch 500 LossPred 0.7719 LossAtt 0.6688 TrainAcc 0.7200 TestAcc 0.5578 0.7150
epoch 600 LossPred 0.7358 LossAtt 0.6737 TrainAcc 0.7300 TestAcc 0.5633 0.7100
epoch 700 LossPred 0.6981 LossAtt 0.6623 TrainAcc 0.7500 TestAcc 0.5638 0.7300
epoch 800 LossPred 0.6868 LossAtt 0.6629 TrainAcc 0.7500 TestAcc 0.5636 0.7400
epoch 900 LossPred 0.6818 LossAtt 0.6439 TrainAcc 0.7500 TestAcc 0.5636 0.7350
epoch 1000 LossPred 0.6713 LossAtt 0.6217 TrainAcc 0.7500 TestAcc 0.5658 0.7350
epoch 1100 LossPred 0.6589 LossAtt 0.5921 TrainAcc 0.7500 TestAcc 0.5603 0.7350
epoch 1200 LossPred 0.6475 LossAtt 0.6111 TrainAcc 0.7500 TestAcc 0.5558 0.7550
epoch 1300 LossPred 0.6229 LossAtt 0.6268 TrainAcc 0.7800 TestAcc 0.5571 0.7700
epoch 1400 LossPred 0.6180 LossAtt 0.6330 TrainAcc 0.7900 TestAcc 0.5651 0.7600
epoch 1500 LossPred 0.5855 LossAtt 0.6230 TrainAcc 0.8000 TestAcc 0.5656 0.7550
epoch 1600 LossPred 0.5727 LossAtt 0.6446 TrainAcc 0.8100 TestAcc 0.5613 0.7600
epoch 1700 LossPred 0.5942 LossAtt 0.6166 TrainAcc 0.7900 TestAcc 0.5598 0.7850
epoch 1800 LossPred 0.6232 LossAtt 0.6316 TrainAcc 0.8300 TestAcc 0.5586 0.7750
epoch 1900 LossPred 0.5815 LossAtt 0.6440 TrainAcc 0.8100 TestAcc 0.5465 0.7650
epoch 2000 LossPred 0.5779 LossAtt 0.6214 TrainAcc 0.8000 TestAcc 0.5485 0.7800
epoch 2100 LossPred 0.5623 LossAtt 0.6355 TrainAcc 0.8300 TestAcc 0.5498 0.8100
epoch 2200 LossPred 0.5565 LossAtt 0.6443 TrainAcc 0.8400 TestAcc 0.5506 0.8050
epoch 2300 LossPred 0.5781 LossAtt 0.6051 TrainAcc 0.8000 TestAcc 0.5666 0.7650
epoch 2400 LossPred 0.5895 LossAtt 0.6344 TrainAcc 0.8200 TestAcc 0.5571 0.7750
epoch 2500 LossPred 0.5691 LossAtt 0.6102 TrainAcc 0.8300 TestAcc 0.5573 0.7850
Optimization Finished!
********** replication  84  **********
epoch   0 LossPred 1.0135 LossAtt 1.0223 TrainAcc 0.5100 TestAcc 0.4950 0.5450
epoch 100 LossPred 0.9401 LossAtt 0.4768 TrainAcc 0.6100 TestAcc 0.5173 0.5950
epoch 200 LossPred 0.9321 LossAtt 0.4249 TrainAcc 0.6100 TestAcc 0.5173 0.5900
epoch 300 LossPred 0.9254 LossAtt 0.4635 TrainAcc 0.6000 TestAcc 0.5063 0.6050
epoch 400 LossPred 0.9154 LossAtt 0.4578 TrainAcc 0.6200 TestAcc 0.5245 0.6250
epoch 500 LossPred 0.8921 LossAtt 0.3904 TrainAcc 0.6200 TestAcc 0.5208 0.6200
epoch 600 LossPred 0.7889 LossAtt 0.6044 TrainAcc 0.6700 TestAcc 0.5508 0.6500
epoch 700 LossPred 0.4601 LossAtt 0.6010 TrainAcc 0.8300 TestAcc 0.7885 0.8400
epoch 800 LossPred 0.3655 LossAtt 0.5574 TrainAcc 0.8900 TestAcc 0.7968 0.8500
epoch 900 LossPred 0.3503 LossAtt 0.5538 TrainAcc 0.8900 TestAcc 0.8013 0.8500
epoch 1000 LossPred 0.4903 LossAtt 0.5501 TrainAcc 0.8400 TestAcc 0.7695 0.7950
epoch 1100 LossPred 0.3423 LossAtt 0.5599 TrainAcc 0.8900 TestAcc 0.8038 0.8850
epoch 1200 LossPred 0.2870 LossAtt 0.6022 TrainAcc 0.9300 TestAcc 0.7955 0.8750
epoch 1300 LossPred 0.2975 LossAtt 0.6228 TrainAcc 0.9100 TestAcc 0.7875 0.8750
epoch 1400 LossPred 0.2566 LossAtt 0.6268 TrainAcc 0.9300 TestAcc 0.7968 0.8700
epoch 1500 LossPred 0.2982 LossAtt 0.6408 TrainAcc 0.9200 TestAcc 0.7993 0.8700
epoch 1600 LossPred 0.2597 LossAtt 0.6038 TrainAcc 0.9300 TestAcc 0.8016 0.8550
epoch 1700 LossPred 0.2621 LossAtt 0.6232 TrainAcc 0.9300 TestAcc 0.8013 0.8650
epoch 1800 LossPred 0.2273 LossAtt 0.5989 TrainAcc 0.9400 TestAcc 0.8013 0.8650
epoch 1900 LossPred 0.2459 LossAtt 0.5728 TrainAcc 0.9300 TestAcc 0.8021 0.8750
epoch 2000 LossPred 0.2224 LossAtt 0.5752 TrainAcc 0.9400 TestAcc 0.8026 0.8750
epoch 2100 LossPred 0.2248 LossAtt 0.5739 TrainAcc 0.9400 TestAcc 0.8003 0.8750
epoch 2200 LossPred 0.2298 LossAtt 0.5521 TrainAcc 0.9300 TestAcc 0.8033 0.8750
epoch 2300 LossPred 0.2238 LossAtt 0.5403 TrainAcc 0.9400 TestAcc 0.8021 0.8800
epoch 2400 LossPred 0.2479 LossAtt 0.5347 TrainAcc 0.9200 TestAcc 0.8026 0.8700
epoch 2500 LossPred 0.2219 LossAtt 0.5331 TrainAcc 0.9400 TestAcc 0.7978 0.8750
Optimization Finished!
********** replication  85  **********
epoch   0 LossPred 0.9677 LossAtt 1.0833 TrainAcc 0.6100 TestAcc 0.5160 0.6100
epoch 100 LossPred 0.9136 LossAtt 0.4382 TrainAcc 0.6400 TestAcc 0.5791 0.6400
epoch 200 LossPred 0.9084 LossAtt 0.4010 TrainAcc 0.6400 TestAcc 0.5791 0.6400
epoch 300 LossPred 0.8894 LossAtt 0.5279 TrainAcc 0.6600 TestAcc 0.5758 0.6450
epoch 400 LossPred 0.8673 LossAtt 0.5373 TrainAcc 0.6700 TestAcc 0.5460 0.6650
epoch 500 LossPred 0.8522 LossAtt 0.5385 TrainAcc 0.6800 TestAcc 0.5425 0.6800
epoch 600 LossPred 0.7991 LossAtt 0.5687 TrainAcc 0.7000 TestAcc 0.5083 0.6850
epoch 700 LossPred 0.7807 LossAtt 0.5512 TrainAcc 0.7200 TestAcc 0.4947 0.6750
epoch 800 LossPred 0.7638 LossAtt 0.5572 TrainAcc 0.7100 TestAcc 0.5048 0.6700
epoch 900 LossPred 0.7569 LossAtt 0.5447 TrainAcc 0.7200 TestAcc 0.5093 0.6550
epoch 1000 LossPred 0.7513 LossAtt 0.5697 TrainAcc 0.7200 TestAcc 0.5095 0.6550
epoch 1100 LossPred 0.7511 LossAtt 0.5530 TrainAcc 0.7200 TestAcc 0.5055 0.6500
epoch 1200 LossPred 0.7439 LossAtt 0.5271 TrainAcc 0.7200 TestAcc 0.5028 0.6350
epoch 1300 LossPred 0.7310 LossAtt 0.5015 TrainAcc 0.7300 TestAcc 0.5078 0.6750
epoch 1400 LossPred 0.7310 LossAtt 0.5267 TrainAcc 0.7300 TestAcc 0.5093 0.6700
epoch 1500 LossPred 0.7273 LossAtt 0.4990 TrainAcc 0.7200 TestAcc 0.5105 0.6500
epoch 1600 LossPred 0.7221 LossAtt 0.4931 TrainAcc 0.7300 TestAcc 0.5158 0.6650
epoch 1700 LossPred 0.7243 LossAtt 0.4952 TrainAcc 0.7300 TestAcc 0.5108 0.6600
epoch 1800 LossPred 0.7065 LossAtt 0.4867 TrainAcc 0.7400 TestAcc 0.5155 0.6550
epoch 1900 LossPred 0.7131 LossAtt 0.4719 TrainAcc 0.7400 TestAcc 0.5135 0.6650
epoch 2000 LossPred 0.7056 LossAtt 0.4620 TrainAcc 0.7200 TestAcc 0.5145 0.6650
epoch 2100 LossPred 0.7165 LossAtt 0.4670 TrainAcc 0.7300 TestAcc 0.5065 0.6850
epoch 2200 LossPred 0.6984 LossAtt 0.4435 TrainAcc 0.7600 TestAcc 0.5080 0.6850
epoch 2300 LossPred 0.6902 LossAtt 0.4578 TrainAcc 0.7700 TestAcc 0.5115 0.6900
epoch 2400 LossPred 0.6834 LossAtt 0.4533 TrainAcc 0.7700 TestAcc 0.5108 0.6950
epoch 2500 LossPred 0.6849 LossAtt 0.4402 TrainAcc 0.7700 TestAcc 0.5120 0.7000
Optimization Finished!
********** replication  86  **********
epoch   0 LossPred 1.0932 LossAtt 1.0309 TrainAcc 0.4100 TestAcc 0.4222 0.4350
epoch 100 LossPred 0.8706 LossAtt 0.5485 TrainAcc 0.6900 TestAcc 0.5468 0.6500
epoch 200 LossPred 0.8199 LossAtt 0.5191 TrainAcc 0.6900 TestAcc 0.5693 0.6850
epoch 300 LossPred 0.8069 LossAtt 0.4678 TrainAcc 0.6900 TestAcc 0.5586 0.6950
epoch 400 LossPred 0.7983 LossAtt 0.4375 TrainAcc 0.7100 TestAcc 0.5453 0.6950
epoch 500 LossPred 0.7770 LossAtt 0.5073 TrainAcc 0.6700 TestAcc 0.5383 0.6900
epoch 600 LossPred 0.7573 LossAtt 0.5325 TrainAcc 0.7200 TestAcc 0.5355 0.7200
epoch 700 LossPred 0.7352 LossAtt 0.5715 TrainAcc 0.7400 TestAcc 0.5360 0.7300
epoch 800 LossPred 0.7094 LossAtt 0.6145 TrainAcc 0.7500 TestAcc 0.5223 0.7450
epoch 900 LossPred 0.6538 LossAtt 0.6397 TrainAcc 0.8000 TestAcc 0.5283 0.7550
epoch 1000 LossPred 0.6403 LossAtt 0.6380 TrainAcc 0.8000 TestAcc 0.5383 0.7850
epoch 1100 LossPred 0.6338 LossAtt 0.5985 TrainAcc 0.8100 TestAcc 0.5375 0.7850
epoch 1200 LossPred 0.6260 LossAtt 0.6263 TrainAcc 0.8100 TestAcc 0.5405 0.7850
epoch 1300 LossPred 0.6006 LossAtt 0.5992 TrainAcc 0.8200 TestAcc 0.5413 0.7850
epoch 1400 LossPred 0.5883 LossAtt 0.6010 TrainAcc 0.8400 TestAcc 0.5415 0.7950
epoch 1500 LossPred 0.6066 LossAtt 0.5569 TrainAcc 0.7900 TestAcc 0.5516 0.7800
epoch 1600 LossPred 0.5712 LossAtt 0.5401 TrainAcc 0.8300 TestAcc 0.5463 0.7850
epoch 1700 LossPred 0.5915 LossAtt 0.5362 TrainAcc 0.8200 TestAcc 0.5333 0.7650
epoch 1800 LossPred 0.5573 LossAtt 0.5181 TrainAcc 0.8600 TestAcc 0.5410 0.7850
epoch 1900 LossPred 0.5743 LossAtt 0.5545 TrainAcc 0.8300 TestAcc 0.5373 0.7900
epoch 2000 LossPred 0.5582 LossAtt 0.5643 TrainAcc 0.8400 TestAcc 0.5303 0.7700
epoch 2100 LossPred 0.5538 LossAtt 0.5705 TrainAcc 0.8600 TestAcc 0.5390 0.7750
epoch 2200 LossPred 0.5325 LossAtt 0.5965 TrainAcc 0.8600 TestAcc 0.5425 0.7800
epoch 2300 LossPred 0.5604 LossAtt 0.5732 TrainAcc 0.8500 TestAcc 0.5418 0.7850
epoch 2400 LossPred 0.6138 LossAtt 0.5896 TrainAcc 0.8000 TestAcc 0.5438 0.7750
epoch 2500 LossPred 0.5603 LossAtt 0.5885 TrainAcc 0.8200 TestAcc 0.5458 0.7750
Optimization Finished!
********** replication  87  **********
epoch   0 LossPred 1.0516 LossAtt 1.0437 TrainAcc 0.5900 TestAcc 0.5040 0.5750
epoch 100 LossPred 0.8531 LossAtt 0.4966 TrainAcc 0.6800 TestAcc 0.5808 0.6600
epoch 200 LossPred 0.8209 LossAtt 0.5160 TrainAcc 0.7000 TestAcc 0.5891 0.6900
epoch 300 LossPred 0.7978 LossAtt 0.5857 TrainAcc 0.7000 TestAcc 0.5903 0.6950
epoch 400 LossPred 0.7838 LossAtt 0.5558 TrainAcc 0.7000 TestAcc 0.5913 0.7000
epoch 500 LossPred 0.7716 LossAtt 0.5220 TrainAcc 0.7400 TestAcc 0.6031 0.7150
epoch 600 LossPred 0.7543 LossAtt 0.4885 TrainAcc 0.7400 TestAcc 0.6031 0.7350
epoch 700 LossPred 0.7369 LossAtt 0.5112 TrainAcc 0.7300 TestAcc 0.6011 0.7450
epoch 800 LossPred 0.7170 LossAtt 0.5037 TrainAcc 0.7400 TestAcc 0.6066 0.7300
epoch 900 LossPred 0.4802 LossAtt 0.5911 TrainAcc 0.8400 TestAcc 0.7798 0.8250
epoch 1000 LossPred 0.2578 LossAtt 0.5519 TrainAcc 0.9300 TestAcc 0.8766 0.8600
epoch 1100 LossPred 0.2236 LossAtt 0.5658 TrainAcc 0.9400 TestAcc 0.8969 0.8750
epoch 1200 LossPred 0.2007 LossAtt 0.5479 TrainAcc 0.9400 TestAcc 0.9024 0.8950
epoch 1300 LossPred 0.2815 LossAtt 0.5416 TrainAcc 0.9100 TestAcc 0.8373 0.8800
epoch 1400 LossPred 0.2340 LossAtt 0.5070 TrainAcc 0.9200 TestAcc 0.8879 0.9050
epoch 1500 LossPred 0.1377 LossAtt 0.5094 TrainAcc 0.9700 TestAcc 0.9079 0.9000
epoch 1600 LossPred 0.2163 LossAtt 0.5108 TrainAcc 0.9200 TestAcc 0.8654 0.8850
epoch 1700 LossPred 0.2630 LossAtt 0.4974 TrainAcc 0.9100 TestAcc 0.8426 0.8750
epoch 1800 LossPred 0.2658 LossAtt 0.4767 TrainAcc 0.9100 TestAcc 0.8251 0.8600
epoch 1900 LossPred 0.0953 LossAtt 0.4977 TrainAcc 0.9900 TestAcc 0.8996 0.9050
epoch 2000 LossPred 0.0952 LossAtt 0.5012 TrainAcc 0.9700 TestAcc 0.8916 0.9000
epoch 2100 LossPred 0.0753 LossAtt 0.5068 TrainAcc 0.9900 TestAcc 0.9097 0.9050
epoch 2200 LossPred 0.1039 LossAtt 0.4907 TrainAcc 0.9800 TestAcc 0.9052 0.9250
epoch 2300 LossPred 0.1068 LossAtt 0.4899 TrainAcc 0.9800 TestAcc 0.8909 0.9050
epoch 2400 LossPred 0.0754 LossAtt 0.4738 TrainAcc 0.9800 TestAcc 0.9064 0.9100
epoch 2500 LossPred 0.0835 LossAtt 0.4685 TrainAcc 0.9800 TestAcc 0.9084 0.9250
Optimization Finished!
********** replication  88  **********
epoch   0 LossPred 1.1196 LossAtt 1.0268 TrainAcc 0.5000 TestAcc 0.4419 0.5200
epoch 100 LossPred 0.8849 LossAtt 0.5428 TrainAcc 0.6500 TestAcc 0.5018 0.6450
epoch 200 LossPred 0.8358 LossAtt 0.5200 TrainAcc 0.6500 TestAcc 0.5400 0.6550
epoch 300 LossPred 0.8120 LossAtt 0.5014 TrainAcc 0.6500 TestAcc 0.5400 0.6650
epoch 400 LossPred 0.8007 LossAtt 0.4867 TrainAcc 0.6600 TestAcc 0.5703 0.6800
epoch 500 LossPred 0.7944 LossAtt 0.4112 TrainAcc 0.6600 TestAcc 0.5756 0.6650
epoch 600 LossPred 0.7526 LossAtt 0.4761 TrainAcc 0.6500 TestAcc 0.5741 0.6450
epoch 700 LossPred 0.5140 LossAtt 0.5292 TrainAcc 0.8100 TestAcc 0.7590 0.8150
epoch 800 LossPred 0.4627 LossAtt 0.5420 TrainAcc 0.8100 TestAcc 0.7775 0.8500
epoch 900 LossPred 0.4741 LossAtt 0.5418 TrainAcc 0.8300 TestAcc 0.7888 0.8100
epoch 1000 LossPred 0.3308 LossAtt 0.5052 TrainAcc 0.9000 TestAcc 0.8168 0.8850
epoch 1100 LossPred 0.3832 LossAtt 0.4748 TrainAcc 0.8600 TestAcc 0.8203 0.8600
epoch 1200 LossPred 0.3399 LossAtt 0.4560 TrainAcc 0.9100 TestAcc 0.8173 0.8850
epoch 1300 LossPred 0.3329 LossAtt 0.4257 TrainAcc 0.9100 TestAcc 0.8211 0.8900
epoch 1400 LossPred 0.3102 LossAtt 0.3979 TrainAcc 0.9200 TestAcc 0.8288 0.8900
epoch 1500 LossPred 0.3253 LossAtt 0.3896 TrainAcc 0.8900 TestAcc 0.8236 0.8850
epoch 1600 LossPred 0.3049 LossAtt 0.3666 TrainAcc 0.8900 TestAcc 0.8356 0.8850
epoch 1700 LossPred 0.3038 LossAtt 0.3522 TrainAcc 0.9000 TestAcc 0.8406 0.8850
epoch 1800 LossPred 0.2915 LossAtt 0.3526 TrainAcc 0.9000 TestAcc 0.8371 0.8950
epoch 1900 LossPred 0.3062 LossAtt 0.3237 TrainAcc 0.8900 TestAcc 0.8238 0.8900
epoch 2000 LossPred 0.3035 LossAtt 0.3264 TrainAcc 0.9000 TestAcc 0.8288 0.8900
epoch 2100 LossPred 0.3146 LossAtt 0.2994 TrainAcc 0.9000 TestAcc 0.8246 0.8900
epoch 2200 LossPred 0.3532 LossAtt 0.3036 TrainAcc 0.8600 TestAcc 0.8116 0.8700
epoch 2300 LossPred 0.3070 LossAtt 0.3048 TrainAcc 0.9000 TestAcc 0.8213 0.9000
epoch 2400 LossPred 0.2746 LossAtt 0.3082 TrainAcc 0.9100 TestAcc 0.8373 0.9150
epoch 2500 LossPred 0.3041 LossAtt 0.3053 TrainAcc 0.9000 TestAcc 0.8213 0.8900
Optimization Finished!
********** replication  89  **********
epoch   0 LossPred 0.9774 LossAtt 1.0077 TrainAcc 0.5700 TestAcc 0.5721 0.5450
epoch 100 LossPred 0.8518 LossAtt 0.6044 TrainAcc 0.6800 TestAcc 0.6029 0.7100
epoch 200 LossPred 0.7082 LossAtt 0.6048 TrainAcc 0.7500 TestAcc 0.6389 0.7450
epoch 300 LossPred 0.5079 LossAtt 0.5976 TrainAcc 0.8500 TestAcc 0.7390 0.8450
epoch 400 LossPred 0.4887 LossAtt 0.6196 TrainAcc 0.8300 TestAcc 0.7628 0.8350
epoch 500 LossPred 0.3913 LossAtt 0.5930 TrainAcc 0.8900 TestAcc 0.7945 0.8600
epoch 600 LossPred 0.4147 LossAtt 0.5840 TrainAcc 0.8800 TestAcc 0.7770 0.8600
epoch 700 LossPred 0.3665 LossAtt 0.5747 TrainAcc 0.8800 TestAcc 0.8198 0.8600
epoch 800 LossPred 0.4578 LossAtt 0.5644 TrainAcc 0.8300 TestAcc 0.8031 0.8400
epoch 900 LossPred 0.4040 LossAtt 0.5184 TrainAcc 0.8700 TestAcc 0.7883 0.8550
epoch 1000 LossPred 0.4105 LossAtt 0.5114 TrainAcc 0.8800 TestAcc 0.7775 0.8600
epoch 1100 LossPred 0.4078 LossAtt 0.5215 TrainAcc 0.8600 TestAcc 0.8161 0.8500
epoch 1200 LossPred 0.4874 LossAtt 0.5016 TrainAcc 0.8300 TestAcc 0.7447 0.8200
epoch 1300 LossPred 0.4747 LossAtt 0.4929 TrainAcc 0.8600 TestAcc 0.7432 0.8300
epoch 1400 LossPred 0.4060 LossAtt 0.5014 TrainAcc 0.8600 TestAcc 0.7613 0.8500
epoch 1500 LossPred 0.5376 LossAtt 0.4783 TrainAcc 0.8000 TestAcc 0.7302 0.8150
epoch 1600 LossPred 0.3340 LossAtt 0.4948 TrainAcc 0.9000 TestAcc 0.8036 0.8700
epoch 1700 LossPred 0.3887 LossAtt 0.5032 TrainAcc 0.8800 TestAcc 0.7938 0.8350
epoch 1800 LossPred 0.6719 LossAtt 0.4830 TrainAcc 0.7800 TestAcc 0.7117 0.7800
epoch 1900 LossPred 0.3238 LossAtt 0.4904 TrainAcc 0.8900 TestAcc 0.8008 0.8800
epoch 2000 LossPred 0.3397 LossAtt 0.4943 TrainAcc 0.8800 TestAcc 0.7928 0.8700
epoch 2100 LossPred 0.3388 LossAtt 0.4971 TrainAcc 0.8800 TestAcc 0.7945 0.8750
epoch 2200 LossPred 0.5412 LossAtt 0.4953 TrainAcc 0.7800 TestAcc 0.7535 0.7700
epoch 2300 LossPred 0.2796 LossAtt 0.4861 TrainAcc 0.9000 TestAcc 0.8046 0.8900
epoch 2400 LossPred 0.3021 LossAtt 0.4698 TrainAcc 0.9000 TestAcc 0.7928 0.8950
epoch 2500 LossPred 0.3398 LossAtt 0.4563 TrainAcc 0.8900 TestAcc 0.7808 0.8750
Optimization Finished!
********** replication  90  **********
epoch   0 LossPred 1.1166 LossAtt 1.0137 TrainAcc 0.5300 TestAcc 0.5008 0.5550
epoch 100 LossPred 0.9081 LossAtt 0.4003 TrainAcc 0.6500 TestAcc 0.5731 0.6500
epoch 200 LossPred 0.8530 LossAtt 0.4170 TrainAcc 0.6500 TestAcc 0.5731 0.6500
epoch 300 LossPred 0.6483 LossAtt 0.5124 TrainAcc 0.7900 TestAcc 0.7115 0.7800
epoch 400 LossPred 0.4086 LossAtt 0.4413 TrainAcc 0.8500 TestAcc 0.8101 0.8400
epoch 500 LossPred 0.3944 LossAtt 0.4344 TrainAcc 0.8500 TestAcc 0.7945 0.8300
epoch 600 LossPred 0.3737 LossAtt 0.4465 TrainAcc 0.8700 TestAcc 0.8186 0.8600
epoch 700 LossPred 0.3552 LossAtt 0.4672 TrainAcc 0.8800 TestAcc 0.8261 0.8800
epoch 800 LossPred 0.3421 LossAtt 0.4501 TrainAcc 0.9000 TestAcc 0.8261 0.8500
epoch 900 LossPred 0.3245 LossAtt 0.4560 TrainAcc 0.8900 TestAcc 0.8353 0.8500
epoch 1000 LossPred 0.2825 LossAtt 0.4594 TrainAcc 0.9000 TestAcc 0.8373 0.8600
epoch 1100 LossPred 0.3540 LossAtt 0.4672 TrainAcc 0.8800 TestAcc 0.8181 0.8800
epoch 1200 LossPred 0.3138 LossAtt 0.4453 TrainAcc 0.9200 TestAcc 0.8323 0.8550
epoch 1300 LossPred 0.2979 LossAtt 0.4268 TrainAcc 0.8900 TestAcc 0.8353 0.8650
epoch 1400 LossPred 0.2567 LossAtt 0.4481 TrainAcc 0.9100 TestAcc 0.8398 0.8600
epoch 1500 LossPred 0.2969 LossAtt 0.4209 TrainAcc 0.9100 TestAcc 0.8441 0.8650
epoch 1600 LossPred 0.2434 LossAtt 0.4289 TrainAcc 0.9100 TestAcc 0.8466 0.8650
epoch 1700 LossPred 0.2758 LossAtt 0.4281 TrainAcc 0.9100 TestAcc 0.8428 0.8500
epoch 1800 LossPred 0.2715 LossAtt 0.4329 TrainAcc 0.9100 TestAcc 0.8438 0.8650
epoch 1900 LossPred 0.2354 LossAtt 0.4222 TrainAcc 0.9100 TestAcc 0.8456 0.8600
epoch 2000 LossPred 0.2698 LossAtt 0.4432 TrainAcc 0.8900 TestAcc 0.8366 0.8800
epoch 2100 LossPred 0.2035 LossAtt 0.4201 TrainAcc 0.9600 TestAcc 0.8471 0.8750
epoch 2200 LossPred 0.2046 LossAtt 0.4370 TrainAcc 0.9400 TestAcc 0.8531 0.9000
epoch 2300 LossPred 0.2131 LossAtt 0.4400 TrainAcc 0.9400 TestAcc 0.8446 0.9050
epoch 2400 LossPred 0.1509 LossAtt 0.4319 TrainAcc 0.9700 TestAcc 0.8611 0.9100
epoch 2500 LossPred 0.1501 LossAtt 0.4085 TrainAcc 0.9700 TestAcc 0.8626 0.9250
Optimization Finished!
********** replication  91  **********
epoch   0 LossPred 0.9932 LossAtt 0.9891 TrainAcc 0.5300 TestAcc 0.5375 0.5450
epoch 100 LossPred 0.9483 LossAtt 0.4899 TrainAcc 0.6000 TestAcc 0.5781 0.6000
epoch 200 LossPred 0.9417 LossAtt 0.2278 TrainAcc 0.6000 TestAcc 0.5781 0.6000
epoch 300 LossPred 0.9413 LossAtt 0.1453 TrainAcc 0.6000 TestAcc 0.5781 0.6000
epoch 400 LossPred 0.9413 LossAtt 0.1427 TrainAcc 0.6000 TestAcc 0.5781 0.6000
epoch 500 LossPred 0.9412 LossAtt 0.1400 TrainAcc 0.6000 TestAcc 0.5781 0.6000
epoch 600 LossPred 0.9411 LossAtt 0.1621 TrainAcc 0.6000 TestAcc 0.5781 0.6000
epoch 700 LossPred 0.9409 LossAtt 0.1887 TrainAcc 0.6000 TestAcc 0.5781 0.6000
epoch 800 LossPred 0.9405 LossAtt 0.2582 TrainAcc 0.6000 TestAcc 0.5781 0.6000
epoch 900 LossPred 0.9292 LossAtt 0.4907 TrainAcc 0.6300 TestAcc 0.6311 0.6700
epoch 1000 LossPred 0.8750 LossAtt 0.3556 TrainAcc 0.6400 TestAcc 0.5536 0.6300
epoch 1100 LossPred 0.8680 LossAtt 0.3095 TrainAcc 0.6400 TestAcc 0.6319 0.6350
epoch 1200 LossPred 0.8683 LossAtt 0.3022 TrainAcc 0.6400 TestAcc 0.6274 0.6300
epoch 1300 LossPred 0.8407 LossAtt 0.2915 TrainAcc 0.6900 TestAcc 0.6512 0.6650
epoch 1400 LossPred 0.8837 LossAtt 0.2769 TrainAcc 0.6200 TestAcc 0.6039 0.6200
epoch 1500 LossPred 0.8813 LossAtt 0.2643 TrainAcc 0.6200 TestAcc 0.6024 0.6200
epoch 1600 LossPred 0.8800 LossAtt 0.2622 TrainAcc 0.6200 TestAcc 0.5993 0.6200
epoch 1700 LossPred 0.8869 LossAtt 0.2612 TrainAcc 0.6200 TestAcc 0.5913 0.6100
epoch 1800 LossPred 0.8775 LossAtt 0.2636 TrainAcc 0.6200 TestAcc 0.6004 0.6250
epoch 1900 LossPred 0.8764 LossAtt 0.2597 TrainAcc 0.6200 TestAcc 0.5993 0.6200
epoch 2000 LossPred 0.8760 LossAtt 0.2566 TrainAcc 0.6200 TestAcc 0.5946 0.6250
epoch 2100 LossPred 0.8820 LossAtt 0.2442 TrainAcc 0.6200 TestAcc 0.5881 0.6100
epoch 2200 LossPred 0.8747 LossAtt 0.2380 TrainAcc 0.6200 TestAcc 0.5966 0.6150
epoch 2300 LossPred 0.8743 LossAtt 0.2282 TrainAcc 0.6200 TestAcc 0.5968 0.6200
epoch 2400 LossPred 0.8744 LossAtt 0.2326 TrainAcc 0.6200 TestAcc 0.5948 0.6250
epoch 2500 LossPred 0.8799 LossAtt 0.2118 TrainAcc 0.6200 TestAcc 0.5903 0.6150
Optimization Finished!
********** replication  92  **********
epoch   0 LossPred 1.1311 LossAtt 1.0049 TrainAcc 0.5300 TestAcc 0.4822 0.5300
epoch 100 LossPred 0.9511 LossAtt 0.5508 TrainAcc 0.6200 TestAcc 0.5698 0.6200
epoch 200 LossPred 0.9167 LossAtt 0.5069 TrainAcc 0.6200 TestAcc 0.5698 0.6200
epoch 300 LossPred 0.8898 LossAtt 0.5082 TrainAcc 0.6300 TestAcc 0.5981 0.6350
epoch 400 LossPred 0.7807 LossAtt 0.5805 TrainAcc 0.7400 TestAcc 0.7608 0.7400
epoch 500 LossPred 0.6457 LossAtt 0.4836 TrainAcc 0.8000 TestAcc 0.7908 0.7900
epoch 600 LossPred 0.6535 LossAtt 0.4482 TrainAcc 0.7800 TestAcc 0.8056 0.7850
epoch 700 LossPred 0.7803 LossAtt 0.4630 TrainAcc 0.7100 TestAcc 0.7320 0.6800
epoch 800 LossPred 0.9568 LossAtt 0.3860 TrainAcc 0.6400 TestAcc 0.5983 0.6400
epoch 900 LossPred 0.7946 LossAtt 0.4136 TrainAcc 0.7200 TestAcc 0.7165 0.7200
epoch 1000 LossPred 0.7719 LossAtt 0.4324 TrainAcc 0.7100 TestAcc 0.7390 0.7250
epoch 1100 LossPred 0.6372 LossAtt 0.4067 TrainAcc 0.7800 TestAcc 0.7740 0.7400
epoch 1200 LossPred 0.6517 LossAtt 0.3942 TrainAcc 0.7800 TestAcc 0.7913 0.7850
epoch 1300 LossPred 0.7744 LossAtt 0.4184 TrainAcc 0.6600 TestAcc 0.5723 0.6600
epoch 1400 LossPred 0.5773 LossAtt 0.4150 TrainAcc 0.8100 TestAcc 0.7830 0.7850
epoch 1500 LossPred 0.5635 LossAtt 0.4049 TrainAcc 0.8000 TestAcc 0.7903 0.7950
epoch 1600 LossPred 0.5468 LossAtt 0.4070 TrainAcc 0.8100 TestAcc 0.7945 0.7900
epoch 1700 LossPred 0.5615 LossAtt 0.4096 TrainAcc 0.8100 TestAcc 0.7910 0.7950
epoch 1800 LossPred 0.9978 LossAtt 0.3465 TrainAcc 0.6300 TestAcc 0.5823 0.6200
epoch 1900 LossPred 0.8955 LossAtt 0.3377 TrainAcc 0.6900 TestAcc 0.6204 0.6550
epoch 2000 LossPred 0.8939 LossAtt 0.3468 TrainAcc 0.6600 TestAcc 0.6154 0.6600
epoch 2100 LossPred 0.8913 LossAtt 0.3354 TrainAcc 0.6600 TestAcc 0.6156 0.6550
epoch 2200 LossPred 0.8899 LossAtt 0.3362 TrainAcc 0.6600 TestAcc 0.6189 0.6550
epoch 2300 LossPred 0.8862 LossAtt 0.3499 TrainAcc 0.6800 TestAcc 0.6326 0.6650
epoch 2400 LossPred 0.8850 LossAtt 0.3318 TrainAcc 0.6800 TestAcc 0.6329 0.6700
epoch 2500 LossPred 0.8831 LossAtt 0.3271 TrainAcc 0.6800 TestAcc 0.6339 0.6800
Optimization Finished!
********** replication  93  **********
epoch   0 LossPred 1.1384 LossAtt 1.0381 TrainAcc 0.4900 TestAcc 0.5165 0.5050
epoch 100 LossPred 0.9793 LossAtt 0.5885 TrainAcc 0.5700 TestAcc 0.5846 0.5650
epoch 200 LossPred 0.9350 LossAtt 0.6495 TrainAcc 0.6000 TestAcc 0.5683 0.5750
epoch 300 LossPred 0.8542 LossAtt 0.7616 TrainAcc 0.6800 TestAcc 0.5060 0.6800
epoch 400 LossPred 0.7911 LossAtt 0.7885 TrainAcc 0.7000 TestAcc 0.5118 0.6850
epoch 500 LossPred 0.7517 LossAtt 0.7785 TrainAcc 0.7300 TestAcc 0.5103 0.7000
epoch 600 LossPred 0.6835 LossAtt 0.7700 TrainAcc 0.7500 TestAcc 0.5030 0.7250
epoch 700 LossPred 0.6512 LossAtt 0.7416 TrainAcc 0.7900 TestAcc 0.5098 0.7200
epoch 800 LossPred 0.6276 LossAtt 0.7375 TrainAcc 0.8000 TestAcc 0.5145 0.7250
epoch 900 LossPred 0.6146 LossAtt 0.7086 TrainAcc 0.7900 TestAcc 0.5100 0.7350
epoch 1000 LossPred 0.5971 LossAtt 0.6873 TrainAcc 0.7800 TestAcc 0.5163 0.7350
epoch 1100 LossPred 0.6422 LossAtt 0.6993 TrainAcc 0.7900 TestAcc 0.5105 0.7500
epoch 1200 LossPred 0.5890 LossAtt 0.6625 TrainAcc 0.8200 TestAcc 0.5080 0.7300
epoch 1300 LossPred 0.5823 LossAtt 0.6670 TrainAcc 0.8000 TestAcc 0.5148 0.7450
epoch 1400 LossPred 0.5802 LossAtt 0.6563 TrainAcc 0.8200 TestAcc 0.5205 0.7600
epoch 1500 LossPred 0.5759 LossAtt 0.6406 TrainAcc 0.8000 TestAcc 0.5243 0.7600
epoch 1600 LossPred 0.5596 LossAtt 0.6568 TrainAcc 0.8200 TestAcc 0.5228 0.7650
epoch 1700 LossPred 0.5546 LossAtt 0.6456 TrainAcc 0.8200 TestAcc 0.5188 0.7500
epoch 1800 LossPred 0.5566 LossAtt 0.6530 TrainAcc 0.8100 TestAcc 0.5300 0.7600
epoch 1900 LossPred 0.5445 LossAtt 0.6466 TrainAcc 0.8400 TestAcc 0.5200 0.7400
epoch 2000 LossPred 0.5259 LossAtt 0.6602 TrainAcc 0.8400 TestAcc 0.5175 0.7400
epoch 2100 LossPred 0.5070 LossAtt 0.6470 TrainAcc 0.8400 TestAcc 0.5178 0.7800
epoch 2200 LossPred 0.5022 LossAtt 0.6492 TrainAcc 0.8400 TestAcc 0.5115 0.7550
epoch 2300 LossPred 0.4956 LossAtt 0.6336 TrainAcc 0.8400 TestAcc 0.5133 0.7650
epoch 2400 LossPred 0.5010 LossAtt 0.6538 TrainAcc 0.8500 TestAcc 0.5100 0.7700
epoch 2500 LossPred 0.4890 LossAtt 0.6534 TrainAcc 0.8600 TestAcc 0.5158 0.7650
Optimization Finished!
********** replication  94  **********
epoch   0 LossPred 1.0410 LossAtt 0.9977 TrainAcc 0.3600 TestAcc 0.4027 0.3800
epoch 100 LossPred 0.9083 LossAtt 0.4788 TrainAcc 0.6000 TestAcc 0.4852 0.6150
epoch 200 LossPred 0.8842 LossAtt 0.4486 TrainAcc 0.5900 TestAcc 0.5190 0.6000
epoch 300 LossPred 0.8692 LossAtt 0.3893 TrainAcc 0.6700 TestAcc 0.5693 0.6600
epoch 400 LossPred 0.8268 LossAtt 0.4831 TrainAcc 0.6700 TestAcc 0.5696 0.6650
epoch 500 LossPred 0.7119 LossAtt 0.5722 TrainAcc 0.7100 TestAcc 0.7543 0.7100
epoch 600 LossPred 0.5519 LossAtt 0.5740 TrainAcc 0.7600 TestAcc 0.7995 0.8350
epoch 700 LossPred 0.5136 LossAtt 0.5061 TrainAcc 0.8100 TestAcc 0.8293 0.8150
epoch 800 LossPred 0.4905 LossAtt 0.4967 TrainAcc 0.8000 TestAcc 0.8306 0.8300
epoch 900 LossPred 0.4506 LossAtt 0.5065 TrainAcc 0.8200 TestAcc 0.8346 0.8400
epoch 1000 LossPred 0.4868 LossAtt 0.4991 TrainAcc 0.8100 TestAcc 0.8201 0.8200
epoch 1100 LossPred 0.6211 LossAtt 0.4904 TrainAcc 0.7600 TestAcc 0.7412 0.7750
epoch 1200 LossPred 0.6042 LossAtt 0.5002 TrainAcc 0.7600 TestAcc 0.7948 0.7450
epoch 1300 LossPred 0.4045 LossAtt 0.4953 TrainAcc 0.8600 TestAcc 0.8418 0.8400
epoch 1400 LossPred 0.3900 LossAtt 0.5050 TrainAcc 0.8600 TestAcc 0.8428 0.8450
epoch 1500 LossPred 0.4567 LossAtt 0.5153 TrainAcc 0.8300 TestAcc 0.8066 0.8500
epoch 1600 LossPred 0.4994 LossAtt 0.5039 TrainAcc 0.8100 TestAcc 0.7870 0.8050
epoch 1700 LossPred 0.3890 LossAtt 0.4853 TrainAcc 0.8800 TestAcc 0.8443 0.8600
epoch 1800 LossPred 0.3873 LossAtt 0.5028 TrainAcc 0.8900 TestAcc 0.8421 0.8700
epoch 1900 LossPred 0.3743 LossAtt 0.4963 TrainAcc 0.8800 TestAcc 0.8338 0.8700
epoch 2000 LossPred 0.4136 LossAtt 0.4877 TrainAcc 0.8300 TestAcc 0.8201 0.8700
epoch 2100 LossPred 0.4457 LossAtt 0.4996 TrainAcc 0.8300 TestAcc 0.8086 0.8450
epoch 2200 LossPred 0.3861 LossAtt 0.4782 TrainAcc 0.8600 TestAcc 0.8378 0.8800
epoch 2300 LossPred 0.3948 LossAtt 0.4870 TrainAcc 0.8700 TestAcc 0.8378 0.8750
epoch 2400 LossPred 0.3546 LossAtt 0.4815 TrainAcc 0.9000 TestAcc 0.8428 0.8900
epoch 2500 LossPred 0.6100 LossAtt 0.4859 TrainAcc 0.7900 TestAcc 0.7660 0.7900
Optimization Finished!
********** replication  95  **********
epoch   0 LossPred 1.2389 LossAtt 0.9897 TrainAcc 0.4100 TestAcc 0.4810 0.3950
epoch 100 LossPred 0.9254 LossAtt 0.4202 TrainAcc 0.6300 TestAcc 0.5848 0.6300
epoch 200 LossPred 0.9090 LossAtt 0.3994 TrainAcc 0.6300 TestAcc 0.5848 0.6300
epoch 300 LossPred 0.8872 LossAtt 0.4702 TrainAcc 0.6300 TestAcc 0.6061 0.6650
epoch 400 LossPred 0.8423 LossAtt 0.5312 TrainAcc 0.6700 TestAcc 0.5978 0.6750
epoch 500 LossPred 0.8098 LossAtt 0.5012 TrainAcc 0.6800 TestAcc 0.5991 0.6850
epoch 600 LossPred 0.7026 LossAtt 0.5497 TrainAcc 0.7600 TestAcc 0.6554 0.7250
epoch 700 LossPred 0.5651 LossAtt 0.5558 TrainAcc 0.8200 TestAcc 0.7540 0.7900
epoch 800 LossPred 0.4820 LossAtt 0.5260 TrainAcc 0.8800 TestAcc 0.7625 0.8200
epoch 900 LossPred 0.4625 LossAtt 0.5401 TrainAcc 0.8600 TestAcc 0.7513 0.8300
epoch 1000 LossPred 0.4190 LossAtt 0.5178 TrainAcc 0.8700 TestAcc 0.7533 0.8450
epoch 1100 LossPred 0.4785 LossAtt 0.4994 TrainAcc 0.8600 TestAcc 0.7402 0.8200
epoch 1200 LossPred 0.4127 LossAtt 0.4616 TrainAcc 0.8700 TestAcc 0.7497 0.8150
epoch 1300 LossPred 0.4076 LossAtt 0.4720 TrainAcc 0.8700 TestAcc 0.7487 0.8200
epoch 1400 LossPred 0.4873 LossAtt 0.4701 TrainAcc 0.8200 TestAcc 0.7610 0.8400
epoch 1500 LossPred 0.4203 LossAtt 0.4726 TrainAcc 0.8700 TestAcc 0.7723 0.8550
epoch 1600 LossPred 0.4398 LossAtt 0.4603 TrainAcc 0.8600 TestAcc 0.7635 0.8500
epoch 1700 LossPred 0.4186 LossAtt 0.4674 TrainAcc 0.8600 TestAcc 0.7713 0.8600
epoch 1800 LossPred 0.8980 LossAtt 0.4682 TrainAcc 0.6800 TestAcc 0.6707 0.7000
epoch 1900 LossPred 0.3541 LossAtt 0.4627 TrainAcc 0.8900 TestAcc 0.7700 0.8450
epoch 2000 LossPred 0.3395 LossAtt 0.4526 TrainAcc 0.9100 TestAcc 0.7703 0.8550
epoch 2100 LossPred 0.3864 LossAtt 0.4531 TrainAcc 0.8700 TestAcc 0.7653 0.8500
epoch 2200 LossPred 0.3214 LossAtt 0.4760 TrainAcc 0.9100 TestAcc 0.7755 0.8550
epoch 2300 LossPred 0.3932 LossAtt 0.4476 TrainAcc 0.8700 TestAcc 0.7668 0.8450
epoch 2400 LossPred 0.4461 LossAtt 0.4630 TrainAcc 0.8400 TestAcc 0.7718 0.8100
epoch 2500 LossPred 0.3064 LossAtt 0.4593 TrainAcc 0.9100 TestAcc 0.7795 0.8500
Optimization Finished!
********** replication  96  **********
epoch   0 LossPred 1.1014 LossAtt 1.0108 TrainAcc 0.5000 TestAcc 0.4317 0.5050
epoch 100 LossPred 0.9629 LossAtt 0.5756 TrainAcc 0.5900 TestAcc 0.5408 0.5950
epoch 200 LossPred 0.9432 LossAtt 0.5742 TrainAcc 0.6000 TestAcc 0.5731 0.6050
epoch 300 LossPred 0.9336 LossAtt 0.5721 TrainAcc 0.6000 TestAcc 0.5906 0.5900
epoch 400 LossPred 0.8962 LossAtt 0.6187 TrainAcc 0.6400 TestAcc 0.5806 0.5950
epoch 500 LossPred 0.4142 LossAtt 0.5590 TrainAcc 0.8800 TestAcc 0.8046 0.8150
epoch 600 LossPred 0.5876 LossAtt 0.5154 TrainAcc 0.8100 TestAcc 0.7367 0.7550
epoch 700 LossPred 0.5485 LossAtt 0.5110 TrainAcc 0.8300 TestAcc 0.7635 0.7950
epoch 800 LossPred 0.5415 LossAtt 0.5087 TrainAcc 0.8300 TestAcc 0.7705 0.8000
epoch 900 LossPred 0.5375 LossAtt 0.4900 TrainAcc 0.8200 TestAcc 0.7728 0.7950
epoch 1000 LossPred 0.3769 LossAtt 0.4805 TrainAcc 0.9000 TestAcc 0.8006 0.8100
epoch 1100 LossPred 0.3572 LossAtt 0.4658 TrainAcc 0.9000 TestAcc 0.8126 0.8250
epoch 1200 LossPred 0.3189 LossAtt 0.4161 TrainAcc 0.9000 TestAcc 0.8016 0.8250
epoch 1300 LossPred 0.3265 LossAtt 0.4157 TrainAcc 0.9000 TestAcc 0.8103 0.8450
epoch 1400 LossPred 0.3638 LossAtt 0.3987 TrainAcc 0.8900 TestAcc 0.7980 0.8300
epoch 1500 LossPred 0.3599 LossAtt 0.3863 TrainAcc 0.8900 TestAcc 0.7925 0.8200
epoch 1600 LossPred 0.3617 LossAtt 0.3998 TrainAcc 0.8900 TestAcc 0.7990 0.8350
epoch 1700 LossPred 0.3082 LossAtt 0.3662 TrainAcc 0.9100 TestAcc 0.7928 0.8700
epoch 1800 LossPred 0.3025 LossAtt 0.3366 TrainAcc 0.9100 TestAcc 0.7938 0.8700
epoch 1900 LossPred 0.3392 LossAtt 0.3523 TrainAcc 0.9100 TestAcc 0.7970 0.8750
epoch 2000 LossPred 0.4648 LossAtt 0.3689 TrainAcc 0.8600 TestAcc 0.7900 0.8400
epoch 2100 LossPred 1.6487 LossAtt 0.3842 TrainAcc 0.5200 TestAcc 0.5943 0.5300
epoch 2200 LossPred 1.0120 LossAtt 0.3267 TrainAcc 0.4200 TestAcc 0.4427 0.4150
epoch 2300 LossPred 0.9817 LossAtt 0.3463 TrainAcc 0.5400 TestAcc 0.5963 0.5350
epoch 2400 LossPred 0.9655 LossAtt 0.3333 TrainAcc 0.6000 TestAcc 0.5776 0.6050
epoch 2500 LossPred 0.9564 LossAtt 0.3273 TrainAcc 0.6000 TestAcc 0.5781 0.6100
Optimization Finished!
********** replication  97  **********
epoch   0 LossPred 1.0418 LossAtt 1.0092 TrainAcc 0.4800 TestAcc 0.5023 0.4750
epoch 100 LossPred 0.9047 LossAtt 0.4951 TrainAcc 0.6200 TestAcc 0.5701 0.6200
epoch 200 LossPred 0.8145 LossAtt 0.6279 TrainAcc 0.6500 TestAcc 0.5776 0.6750
epoch 300 LossPred 0.7620 LossAtt 0.5957 TrainAcc 0.6800 TestAcc 0.5425 0.6600
epoch 400 LossPred 0.7381 LossAtt 0.5758 TrainAcc 0.7100 TestAcc 0.5463 0.6650
epoch 500 LossPred 0.7239 LossAtt 0.5712 TrainAcc 0.7000 TestAcc 0.5493 0.6500
epoch 600 LossPred 0.7157 LossAtt 0.5653 TrainAcc 0.7100 TestAcc 0.5360 0.6800
epoch 700 LossPred 0.7138 LossAtt 0.5935 TrainAcc 0.7100 TestAcc 0.5338 0.6850
epoch 800 LossPred 0.7052 LossAtt 0.5840 TrainAcc 0.7100 TestAcc 0.5350 0.6700
epoch 900 LossPred 0.7134 LossAtt 0.5451 TrainAcc 0.7200 TestAcc 0.5463 0.6650
epoch 1000 LossPred 0.7279 LossAtt 0.5354 TrainAcc 0.7100 TestAcc 0.5428 0.6600
epoch 1100 LossPred 0.7405 LossAtt 0.5384 TrainAcc 0.6900 TestAcc 0.5465 0.6700
epoch 1200 LossPred 0.7274 LossAtt 0.4986 TrainAcc 0.7100 TestAcc 0.5458 0.6750
epoch 1300 LossPred 0.7372 LossAtt 0.4811 TrainAcc 0.7000 TestAcc 0.5405 0.6650
epoch 1400 LossPred 0.7145 LossAtt 0.4829 TrainAcc 0.7100 TestAcc 0.5318 0.6700
epoch 1500 LossPred 0.7143 LossAtt 0.5028 TrainAcc 0.7100 TestAcc 0.5308 0.7000
epoch 1600 LossPred 0.7028 LossAtt 0.5085 TrainAcc 0.7100 TestAcc 0.5293 0.6850
epoch 1700 LossPred 0.7464 LossAtt 0.5467 TrainAcc 0.7200 TestAcc 0.5375 0.6850
epoch 1800 LossPred 0.6768 LossAtt 0.5247 TrainAcc 0.7300 TestAcc 0.5383 0.7000
epoch 1900 LossPred 0.6718 LossAtt 0.5243 TrainAcc 0.7400 TestAcc 0.5388 0.7150
epoch 2000 LossPred 0.6756 LossAtt 0.5263 TrainAcc 0.7300 TestAcc 0.5393 0.7000
epoch 2100 LossPred 0.6643 LossAtt 0.5383 TrainAcc 0.7400 TestAcc 0.5333 0.7100
epoch 2200 LossPred 0.6602 LossAtt 0.5325 TrainAcc 0.7400 TestAcc 0.5323 0.7150
epoch 2300 LossPred 0.6625 LossAtt 0.5322 TrainAcc 0.7300 TestAcc 0.5358 0.7150
epoch 2400 LossPred 0.6638 LossAtt 0.5349 TrainAcc 0.7200 TestAcc 0.5400 0.7100
epoch 2500 LossPred 0.6628 LossAtt 0.5300 TrainAcc 0.7200 TestAcc 0.5400 0.7100
Optimization Finished!
********** replication  98  **********
epoch   0 LossPred 1.2031 LossAtt 1.0222 TrainAcc 0.4000 TestAcc 0.4515 0.4350
epoch 100 LossPred 0.9799 LossAtt 0.5264 TrainAcc 0.5000 TestAcc 0.5248 0.5300
epoch 200 LossPred 0.9545 LossAtt 0.4280 TrainAcc 0.6100 TestAcc 0.6251 0.6050
epoch 300 LossPred 0.9366 LossAtt 0.4186 TrainAcc 0.6500 TestAcc 0.6116 0.6550
epoch 400 LossPred 0.8321 LossAtt 0.5491 TrainAcc 0.6800 TestAcc 0.6309 0.6600
epoch 500 LossPred 0.5476 LossAtt 0.4685 TrainAcc 0.8100 TestAcc 0.8038 0.8050
epoch 600 LossPred 0.4661 LossAtt 0.5051 TrainAcc 0.8200 TestAcc 0.7698 0.8200
epoch 700 LossPred 0.4180 LossAtt 0.5394 TrainAcc 0.8600 TestAcc 0.8173 0.8450
epoch 800 LossPred 0.3588 LossAtt 0.5559 TrainAcc 0.8700 TestAcc 0.8323 0.8550
epoch 900 LossPred 0.3941 LossAtt 0.5178 TrainAcc 0.8500 TestAcc 0.7920 0.8300
epoch 1000 LossPred 0.3493 LossAtt 0.5025 TrainAcc 0.8700 TestAcc 0.8161 0.8600
epoch 1100 LossPred 0.3438 LossAtt 0.5049 TrainAcc 0.8700 TestAcc 0.8256 0.8750
epoch 1200 LossPred 0.3473 LossAtt 0.4890 TrainAcc 0.8700 TestAcc 0.8258 0.8400
epoch 1300 LossPred 0.3394 LossAtt 0.4595 TrainAcc 0.8700 TestAcc 0.8221 0.8700
epoch 1400 LossPred 0.3422 LossAtt 0.4746 TrainAcc 0.8700 TestAcc 0.8138 0.8600
epoch 1500 LossPred 0.3160 LossAtt 0.4789 TrainAcc 0.8800 TestAcc 0.8396 0.8550
epoch 1600 LossPred 0.3128 LossAtt 0.4732 TrainAcc 0.8800 TestAcc 0.8371 0.8700
epoch 1700 LossPred 0.3437 LossAtt 0.4509 TrainAcc 0.8700 TestAcc 0.8366 0.8350
epoch 1800 LossPred 0.3350 LossAtt 0.4429 TrainAcc 0.8800 TestAcc 0.8138 0.8600
epoch 1900 LossPred 0.3443 LossAtt 0.4668 TrainAcc 0.8600 TestAcc 0.8216 0.8500
epoch 2000 LossPred 0.3317 LossAtt 0.4642 TrainAcc 0.8700 TestAcc 0.8441 0.8650
epoch 2100 LossPred 0.4606 LossAtt 0.4899 TrainAcc 0.8300 TestAcc 0.7525 0.8200
epoch 2200 LossPred 0.2830 LossAtt 0.4666 TrainAcc 0.8900 TestAcc 0.8448 0.8700
epoch 2300 LossPred 0.3177 LossAtt 0.4900 TrainAcc 0.8700 TestAcc 0.8516 0.8750
epoch 2400 LossPred 0.2340 LossAtt 0.4785 TrainAcc 0.9100 TestAcc 0.8751 0.8750
epoch 2500 LossPred 0.1971 LossAtt 0.4836 TrainAcc 0.9200 TestAcc 0.8871 0.9000
Optimization Finished!
********** replication  99  **********
epoch   0 LossPred 1.0133 LossAtt 1.0315 TrainAcc 0.5200 TestAcc 0.4575 0.5100
epoch 100 LossPred 0.9105 LossAtt 0.3845 TrainAcc 0.6300 TestAcc 0.5716 0.6300
epoch 200 LossPred 0.7670 LossAtt 0.4249 TrainAcc 0.7300 TestAcc 0.7097 0.7000
epoch 300 LossPred 0.7728 LossAtt 0.3932 TrainAcc 0.7100 TestAcc 0.7170 0.6950
epoch 400 LossPred 0.6297 LossAtt 0.3557 TrainAcc 0.7900 TestAcc 0.8016 0.7700
epoch 500 LossPred 0.7437 LossAtt 0.3029 TrainAcc 0.7300 TestAcc 0.7092 0.6850
epoch 600 LossPred 0.7397 LossAtt 0.3347 TrainAcc 0.7200 TestAcc 0.7320 0.7250
epoch 700 LossPred 0.6864 LossAtt 0.3104 TrainAcc 0.7900 TestAcc 0.7430 0.7550
epoch 800 LossPred 0.8534 LossAtt 0.3086 TrainAcc 0.6700 TestAcc 0.6291 0.6500
epoch 900 LossPred 0.6857 LossAtt 0.3182 TrainAcc 0.7800 TestAcc 0.7500 0.7550
epoch 1000 LossPred 0.5380 LossAtt 0.3058 TrainAcc 0.7800 TestAcc 0.8143 0.7900
epoch 1100 LossPred 0.7795 LossAtt 0.3138 TrainAcc 0.7200 TestAcc 0.7342 0.6950
epoch 1200 LossPred 0.5733 LossAtt 0.3298 TrainAcc 0.7800 TestAcc 0.8016 0.7800
epoch 1300 LossPred 0.8146 LossAtt 0.3423 TrainAcc 0.7200 TestAcc 0.6849 0.6900
epoch 1400 LossPred 0.5902 LossAtt 0.3130 TrainAcc 0.7700 TestAcc 0.8073 0.7500
epoch 1500 LossPred 0.7549 LossAtt 0.3288 TrainAcc 0.7100 TestAcc 0.7057 0.7100
epoch 1600 LossPred 0.8057 LossAtt 0.3141 TrainAcc 0.7100 TestAcc 0.7052 0.7100
epoch 1700 LossPred 0.6057 LossAtt 0.3081 TrainAcc 0.7700 TestAcc 0.7808 0.7600
epoch 1800 LossPred 0.4915 LossAtt 0.3032 TrainAcc 0.8200 TestAcc 0.8321 0.8150
epoch 1900 LossPred 0.7006 LossAtt 0.3131 TrainAcc 0.7400 TestAcc 0.7783 0.7400
epoch 2000 LossPred 0.5184 LossAtt 0.2920 TrainAcc 0.8300 TestAcc 0.8381 0.8400
epoch 2100 LossPred 0.4834 LossAtt 0.2898 TrainAcc 0.8600 TestAcc 0.8301 0.8400
epoch 2200 LossPred 0.6349 LossAtt 0.2995 TrainAcc 0.7600 TestAcc 0.8051 0.7600
epoch 2300 LossPred 0.6218 LossAtt 0.3134 TrainAcc 0.7600 TestAcc 0.7718 0.7550
epoch 2400 LossPred 0.4556 LossAtt 0.3004 TrainAcc 0.8500 TestAcc 0.8336 0.8350
epoch 2500 LossPred 0.4574 LossAtt 0.2879 TrainAcc 0.8500 TestAcc 0.8278 0.8200
Optimization Finished!
********************************************************************
Namespace(arch='tanh', batch_size=256, display_epoch=100, input_noise_level=0.15, latent_attractor_space=True, loss_switch_frequency=0, lrate_attractor=0.002, lrate_prediction=0.002, lrate_wt_penalty=0.0, n_attractor_hidden=10, n_attractor_steps=5, n_hidden=5, n_replications=100, noise_level=0.25, report_best_train_performance=True, seq_len=30, task='majority', train_attr_weights_on_prediction=False, training_epochs=2500)
********************************************************************
mean train accuracy 0.86199987
indiv runs  [0.84, 0.86, 0.84, 0.84, 0.91, 0.96, 0.74, 0.88, 0.96, 0.94, 0.83, 0.78, 0.78, 0.89, 0.97, 0.7, 0.81, 0.94, 0.99, 0.92, 0.86, 0.83, 0.74, 0.84, 0.85, 0.96, 0.74, 0.84, 0.94, 0.92, 0.85, 0.9, 0.85, 0.78, 0.93, 0.84, 0.85, 0.88, 0.9, 0.89, 0.92, 0.68, 0.94, 0.95, 0.78, 0.92, 0.62, 0.82, 0.8, 0.94, 0.85, 0.84, 0.86, 0.79, 0.83, 0.89, 0.66, 0.95, 0.95, 0.95, 0.86, 0.86, 0.96, 0.89, 0.9, 0.66, 0.88, 0.93, 0.84, 0.88, 0.78, 0.97, 0.97, 0.95, 0.92, 0.79, 0.82, 0.81, 0.86, 0.85, 0.95, 0.7, 0.87, 0.84, 0.94, 0.77, 0.86, 0.99, 0.92, 0.9, 0.97, 0.69, 0.81, 0.86, 0.9, 0.91, 0.91, 0.74, 0.92, 0.86]
mean epoch nan
indiv epochs  []
test1 accuracy mean  0.7238438  median  0.7839089
test2 accuracy mean  0.8108499  median  0.825
test1 indiv runs  [0.5202703, 0.8353353, 0.6176176, 0.7462462, 0.8328328, 0.8360861, 0.5427928, 0.7955455, 0.8283283, 0.8283283, 0.5407908, 0.8018018, 0.5558058, 0.8238238, 0.8463463, 0.544044, 0.7977978, 0.7797798, 0.8513514, 0.8140641, 0.7467467, 0.5152653, 0.5600601, 0.5385385, 0.8000501, 0.8448448, 0.5152653, 0.5362863, 0.8891391, 0.8225726, 0.7755255, 0.794044, 0.53003, 0.5808308, 0.8586086, 0.7827828, 0.5660661, 0.5242743, 0.7457457, 0.8390891, 0.8008008, 0.5978478, 0.8083083, 0.8546046, 0.5528028, 0.8911411, 0.532032, 0.8038038, 0.5795796, 0.8408408, 0.8200701, 0.5257758, 0.5613113, 0.5685686, 0.7527528, 0.8578579, 0.5665666, 0.7337337, 0.8816316, 0.8761261, 0.7507508, 0.8506006, 0.9004004, 0.7807808, 0.8355856, 0.48773775, 0.7727728, 0.8080581, 0.5675676, 0.8128128, 0.5968468, 0.9051552, 0.9091592, 0.8133133, 0.8030531, 0.5412913, 0.7297297, 0.5713213, 0.7847848, 0.5520521, 0.8185686, 0.6056056, 0.8661161, 0.5505506, 0.8013013, 0.5115115, 0.541041, 0.8996496, 0.8288288, 0.8035536, 0.8611111, 0.6511512, 0.783033, 0.5157658, 0.8428428, 0.7702703, 0.7927928, 0.5387888, 0.8871371, 0.8300801]
test2 indiv runs  [0.705, 0.845, 0.765, 0.82, 0.87, 0.895, 0.705, 0.875, 0.9, 0.84, 0.745, 0.715, 0.665, 0.845, 0.96, 0.565, 0.815, 0.86, 0.945, 0.87, 0.775, 0.78, 0.695, 0.77, 0.81, 0.87, 0.665, 0.725, 0.935, 0.9, 0.835, 0.835, 0.76, 0.7, 0.92, 0.83, 0.75, 0.805, 0.865, 0.865, 0.855, 0.6, 0.925, 0.92, 0.62, 0.895, 0.645, 0.765, 0.745, 0.885, 0.825, 0.73, 0.795, 0.705, 0.8, 0.905, 0.66, 0.915, 0.915, 0.915, 0.815, 0.825, 0.89, 0.805, 0.875, 0.63, 0.845, 0.92, 0.805, 0.815, 0.735, 0.93, 0.935, 0.925, 0.84, 0.73, 0.78, 0.68, 0.85, 0.79, 0.88, 0.655, 0.81, 0.805, 0.865, 0.69, 0.785, 0.905, 0.89, 0.87, 0.91, 0.665, 0.785, 0.765, 0.89, 0.855, 0.87, 0.715, 0.9, 0.84]
