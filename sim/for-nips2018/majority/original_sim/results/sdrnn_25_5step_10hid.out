Namespace(arch='tanh', batch_size=256, display_epoch=100, input_noise_level=0.15, latent_attractor_space=True, loss_switch_frequency=0, lrate_attractor=0.002, lrate_prediction=0.002, lrate_wt_penalty=0.0, n_attractor_hidden=20, n_attractor_steps=5, n_hidden=10, n_replications=100, noise_level=0.5, report_best_train_performance=True, seq_len=25, task='majority', train_attr_weights_on_prediction=False, training_epochs=2500)
TRAINING ON 100 EXAMPLES, TESTING ON 3996
********** replication  0  **********
epoch   0 LossPred 1.1430 LossAtt 1.0177 TrainAcc 0.5100 TestAcc 0.5403 0.5050
epoch 100 LossPred 0.9032 LossAtt 0.2775 TrainAcc 0.6400 TestAcc 0.5658 0.6250
epoch 200 LossPred 0.8422 LossAtt 0.2686 TrainAcc 0.6600 TestAcc 0.5558 0.6350
epoch 300 LossPred 0.7236 LossAtt 0.3043 TrainAcc 0.7100 TestAcc 0.6176 0.6650
epoch 400 LossPred 0.4880 LossAtt 0.2976 TrainAcc 0.8400 TestAcc 0.7663 0.8100
epoch 500 LossPred 0.4006 LossAtt 0.2787 TrainAcc 0.8900 TestAcc 0.8148 0.8500
epoch 600 LossPred 0.4883 LossAtt 0.2646 TrainAcc 0.8300 TestAcc 0.7975 0.8050
epoch 700 LossPred 0.3960 LossAtt 0.2408 TrainAcc 0.8800 TestAcc 0.8186 0.8400
epoch 800 LossPred 0.3506 LossAtt 0.2312 TrainAcc 0.9000 TestAcc 0.8181 0.8450
epoch 900 LossPred 0.4739 LossAtt 0.2478 TrainAcc 0.8300 TestAcc 0.7695 0.7950
epoch 1000 LossPred 0.4457 LossAtt 0.2371 TrainAcc 0.8400 TestAcc 0.7738 0.7850
epoch 1100 LossPred 0.4701 LossAtt 0.2219 TrainAcc 0.8300 TestAcc 0.7743 0.8100
epoch 1200 LossPred 0.5466 LossAtt 0.1991 TrainAcc 0.8300 TestAcc 0.7840 0.8050
epoch 1300 LossPred 0.5035 LossAtt 0.2013 TrainAcc 0.8300 TestAcc 0.7923 0.8350
epoch 1400 LossPred 0.4538 LossAtt 0.2039 TrainAcc 0.8600 TestAcc 0.7940 0.8450
epoch 1500 LossPred 0.4472 LossAtt 0.1956 TrainAcc 0.8700 TestAcc 0.8018 0.8550
epoch 1600 LossPred 0.4539 LossAtt 0.1905 TrainAcc 0.8500 TestAcc 0.7970 0.8600
epoch 1700 LossPred 0.4660 LossAtt 0.1832 TrainAcc 0.8600 TestAcc 0.7873 0.8550
epoch 1800 LossPred 0.4926 LossAtt 0.1767 TrainAcc 0.8600 TestAcc 0.7868 0.8350
epoch 1900 LossPred 0.4355 LossAtt 0.1721 TrainAcc 0.8800 TestAcc 0.7950 0.8700
epoch 2000 LossPred 0.4066 LossAtt 0.1659 TrainAcc 0.9000 TestAcc 0.7875 0.8650
epoch 2100 LossPred 0.9824 LossAtt 0.1491 TrainAcc 0.6400 TestAcc 0.6086 0.6250
epoch 2200 LossPred 0.7733 LossAtt 0.1560 TrainAcc 0.7200 TestAcc 0.6894 0.7250
epoch 2300 LossPred 0.7571 LossAtt 0.1563 TrainAcc 0.7200 TestAcc 0.6704 0.7150
epoch 2400 LossPred 0.7268 LossAtt 0.1552 TrainAcc 0.7400 TestAcc 0.7075 0.7050
epoch 2500 LossPred 0.6598 LossAtt 0.1532 TrainAcc 0.7400 TestAcc 0.7072 0.7300
Optimization Finished!
********** replication  1  **********
epoch   0 LossPred 1.0399 LossAtt 1.0231 TrainAcc 0.5100 TestAcc 0.4737 0.5300
epoch 100 LossPred 0.8837 LossAtt 0.3366 TrainAcc 0.6700 TestAcc 0.6036 0.6650
epoch 200 LossPred 0.6145 LossAtt 0.3352 TrainAcc 0.7900 TestAcc 0.7545 0.7800
epoch 300 LossPred 0.4988 LossAtt 0.3273 TrainAcc 0.8400 TestAcc 0.8061 0.8350
epoch 400 LossPred 0.4494 LossAtt 0.3376 TrainAcc 0.8300 TestAcc 0.7895 0.7850
epoch 500 LossPred 0.3762 LossAtt 0.3333 TrainAcc 0.8900 TestAcc 0.8201 0.8650
epoch 600 LossPred 0.2685 LossAtt 0.3155 TrainAcc 0.9000 TestAcc 0.8423 0.8650
epoch 700 LossPred 0.5672 LossAtt 0.3119 TrainAcc 0.8000 TestAcc 0.7858 0.8150
epoch 800 LossPred 0.1974 LossAtt 0.3054 TrainAcc 0.9300 TestAcc 0.8333 0.8950
epoch 900 LossPred 0.1808 LossAtt 0.2953 TrainAcc 0.9500 TestAcc 0.8428 0.9000
epoch 1000 LossPred 0.1679 LossAtt 0.2969 TrainAcc 0.9400 TestAcc 0.8411 0.8900
epoch 1100 LossPred 0.1402 LossAtt 0.2936 TrainAcc 0.9700 TestAcc 0.8331 0.8800
epoch 1200 LossPred 0.1176 LossAtt 0.2952 TrainAcc 0.9700 TestAcc 0.8416 0.9050
epoch 1300 LossPred 0.1336 LossAtt 0.2902 TrainAcc 0.9700 TestAcc 0.8298 0.8850
epoch 1400 LossPred 0.1297 LossAtt 0.2840 TrainAcc 0.9700 TestAcc 0.8486 0.8950
epoch 1500 LossPred 0.1302 LossAtt 0.2862 TrainAcc 0.9600 TestAcc 0.8539 0.9300
epoch 1600 LossPred 0.1189 LossAtt 0.2802 TrainAcc 0.9600 TestAcc 0.8333 0.9200
epoch 1700 LossPred 0.1543 LossAtt 0.2742 TrainAcc 0.9500 TestAcc 0.8521 0.9200
epoch 1800 LossPred 0.1067 LossAtt 0.2662 TrainAcc 0.9700 TestAcc 0.8551 0.9350
epoch 1900 LossPred 0.2071 LossAtt 0.2763 TrainAcc 0.9100 TestAcc 0.8451 0.9150
epoch 2000 LossPred 0.2121 LossAtt 0.2697 TrainAcc 0.9300 TestAcc 0.8509 0.9250
epoch 2100 LossPred 0.1288 LossAtt 0.2711 TrainAcc 0.9700 TestAcc 0.8539 0.9150
epoch 2200 LossPred 0.1773 LossAtt 0.2472 TrainAcc 0.9300 TestAcc 0.8201 0.9300
epoch 2300 LossPred 0.2291 LossAtt 0.2631 TrainAcc 0.9100 TestAcc 0.8231 0.9100
epoch 2400 LossPred 0.0848 LossAtt 0.2591 TrainAcc 0.9700 TestAcc 0.8378 0.9400
epoch 2500 LossPred 0.1030 LossAtt 0.2656 TrainAcc 0.9700 TestAcc 0.8433 0.9150
Optimization Finished!
********** replication  2  **********
epoch   0 LossPred 1.0429 LossAtt 1.0075 TrainAcc 0.4200 TestAcc 0.4432 0.4150
epoch 100 LossPred 0.9119 LossAtt 0.2875 TrainAcc 0.6300 TestAcc 0.5783 0.6350
epoch 200 LossPred 0.8388 LossAtt 0.2541 TrainAcc 0.6500 TestAcc 0.6239 0.6450
epoch 300 LossPred 0.4130 LossAtt 0.2806 TrainAcc 0.8700 TestAcc 0.8271 0.8650
epoch 400 LossPred 0.4104 LossAtt 0.2542 TrainAcc 0.8700 TestAcc 0.8343 0.8800
epoch 500 LossPred 0.3588 LossAtt 0.2455 TrainAcc 0.8800 TestAcc 0.8378 0.8850
epoch 600 LossPred 0.3774 LossAtt 0.2446 TrainAcc 0.8600 TestAcc 0.8356 0.8800
epoch 700 LossPred 0.3481 LossAtt 0.2393 TrainAcc 0.8900 TestAcc 0.8393 0.8800
epoch 800 LossPred 0.3662 LossAtt 0.2456 TrainAcc 0.8900 TestAcc 0.8368 0.8800
epoch 900 LossPred 0.3766 LossAtt 0.2401 TrainAcc 0.8900 TestAcc 0.8328 0.8800
epoch 1000 LossPred 0.4817 LossAtt 0.2481 TrainAcc 0.8400 TestAcc 0.8133 0.8400
epoch 1100 LossPred 0.3385 LossAtt 0.2409 TrainAcc 0.8900 TestAcc 0.8496 0.9150
epoch 1200 LossPred 0.2910 LossAtt 0.2568 TrainAcc 0.9000 TestAcc 0.8471 0.8900
epoch 1300 LossPred 0.2641 LossAtt 0.2605 TrainAcc 0.9300 TestAcc 0.8418 0.8950
epoch 1400 LossPred 0.2980 LossAtt 0.2720 TrainAcc 0.9100 TestAcc 0.8281 0.8900
epoch 1500 LossPred 0.2869 LossAtt 0.2733 TrainAcc 0.9000 TestAcc 0.8493 0.8950
epoch 1600 LossPred 0.2903 LossAtt 0.2575 TrainAcc 0.9100 TestAcc 0.8524 0.9300
epoch 1700 LossPred 0.2208 LossAtt 0.2583 TrainAcc 0.9300 TestAcc 0.8626 0.9200
epoch 1800 LossPred 0.2308 LossAtt 0.2391 TrainAcc 0.9300 TestAcc 0.8711 0.9300
epoch 1900 LossPred 0.2270 LossAtt 0.2428 TrainAcc 0.9400 TestAcc 0.8684 0.9100
epoch 2000 LossPred 0.2849 LossAtt 0.2218 TrainAcc 0.9000 TestAcc 0.8584 0.8750
epoch 2100 LossPred 0.3164 LossAtt 0.2321 TrainAcc 0.9100 TestAcc 0.8616 0.8700
epoch 2200 LossPred 0.2324 LossAtt 0.2400 TrainAcc 0.9400 TestAcc 0.8739 0.9250
epoch 2300 LossPred 0.2210 LossAtt 0.2507 TrainAcc 0.9400 TestAcc 0.8739 0.9300
epoch 2400 LossPred 0.2138 LossAtt 0.2353 TrainAcc 0.9200 TestAcc 0.8779 0.9100
epoch 2500 LossPred 0.1829 LossAtt 0.2230 TrainAcc 0.9300 TestAcc 0.8779 0.9150
Optimization Finished!
********** replication  3  **********
epoch   0 LossPred 0.9983 LossAtt 1.0282 TrainAcc 0.4600 TestAcc 0.4980 0.4700
epoch 100 LossPred 0.9003 LossAtt 0.3216 TrainAcc 0.6200 TestAcc 0.5613 0.6050
epoch 200 LossPred 0.2986 LossAtt 0.3674 TrainAcc 0.9200 TestAcc 0.8679 0.9050
epoch 300 LossPred 0.2969 LossAtt 0.3383 TrainAcc 0.8900 TestAcc 0.8403 0.8950
epoch 400 LossPred 0.2214 LossAtt 0.3392 TrainAcc 0.9500 TestAcc 0.8639 0.9100
epoch 500 LossPred 0.2494 LossAtt 0.3334 TrainAcc 0.9200 TestAcc 0.8549 0.9000
epoch 600 LossPred 0.3325 LossAtt 0.3131 TrainAcc 0.8800 TestAcc 0.8231 0.8900
epoch 700 LossPred 0.1541 LossAtt 0.2930 TrainAcc 0.9600 TestAcc 0.8694 0.9200
epoch 800 LossPred 0.1175 LossAtt 0.2824 TrainAcc 0.9700 TestAcc 0.8721 0.9650
epoch 900 LossPred 0.1988 LossAtt 0.2815 TrainAcc 0.9500 TestAcc 0.8641 0.9100
epoch 1000 LossPred 0.3119 LossAtt 0.2760 TrainAcc 0.8900 TestAcc 0.8401 0.8800
epoch 1100 LossPred 0.4998 LossAtt 0.2676 TrainAcc 0.8200 TestAcc 0.7815 0.8500
epoch 1200 LossPred 0.3482 LossAtt 0.2719 TrainAcc 0.8800 TestAcc 0.8338 0.8500
epoch 1300 LossPred 0.2873 LossAtt 0.2663 TrainAcc 0.9200 TestAcc 0.8351 0.8950
epoch 1400 LossPred 0.1838 LossAtt 0.2535 TrainAcc 0.9500 TestAcc 0.8529 0.9450
epoch 1500 LossPred 0.2692 LossAtt 0.2406 TrainAcc 0.9200 TestAcc 0.8203 0.9050
epoch 1600 LossPred 0.1714 LossAtt 0.2436 TrainAcc 0.9600 TestAcc 0.8519 0.9400
epoch 1700 LossPred 0.2634 LossAtt 0.2478 TrainAcc 0.9400 TestAcc 0.8441 0.9000
epoch 1800 LossPred 0.3132 LossAtt 0.2312 TrainAcc 0.8800 TestAcc 0.8103 0.8850
epoch 1900 LossPred 0.3510 LossAtt 0.2319 TrainAcc 0.8800 TestAcc 0.8021 0.8650
epoch 2000 LossPred 0.1631 LossAtt 0.2224 TrainAcc 0.9600 TestAcc 0.8476 0.9500
epoch 2100 LossPred 0.1863 LossAtt 0.2256 TrainAcc 0.9600 TestAcc 0.8511 0.9300
epoch 2200 LossPred 0.2277 LossAtt 0.2270 TrainAcc 0.9200 TestAcc 0.8281 0.9200
epoch 2300 LossPred 0.1699 LossAtt 0.2211 TrainAcc 0.9500 TestAcc 0.8496 0.9300
epoch 2400 LossPred 0.5588 LossAtt 0.2036 TrainAcc 0.8200 TestAcc 0.7603 0.8000
epoch 2500 LossPred 0.1773 LossAtt 0.2156 TrainAcc 0.9500 TestAcc 0.8486 0.9450
Optimization Finished!
********** replication  4  **********
epoch   0 LossPred 1.0120 LossAtt 1.0097 TrainAcc 0.5000 TestAcc 0.5070 0.5000
epoch 100 LossPred 0.9154 LossAtt 0.3026 TrainAcc 0.6100 TestAcc 0.5821 0.6200
epoch 200 LossPred 0.6657 LossAtt 0.3467 TrainAcc 0.7900 TestAcc 0.7430 0.7750
epoch 300 LossPred 0.4575 LossAtt 0.3134 TrainAcc 0.8600 TestAcc 0.7770 0.8350
epoch 400 LossPred 0.3020 LossAtt 0.2985 TrainAcc 0.9300 TestAcc 0.8423 0.9050
epoch 500 LossPred 0.2804 LossAtt 0.3045 TrainAcc 0.9300 TestAcc 0.8428 0.9000
epoch 600 LossPred 0.2643 LossAtt 0.3187 TrainAcc 0.9300 TestAcc 0.8383 0.8900
epoch 700 LossPred 0.3032 LossAtt 0.3158 TrainAcc 0.9200 TestAcc 0.8311 0.9150
epoch 800 LossPred 0.3092 LossAtt 0.3170 TrainAcc 0.9100 TestAcc 0.7973 0.9000
epoch 900 LossPred 1.3802 LossAtt 0.3056 TrainAcc 0.5800 TestAcc 0.5698 0.5850
epoch 1000 LossPred 0.5182 LossAtt 0.3184 TrainAcc 0.8400 TestAcc 0.7417 0.8400
epoch 1100 LossPred 0.3336 LossAtt 0.3170 TrainAcc 0.8900 TestAcc 0.7803 0.8900
epoch 1200 LossPred 0.2750 LossAtt 0.2981 TrainAcc 0.9100 TestAcc 0.7928 0.8950
epoch 1300 LossPred 0.2439 LossAtt 0.2874 TrainAcc 0.9200 TestAcc 0.8163 0.9250
epoch 1400 LossPred 0.3002 LossAtt 0.2825 TrainAcc 0.9100 TestAcc 0.7953 0.9050
epoch 1500 LossPred 0.2207 LossAtt 0.2815 TrainAcc 0.9300 TestAcc 0.8096 0.9300
epoch 1600 LossPred 0.2322 LossAtt 0.2881 TrainAcc 0.9300 TestAcc 0.8051 0.9350
epoch 1700 LossPred 0.3840 LossAtt 0.2774 TrainAcc 0.8700 TestAcc 0.7743 0.8950
epoch 1800 LossPred 0.1914 LossAtt 0.2836 TrainAcc 0.9500 TestAcc 0.8148 0.9350
epoch 1900 LossPred 0.1957 LossAtt 0.2787 TrainAcc 0.9500 TestAcc 0.8301 0.9450
epoch 2000 LossPred 0.2631 LossAtt 0.2818 TrainAcc 0.9100 TestAcc 0.7900 0.9250
epoch 2100 LossPred 0.2516 LossAtt 0.2887 TrainAcc 0.9300 TestAcc 0.8248 0.9400
epoch 2200 LossPred 0.1696 LossAtt 0.2812 TrainAcc 0.9400 TestAcc 0.8078 0.9350
epoch 2300 LossPred 0.1636 LossAtt 0.2795 TrainAcc 0.9700 TestAcc 0.8068 0.9500
epoch 2400 LossPred 0.1595 LossAtt 0.2900 TrainAcc 0.9500 TestAcc 0.8131 0.9450
epoch 2500 LossPred 0.1803 LossAtt 0.2891 TrainAcc 0.9600 TestAcc 0.8168 0.9400
Optimization Finished!
********** replication  5  **********
epoch   0 LossPred 1.0690 LossAtt 1.0044 TrainAcc 0.4500 TestAcc 0.4617 0.4200
epoch 100 LossPred 0.9483 LossAtt 0.2429 TrainAcc 0.5600 TestAcc 0.5445 0.5850
epoch 200 LossPred 0.9269 LossAtt 0.2410 TrainAcc 0.6200 TestAcc 0.5851 0.6250
epoch 300 LossPred 0.2384 LossAtt 0.2594 TrainAcc 0.9200 TestAcc 0.8093 0.8750
epoch 400 LossPred 0.1859 LossAtt 0.2465 TrainAcc 0.9500 TestAcc 0.8166 0.8950
epoch 500 LossPred 0.4734 LossAtt 0.2526 TrainAcc 0.8400 TestAcc 0.7738 0.8400
epoch 600 LossPred 0.3309 LossAtt 0.2516 TrainAcc 0.8800 TestAcc 0.7895 0.8750
epoch 700 LossPred 0.1891 LossAtt 0.2433 TrainAcc 0.9500 TestAcc 0.7998 0.9100
epoch 800 LossPred 0.2182 LossAtt 0.2429 TrainAcc 0.9300 TestAcc 0.8216 0.8950
epoch 900 LossPred 0.1653 LossAtt 0.2421 TrainAcc 0.9600 TestAcc 0.8181 0.9150
epoch 1000 LossPred 0.1672 LossAtt 0.2345 TrainAcc 0.9600 TestAcc 0.8173 0.9250
epoch 1100 LossPred 0.1669 LossAtt 0.2344 TrainAcc 0.9500 TestAcc 0.8188 0.9050
epoch 1200 LossPred 0.2027 LossAtt 0.2361 TrainAcc 0.9300 TestAcc 0.8436 0.8700
epoch 1300 LossPred 0.1648 LossAtt 0.2265 TrainAcc 0.9500 TestAcc 0.8153 0.9100
epoch 1400 LossPred 0.1915 LossAtt 0.2197 TrainAcc 0.9400 TestAcc 0.8043 0.9150
epoch 1500 LossPred 0.2160 LossAtt 0.2302 TrainAcc 0.9300 TestAcc 0.8073 0.8950
epoch 1600 LossPred 0.1646 LossAtt 0.2238 TrainAcc 0.9600 TestAcc 0.8106 0.9250
epoch 1700 LossPred 0.2353 LossAtt 0.2218 TrainAcc 0.9200 TestAcc 0.8201 0.9100
epoch 1800 LossPred 0.2802 LossAtt 0.2105 TrainAcc 0.9000 TestAcc 0.7913 0.9000
epoch 1900 LossPred 0.1699 LossAtt 0.2032 TrainAcc 0.9500 TestAcc 0.8121 0.9200
epoch 2000 LossPred 0.2527 LossAtt 0.2246 TrainAcc 0.9000 TestAcc 0.8493 0.8750
epoch 2100 LossPred 0.6361 LossAtt 0.2293 TrainAcc 0.8100 TestAcc 0.7095 0.7950
epoch 2200 LossPred 0.2214 LossAtt 0.2066 TrainAcc 0.9300 TestAcc 0.8203 0.9100
epoch 2300 LossPred 0.1659 LossAtt 0.2075 TrainAcc 0.9500 TestAcc 0.8093 0.9100
epoch 2400 LossPred 0.1626 LossAtt 0.2152 TrainAcc 0.9500 TestAcc 0.8073 0.9100
epoch 2500 LossPred 0.1612 LossAtt 0.2081 TrainAcc 0.9500 TestAcc 0.8031 0.9050
Optimization Finished!
********** replication  6  **********
epoch   0 LossPred 1.0648 LossAtt 0.9995 TrainAcc 0.5900 TestAcc 0.4907 0.5600
epoch 100 LossPred 0.9480 LossAtt 0.2339 TrainAcc 0.6100 TestAcc 0.5671 0.6100
epoch 200 LossPred 0.9288 LossAtt 0.2024 TrainAcc 0.6000 TestAcc 0.5561 0.6100
epoch 300 LossPred 0.3603 LossAtt 0.2297 TrainAcc 0.9000 TestAcc 0.8634 0.8950
epoch 400 LossPred 0.3682 LossAtt 0.2045 TrainAcc 0.8900 TestAcc 0.8581 0.9000
epoch 500 LossPred 0.3740 LossAtt 0.2013 TrainAcc 0.9000 TestAcc 0.8416 0.8750
epoch 600 LossPred 0.2567 LossAtt 0.2195 TrainAcc 0.9200 TestAcc 0.8594 0.9050
epoch 700 LossPred 0.3547 LossAtt 0.2054 TrainAcc 0.9100 TestAcc 0.8539 0.8750
epoch 800 LossPred 0.8320 LossAtt 0.1934 TrainAcc 0.7300 TestAcc 0.7095 0.7400
epoch 900 LossPred 0.4714 LossAtt 0.2024 TrainAcc 0.8600 TestAcc 0.8276 0.8900
epoch 1000 LossPred 0.7145 LossAtt 0.1934 TrainAcc 0.7900 TestAcc 0.7768 0.7950
epoch 1100 LossPred 0.6186 LossAtt 0.1903 TrainAcc 0.8100 TestAcc 0.7648 0.7900
epoch 1200 LossPred 0.3124 LossAtt 0.1859 TrainAcc 0.9100 TestAcc 0.8516 0.9000
epoch 1300 LossPred 1.1689 LossAtt 0.1910 TrainAcc 0.6200 TestAcc 0.6699 0.6250
epoch 1400 LossPred 0.9331 LossAtt 0.1447 TrainAcc 0.5900 TestAcc 0.4907 0.5950
epoch 1500 LossPred 0.9119 LossAtt 0.1551 TrainAcc 0.5600 TestAcc 0.5853 0.5600
epoch 1600 LossPred 0.9106 LossAtt 0.1653 TrainAcc 0.5700 TestAcc 0.5836 0.5700
epoch 1700 LossPred 0.9034 LossAtt 0.1523 TrainAcc 0.6100 TestAcc 0.6079 0.5950
epoch 1800 LossPred 0.8902 LossAtt 0.1602 TrainAcc 0.6300 TestAcc 0.6236 0.6200
epoch 1900 LossPred 0.8698 LossAtt 0.1641 TrainAcc 0.6500 TestAcc 0.6386 0.6450
epoch 2000 LossPred 0.8611 LossAtt 0.1709 TrainAcc 0.6500 TestAcc 0.6594 0.6350
epoch 2100 LossPred 0.7584 LossAtt 0.1670 TrainAcc 0.6700 TestAcc 0.7685 0.7050
epoch 2200 LossPred 0.7632 LossAtt 0.1993 TrainAcc 0.6800 TestAcc 0.7568 0.7100
epoch 2300 LossPred 0.9669 LossAtt 0.2027 TrainAcc 0.6000 TestAcc 0.5413 0.6050
epoch 2400 LossPred 0.9270 LossAtt 0.2001 TrainAcc 0.6600 TestAcc 0.5951 0.6200
epoch 2500 LossPred 0.9205 LossAtt 0.2071 TrainAcc 0.6300 TestAcc 0.6104 0.6350
Optimization Finished!
********** replication  7  **********
epoch   0 LossPred 1.0606 LossAtt 1.0158 TrainAcc 0.5200 TestAcc 0.5465 0.5450
epoch 100 LossPred 0.9640 LossAtt 0.2774 TrainAcc 0.5700 TestAcc 0.4997 0.5700
epoch 200 LossPred 0.9312 LossAtt 0.2748 TrainAcc 0.6100 TestAcc 0.5290 0.6050
epoch 300 LossPred 0.5455 LossAtt 0.2682 TrainAcc 0.8600 TestAcc 0.7865 0.8000
epoch 400 LossPred 0.4827 LossAtt 0.2474 TrainAcc 0.8200 TestAcc 0.8313 0.8000
epoch 500 LossPred 0.4516 LossAtt 0.2458 TrainAcc 0.8600 TestAcc 0.8443 0.8050
epoch 600 LossPred 0.5322 LossAtt 0.2293 TrainAcc 0.8100 TestAcc 0.7840 0.7900
epoch 700 LossPred 0.5455 LossAtt 0.2342 TrainAcc 0.8000 TestAcc 0.8391 0.7750
epoch 800 LossPred 0.4641 LossAtt 0.2111 TrainAcc 0.8600 TestAcc 0.8356 0.8150
epoch 900 LossPred 0.4900 LossAtt 0.2243 TrainAcc 0.8400 TestAcc 0.8531 0.8150
epoch 1000 LossPred 0.4836 LossAtt 0.2078 TrainAcc 0.8300 TestAcc 0.8351 0.7950
epoch 1100 LossPred 0.4436 LossAtt 0.2043 TrainAcc 0.8600 TestAcc 0.8351 0.8200
epoch 1200 LossPred 0.4207 LossAtt 0.1974 TrainAcc 0.8700 TestAcc 0.8446 0.8200
epoch 1300 LossPred 0.4068 LossAtt 0.1918 TrainAcc 0.8700 TestAcc 0.8391 0.8250
epoch 1400 LossPred 0.4815 LossAtt 0.1895 TrainAcc 0.8300 TestAcc 0.8356 0.8150
epoch 1500 LossPred 0.3804 LossAtt 0.1951 TrainAcc 0.8900 TestAcc 0.8571 0.8250
epoch 1600 LossPred 0.4517 LossAtt 0.2045 TrainAcc 0.8600 TestAcc 0.8524 0.8100
epoch 1700 LossPred 0.4013 LossAtt 0.2002 TrainAcc 0.8900 TestAcc 0.8524 0.8150
epoch 1800 LossPred 0.4480 LossAtt 0.2018 TrainAcc 0.8500 TestAcc 0.8524 0.8150
epoch 1900 LossPred 0.3614 LossAtt 0.1877 TrainAcc 0.8900 TestAcc 0.8576 0.8350
epoch 2000 LossPred 0.3623 LossAtt 0.1896 TrainAcc 0.9100 TestAcc 0.8536 0.8350
epoch 2100 LossPred 0.3503 LossAtt 0.1843 TrainAcc 0.9000 TestAcc 0.8569 0.8450
epoch 2200 LossPred 0.4246 LossAtt 0.1819 TrainAcc 0.8500 TestAcc 0.8566 0.8350
epoch 2300 LossPred 0.3966 LossAtt 0.1834 TrainAcc 0.8600 TestAcc 0.8551 0.8400
epoch 2400 LossPred 0.3803 LossAtt 0.1813 TrainAcc 0.8800 TestAcc 0.8581 0.8350
epoch 2500 LossPred 0.3917 LossAtt 0.1855 TrainAcc 0.9000 TestAcc 0.8536 0.8350
Optimization Finished!
********** replication  8  **********
epoch   0 LossPred 1.2341 LossAtt 1.0167 TrainAcc 0.4000 TestAcc 0.4334 0.4000
epoch 100 LossPred 0.9222 LossAtt 0.2576 TrainAcc 0.6200 TestAcc 0.5823 0.6200
epoch 200 LossPred 0.8791 LossAtt 0.1813 TrainAcc 0.6700 TestAcc 0.6031 0.6750
epoch 300 LossPred 0.8623 LossAtt 0.1332 TrainAcc 0.6800 TestAcc 0.5796 0.6300
epoch 400 LossPred 0.8492 LossAtt 0.1323 TrainAcc 0.6700 TestAcc 0.6056 0.6750
epoch 500 LossPred 0.8406 LossAtt 0.1617 TrainAcc 0.6600 TestAcc 0.5816 0.6550
epoch 600 LossPred 0.9029 LossAtt 0.1646 TrainAcc 0.6700 TestAcc 0.6309 0.6700
epoch 700 LossPred 0.5796 LossAtt 0.2005 TrainAcc 0.8200 TestAcc 0.7990 0.8050
epoch 800 LossPred 0.3717 LossAtt 0.2393 TrainAcc 0.8800 TestAcc 0.8511 0.8700
epoch 900 LossPred 0.3323 LossAtt 0.2622 TrainAcc 0.8800 TestAcc 0.8466 0.8750
epoch 1000 LossPred 0.2735 LossAtt 0.2418 TrainAcc 0.9100 TestAcc 0.8554 0.9100
epoch 1100 LossPred 0.2669 LossAtt 0.2192 TrainAcc 0.9200 TestAcc 0.8468 0.9000
epoch 1200 LossPred 0.2356 LossAtt 0.2121 TrainAcc 0.9200 TestAcc 0.8413 0.9050
epoch 1300 LossPred 0.2337 LossAtt 0.2035 TrainAcc 0.9400 TestAcc 0.8461 0.9100
epoch 1400 LossPred 0.3249 LossAtt 0.2069 TrainAcc 0.9000 TestAcc 0.8153 0.9050
epoch 1500 LossPred 0.2142 LossAtt 0.1957 TrainAcc 0.9300 TestAcc 0.8468 0.9150
epoch 1600 LossPred 0.2631 LossAtt 0.1960 TrainAcc 0.9100 TestAcc 0.8531 0.9200
epoch 1700 LossPred 0.2173 LossAtt 0.1913 TrainAcc 0.9300 TestAcc 0.8456 0.9100
epoch 1800 LossPred 0.2545 LossAtt 0.1989 TrainAcc 0.9100 TestAcc 0.8378 0.8850
epoch 1900 LossPred 0.3016 LossAtt 0.2011 TrainAcc 0.9100 TestAcc 0.8226 0.9050
epoch 2000 LossPred 0.1962 LossAtt 0.2240 TrainAcc 0.9400 TestAcc 0.8644 0.9200
epoch 2100 LossPred 0.2224 LossAtt 0.2285 TrainAcc 0.9200 TestAcc 0.8676 0.9150
epoch 2200 LossPred 0.1582 LossAtt 0.2376 TrainAcc 0.9500 TestAcc 0.8739 0.9400
epoch 2300 LossPred 0.2621 LossAtt 0.2322 TrainAcc 0.9200 TestAcc 0.8411 0.9150
epoch 2400 LossPred 0.1385 LossAtt 0.2441 TrainAcc 0.9500 TestAcc 0.8809 0.9350
epoch 2500 LossPred 0.2267 LossAtt 0.2447 TrainAcc 0.9400 TestAcc 0.8436 0.9150
Optimization Finished!
********** replication  9  **********
epoch   0 LossPred 1.0805 LossAtt 1.0246 TrainAcc 0.4900 TestAcc 0.4942 0.5050
epoch 100 LossPred 0.9341 LossAtt 0.2920 TrainAcc 0.5000 TestAcc 0.5403 0.5650
epoch 200 LossPred 0.9222 LossAtt 0.2553 TrainAcc 0.5500 TestAcc 0.5190 0.5800
epoch 300 LossPred 0.9076 LossAtt 0.2220 TrainAcc 0.6500 TestAcc 0.5561 0.6300
epoch 400 LossPred 0.8698 LossAtt 0.2452 TrainAcc 0.6800 TestAcc 0.5773 0.6400
epoch 500 LossPred 0.8073 LossAtt 0.2402 TrainAcc 0.6800 TestAcc 0.5561 0.6750
epoch 600 LossPred 0.7794 LossAtt 0.2319 TrainAcc 0.7200 TestAcc 0.5758 0.6750
epoch 700 LossPred 0.7658 LossAtt 0.2582 TrainAcc 0.7100 TestAcc 0.5728 0.6950
epoch 800 LossPred 0.7555 LossAtt 0.2820 TrainAcc 0.7200 TestAcc 0.5626 0.7100
epoch 900 LossPred 0.7070 LossAtt 0.2894 TrainAcc 0.7500 TestAcc 0.5651 0.7200
epoch 1000 LossPred 0.6679 LossAtt 0.3189 TrainAcc 0.7600 TestAcc 0.5563 0.7400
epoch 1100 LossPred 0.6433 LossAtt 0.3276 TrainAcc 0.7800 TestAcc 0.5488 0.7500
epoch 1200 LossPred 0.6038 LossAtt 0.3448 TrainAcc 0.8100 TestAcc 0.5450 0.7350
epoch 1300 LossPred 0.5620 LossAtt 0.3378 TrainAcc 0.8200 TestAcc 0.5383 0.7400
epoch 1400 LossPred 0.5432 LossAtt 0.3230 TrainAcc 0.8200 TestAcc 0.5295 0.7500
epoch 1500 LossPred 0.5308 LossAtt 0.3075 TrainAcc 0.8400 TestAcc 0.5380 0.7550
epoch 1600 LossPred 0.5104 LossAtt 0.3082 TrainAcc 0.8400 TestAcc 0.5365 0.7450
epoch 1700 LossPred 0.4937 LossAtt 0.2936 TrainAcc 0.8200 TestAcc 0.5270 0.7500
epoch 1800 LossPred 0.4930 LossAtt 0.2926 TrainAcc 0.8400 TestAcc 0.5213 0.7650
epoch 1900 LossPred 0.4487 LossAtt 0.2778 TrainAcc 0.8600 TestAcc 0.5185 0.7800
epoch 2000 LossPred 0.4591 LossAtt 0.2857 TrainAcc 0.8400 TestAcc 0.5190 0.7550
epoch 2100 LossPred 0.4867 LossAtt 0.2888 TrainAcc 0.8600 TestAcc 0.5225 0.7600
epoch 2200 LossPred 0.5204 LossAtt 0.2733 TrainAcc 0.8300 TestAcc 0.5225 0.7600
epoch 2300 LossPred 0.5220 LossAtt 0.2877 TrainAcc 0.8300 TestAcc 0.5288 0.7500
epoch 2400 LossPred 0.4990 LossAtt 0.2754 TrainAcc 0.8500 TestAcc 0.5310 0.7850
epoch 2500 LossPred 0.5218 LossAtt 0.2901 TrainAcc 0.8500 TestAcc 0.5263 0.7650
Optimization Finished!
********** replication  10  **********
epoch   0 LossPred 1.1568 LossAtt 1.0075 TrainAcc 0.4100 TestAcc 0.5453 0.4300
epoch 100 LossPred 0.8885 LossAtt 0.2263 TrainAcc 0.6400 TestAcc 0.4955 0.6200
epoch 200 LossPred 0.8757 LossAtt 0.1773 TrainAcc 0.6600 TestAcc 0.5195 0.6450
epoch 300 LossPred 0.8645 LossAtt 0.2129 TrainAcc 0.6800 TestAcc 0.5618 0.6700
epoch 400 LossPred 0.5192 LossAtt 0.2334 TrainAcc 0.8600 TestAcc 0.7815 0.8150
epoch 500 LossPred 0.3981 LossAtt 0.2178 TrainAcc 0.8800 TestAcc 0.8203 0.8600
epoch 600 LossPred 0.3955 LossAtt 0.2052 TrainAcc 0.8800 TestAcc 0.8381 0.8600
epoch 700 LossPred 0.5674 LossAtt 0.1945 TrainAcc 0.8300 TestAcc 0.7302 0.8150
epoch 800 LossPred 0.4873 LossAtt 0.1890 TrainAcc 0.8600 TestAcc 0.7920 0.8500
epoch 900 LossPred 0.3367 LossAtt 0.1889 TrainAcc 0.8900 TestAcc 0.8446 0.8950
epoch 1000 LossPred 0.4020 LossAtt 0.1857 TrainAcc 0.8900 TestAcc 0.8426 0.8700
epoch 1100 LossPred 0.3341 LossAtt 0.1772 TrainAcc 0.9000 TestAcc 0.8343 0.8700
epoch 1200 LossPred 0.4560 LossAtt 0.1771 TrainAcc 0.8700 TestAcc 0.8316 0.8350
epoch 1300 LossPred 0.4809 LossAtt 0.1671 TrainAcc 0.8600 TestAcc 0.7855 0.8500
epoch 1400 LossPred 0.3574 LossAtt 0.1736 TrainAcc 0.8800 TestAcc 0.8371 0.8700
epoch 1500 LossPred 0.3303 LossAtt 0.1795 TrainAcc 0.9100 TestAcc 0.8584 0.8800
epoch 1600 LossPred 0.3807 LossAtt 0.1878 TrainAcc 0.8800 TestAcc 0.8291 0.8750
epoch 1700 LossPred 0.3700 LossAtt 0.1802 TrainAcc 0.9000 TestAcc 0.8266 0.8650
epoch 1800 LossPred 0.6024 LossAtt 0.1675 TrainAcc 0.8100 TestAcc 0.7397 0.7950
epoch 1900 LossPred 0.7312 LossAtt 0.1687 TrainAcc 0.7500 TestAcc 0.6794 0.7600
epoch 2000 LossPred 0.4308 LossAtt 0.1920 TrainAcc 0.8600 TestAcc 0.8256 0.8650
epoch 2100 LossPred 0.3170 LossAtt 0.1830 TrainAcc 0.9100 TestAcc 0.8516 0.8750
epoch 2200 LossPred 0.3321 LossAtt 0.1810 TrainAcc 0.9100 TestAcc 0.8551 0.8800
epoch 2300 LossPred 0.3538 LossAtt 0.1875 TrainAcc 0.8900 TestAcc 0.8566 0.8700
epoch 2400 LossPred 0.4563 LossAtt 0.1923 TrainAcc 0.8600 TestAcc 0.7910 0.8450
epoch 2500 LossPred 0.2980 LossAtt 0.1885 TrainAcc 0.9200 TestAcc 0.8498 0.8800
Optimization Finished!
********** replication  11  **********
epoch   0 LossPred 1.1388 LossAtt 0.9800 TrainAcc 0.4800 TestAcc 0.5048 0.4800
epoch 100 LossPred 0.9670 LossAtt 0.2396 TrainAcc 0.6100 TestAcc 0.5658 0.6050
epoch 200 LossPred 0.9566 LossAtt 0.2060 TrainAcc 0.6100 TestAcc 0.5658 0.6200
epoch 300 LossPred 0.9425 LossAtt 0.1678 TrainAcc 0.6100 TestAcc 0.5608 0.6100
epoch 400 LossPred 0.9237 LossAtt 0.1867 TrainAcc 0.6200 TestAcc 0.5541 0.6150
epoch 500 LossPred 0.8726 LossAtt 0.2166 TrainAcc 0.6800 TestAcc 0.5440 0.6700
epoch 600 LossPred 0.8497 LossAtt 0.2822 TrainAcc 0.6900 TestAcc 0.5455 0.6650
epoch 700 LossPred 0.8232 LossAtt 0.2956 TrainAcc 0.7000 TestAcc 0.5531 0.6550
epoch 800 LossPred 0.7919 LossAtt 0.3081 TrainAcc 0.6900 TestAcc 0.5440 0.6800
epoch 900 LossPred 0.7718 LossAtt 0.3198 TrainAcc 0.6700 TestAcc 0.5468 0.6800
epoch 1000 LossPred 0.7550 LossAtt 0.3279 TrainAcc 0.7100 TestAcc 0.5576 0.6800
epoch 1100 LossPred 0.7515 LossAtt 0.3240 TrainAcc 0.7100 TestAcc 0.5448 0.6900
epoch 1200 LossPred 0.7410 LossAtt 0.3043 TrainAcc 0.6900 TestAcc 0.5498 0.6950
epoch 1300 LossPred 0.7148 LossAtt 0.3053 TrainAcc 0.7200 TestAcc 0.5485 0.6800
epoch 1400 LossPred 0.6779 LossAtt 0.3188 TrainAcc 0.7200 TestAcc 0.5531 0.6850
epoch 1500 LossPred 0.7022 LossAtt 0.3055 TrainAcc 0.7100 TestAcc 0.5518 0.7050
epoch 1600 LossPred 0.6471 LossAtt 0.3085 TrainAcc 0.7400 TestAcc 0.5568 0.6800
epoch 1700 LossPred 0.7061 LossAtt 0.2915 TrainAcc 0.6800 TestAcc 0.5501 0.6850
epoch 1800 LossPred 0.6598 LossAtt 0.3063 TrainAcc 0.7500 TestAcc 0.5475 0.6900
epoch 1900 LossPred 0.7352 LossAtt 0.3163 TrainAcc 0.7100 TestAcc 0.5726 0.6600
epoch 2000 LossPred 0.6431 LossAtt 0.3243 TrainAcc 0.6900 TestAcc 0.6041 0.6650
epoch 2100 LossPred 0.7267 LossAtt 0.3110 TrainAcc 0.7400 TestAcc 0.6041 0.6700
epoch 2200 LossPred 0.8168 LossAtt 0.3264 TrainAcc 0.6700 TestAcc 0.6496 0.6800
epoch 2300 LossPred 0.6136 LossAtt 0.2923 TrainAcc 0.7500 TestAcc 0.6454 0.7450
epoch 2400 LossPred 0.5901 LossAtt 0.3298 TrainAcc 0.7800 TestAcc 0.6346 0.7650
epoch 2500 LossPred 0.4712 LossAtt 0.3517 TrainAcc 0.8500 TestAcc 0.7217 0.8150
Optimization Finished!
********** replication  12  **********
epoch   0 LossPred 1.0106 LossAtt 1.0018 TrainAcc 0.4600 TestAcc 0.4660 0.4500
epoch 100 LossPred 0.8185 LossAtt 0.2801 TrainAcc 0.7000 TestAcc 0.5813 0.7000
epoch 200 LossPred 0.6144 LossAtt 0.2861 TrainAcc 0.7600 TestAcc 0.7763 0.7600
epoch 300 LossPred 0.5307 LossAtt 0.2674 TrainAcc 0.8100 TestAcc 0.8181 0.8100
epoch 400 LossPred 0.5875 LossAtt 0.2401 TrainAcc 0.7900 TestAcc 0.7880 0.7850
epoch 500 LossPred 0.5886 LossAtt 0.2346 TrainAcc 0.8300 TestAcc 0.7603 0.7700
epoch 600 LossPred 0.3980 LossAtt 0.2264 TrainAcc 0.8600 TestAcc 0.8564 0.8550
epoch 700 LossPred 0.5580 LossAtt 0.2190 TrainAcc 0.8300 TestAcc 0.7785 0.8050
epoch 800 LossPred 0.5897 LossAtt 0.2219 TrainAcc 0.8000 TestAcc 0.7575 0.7850
epoch 900 LossPred 0.6781 LossAtt 0.2102 TrainAcc 0.7300 TestAcc 0.7347 0.7500
epoch 1000 LossPred 0.5886 LossAtt 0.1899 TrainAcc 0.7500 TestAcc 0.7710 0.7450
epoch 1100 LossPred 0.5448 LossAtt 0.1850 TrainAcc 0.7900 TestAcc 0.7855 0.8100
epoch 1200 LossPred 0.7624 LossAtt 0.1952 TrainAcc 0.7000 TestAcc 0.6637 0.7000
epoch 1300 LossPred 0.7108 LossAtt 0.1879 TrainAcc 0.7100 TestAcc 0.7422 0.7000
epoch 1400 LossPred 0.6472 LossAtt 0.1892 TrainAcc 0.7400 TestAcc 0.7793 0.7500
epoch 1500 LossPred 0.6721 LossAtt 0.1951 TrainAcc 0.7300 TestAcc 0.7277 0.7500
epoch 1600 LossPred 0.4641 LossAtt 0.1881 TrainAcc 0.8500 TestAcc 0.8213 0.8200
epoch 1700 LossPred 0.5910 LossAtt 0.1900 TrainAcc 0.7800 TestAcc 0.7630 0.7500
epoch 1800 LossPred 0.5143 LossAtt 0.1952 TrainAcc 0.7900 TestAcc 0.8171 0.7700
epoch 1900 LossPred 0.4577 LossAtt 0.1899 TrainAcc 0.8300 TestAcc 0.8206 0.8150
epoch 2000 LossPred 0.5471 LossAtt 0.1877 TrainAcc 0.7800 TestAcc 0.7770 0.7750
epoch 2100 LossPred 0.4690 LossAtt 0.1899 TrainAcc 0.8100 TestAcc 0.8196 0.7950
epoch 2200 LossPred 0.4341 LossAtt 0.1771 TrainAcc 0.8400 TestAcc 0.8201 0.8050
epoch 2300 LossPred 0.6233 LossAtt 0.1871 TrainAcc 0.7800 TestAcc 0.7910 0.7950
epoch 2400 LossPred 0.5223 LossAtt 0.1899 TrainAcc 0.8300 TestAcc 0.8141 0.8200
epoch 2500 LossPred 0.3954 LossAtt 0.1609 TrainAcc 0.8600 TestAcc 0.8251 0.8450
Optimization Finished!
********** replication  13  **********
epoch   0 LossPred 1.1596 LossAtt 1.0151 TrainAcc 0.4500 TestAcc 0.4367 0.4950
epoch 100 LossPred 0.8416 LossAtt 0.3696 TrainAcc 0.7000 TestAcc 0.5741 0.6500
epoch 200 LossPred 0.4789 LossAtt 0.3808 TrainAcc 0.8700 TestAcc 0.8166 0.8500
epoch 300 LossPred 0.3392 LossAtt 0.3625 TrainAcc 0.8900 TestAcc 0.8341 0.8800
epoch 400 LossPred 0.2644 LossAtt 0.3470 TrainAcc 0.9000 TestAcc 0.8524 0.8950
epoch 500 LossPred 0.2426 LossAtt 0.2870 TrainAcc 0.9300 TestAcc 0.8544 0.9250
epoch 600 LossPred 0.2319 LossAtt 0.2667 TrainAcc 0.9300 TestAcc 0.8686 0.9250
epoch 700 LossPred 0.2639 LossAtt 0.2570 TrainAcc 0.9400 TestAcc 0.8701 0.9050
epoch 800 LossPred 0.2043 LossAtt 0.2631 TrainAcc 0.9300 TestAcc 0.8546 0.9250
epoch 900 LossPred 0.2226 LossAtt 0.2787 TrainAcc 0.9100 TestAcc 0.8764 0.9100
epoch 1000 LossPred 0.1866 LossAtt 0.2719 TrainAcc 0.9400 TestAcc 0.8609 0.9250
epoch 1100 LossPred 0.1842 LossAtt 0.2748 TrainAcc 0.9400 TestAcc 0.8786 0.9450
epoch 1200 LossPred 0.1248 LossAtt 0.2797 TrainAcc 0.9600 TestAcc 0.8526 0.9700
epoch 1300 LossPred 0.1153 LossAtt 0.2723 TrainAcc 0.9700 TestAcc 0.8544 0.9700
epoch 1400 LossPred 0.1234 LossAtt 0.2658 TrainAcc 0.9700 TestAcc 0.8711 0.9550
epoch 1500 LossPred 0.1227 LossAtt 0.2658 TrainAcc 0.9600 TestAcc 0.8674 0.9650
epoch 1600 LossPred 0.0822 LossAtt 0.2620 TrainAcc 0.9800 TestAcc 0.8584 0.9650
epoch 1700 LossPred 0.0877 LossAtt 0.2493 TrainAcc 0.9900 TestAcc 0.8521 0.9700
epoch 1800 LossPred 0.0974 LossAtt 0.2550 TrainAcc 0.9700 TestAcc 0.8461 0.9650
epoch 1900 LossPred 0.0765 LossAtt 0.2500 TrainAcc 0.9800 TestAcc 0.8559 0.9600
epoch 2000 LossPred 0.0886 LossAtt 0.2496 TrainAcc 0.9700 TestAcc 0.8483 0.9600
epoch 2100 LossPred 0.0636 LossAtt 0.2429 TrainAcc 0.9900 TestAcc 0.8536 0.9700
epoch 2200 LossPred 0.1495 LossAtt 0.2478 TrainAcc 0.9500 TestAcc 0.8549 0.9450
epoch 2300 LossPred 0.0584 LossAtt 0.2445 TrainAcc 0.9900 TestAcc 0.8569 0.9650
epoch 2400 LossPred 0.0886 LossAtt 0.2461 TrainAcc 0.9800 TestAcc 0.8371 0.9650
epoch 2500 LossPred 0.0501 LossAtt 0.2440 TrainAcc 0.9900 TestAcc 0.8554 0.9900
Optimization Finished!
********** replication  14  **********
epoch   0 LossPred 1.0787 LossAtt 1.0089 TrainAcc 0.4900 TestAcc 0.4692 0.4800
epoch 100 LossPred 0.9526 LossAtt 0.2440 TrainAcc 0.6000 TestAcc 0.5846 0.5950
epoch 200 LossPred 0.9266 LossAtt 0.2628 TrainAcc 0.6000 TestAcc 0.5846 0.6250
epoch 300 LossPred 0.4499 LossAtt 0.2937 TrainAcc 0.8900 TestAcc 0.7885 0.8250
epoch 400 LossPred 0.2755 LossAtt 0.2687 TrainAcc 0.9100 TestAcc 0.8216 0.8850
epoch 500 LossPred 0.2884 LossAtt 0.2465 TrainAcc 0.9100 TestAcc 0.8121 0.9000
epoch 600 LossPred 0.2141 LossAtt 0.2194 TrainAcc 0.9400 TestAcc 0.8413 0.9150
epoch 700 LossPred 0.2227 LossAtt 0.2080 TrainAcc 0.9300 TestAcc 0.8293 0.9150
epoch 800 LossPred 0.2043 LossAtt 0.2036 TrainAcc 0.9400 TestAcc 0.8383 0.9200
epoch 900 LossPred 0.2815 LossAtt 0.2005 TrainAcc 0.9100 TestAcc 0.8421 0.9150
epoch 1000 LossPred 0.2620 LossAtt 0.2125 TrainAcc 0.9100 TestAcc 0.7985 0.8850
epoch 1100 LossPred 0.2633 LossAtt 0.1987 TrainAcc 0.9300 TestAcc 0.8163 0.9050
epoch 1200 LossPred 0.2316 LossAtt 0.1837 TrainAcc 0.9100 TestAcc 0.8163 0.9050
epoch 1300 LossPred 0.1910 LossAtt 0.1913 TrainAcc 0.9400 TestAcc 0.8416 0.9050
epoch 1400 LossPred 0.8807 LossAtt 0.2203 TrainAcc 0.7400 TestAcc 0.7007 0.7000
epoch 1500 LossPred 0.2333 LossAtt 0.2204 TrainAcc 0.9200 TestAcc 0.8203 0.9150
epoch 1600 LossPred 0.2245 LossAtt 0.2085 TrainAcc 0.9300 TestAcc 0.8286 0.9200
epoch 1700 LossPred 0.2460 LossAtt 0.1938 TrainAcc 0.9400 TestAcc 0.8376 0.9000
epoch 1800 LossPred 0.1709 LossAtt 0.1816 TrainAcc 0.9400 TestAcc 0.8403 0.9200
epoch 1900 LossPred 0.2323 LossAtt 0.1880 TrainAcc 0.9200 TestAcc 0.8178 0.9150
epoch 2000 LossPred 0.1941 LossAtt 0.1799 TrainAcc 0.9400 TestAcc 0.8303 0.9200
epoch 2100 LossPred 0.1975 LossAtt 0.1839 TrainAcc 0.9500 TestAcc 0.8293 0.9150
epoch 2200 LossPred 0.2302 LossAtt 0.1683 TrainAcc 0.9300 TestAcc 0.8416 0.9150
epoch 2300 LossPred 0.2174 LossAtt 0.1676 TrainAcc 0.9400 TestAcc 0.8306 0.9200
epoch 2400 LossPred 0.2291 LossAtt 0.1702 TrainAcc 0.9200 TestAcc 0.8266 0.8950
epoch 2500 LossPred 0.2064 LossAtt 0.1735 TrainAcc 0.9400 TestAcc 0.8366 0.9100
Optimization Finished!
********** replication  15  **********
epoch   0 LossPred 1.0409 LossAtt 1.0213 TrainAcc 0.5600 TestAcc 0.5648 0.5450
epoch 100 LossPred 0.8540 LossAtt 0.3057 TrainAcc 0.6700 TestAcc 0.5766 0.6450
epoch 200 LossPred 0.8330 LossAtt 0.2227 TrainAcc 0.6800 TestAcc 0.5566 0.6800
epoch 300 LossPred 0.7593 LossAtt 0.2713 TrainAcc 0.7000 TestAcc 0.5706 0.6750
epoch 400 LossPred 0.4403 LossAtt 0.3026 TrainAcc 0.8600 TestAcc 0.7205 0.8300
epoch 500 LossPred 0.4814 LossAtt 0.3102 TrainAcc 0.8300 TestAcc 0.6709 0.8200
epoch 600 LossPred 0.4454 LossAtt 0.2970 TrainAcc 0.8500 TestAcc 0.7102 0.8550
epoch 700 LossPred 0.4661 LossAtt 0.3058 TrainAcc 0.8500 TestAcc 0.7410 0.8550
epoch 800 LossPred 0.4778 LossAtt 0.2900 TrainAcc 0.8400 TestAcc 0.6597 0.8300
epoch 900 LossPred 0.4340 LossAtt 0.2989 TrainAcc 0.8200 TestAcc 0.7798 0.8500
epoch 1000 LossPred 0.4507 LossAtt 0.3007 TrainAcc 0.8300 TestAcc 0.7818 0.8200
epoch 1100 LossPred 0.4622 LossAtt 0.2859 TrainAcc 0.8600 TestAcc 0.6722 0.8450
epoch 1200 LossPred 0.3890 LossAtt 0.2815 TrainAcc 0.8700 TestAcc 0.7395 0.8750
epoch 1300 LossPred 0.4187 LossAtt 0.2690 TrainAcc 0.8600 TestAcc 0.7012 0.8600
epoch 1400 LossPred 0.4240 LossAtt 0.2834 TrainAcc 0.8600 TestAcc 0.7432 0.8650
epoch 1500 LossPred 0.4899 LossAtt 0.2702 TrainAcc 0.8500 TestAcc 0.6559 0.8500
epoch 1600 LossPred 0.4404 LossAtt 0.2677 TrainAcc 0.8800 TestAcc 0.6852 0.8700
epoch 1700 LossPred 0.4450 LossAtt 0.2666 TrainAcc 0.8600 TestAcc 0.6864 0.8650
epoch 1800 LossPred 0.4645 LossAtt 0.2759 TrainAcc 0.8700 TestAcc 0.7277 0.8700
epoch 1900 LossPred 0.4059 LossAtt 0.2493 TrainAcc 0.8700 TestAcc 0.7465 0.8750
epoch 2000 LossPred 0.4360 LossAtt 0.2606 TrainAcc 0.8600 TestAcc 0.6917 0.8550
epoch 2100 LossPred 0.4236 LossAtt 0.2633 TrainAcc 0.8500 TestAcc 0.7067 0.8550
epoch 2200 LossPred 0.4190 LossAtt 0.2598 TrainAcc 0.8600 TestAcc 0.6972 0.8600
epoch 2300 LossPred 0.3883 LossAtt 0.2615 TrainAcc 0.8900 TestAcc 0.7490 0.8900
epoch 2400 LossPred 0.4580 LossAtt 0.2729 TrainAcc 0.8600 TestAcc 0.7803 0.8400
epoch 2500 LossPred 0.4152 LossAtt 0.2705 TrainAcc 0.8700 TestAcc 0.6919 0.8750
Optimization Finished!
********** replication  16  **********
epoch   0 LossPred 1.3557 LossAtt 0.9753 TrainAcc 0.4300 TestAcc 0.5040 0.4300
epoch 100 LossPred 0.9668 LossAtt 0.2710 TrainAcc 0.5700 TestAcc 0.4960 0.5600
epoch 200 LossPred 0.9660 LossAtt 0.1909 TrainAcc 0.5700 TestAcc 0.4960 0.5700
epoch 300 LossPred 0.9655 LossAtt 0.1294 TrainAcc 0.5700 TestAcc 0.4960 0.5700
epoch 400 LossPred 0.9644 LossAtt 0.1125 TrainAcc 0.5700 TestAcc 0.4960 0.5700
epoch 500 LossPred 0.9631 LossAtt 0.1037 TrainAcc 0.5700 TestAcc 0.4960 0.5700
epoch 600 LossPred 0.9559 LossAtt 0.1483 TrainAcc 0.5700 TestAcc 0.4960 0.5700
epoch 700 LossPred 0.5098 LossAtt 0.2520 TrainAcc 0.9000 TestAcc 0.8906 0.8900
epoch 800 LossPred 0.4048 LossAtt 0.2355 TrainAcc 0.8800 TestAcc 0.8646 0.9100
epoch 900 LossPred 0.3515 LossAtt 0.2416 TrainAcc 0.9200 TestAcc 0.9009 0.9000
epoch 1000 LossPred 0.2662 LossAtt 0.2179 TrainAcc 0.9100 TestAcc 0.9037 0.9050
epoch 1100 LossPred 0.3042 LossAtt 0.2255 TrainAcc 0.9100 TestAcc 0.8809 0.9000
epoch 1200 LossPred 0.3090 LossAtt 0.2113 TrainAcc 0.8800 TestAcc 0.8901 0.8850
epoch 1300 LossPred 0.3095 LossAtt 0.2080 TrainAcc 0.8800 TestAcc 0.8961 0.8900
epoch 1400 LossPred 0.2543 LossAtt 0.1916 TrainAcc 0.9300 TestAcc 0.9219 0.9300
epoch 1500 LossPred 0.3233 LossAtt 0.1868 TrainAcc 0.9000 TestAcc 0.8569 0.8850
epoch 1600 LossPred 0.2243 LossAtt 0.1740 TrainAcc 0.9100 TestAcc 0.9139 0.9250
epoch 1700 LossPred 0.2622 LossAtt 0.1766 TrainAcc 0.8900 TestAcc 0.8874 0.9000
epoch 1800 LossPred 0.4659 LossAtt 0.1783 TrainAcc 0.8600 TestAcc 0.8236 0.8650
epoch 1900 LossPred 0.3656 LossAtt 0.1813 TrainAcc 0.8900 TestAcc 0.8529 0.9100
epoch 2000 LossPred 0.3554 LossAtt 0.1979 TrainAcc 0.8900 TestAcc 0.8423 0.8900
epoch 2100 LossPred 0.6173 LossAtt 0.1986 TrainAcc 0.7700 TestAcc 0.8208 0.7750
epoch 2200 LossPred 0.1745 LossAtt 0.2015 TrainAcc 0.9400 TestAcc 0.9042 0.9350
epoch 2300 LossPred 0.1869 LossAtt 0.2017 TrainAcc 0.9300 TestAcc 0.9084 0.9250
epoch 2400 LossPred 0.2261 LossAtt 0.2024 TrainAcc 0.9300 TestAcc 0.9132 0.9250
epoch 2500 LossPred 0.2759 LossAtt 0.2088 TrainAcc 0.8900 TestAcc 0.9027 0.8850
Optimization Finished!
********** replication  17  **********
epoch   0 LossPred 1.0180 LossAtt 1.0184 TrainAcc 0.4900 TestAcc 0.4832 0.4900
epoch 100 LossPred 0.8753 LossAtt 0.2241 TrainAcc 0.6200 TestAcc 0.5731 0.6250
epoch 200 LossPred 0.5745 LossAtt 0.2247 TrainAcc 0.7900 TestAcc 0.8096 0.7800
epoch 300 LossPred 0.5067 LossAtt 0.1985 TrainAcc 0.8200 TestAcc 0.8096 0.8050
epoch 400 LossPred 0.5725 LossAtt 0.1984 TrainAcc 0.8100 TestAcc 0.7940 0.8300
epoch 500 LossPred 0.5102 LossAtt 0.2078 TrainAcc 0.8100 TestAcc 0.8346 0.7900
epoch 600 LossPred 0.4230 LossAtt 0.2232 TrainAcc 0.8500 TestAcc 0.8346 0.8150
epoch 700 LossPred 0.3842 LossAtt 0.2251 TrainAcc 0.8700 TestAcc 0.8358 0.8400
epoch 800 LossPred 0.3307 LossAtt 0.2243 TrainAcc 0.8900 TestAcc 0.8323 0.8550
epoch 900 LossPred 0.3373 LossAtt 0.2242 TrainAcc 0.8800 TestAcc 0.8251 0.8650
epoch 1000 LossPred 0.3701 LossAtt 0.2193 TrainAcc 0.8700 TestAcc 0.8223 0.8700
epoch 1100 LossPred 0.3474 LossAtt 0.2263 TrainAcc 0.8800 TestAcc 0.8158 0.8300
epoch 1200 LossPred 0.3990 LossAtt 0.2127 TrainAcc 0.8600 TestAcc 0.8178 0.8600
epoch 1300 LossPred 0.3420 LossAtt 0.2172 TrainAcc 0.8900 TestAcc 0.8101 0.8700
epoch 1400 LossPred 0.3145 LossAtt 0.2138 TrainAcc 0.8900 TestAcc 0.8056 0.8350
epoch 1500 LossPred 0.3477 LossAtt 0.2296 TrainAcc 0.8900 TestAcc 0.8076 0.8700
epoch 1600 LossPred 0.3529 LossAtt 0.2149 TrainAcc 0.8800 TestAcc 0.8016 0.8550
epoch 1700 LossPred 0.4366 LossAtt 0.2155 TrainAcc 0.8700 TestAcc 0.7955 0.8550
epoch 1800 LossPred 0.3369 LossAtt 0.2101 TrainAcc 0.9100 TestAcc 0.7988 0.8700
epoch 1900 LossPred 0.4561 LossAtt 0.2048 TrainAcc 0.8300 TestAcc 0.7795 0.8700
epoch 2000 LossPred 0.2919 LossAtt 0.2259 TrainAcc 0.9100 TestAcc 0.7895 0.8800
epoch 2100 LossPred 0.2885 LossAtt 0.2197 TrainAcc 0.9000 TestAcc 0.7948 0.8700
epoch 2200 LossPred 0.3242 LossAtt 0.2089 TrainAcc 0.8700 TestAcc 0.7918 0.8700
epoch 2300 LossPred 0.3587 LossAtt 0.2118 TrainAcc 0.8500 TestAcc 0.7758 0.8650
epoch 2400 LossPred 0.4133 LossAtt 0.2184 TrainAcc 0.8500 TestAcc 0.7735 0.8700
epoch 2500 LossPred 0.3872 LossAtt 0.2141 TrainAcc 0.8800 TestAcc 0.7748 0.8650
Optimization Finished!
********** replication  18  **********
epoch   0 LossPred 1.0282 LossAtt 1.0335 TrainAcc 0.5100 TestAcc 0.5153 0.5250
epoch 100 LossPred 0.9443 LossAtt 0.2453 TrainAcc 0.6000 TestAcc 0.5938 0.5800
epoch 200 LossPred 0.6279 LossAtt 0.2509 TrainAcc 0.7900 TestAcc 0.8226 0.7700
epoch 300 LossPred 0.4347 LossAtt 0.2625 TrainAcc 0.8700 TestAcc 0.8371 0.8050
epoch 400 LossPred 0.3951 LossAtt 0.2557 TrainAcc 0.8700 TestAcc 0.8446 0.8500
epoch 500 LossPred 0.4235 LossAtt 0.2486 TrainAcc 0.8600 TestAcc 0.8311 0.8000
epoch 600 LossPred 0.3276 LossAtt 0.2428 TrainAcc 0.9000 TestAcc 0.8519 0.8550
epoch 700 LossPred 0.3500 LossAtt 0.2488 TrainAcc 0.8700 TestAcc 0.8486 0.8550
epoch 800 LossPred 0.4228 LossAtt 0.2285 TrainAcc 0.8700 TestAcc 0.8436 0.8200
epoch 900 LossPred 0.4660 LossAtt 0.2416 TrainAcc 0.8600 TestAcc 0.8346 0.8150
epoch 1000 LossPred 0.6699 LossAtt 0.2368 TrainAcc 0.7900 TestAcc 0.7990 0.7900
epoch 1100 LossPred 0.7318 LossAtt 0.2304 TrainAcc 0.7600 TestAcc 0.7903 0.7750
epoch 1200 LossPred 0.4023 LossAtt 0.2077 TrainAcc 0.8900 TestAcc 0.8466 0.8350
epoch 1300 LossPred 0.4133 LossAtt 0.2161 TrainAcc 0.8700 TestAcc 0.8476 0.8300
epoch 1400 LossPred 0.4283 LossAtt 0.2122 TrainAcc 0.8600 TestAcc 0.8456 0.8150
epoch 1500 LossPred 0.3853 LossAtt 0.2205 TrainAcc 0.8700 TestAcc 0.8433 0.8400
epoch 1600 LossPred 0.3940 LossAtt 0.2149 TrainAcc 0.8700 TestAcc 0.8478 0.8350
epoch 1700 LossPred 0.3778 LossAtt 0.2061 TrainAcc 0.8700 TestAcc 0.8431 0.8450
epoch 1800 LossPred 0.4080 LossAtt 0.1913 TrainAcc 0.8600 TestAcc 0.8433 0.8450
epoch 1900 LossPred 0.4019 LossAtt 0.1938 TrainAcc 0.8900 TestAcc 0.8443 0.8400
epoch 2000 LossPred 0.4413 LossAtt 0.1865 TrainAcc 0.8700 TestAcc 0.8343 0.8200
epoch 2100 LossPred 0.4501 LossAtt 0.1890 TrainAcc 0.8600 TestAcc 0.8381 0.8400
epoch 2200 LossPred 0.4593 LossAtt 0.1859 TrainAcc 0.8300 TestAcc 0.8313 0.8350
epoch 2300 LossPred 0.5454 LossAtt 0.1703 TrainAcc 0.8000 TestAcc 0.8173 0.7950
epoch 2400 LossPred 0.4164 LossAtt 0.1690 TrainAcc 0.8600 TestAcc 0.8373 0.8600
epoch 2500 LossPred 0.5722 LossAtt 0.2044 TrainAcc 0.7900 TestAcc 0.8156 0.7700
Optimization Finished!
********** replication  19  **********
epoch   0 LossPred 1.0886 LossAtt 1.0000 TrainAcc 0.4200 TestAcc 0.5053 0.4450
epoch 100 LossPred 0.9450 LossAtt 0.2762 TrainAcc 0.6000 TestAcc 0.5623 0.5900
epoch 200 LossPred 0.9403 LossAtt 0.1843 TrainAcc 0.5900 TestAcc 0.5498 0.5900
epoch 300 LossPred 0.9374 LossAtt 0.1787 TrainAcc 0.6000 TestAcc 0.5435 0.5950
epoch 400 LossPred 0.9331 LossAtt 0.1469 TrainAcc 0.6100 TestAcc 0.5546 0.6100
epoch 500 LossPred 0.9315 LossAtt 0.1397 TrainAcc 0.6100 TestAcc 0.5531 0.6200
epoch 600 LossPred 0.9296 LossAtt 0.1313 TrainAcc 0.6100 TestAcc 0.5578 0.6200
epoch 700 LossPred 0.9270 LossAtt 0.1395 TrainAcc 0.6100 TestAcc 0.5661 0.6100
epoch 800 LossPred 0.9226 LossAtt 0.1778 TrainAcc 0.6100 TestAcc 0.5626 0.6100
epoch 900 LossPred 0.9361 LossAtt 0.2968 TrainAcc 0.5900 TestAcc 0.5941 0.6000
epoch 1000 LossPred 0.9240 LossAtt 0.2530 TrainAcc 0.6200 TestAcc 0.6386 0.6250
epoch 1100 LossPred 0.7423 LossAtt 0.2485 TrainAcc 0.7700 TestAcc 0.7062 0.7600
epoch 1200 LossPred 0.5149 LossAtt 0.2240 TrainAcc 0.8500 TestAcc 0.6942 0.8450
epoch 1300 LossPred 0.8492 LossAtt 0.2076 TrainAcc 0.7100 TestAcc 0.5573 0.7000
epoch 1400 LossPred 0.4052 LossAtt 0.2067 TrainAcc 0.8800 TestAcc 0.7988 0.8750
epoch 1500 LossPred 0.3282 LossAtt 0.2151 TrainAcc 0.9100 TestAcc 0.8311 0.8700
epoch 1600 LossPred 0.4680 LossAtt 0.2479 TrainAcc 0.8500 TestAcc 0.7280 0.8500
epoch 1700 LossPred 0.4400 LossAtt 0.2373 TrainAcc 0.8700 TestAcc 0.7340 0.8600
epoch 1800 LossPred 0.3693 LossAtt 0.2285 TrainAcc 0.8800 TestAcc 0.8198 0.8750
epoch 1900 LossPred 0.3640 LossAtt 0.2188 TrainAcc 0.8900 TestAcc 0.8171 0.8650
epoch 2000 LossPred 0.4257 LossAtt 0.2267 TrainAcc 0.8600 TestAcc 0.8316 0.8800
epoch 2100 LossPred 0.4540 LossAtt 0.2323 TrainAcc 0.8600 TestAcc 0.7402 0.8750
epoch 2200 LossPred 0.3615 LossAtt 0.2401 TrainAcc 0.8700 TestAcc 0.8296 0.8950
epoch 2300 LossPred 0.5551 LossAtt 0.2279 TrainAcc 0.8200 TestAcc 0.7953 0.8250
epoch 2400 LossPred 0.3883 LossAtt 0.2370 TrainAcc 0.8800 TestAcc 0.8466 0.8650
epoch 2500 LossPred 0.3860 LossAtt 0.2357 TrainAcc 0.8600 TestAcc 0.8273 0.8650
Optimization Finished!
********** replication  20  **********
epoch   0 LossPred 0.9428 LossAtt 1.0206 TrainAcc 0.6200 TestAcc 0.5798 0.6100
epoch 100 LossPred 0.8697 LossAtt 0.3047 TrainAcc 0.6600 TestAcc 0.5623 0.6800
epoch 200 LossPred 0.8374 LossAtt 0.3104 TrainAcc 0.6800 TestAcc 0.5741 0.6700
epoch 300 LossPred 0.8222 LossAtt 0.3165 TrainAcc 0.6800 TestAcc 0.5773 0.6750
epoch 400 LossPred 0.4378 LossAtt 0.3814 TrainAcc 0.8700 TestAcc 0.7630 0.8150
epoch 500 LossPred 0.3557 LossAtt 0.3740 TrainAcc 0.8900 TestAcc 0.8158 0.8700
epoch 600 LossPred 0.3201 LossAtt 0.3664 TrainAcc 0.9000 TestAcc 0.7988 0.8650
epoch 700 LossPred 0.3029 LossAtt 0.3425 TrainAcc 0.9000 TestAcc 0.8226 0.8700
epoch 800 LossPred 0.2936 LossAtt 0.3381 TrainAcc 0.9000 TestAcc 0.7963 0.8800
epoch 900 LossPred 0.3071 LossAtt 0.3311 TrainAcc 0.9100 TestAcc 0.8163 0.8850
epoch 1000 LossPred 0.2883 LossAtt 0.3289 TrainAcc 0.9100 TestAcc 0.8381 0.8650
epoch 1100 LossPred 0.2885 LossAtt 0.3407 TrainAcc 0.9000 TestAcc 0.8191 0.8650
epoch 1200 LossPred 0.2623 LossAtt 0.3258 TrainAcc 0.9200 TestAcc 0.8436 0.8700
epoch 1300 LossPred 0.2499 LossAtt 0.3323 TrainAcc 0.9000 TestAcc 0.8463 0.8750
epoch 1400 LossPred 0.2556 LossAtt 0.3237 TrainAcc 0.9000 TestAcc 0.8408 0.8750
epoch 1500 LossPred 0.2540 LossAtt 0.3316 TrainAcc 0.9200 TestAcc 0.8403 0.8750
epoch 1600 LossPred 0.2917 LossAtt 0.3357 TrainAcc 0.8900 TestAcc 0.8126 0.8650
epoch 1700 LossPred 0.2222 LossAtt 0.3219 TrainAcc 0.9000 TestAcc 0.8448 0.9000
epoch 1800 LossPred 0.3630 LossAtt 0.3378 TrainAcc 0.8800 TestAcc 0.7895 0.8400
epoch 1900 LossPred 0.2720 LossAtt 0.3163 TrainAcc 0.9100 TestAcc 0.8481 0.8850
epoch 2000 LossPred 0.2167 LossAtt 0.3224 TrainAcc 0.9200 TestAcc 0.8428 0.8900
epoch 2100 LossPred 0.2179 LossAtt 0.3096 TrainAcc 0.9200 TestAcc 0.8361 0.8950
epoch 2200 LossPred 0.2620 LossAtt 0.3145 TrainAcc 0.9200 TestAcc 0.8493 0.8850
epoch 2300 LossPred 0.2065 LossAtt 0.3201 TrainAcc 0.9200 TestAcc 0.8353 0.9000
epoch 2400 LossPred 0.1840 LossAtt 0.3129 TrainAcc 0.9500 TestAcc 0.8413 0.9050
epoch 2500 LossPred 0.2049 LossAtt 0.3307 TrainAcc 0.9300 TestAcc 0.8343 0.8950
Optimization Finished!
********** replication  21  **********
epoch   0 LossPred 1.0034 LossAtt 1.0181 TrainAcc 0.5400 TestAcc 0.5373 0.5500
epoch 100 LossPred 0.9090 LossAtt 0.3200 TrainAcc 0.6200 TestAcc 0.5613 0.6150
epoch 200 LossPred 0.5444 LossAtt 0.2983 TrainAcc 0.8200 TestAcc 0.7773 0.7550
epoch 300 LossPred 0.4414 LossAtt 0.3061 TrainAcc 0.8600 TestAcc 0.8268 0.8600
epoch 400 LossPred 0.4259 LossAtt 0.2995 TrainAcc 0.8600 TestAcc 0.8428 0.8250
epoch 500 LossPred 0.3847 LossAtt 0.2984 TrainAcc 0.8800 TestAcc 0.8156 0.8600
epoch 600 LossPred 0.4448 LossAtt 0.2931 TrainAcc 0.8500 TestAcc 0.7970 0.8500
epoch 700 LossPred 0.6068 LossAtt 0.3002 TrainAcc 0.7800 TestAcc 0.7472 0.7750
epoch 800 LossPred 0.4241 LossAtt 0.2989 TrainAcc 0.8600 TestAcc 0.7890 0.8200
epoch 900 LossPred 0.3683 LossAtt 0.2864 TrainAcc 0.8700 TestAcc 0.8223 0.8400
epoch 1000 LossPred 0.3699 LossAtt 0.2750 TrainAcc 0.8900 TestAcc 0.8136 0.8500
epoch 1100 LossPred 0.4319 LossAtt 0.2731 TrainAcc 0.8400 TestAcc 0.7903 0.8100
epoch 1200 LossPred 0.3622 LossAtt 0.2800 TrainAcc 0.8800 TestAcc 0.8248 0.8850
epoch 1300 LossPred 0.3777 LossAtt 0.2721 TrainAcc 0.8700 TestAcc 0.8188 0.8650
epoch 1400 LossPred 0.3867 LossAtt 0.2617 TrainAcc 0.8600 TestAcc 0.8151 0.8600
epoch 1500 LossPred 0.4022 LossAtt 0.2710 TrainAcc 0.8700 TestAcc 0.7920 0.8150
epoch 1600 LossPred 0.3612 LossAtt 0.2754 TrainAcc 0.8900 TestAcc 0.8288 0.8850
epoch 1700 LossPred 0.4303 LossAtt 0.2635 TrainAcc 0.8400 TestAcc 0.7783 0.8000
epoch 1800 LossPred 0.3440 LossAtt 0.2751 TrainAcc 0.8800 TestAcc 0.8128 0.8700
epoch 1900 LossPred 0.3718 LossAtt 0.2698 TrainAcc 0.8900 TestAcc 0.8076 0.8850
epoch 2000 LossPred 0.3430 LossAtt 0.2673 TrainAcc 0.8800 TestAcc 0.8058 0.8750
epoch 2100 LossPred 0.3668 LossAtt 0.2630 TrainAcc 0.8900 TestAcc 0.8053 0.8800
epoch 2200 LossPred 0.3478 LossAtt 0.2676 TrainAcc 0.9000 TestAcc 0.8096 0.8750
epoch 2300 LossPred 0.3542 LossAtt 0.2743 TrainAcc 0.9000 TestAcc 0.8051 0.8650
epoch 2400 LossPred 0.4372 LossAtt 0.2552 TrainAcc 0.8600 TestAcc 0.7948 0.8400
epoch 2500 LossPred 0.3396 LossAtt 0.2645 TrainAcc 0.8800 TestAcc 0.8131 0.8700
Optimization Finished!
********** replication  22  **********
epoch   0 LossPred 1.0834 LossAtt 0.9910 TrainAcc 0.4900 TestAcc 0.5465 0.4850
epoch 100 LossPred 0.9381 LossAtt 0.2599 TrainAcc 0.6000 TestAcc 0.5848 0.6050
epoch 200 LossPred 0.7966 LossAtt 0.3094 TrainAcc 0.7200 TestAcc 0.6336 0.7050
epoch 300 LossPred 0.3374 LossAtt 0.3039 TrainAcc 0.8900 TestAcc 0.8594 0.8500
epoch 400 LossPred 0.2507 LossAtt 0.2938 TrainAcc 0.9000 TestAcc 0.8766 0.8750
epoch 500 LossPred 0.2269 LossAtt 0.2869 TrainAcc 0.9200 TestAcc 0.8794 0.8850
epoch 600 LossPred 0.2018 LossAtt 0.2784 TrainAcc 0.9200 TestAcc 0.8789 0.9100
epoch 700 LossPred 0.2052 LossAtt 0.2706 TrainAcc 0.9400 TestAcc 0.8829 0.9300
epoch 800 LossPred 0.2929 LossAtt 0.2617 TrainAcc 0.9100 TestAcc 0.8714 0.8750
epoch 900 LossPred 0.2464 LossAtt 0.2622 TrainAcc 0.9100 TestAcc 0.8816 0.9050
epoch 1000 LossPred 0.2043 LossAtt 0.2480 TrainAcc 0.9500 TestAcc 0.8831 0.9250
epoch 1100 LossPred 0.2183 LossAtt 0.2500 TrainAcc 0.9300 TestAcc 0.8559 0.9050
epoch 1200 LossPred 0.2353 LossAtt 0.2557 TrainAcc 0.9100 TestAcc 0.8736 0.8950
epoch 1300 LossPred 0.1627 LossAtt 0.2426 TrainAcc 0.9600 TestAcc 0.8736 0.9400
epoch 1400 LossPred 0.2598 LossAtt 0.2483 TrainAcc 0.9200 TestAcc 0.8378 0.8950
epoch 1500 LossPred 0.2803 LossAtt 0.2417 TrainAcc 0.8900 TestAcc 0.8801 0.8800
epoch 1600 LossPred 0.3389 LossAtt 0.2319 TrainAcc 0.8800 TestAcc 0.8746 0.8750
epoch 1700 LossPred 0.2494 LossAtt 0.2275 TrainAcc 0.9200 TestAcc 0.8779 0.9100
epoch 1800 LossPred 0.3830 LossAtt 0.2213 TrainAcc 0.8600 TestAcc 0.8141 0.8600
epoch 1900 LossPred 0.3497 LossAtt 0.2043 TrainAcc 0.8800 TestAcc 0.8208 0.8700
epoch 2000 LossPred 0.2970 LossAtt 0.2021 TrainAcc 0.8700 TestAcc 0.8611 0.8800
epoch 2100 LossPred 0.2779 LossAtt 0.1941 TrainAcc 0.9200 TestAcc 0.8531 0.8850
epoch 2200 LossPred 0.2145 LossAtt 0.1874 TrainAcc 0.9300 TestAcc 0.8529 0.9050
epoch 2300 LossPred 0.2772 LossAtt 0.1759 TrainAcc 0.8800 TestAcc 0.8208 0.8850
epoch 2400 LossPred 0.2184 LossAtt 0.1811 TrainAcc 0.9200 TestAcc 0.8388 0.9150
epoch 2500 LossPred 0.2973 LossAtt 0.1762 TrainAcc 0.8900 TestAcc 0.8271 0.8850
Optimization Finished!
********** replication  23  **********
epoch   0 LossPred 1.0201 LossAtt 1.0102 TrainAcc 0.5600 TestAcc 0.5343 0.5600
epoch 100 LossPred 0.9472 LossAtt 0.2418 TrainAcc 0.6000 TestAcc 0.5823 0.6000
epoch 200 LossPred 0.9028 LossAtt 0.2217 TrainAcc 0.6400 TestAcc 0.6166 0.6450
epoch 300 LossPred 0.4922 LossAtt 0.2028 TrainAcc 0.8400 TestAcc 0.7415 0.8300
epoch 400 LossPred 0.4073 LossAtt 0.1886 TrainAcc 0.8800 TestAcc 0.7800 0.8950
epoch 500 LossPred 0.4111 LossAtt 0.1940 TrainAcc 0.8900 TestAcc 0.7738 0.8900
epoch 600 LossPred 0.4156 LossAtt 0.1794 TrainAcc 0.8800 TestAcc 0.7968 0.8700
epoch 700 LossPred 0.3639 LossAtt 0.1736 TrainAcc 0.9000 TestAcc 0.7933 0.8900
epoch 800 LossPred 0.4021 LossAtt 0.1854 TrainAcc 0.8900 TestAcc 0.7970 0.8750
epoch 900 LossPred 0.4348 LossAtt 0.1799 TrainAcc 0.8800 TestAcc 0.7735 0.8900
epoch 1000 LossPred 0.3587 LossAtt 0.1760 TrainAcc 0.9000 TestAcc 0.7930 0.8800
epoch 1100 LossPred 0.3603 LossAtt 0.1726 TrainAcc 0.9000 TestAcc 0.7955 0.8800
epoch 1200 LossPred 0.4001 LossAtt 0.1704 TrainAcc 0.8900 TestAcc 0.7735 0.8800
epoch 1300 LossPred 0.4231 LossAtt 0.1669 TrainAcc 0.8800 TestAcc 0.7497 0.8650
epoch 1400 LossPred 0.3582 LossAtt 0.1646 TrainAcc 0.9000 TestAcc 0.7870 0.8700
epoch 1500 LossPred 0.5690 LossAtt 0.1492 TrainAcc 0.8200 TestAcc 0.7920 0.7500
epoch 1600 LossPred 0.4149 LossAtt 0.1606 TrainAcc 0.8900 TestAcc 0.7723 0.8850
epoch 1700 LossPred 0.4549 LossAtt 0.1528 TrainAcc 0.8700 TestAcc 0.8058 0.8450
epoch 1800 LossPred 0.5979 LossAtt 0.1598 TrainAcc 0.8100 TestAcc 0.8026 0.7500
epoch 1900 LossPred 0.3613 LossAtt 0.1523 TrainAcc 0.8900 TestAcc 0.7858 0.8650
epoch 2000 LossPred 0.6067 LossAtt 0.1626 TrainAcc 0.8400 TestAcc 0.7070 0.8050
epoch 2100 LossPred 0.3758 LossAtt 0.1459 TrainAcc 0.8900 TestAcc 0.7800 0.8750
epoch 2200 LossPred 0.3846 LossAtt 0.1481 TrainAcc 0.8800 TestAcc 0.7855 0.8700
epoch 2300 LossPred 0.3892 LossAtt 0.1483 TrainAcc 0.8800 TestAcc 0.7950 0.8700
epoch 2400 LossPred 0.3689 LossAtt 0.1503 TrainAcc 0.8900 TestAcc 0.7815 0.8800
epoch 2500 LossPred 0.7943 LossAtt 0.1769 TrainAcc 0.6500 TestAcc 0.6574 0.6900
Optimization Finished!
********** replication  24  **********
epoch   0 LossPred 0.9880 LossAtt 1.0032 TrainAcc 0.5100 TestAcc 0.5298 0.5150
epoch 100 LossPred 0.9408 LossAtt 0.2466 TrainAcc 0.6200 TestAcc 0.5766 0.6200
epoch 200 LossPred 0.9175 LossAtt 0.2409 TrainAcc 0.6300 TestAcc 0.5853 0.6300
epoch 300 LossPred 0.8142 LossAtt 0.2709 TrainAcc 0.6800 TestAcc 0.6489 0.6950
epoch 400 LossPred 0.7803 LossAtt 0.2301 TrainAcc 0.7000 TestAcc 0.6399 0.6950
epoch 500 LossPred 0.7657 LossAtt 0.2189 TrainAcc 0.7100 TestAcc 0.6384 0.6950
epoch 600 LossPred 0.7764 LossAtt 0.2077 TrainAcc 0.7000 TestAcc 0.6209 0.6850
epoch 700 LossPred 0.9467 LossAtt 0.2077 TrainAcc 0.6000 TestAcc 0.5926 0.5900
epoch 800 LossPred 0.9410 LossAtt 0.2087 TrainAcc 0.6200 TestAcc 0.5921 0.6100
epoch 900 LossPred 0.9354 LossAtt 0.2127 TrainAcc 0.6200 TestAcc 0.5928 0.6200
epoch 1000 LossPred 0.8642 LossAtt 0.2035 TrainAcc 0.6600 TestAcc 0.6129 0.6500
epoch 1100 LossPred 0.7737 LossAtt 0.2055 TrainAcc 0.6900 TestAcc 0.6544 0.6900
epoch 1200 LossPred 0.7512 LossAtt 0.2082 TrainAcc 0.7000 TestAcc 0.6306 0.6850
epoch 1300 LossPred 0.7354 LossAtt 0.2061 TrainAcc 0.7000 TestAcc 0.6512 0.6900
epoch 1400 LossPred 0.7830 LossAtt 0.2052 TrainAcc 0.6600 TestAcc 0.6279 0.7050
epoch 1500 LossPred 0.7262 LossAtt 0.2001 TrainAcc 0.7100 TestAcc 0.6431 0.6950
epoch 1600 LossPred 0.7667 LossAtt 0.1919 TrainAcc 0.6900 TestAcc 0.6522 0.6900
epoch 1700 LossPred 0.7345 LossAtt 0.1807 TrainAcc 0.7000 TestAcc 0.6301 0.6950
epoch 1800 LossPred 0.7747 LossAtt 0.1785 TrainAcc 0.6900 TestAcc 0.6639 0.6900
epoch 1900 LossPred 0.8299 LossAtt 0.1830 TrainAcc 0.6500 TestAcc 0.5671 0.6350
epoch 2000 LossPred 0.8671 LossAtt 0.1585 TrainAcc 0.6400 TestAcc 0.5641 0.6550
epoch 2100 LossPred 0.8570 LossAtt 0.1538 TrainAcc 0.6500 TestAcc 0.5490 0.6250
epoch 2200 LossPred 0.8505 LossAtt 0.1492 TrainAcc 0.6600 TestAcc 0.6144 0.6550
epoch 2300 LossPred 0.8507 LossAtt 0.1532 TrainAcc 0.6500 TestAcc 0.5926 0.6550
epoch 2400 LossPred 0.8469 LossAtt 0.1472 TrainAcc 0.6600 TestAcc 0.5981 0.6600
epoch 2500 LossPred 0.8458 LossAtt 0.1380 TrainAcc 0.6600 TestAcc 0.5606 0.6550
Optimization Finished!
********** replication  25  **********
epoch   0 LossPred 1.0137 LossAtt 1.0243 TrainAcc 0.4700 TestAcc 0.4965 0.5000
epoch 100 LossPred 0.8779 LossAtt 0.2659 TrainAcc 0.6300 TestAcc 0.5758 0.6400
epoch 200 LossPred 0.7708 LossAtt 0.3076 TrainAcc 0.7200 TestAcc 0.6319 0.6850
epoch 300 LossPred 0.5546 LossAtt 0.2600 TrainAcc 0.8000 TestAcc 0.8383 0.7800
epoch 400 LossPred 0.5578 LossAtt 0.2419 TrainAcc 0.7600 TestAcc 0.7923 0.7550
epoch 500 LossPred 0.5653 LossAtt 0.2393 TrainAcc 0.7800 TestAcc 0.7705 0.7550
epoch 600 LossPred 0.4514 LossAtt 0.2520 TrainAcc 0.8300 TestAcc 0.8428 0.8200
epoch 700 LossPred 0.7004 LossAtt 0.2571 TrainAcc 0.7300 TestAcc 0.7062 0.7400
epoch 800 LossPred 0.3841 LossAtt 0.2457 TrainAcc 0.8800 TestAcc 0.8599 0.8200
epoch 900 LossPred 0.5197 LossAtt 0.2375 TrainAcc 0.8300 TestAcc 0.8286 0.7800
epoch 1000 LossPred 0.4716 LossAtt 0.2391 TrainAcc 0.8200 TestAcc 0.7903 0.8050
epoch 1100 LossPred 0.4755 LossAtt 0.2302 TrainAcc 0.8300 TestAcc 0.7773 0.7800
epoch 1200 LossPred 0.4219 LossAtt 0.2186 TrainAcc 0.8800 TestAcc 0.7893 0.8200
epoch 1300 LossPred 0.4380 LossAtt 0.2132 TrainAcc 0.8500 TestAcc 0.8371 0.8200
epoch 1400 LossPred 0.3513 LossAtt 0.2112 TrainAcc 0.8800 TestAcc 0.8556 0.8400
epoch 1500 LossPred 0.3855 LossAtt 0.1904 TrainAcc 0.8700 TestAcc 0.8476 0.8550
epoch 1600 LossPred 0.5613 LossAtt 0.2097 TrainAcc 0.8300 TestAcc 0.7392 0.7950
epoch 1700 LossPred 0.3990 LossAtt 0.2164 TrainAcc 0.8400 TestAcc 0.8121 0.8300
epoch 1800 LossPred 0.3560 LossAtt 0.2038 TrainAcc 0.8800 TestAcc 0.8509 0.8450
epoch 1900 LossPred 0.3103 LossAtt 0.2026 TrainAcc 0.8900 TestAcc 0.8468 0.8750
epoch 2000 LossPred 0.5942 LossAtt 0.1980 TrainAcc 0.8200 TestAcc 0.8178 0.8150
epoch 2100 LossPred 0.4332 LossAtt 0.2064 TrainAcc 0.8400 TestAcc 0.8266 0.8300
epoch 2200 LossPred 0.3513 LossAtt 0.2105 TrainAcc 0.8700 TestAcc 0.8471 0.8600
epoch 2300 LossPred 0.3763 LossAtt 0.2199 TrainAcc 0.8800 TestAcc 0.7943 0.8700
epoch 2400 LossPred 0.3079 LossAtt 0.2043 TrainAcc 0.8900 TestAcc 0.8203 0.8850
epoch 2500 LossPred 0.3506 LossAtt 0.2169 TrainAcc 0.8800 TestAcc 0.8143 0.8550
Optimization Finished!
********** replication  26  **********
epoch   0 LossPred 1.0350 LossAtt 1.0025 TrainAcc 0.4900 TestAcc 0.4850 0.5050
epoch 100 LossPred 0.9737 LossAtt 0.2496 TrainAcc 0.5500 TestAcc 0.5618 0.5500
epoch 200 LossPred 0.9682 LossAtt 0.1343 TrainAcc 0.5500 TestAcc 0.5866 0.5500
epoch 300 LossPred 0.9631 LossAtt 0.1029 TrainAcc 0.5500 TestAcc 0.5861 0.5500
epoch 400 LossPred 0.9602 LossAtt 0.1030 TrainAcc 0.5500 TestAcc 0.5861 0.5500
epoch 500 LossPred 0.9589 LossAtt 0.1118 TrainAcc 0.5500 TestAcc 0.5863 0.5500
epoch 600 LossPred 0.9593 LossAtt 0.1152 TrainAcc 0.5500 TestAcc 0.5863 0.5500
epoch 700 LossPred 0.9614 LossAtt 0.1065 TrainAcc 0.5500 TestAcc 0.5761 0.5600
epoch 800 LossPred 0.9606 LossAtt 0.1047 TrainAcc 0.5500 TestAcc 0.5748 0.5500
epoch 900 LossPred 0.9581 LossAtt 0.1285 TrainAcc 0.5500 TestAcc 0.5766 0.5500
epoch 1000 LossPred 0.9556 LossAtt 0.1243 TrainAcc 0.5500 TestAcc 0.5766 0.5450
epoch 1100 LossPred 0.9524 LossAtt 0.1196 TrainAcc 0.5500 TestAcc 0.5803 0.5450
epoch 1200 LossPred 0.9454 LossAtt 0.1794 TrainAcc 0.5800 TestAcc 0.6069 0.5600
epoch 1300 LossPred 0.9633 LossAtt 0.2515 TrainAcc 0.5400 TestAcc 0.5095 0.5400
epoch 1400 LossPred 0.9105 LossAtt 0.2713 TrainAcc 0.6000 TestAcc 0.5896 0.5950
epoch 1500 LossPred 0.8561 LossAtt 0.3431 TrainAcc 0.6600 TestAcc 0.6141 0.6450
epoch 1600 LossPred 0.8735 LossAtt 0.3247 TrainAcc 0.7000 TestAcc 0.6446 0.6800
epoch 1700 LossPred 0.7712 LossAtt 0.3498 TrainAcc 0.7400 TestAcc 0.6839 0.7250
epoch 1800 LossPred 0.9422 LossAtt 0.3281 TrainAcc 0.6600 TestAcc 0.6221 0.6700
epoch 1900 LossPred 0.7652 LossAtt 0.3371 TrainAcc 0.7400 TestAcc 0.7620 0.7350
epoch 2000 LossPred 0.5149 LossAtt 0.3271 TrainAcc 0.8600 TestAcc 0.8093 0.8250
epoch 2100 LossPred 0.5488 LossAtt 0.3165 TrainAcc 0.8400 TestAcc 0.7905 0.8350
epoch 2200 LossPred 0.5279 LossAtt 0.3047 TrainAcc 0.8500 TestAcc 0.7990 0.8500
epoch 2300 LossPred 0.8400 LossAtt 0.3075 TrainAcc 0.6800 TestAcc 0.6754 0.7200
epoch 2400 LossPred 0.3253 LossAtt 0.3146 TrainAcc 0.8900 TestAcc 0.8496 0.8950
epoch 2500 LossPred 0.3124 LossAtt 0.3173 TrainAcc 0.9000 TestAcc 0.8561 0.9000
Optimization Finished!
********** replication  27  **********
epoch   0 LossPred 1.2323 LossAtt 1.0099 TrainAcc 0.3600 TestAcc 0.4452 0.3850
epoch 100 LossPred 0.8835 LossAtt 0.2344 TrainAcc 0.6300 TestAcc 0.4997 0.6200
epoch 200 LossPred 0.8737 LossAtt 0.1611 TrainAcc 0.6300 TestAcc 0.4997 0.6300
epoch 300 LossPred 0.8932 LossAtt 0.1482 TrainAcc 0.6300 TestAcc 0.4997 0.6300
epoch 400 LossPred 0.8725 LossAtt 0.0519 TrainAcc 0.6300 TestAcc 0.4997 0.6300
epoch 500 LossPred 0.8665 LossAtt 0.0984 TrainAcc 0.6400 TestAcc 0.5703 0.6300
epoch 600 LossPred 0.7635 LossAtt 0.2330 TrainAcc 0.7200 TestAcc 0.6094 0.7100
epoch 700 LossPred 0.5146 LossAtt 0.1939 TrainAcc 0.8200 TestAcc 0.7645 0.8200
epoch 800 LossPred 0.4865 LossAtt 0.1748 TrainAcc 0.8300 TestAcc 0.7683 0.8200
epoch 900 LossPred 0.4722 LossAtt 0.1682 TrainAcc 0.8200 TestAcc 0.7688 0.8250
epoch 1000 LossPred 0.5045 LossAtt 0.1646 TrainAcc 0.8100 TestAcc 0.7553 0.8400
epoch 1100 LossPred 0.4658 LossAtt 0.1523 TrainAcc 0.8300 TestAcc 0.7708 0.8200
epoch 1200 LossPred 0.4618 LossAtt 0.1577 TrainAcc 0.8400 TestAcc 0.7913 0.8250
epoch 1300 LossPred 0.4626 LossAtt 0.1539 TrainAcc 0.8300 TestAcc 0.7730 0.8250
epoch 1400 LossPred 0.5101 LossAtt 0.1562 TrainAcc 0.8100 TestAcc 0.7783 0.8450
epoch 1500 LossPred 0.4561 LossAtt 0.1561 TrainAcc 0.8400 TestAcc 0.8033 0.8250
epoch 1600 LossPred 0.4871 LossAtt 0.1630 TrainAcc 0.8400 TestAcc 0.7595 0.8250
epoch 1700 LossPred 0.4547 LossAtt 0.1602 TrainAcc 0.8400 TestAcc 0.8033 0.8250
epoch 1800 LossPred 0.4523 LossAtt 0.1512 TrainAcc 0.8400 TestAcc 0.8048 0.8250
epoch 1900 LossPred 0.4465 LossAtt 0.1633 TrainAcc 0.8400 TestAcc 0.8081 0.8350
epoch 2000 LossPred 0.4791 LossAtt 0.1598 TrainAcc 0.8300 TestAcc 0.8083 0.8250
epoch 2100 LossPred 0.4560 LossAtt 0.1644 TrainAcc 0.8300 TestAcc 0.8048 0.8350
epoch 2200 LossPred 0.4970 LossAtt 0.1748 TrainAcc 0.8100 TestAcc 0.7755 0.8400
epoch 2300 LossPred 0.5637 LossAtt 0.1733 TrainAcc 0.8000 TestAcc 0.7918 0.8300
epoch 2400 LossPred 0.5285 LossAtt 0.1787 TrainAcc 0.7900 TestAcc 0.8026 0.8200
epoch 2500 LossPred 0.4744 LossAtt 0.1851 TrainAcc 0.8600 TestAcc 0.7690 0.8350
Optimization Finished!
********** replication  28  **********
epoch   0 LossPred 1.1659 LossAtt 0.9950 TrainAcc 0.4400 TestAcc 0.4234 0.4850
epoch 100 LossPred 0.9146 LossAtt 0.3431 TrainAcc 0.6200 TestAcc 0.5743 0.6050
epoch 200 LossPred 0.8817 LossAtt 0.3305 TrainAcc 0.6300 TestAcc 0.5923 0.6150
epoch 300 LossPred 0.6076 LossAtt 0.4066 TrainAcc 0.7900 TestAcc 0.7465 0.8050
epoch 400 LossPred 0.3897 LossAtt 0.3838 TrainAcc 0.8700 TestAcc 0.8241 0.8400
epoch 500 LossPred 0.2778 LossAtt 0.3870 TrainAcc 0.9000 TestAcc 0.8251 0.8350
epoch 600 LossPred 0.2638 LossAtt 0.3804 TrainAcc 0.8900 TestAcc 0.8256 0.8650
epoch 700 LossPred 0.2349 LossAtt 0.3653 TrainAcc 0.9300 TestAcc 0.8273 0.8850
epoch 800 LossPred 0.2370 LossAtt 0.3570 TrainAcc 0.9000 TestAcc 0.8316 0.8700
epoch 900 LossPred 0.1967 LossAtt 0.3465 TrainAcc 0.8900 TestAcc 0.8283 0.8800
epoch 1000 LossPred 0.1934 LossAtt 0.3434 TrainAcc 0.9200 TestAcc 0.8261 0.8900
epoch 1100 LossPred 0.2553 LossAtt 0.3328 TrainAcc 0.9200 TestAcc 0.8308 0.8800
epoch 1200 LossPred 0.2108 LossAtt 0.3318 TrainAcc 0.9200 TestAcc 0.8133 0.8850
epoch 1300 LossPred 0.2217 LossAtt 0.3257 TrainAcc 0.9300 TestAcc 0.8151 0.8850
epoch 1400 LossPred 0.2087 LossAtt 0.3214 TrainAcc 0.9400 TestAcc 0.8163 0.9100
epoch 1500 LossPred 0.2233 LossAtt 0.3170 TrainAcc 0.9100 TestAcc 0.8121 0.9150
epoch 1600 LossPred 0.1518 LossAtt 0.3016 TrainAcc 0.9400 TestAcc 0.8243 0.9150
epoch 1700 LossPred 0.1361 LossAtt 0.2935 TrainAcc 0.9400 TestAcc 0.8328 0.9100
epoch 1800 LossPred 0.1628 LossAtt 0.3001 TrainAcc 0.9500 TestAcc 0.8263 0.9050
epoch 1900 LossPred 0.1240 LossAtt 0.3045 TrainAcc 0.9600 TestAcc 0.8301 0.9050
epoch 2000 LossPred 0.1801 LossAtt 0.3078 TrainAcc 0.9300 TestAcc 0.8208 0.9000
epoch 2100 LossPred 0.1530 LossAtt 0.3042 TrainAcc 0.9300 TestAcc 0.8323 0.9150
epoch 2200 LossPred 0.1635 LossAtt 0.3108 TrainAcc 0.9400 TestAcc 0.8288 0.9200
epoch 2300 LossPred 0.0874 LossAtt 0.3081 TrainAcc 0.9800 TestAcc 0.8298 0.9200
epoch 2400 LossPred 0.0913 LossAtt 0.3012 TrainAcc 0.9800 TestAcc 0.8288 0.9300
epoch 2500 LossPred 0.0860 LossAtt 0.2999 TrainAcc 0.9900 TestAcc 0.8313 0.9300
Optimization Finished!
********** replication  29  **********
epoch   0 LossPred 1.0273 LossAtt 1.0342 TrainAcc 0.4900 TestAcc 0.5045 0.4900
epoch 100 LossPred 0.9159 LossAtt 0.2076 TrainAcc 0.6100 TestAcc 0.5928 0.6050
epoch 200 LossPred 0.5317 LossAtt 0.2494 TrainAcc 0.8300 TestAcc 0.8191 0.8100
epoch 300 LossPred 0.7256 LossAtt 0.2590 TrainAcc 0.7400 TestAcc 0.7608 0.7550
epoch 400 LossPred 0.4838 LossAtt 0.2702 TrainAcc 0.8300 TestAcc 0.8016 0.8300
epoch 500 LossPred 0.5329 LossAtt 0.2413 TrainAcc 0.8500 TestAcc 0.7675 0.8400
epoch 600 LossPred 0.4926 LossAtt 0.2379 TrainAcc 0.8400 TestAcc 0.7995 0.8250
epoch 700 LossPred 0.3649 LossAtt 0.2402 TrainAcc 0.8800 TestAcc 0.8393 0.8500
epoch 800 LossPred 0.3839 LossAtt 0.2309 TrainAcc 0.8600 TestAcc 0.8388 0.8500
epoch 900 LossPred 0.3166 LossAtt 0.2196 TrainAcc 0.8900 TestAcc 0.8611 0.8650
epoch 1000 LossPred 0.2996 LossAtt 0.2138 TrainAcc 0.9000 TestAcc 0.8614 0.8650
epoch 1100 LossPred 0.2637 LossAtt 0.2257 TrainAcc 0.9000 TestAcc 0.8571 0.8850
epoch 1200 LossPred 0.2919 LossAtt 0.2282 TrainAcc 0.8900 TestAcc 0.8571 0.8700
epoch 1300 LossPred 0.3617 LossAtt 0.2338 TrainAcc 0.8600 TestAcc 0.8286 0.8500
epoch 1400 LossPred 0.2670 LossAtt 0.2340 TrainAcc 0.9100 TestAcc 0.8584 0.8700
epoch 1500 LossPred 0.2596 LossAtt 0.2294 TrainAcc 0.9100 TestAcc 0.8596 0.8700
epoch 1600 LossPred 0.2434 LossAtt 0.2342 TrainAcc 0.9200 TestAcc 0.8539 0.8500
epoch 1700 LossPred 0.2547 LossAtt 0.2223 TrainAcc 0.9000 TestAcc 0.8461 0.8500
epoch 1800 LossPred 0.2637 LossAtt 0.2279 TrainAcc 0.9100 TestAcc 0.8433 0.8550
epoch 1900 LossPred 0.3727 LossAtt 0.2195 TrainAcc 0.8800 TestAcc 0.8473 0.8450
epoch 2000 LossPred 0.2155 LossAtt 0.2144 TrainAcc 0.9200 TestAcc 0.8478 0.8750
epoch 2100 LossPred 0.3059 LossAtt 0.2236 TrainAcc 0.9100 TestAcc 0.8428 0.8700
epoch 2200 LossPred 0.2928 LossAtt 0.2156 TrainAcc 0.9100 TestAcc 0.8401 0.8650
epoch 2300 LossPred 0.2175 LossAtt 0.2252 TrainAcc 0.9300 TestAcc 0.8456 0.8600
epoch 2400 LossPred 0.2507 LossAtt 0.2210 TrainAcc 0.9300 TestAcc 0.8451 0.8750
epoch 2500 LossPred 0.2927 LossAtt 0.2237 TrainAcc 0.9200 TestAcc 0.8413 0.8750
Optimization Finished!
********** replication  30  **********
epoch   0 LossPred 1.1724 LossAtt 1.0392 TrainAcc 0.3400 TestAcc 0.3924 0.3750
epoch 100 LossPred 0.8515 LossAtt 0.2519 TrainAcc 0.6700 TestAcc 0.5813 0.6700
epoch 200 LossPred 0.6200 LossAtt 0.2431 TrainAcc 0.7900 TestAcc 0.7678 0.7800
epoch 300 LossPred 0.3291 LossAtt 0.2232 TrainAcc 0.9200 TestAcc 0.8498 0.8500
epoch 400 LossPred 0.3560 LossAtt 0.2217 TrainAcc 0.8800 TestAcc 0.8331 0.8600
epoch 500 LossPred 0.2980 LossAtt 0.2173 TrainAcc 0.9100 TestAcc 0.8571 0.8800
epoch 600 LossPred 0.4013 LossAtt 0.2178 TrainAcc 0.8900 TestAcc 0.7788 0.8450
epoch 700 LossPred 0.3484 LossAtt 0.2094 TrainAcc 0.8800 TestAcc 0.8293 0.8450
epoch 800 LossPred 0.3734 LossAtt 0.2100 TrainAcc 0.9000 TestAcc 0.8403 0.8650
epoch 900 LossPred 0.3646 LossAtt 0.2319 TrainAcc 0.8900 TestAcc 0.8218 0.8600
epoch 1000 LossPred 0.4602 LossAtt 0.2207 TrainAcc 0.8800 TestAcc 0.7703 0.8400
epoch 1100 LossPred 0.3968 LossAtt 0.2133 TrainAcc 0.8900 TestAcc 0.8396 0.8400
epoch 1200 LossPred 0.3096 LossAtt 0.2128 TrainAcc 0.9000 TestAcc 0.8468 0.8650
epoch 1300 LossPred 0.3742 LossAtt 0.2097 TrainAcc 0.8700 TestAcc 0.8351 0.8700
epoch 1400 LossPred 0.3660 LossAtt 0.2067 TrainAcc 0.8800 TestAcc 0.8228 0.8700
epoch 1500 LossPred 0.4227 LossAtt 0.2125 TrainAcc 0.8900 TestAcc 0.7875 0.8300
epoch 1600 LossPred 0.3163 LossAtt 0.2034 TrainAcc 0.9100 TestAcc 0.8401 0.8700
epoch 1700 LossPred 0.4902 LossAtt 0.1993 TrainAcc 0.8300 TestAcc 0.8123 0.8550
epoch 1800 LossPred 0.2699 LossAtt 0.2004 TrainAcc 0.9100 TestAcc 0.8521 0.8650
epoch 1900 LossPred 0.3179 LossAtt 0.1964 TrainAcc 0.9000 TestAcc 0.8416 0.8750
epoch 2000 LossPred 0.3214 LossAtt 0.2004 TrainAcc 0.9000 TestAcc 0.8371 0.8850
epoch 2100 LossPred 0.5711 LossAtt 0.1956 TrainAcc 0.8200 TestAcc 0.7848 0.8200
epoch 2200 LossPred 0.4318 LossAtt 0.2012 TrainAcc 0.8700 TestAcc 0.7903 0.8450
epoch 2300 LossPred 0.4238 LossAtt 0.1922 TrainAcc 0.8700 TestAcc 0.8073 0.8550
epoch 2400 LossPred 0.3298 LossAtt 0.1876 TrainAcc 0.9100 TestAcc 0.8318 0.8700
epoch 2500 LossPred 0.3546 LossAtt 0.1850 TrainAcc 0.8900 TestAcc 0.8248 0.8800
Optimization Finished!
********** replication  31  **********
epoch   0 LossPred 1.1107 LossAtt 1.0051 TrainAcc 0.5000 TestAcc 0.4327 0.5200
epoch 100 LossPred 0.9606 LossAtt 0.2795 TrainAcc 0.6000 TestAcc 0.5420 0.6000
epoch 200 LossPred 0.9162 LossAtt 0.2704 TrainAcc 0.6600 TestAcc 0.4990 0.6600
epoch 300 LossPred 0.8001 LossAtt 0.3208 TrainAcc 0.7000 TestAcc 0.5090 0.7000
epoch 400 LossPred 0.7094 LossAtt 0.2893 TrainAcc 0.7400 TestAcc 0.5115 0.7000
epoch 500 LossPred 0.6690 LossAtt 0.2958 TrainAcc 0.7600 TestAcc 0.5415 0.7150
epoch 600 LossPred 0.6217 LossAtt 0.2914 TrainAcc 0.7800 TestAcc 0.5463 0.7350
epoch 700 LossPred 0.5883 LossAtt 0.2913 TrainAcc 0.8200 TestAcc 0.5591 0.7200
epoch 800 LossPred 0.5554 LossAtt 0.2875 TrainAcc 0.8300 TestAcc 0.5728 0.7500
epoch 900 LossPred 0.5094 LossAtt 0.3017 TrainAcc 0.8400 TestAcc 0.5806 0.7550
epoch 1000 LossPred 0.4806 LossAtt 0.2843 TrainAcc 0.8500 TestAcc 0.5818 0.7400
epoch 1100 LossPred 0.4873 LossAtt 0.2710 TrainAcc 0.8500 TestAcc 0.5876 0.7750
epoch 1200 LossPred 0.4965 LossAtt 0.2585 TrainAcc 0.8500 TestAcc 0.5871 0.7800
epoch 1300 LossPred 0.4517 LossAtt 0.2512 TrainAcc 0.8700 TestAcc 0.5713 0.7550
epoch 1400 LossPred 0.4402 LossAtt 0.2471 TrainAcc 0.8700 TestAcc 0.5703 0.7700
epoch 1500 LossPred 0.4211 LossAtt 0.2566 TrainAcc 0.9000 TestAcc 0.5678 0.7750
epoch 1600 LossPred 0.4294 LossAtt 0.2416 TrainAcc 0.8600 TestAcc 0.5633 0.7800
epoch 1700 LossPred 0.4029 LossAtt 0.2390 TrainAcc 0.8800 TestAcc 0.5743 0.7800
epoch 1800 LossPred 0.3944 LossAtt 0.2413 TrainAcc 0.9000 TestAcc 0.5686 0.7850
epoch 1900 LossPred 0.3917 LossAtt 0.2344 TrainAcc 0.9000 TestAcc 0.5748 0.8000
epoch 2000 LossPred 0.3876 LossAtt 0.2334 TrainAcc 0.9000 TestAcc 0.5708 0.8050
epoch 2100 LossPred 0.3819 LossAtt 0.2482 TrainAcc 0.9100 TestAcc 0.5666 0.7900
epoch 2200 LossPred 0.4036 LossAtt 0.2501 TrainAcc 0.9000 TestAcc 0.5666 0.7800
epoch 2300 LossPred 0.4034 LossAtt 0.2500 TrainAcc 0.9000 TestAcc 0.5661 0.7700
epoch 2400 LossPred 0.4357 LossAtt 0.2562 TrainAcc 0.8800 TestAcc 0.5631 0.7800
epoch 2500 LossPred 0.3917 LossAtt 0.2398 TrainAcc 0.8900 TestAcc 0.5681 0.7950
Optimization Finished!
********** replication  32  **********
epoch   0 LossPred 1.0346 LossAtt 0.9833 TrainAcc 0.4600 TestAcc 0.5320 0.4650
epoch 100 LossPred 0.9433 LossAtt 0.2111 TrainAcc 0.6000 TestAcc 0.5398 0.5900
epoch 200 LossPred 0.9325 LossAtt 0.1971 TrainAcc 0.5800 TestAcc 0.5448 0.5800
epoch 300 LossPred 0.8886 LossAtt 0.2363 TrainAcc 0.6200 TestAcc 0.5413 0.6250
epoch 400 LossPred 0.8108 LossAtt 0.2747 TrainAcc 0.6500 TestAcc 0.5568 0.6400
epoch 500 LossPred 0.7395 LossAtt 0.3016 TrainAcc 0.7000 TestAcc 0.5370 0.6900
epoch 600 LossPred 0.6712 LossAtt 0.3428 TrainAcc 0.7400 TestAcc 0.5410 0.7450
epoch 700 LossPred 0.5679 LossAtt 0.4098 TrainAcc 0.8200 TestAcc 0.5528 0.7350
epoch 800 LossPred 0.5361 LossAtt 0.4067 TrainAcc 0.8300 TestAcc 0.5573 0.7400
epoch 900 LossPred 0.4703 LossAtt 0.4230 TrainAcc 0.8600 TestAcc 0.5526 0.7600
epoch 1000 LossPred 0.4442 LossAtt 0.4185 TrainAcc 0.8600 TestAcc 0.5501 0.7950
epoch 1100 LossPred 0.4597 LossAtt 0.4204 TrainAcc 0.8400 TestAcc 0.5606 0.7800
epoch 1200 LossPred 0.4274 LossAtt 0.4216 TrainAcc 0.8500 TestAcc 0.5588 0.7700
epoch 1300 LossPred 0.4992 LossAtt 0.4339 TrainAcc 0.8200 TestAcc 0.5541 0.7800
epoch 1400 LossPred 0.3819 LossAtt 0.4302 TrainAcc 0.8900 TestAcc 0.5618 0.7700
epoch 1500 LossPred 0.3879 LossAtt 0.4289 TrainAcc 0.8600 TestAcc 0.5571 0.7750
epoch 1600 LossPred 0.4090 LossAtt 0.4238 TrainAcc 0.8900 TestAcc 0.5608 0.7750
epoch 1700 LossPred 0.4264 LossAtt 0.4261 TrainAcc 0.8600 TestAcc 0.5538 0.7750
epoch 1800 LossPred 0.5199 LossAtt 0.4293 TrainAcc 0.8400 TestAcc 0.5430 0.7600
epoch 1900 LossPred 0.3878 LossAtt 0.4046 TrainAcc 0.8800 TestAcc 0.5556 0.8100
epoch 2000 LossPred 0.4427 LossAtt 0.4026 TrainAcc 0.8300 TestAcc 0.5488 0.7850
epoch 2100 LossPred 0.3661 LossAtt 0.3993 TrainAcc 0.8900 TestAcc 0.5571 0.7950
epoch 2200 LossPred 0.3479 LossAtt 0.3965 TrainAcc 0.8900 TestAcc 0.5571 0.8000
epoch 2300 LossPred 0.3474 LossAtt 0.4033 TrainAcc 0.8800 TestAcc 0.5518 0.8100
epoch 2400 LossPred 0.3795 LossAtt 0.4005 TrainAcc 0.8700 TestAcc 0.5543 0.7850
epoch 2500 LossPred 0.3297 LossAtt 0.3957 TrainAcc 0.8700 TestAcc 0.5576 0.8200
Optimization Finished!
********** replication  33  **********
epoch   0 LossPred 1.0144 LossAtt 1.0251 TrainAcc 0.4800 TestAcc 0.4715 0.4900
epoch 100 LossPred 0.9441 LossAtt 0.3346 TrainAcc 0.6000 TestAcc 0.5863 0.5900
epoch 200 LossPred 0.2819 LossAtt 0.3793 TrainAcc 0.9300 TestAcc 0.8418 0.8850
epoch 300 LossPred 0.2185 LossAtt 0.3219 TrainAcc 0.9400 TestAcc 0.8311 0.8950
epoch 400 LossPred 0.2232 LossAtt 0.2860 TrainAcc 0.9500 TestAcc 0.8514 0.9200
epoch 500 LossPred 0.1941 LossAtt 0.2751 TrainAcc 0.9500 TestAcc 0.8431 0.9350
epoch 600 LossPred 0.3170 LossAtt 0.2914 TrainAcc 0.9100 TestAcc 0.8246 0.9100
epoch 700 LossPred 0.2504 LossAtt 0.2763 TrainAcc 0.9300 TestAcc 0.8166 0.9250
epoch 800 LossPred 0.2374 LossAtt 0.2716 TrainAcc 0.9200 TestAcc 0.8176 0.9150
epoch 900 LossPred 0.1720 LossAtt 0.2559 TrainAcc 0.9500 TestAcc 0.8436 0.9300
epoch 1000 LossPred 0.2146 LossAtt 0.2603 TrainAcc 0.9400 TestAcc 0.8198 0.9250
epoch 1100 LossPred 0.1708 LossAtt 0.2443 TrainAcc 0.9600 TestAcc 0.8398 0.9400
epoch 1200 LossPred 0.1731 LossAtt 0.2272 TrainAcc 0.9500 TestAcc 0.8351 0.9400
epoch 1300 LossPred 0.1826 LossAtt 0.2184 TrainAcc 0.9500 TestAcc 0.8223 0.9300
epoch 1400 LossPred 0.1697 LossAtt 0.2132 TrainAcc 0.9500 TestAcc 0.8296 0.9400
epoch 1500 LossPred 0.1757 LossAtt 0.2050 TrainAcc 0.9500 TestAcc 0.8263 0.9350
epoch 1600 LossPred 0.1340 LossAtt 0.1996 TrainAcc 0.9600 TestAcc 0.8261 0.9300
epoch 1700 LossPred 0.1693 LossAtt 0.2082 TrainAcc 0.9600 TestAcc 0.8286 0.9450
epoch 1800 LossPred 0.1498 LossAtt 0.2061 TrainAcc 0.9400 TestAcc 0.8261 0.9350
epoch 1900 LossPred 0.1581 LossAtt 0.2023 TrainAcc 0.9600 TestAcc 0.8166 0.9400
epoch 2000 LossPred 0.1514 LossAtt 0.2057 TrainAcc 0.9500 TestAcc 0.8206 0.9450
epoch 2100 LossPred 0.1550 LossAtt 0.1971 TrainAcc 0.9600 TestAcc 0.8193 0.9500
epoch 2200 LossPred 0.1167 LossAtt 0.2084 TrainAcc 0.9700 TestAcc 0.8133 0.9500
epoch 2300 LossPred 0.1443 LossAtt 0.2024 TrainAcc 0.9500 TestAcc 0.8156 0.9450
epoch 2400 LossPred 0.1336 LossAtt 0.2038 TrainAcc 0.9600 TestAcc 0.8116 0.9400
epoch 2500 LossPred 0.1285 LossAtt 0.1992 TrainAcc 0.9600 TestAcc 0.8156 0.9400
Optimization Finished!
********** replication  34  **********
epoch   0 LossPred 1.0126 LossAtt 1.0270 TrainAcc 0.5500 TestAcc 0.5368 0.5450
epoch 100 LossPred 0.9055 LossAtt 0.2927 TrainAcc 0.6400 TestAcc 0.5921 0.6400
epoch 200 LossPred 0.8952 LossAtt 0.1556 TrainAcc 0.6400 TestAcc 0.5818 0.6400
epoch 300 LossPred 0.8535 LossAtt 0.2324 TrainAcc 0.6700 TestAcc 0.6044 0.6750
epoch 400 LossPred 0.5867 LossAtt 0.1737 TrainAcc 0.8200 TestAcc 0.7848 0.7650
epoch 500 LossPred 0.6617 LossAtt 0.1724 TrainAcc 0.7400 TestAcc 0.7948 0.7400
epoch 600 LossPred 0.6607 LossAtt 0.1513 TrainAcc 0.7300 TestAcc 0.7530 0.7200
epoch 700 LossPred 0.6354 LossAtt 0.1623 TrainAcc 0.7700 TestAcc 0.8031 0.7400
epoch 800 LossPred 0.6513 LossAtt 0.1574 TrainAcc 0.7800 TestAcc 0.7618 0.7500
epoch 900 LossPred 0.6424 LossAtt 0.1458 TrainAcc 0.7300 TestAcc 0.7610 0.7400
epoch 1000 LossPred 0.6456 LossAtt 0.1521 TrainAcc 0.7300 TestAcc 0.7482 0.7300
epoch 1100 LossPred 0.6109 LossAtt 0.1472 TrainAcc 0.8100 TestAcc 0.7698 0.7700
epoch 1200 LossPred 0.6460 LossAtt 0.1489 TrainAcc 0.7300 TestAcc 0.7477 0.7300
epoch 1300 LossPred 0.6427 LossAtt 0.1438 TrainAcc 0.7900 TestAcc 0.7360 0.7800
epoch 1400 LossPred 0.6630 LossAtt 0.1320 TrainAcc 0.7700 TestAcc 0.7147 0.7300
epoch 1500 LossPred 0.6195 LossAtt 0.1561 TrainAcc 0.8100 TestAcc 0.7720 0.7450
epoch 1600 LossPred 0.6010 LossAtt 0.1507 TrainAcc 0.8200 TestAcc 0.7648 0.7750
epoch 1700 LossPred 0.6333 LossAtt 0.1531 TrainAcc 0.7900 TestAcc 0.7417 0.7650
epoch 1800 LossPred 0.6078 LossAtt 0.1349 TrainAcc 0.8000 TestAcc 0.7555 0.7850
epoch 1900 LossPred 0.5948 LossAtt 0.1508 TrainAcc 0.8200 TestAcc 0.7635 0.7850
epoch 2000 LossPred 0.5937 LossAtt 0.1520 TrainAcc 0.8100 TestAcc 0.7655 0.7850
epoch 2100 LossPred 0.8829 LossAtt 0.1237 TrainAcc 0.7000 TestAcc 0.6767 0.6850
epoch 2200 LossPred 0.7969 LossAtt 0.1150 TrainAcc 0.7000 TestAcc 0.6934 0.7000
epoch 2300 LossPred 0.7937 LossAtt 0.1101 TrainAcc 0.7300 TestAcc 0.7052 0.7100
epoch 2400 LossPred 0.7833 LossAtt 0.1026 TrainAcc 0.7000 TestAcc 0.6989 0.7200
epoch 2500 LossPred 0.7010 LossAtt 0.1105 TrainAcc 0.7200 TestAcc 0.7180 0.7100
Optimization Finished!
********** replication  35  **********
epoch   0 LossPred 1.0852 LossAtt 1.0136 TrainAcc 0.4900 TestAcc 0.5260 0.4850
epoch 100 LossPred 0.9224 LossAtt 0.2739 TrainAcc 0.6100 TestAcc 0.5828 0.6050
epoch 200 LossPred 0.8795 LossAtt 0.2450 TrainAcc 0.6400 TestAcc 0.6139 0.6400
epoch 300 LossPred 0.4609 LossAtt 0.2579 TrainAcc 0.8400 TestAcc 0.7420 0.8150
epoch 400 LossPred 0.9944 LossAtt 0.2358 TrainAcc 0.6800 TestAcc 0.5776 0.6700
epoch 500 LossPred 0.2739 LossAtt 0.2382 TrainAcc 0.9200 TestAcc 0.8023 0.8750
epoch 600 LossPred 0.2600 LossAtt 0.2377 TrainAcc 0.9200 TestAcc 0.8103 0.8550
epoch 700 LossPred 0.2729 LossAtt 0.2267 TrainAcc 0.9300 TestAcc 0.8148 0.8800
epoch 800 LossPred 0.2908 LossAtt 0.2240 TrainAcc 0.9000 TestAcc 0.8036 0.8500
epoch 900 LossPred 0.2435 LossAtt 0.2062 TrainAcc 0.9200 TestAcc 0.8218 0.8900
epoch 1000 LossPred 0.2125 LossAtt 0.1978 TrainAcc 0.9200 TestAcc 0.8231 0.8700
epoch 1100 LossPred 0.2350 LossAtt 0.2007 TrainAcc 0.9200 TestAcc 0.8506 0.8900
epoch 1200 LossPred 0.2548 LossAtt 0.1985 TrainAcc 0.9100 TestAcc 0.8423 0.8850
epoch 1300 LossPred 0.2698 LossAtt 0.1928 TrainAcc 0.9000 TestAcc 0.8103 0.8400
epoch 1400 LossPred 0.2453 LossAtt 0.1859 TrainAcc 0.9300 TestAcc 0.8371 0.9000
epoch 1500 LossPred 0.3026 LossAtt 0.1957 TrainAcc 0.9000 TestAcc 0.8448 0.8750
epoch 1600 LossPred 0.2265 LossAtt 0.1767 TrainAcc 0.9200 TestAcc 0.8416 0.8900
epoch 1700 LossPred 0.2105 LossAtt 0.1722 TrainAcc 0.9300 TestAcc 0.8296 0.8750
epoch 1800 LossPred 0.2173 LossAtt 0.1730 TrainAcc 0.9300 TestAcc 0.8291 0.9000
epoch 1900 LossPred 0.3484 LossAtt 0.1681 TrainAcc 0.8700 TestAcc 0.8183 0.8950
epoch 2000 LossPred 0.2641 LossAtt 0.1687 TrainAcc 0.9200 TestAcc 0.8333 0.9050
epoch 2100 LossPred 0.2325 LossAtt 0.1668 TrainAcc 0.9200 TestAcc 0.8393 0.8850
epoch 2200 LossPred 0.2196 LossAtt 0.1652 TrainAcc 0.9300 TestAcc 0.8363 0.9000
epoch 2300 LossPred 0.2280 LossAtt 0.1595 TrainAcc 0.9300 TestAcc 0.8363 0.9000
epoch 2400 LossPred 0.2075 LossAtt 0.1603 TrainAcc 0.9300 TestAcc 0.8368 0.9200
epoch 2500 LossPred 0.2131 LossAtt 0.1631 TrainAcc 0.9300 TestAcc 0.8441 0.8950
Optimization Finished!
********** replication  36  **********
epoch   0 LossPred 1.0394 LossAtt 1.0354 TrainAcc 0.4300 TestAcc 0.5148 0.5100
epoch 100 LossPred 0.8879 LossAtt 0.2806 TrainAcc 0.6600 TestAcc 0.6026 0.6600
epoch 200 LossPred 0.6842 LossAtt 0.2902 TrainAcc 0.7700 TestAcc 0.7402 0.7950
epoch 300 LossPred 0.3500 LossAtt 0.2386 TrainAcc 0.8800 TestAcc 0.8754 0.8750
epoch 400 LossPred 0.2621 LossAtt 0.2163 TrainAcc 0.9100 TestAcc 0.8674 0.8600
epoch 500 LossPred 0.3209 LossAtt 0.1962 TrainAcc 0.9100 TestAcc 0.8711 0.8750
epoch 600 LossPred 0.3519 LossAtt 0.1994 TrainAcc 0.8800 TestAcc 0.8298 0.8600
epoch 700 LossPred 0.4983 LossAtt 0.1870 TrainAcc 0.8500 TestAcc 0.7808 0.8200
epoch 800 LossPred 0.4562 LossAtt 0.1918 TrainAcc 0.8400 TestAcc 0.8313 0.8450
epoch 900 LossPred 0.2811 LossAtt 0.1842 TrainAcc 0.9100 TestAcc 0.8626 0.8950
epoch 1000 LossPred 0.2968 LossAtt 0.1781 TrainAcc 0.9100 TestAcc 0.8599 0.8950
epoch 1100 LossPred 0.6507 LossAtt 0.1694 TrainAcc 0.7800 TestAcc 0.7312 0.7650
epoch 1200 LossPred 0.2665 LossAtt 0.1791 TrainAcc 0.9100 TestAcc 0.8674 0.9050
epoch 1300 LossPred 0.2387 LossAtt 0.1692 TrainAcc 0.9100 TestAcc 0.8791 0.9050
epoch 1400 LossPred 0.4713 LossAtt 0.1768 TrainAcc 0.8500 TestAcc 0.7973 0.8300
epoch 1500 LossPred 0.2957 LossAtt 0.1825 TrainAcc 0.9200 TestAcc 0.8576 0.9050
epoch 1600 LossPred 0.3041 LossAtt 0.1737 TrainAcc 0.9000 TestAcc 0.8824 0.8700
epoch 1700 LossPred 0.4515 LossAtt 0.1910 TrainAcc 0.8500 TestAcc 0.7838 0.8400
epoch 1800 LossPred 0.2991 LossAtt 0.1916 TrainAcc 0.9000 TestAcc 0.8634 0.8800
epoch 1900 LossPred 0.2314 LossAtt 0.1949 TrainAcc 0.9100 TestAcc 0.8721 0.9050
epoch 2000 LossPred 0.2240 LossAtt 0.1963 TrainAcc 0.9500 TestAcc 0.8724 0.9200
epoch 2100 LossPred 0.2442 LossAtt 0.2014 TrainAcc 0.9000 TestAcc 0.8729 0.9050
epoch 2200 LossPred 0.2214 LossAtt 0.1995 TrainAcc 0.9300 TestAcc 0.8656 0.9100
epoch 2300 LossPred 0.2231 LossAtt 0.2015 TrainAcc 0.9400 TestAcc 0.8589 0.9200
epoch 2400 LossPred 0.2488 LossAtt 0.2011 TrainAcc 0.9400 TestAcc 0.8456 0.9100
epoch 2500 LossPred 0.2626 LossAtt 0.1986 TrainAcc 0.9200 TestAcc 0.8431 0.8900
Optimization Finished!
********** replication  37  **********
epoch   0 LossPred 0.9817 LossAtt 1.0146 TrainAcc 0.5800 TestAcc 0.5270 0.5600
epoch 100 LossPred 0.8564 LossAtt 0.3368 TrainAcc 0.6500 TestAcc 0.5738 0.6500
epoch 200 LossPred 0.4197 LossAtt 0.3477 TrainAcc 0.8700 TestAcc 0.8263 0.8350
epoch 300 LossPred 0.3262 LossAtt 0.3467 TrainAcc 0.9000 TestAcc 0.8398 0.8850
epoch 400 LossPred 0.2928 LossAtt 0.3444 TrainAcc 0.9100 TestAcc 0.8403 0.8700
epoch 500 LossPred 0.3118 LossAtt 0.3354 TrainAcc 0.9100 TestAcc 0.8296 0.8550
epoch 600 LossPred 0.2662 LossAtt 0.3274 TrainAcc 0.9100 TestAcc 0.8351 0.8700
epoch 700 LossPred 0.2955 LossAtt 0.3142 TrainAcc 0.9000 TestAcc 0.8451 0.8750
epoch 800 LossPred 0.2687 LossAtt 0.2944 TrainAcc 0.9300 TestAcc 0.8423 0.8850
epoch 900 LossPred 0.2595 LossAtt 0.2838 TrainAcc 0.9200 TestAcc 0.8446 0.9050
epoch 1000 LossPred 0.2608 LossAtt 0.2844 TrainAcc 0.9200 TestAcc 0.8368 0.9000
epoch 1100 LossPred 0.2883 LossAtt 0.2612 TrainAcc 0.9000 TestAcc 0.8368 0.8900
epoch 1200 LossPred 0.3042 LossAtt 0.2589 TrainAcc 0.8900 TestAcc 0.8519 0.8950
epoch 1300 LossPred 0.3555 LossAtt 0.2591 TrainAcc 0.8800 TestAcc 0.8176 0.8750
epoch 1400 LossPred 0.3572 LossAtt 0.2782 TrainAcc 0.8900 TestAcc 0.8453 0.8750
epoch 1500 LossPred 0.3120 LossAtt 0.2646 TrainAcc 0.9000 TestAcc 0.8183 0.8950
epoch 1600 LossPred 0.1947 LossAtt 0.2659 TrainAcc 0.9500 TestAcc 0.8473 0.9200
epoch 1700 LossPred 0.2450 LossAtt 0.2573 TrainAcc 0.9200 TestAcc 0.8406 0.8900
epoch 1800 LossPred 0.1586 LossAtt 0.2632 TrainAcc 0.9500 TestAcc 0.8476 0.9450
epoch 1900 LossPred 0.1982 LossAtt 0.2631 TrainAcc 0.9400 TestAcc 0.8491 0.9300
epoch 2000 LossPred 0.2133 LossAtt 0.2619 TrainAcc 0.9300 TestAcc 0.8463 0.9250
epoch 2100 LossPred 0.1381 LossAtt 0.2865 TrainAcc 0.9600 TestAcc 0.8541 0.9350
epoch 2200 LossPred 0.1315 LossAtt 0.2654 TrainAcc 0.9600 TestAcc 0.8398 0.9350
epoch 2300 LossPred 0.1600 LossAtt 0.2669 TrainAcc 0.9500 TestAcc 0.8488 0.9450
epoch 2400 LossPred 0.1666 LossAtt 0.2789 TrainAcc 0.9500 TestAcc 0.8323 0.9300
epoch 2500 LossPred 0.1921 LossAtt 0.2786 TrainAcc 0.9400 TestAcc 0.8441 0.9250
Optimization Finished!
********** replication  38  **********
epoch   0 LossPred 1.0486 LossAtt 1.0032 TrainAcc 0.5100 TestAcc 0.5523 0.5500
epoch 100 LossPred 0.8885 LossAtt 0.2196 TrainAcc 0.6600 TestAcc 0.5818 0.6600
epoch 200 LossPred 0.8698 LossAtt 0.1518 TrainAcc 0.6600 TestAcc 0.5818 0.6600
epoch 300 LossPred 0.4647 LossAtt 0.2006 TrainAcc 0.8500 TestAcc 0.8173 0.8450
epoch 400 LossPred 0.6107 LossAtt 0.1924 TrainAcc 0.8100 TestAcc 0.7563 0.8150
epoch 500 LossPred 0.3665 LossAtt 0.1870 TrainAcc 0.8600 TestAcc 0.8303 0.8500
epoch 600 LossPred 0.4639 LossAtt 0.1951 TrainAcc 0.8500 TestAcc 0.8098 0.8500
epoch 700 LossPred 0.4544 LossAtt 0.1961 TrainAcc 0.8500 TestAcc 0.8118 0.8450
epoch 800 LossPred 0.3372 LossAtt 0.1996 TrainAcc 0.8900 TestAcc 0.8421 0.8500
epoch 900 LossPred 0.3390 LossAtt 0.1962 TrainAcc 0.8800 TestAcc 0.8446 0.8500
epoch 1000 LossPred 0.3453 LossAtt 0.2022 TrainAcc 0.8800 TestAcc 0.8471 0.8450
epoch 1100 LossPred 0.3389 LossAtt 0.1934 TrainAcc 0.9000 TestAcc 0.8223 0.8700
epoch 1200 LossPred 0.3175 LossAtt 0.1853 TrainAcc 0.8900 TestAcc 0.8393 0.8700
epoch 1300 LossPred 0.3173 LossAtt 0.1919 TrainAcc 0.9000 TestAcc 0.8338 0.8850
epoch 1400 LossPred 0.3292 LossAtt 0.1929 TrainAcc 0.8900 TestAcc 0.8323 0.8850
epoch 1500 LossPred 0.3166 LossAtt 0.1874 TrainAcc 0.9000 TestAcc 0.8366 0.8850
epoch 1600 LossPred 0.3063 LossAtt 0.1814 TrainAcc 0.9000 TestAcc 0.8411 0.8850
epoch 1700 LossPred 0.4564 LossAtt 0.1907 TrainAcc 0.8600 TestAcc 0.8286 0.8700
epoch 1800 LossPred 0.3403 LossAtt 0.1797 TrainAcc 0.8800 TestAcc 0.8361 0.8850
epoch 1900 LossPred 0.3424 LossAtt 0.1933 TrainAcc 0.8700 TestAcc 0.8286 0.8750
epoch 2000 LossPred 0.3279 LossAtt 0.1990 TrainAcc 0.8800 TestAcc 0.8233 0.8850
epoch 2100 LossPred 0.2920 LossAtt 0.1951 TrainAcc 0.9100 TestAcc 0.8463 0.9050
epoch 2200 LossPred 0.6243 LossAtt 0.1899 TrainAcc 0.7900 TestAcc 0.7122 0.7700
epoch 2300 LossPred 0.3228 LossAtt 0.1879 TrainAcc 0.8800 TestAcc 0.8351 0.8950
epoch 2400 LossPred 0.2968 LossAtt 0.2069 TrainAcc 0.8900 TestAcc 0.8436 0.9050
epoch 2500 LossPred 0.2980 LossAtt 0.1959 TrainAcc 0.8900 TestAcc 0.8333 0.9000
Optimization Finished!
********** replication  39  **********
epoch   0 LossPred 1.0183 LossAtt 1.0019 TrainAcc 0.4800 TestAcc 0.4837 0.4800
epoch 100 LossPred 0.9480 LossAtt 0.3137 TrainAcc 0.6000 TestAcc 0.5723 0.5900
epoch 200 LossPred 0.9743 LossAtt 0.3422 TrainAcc 0.6000 TestAcc 0.6076 0.6000
epoch 300 LossPred 0.7543 LossAtt 0.3235 TrainAcc 0.7200 TestAcc 0.6934 0.7350
epoch 400 LossPred 0.5681 LossAtt 0.3355 TrainAcc 0.8300 TestAcc 0.7725 0.7800
epoch 500 LossPred 0.6254 LossAtt 0.3252 TrainAcc 0.7900 TestAcc 0.7467 0.7800
epoch 600 LossPred 0.4918 LossAtt 0.3143 TrainAcc 0.8500 TestAcc 0.7815 0.8200
epoch 700 LossPred 0.4678 LossAtt 0.3144 TrainAcc 0.8700 TestAcc 0.7883 0.8250
epoch 800 LossPred 0.4629 LossAtt 0.3123 TrainAcc 0.8500 TestAcc 0.7888 0.8250
epoch 900 LossPred 0.3703 LossAtt 0.3133 TrainAcc 0.9100 TestAcc 0.8021 0.8500
epoch 1000 LossPred 0.3704 LossAtt 0.3005 TrainAcc 0.9100 TestAcc 0.7953 0.8500
epoch 1100 LossPred 0.3728 LossAtt 0.3181 TrainAcc 0.9100 TestAcc 0.7983 0.8550
epoch 1200 LossPred 0.3895 LossAtt 0.3033 TrainAcc 0.8800 TestAcc 0.8011 0.8700
epoch 1300 LossPred 0.3736 LossAtt 0.3068 TrainAcc 0.8700 TestAcc 0.8056 0.8600
epoch 1400 LossPred 0.4123 LossAtt 0.3004 TrainAcc 0.8900 TestAcc 0.7933 0.8300
epoch 1500 LossPred 0.4187 LossAtt 0.3044 TrainAcc 0.8900 TestAcc 0.7853 0.8550
epoch 1600 LossPred 0.4391 LossAtt 0.3032 TrainAcc 0.8800 TestAcc 0.7835 0.8400
epoch 1700 LossPred 0.4016 LossAtt 0.2959 TrainAcc 0.8800 TestAcc 0.7903 0.8300
epoch 1800 LossPred 0.8144 LossAtt 0.3039 TrainAcc 0.7400 TestAcc 0.6787 0.7000
epoch 1900 LossPred 0.6045 LossAtt 0.2863 TrainAcc 0.8000 TestAcc 0.7658 0.8000
epoch 2000 LossPred 0.4494 LossAtt 0.2829 TrainAcc 0.8700 TestAcc 0.8093 0.8450
epoch 2100 LossPred 0.4231 LossAtt 0.2795 TrainAcc 0.8800 TestAcc 0.8123 0.8500
epoch 2200 LossPred 0.3761 LossAtt 0.2709 TrainAcc 0.8800 TestAcc 0.8123 0.8600
epoch 2300 LossPred 0.3724 LossAtt 0.2716 TrainAcc 0.8800 TestAcc 0.8151 0.8800
epoch 2400 LossPred 0.3428 LossAtt 0.2675 TrainAcc 0.8900 TestAcc 0.8103 0.8700
epoch 2500 LossPred 0.3305 LossAtt 0.2609 TrainAcc 0.9000 TestAcc 0.8121 0.8950
Optimization Finished!
********** replication  40  **********
epoch   0 LossPred 1.1589 LossAtt 0.9872 TrainAcc 0.5200 TestAcc 0.4970 0.4950
epoch 100 LossPred 0.9014 LossAtt 0.3003 TrainAcc 0.6500 TestAcc 0.5618 0.6450
epoch 200 LossPred 0.8385 LossAtt 0.2749 TrainAcc 0.6500 TestAcc 0.5588 0.6300
epoch 300 LossPred 0.7360 LossAtt 0.3518 TrainAcc 0.7500 TestAcc 0.6106 0.7350
epoch 400 LossPred 0.4376 LossAtt 0.3396 TrainAcc 0.8700 TestAcc 0.7825 0.8350
epoch 500 LossPred 0.5015 LossAtt 0.3618 TrainAcc 0.8100 TestAcc 0.7605 0.7900
epoch 600 LossPred 0.4944 LossAtt 0.3474 TrainAcc 0.8300 TestAcc 0.7688 0.8000
epoch 700 LossPred 0.5223 LossAtt 0.3400 TrainAcc 0.8200 TestAcc 0.7630 0.8200
epoch 800 LossPred 0.4685 LossAtt 0.3434 TrainAcc 0.8400 TestAcc 0.7903 0.8250
epoch 900 LossPred 0.4350 LossAtt 0.3326 TrainAcc 0.8500 TestAcc 0.8043 0.8200
epoch 1000 LossPred 0.4459 LossAtt 0.3243 TrainAcc 0.8400 TestAcc 0.7948 0.8350
epoch 1100 LossPred 0.4077 LossAtt 0.3164 TrainAcc 0.8600 TestAcc 0.8043 0.8500
epoch 1200 LossPred 0.3843 LossAtt 0.3038 TrainAcc 0.8700 TestAcc 0.8181 0.8350
epoch 1300 LossPred 0.3720 LossAtt 0.3072 TrainAcc 0.8700 TestAcc 0.8238 0.8500
epoch 1400 LossPred 0.3844 LossAtt 0.3108 TrainAcc 0.8600 TestAcc 0.8313 0.8650
epoch 1500 LossPred 0.3844 LossAtt 0.3066 TrainAcc 0.9000 TestAcc 0.8196 0.8550
epoch 1600 LossPred 0.4113 LossAtt 0.3007 TrainAcc 0.8200 TestAcc 0.8116 0.8400
epoch 1700 LossPred 0.4468 LossAtt 0.2946 TrainAcc 0.8500 TestAcc 0.8071 0.8250
epoch 1800 LossPred 0.3923 LossAtt 0.2832 TrainAcc 0.8600 TestAcc 0.7968 0.8450
epoch 1900 LossPred 0.2953 LossAtt 0.2900 TrainAcc 0.9200 TestAcc 0.8026 0.8950
epoch 2000 LossPred 0.2817 LossAtt 0.2855 TrainAcc 0.9200 TestAcc 0.7925 0.8950
epoch 2100 LossPred 0.3497 LossAtt 0.2875 TrainAcc 0.8700 TestAcc 0.7870 0.8750
epoch 2200 LossPred 0.2479 LossAtt 0.2901 TrainAcc 0.9200 TestAcc 0.7940 0.8800
epoch 2300 LossPred 0.2394 LossAtt 0.2809 TrainAcc 0.9300 TestAcc 0.8033 0.8950
epoch 2400 LossPred 0.2656 LossAtt 0.2850 TrainAcc 0.9300 TestAcc 0.7963 0.9000
epoch 2500 LossPred 0.2632 LossAtt 0.3012 TrainAcc 0.9100 TestAcc 0.7998 0.9000
Optimization Finished!
********** replication  41  **********
epoch   0 LossPred 1.0210 LossAtt 1.0014 TrainAcc 0.4700 TestAcc 0.4747 0.4650
epoch 100 LossPred 0.9507 LossAtt 0.2637 TrainAcc 0.6000 TestAcc 0.5701 0.6050
epoch 200 LossPred 0.8861 LossAtt 0.2788 TrainAcc 0.6500 TestAcc 0.5643 0.6550
epoch 300 LossPred 0.7885 LossAtt 0.2975 TrainAcc 0.6900 TestAcc 0.5593 0.6400
epoch 400 LossPred 0.7459 LossAtt 0.2845 TrainAcc 0.6900 TestAcc 0.5651 0.6750
epoch 500 LossPred 0.7446 LossAtt 0.2786 TrainAcc 0.7200 TestAcc 0.5763 0.6850
epoch 600 LossPred 0.7144 LossAtt 0.3007 TrainAcc 0.7600 TestAcc 0.6046 0.7300
epoch 700 LossPred 0.7350 LossAtt 0.2887 TrainAcc 0.7200 TestAcc 0.6271 0.7250
epoch 800 LossPred 0.7102 LossAtt 0.2894 TrainAcc 0.7300 TestAcc 0.6301 0.7350
epoch 900 LossPred 0.6669 LossAtt 0.3028 TrainAcc 0.7500 TestAcc 0.6527 0.7500
epoch 1000 LossPred 0.6983 LossAtt 0.2976 TrainAcc 0.7500 TestAcc 0.6547 0.7550
epoch 1100 LossPred 0.8133 LossAtt 0.3067 TrainAcc 0.7200 TestAcc 0.6884 0.7250
epoch 1200 LossPred 0.6754 LossAtt 0.2726 TrainAcc 0.7500 TestAcc 0.6684 0.7650
epoch 1300 LossPred 0.6446 LossAtt 0.2553 TrainAcc 0.7600 TestAcc 0.6599 0.7650
epoch 1400 LossPred 0.6327 LossAtt 0.2382 TrainAcc 0.7600 TestAcc 0.6509 0.7600
epoch 1500 LossPred 0.6126 LossAtt 0.2645 TrainAcc 0.7800 TestAcc 0.6672 0.7850
epoch 1600 LossPred 0.6551 LossAtt 0.2655 TrainAcc 0.7600 TestAcc 0.6729 0.7700
epoch 1700 LossPred 0.6245 LossAtt 0.2558 TrainAcc 0.7600 TestAcc 0.6699 0.7800
epoch 1800 LossPred 0.6140 LossAtt 0.2538 TrainAcc 0.7900 TestAcc 0.6687 0.8100
epoch 1900 LossPred 0.6537 LossAtt 0.2293 TrainAcc 0.7600 TestAcc 0.6494 0.7800
epoch 2000 LossPred 0.7853 LossAtt 0.2203 TrainAcc 0.6700 TestAcc 0.6119 0.6800
epoch 2100 LossPred 0.7184 LossAtt 0.2239 TrainAcc 0.7200 TestAcc 0.6204 0.7200
epoch 2200 LossPred 0.6258 LossAtt 0.2427 TrainAcc 0.7700 TestAcc 0.6784 0.7750
epoch 2300 LossPred 0.6218 LossAtt 0.2350 TrainAcc 0.7700 TestAcc 0.6649 0.7550
epoch 2400 LossPred 0.6341 LossAtt 0.2258 TrainAcc 0.7600 TestAcc 0.6614 0.7300
epoch 2500 LossPred 0.6479 LossAtt 0.2307 TrainAcc 0.7600 TestAcc 0.6577 0.7850
Optimization Finished!
********** replication  42  **********
epoch   0 LossPred 1.0523 LossAtt 1.0102 TrainAcc 0.4000 TestAcc 0.4502 0.4400
epoch 100 LossPred 0.9243 LossAtt 0.2570 TrainAcc 0.6300 TestAcc 0.5501 0.6400
epoch 200 LossPred 0.8768 LossAtt 0.2330 TrainAcc 0.6700 TestAcc 0.5903 0.6350
epoch 300 LossPred 0.4502 LossAtt 0.2181 TrainAcc 0.8500 TestAcc 0.8031 0.8550
epoch 400 LossPred 0.2887 LossAtt 0.2192 TrainAcc 0.9100 TestAcc 0.8418 0.8750
epoch 500 LossPred 0.2758 LossAtt 0.2239 TrainAcc 0.9100 TestAcc 0.8431 0.8700
epoch 600 LossPred 0.3863 LossAtt 0.2116 TrainAcc 0.8700 TestAcc 0.8426 0.8650
epoch 700 LossPred 0.3231 LossAtt 0.1993 TrainAcc 0.8900 TestAcc 0.8473 0.8200
epoch 800 LossPred 0.2969 LossAtt 0.2087 TrainAcc 0.9200 TestAcc 0.8516 0.8800
epoch 900 LossPred 0.4872 LossAtt 0.1937 TrainAcc 0.8300 TestAcc 0.8183 0.8100
epoch 1000 LossPred 0.5410 LossAtt 0.2092 TrainAcc 0.8000 TestAcc 0.7933 0.8000
epoch 1100 LossPred 0.3566 LossAtt 0.1970 TrainAcc 0.8800 TestAcc 0.8476 0.8650
epoch 1200 LossPred 0.5073 LossAtt 0.1990 TrainAcc 0.8100 TestAcc 0.8011 0.8000
epoch 1300 LossPred 0.3828 LossAtt 0.1997 TrainAcc 0.8500 TestAcc 0.8376 0.8550
epoch 1400 LossPred 0.3475 LossAtt 0.1982 TrainAcc 0.8800 TestAcc 0.8453 0.8500
epoch 1500 LossPred 0.3369 LossAtt 0.1963 TrainAcc 0.8800 TestAcc 0.8488 0.8900
epoch 1600 LossPred 0.2536 LossAtt 0.2123 TrainAcc 0.9200 TestAcc 0.8639 0.9150
epoch 1700 LossPred 0.3292 LossAtt 0.2313 TrainAcc 0.8700 TestAcc 0.8473 0.8900
epoch 1800 LossPred 0.4241 LossAtt 0.2291 TrainAcc 0.8300 TestAcc 0.7918 0.8250
epoch 1900 LossPred 0.4892 LossAtt 0.2370 TrainAcc 0.8500 TestAcc 0.8183 0.8200
epoch 2000 LossPred 0.2503 LossAtt 0.2319 TrainAcc 0.9000 TestAcc 0.8446 0.9200
epoch 2100 LossPred 0.2340 LossAtt 0.2375 TrainAcc 0.9100 TestAcc 0.8651 0.9200
epoch 2200 LossPred 0.2257 LossAtt 0.2315 TrainAcc 0.9300 TestAcc 0.8771 0.9300
epoch 2300 LossPred 0.2817 LossAtt 0.2485 TrainAcc 0.9000 TestAcc 0.8093 0.8900
epoch 2400 LossPred 0.2199 LossAtt 0.2448 TrainAcc 0.9200 TestAcc 0.8651 0.9300
epoch 2500 LossPred 0.1747 LossAtt 0.2349 TrainAcc 0.9300 TestAcc 0.8734 0.9350
Optimization Finished!
********** replication  43  **********
epoch   0 LossPred 1.0427 LossAtt 1.0369 TrainAcc 0.5300 TestAcc 0.4187 0.5350
epoch 100 LossPred 0.7515 LossAtt 0.2982 TrainAcc 0.7600 TestAcc 0.5868 0.7250
epoch 200 LossPred 0.6861 LossAtt 0.2848 TrainAcc 0.7700 TestAcc 0.5848 0.7350
epoch 300 LossPred 0.6651 LossAtt 0.2994 TrainAcc 0.7500 TestAcc 0.5661 0.7350
epoch 400 LossPred 0.6010 LossAtt 0.3095 TrainAcc 0.8000 TestAcc 0.5513 0.7550
epoch 500 LossPred 0.5810 LossAtt 0.2577 TrainAcc 0.8200 TestAcc 0.5518 0.7550
epoch 600 LossPred 0.5572 LossAtt 0.2447 TrainAcc 0.8200 TestAcc 0.5561 0.7600
epoch 700 LossPred 0.5441 LossAtt 0.2396 TrainAcc 0.8200 TestAcc 0.5558 0.7550
epoch 800 LossPred 0.5355 LossAtt 0.2227 TrainAcc 0.8300 TestAcc 0.5541 0.7650
epoch 900 LossPred 0.5350 LossAtt 0.2238 TrainAcc 0.8200 TestAcc 0.5506 0.7800
epoch 1000 LossPred 0.5148 LossAtt 0.2209 TrainAcc 0.8200 TestAcc 0.5526 0.7750
epoch 1100 LossPred 0.4923 LossAtt 0.2121 TrainAcc 0.8500 TestAcc 0.5393 0.7900
epoch 1200 LossPred 0.4797 LossAtt 0.2171 TrainAcc 0.8500 TestAcc 0.5393 0.7950
epoch 1300 LossPred 0.4750 LossAtt 0.2197 TrainAcc 0.8500 TestAcc 0.5403 0.7950
epoch 1400 LossPred 0.4726 LossAtt 0.2181 TrainAcc 0.8500 TestAcc 0.5463 0.7900
epoch 1500 LossPred 0.4732 LossAtt 0.2077 TrainAcc 0.8500 TestAcc 0.5400 0.7900
epoch 1600 LossPred 0.4700 LossAtt 0.2031 TrainAcc 0.8500 TestAcc 0.5415 0.7900
epoch 1700 LossPred 0.4661 LossAtt 0.2036 TrainAcc 0.8500 TestAcc 0.5440 0.7900
epoch 1800 LossPred 0.4608 LossAtt 0.2190 TrainAcc 0.8600 TestAcc 0.5393 0.7850
epoch 1900 LossPred 0.4668 LossAtt 0.2228 TrainAcc 0.8600 TestAcc 0.5453 0.7850
epoch 2000 LossPred 0.4589 LossAtt 0.2224 TrainAcc 0.8600 TestAcc 0.5395 0.7800
epoch 2100 LossPred 0.4654 LossAtt 0.2273 TrainAcc 0.8500 TestAcc 0.5360 0.8050
epoch 2200 LossPred 0.4629 LossAtt 0.2125 TrainAcc 0.8400 TestAcc 0.5380 0.7950
epoch 2300 LossPred 0.4651 LossAtt 0.2296 TrainAcc 0.8500 TestAcc 0.5428 0.7900
epoch 2400 LossPred 0.4795 LossAtt 0.2072 TrainAcc 0.8300 TestAcc 0.5390 0.7900
epoch 2500 LossPred 0.4832 LossAtt 0.2016 TrainAcc 0.8400 TestAcc 0.5363 0.7850
Optimization Finished!
********** replication  44  **********
epoch   0 LossPred 1.1719 LossAtt 0.9880 TrainAcc 0.4300 TestAcc 0.4142 0.4500
epoch 100 LossPred 0.9212 LossAtt 0.2523 TrainAcc 0.5800 TestAcc 0.5766 0.5900
epoch 200 LossPred 0.9031 LossAtt 0.1654 TrainAcc 0.6300 TestAcc 0.5936 0.6350
epoch 300 LossPred 0.5089 LossAtt 0.2583 TrainAcc 0.8700 TestAcc 0.8038 0.8750
epoch 400 LossPred 0.5774 LossAtt 0.2321 TrainAcc 0.8200 TestAcc 0.7695 0.8450
epoch 500 LossPred 0.4166 LossAtt 0.2258 TrainAcc 0.8800 TestAcc 0.8278 0.8700
epoch 600 LossPred 0.3615 LossAtt 0.2040 TrainAcc 0.8900 TestAcc 0.8236 0.8750
epoch 700 LossPred 0.7506 LossAtt 0.2111 TrainAcc 0.7500 TestAcc 0.7227 0.7500
epoch 800 LossPred 0.4166 LossAtt 0.1923 TrainAcc 0.8800 TestAcc 0.8116 0.8450
epoch 900 LossPred 0.3239 LossAtt 0.1802 TrainAcc 0.9100 TestAcc 0.8316 0.8850
epoch 1000 LossPred 0.6132 LossAtt 0.1942 TrainAcc 0.8000 TestAcc 0.7700 0.8100
epoch 1100 LossPred 0.3806 LossAtt 0.1897 TrainAcc 0.8900 TestAcc 0.8251 0.8800
epoch 1200 LossPred 0.4332 LossAtt 0.1774 TrainAcc 0.8600 TestAcc 0.8091 0.8400
epoch 1300 LossPred 0.6451 LossAtt 0.1796 TrainAcc 0.7900 TestAcc 0.7610 0.7700
epoch 1400 LossPred 0.3688 LossAtt 0.1771 TrainAcc 0.8800 TestAcc 0.8203 0.8850
epoch 1500 LossPred 0.5933 LossAtt 0.1906 TrainAcc 0.8200 TestAcc 0.7685 0.7750
epoch 1600 LossPred 1.1179 LossAtt 0.1864 TrainAcc 0.5800 TestAcc 0.6119 0.5850
epoch 1700 LossPred 0.7002 LossAtt 0.1871 TrainAcc 0.7300 TestAcc 0.7492 0.7400
epoch 1800 LossPred 0.4640 LossAtt 0.1742 TrainAcc 0.8500 TestAcc 0.7983 0.8500
epoch 1900 LossPred 0.3381 LossAtt 0.1772 TrainAcc 0.9000 TestAcc 0.8213 0.8850
epoch 2000 LossPred 0.3469 LossAtt 0.1754 TrainAcc 0.8900 TestAcc 0.8211 0.8800
epoch 2100 LossPred 0.3422 LossAtt 0.1705 TrainAcc 0.9000 TestAcc 0.8211 0.8900
epoch 2200 LossPred 0.3910 LossAtt 0.1723 TrainAcc 0.8600 TestAcc 0.8126 0.8650
epoch 2300 LossPred 0.3637 LossAtt 0.1675 TrainAcc 0.8800 TestAcc 0.8158 0.8700
epoch 2400 LossPred 0.4416 LossAtt 0.1663 TrainAcc 0.8400 TestAcc 0.8186 0.8500
epoch 2500 LossPred 0.3384 LossAtt 0.1635 TrainAcc 0.9100 TestAcc 0.8218 0.8900
Optimization Finished!
********** replication  45  **********
epoch   0 LossPred 1.0683 LossAtt 1.0178 TrainAcc 0.4900 TestAcc 0.4484 0.4650
epoch 100 LossPred 0.8886 LossAtt 0.2595 TrainAcc 0.6400 TestAcc 0.6276 0.6450
epoch 200 LossPred 0.7049 LossAtt 0.2451 TrainAcc 0.7400 TestAcc 0.7675 0.7500
epoch 300 LossPred 0.4910 LossAtt 0.1926 TrainAcc 0.8400 TestAcc 0.7925 0.7950
epoch 400 LossPred 0.5044 LossAtt 0.1774 TrainAcc 0.8500 TestAcc 0.7860 0.8200
epoch 500 LossPred 0.6996 LossAtt 0.1747 TrainAcc 0.7500 TestAcc 0.6944 0.7350
epoch 600 LossPred 0.5823 LossAtt 0.1758 TrainAcc 0.8100 TestAcc 0.7775 0.8150
epoch 700 LossPred 0.5091 LossAtt 0.1869 TrainAcc 0.8500 TestAcc 0.7915 0.8150
epoch 800 LossPred 0.4806 LossAtt 0.1915 TrainAcc 0.8500 TestAcc 0.8043 0.8200
epoch 900 LossPred 0.5408 LossAtt 0.1960 TrainAcc 0.8000 TestAcc 0.7643 0.7950
epoch 1000 LossPred 0.4677 LossAtt 0.1994 TrainAcc 0.8400 TestAcc 0.8208 0.8200
epoch 1100 LossPred 0.4766 LossAtt 0.1914 TrainAcc 0.8300 TestAcc 0.8156 0.8250
epoch 1200 LossPred 0.3770 LossAtt 0.1958 TrainAcc 0.8900 TestAcc 0.8426 0.8600
epoch 1300 LossPred 0.5774 LossAtt 0.1784 TrainAcc 0.7900 TestAcc 0.7462 0.8000
epoch 1400 LossPred 0.5018 LossAtt 0.1797 TrainAcc 0.8300 TestAcc 0.7855 0.8300
epoch 1500 LossPred 0.3970 LossAtt 0.1687 TrainAcc 0.8500 TestAcc 0.8233 0.8400
epoch 1600 LossPred 0.3482 LossAtt 0.1831 TrainAcc 0.9000 TestAcc 0.8466 0.8650
epoch 1700 LossPred 0.3870 LossAtt 0.1785 TrainAcc 0.8600 TestAcc 0.8493 0.8700
epoch 1800 LossPred 0.3165 LossAtt 0.1675 TrainAcc 0.9100 TestAcc 0.8549 0.8950
epoch 1900 LossPred 0.5401 LossAtt 0.1815 TrainAcc 0.7800 TestAcc 0.8233 0.8200
epoch 2000 LossPred 0.3713 LossAtt 0.1730 TrainAcc 0.8800 TestAcc 0.8506 0.8600
epoch 2100 LossPred 0.3654 LossAtt 0.1746 TrainAcc 0.8700 TestAcc 0.8561 0.8600
epoch 2200 LossPred 0.3595 LossAtt 0.1714 TrainAcc 0.8800 TestAcc 0.8619 0.8600
epoch 2300 LossPred 0.3375 LossAtt 0.1705 TrainAcc 0.8900 TestAcc 0.8519 0.8850
epoch 2400 LossPred 0.5019 LossAtt 0.1577 TrainAcc 0.8300 TestAcc 0.7733 0.8550
epoch 2500 LossPred 0.3202 LossAtt 0.1718 TrainAcc 0.9000 TestAcc 0.8591 0.8650
Optimization Finished!
********** replication  46  **********
epoch   0 LossPred 1.4069 LossAtt 1.0068 TrainAcc 0.3600 TestAcc 0.4565 0.3500
epoch 100 LossPred 0.8930 LossAtt 0.2221 TrainAcc 0.6800 TestAcc 0.5791 0.6850
epoch 200 LossPred 0.8437 LossAtt 0.1562 TrainAcc 0.6800 TestAcc 0.5791 0.6800
epoch 300 LossPred 0.4849 LossAtt 0.2223 TrainAcc 0.8800 TestAcc 0.7327 0.8300
epoch 400 LossPred 0.4038 LossAtt 0.2111 TrainAcc 0.8800 TestAcc 0.7835 0.8550
epoch 500 LossPred 0.4373 LossAtt 0.1916 TrainAcc 0.8300 TestAcc 0.7800 0.8550
epoch 600 LossPred 0.3786 LossAtt 0.1879 TrainAcc 0.8700 TestAcc 0.7815 0.8700
epoch 700 LossPred 0.3863 LossAtt 0.1860 TrainAcc 0.8900 TestAcc 0.7690 0.8350
epoch 800 LossPred 0.3710 LossAtt 0.1864 TrainAcc 0.8700 TestAcc 0.7850 0.8650
epoch 900 LossPred 0.3635 LossAtt 0.1701 TrainAcc 0.8900 TestAcc 0.7835 0.8700
epoch 1000 LossPred 0.4575 LossAtt 0.1726 TrainAcc 0.8300 TestAcc 0.7578 0.8200
epoch 1100 LossPred 0.3596 LossAtt 0.1618 TrainAcc 0.8800 TestAcc 0.7780 0.8500
epoch 1200 LossPred 0.3541 LossAtt 0.1664 TrainAcc 0.8800 TestAcc 0.7910 0.8700
epoch 1300 LossPred 0.7009 LossAtt 0.1622 TrainAcc 0.7600 TestAcc 0.7105 0.7950
epoch 1400 LossPred 0.3685 LossAtt 0.1571 TrainAcc 0.8700 TestAcc 0.7955 0.8600
epoch 1500 LossPred 0.3568 LossAtt 0.1576 TrainAcc 0.8900 TestAcc 0.7793 0.8700
epoch 1600 LossPred 0.3701 LossAtt 0.1698 TrainAcc 0.8800 TestAcc 0.7585 0.8400
epoch 1700 LossPred 0.3508 LossAtt 0.1708 TrainAcc 0.8900 TestAcc 0.7923 0.8650
epoch 1800 LossPred 0.3710 LossAtt 0.1771 TrainAcc 0.8900 TestAcc 0.7910 0.8600
epoch 1900 LossPred 0.3673 LossAtt 0.1849 TrainAcc 0.8700 TestAcc 0.7690 0.8700
epoch 2000 LossPred 0.3223 LossAtt 0.1788 TrainAcc 0.9000 TestAcc 0.7790 0.8750
epoch 2100 LossPred 0.3506 LossAtt 0.1707 TrainAcc 0.8700 TestAcc 0.7745 0.8600
epoch 2200 LossPred 0.3457 LossAtt 0.1754 TrainAcc 0.8700 TestAcc 0.7805 0.8750
epoch 2300 LossPred 0.3597 LossAtt 0.1808 TrainAcc 0.8800 TestAcc 0.7840 0.8600
epoch 2400 LossPred 0.3713 LossAtt 0.1867 TrainAcc 0.8800 TestAcc 0.7830 0.8550
epoch 2500 LossPred 0.3223 LossAtt 0.1916 TrainAcc 0.8800 TestAcc 0.7803 0.8600
Optimization Finished!
********** replication  47  **********
epoch   0 LossPred 1.2853 LossAtt 1.0130 TrainAcc 0.4000 TestAcc 0.4700 0.4050
epoch 100 LossPred 0.9074 LossAtt 0.2863 TrainAcc 0.6500 TestAcc 0.5365 0.6500
epoch 200 LossPred 0.8641 LossAtt 0.2699 TrainAcc 0.6800 TestAcc 0.5323 0.6800
epoch 300 LossPred 0.8468 LossAtt 0.2838 TrainAcc 0.6800 TestAcc 0.5280 0.6950
epoch 400 LossPred 0.8313 LossAtt 0.2895 TrainAcc 0.6900 TestAcc 0.5235 0.6850
epoch 500 LossPred 0.7922 LossAtt 0.3225 TrainAcc 0.7000 TestAcc 0.5300 0.6950
epoch 600 LossPred 0.7578 LossAtt 0.3381 TrainAcc 0.7200 TestAcc 0.5195 0.6850
epoch 700 LossPred 0.7417 LossAtt 0.3296 TrainAcc 0.7400 TestAcc 0.5115 0.6800
epoch 800 LossPred 0.7067 LossAtt 0.3362 TrainAcc 0.7500 TestAcc 0.5090 0.6750
epoch 900 LossPred 0.6615 LossAtt 0.3367 TrainAcc 0.7900 TestAcc 0.5085 0.6900
epoch 1000 LossPred 0.7025 LossAtt 0.3264 TrainAcc 0.7600 TestAcc 0.5078 0.6700
epoch 1100 LossPred 0.6453 LossAtt 0.3235 TrainAcc 0.7700 TestAcc 0.5048 0.6800
epoch 1200 LossPred 0.6563 LossAtt 0.3244 TrainAcc 0.7800 TestAcc 0.5073 0.6600
epoch 1300 LossPred 0.6434 LossAtt 0.3257 TrainAcc 0.7700 TestAcc 0.5095 0.6900
epoch 1400 LossPred 0.6424 LossAtt 0.3278 TrainAcc 0.7800 TestAcc 0.5088 0.6800
epoch 1500 LossPred 0.6367 LossAtt 0.3200 TrainAcc 0.7900 TestAcc 0.5070 0.6800
epoch 1600 LossPred 0.6207 LossAtt 0.3078 TrainAcc 0.8000 TestAcc 0.5033 0.6800
epoch 1700 LossPred 0.6238 LossAtt 0.3079 TrainAcc 0.8100 TestAcc 0.5023 0.6800
epoch 1800 LossPred 0.6464 LossAtt 0.3242 TrainAcc 0.7700 TestAcc 0.5033 0.6900
epoch 1900 LossPred 0.6211 LossAtt 0.3077 TrainAcc 0.7800 TestAcc 0.4997 0.6800
epoch 2000 LossPred 0.6699 LossAtt 0.3001 TrainAcc 0.7900 TestAcc 0.5050 0.7000
epoch 2100 LossPred 0.6288 LossAtt 0.2929 TrainAcc 0.7800 TestAcc 0.5058 0.6950
epoch 2200 LossPred 0.6640 LossAtt 0.2874 TrainAcc 0.7500 TestAcc 0.5053 0.6950
epoch 2300 LossPred 0.6223 LossAtt 0.2900 TrainAcc 0.7800 TestAcc 0.5045 0.7100
epoch 2400 LossPred 0.6387 LossAtt 0.2712 TrainAcc 0.7800 TestAcc 0.5033 0.7000
epoch 2500 LossPred 0.6468 LossAtt 0.2860 TrainAcc 0.7900 TestAcc 0.5053 0.7350
Optimization Finished!
********** replication  48  **********
epoch   0 LossPred 1.0977 LossAtt 1.0145 TrainAcc 0.4700 TestAcc 0.5518 0.4750
epoch 100 LossPred 0.9288 LossAtt 0.2441 TrainAcc 0.6000 TestAcc 0.6119 0.6100
epoch 200 LossPred 0.7656 LossAtt 0.2728 TrainAcc 0.7200 TestAcc 0.7342 0.7450
epoch 300 LossPred 0.7845 LossAtt 0.2426 TrainAcc 0.7500 TestAcc 0.7380 0.7450
epoch 400 LossPred 0.6523 LossAtt 0.2377 TrainAcc 0.7500 TestAcc 0.7938 0.7450
epoch 500 LossPred 0.6376 LossAtt 0.2267 TrainAcc 0.7600 TestAcc 0.7893 0.7350
epoch 600 LossPred 0.5630 LossAtt 0.2505 TrainAcc 0.8100 TestAcc 0.8178 0.7650
epoch 700 LossPred 0.4959 LossAtt 0.2302 TrainAcc 0.8500 TestAcc 0.8318 0.7950
epoch 800 LossPred 0.4806 LossAtt 0.2454 TrainAcc 0.8200 TestAcc 0.8183 0.7700
epoch 900 LossPred 0.4613 LossAtt 0.2337 TrainAcc 0.8300 TestAcc 0.8301 0.7900
epoch 1000 LossPred 0.6409 LossAtt 0.2365 TrainAcc 0.7900 TestAcc 0.7783 0.7350
epoch 1100 LossPred 0.4469 LossAtt 0.2406 TrainAcc 0.8600 TestAcc 0.8198 0.8150
epoch 1200 LossPred 0.5246 LossAtt 0.2323 TrainAcc 0.8200 TestAcc 0.8103 0.8050
epoch 1300 LossPred 0.4851 LossAtt 0.2185 TrainAcc 0.8500 TestAcc 0.8093 0.8000
epoch 1400 LossPred 0.3952 LossAtt 0.2093 TrainAcc 0.8900 TestAcc 0.8168 0.8500
epoch 1500 LossPred 0.8014 LossAtt 0.2068 TrainAcc 0.7400 TestAcc 0.7490 0.7200
epoch 1600 LossPred 0.4093 LossAtt 0.1965 TrainAcc 0.8900 TestAcc 0.8121 0.8500
epoch 1700 LossPred 0.5446 LossAtt 0.1963 TrainAcc 0.8100 TestAcc 0.7918 0.7800
epoch 1800 LossPred 0.3399 LossAtt 0.1956 TrainAcc 0.8900 TestAcc 0.8293 0.8250
epoch 1900 LossPred 0.7762 LossAtt 0.2090 TrainAcc 0.7400 TestAcc 0.7455 0.7600
epoch 2000 LossPred 0.3287 LossAtt 0.1858 TrainAcc 0.9100 TestAcc 0.8333 0.8450
epoch 2100 LossPred 0.3517 LossAtt 0.1836 TrainAcc 0.8900 TestAcc 0.8181 0.8400
epoch 2200 LossPred 0.7214 LossAtt 0.2128 TrainAcc 0.7700 TestAcc 0.7482 0.7600
epoch 2300 LossPred 0.5229 LossAtt 0.1965 TrainAcc 0.8400 TestAcc 0.7775 0.8200
epoch 2400 LossPred 0.4911 LossAtt 0.1788 TrainAcc 0.8500 TestAcc 0.7803 0.8300
epoch 2500 LossPred 0.4589 LossAtt 0.1798 TrainAcc 0.8600 TestAcc 0.8158 0.8000
Optimization Finished!
********** replication  49  **********
epoch   0 LossPred 0.9690 LossAtt 1.0009 TrainAcc 0.5700 TestAcc 0.5455 0.5750
epoch 100 LossPred 0.8308 LossAtt 0.2547 TrainAcc 0.6900 TestAcc 0.5868 0.6900
epoch 200 LossPred 0.6103 LossAtt 0.2146 TrainAcc 0.7800 TestAcc 0.7873 0.7850
epoch 300 LossPred 0.6641 LossAtt 0.2014 TrainAcc 0.7300 TestAcc 0.7060 0.7300
epoch 400 LossPred 0.5860 LossAtt 0.2003 TrainAcc 0.7900 TestAcc 0.7432 0.7600
epoch 500 LossPred 0.4592 LossAtt 0.1928 TrainAcc 0.8600 TestAcc 0.8206 0.8150
epoch 600 LossPred 0.7090 LossAtt 0.1725 TrainAcc 0.7100 TestAcc 0.7260 0.7250
epoch 700 LossPred 0.5440 LossAtt 0.1872 TrainAcc 0.8000 TestAcc 0.7693 0.8000
epoch 800 LossPred 0.7981 LossAtt 0.1741 TrainAcc 0.7100 TestAcc 0.6444 0.6950
epoch 900 LossPred 0.5137 LossAtt 0.1696 TrainAcc 0.8300 TestAcc 0.7628 0.8100
epoch 1000 LossPred 0.8134 LossAtt 0.1768 TrainAcc 0.6600 TestAcc 0.6236 0.6700
epoch 1100 LossPred 0.6852 LossAtt 0.1733 TrainAcc 0.7100 TestAcc 0.6947 0.7000
epoch 1200 LossPred 0.6580 LossAtt 0.1534 TrainAcc 0.7500 TestAcc 0.7708 0.7500
epoch 1300 LossPred 0.5398 LossAtt 0.1671 TrainAcc 0.8000 TestAcc 0.7568 0.7250
epoch 1400 LossPred 0.7250 LossAtt 0.1443 TrainAcc 0.7100 TestAcc 0.6974 0.6950
epoch 1500 LossPred 0.5303 LossAtt 0.1651 TrainAcc 0.8200 TestAcc 0.7835 0.7800
epoch 1600 LossPred 0.5992 LossAtt 0.1530 TrainAcc 0.7800 TestAcc 0.8001 0.7700
epoch 1700 LossPred 0.7050 LossAtt 0.1523 TrainAcc 0.7200 TestAcc 0.7603 0.7500
epoch 1800 LossPred 0.6629 LossAtt 0.1621 TrainAcc 0.7500 TestAcc 0.7395 0.7100
epoch 1900 LossPred 0.5023 LossAtt 0.1631 TrainAcc 0.8200 TestAcc 0.7910 0.8200
epoch 2000 LossPred 0.7524 LossAtt 0.1661 TrainAcc 0.7000 TestAcc 0.6934 0.6950
epoch 2100 LossPred 0.5776 LossAtt 0.1507 TrainAcc 0.7900 TestAcc 0.7890 0.7950
epoch 2200 LossPred 0.5421 LossAtt 0.1438 TrainAcc 0.8100 TestAcc 0.7720 0.7850
epoch 2300 LossPred 0.6097 LossAtt 0.1500 TrainAcc 0.7600 TestAcc 0.7878 0.7950
epoch 2400 LossPred 1.3965 LossAtt 0.1806 TrainAcc 0.5100 TestAcc 0.4982 0.5100
epoch 2500 LossPred 0.7350 LossAtt 0.1465 TrainAcc 0.7100 TestAcc 0.6341 0.7000
Optimization Finished!
********** replication  50  **********
epoch   0 LossPred 1.1619 LossAtt 1.0369 TrainAcc 0.5300 TestAcc 0.4710 0.5250
epoch 100 LossPred 0.8977 LossAtt 0.3254 TrainAcc 0.6100 TestAcc 0.5716 0.6400
epoch 200 LossPred 0.7176 LossAtt 0.3423 TrainAcc 0.7500 TestAcc 0.7092 0.7400
epoch 300 LossPred 0.6557 LossAtt 0.3074 TrainAcc 0.7700 TestAcc 0.6724 0.7600
epoch 400 LossPred 0.4902 LossAtt 0.3079 TrainAcc 0.8400 TestAcc 0.7533 0.8250
epoch 500 LossPred 0.6496 LossAtt 0.2908 TrainAcc 0.7700 TestAcc 0.7548 0.7300
epoch 600 LossPred 1.1511 LossAtt 0.2805 TrainAcc 0.5500 TestAcc 0.5766 0.5500
epoch 700 LossPred 0.6469 LossAtt 0.2842 TrainAcc 0.7700 TestAcc 0.7467 0.7800
epoch 800 LossPred 0.7266 LossAtt 0.2681 TrainAcc 0.7400 TestAcc 0.6539 0.7450
epoch 900 LossPred 0.9246 LossAtt 0.2501 TrainAcc 0.6200 TestAcc 0.5495 0.6100
epoch 1000 LossPred 0.9131 LossAtt 0.2411 TrainAcc 0.6100 TestAcc 0.5380 0.6050
epoch 1100 LossPred 0.9106 LossAtt 0.2315 TrainAcc 0.6100 TestAcc 0.5380 0.6050
epoch 1200 LossPred 0.9093 LossAtt 0.2419 TrainAcc 0.6100 TestAcc 0.5383 0.6050
epoch 1300 LossPred 0.9080 LossAtt 0.2289 TrainAcc 0.6100 TestAcc 0.5380 0.6100
epoch 1400 LossPred 0.9061 LossAtt 0.2254 TrainAcc 0.6100 TestAcc 0.5380 0.6050
epoch 1500 LossPred 0.9050 LossAtt 0.2188 TrainAcc 0.6100 TestAcc 0.5380 0.6050
epoch 1600 LossPred 0.8930 LossAtt 0.2257 TrainAcc 0.6200 TestAcc 0.5403 0.6200
epoch 1700 LossPred 0.8804 LossAtt 0.2248 TrainAcc 0.6400 TestAcc 0.5513 0.6250
epoch 1800 LossPred 0.8382 LossAtt 0.2323 TrainAcc 0.6600 TestAcc 0.5751 0.6900
epoch 1900 LossPred 0.6101 LossAtt 0.2327 TrainAcc 0.7700 TestAcc 0.6264 0.7350
epoch 2000 LossPred 0.5952 LossAtt 0.2144 TrainAcc 0.7700 TestAcc 0.6314 0.7400
epoch 2100 LossPred 0.5865 LossAtt 0.2085 TrainAcc 0.7700 TestAcc 0.6299 0.7500
epoch 2200 LossPred 0.5765 LossAtt 0.2085 TrainAcc 0.7800 TestAcc 0.6384 0.7550
epoch 2300 LossPred 0.6271 LossAtt 0.1942 TrainAcc 0.7700 TestAcc 0.6381 0.7600
epoch 2400 LossPred 0.5757 LossAtt 0.1846 TrainAcc 0.8000 TestAcc 0.6459 0.7600
epoch 2500 LossPred 0.6200 LossAtt 0.1897 TrainAcc 0.7800 TestAcc 0.6379 0.7600
Optimization Finished!
********** replication  51  **********
epoch   0 LossPred 1.1784 LossAtt 1.0067 TrainAcc 0.5200 TestAcc 0.4847 0.4950
epoch 100 LossPred 0.9431 LossAtt 0.2397 TrainAcc 0.5900 TestAcc 0.5616 0.5950
epoch 200 LossPred 0.9355 LossAtt 0.1887 TrainAcc 0.5900 TestAcc 0.5561 0.5900
epoch 300 LossPred 0.9280 LossAtt 0.1837 TrainAcc 0.5900 TestAcc 0.5653 0.6050
epoch 400 LossPred 0.9233 LossAtt 0.1601 TrainAcc 0.5900 TestAcc 0.5763 0.6000
epoch 500 LossPred 0.9199 LossAtt 0.1288 TrainAcc 0.5900 TestAcc 0.5796 0.6050
epoch 600 LossPred 0.9182 LossAtt 0.1208 TrainAcc 0.6000 TestAcc 0.5971 0.6050
epoch 700 LossPred 0.9160 LossAtt 0.1254 TrainAcc 0.6000 TestAcc 0.5971 0.6000
epoch 800 LossPred 0.9210 LossAtt 0.1439 TrainAcc 0.6000 TestAcc 0.5971 0.6000
epoch 900 LossPred 0.8965 LossAtt 0.2001 TrainAcc 0.6100 TestAcc 0.6196 0.6200
epoch 1000 LossPred 0.7823 LossAtt 0.2298 TrainAcc 0.7500 TestAcc 0.7247 0.7250
epoch 1100 LossPred 0.8503 LossAtt 0.2066 TrainAcc 0.6800 TestAcc 0.6664 0.6800
epoch 1200 LossPred 0.6055 LossAtt 0.2315 TrainAcc 0.7600 TestAcc 0.7593 0.7300
epoch 1300 LossPred 0.5877 LossAtt 0.2406 TrainAcc 0.7800 TestAcc 0.8141 0.7700
epoch 1400 LossPred 0.5576 LossAtt 0.2276 TrainAcc 0.7800 TestAcc 0.8078 0.7650
epoch 1500 LossPred 0.4687 LossAtt 0.2348 TrainAcc 0.8000 TestAcc 0.8278 0.8000
epoch 1600 LossPred 0.4828 LossAtt 0.2130 TrainAcc 0.8100 TestAcc 0.8338 0.8300
epoch 1700 LossPred 0.5116 LossAtt 0.2224 TrainAcc 0.8100 TestAcc 0.8131 0.7600
epoch 1800 LossPred 0.4398 LossAtt 0.2137 TrainAcc 0.8200 TestAcc 0.8403 0.8150
epoch 1900 LossPred 0.4517 LossAtt 0.1992 TrainAcc 0.8400 TestAcc 0.8386 0.8050
epoch 2000 LossPred 0.3692 LossAtt 0.1952 TrainAcc 0.8800 TestAcc 0.8376 0.8250
epoch 2100 LossPred 0.4136 LossAtt 0.1912 TrainAcc 0.8500 TestAcc 0.8418 0.8150
epoch 2200 LossPred 0.3950 LossAtt 0.1877 TrainAcc 0.8400 TestAcc 0.8426 0.8550
epoch 2300 LossPred 0.4323 LossAtt 0.1903 TrainAcc 0.8300 TestAcc 0.8461 0.8200
epoch 2400 LossPred 0.3545 LossAtt 0.1994 TrainAcc 0.8600 TestAcc 0.8343 0.8550
epoch 2500 LossPred 0.3829 LossAtt 0.1959 TrainAcc 0.8500 TestAcc 0.8451 0.8600
Optimization Finished!
********** replication  52  **********
epoch   0 LossPred 0.9927 LossAtt 1.0139 TrainAcc 0.5800 TestAcc 0.5946 0.5750
epoch 100 LossPred 0.9010 LossAtt 0.2701 TrainAcc 0.6500 TestAcc 0.5926 0.6500
epoch 200 LossPred 0.5827 LossAtt 0.2825 TrainAcc 0.8100 TestAcc 0.7603 0.7750
epoch 300 LossPred 0.4314 LossAtt 0.2390 TrainAcc 0.8600 TestAcc 0.8246 0.8550
epoch 400 LossPred 0.4839 LossAtt 0.2494 TrainAcc 0.8200 TestAcc 0.7785 0.8300
epoch 500 LossPred 0.3119 LossAtt 0.2370 TrainAcc 0.9100 TestAcc 0.8493 0.9150
epoch 600 LossPred 0.4042 LossAtt 0.2275 TrainAcc 0.8600 TestAcc 0.8421 0.8700
epoch 700 LossPred 0.4618 LossAtt 0.2383 TrainAcc 0.8500 TestAcc 0.7993 0.8500
epoch 800 LossPred 0.3653 LossAtt 0.2305 TrainAcc 0.8700 TestAcc 0.8521 0.8700
epoch 900 LossPred 0.3709 LossAtt 0.2212 TrainAcc 0.8500 TestAcc 0.8514 0.8850
epoch 1000 LossPred 0.2897 LossAtt 0.2175 TrainAcc 0.9100 TestAcc 0.8746 0.8950
epoch 1100 LossPred 0.3862 LossAtt 0.2139 TrainAcc 0.8700 TestAcc 0.8276 0.8650
epoch 1200 LossPred 0.4801 LossAtt 0.2308 TrainAcc 0.8500 TestAcc 0.7910 0.8500
epoch 1300 LossPred 0.4989 LossAtt 0.2295 TrainAcc 0.8200 TestAcc 0.8051 0.8450
epoch 1400 LossPred 0.2826 LossAtt 0.2116 TrainAcc 0.8900 TestAcc 0.8604 0.8950
epoch 1500 LossPred 0.4898 LossAtt 0.2142 TrainAcc 0.8400 TestAcc 0.7763 0.8350
epoch 1600 LossPred 0.3268 LossAtt 0.2133 TrainAcc 0.8600 TestAcc 0.8476 0.8650
epoch 1700 LossPred 0.2971 LossAtt 0.2166 TrainAcc 0.9000 TestAcc 0.8584 0.8950
epoch 1800 LossPred 0.3456 LossAtt 0.2200 TrainAcc 0.9000 TestAcc 0.8589 0.8950
epoch 1900 LossPred 0.6694 LossAtt 0.2184 TrainAcc 0.8000 TestAcc 0.7610 0.7900
epoch 2000 LossPred 0.4908 LossAtt 0.2462 TrainAcc 0.8300 TestAcc 0.7695 0.8200
epoch 2100 LossPred 0.3807 LossAtt 0.2463 TrainAcc 0.8500 TestAcc 0.7983 0.8600
epoch 2200 LossPred 0.2298 LossAtt 0.2379 TrainAcc 0.9100 TestAcc 0.8601 0.9300
epoch 2300 LossPred 0.2369 LossAtt 0.2315 TrainAcc 0.9200 TestAcc 0.8679 0.9250
epoch 2400 LossPred 0.2661 LossAtt 0.2461 TrainAcc 0.9000 TestAcc 0.8361 0.9150
epoch 2500 LossPred 0.1912 LossAtt 0.2424 TrainAcc 0.9400 TestAcc 0.8649 0.9450
Optimization Finished!
********** replication  53  **********
epoch   0 LossPred 1.2428 LossAtt 1.0169 TrainAcc 0.4500 TestAcc 0.4705 0.4450
epoch 100 LossPred 0.9320 LossAtt 0.2180 TrainAcc 0.6300 TestAcc 0.5866 0.6300
epoch 200 LossPred 0.9224 LossAtt 0.1494 TrainAcc 0.6300 TestAcc 0.5866 0.6300
epoch 300 LossPred 0.9034 LossAtt 0.1795 TrainAcc 0.6300 TestAcc 0.5866 0.6300
epoch 400 LossPred 0.7623 LossAtt 0.2209 TrainAcc 0.7000 TestAcc 0.6854 0.7000
epoch 500 LossPred 1.0129 LossAtt 0.1887 TrainAcc 0.6100 TestAcc 0.5958 0.6350
epoch 600 LossPred 0.8728 LossAtt 0.1524 TrainAcc 0.6800 TestAcc 0.6484 0.6800
epoch 700 LossPred 0.8059 LossAtt 0.1565 TrainAcc 0.6900 TestAcc 0.6354 0.7200
epoch 800 LossPred 0.8088 LossAtt 0.1523 TrainAcc 0.6800 TestAcc 0.6336 0.7050
epoch 900 LossPred 0.7227 LossAtt 0.1730 TrainAcc 0.7400 TestAcc 0.7375 0.7200
epoch 1000 LossPred 0.9051 LossAtt 0.1595 TrainAcc 0.6400 TestAcc 0.6404 0.6750
epoch 1100 LossPred 0.8110 LossAtt 0.1417 TrainAcc 0.6700 TestAcc 0.6381 0.6650
epoch 1200 LossPred 0.7919 LossAtt 0.1398 TrainAcc 0.6700 TestAcc 0.6391 0.6700
epoch 1300 LossPred 0.7822 LossAtt 0.1337 TrainAcc 0.6800 TestAcc 0.6399 0.6250
epoch 1400 LossPred 0.7742 LossAtt 0.1290 TrainAcc 0.6400 TestAcc 0.6066 0.6250
epoch 1500 LossPred 0.7704 LossAtt 0.1281 TrainAcc 0.6400 TestAcc 0.6121 0.6350
epoch 1600 LossPred 0.7663 LossAtt 0.1225 TrainAcc 0.6400 TestAcc 0.6076 0.6300
epoch 1700 LossPred 0.7635 LossAtt 0.1253 TrainAcc 0.6400 TestAcc 0.6096 0.6300
epoch 1800 LossPred 0.7665 LossAtt 0.1275 TrainAcc 0.6300 TestAcc 0.6031 0.6150
epoch 1900 LossPred 0.8319 LossAtt 0.1143 TrainAcc 0.6700 TestAcc 0.6364 0.6650
epoch 2000 LossPred 0.7568 LossAtt 0.1224 TrainAcc 0.7000 TestAcc 0.6489 0.6650
epoch 2100 LossPred 0.8041 LossAtt 0.1139 TrainAcc 0.6800 TestAcc 0.6394 0.6700
epoch 2200 LossPred 0.7539 LossAtt 0.1132 TrainAcc 0.6500 TestAcc 0.6081 0.6250
epoch 2300 LossPred 0.7958 LossAtt 0.1124 TrainAcc 0.6800 TestAcc 0.6401 0.6800
epoch 2400 LossPred 0.9194 LossAtt 0.1033 TrainAcc 0.6500 TestAcc 0.6161 0.6550
epoch 2500 LossPred 0.8876 LossAtt 0.0927 TrainAcc 0.6500 TestAcc 0.6201 0.6500
Optimization Finished!
********** replication  54  **********
epoch   0 LossPred 0.9907 LossAtt 1.0124 TrainAcc 0.6200 TestAcc 0.5821 0.6000
epoch 100 LossPred 0.8699 LossAtt 0.2963 TrainAcc 0.6500 TestAcc 0.5958 0.6500
epoch 200 LossPred 0.8391 LossAtt 0.2628 TrainAcc 0.6600 TestAcc 0.6304 0.6500
epoch 300 LossPred 0.7885 LossAtt 0.3441 TrainAcc 0.7300 TestAcc 0.6642 0.7350
epoch 400 LossPred 0.4562 LossAtt 0.3231 TrainAcc 0.8500 TestAcc 0.8463 0.8100
epoch 500 LossPred 0.4067 LossAtt 0.3132 TrainAcc 0.8600 TestAcc 0.8701 0.8150
epoch 600 LossPred 0.3506 LossAtt 0.2922 TrainAcc 0.8900 TestAcc 0.8721 0.8400
epoch 700 LossPred 0.3651 LossAtt 0.2846 TrainAcc 0.8700 TestAcc 0.8566 0.8600
epoch 800 LossPred 0.3516 LossAtt 0.2744 TrainAcc 0.8900 TestAcc 0.8669 0.8650
epoch 900 LossPred 0.3102 LossAtt 0.2802 TrainAcc 0.9000 TestAcc 0.8483 0.8650
epoch 1000 LossPred 0.3057 LossAtt 0.2801 TrainAcc 0.9000 TestAcc 0.8539 0.8500
epoch 1100 LossPred 0.4190 LossAtt 0.2711 TrainAcc 0.8600 TestAcc 0.8416 0.8350
epoch 1200 LossPred 0.2772 LossAtt 0.2740 TrainAcc 0.9000 TestAcc 0.8644 0.8850
epoch 1300 LossPred 0.2723 LossAtt 0.2683 TrainAcc 0.9100 TestAcc 0.8691 0.8850
epoch 1400 LossPred 0.2681 LossAtt 0.2650 TrainAcc 0.9100 TestAcc 0.8616 0.8600
epoch 1500 LossPred 0.3363 LossAtt 0.2717 TrainAcc 0.9100 TestAcc 0.8423 0.8800
epoch 1600 LossPred 0.2434 LossAtt 0.2661 TrainAcc 0.9400 TestAcc 0.8428 0.9100
epoch 1700 LossPred 0.2356 LossAtt 0.2627 TrainAcc 0.9400 TestAcc 0.8406 0.8950
epoch 1800 LossPred 0.3082 LossAtt 0.2566 TrainAcc 0.9300 TestAcc 0.8186 0.8950
epoch 1900 LossPred 0.2314 LossAtt 0.2555 TrainAcc 0.9500 TestAcc 0.8161 0.9000
epoch 2000 LossPred 0.2318 LossAtt 0.2592 TrainAcc 0.9500 TestAcc 0.8076 0.8900
epoch 2100 LossPred 0.4776 LossAtt 0.2516 TrainAcc 0.8300 TestAcc 0.7983 0.8350
epoch 2200 LossPred 0.2757 LossAtt 0.2650 TrainAcc 0.9300 TestAcc 0.7973 0.9000
epoch 2300 LossPred 0.1946 LossAtt 0.2614 TrainAcc 0.9600 TestAcc 0.7973 0.9100
epoch 2400 LossPred 0.3723 LossAtt 0.2706 TrainAcc 0.8700 TestAcc 0.7953 0.8550
epoch 2500 LossPred 0.2095 LossAtt 0.2570 TrainAcc 0.9500 TestAcc 0.7983 0.9100
Optimization Finished!
********** replication  55  **********
epoch   0 LossPred 1.1437 LossAtt 1.0130 TrainAcc 0.4800 TestAcc 0.5078 0.5000
epoch 100 LossPred 0.9189 LossAtt 0.1921 TrainAcc 0.6400 TestAcc 0.5766 0.6400
epoch 200 LossPred 0.9133 LossAtt 0.1331 TrainAcc 0.6400 TestAcc 0.5766 0.6400
epoch 300 LossPred 0.9025 LossAtt 0.1710 TrainAcc 0.6400 TestAcc 0.5766 0.6400
epoch 400 LossPred 0.7278 LossAtt 0.2042 TrainAcc 0.7400 TestAcc 0.7833 0.7750
epoch 500 LossPred 0.5823 LossAtt 0.1748 TrainAcc 0.8100 TestAcc 0.7920 0.8050
epoch 600 LossPred 0.5648 LossAtt 0.1821 TrainAcc 0.7800 TestAcc 0.8121 0.8200
epoch 700 LossPred 0.7943 LossAtt 0.1461 TrainAcc 0.6900 TestAcc 0.6609 0.7050
epoch 800 LossPred 0.9781 LossAtt 0.1271 TrainAcc 0.6400 TestAcc 0.5806 0.6450
epoch 900 LossPred 0.9649 LossAtt 0.1362 TrainAcc 0.6400 TestAcc 0.5803 0.6450
epoch 1000 LossPred 0.9534 LossAtt 0.1309 TrainAcc 0.6400 TestAcc 0.5808 0.6450
epoch 1100 LossPred 0.9443 LossAtt 0.1225 TrainAcc 0.6400 TestAcc 0.5803 0.6450
epoch 1200 LossPred 0.9366 LossAtt 0.1291 TrainAcc 0.6400 TestAcc 0.5798 0.6450
epoch 1300 LossPred 0.9256 LossAtt 0.1235 TrainAcc 0.6400 TestAcc 0.5798 0.6400
epoch 1400 LossPred 0.9234 LossAtt 0.1273 TrainAcc 0.6400 TestAcc 0.5783 0.6400
epoch 1500 LossPred 0.9190 LossAtt 0.1220 TrainAcc 0.6400 TestAcc 0.5796 0.6450
epoch 1600 LossPred 0.9172 LossAtt 0.1170 TrainAcc 0.6400 TestAcc 0.5776 0.6400
epoch 1700 LossPred 0.9145 LossAtt 0.1182 TrainAcc 0.6400 TestAcc 0.5786 0.6400
epoch 1800 LossPred 0.9145 LossAtt 0.1181 TrainAcc 0.6400 TestAcc 0.5776 0.6400
epoch 1900 LossPred 0.9132 LossAtt 0.1094 TrainAcc 0.6400 TestAcc 0.5773 0.6400
epoch 2000 LossPred 0.9134 LossAtt 0.1103 TrainAcc 0.6400 TestAcc 0.5773 0.6400
epoch 2100 LossPred 0.9135 LossAtt 0.1216 TrainAcc 0.6400 TestAcc 0.5773 0.6400
epoch 2200 LossPred 0.9130 LossAtt 0.1124 TrainAcc 0.6400 TestAcc 0.5786 0.6450
epoch 2300 LossPred 0.9138 LossAtt 0.1154 TrainAcc 0.6400 TestAcc 0.5766 0.6400
epoch 2400 LossPred 0.9133 LossAtt 0.1102 TrainAcc 0.6400 TestAcc 0.5773 0.6400
epoch 2500 LossPred 0.9130 LossAtt 0.1080 TrainAcc 0.6400 TestAcc 0.5768 0.6400
Optimization Finished!
********** replication  56  **********
epoch   0 LossPred 1.0380 LossAtt 1.0140 TrainAcc 0.4900 TestAcc 0.5343 0.5050
epoch 100 LossPred 0.9351 LossAtt 0.2655 TrainAcc 0.5100 TestAcc 0.5160 0.5250
epoch 200 LossPred 0.9320 LossAtt 0.1583 TrainAcc 0.5800 TestAcc 0.5671 0.5350
epoch 300 LossPred 0.9329 LossAtt 0.1566 TrainAcc 0.5800 TestAcc 0.5013 0.5850
epoch 400 LossPred 0.9269 LossAtt 0.1653 TrainAcc 0.5800 TestAcc 0.5013 0.5800
epoch 500 LossPred 0.9357 LossAtt 0.1292 TrainAcc 0.5800 TestAcc 0.5013 0.5800
epoch 600 LossPred 0.9360 LossAtt 0.1757 TrainAcc 0.5700 TestAcc 0.5140 0.5800
epoch 700 LossPred 0.8957 LossAtt 0.1934 TrainAcc 0.6100 TestAcc 0.5278 0.5950
epoch 800 LossPred 0.8724 LossAtt 0.1914 TrainAcc 0.6400 TestAcc 0.5445 0.6400
epoch 900 LossPred 0.8205 LossAtt 0.3374 TrainAcc 0.7100 TestAcc 0.5333 0.7000
epoch 1000 LossPred 0.7078 LossAtt 0.3992 TrainAcc 0.7700 TestAcc 0.5423 0.7400
epoch 1100 LossPred 0.4807 LossAtt 0.4192 TrainAcc 0.8000 TestAcc 0.6209 0.8000
epoch 1200 LossPred 0.6367 LossAtt 0.3946 TrainAcc 0.7800 TestAcc 0.5733 0.7800
epoch 1300 LossPred 0.3490 LossAtt 0.3848 TrainAcc 0.8900 TestAcc 0.7420 0.8550
epoch 1400 LossPred 0.2675 LossAtt 0.3904 TrainAcc 0.9300 TestAcc 0.7518 0.8250
epoch 1500 LossPred 0.3016 LossAtt 0.3782 TrainAcc 0.8800 TestAcc 0.7472 0.8650
epoch 1600 LossPred 0.2960 LossAtt 0.3836 TrainAcc 0.9000 TestAcc 0.7352 0.8550
epoch 1700 LossPred 0.2089 LossAtt 0.3781 TrainAcc 0.9400 TestAcc 0.7420 0.8700
epoch 1800 LossPred 0.2338 LossAtt 0.3779 TrainAcc 0.9100 TestAcc 0.7442 0.8800
epoch 1900 LossPred 0.2239 LossAtt 0.3771 TrainAcc 0.9200 TestAcc 0.7427 0.8800
epoch 2000 LossPred 0.1770 LossAtt 0.3803 TrainAcc 0.9600 TestAcc 0.7442 0.8850
epoch 2100 LossPred 0.1595 LossAtt 0.3711 TrainAcc 0.9500 TestAcc 0.7437 0.8800
epoch 2200 LossPred 0.1547 LossAtt 0.3705 TrainAcc 0.9500 TestAcc 0.7417 0.8750
epoch 2300 LossPred 0.3824 LossAtt 0.3646 TrainAcc 0.8800 TestAcc 0.7580 0.8550
epoch 2400 LossPred 0.3170 LossAtt 0.3496 TrainAcc 0.9100 TestAcc 0.7487 0.8550
epoch 2500 LossPred 0.2253 LossAtt 0.3199 TrainAcc 0.9400 TestAcc 0.7252 0.8500
Optimization Finished!
********** replication  57  **********
epoch   0 LossPred 1.3168 LossAtt 1.0502 TrainAcc 0.3600 TestAcc 0.4489 0.4250
epoch 100 LossPred 0.8926 LossAtt 0.2907 TrainAcc 0.6800 TestAcc 0.5813 0.6700
epoch 200 LossPred 0.8256 LossAtt 0.2747 TrainAcc 0.7400 TestAcc 0.6219 0.7050
epoch 300 LossPred 0.7106 LossAtt 0.2847 TrainAcc 0.7800 TestAcc 0.6697 0.7800
epoch 400 LossPred 0.5867 LossAtt 0.2742 TrainAcc 0.7600 TestAcc 0.7220 0.7650
epoch 500 LossPred 0.5991 LossAtt 0.3162 TrainAcc 0.7600 TestAcc 0.7523 0.7950
epoch 600 LossPred 0.5415 LossAtt 0.3021 TrainAcc 0.8300 TestAcc 0.7510 0.8150
epoch 700 LossPred 0.4619 LossAtt 0.3080 TrainAcc 0.8500 TestAcc 0.7815 0.8300
epoch 800 LossPred 0.3735 LossAtt 0.3087 TrainAcc 0.8900 TestAcc 0.7935 0.8450
epoch 900 LossPred 0.3644 LossAtt 0.3266 TrainAcc 0.9000 TestAcc 0.7990 0.8550
epoch 1000 LossPred 0.3556 LossAtt 0.3366 TrainAcc 0.8800 TestAcc 0.7978 0.8750
epoch 1100 LossPred 0.3026 LossAtt 0.3354 TrainAcc 0.9000 TestAcc 0.8023 0.8550
epoch 1200 LossPred 0.3420 LossAtt 0.3366 TrainAcc 0.8800 TestAcc 0.8121 0.8800
epoch 1300 LossPred 0.3261 LossAtt 0.3308 TrainAcc 0.8600 TestAcc 0.8133 0.8800
epoch 1400 LossPred 0.3054 LossAtt 0.3239 TrainAcc 0.9200 TestAcc 0.8176 0.8850
epoch 1500 LossPred 0.2594 LossAtt 0.3243 TrainAcc 0.9200 TestAcc 0.8201 0.8950
epoch 1600 LossPred 0.2163 LossAtt 0.3080 TrainAcc 0.9300 TestAcc 0.8148 0.8700
epoch 1700 LossPred 0.3134 LossAtt 0.3049 TrainAcc 0.8900 TestAcc 0.8033 0.8700
epoch 1800 LossPred 0.2390 LossAtt 0.3150 TrainAcc 0.9200 TestAcc 0.8111 0.8650
epoch 1900 LossPred 0.3470 LossAtt 0.2976 TrainAcc 0.8800 TestAcc 0.7980 0.8750
epoch 2000 LossPred 0.2279 LossAtt 0.2974 TrainAcc 0.9200 TestAcc 0.8163 0.8900
epoch 2100 LossPred 0.2675 LossAtt 0.2857 TrainAcc 0.9000 TestAcc 0.8093 0.8850
epoch 2200 LossPred 0.2266 LossAtt 0.2848 TrainAcc 0.9300 TestAcc 0.8071 0.8850
epoch 2300 LossPred 0.2715 LossAtt 0.2873 TrainAcc 0.8900 TestAcc 0.8071 0.8850
epoch 2400 LossPred 0.1935 LossAtt 0.2807 TrainAcc 0.9500 TestAcc 0.8068 0.8900
epoch 2500 LossPred 0.2837 LossAtt 0.2852 TrainAcc 0.9200 TestAcc 0.8011 0.8800
Optimization Finished!
********** replication  58  **********
epoch   0 LossPred 0.9658 LossAtt 1.0075 TrainAcc 0.6100 TestAcc 0.5420 0.6150
epoch 100 LossPred 0.8903 LossAtt 0.2761 TrainAcc 0.6400 TestAcc 0.5748 0.6450
epoch 200 LossPred 0.8263 LossAtt 0.3006 TrainAcc 0.7200 TestAcc 0.6396 0.6950
epoch 300 LossPred 0.7636 LossAtt 0.2877 TrainAcc 0.7100 TestAcc 0.6957 0.7250
epoch 400 LossPred 0.6748 LossAtt 0.2765 TrainAcc 0.8000 TestAcc 0.6912 0.7750
epoch 500 LossPred 0.3566 LossAtt 0.2525 TrainAcc 0.8800 TestAcc 0.8031 0.8250
epoch 600 LossPred 0.3980 LossAtt 0.2403 TrainAcc 0.8800 TestAcc 0.8226 0.8350
epoch 700 LossPred 0.2931 LossAtt 0.2389 TrainAcc 0.9000 TestAcc 0.8143 0.8300
epoch 800 LossPred 0.3862 LossAtt 0.2234 TrainAcc 0.8800 TestAcc 0.8248 0.8500
epoch 900 LossPred 0.3838 LossAtt 0.2163 TrainAcc 0.8800 TestAcc 0.8293 0.8550
epoch 1000 LossPred 0.3725 LossAtt 0.2187 TrainAcc 0.9000 TestAcc 0.8326 0.8550
epoch 1100 LossPred 0.3007 LossAtt 0.2287 TrainAcc 0.8900 TestAcc 0.8151 0.8400
epoch 1200 LossPred 0.2939 LossAtt 0.2219 TrainAcc 0.9000 TestAcc 0.8231 0.8650
epoch 1300 LossPred 0.3429 LossAtt 0.2083 TrainAcc 0.8800 TestAcc 0.7988 0.8400
epoch 1400 LossPred 0.2937 LossAtt 0.2130 TrainAcc 0.9000 TestAcc 0.8236 0.8650
epoch 1500 LossPred 0.4205 LossAtt 0.2043 TrainAcc 0.8800 TestAcc 0.8313 0.8750
epoch 1600 LossPred 0.3724 LossAtt 0.2006 TrainAcc 0.8800 TestAcc 0.8408 0.8650
epoch 1700 LossPred 0.3265 LossAtt 0.1934 TrainAcc 0.8900 TestAcc 0.7960 0.8300
epoch 1800 LossPred 0.3157 LossAtt 0.1892 TrainAcc 0.8700 TestAcc 0.7925 0.8350
epoch 1900 LossPred 0.4002 LossAtt 0.1813 TrainAcc 0.8700 TestAcc 0.8378 0.8800
epoch 2000 LossPred 0.3747 LossAtt 0.1704 TrainAcc 0.8900 TestAcc 0.8371 0.8850
epoch 2100 LossPred 0.4973 LossAtt 0.1659 TrainAcc 0.8500 TestAcc 0.7357 0.8200
epoch 2200 LossPred 0.3279 LossAtt 0.1680 TrainAcc 0.9000 TestAcc 0.8313 0.8750
epoch 2300 LossPred 0.3195 LossAtt 0.1519 TrainAcc 0.9100 TestAcc 0.8296 0.8900
epoch 2400 LossPred 0.3111 LossAtt 0.1544 TrainAcc 0.9200 TestAcc 0.8213 0.8800
epoch 2500 LossPred 0.4269 LossAtt 0.1528 TrainAcc 0.8800 TestAcc 0.8246 0.8550
Optimization Finished!
********** replication  59  **********
epoch   0 LossPred 1.2689 LossAtt 1.0205 TrainAcc 0.3900 TestAcc 0.4570 0.4050
epoch 100 LossPred 0.8665 LossAtt 0.2947 TrainAcc 0.6600 TestAcc 0.5818 0.6450
epoch 200 LossPred 0.3723 LossAtt 0.2475 TrainAcc 0.8600 TestAcc 0.8063 0.8500
epoch 300 LossPred 0.1902 LossAtt 0.2242 TrainAcc 0.9500 TestAcc 0.8536 0.9100
epoch 400 LossPred 0.1689 LossAtt 0.2177 TrainAcc 0.9600 TestAcc 0.8606 0.9250
epoch 500 LossPred 0.1848 LossAtt 0.1989 TrainAcc 0.9700 TestAcc 0.8666 0.9350
epoch 600 LossPred 0.2115 LossAtt 0.1984 TrainAcc 0.9300 TestAcc 0.8701 0.9300
epoch 700 LossPred 0.4029 LossAtt 0.1848 TrainAcc 0.8600 TestAcc 0.8106 0.8650
epoch 800 LossPred 0.2922 LossAtt 0.1937 TrainAcc 0.9100 TestAcc 0.8338 0.8950
epoch 900 LossPred 0.1769 LossAtt 0.1820 TrainAcc 0.9400 TestAcc 0.8461 0.9250
epoch 1000 LossPred 0.2172 LossAtt 0.1768 TrainAcc 0.9200 TestAcc 0.8321 0.9000
epoch 1100 LossPred 0.1629 LossAtt 0.1712 TrainAcc 0.9600 TestAcc 0.8701 0.9450
epoch 1200 LossPred 0.3486 LossAtt 0.1761 TrainAcc 0.8400 TestAcc 0.8003 0.8800
epoch 1300 LossPred 0.1583 LossAtt 0.1676 TrainAcc 0.9600 TestAcc 0.8799 0.9450
epoch 1400 LossPred 0.2646 LossAtt 0.1586 TrainAcc 0.9100 TestAcc 0.8566 0.9100
epoch 1500 LossPred 0.3521 LossAtt 0.1620 TrainAcc 0.8800 TestAcc 0.8046 0.8650
epoch 1600 LossPred 0.3183 LossAtt 0.1613 TrainAcc 0.8800 TestAcc 0.8161 0.8750
epoch 1700 LossPred 0.1853 LossAtt 0.1516 TrainAcc 0.9400 TestAcc 0.8714 0.9250
epoch 1800 LossPred 0.4000 LossAtt 0.1517 TrainAcc 0.8400 TestAcc 0.7935 0.8550
epoch 1900 LossPred 0.1405 LossAtt 0.1458 TrainAcc 0.9600 TestAcc 0.8836 0.9600
epoch 2000 LossPred 0.1806 LossAtt 0.1436 TrainAcc 0.9400 TestAcc 0.8749 0.9300
epoch 2100 LossPred 0.1248 LossAtt 0.1419 TrainAcc 0.9600 TestAcc 0.8839 0.9500
epoch 2200 LossPred 0.1327 LossAtt 0.1430 TrainAcc 0.9600 TestAcc 0.8906 0.9400
epoch 2300 LossPred 0.2257 LossAtt 0.1411 TrainAcc 0.9200 TestAcc 0.8611 0.9150
epoch 2400 LossPred 0.2089 LossAtt 0.1351 TrainAcc 0.9400 TestAcc 0.8636 0.9450
epoch 2500 LossPred 0.1241 LossAtt 0.1359 TrainAcc 0.9600 TestAcc 0.8906 0.9500
Optimization Finished!
********** replication  60  **********
epoch   0 LossPred 0.9731 LossAtt 1.0181 TrainAcc 0.6100 TestAcc 0.5511 0.5800
epoch 100 LossPred 0.8210 LossAtt 0.2662 TrainAcc 0.7000 TestAcc 0.6204 0.6750
epoch 200 LossPred 0.6136 LossAtt 0.2221 TrainAcc 0.8000 TestAcc 0.8018 0.7800
epoch 300 LossPred 0.5802 LossAtt 0.2026 TrainAcc 0.8100 TestAcc 0.7913 0.8150
epoch 400 LossPred 0.5335 LossAtt 0.1998 TrainAcc 0.8100 TestAcc 0.7990 0.7900
epoch 500 LossPred 0.5060 LossAtt 0.1769 TrainAcc 0.8500 TestAcc 0.7968 0.8000
epoch 600 LossPred 0.5373 LossAtt 0.1748 TrainAcc 0.8200 TestAcc 0.8091 0.8000
epoch 700 LossPred 0.5429 LossAtt 0.1654 TrainAcc 0.8200 TestAcc 0.7885 0.8000
epoch 800 LossPred 0.5472 LossAtt 0.1584 TrainAcc 0.8200 TestAcc 0.7928 0.7900
epoch 900 LossPred 0.9133 LossAtt 0.1616 TrainAcc 0.6200 TestAcc 0.6171 0.6100
epoch 1000 LossPred 0.8494 LossAtt 0.1717 TrainAcc 0.6300 TestAcc 0.5973 0.6050
epoch 1100 LossPred 0.7855 LossAtt 0.1857 TrainAcc 0.7000 TestAcc 0.6657 0.6750
epoch 1200 LossPred 0.6530 LossAtt 0.1940 TrainAcc 0.7500 TestAcc 0.6944 0.7250
epoch 1300 LossPred 0.5518 LossAtt 0.1923 TrainAcc 0.7900 TestAcc 0.7905 0.7850
epoch 1400 LossPred 0.4739 LossAtt 0.1760 TrainAcc 0.8300 TestAcc 0.8098 0.8050
epoch 1500 LossPred 0.4669 LossAtt 0.1759 TrainAcc 0.8300 TestAcc 0.8076 0.7800
epoch 1600 LossPred 0.5095 LossAtt 0.1819 TrainAcc 0.8000 TestAcc 0.7948 0.7850
epoch 1700 LossPred 0.5100 LossAtt 0.1898 TrainAcc 0.8100 TestAcc 0.7813 0.7800
epoch 1800 LossPred 0.5711 LossAtt 0.1938 TrainAcc 0.7900 TestAcc 0.7563 0.7900
epoch 1900 LossPred 0.5633 LossAtt 0.1818 TrainAcc 0.7900 TestAcc 0.7568 0.7900
epoch 2000 LossPred 0.5521 LossAtt 0.1737 TrainAcc 0.7900 TestAcc 0.7663 0.7850
epoch 2100 LossPred 0.5681 LossAtt 0.1859 TrainAcc 0.7800 TestAcc 0.7523 0.7800
epoch 2200 LossPred 0.5535 LossAtt 0.1885 TrainAcc 0.7900 TestAcc 0.7680 0.7650
epoch 2300 LossPred 0.5340 LossAtt 0.1915 TrainAcc 0.8000 TestAcc 0.7860 0.8050
epoch 2400 LossPred 0.5706 LossAtt 0.1865 TrainAcc 0.8100 TestAcc 0.8098 0.8250
epoch 2500 LossPred 0.5767 LossAtt 0.1804 TrainAcc 0.7900 TestAcc 0.8041 0.7850
Optimization Finished!
********** replication  61  **********
epoch   0 LossPred 0.9928 LossAtt 1.0061 TrainAcc 0.5300 TestAcc 0.5005 0.5200
epoch 100 LossPred 0.8835 LossAtt 0.3372 TrainAcc 0.6500 TestAcc 0.5728 0.6500
epoch 200 LossPred 0.4252 LossAtt 0.3148 TrainAcc 0.8700 TestAcc 0.8193 0.8550
epoch 300 LossPred 0.3246 LossAtt 0.2876 TrainAcc 0.9100 TestAcc 0.8741 0.8750
epoch 400 LossPred 0.2920 LossAtt 0.2388 TrainAcc 0.9300 TestAcc 0.8811 0.9050
epoch 500 LossPred 0.5678 LossAtt 0.2383 TrainAcc 0.8000 TestAcc 0.7750 0.8100
epoch 600 LossPred 0.4090 LossAtt 0.2189 TrainAcc 0.8800 TestAcc 0.8526 0.8750
epoch 700 LossPred 0.4992 LossAtt 0.2097 TrainAcc 0.8400 TestAcc 0.8233 0.8200
epoch 800 LossPred 0.3081 LossAtt 0.1786 TrainAcc 0.9200 TestAcc 0.8734 0.9050
epoch 900 LossPred 0.5079 LossAtt 0.1722 TrainAcc 0.8400 TestAcc 0.7958 0.8250
epoch 1000 LossPred 0.4089 LossAtt 0.1930 TrainAcc 0.8700 TestAcc 0.8066 0.8550
epoch 1100 LossPred 0.3428 LossAtt 0.1773 TrainAcc 0.9100 TestAcc 0.8493 0.8750
epoch 1200 LossPred 0.3474 LossAtt 0.1747 TrainAcc 0.8900 TestAcc 0.8544 0.8550
epoch 1300 LossPred 0.5350 LossAtt 0.1829 TrainAcc 0.8300 TestAcc 0.8078 0.8000
epoch 1400 LossPred 0.6324 LossAtt 0.1627 TrainAcc 0.7900 TestAcc 0.7590 0.8150
epoch 1500 LossPred 0.3769 LossAtt 0.1681 TrainAcc 0.8900 TestAcc 0.8473 0.8150
epoch 1600 LossPred 0.5591 LossAtt 0.1749 TrainAcc 0.8200 TestAcc 0.7888 0.8200
epoch 1700 LossPred 0.7489 LossAtt 0.1757 TrainAcc 0.7500 TestAcc 0.7605 0.7400
epoch 1800 LossPred 0.4423 LossAtt 0.1807 TrainAcc 0.8600 TestAcc 0.8048 0.8100
epoch 1900 LossPred 0.3735 LossAtt 0.1789 TrainAcc 0.8900 TestAcc 0.8388 0.8300
epoch 2000 LossPred 0.7565 LossAtt 0.1856 TrainAcc 0.7300 TestAcc 0.7680 0.7250
epoch 2100 LossPred 0.3221 LossAtt 0.1884 TrainAcc 0.9200 TestAcc 0.8536 0.8850
epoch 2200 LossPred 0.5350 LossAtt 0.1955 TrainAcc 0.8200 TestAcc 0.7835 0.8300
epoch 2300 LossPred 0.3270 LossAtt 0.2000 TrainAcc 0.9000 TestAcc 0.8504 0.9000
epoch 2400 LossPred 0.4246 LossAtt 0.2232 TrainAcc 0.8500 TestAcc 0.8388 0.8500
epoch 2500 LossPred 0.4620 LossAtt 0.2149 TrainAcc 0.8400 TestAcc 0.8006 0.8600
Optimization Finished!
********** replication  62  **********
epoch   0 LossPred 1.2245 LossAtt 1.0127 TrainAcc 0.4200 TestAcc 0.5000 0.4200
epoch 100 LossPred 0.9683 LossAtt 0.2832 TrainAcc 0.5900 TestAcc 0.5420 0.5850
epoch 200 LossPred 0.9574 LossAtt 0.2086 TrainAcc 0.6000 TestAcc 0.5255 0.6100
epoch 300 LossPred 0.8882 LossAtt 0.2887 TrainAcc 0.6800 TestAcc 0.5425 0.6750
epoch 400 LossPred 0.6282 LossAtt 0.3312 TrainAcc 0.8100 TestAcc 0.7340 0.8050
epoch 500 LossPred 0.4976 LossAtt 0.3185 TrainAcc 0.8500 TestAcc 0.7780 0.8500
epoch 600 LossPred 0.4273 LossAtt 0.3211 TrainAcc 0.8800 TestAcc 0.7675 0.8750
epoch 700 LossPred 0.4034 LossAtt 0.3049 TrainAcc 0.9000 TestAcc 0.7878 0.8800
epoch 800 LossPred 0.3789 LossAtt 0.3042 TrainAcc 0.9200 TestAcc 0.7830 0.9000
epoch 900 LossPred 0.3501 LossAtt 0.2823 TrainAcc 0.9200 TestAcc 0.7900 0.9000
epoch 1000 LossPred 0.3404 LossAtt 0.2861 TrainAcc 0.9200 TestAcc 0.7900 0.9100
epoch 1100 LossPred 0.3364 LossAtt 0.2927 TrainAcc 0.9200 TestAcc 0.7893 0.8950
epoch 1200 LossPred 0.3309 LossAtt 0.2914 TrainAcc 0.9100 TestAcc 0.7853 0.9150
epoch 1300 LossPred 0.3210 LossAtt 0.3138 TrainAcc 0.9200 TestAcc 0.7910 0.9050
epoch 1400 LossPred 0.2860 LossAtt 0.3157 TrainAcc 0.9200 TestAcc 0.7900 0.9200
epoch 1500 LossPred 0.2680 LossAtt 0.3276 TrainAcc 0.9300 TestAcc 0.8063 0.9350
epoch 1600 LossPred 0.2360 LossAtt 0.3360 TrainAcc 0.9300 TestAcc 0.8181 0.9000
epoch 1700 LossPred 0.2319 LossAtt 0.3483 TrainAcc 0.9300 TestAcc 0.8186 0.9400
epoch 1800 LossPred 0.1543 LossAtt 0.3460 TrainAcc 0.9700 TestAcc 0.8293 0.9450
epoch 1900 LossPred 0.1546 LossAtt 0.3454 TrainAcc 0.9600 TestAcc 0.8333 0.9500
epoch 2000 LossPred 0.1445 LossAtt 0.3377 TrainAcc 0.9700 TestAcc 0.8326 0.9400
epoch 2100 LossPred 0.1373 LossAtt 0.3373 TrainAcc 0.9600 TestAcc 0.8426 0.9500
epoch 2200 LossPred 0.1288 LossAtt 0.3345 TrainAcc 0.9700 TestAcc 0.8383 0.9600
epoch 2300 LossPred 0.1273 LossAtt 0.3482 TrainAcc 0.9700 TestAcc 0.8333 0.9450
epoch 2400 LossPred 0.0612 LossAtt 0.3411 TrainAcc 0.9900 TestAcc 0.8431 0.9450
epoch 2500 LossPred 0.1451 LossAtt 0.3284 TrainAcc 0.9600 TestAcc 0.8433 0.9300
Optimization Finished!
********** replication  63  **********
epoch   0 LossPred 1.0081 LossAtt 1.0044 TrainAcc 0.5700 TestAcc 0.5521 0.5750
epoch 100 LossPred 0.8525 LossAtt 0.2998 TrainAcc 0.7100 TestAcc 0.6086 0.6650
epoch 200 LossPred 0.3267 LossAtt 0.3390 TrainAcc 0.9100 TestAcc 0.8141 0.8800
epoch 300 LossPred 0.2193 LossAtt 0.3227 TrainAcc 0.9300 TestAcc 0.8564 0.9100
epoch 400 LossPred 0.1911 LossAtt 0.3232 TrainAcc 0.9400 TestAcc 0.8493 0.9300
epoch 500 LossPred 0.1662 LossAtt 0.3083 TrainAcc 0.9400 TestAcc 0.8646 0.9100
epoch 600 LossPred 0.1764 LossAtt 0.2885 TrainAcc 0.9300 TestAcc 0.8584 0.9250
epoch 700 LossPred 0.1706 LossAtt 0.2825 TrainAcc 0.9400 TestAcc 0.8576 0.9150
epoch 800 LossPred 0.1564 LossAtt 0.2698 TrainAcc 0.9400 TestAcc 0.8586 0.9200
epoch 900 LossPred 0.1789 LossAtt 0.2792 TrainAcc 0.9500 TestAcc 0.8496 0.9250
epoch 1000 LossPred 0.1861 LossAtt 0.2653 TrainAcc 0.9400 TestAcc 0.8458 0.9150
epoch 1100 LossPred 0.1880 LossAtt 0.2729 TrainAcc 0.9400 TestAcc 0.8453 0.9200
epoch 1200 LossPred 0.2067 LossAtt 0.2451 TrainAcc 0.9400 TestAcc 0.8373 0.9150
epoch 1300 LossPred 0.1802 LossAtt 0.2510 TrainAcc 0.9400 TestAcc 0.8546 0.9350
epoch 1400 LossPred 0.1587 LossAtt 0.2405 TrainAcc 0.9400 TestAcc 0.8576 0.9150
epoch 1500 LossPred 0.2181 LossAtt 0.2417 TrainAcc 0.9100 TestAcc 0.8541 0.9150
epoch 1600 LossPred 0.1852 LossAtt 0.2472 TrainAcc 0.9400 TestAcc 0.8506 0.9000
epoch 1700 LossPred 0.2234 LossAtt 0.2217 TrainAcc 0.9300 TestAcc 0.8368 0.8950
epoch 1800 LossPred 0.1444 LossAtt 0.2253 TrainAcc 0.9200 TestAcc 0.8691 0.9350
epoch 1900 LossPred 0.1289 LossAtt 0.2398 TrainAcc 0.9400 TestAcc 0.8749 0.9400
epoch 2000 LossPred 0.1817 LossAtt 0.2444 TrainAcc 0.9300 TestAcc 0.8669 0.9250
epoch 2100 LossPred 0.1558 LossAtt 0.2407 TrainAcc 0.9500 TestAcc 0.8761 0.9400
epoch 2200 LossPred 0.1460 LossAtt 0.2606 TrainAcc 0.9400 TestAcc 0.8691 0.9400
epoch 2300 LossPred 0.1279 LossAtt 0.2417 TrainAcc 0.9500 TestAcc 0.8724 0.9500
epoch 2400 LossPred 0.2083 LossAtt 0.2513 TrainAcc 0.9300 TestAcc 0.8458 0.9050
epoch 2500 LossPred 0.3957 LossAtt 0.2622 TrainAcc 0.8600 TestAcc 0.7462 0.8500
Optimization Finished!
********** replication  64  **********
epoch   0 LossPred 1.0688 LossAtt 1.0114 TrainAcc 0.5000 TestAcc 0.4735 0.4600
epoch 100 LossPred 0.9333 LossAtt 0.2680 TrainAcc 0.5900 TestAcc 0.5741 0.6050
epoch 200 LossPred 0.9148 LossAtt 0.2360 TrainAcc 0.6200 TestAcc 0.5713 0.6100
epoch 300 LossPred 0.4866 LossAtt 0.2988 TrainAcc 0.8100 TestAcc 0.7710 0.8150
epoch 400 LossPred 0.3096 LossAtt 0.2497 TrainAcc 0.8900 TestAcc 0.7978 0.8750
epoch 500 LossPred 0.2154 LossAtt 0.2327 TrainAcc 0.9200 TestAcc 0.8413 0.9250
epoch 600 LossPred 0.1929 LossAtt 0.2269 TrainAcc 0.9200 TestAcc 0.8511 0.9300
epoch 700 LossPred 0.2215 LossAtt 0.2207 TrainAcc 0.9300 TestAcc 0.8521 0.9300
epoch 800 LossPred 0.1941 LossAtt 0.2212 TrainAcc 0.9500 TestAcc 0.8521 0.9200
epoch 900 LossPred 0.1851 LossAtt 0.2175 TrainAcc 0.9500 TestAcc 0.8413 0.9350
epoch 1000 LossPred 0.2073 LossAtt 0.2206 TrainAcc 0.9200 TestAcc 0.8268 0.9200
epoch 1100 LossPred 0.1954 LossAtt 0.2156 TrainAcc 0.9500 TestAcc 0.8451 0.9350
epoch 1200 LossPred 0.1776 LossAtt 0.2059 TrainAcc 0.9600 TestAcc 0.8391 0.9400
epoch 1300 LossPred 0.2009 LossAtt 0.2002 TrainAcc 0.9400 TestAcc 0.8481 0.9250
epoch 1400 LossPred 0.2370 LossAtt 0.1952 TrainAcc 0.9000 TestAcc 0.8301 0.9000
epoch 1500 LossPred 0.1560 LossAtt 0.1990 TrainAcc 0.9600 TestAcc 0.8391 0.9400
epoch 1600 LossPred 0.1496 LossAtt 0.1950 TrainAcc 0.9700 TestAcc 0.8356 0.9350
epoch 1700 LossPred 0.1804 LossAtt 0.1836 TrainAcc 0.9400 TestAcc 0.8313 0.9500
epoch 1800 LossPred 0.1660 LossAtt 0.1919 TrainAcc 0.9500 TestAcc 0.8291 0.9250
epoch 1900 LossPred 0.1849 LossAtt 0.1831 TrainAcc 0.9200 TestAcc 0.8158 0.9150
epoch 2000 LossPred 0.1761 LossAtt 0.1892 TrainAcc 0.9400 TestAcc 0.8308 0.9300
epoch 2100 LossPred 0.1942 LossAtt 0.1840 TrainAcc 0.9500 TestAcc 0.8233 0.9100
epoch 2200 LossPred 0.2223 LossAtt 0.1971 TrainAcc 0.9100 TestAcc 0.8171 0.9000
epoch 2300 LossPred 0.1584 LossAtt 0.1820 TrainAcc 0.9400 TestAcc 0.8191 0.9300
epoch 2400 LossPred 0.2061 LossAtt 0.1819 TrainAcc 0.9300 TestAcc 0.8036 0.9100
epoch 2500 LossPred 0.2183 LossAtt 0.1778 TrainAcc 0.9300 TestAcc 0.8161 0.9150
Optimization Finished!
********** replication  65  **********
epoch   0 LossPred 0.9923 LossAtt 1.0050 TrainAcc 0.5700 TestAcc 0.5768 0.5700
epoch 100 LossPred 0.9163 LossAtt 0.3174 TrainAcc 0.6400 TestAcc 0.5676 0.6350
epoch 200 LossPred 0.9044 LossAtt 0.2679 TrainAcc 0.6400 TestAcc 0.5676 0.6300
epoch 300 LossPred 0.8799 LossAtt 0.2471 TrainAcc 0.6500 TestAcc 0.5563 0.6450
epoch 400 LossPred 0.8626 LossAtt 0.2245 TrainAcc 0.6500 TestAcc 0.5338 0.6500
epoch 500 LossPred 0.8205 LossAtt 0.3124 TrainAcc 0.7100 TestAcc 0.5130 0.6950
epoch 600 LossPred 0.7734 LossAtt 0.3544 TrainAcc 0.7300 TestAcc 0.5233 0.7250
epoch 700 LossPred 0.7467 LossAtt 0.4056 TrainAcc 0.7100 TestAcc 0.5205 0.7100
epoch 800 LossPred 0.6406 LossAtt 0.4267 TrainAcc 0.7700 TestAcc 0.5113 0.7550
epoch 900 LossPred 0.5469 LossAtt 0.4538 TrainAcc 0.8500 TestAcc 0.5135 0.7900
epoch 1000 LossPred 0.4980 LossAtt 0.4327 TrainAcc 0.8500 TestAcc 0.5218 0.8100
epoch 1100 LossPred 0.4840 LossAtt 0.4313 TrainAcc 0.8500 TestAcc 0.5273 0.8150
epoch 1200 LossPred 0.4224 LossAtt 0.4234 TrainAcc 0.9000 TestAcc 0.5240 0.8250
epoch 1300 LossPred 0.4257 LossAtt 0.4202 TrainAcc 0.8800 TestAcc 0.5215 0.8250
epoch 1400 LossPred 0.3632 LossAtt 0.4219 TrainAcc 0.9100 TestAcc 0.5218 0.8350
epoch 1500 LossPred 0.3415 LossAtt 0.4213 TrainAcc 0.9200 TestAcc 0.5260 0.8450
epoch 1600 LossPred 0.4090 LossAtt 0.4154 TrainAcc 0.8700 TestAcc 0.5275 0.8400
epoch 1700 LossPred 0.3207 LossAtt 0.4074 TrainAcc 0.9100 TestAcc 0.5273 0.8550
epoch 1800 LossPred 0.3181 LossAtt 0.4216 TrainAcc 0.9200 TestAcc 0.5280 0.8500
epoch 1900 LossPred 0.3263 LossAtt 0.4161 TrainAcc 0.9200 TestAcc 0.5238 0.8600
epoch 2000 LossPred 0.2775 LossAtt 0.4129 TrainAcc 0.9100 TestAcc 0.5270 0.8450
epoch 2100 LossPred 0.2725 LossAtt 0.4218 TrainAcc 0.9200 TestAcc 0.5190 0.8550
epoch 2200 LossPred 0.2715 LossAtt 0.4246 TrainAcc 0.9200 TestAcc 0.5225 0.8500
epoch 2300 LossPred 0.2619 LossAtt 0.4272 TrainAcc 0.9300 TestAcc 0.5273 0.8550
epoch 2400 LossPred 0.3081 LossAtt 0.4240 TrainAcc 0.9000 TestAcc 0.5233 0.8500
epoch 2500 LossPred 0.2612 LossAtt 0.4259 TrainAcc 0.9300 TestAcc 0.5250 0.8600
Optimization Finished!
********** replication  66  **********
epoch   0 LossPred 0.9773 LossAtt 1.0337 TrainAcc 0.5700 TestAcc 0.5533 0.5950
epoch 100 LossPred 0.9241 LossAtt 0.2608 TrainAcc 0.6300 TestAcc 0.5866 0.6300
epoch 200 LossPred 0.9192 LossAtt 0.1828 TrainAcc 0.6300 TestAcc 0.5866 0.6300
epoch 300 LossPred 0.8804 LossAtt 0.2023 TrainAcc 0.6700 TestAcc 0.5888 0.6500
epoch 400 LossPred 0.6949 LossAtt 0.3239 TrainAcc 0.7400 TestAcc 0.7558 0.7650
epoch 500 LossPred 0.4732 LossAtt 0.3191 TrainAcc 0.8500 TestAcc 0.8251 0.8050
epoch 600 LossPred 0.7395 LossAtt 0.3002 TrainAcc 0.7300 TestAcc 0.7432 0.7250
epoch 700 LossPred 0.6529 LossAtt 0.2464 TrainAcc 0.7900 TestAcc 0.7750 0.7900
epoch 800 LossPred 0.4506 LossAtt 0.2551 TrainAcc 0.8600 TestAcc 0.8053 0.8200
epoch 900 LossPred 0.4830 LossAtt 0.2553 TrainAcc 0.8600 TestAcc 0.8086 0.8050
epoch 1000 LossPred 0.5764 LossAtt 0.2414 TrainAcc 0.8100 TestAcc 0.7888 0.7800
epoch 1100 LossPred 0.5563 LossAtt 0.2015 TrainAcc 0.8300 TestAcc 0.8026 0.7850
epoch 1200 LossPred 0.5432 LossAtt 0.1844 TrainAcc 0.8200 TestAcc 0.8021 0.7850
epoch 1300 LossPred 0.5436 LossAtt 0.1833 TrainAcc 0.8300 TestAcc 0.7980 0.8000
epoch 1400 LossPred 0.5018 LossAtt 0.1843 TrainAcc 0.8400 TestAcc 0.8013 0.8100
epoch 1500 LossPred 0.5338 LossAtt 0.1873 TrainAcc 0.8500 TestAcc 0.7995 0.8050
epoch 1600 LossPred 0.5045 LossAtt 0.1717 TrainAcc 0.8500 TestAcc 0.8041 0.8200
epoch 1700 LossPred 0.5131 LossAtt 0.1765 TrainAcc 0.8300 TestAcc 0.8028 0.8100
epoch 1800 LossPred 0.5324 LossAtt 0.1744 TrainAcc 0.8300 TestAcc 0.8038 0.8100
epoch 1900 LossPred 0.5033 LossAtt 0.1770 TrainAcc 0.8500 TestAcc 0.8126 0.8250
epoch 2000 LossPred 0.5418 LossAtt 0.1799 TrainAcc 0.8300 TestAcc 0.7943 0.8050
epoch 2100 LossPred 0.5176 LossAtt 0.1760 TrainAcc 0.8300 TestAcc 0.8088 0.8050
epoch 2200 LossPred 0.5093 LossAtt 0.1785 TrainAcc 0.8100 TestAcc 0.8091 0.8300
epoch 2300 LossPred 0.4889 LossAtt 0.1723 TrainAcc 0.8600 TestAcc 0.8091 0.8350
epoch 2400 LossPred 0.4934 LossAtt 0.1694 TrainAcc 0.8400 TestAcc 0.8088 0.8350
epoch 2500 LossPred 0.4725 LossAtt 0.1737 TrainAcc 0.8400 TestAcc 0.8166 0.8300
Optimization Finished!
********** replication  67  **********
epoch   0 LossPred 1.1117 LossAtt 1.0143 TrainAcc 0.5200 TestAcc 0.4730 0.4300
epoch 100 LossPred 0.9693 LossAtt 0.2340 TrainAcc 0.5800 TestAcc 0.5688 0.5800
epoch 200 LossPred 0.9325 LossAtt 0.2400 TrainAcc 0.6300 TestAcc 0.6081 0.6400
epoch 300 LossPred 0.6580 LossAtt 0.2596 TrainAcc 0.7700 TestAcc 0.8041 0.7350
epoch 400 LossPred 0.5632 LossAtt 0.2438 TrainAcc 0.8200 TestAcc 0.8478 0.8200
epoch 500 LossPred 0.4790 LossAtt 0.2376 TrainAcc 0.8600 TestAcc 0.8596 0.8050
epoch 600 LossPred 0.4730 LossAtt 0.2417 TrainAcc 0.8300 TestAcc 0.8453 0.8050
epoch 700 LossPred 0.5210 LossAtt 0.2419 TrainAcc 0.8200 TestAcc 0.8571 0.8350
epoch 800 LossPred 0.5095 LossAtt 0.2227 TrainAcc 0.8200 TestAcc 0.8401 0.8200
epoch 900 LossPred 0.5349 LossAtt 0.2266 TrainAcc 0.8300 TestAcc 0.8428 0.8200
epoch 1000 LossPred 0.6065 LossAtt 0.2304 TrainAcc 0.8100 TestAcc 0.8101 0.7850
epoch 1100 LossPred 0.5671 LossAtt 0.2287 TrainAcc 0.8300 TestAcc 0.8276 0.7950
epoch 1200 LossPred 0.5705 LossAtt 0.2230 TrainAcc 0.8300 TestAcc 0.8256 0.7850
epoch 1300 LossPred 0.6230 LossAtt 0.1935 TrainAcc 0.7800 TestAcc 0.7918 0.7500
epoch 1400 LossPred 0.5005 LossAtt 0.1904 TrainAcc 0.8200 TestAcc 0.8381 0.8100
epoch 1500 LossPred 0.5846 LossAtt 0.2106 TrainAcc 0.7800 TestAcc 0.8504 0.8200
epoch 1600 LossPred 0.4533 LossAtt 0.2019 TrainAcc 0.8400 TestAcc 0.8711 0.8200
epoch 1700 LossPred 0.4457 LossAtt 0.2060 TrainAcc 0.8600 TestAcc 0.8644 0.8050
epoch 1800 LossPred 0.5573 LossAtt 0.1959 TrainAcc 0.8500 TestAcc 0.8341 0.7900
epoch 1900 LossPred 0.6513 LossAtt 0.1953 TrainAcc 0.7800 TestAcc 0.7560 0.7650
epoch 2000 LossPred 0.4885 LossAtt 0.2052 TrainAcc 0.8100 TestAcc 0.8498 0.8050
epoch 2100 LossPred 0.4974 LossAtt 0.1917 TrainAcc 0.8100 TestAcc 0.8614 0.8000
epoch 2200 LossPred 0.4941 LossAtt 0.1898 TrainAcc 0.8400 TestAcc 0.8343 0.8000
epoch 2300 LossPred 0.4446 LossAtt 0.1804 TrainAcc 0.8400 TestAcc 0.8776 0.8150
epoch 2400 LossPred 0.5432 LossAtt 0.1790 TrainAcc 0.8200 TestAcc 0.8451 0.7800
epoch 2500 LossPred 0.5570 LossAtt 0.1669 TrainAcc 0.8100 TestAcc 0.8056 0.8000
Optimization Finished!
********** replication  68  **********
epoch   0 LossPred 0.9244 LossAtt 1.0194 TrainAcc 0.6300 TestAcc 0.5681 0.6300
epoch 100 LossPred 0.7480 LossAtt 0.2938 TrainAcc 0.7200 TestAcc 0.5886 0.7150
epoch 200 LossPred 0.6756 LossAtt 0.2627 TrainAcc 0.8000 TestAcc 0.6084 0.7800
epoch 300 LossPred 0.6149 LossAtt 0.2312 TrainAcc 0.8100 TestAcc 0.6349 0.7900
epoch 400 LossPred 0.3866 LossAtt 0.2006 TrainAcc 0.8700 TestAcc 0.8273 0.8050
epoch 500 LossPred 0.3756 LossAtt 0.1946 TrainAcc 0.8500 TestAcc 0.8206 0.8200
epoch 600 LossPred 0.3752 LossAtt 0.1975 TrainAcc 0.8400 TestAcc 0.8241 0.8250
epoch 700 LossPred 0.3521 LossAtt 0.1934 TrainAcc 0.8500 TestAcc 0.8226 0.8450
epoch 800 LossPred 0.3591 LossAtt 0.1881 TrainAcc 0.8400 TestAcc 0.8216 0.8300
epoch 900 LossPred 0.3432 LossAtt 0.1915 TrainAcc 0.8500 TestAcc 0.8238 0.8500
epoch 1000 LossPred 0.3406 LossAtt 0.2004 TrainAcc 0.8600 TestAcc 0.8183 0.8450
epoch 1100 LossPred 0.3463 LossAtt 0.1931 TrainAcc 0.8500 TestAcc 0.8136 0.8400
epoch 1200 LossPred 0.3780 LossAtt 0.2012 TrainAcc 0.8800 TestAcc 0.8001 0.8350
epoch 1300 LossPred 0.3519 LossAtt 0.2060 TrainAcc 0.8500 TestAcc 0.8201 0.8450
epoch 1400 LossPred 0.3375 LossAtt 0.1961 TrainAcc 0.8500 TestAcc 0.8223 0.8450
epoch 1500 LossPred 0.3387 LossAtt 0.1852 TrainAcc 0.8700 TestAcc 0.8178 0.8350
epoch 1600 LossPred 0.3369 LossAtt 0.1869 TrainAcc 0.8500 TestAcc 0.8118 0.8400
epoch 1700 LossPred 0.3394 LossAtt 0.1823 TrainAcc 0.8700 TestAcc 0.8068 0.8200
epoch 1800 LossPred 0.3871 LossAtt 0.1818 TrainAcc 0.8500 TestAcc 0.7858 0.8150
epoch 1900 LossPred 0.3294 LossAtt 0.1820 TrainAcc 0.8700 TestAcc 0.8083 0.8400
epoch 2000 LossPred 0.3400 LossAtt 0.1888 TrainAcc 0.8500 TestAcc 0.8126 0.8400
epoch 2100 LossPred 0.3548 LossAtt 0.1735 TrainAcc 0.8500 TestAcc 0.8036 0.8350
epoch 2200 LossPred 0.3260 LossAtt 0.1899 TrainAcc 0.8700 TestAcc 0.8121 0.8350
epoch 2300 LossPred 0.3440 LossAtt 0.1846 TrainAcc 0.8500 TestAcc 0.8173 0.8550
epoch 2400 LossPred 0.3318 LossAtt 0.1824 TrainAcc 0.8500 TestAcc 0.8188 0.8450
epoch 2500 LossPred 0.3255 LossAtt 0.1970 TrainAcc 0.8700 TestAcc 0.8186 0.8600
Optimization Finished!
********** replication  69  **********
epoch   0 LossPred 1.0414 LossAtt 1.0046 TrainAcc 0.4600 TestAcc 0.4717 0.4450
epoch 100 LossPred 0.8943 LossAtt 0.2643 TrainAcc 0.6300 TestAcc 0.6124 0.6400
epoch 200 LossPred 0.8943 LossAtt 0.2154 TrainAcc 0.7100 TestAcc 0.6532 0.7000
epoch 300 LossPred 0.3691 LossAtt 0.2222 TrainAcc 0.8800 TestAcc 0.8108 0.8700
epoch 400 LossPred 0.3567 LossAtt 0.2100 TrainAcc 0.8800 TestAcc 0.8136 0.8600
epoch 500 LossPred 0.3369 LossAtt 0.1981 TrainAcc 0.8800 TestAcc 0.8041 0.8650
epoch 600 LossPred 0.3376 LossAtt 0.2023 TrainAcc 0.8800 TestAcc 0.8028 0.8550
epoch 700 LossPred 0.3694 LossAtt 0.2093 TrainAcc 0.8700 TestAcc 0.7975 0.8650
epoch 800 LossPred 0.3433 LossAtt 0.2011 TrainAcc 0.8700 TestAcc 0.7990 0.8550
epoch 900 LossPred 0.3546 LossAtt 0.1818 TrainAcc 0.8800 TestAcc 0.8008 0.8600
epoch 1000 LossPred 0.3877 LossAtt 0.1906 TrainAcc 0.8700 TestAcc 0.7940 0.8850
epoch 1100 LossPred 0.3538 LossAtt 0.1962 TrainAcc 0.8700 TestAcc 0.8013 0.8600
epoch 1200 LossPred 0.3186 LossAtt 0.1961 TrainAcc 0.8800 TestAcc 0.7998 0.8600
epoch 1300 LossPred 0.3765 LossAtt 0.2072 TrainAcc 0.8700 TestAcc 0.7943 0.8800
epoch 1400 LossPred 0.3073 LossAtt 0.1988 TrainAcc 0.8900 TestAcc 0.8171 0.8700
epoch 1500 LossPred 0.3180 LossAtt 0.2082 TrainAcc 0.8900 TestAcc 0.8041 0.8750
epoch 1600 LossPred 1.2500 LossAtt 0.1961 TrainAcc 0.5900 TestAcc 0.5511 0.5750
epoch 1700 LossPred 0.8265 LossAtt 0.1685 TrainAcc 0.7000 TestAcc 0.6264 0.6950
epoch 1800 LossPred 0.7953 LossAtt 0.1763 TrainAcc 0.7000 TestAcc 0.6154 0.7000
epoch 1900 LossPred 0.7854 LossAtt 0.1736 TrainAcc 0.7000 TestAcc 0.6139 0.7000
epoch 2000 LossPred 0.7977 LossAtt 0.1706 TrainAcc 0.6900 TestAcc 0.6106 0.6950
epoch 2100 LossPred 0.7848 LossAtt 0.1710 TrainAcc 0.6900 TestAcc 0.6296 0.7000
epoch 2200 LossPred 0.7756 LossAtt 0.1624 TrainAcc 0.7000 TestAcc 0.6181 0.6950
epoch 2300 LossPred 0.6561 LossAtt 0.1674 TrainAcc 0.7400 TestAcc 0.7080 0.7400
epoch 2400 LossPred 0.5547 LossAtt 0.1721 TrainAcc 0.7900 TestAcc 0.7450 0.8000
epoch 2500 LossPred 0.6325 LossAtt 0.1572 TrainAcc 0.7400 TestAcc 0.7132 0.7550
Optimization Finished!
********** replication  70  **********
epoch   0 LossPred 1.1069 LossAtt 0.9794 TrainAcc 0.4000 TestAcc 0.4467 0.4100
epoch 100 LossPred 0.8999 LossAtt 0.3047 TrainAcc 0.6400 TestAcc 0.5756 0.6300
epoch 200 LossPred 0.8861 LossAtt 0.2645 TrainAcc 0.6400 TestAcc 0.5756 0.6350
epoch 300 LossPred 0.6877 LossAtt 0.3875 TrainAcc 0.7700 TestAcc 0.7472 0.7750
epoch 400 LossPred 0.4460 LossAtt 0.3950 TrainAcc 0.8400 TestAcc 0.7928 0.8150
epoch 500 LossPred 0.2544 LossAtt 0.3737 TrainAcc 0.9300 TestAcc 0.8726 0.8950
epoch 600 LossPred 0.3588 LossAtt 0.3497 TrainAcc 0.8800 TestAcc 0.8373 0.8450
epoch 700 LossPred 0.1917 LossAtt 0.3500 TrainAcc 0.9400 TestAcc 0.8611 0.9050
epoch 800 LossPred 0.1371 LossAtt 0.3354 TrainAcc 0.9600 TestAcc 0.8774 0.9400
epoch 900 LossPred 0.1240 LossAtt 0.3317 TrainAcc 0.9800 TestAcc 0.8691 0.9400
epoch 1000 LossPred 0.1185 LossAtt 0.3202 TrainAcc 0.9600 TestAcc 0.8724 0.9600
epoch 1100 LossPred 0.2204 LossAtt 0.3150 TrainAcc 0.9300 TestAcc 0.8639 0.9250
epoch 1200 LossPred 0.1049 LossAtt 0.2993 TrainAcc 0.9800 TestAcc 0.8724 0.9700
epoch 1300 LossPred 0.2564 LossAtt 0.3029 TrainAcc 0.9300 TestAcc 0.8529 0.9150
epoch 1400 LossPred 0.1587 LossAtt 0.3121 TrainAcc 0.9400 TestAcc 0.8551 0.9450
epoch 1500 LossPred 0.1786 LossAtt 0.2868 TrainAcc 0.9500 TestAcc 0.8504 0.9300
epoch 1600 LossPred 0.2136 LossAtt 0.2904 TrainAcc 0.9300 TestAcc 0.8398 0.9200
epoch 1700 LossPred 0.1760 LossAtt 0.2929 TrainAcc 0.9400 TestAcc 0.8509 0.9450
epoch 1800 LossPred 0.2730 LossAtt 0.2849 TrainAcc 0.9100 TestAcc 0.8296 0.9150
epoch 1900 LossPred 0.3067 LossAtt 0.2798 TrainAcc 0.9000 TestAcc 0.8341 0.8900
epoch 2000 LossPred 0.3057 LossAtt 0.2792 TrainAcc 0.9200 TestAcc 0.8436 0.9100
epoch 2100 LossPred 0.1664 LossAtt 0.2705 TrainAcc 0.9600 TestAcc 0.8516 0.9550
epoch 2200 LossPred 0.1498 LossAtt 0.2716 TrainAcc 0.9600 TestAcc 0.8569 0.9450
epoch 2300 LossPred 0.1153 LossAtt 0.2686 TrainAcc 0.9800 TestAcc 0.8546 0.9650
epoch 2400 LossPred 0.1501 LossAtt 0.2665 TrainAcc 0.9700 TestAcc 0.8448 0.9600
epoch 2500 LossPred 0.1472 LossAtt 0.2653 TrainAcc 0.9700 TestAcc 0.8509 0.9600
Optimization Finished!
********** replication  71  **********
epoch   0 LossPred 1.1030 LossAtt 0.9891 TrainAcc 0.4300 TestAcc 0.5145 0.4550
epoch 100 LossPred 0.9493 LossAtt 0.2362 TrainAcc 0.6200 TestAcc 0.5260 0.5950
epoch 200 LossPred 0.8091 LossAtt 0.2254 TrainAcc 0.6500 TestAcc 0.5838 0.6600
epoch 300 LossPred 0.7200 LossAtt 0.2132 TrainAcc 0.7800 TestAcc 0.7315 0.7750
epoch 400 LossPred 0.6745 LossAtt 0.2037 TrainAcc 0.7800 TestAcc 0.7107 0.7750
epoch 500 LossPred 0.7289 LossAtt 0.1761 TrainAcc 0.7300 TestAcc 0.6406 0.7500
epoch 600 LossPred 0.7107 LossAtt 0.1680 TrainAcc 0.7600 TestAcc 0.6559 0.7650
epoch 700 LossPred 0.9625 LossAtt 0.1552 TrainAcc 0.6100 TestAcc 0.5536 0.6300
epoch 800 LossPred 0.6334 LossAtt 0.1582 TrainAcc 0.8000 TestAcc 0.6997 0.7900
epoch 900 LossPred 0.6689 LossAtt 0.1514 TrainAcc 0.7800 TestAcc 0.7035 0.7950
epoch 1000 LossPred 0.6389 LossAtt 0.1493 TrainAcc 0.7800 TestAcc 0.6709 0.8050
epoch 1100 LossPred 0.7170 LossAtt 0.1413 TrainAcc 0.7400 TestAcc 0.6627 0.7350
epoch 1200 LossPred 0.7753 LossAtt 0.1707 TrainAcc 0.7100 TestAcc 0.6304 0.7200
epoch 1300 LossPred 0.7219 LossAtt 0.1591 TrainAcc 0.7100 TestAcc 0.6401 0.7150
epoch 1400 LossPred 0.6987 LossAtt 0.1562 TrainAcc 0.7600 TestAcc 0.6496 0.7400
epoch 1500 LossPred 0.7390 LossAtt 0.1363 TrainAcc 0.7300 TestAcc 0.6689 0.7350
epoch 1600 LossPred 0.7411 LossAtt 0.1412 TrainAcc 0.7200 TestAcc 0.6684 0.7350
epoch 1700 LossPred 0.7235 LossAtt 0.1343 TrainAcc 0.7300 TestAcc 0.6624 0.7350
epoch 1800 LossPred 0.8342 LossAtt 0.1336 TrainAcc 0.6700 TestAcc 0.6829 0.6700
epoch 1900 LossPred 0.8184 LossAtt 0.1307 TrainAcc 0.6700 TestAcc 0.6702 0.6700
epoch 2000 LossPred 0.8123 LossAtt 0.1380 TrainAcc 0.6700 TestAcc 0.6729 0.6700
epoch 2100 LossPred 0.8066 LossAtt 0.1388 TrainAcc 0.6700 TestAcc 0.6732 0.6700
epoch 2200 LossPred 0.7948 LossAtt 0.1303 TrainAcc 0.6700 TestAcc 0.6824 0.6750
epoch 2300 LossPred 0.7496 LossAtt 0.1299 TrainAcc 0.7100 TestAcc 0.6867 0.6900
epoch 2400 LossPred 0.7620 LossAtt 0.1256 TrainAcc 0.7300 TestAcc 0.6439 0.7500
epoch 2500 LossPred 0.7430 LossAtt 0.1183 TrainAcc 0.7300 TestAcc 0.6441 0.7500
Optimization Finished!
********** replication  72  **********
epoch   0 LossPred 1.2299 LossAtt 1.0333 TrainAcc 0.3100 TestAcc 0.4274 0.3600
epoch 100 LossPred 0.8608 LossAtt 0.2774 TrainAcc 0.6900 TestAcc 0.5726 0.6900
epoch 200 LossPred 0.7510 LossAtt 0.2742 TrainAcc 0.7100 TestAcc 0.6246 0.7350
epoch 300 LossPred 0.4767 LossAtt 0.2483 TrainAcc 0.8300 TestAcc 0.8031 0.8200
epoch 400 LossPred 0.3762 LossAtt 0.2459 TrainAcc 0.8700 TestAcc 0.8328 0.8550
epoch 500 LossPred 0.3492 LossAtt 0.2319 TrainAcc 0.8800 TestAcc 0.8371 0.8650
epoch 600 LossPred 0.2978 LossAtt 0.2321 TrainAcc 0.9100 TestAcc 0.8521 0.8700
epoch 700 LossPred 0.2837 LossAtt 0.2226 TrainAcc 0.9000 TestAcc 0.8514 0.8700
epoch 800 LossPred 0.2614 LossAtt 0.2323 TrainAcc 0.9200 TestAcc 0.8561 0.8900
epoch 900 LossPred 0.2516 LossAtt 0.2269 TrainAcc 0.9200 TestAcc 0.8556 0.8750
epoch 1000 LossPred 0.2419 LossAtt 0.2105 TrainAcc 0.9200 TestAcc 0.8594 0.8950
epoch 1100 LossPred 0.2347 LossAtt 0.2095 TrainAcc 0.9300 TestAcc 0.8656 0.8800
epoch 1200 LossPred 0.2373 LossAtt 0.2054 TrainAcc 0.9300 TestAcc 0.8664 0.8850
epoch 1300 LossPred 0.2065 LossAtt 0.1906 TrainAcc 0.9400 TestAcc 0.8749 0.8750
epoch 1400 LossPred 0.1945 LossAtt 0.2049 TrainAcc 0.9600 TestAcc 0.8791 0.9050
epoch 1500 LossPred 0.1768 LossAtt 0.1919 TrainAcc 0.9500 TestAcc 0.8779 0.9050
epoch 1600 LossPred 0.1680 LossAtt 0.2015 TrainAcc 0.9500 TestAcc 0.8866 0.9100
epoch 1700 LossPred 0.1833 LossAtt 0.1872 TrainAcc 0.9500 TestAcc 0.8731 0.8900
epoch 1800 LossPred 0.2370 LossAtt 0.1908 TrainAcc 0.9200 TestAcc 0.8756 0.8800
epoch 1900 LossPred 0.1707 LossAtt 0.1857 TrainAcc 0.9500 TestAcc 0.8844 0.9200
epoch 2000 LossPred 0.1537 LossAtt 0.1703 TrainAcc 0.9600 TestAcc 0.8891 0.9100
epoch 2100 LossPred 0.1426 LossAtt 0.1786 TrainAcc 0.9600 TestAcc 0.8894 0.9350
epoch 2200 LossPred 0.1835 LossAtt 0.1691 TrainAcc 0.9400 TestAcc 0.8909 0.9250
epoch 2300 LossPred 0.1484 LossAtt 0.1765 TrainAcc 0.9600 TestAcc 0.8909 0.9250
epoch 2400 LossPred 0.1675 LossAtt 0.1729 TrainAcc 0.9400 TestAcc 0.8984 0.9200
epoch 2500 LossPred 0.2411 LossAtt 0.1765 TrainAcc 0.9200 TestAcc 0.8729 0.8800
Optimization Finished!
********** replication  73  **********
epoch   0 LossPred 0.9869 LossAtt 1.0272 TrainAcc 0.5800 TestAcc 0.5831 0.5850
epoch 100 LossPred 0.8719 LossAtt 0.2674 TrainAcc 0.6700 TestAcc 0.5168 0.6650
epoch 200 LossPred 0.8541 LossAtt 0.2419 TrainAcc 0.6700 TestAcc 0.5168 0.6800
epoch 300 LossPred 0.7951 LossAtt 0.2840 TrainAcc 0.7100 TestAcc 0.5253 0.7050
epoch 400 LossPred 0.7715 LossAtt 0.2937 TrainAcc 0.7300 TestAcc 0.5353 0.7300
epoch 500 LossPred 0.7614 LossAtt 0.2798 TrainAcc 0.7200 TestAcc 0.5308 0.7200
epoch 600 LossPred 0.7519 LossAtt 0.2800 TrainAcc 0.7200 TestAcc 0.5323 0.7150
epoch 700 LossPred 0.7434 LossAtt 0.2774 TrainAcc 0.7200 TestAcc 0.5300 0.7200
epoch 800 LossPred 0.7328 LossAtt 0.2633 TrainAcc 0.7400 TestAcc 0.5225 0.7100
epoch 900 LossPred 0.7257 LossAtt 0.2644 TrainAcc 0.7300 TestAcc 0.5235 0.7050
epoch 1000 LossPred 0.7242 LossAtt 0.2539 TrainAcc 0.7300 TestAcc 0.5250 0.7150
epoch 1100 LossPred 0.7134 LossAtt 0.2547 TrainAcc 0.7500 TestAcc 0.5165 0.7100
epoch 1200 LossPred 0.7093 LossAtt 0.2618 TrainAcc 0.7500 TestAcc 0.5143 0.7100
epoch 1300 LossPred 0.7367 LossAtt 0.2301 TrainAcc 0.7100 TestAcc 0.5213 0.7200
epoch 1400 LossPred 0.7188 LossAtt 0.2263 TrainAcc 0.7400 TestAcc 0.5430 0.7350
epoch 1500 LossPred 0.6917 LossAtt 0.2403 TrainAcc 0.7700 TestAcc 0.5370 0.7300
epoch 1600 LossPred 0.6880 LossAtt 0.2491 TrainAcc 0.7600 TestAcc 0.5338 0.7250
epoch 1700 LossPred 0.6873 LossAtt 0.2583 TrainAcc 0.7400 TestAcc 0.5320 0.7350
epoch 1800 LossPred 0.6817 LossAtt 0.2368 TrainAcc 0.7700 TestAcc 0.5238 0.7200
epoch 1900 LossPred 0.7070 LossAtt 0.2246 TrainAcc 0.7500 TestAcc 0.5323 0.7400
epoch 2000 LossPred 0.6853 LossAtt 0.2236 TrainAcc 0.7700 TestAcc 0.5203 0.7350
epoch 2100 LossPred 0.7052 LossAtt 0.1983 TrainAcc 0.7500 TestAcc 0.5170 0.7350
epoch 2200 LossPred 0.6680 LossAtt 0.2181 TrainAcc 0.7800 TestAcc 0.5205 0.7250
epoch 2300 LossPred 0.7045 LossAtt 0.2072 TrainAcc 0.7400 TestAcc 0.5190 0.7200
epoch 2400 LossPred 0.6544 LossAtt 0.2217 TrainAcc 0.7700 TestAcc 0.5278 0.7200
epoch 2500 LossPred 0.6371 LossAtt 0.2352 TrainAcc 0.7900 TestAcc 0.5343 0.7450
Optimization Finished!
********** replication  74  **********
epoch   0 LossPred 1.0581 LossAtt 1.0415 TrainAcc 0.5300 TestAcc 0.5488 0.5500
epoch 100 LossPred 0.9457 LossAtt 0.2771 TrainAcc 0.6000 TestAcc 0.5553 0.6000
epoch 200 LossPred 0.9292 LossAtt 0.2634 TrainAcc 0.6000 TestAcc 0.5506 0.5900
epoch 300 LossPred 0.8889 LossAtt 0.2603 TrainAcc 0.6500 TestAcc 0.5576 0.6100
epoch 400 LossPred 0.8696 LossAtt 0.2585 TrainAcc 0.6700 TestAcc 0.5458 0.6650
epoch 500 LossPred 0.8173 LossAtt 0.2580 TrainAcc 0.6800 TestAcc 0.5395 0.6550
epoch 600 LossPred 0.7916 LossAtt 0.2643 TrainAcc 0.6900 TestAcc 0.5460 0.6650
epoch 700 LossPred 0.7729 LossAtt 0.2493 TrainAcc 0.6900 TestAcc 0.5493 0.6800
epoch 800 LossPred 0.7470 LossAtt 0.2455 TrainAcc 0.6700 TestAcc 0.5613 0.6750
epoch 900 LossPred 0.7272 LossAtt 0.2604 TrainAcc 0.7000 TestAcc 0.5448 0.6800
epoch 1000 LossPred 0.7278 LossAtt 0.2732 TrainAcc 0.6900 TestAcc 0.5508 0.6900
epoch 1100 LossPred 0.7183 LossAtt 0.2834 TrainAcc 0.6800 TestAcc 0.5571 0.6900
epoch 1200 LossPred 0.6962 LossAtt 0.2830 TrainAcc 0.7100 TestAcc 0.5616 0.6850
epoch 1300 LossPred 0.7089 LossAtt 0.2809 TrainAcc 0.7200 TestAcc 0.5603 0.7150
epoch 1400 LossPred 0.7069 LossAtt 0.2714 TrainAcc 0.7300 TestAcc 0.5618 0.7050
epoch 1500 LossPred 0.7098 LossAtt 0.2745 TrainAcc 0.7100 TestAcc 0.5551 0.7100
epoch 1600 LossPred 0.7055 LossAtt 0.2778 TrainAcc 0.7000 TestAcc 0.5498 0.6850
epoch 1700 LossPred 0.7201 LossAtt 0.2619 TrainAcc 0.7000 TestAcc 0.5598 0.7050
epoch 1800 LossPred 0.6773 LossAtt 0.2707 TrainAcc 0.7000 TestAcc 0.5648 0.7100
epoch 1900 LossPred 0.6705 LossAtt 0.2538 TrainAcc 0.7300 TestAcc 0.5668 0.7000
epoch 2000 LossPred 0.7514 LossAtt 0.2698 TrainAcc 0.6900 TestAcc 0.5636 0.6850
epoch 2100 LossPred 0.6935 LossAtt 0.2412 TrainAcc 0.7400 TestAcc 0.5666 0.7000
epoch 2200 LossPred 0.6998 LossAtt 0.2356 TrainAcc 0.7400 TestAcc 0.5653 0.7250
epoch 2300 LossPred 0.8192 LossAtt 0.2306 TrainAcc 0.6600 TestAcc 0.5696 0.6750
epoch 2400 LossPred 0.7958 LossAtt 0.2251 TrainAcc 0.7000 TestAcc 0.5748 0.7100
epoch 2500 LossPred 0.7843 LossAtt 0.2215 TrainAcc 0.7100 TestAcc 0.5756 0.7250
Optimization Finished!
********** replication  75  **********
epoch   0 LossPred 0.9771 LossAtt 1.0177 TrainAcc 0.5600 TestAcc 0.5230 0.5550
epoch 100 LossPred 0.8622 LossAtt 0.3022 TrainAcc 0.6600 TestAcc 0.5485 0.6550
epoch 200 LossPred 0.7959 LossAtt 0.3514 TrainAcc 0.7000 TestAcc 0.5573 0.6900
epoch 300 LossPred 0.7322 LossAtt 0.4080 TrainAcc 0.7300 TestAcc 0.5518 0.7350
epoch 400 LossPred 0.6544 LossAtt 0.4405 TrainAcc 0.7800 TestAcc 0.5988 0.7400
epoch 500 LossPred 0.5794 LossAtt 0.4332 TrainAcc 0.8000 TestAcc 0.6059 0.7750
epoch 600 LossPred 0.5540 LossAtt 0.4177 TrainAcc 0.8100 TestAcc 0.6139 0.7550
epoch 700 LossPred 0.5137 LossAtt 0.4082 TrainAcc 0.8400 TestAcc 0.6121 0.7800
epoch 800 LossPred 0.4898 LossAtt 0.4024 TrainAcc 0.8300 TestAcc 0.6081 0.7850
epoch 900 LossPred 0.4798 LossAtt 0.3995 TrainAcc 0.8500 TestAcc 0.6154 0.7850
epoch 1000 LossPred 0.4579 LossAtt 0.4054 TrainAcc 0.8500 TestAcc 0.6166 0.8100
epoch 1100 LossPred 0.4324 LossAtt 0.4204 TrainAcc 0.8600 TestAcc 0.6109 0.8200
epoch 1200 LossPred 0.4016 LossAtt 0.4091 TrainAcc 0.8800 TestAcc 0.6089 0.8250
epoch 1300 LossPred 0.4253 LossAtt 0.4162 TrainAcc 0.8900 TestAcc 0.6244 0.8100
epoch 1400 LossPred 0.4777 LossAtt 0.4220 TrainAcc 0.8600 TestAcc 0.6251 0.8000
epoch 1500 LossPred 0.3738 LossAtt 0.4197 TrainAcc 0.8800 TestAcc 0.6224 0.8200
epoch 1600 LossPred 0.3811 LossAtt 0.4179 TrainAcc 0.8900 TestAcc 0.6229 0.8150
epoch 1700 LossPred 0.3829 LossAtt 0.4081 TrainAcc 0.8900 TestAcc 0.6151 0.8350
epoch 1800 LossPred 0.3338 LossAtt 0.4089 TrainAcc 0.9100 TestAcc 0.6206 0.8300
epoch 1900 LossPred 0.3463 LossAtt 0.3985 TrainAcc 0.8900 TestAcc 0.6231 0.8250
epoch 2000 LossPred 0.3685 LossAtt 0.4083 TrainAcc 0.9000 TestAcc 0.6174 0.7950
epoch 2100 LossPred 0.3254 LossAtt 0.4024 TrainAcc 0.9100 TestAcc 0.6181 0.8300
epoch 2200 LossPred 0.3080 LossAtt 0.4183 TrainAcc 0.8800 TestAcc 0.6144 0.8350
epoch 2300 LossPred 0.5611 LossAtt 0.4147 TrainAcc 0.8300 TestAcc 0.6289 0.7800
epoch 2400 LossPred 0.3666 LossAtt 0.3902 TrainAcc 0.8900 TestAcc 0.6186 0.8600
epoch 2500 LossPred 0.3324 LossAtt 0.3991 TrainAcc 0.9000 TestAcc 0.6146 0.8600
Optimization Finished!
********** replication  76  **********
epoch   0 LossPred 1.3368 LossAtt 1.0505 TrainAcc 0.4200 TestAcc 0.4239 0.5000
epoch 100 LossPred 0.9080 LossAtt 0.3110 TrainAcc 0.6200 TestAcc 0.5883 0.6150
epoch 200 LossPred 0.8727 LossAtt 0.2082 TrainAcc 0.6200 TestAcc 0.5883 0.6200
epoch 300 LossPred 0.6529 LossAtt 0.3053 TrainAcc 0.7500 TestAcc 0.8146 0.7650
epoch 400 LossPred 0.4480 LossAtt 0.2656 TrainAcc 0.8700 TestAcc 0.8248 0.8050
epoch 500 LossPred 0.4388 LossAtt 0.2546 TrainAcc 0.8500 TestAcc 0.8386 0.8400
epoch 600 LossPred 0.3739 LossAtt 0.2441 TrainAcc 0.8900 TestAcc 0.8453 0.8400
epoch 700 LossPred 0.5595 LossAtt 0.2361 TrainAcc 0.8100 TestAcc 0.7935 0.8000
epoch 800 LossPred 0.5704 LossAtt 0.2435 TrainAcc 0.8000 TestAcc 0.8038 0.7950
epoch 900 LossPred 0.4793 LossAtt 0.2416 TrainAcc 0.8300 TestAcc 0.8213 0.8350
epoch 1000 LossPred 0.3692 LossAtt 0.2344 TrainAcc 0.8700 TestAcc 0.8401 0.8500
epoch 1100 LossPred 0.5876 LossAtt 0.2309 TrainAcc 0.7700 TestAcc 0.7868 0.7650
epoch 1200 LossPred 0.5051 LossAtt 0.2397 TrainAcc 0.8100 TestAcc 0.8176 0.8200
epoch 1300 LossPred 0.4860 LossAtt 0.2382 TrainAcc 0.8600 TestAcc 0.8193 0.8250
epoch 1400 LossPred 0.4278 LossAtt 0.2253 TrainAcc 0.8600 TestAcc 0.8426 0.8250
epoch 1500 LossPred 0.3453 LossAtt 0.2318 TrainAcc 0.9100 TestAcc 0.8391 0.8950
epoch 1600 LossPred 0.3869 LossAtt 0.2261 TrainAcc 0.8600 TestAcc 0.8368 0.8650
epoch 1700 LossPred 0.4876 LossAtt 0.2231 TrainAcc 0.8200 TestAcc 0.8191 0.8150
epoch 1800 LossPred 0.5270 LossAtt 0.2391 TrainAcc 0.8300 TestAcc 0.8066 0.8150
epoch 1900 LossPred 0.4376 LossAtt 0.2416 TrainAcc 0.8400 TestAcc 0.8303 0.8350
epoch 2000 LossPred 0.4295 LossAtt 0.2599 TrainAcc 0.8400 TestAcc 0.8318 0.8550
epoch 2100 LossPred 0.3280 LossAtt 0.2738 TrainAcc 0.9100 TestAcc 0.8366 0.8600
epoch 2200 LossPred 0.3417 LossAtt 0.2665 TrainAcc 0.8900 TestAcc 0.8436 0.8800
epoch 2300 LossPred 0.3469 LossAtt 0.2605 TrainAcc 0.8800 TestAcc 0.8328 0.8700
epoch 2400 LossPred 0.2789 LossAtt 0.2736 TrainAcc 0.9300 TestAcc 0.8491 0.9000
epoch 2500 LossPred 0.3065 LossAtt 0.2509 TrainAcc 0.9000 TestAcc 0.8338 0.9000
Optimization Finished!
********** replication  77  **********
epoch   0 LossPred 0.9920 LossAtt 1.0246 TrainAcc 0.5400 TestAcc 0.5063 0.5400
epoch 100 LossPred 0.8533 LossAtt 0.2608 TrainAcc 0.6600 TestAcc 0.5803 0.6750
epoch 200 LossPred 0.4472 LossAtt 0.2814 TrainAcc 0.8800 TestAcc 0.8193 0.8850
epoch 300 LossPred 0.4004 LossAtt 0.2577 TrainAcc 0.8800 TestAcc 0.8341 0.8700
epoch 400 LossPred 0.3418 LossAtt 0.2503 TrainAcc 0.9000 TestAcc 0.8483 0.8850
epoch 500 LossPred 0.4269 LossAtt 0.2418 TrainAcc 0.8700 TestAcc 0.8361 0.8700
epoch 600 LossPred 0.3490 LossAtt 0.2369 TrainAcc 0.8900 TestAcc 0.8566 0.8950
epoch 700 LossPred 0.3530 LossAtt 0.2312 TrainAcc 0.8900 TestAcc 0.8589 0.8900
epoch 800 LossPred 0.3773 LossAtt 0.2213 TrainAcc 0.8800 TestAcc 0.8501 0.8900
epoch 900 LossPred 0.3629 LossAtt 0.2197 TrainAcc 0.8800 TestAcc 0.8521 0.8900
epoch 1000 LossPred 0.3160 LossAtt 0.2055 TrainAcc 0.8900 TestAcc 0.8453 0.8750
epoch 1100 LossPred 0.3234 LossAtt 0.1950 TrainAcc 0.8800 TestAcc 0.8406 0.8800
epoch 1200 LossPred 0.4472 LossAtt 0.1987 TrainAcc 0.8500 TestAcc 0.8281 0.8650
epoch 1300 LossPred 0.3488 LossAtt 0.1958 TrainAcc 0.8900 TestAcc 0.8356 0.9000
epoch 1400 LossPred 0.3802 LossAtt 0.1902 TrainAcc 0.8800 TestAcc 0.8273 0.8800
epoch 1500 LossPred 0.3365 LossAtt 0.1893 TrainAcc 0.8900 TestAcc 0.8121 0.8600
epoch 1600 LossPred 0.4772 LossAtt 0.1796 TrainAcc 0.8500 TestAcc 0.8103 0.8700
epoch 1700 LossPred 0.3629 LossAtt 0.1721 TrainAcc 0.8900 TestAcc 0.8301 0.8850
epoch 1800 LossPred 0.5576 LossAtt 0.1749 TrainAcc 0.8000 TestAcc 0.7830 0.8050
epoch 1900 LossPred 0.4743 LossAtt 0.1848 TrainAcc 0.8300 TestAcc 0.8036 0.8500
epoch 2000 LossPred 0.5242 LossAtt 0.1716 TrainAcc 0.7900 TestAcc 0.7808 0.8100
epoch 2100 LossPred 0.3462 LossAtt 0.1748 TrainAcc 0.9000 TestAcc 0.8238 0.8850
epoch 2200 LossPred 0.3496 LossAtt 0.1666 TrainAcc 0.8900 TestAcc 0.8221 0.8900
epoch 2300 LossPred 0.4954 LossAtt 0.1742 TrainAcc 0.8300 TestAcc 0.8136 0.8550
epoch 2400 LossPred 0.5172 LossAtt 0.1799 TrainAcc 0.8400 TestAcc 0.7628 0.8500
epoch 2500 LossPred 0.3961 LossAtt 0.1706 TrainAcc 0.8800 TestAcc 0.8056 0.8650
Optimization Finished!
********** replication  78  **********
epoch   0 LossPred 1.0019 LossAtt 1.0067 TrainAcc 0.5700 TestAcc 0.5078 0.5850
epoch 100 LossPred 0.9059 LossAtt 0.2320 TrainAcc 0.6400 TestAcc 0.5828 0.6550
epoch 200 LossPred 0.8949 LossAtt 0.2069 TrainAcc 0.6400 TestAcc 0.5828 0.6600
epoch 300 LossPred 0.6426 LossAtt 0.1566 TrainAcc 0.7600 TestAcc 0.7698 0.8100
epoch 400 LossPred 0.5388 LossAtt 0.1418 TrainAcc 0.7900 TestAcc 0.8101 0.7900
epoch 500 LossPred 0.7503 LossAtt 0.1450 TrainAcc 0.7200 TestAcc 0.7678 0.7050
epoch 600 LossPred 0.5288 LossAtt 0.1459 TrainAcc 0.8000 TestAcc 0.8138 0.7950
epoch 700 LossPred 0.6190 LossAtt 0.1496 TrainAcc 0.7500 TestAcc 0.8138 0.7750
epoch 800 LossPred 0.6063 LossAtt 0.1534 TrainAcc 0.7700 TestAcc 0.7998 0.8000
epoch 900 LossPred 0.5571 LossAtt 0.1433 TrainAcc 0.8100 TestAcc 0.7808 0.8200
epoch 1000 LossPred 0.5034 LossAtt 0.1373 TrainAcc 0.8200 TestAcc 0.7965 0.8200
epoch 1100 LossPred 0.6536 LossAtt 0.1318 TrainAcc 0.7600 TestAcc 0.7492 0.8000
epoch 1200 LossPred 0.5500 LossAtt 0.1433 TrainAcc 0.8100 TestAcc 0.7748 0.8250
epoch 1300 LossPred 0.7785 LossAtt 0.1626 TrainAcc 0.7100 TestAcc 0.7045 0.6950
epoch 1400 LossPred 0.7484 LossAtt 0.1495 TrainAcc 0.7200 TestAcc 0.7137 0.7150
epoch 1500 LossPred 0.5997 LossAtt 0.1451 TrainAcc 0.7600 TestAcc 0.7765 0.7850
epoch 1600 LossPred 0.5315 LossAtt 0.1404 TrainAcc 0.8300 TestAcc 0.7845 0.8550
epoch 1700 LossPred 0.5215 LossAtt 0.1260 TrainAcc 0.8200 TestAcc 0.7820 0.8350
epoch 1800 LossPred 0.5147 LossAtt 0.1415 TrainAcc 0.8500 TestAcc 0.7943 0.8450
epoch 1900 LossPred 0.6175 LossAtt 0.1444 TrainAcc 0.7500 TestAcc 0.7773 0.8050
epoch 2000 LossPred 0.5145 LossAtt 0.1331 TrainAcc 0.8200 TestAcc 0.7860 0.8450
epoch 2100 LossPred 0.5714 LossAtt 0.1379 TrainAcc 0.8000 TestAcc 0.7688 0.8400
epoch 2200 LossPred 0.5011 LossAtt 0.1424 TrainAcc 0.8300 TestAcc 0.7875 0.8400
epoch 2300 LossPred 0.6931 LossAtt 0.1447 TrainAcc 0.7600 TestAcc 0.7638 0.7500
epoch 2400 LossPred 0.5845 LossAtt 0.1336 TrainAcc 0.8100 TestAcc 0.7665 0.8300
epoch 2500 LossPred 0.6018 LossAtt 0.1470 TrainAcc 0.7500 TestAcc 0.7740 0.7750
Optimization Finished!
********** replication  79  **********
epoch   0 LossPred 1.2506 LossAtt 1.0194 TrainAcc 0.4400 TestAcc 0.4107 0.4100
epoch 100 LossPred 0.9262 LossAtt 0.2906 TrainAcc 0.6400 TestAcc 0.6074 0.6050
epoch 200 LossPred 0.7214 LossAtt 0.3650 TrainAcc 0.7900 TestAcc 0.7580 0.7600
epoch 300 LossPred 0.5087 LossAtt 0.3701 TrainAcc 0.8300 TestAcc 0.8418 0.8000
epoch 400 LossPred 0.4458 LossAtt 0.3418 TrainAcc 0.8300 TestAcc 0.8233 0.7850
epoch 500 LossPred 0.4681 LossAtt 0.3411 TrainAcc 0.8400 TestAcc 0.8136 0.8300
epoch 600 LossPred 0.3900 LossAtt 0.3326 TrainAcc 0.8700 TestAcc 0.8118 0.8550
epoch 700 LossPred 0.3917 LossAtt 0.3412 TrainAcc 0.8800 TestAcc 0.8106 0.8600
epoch 800 LossPred 0.3395 LossAtt 0.3387 TrainAcc 0.9100 TestAcc 0.8256 0.8850
epoch 900 LossPred 0.4490 LossAtt 0.3248 TrainAcc 0.8500 TestAcc 0.7828 0.8550
epoch 1000 LossPred 0.2903 LossAtt 0.3251 TrainAcc 0.9300 TestAcc 0.8431 0.9150
epoch 1100 LossPred 0.2928 LossAtt 0.3165 TrainAcc 0.9300 TestAcc 0.8368 0.9250
epoch 1200 LossPred 0.2583 LossAtt 0.2964 TrainAcc 0.9400 TestAcc 0.8466 0.9300
epoch 1300 LossPred 0.3209 LossAtt 0.3046 TrainAcc 0.9000 TestAcc 0.8473 0.8800
epoch 1400 LossPred 0.2793 LossAtt 0.2932 TrainAcc 0.8800 TestAcc 0.8519 0.8900
epoch 1500 LossPred 0.3216 LossAtt 0.2890 TrainAcc 0.9200 TestAcc 0.8438 0.9100
epoch 1600 LossPred 0.3012 LossAtt 0.2848 TrainAcc 0.9000 TestAcc 0.8574 0.9100
epoch 1700 LossPred 0.3427 LossAtt 0.2850 TrainAcc 0.9000 TestAcc 0.8356 0.8950
epoch 1800 LossPred 0.2454 LossAtt 0.2822 TrainAcc 0.9200 TestAcc 0.8584 0.9400
epoch 1900 LossPred 0.3049 LossAtt 0.2788 TrainAcc 0.9200 TestAcc 0.8471 0.9150
epoch 2000 LossPred 0.2687 LossAtt 0.2610 TrainAcc 0.9300 TestAcc 0.8506 0.9250
epoch 2100 LossPred 0.2805 LossAtt 0.2609 TrainAcc 0.9300 TestAcc 0.8491 0.9300
epoch 2200 LossPred 0.2296 LossAtt 0.2497 TrainAcc 0.9200 TestAcc 0.8574 0.9250
epoch 2300 LossPred 0.1872 LossAtt 0.2568 TrainAcc 0.9600 TestAcc 0.8619 0.9550
epoch 2400 LossPred 0.3059 LossAtt 0.2495 TrainAcc 0.9100 TestAcc 0.8368 0.8950
epoch 2500 LossPred 0.1959 LossAtt 0.2464 TrainAcc 0.9500 TestAcc 0.8639 0.9500
Optimization Finished!
********** replication  80  **********
epoch   0 LossPred 1.2271 LossAtt 1.0125 TrainAcc 0.3800 TestAcc 0.4074 0.4050
epoch 100 LossPred 0.9227 LossAtt 0.2010 TrainAcc 0.6200 TestAcc 0.5876 0.6300
epoch 200 LossPred 0.8272 LossAtt 0.2122 TrainAcc 0.6800 TestAcc 0.6652 0.6750
epoch 300 LossPred 0.5274 LossAtt 0.2061 TrainAcc 0.8400 TestAcc 0.7650 0.8400
epoch 400 LossPred 0.4867 LossAtt 0.1824 TrainAcc 0.8600 TestAcc 0.8286 0.8650
epoch 500 LossPred 0.7801 LossAtt 0.2121 TrainAcc 0.7200 TestAcc 0.7007 0.6400
epoch 600 LossPred 0.5296 LossAtt 0.1771 TrainAcc 0.8300 TestAcc 0.7923 0.8200
epoch 700 LossPred 0.5524 LossAtt 0.1569 TrainAcc 0.8100 TestAcc 0.7678 0.8200
epoch 800 LossPred 0.5045 LossAtt 0.1567 TrainAcc 0.8300 TestAcc 0.8143 0.8350
epoch 900 LossPred 0.6173 LossAtt 0.1602 TrainAcc 0.7700 TestAcc 0.7723 0.7600
epoch 1000 LossPred 1.2289 LossAtt 0.1409 TrainAcc 0.4700 TestAcc 0.5425 0.4700
epoch 1100 LossPred 0.5710 LossAtt 0.1442 TrainAcc 0.8100 TestAcc 0.7868 0.8100
epoch 1200 LossPred 0.5034 LossAtt 0.1312 TrainAcc 0.8600 TestAcc 0.7940 0.8400
epoch 1300 LossPred 1.5738 LossAtt 0.1773 TrainAcc 0.4400 TestAcc 0.5040 0.4400
epoch 1400 LossPred 0.6001 LossAtt 0.1363 TrainAcc 0.7900 TestAcc 0.7578 0.7850
epoch 1500 LossPred 0.5038 LossAtt 0.1183 TrainAcc 0.8300 TestAcc 0.7462 0.8300
epoch 1600 LossPred 0.5757 LossAtt 0.1221 TrainAcc 0.8000 TestAcc 0.7910 0.8150
epoch 1700 LossPred 0.4921 LossAtt 0.1330 TrainAcc 0.8300 TestAcc 0.7800 0.8200
epoch 1800 LossPred 0.5848 LossAtt 0.1216 TrainAcc 0.8100 TestAcc 0.7810 0.8050
epoch 1900 LossPred 0.4787 LossAtt 0.1279 TrainAcc 0.8400 TestAcc 0.7748 0.8400
epoch 2000 LossPred 1.7118 LossAtt 0.1591 TrainAcc 0.4400 TestAcc 0.5040 0.4400
epoch 2100 LossPred 0.6229 LossAtt 0.1334 TrainAcc 0.8200 TestAcc 0.7370 0.8150
epoch 2200 LossPred 0.5829 LossAtt 0.1126 TrainAcc 0.8300 TestAcc 0.7505 0.8250
epoch 2300 LossPred 0.5046 LossAtt 0.1062 TrainAcc 0.8300 TestAcc 0.7813 0.8550
epoch 2400 LossPred 0.4756 LossAtt 0.1148 TrainAcc 0.8400 TestAcc 0.7863 0.8250
epoch 2500 LossPred 0.7336 LossAtt 0.1084 TrainAcc 0.7400 TestAcc 0.6654 0.7550
Optimization Finished!
********** replication  81  **********
epoch   0 LossPred 0.9343 LossAtt 1.0272 TrainAcc 0.6100 TestAcc 0.5078 0.6100
epoch 100 LossPred 0.8720 LossAtt 0.2418 TrainAcc 0.6500 TestAcc 0.5893 0.6550
epoch 200 LossPred 0.8465 LossAtt 0.2507 TrainAcc 0.6600 TestAcc 0.5638 0.6600
epoch 300 LossPred 0.8240 LossAtt 0.2616 TrainAcc 0.6600 TestAcc 0.5626 0.6700
epoch 400 LossPred 0.8010 LossAtt 0.2808 TrainAcc 0.6800 TestAcc 0.5536 0.6850
epoch 500 LossPred 0.6882 LossAtt 0.3523 TrainAcc 0.6900 TestAcc 0.5395 0.6900
epoch 600 LossPred 0.5261 LossAtt 0.3728 TrainAcc 0.8500 TestAcc 0.5365 0.7800
epoch 700 LossPred 0.4661 LossAtt 0.3801 TrainAcc 0.8700 TestAcc 0.5355 0.7800
epoch 800 LossPred 0.4368 LossAtt 0.3620 TrainAcc 0.8600 TestAcc 0.5263 0.7800
epoch 900 LossPred 0.4833 LossAtt 0.3534 TrainAcc 0.8500 TestAcc 0.5270 0.8150
epoch 1000 LossPred 0.4427 LossAtt 0.3544 TrainAcc 0.8800 TestAcc 0.5260 0.8050
epoch 1100 LossPred 0.4989 LossAtt 0.3471 TrainAcc 0.8500 TestAcc 0.5208 0.7850
epoch 1200 LossPred 0.4305 LossAtt 0.3521 TrainAcc 0.8800 TestAcc 0.5255 0.8150
epoch 1300 LossPred 0.4618 LossAtt 0.3509 TrainAcc 0.8700 TestAcc 0.5183 0.7950
epoch 1400 LossPred 0.4541 LossAtt 0.3397 TrainAcc 0.8700 TestAcc 0.5250 0.7950
epoch 1500 LossPred 0.4571 LossAtt 0.3411 TrainAcc 0.8900 TestAcc 0.5250 0.8000
epoch 1600 LossPred 0.4518 LossAtt 0.3324 TrainAcc 0.8600 TestAcc 0.5170 0.7950
epoch 1700 LossPred 0.4246 LossAtt 0.3355 TrainAcc 0.8800 TestAcc 0.5158 0.8000
epoch 1800 LossPred 0.4415 LossAtt 0.3386 TrainAcc 0.8800 TestAcc 0.5100 0.8050
epoch 1900 LossPred 0.4164 LossAtt 0.3218 TrainAcc 0.8800 TestAcc 0.5143 0.8150
epoch 2000 LossPred 0.4557 LossAtt 0.3415 TrainAcc 0.8700 TestAcc 0.5203 0.8150
epoch 2100 LossPred 0.4040 LossAtt 0.3333 TrainAcc 0.8800 TestAcc 0.5158 0.8300
epoch 2200 LossPred 0.4871 LossAtt 0.3214 TrainAcc 0.8700 TestAcc 0.5180 0.8000
epoch 2300 LossPred 0.5518 LossAtt 0.3224 TrainAcc 0.8000 TestAcc 0.5170 0.7850
epoch 2400 LossPred 0.4293 LossAtt 0.3277 TrainAcc 0.8800 TestAcc 0.5180 0.8000
epoch 2500 LossPred 0.5483 LossAtt 0.3220 TrainAcc 0.8300 TestAcc 0.5158 0.8000
Optimization Finished!
********** replication  82  **********
epoch   0 LossPred 1.0418 LossAtt 1.0234 TrainAcc 0.4400 TestAcc 0.5433 0.4600
epoch 100 LossPred 0.9404 LossAtt 0.2734 TrainAcc 0.6000 TestAcc 0.5808 0.6100
epoch 200 LossPred 0.9319 LossAtt 0.2327 TrainAcc 0.6000 TestAcc 0.5808 0.6050
epoch 300 LossPred 0.9004 LossAtt 0.2301 TrainAcc 0.6400 TestAcc 0.5656 0.6200
epoch 400 LossPred 0.7982 LossAtt 0.3362 TrainAcc 0.7100 TestAcc 0.5891 0.7200
epoch 500 LossPred 0.6873 LossAtt 0.3670 TrainAcc 0.7400 TestAcc 0.6044 0.7200
epoch 600 LossPred 0.6151 LossAtt 0.3710 TrainAcc 0.7800 TestAcc 0.6221 0.7650
epoch 700 LossPred 0.4637 LossAtt 0.3959 TrainAcc 0.8600 TestAcc 0.7833 0.8700
epoch 800 LossPred 0.3020 LossAtt 0.3926 TrainAcc 0.9100 TestAcc 0.8253 0.8850
epoch 900 LossPred 0.2758 LossAtt 0.3711 TrainAcc 0.9300 TestAcc 0.8248 0.9000
epoch 1000 LossPred 0.2467 LossAtt 0.3683 TrainAcc 0.9300 TestAcc 0.8343 0.9100
epoch 1100 LossPred 0.2307 LossAtt 0.3820 TrainAcc 0.9400 TestAcc 0.8301 0.9050
epoch 1200 LossPred 0.2021 LossAtt 0.3593 TrainAcc 0.9600 TestAcc 0.8368 0.9000
epoch 1300 LossPred 0.2945 LossAtt 0.3592 TrainAcc 0.9200 TestAcc 0.8193 0.8950
epoch 1400 LossPred 0.3447 LossAtt 0.3553 TrainAcc 0.8900 TestAcc 0.8396 0.8950
epoch 1500 LossPred 0.2141 LossAtt 0.3604 TrainAcc 0.9500 TestAcc 0.8298 0.8900
epoch 1600 LossPred 0.2795 LossAtt 0.3422 TrainAcc 0.9200 TestAcc 0.8366 0.8950
epoch 1700 LossPred 0.2521 LossAtt 0.3404 TrainAcc 0.9400 TestAcc 0.8351 0.8950
epoch 1800 LossPred 0.1731 LossAtt 0.3477 TrainAcc 0.9600 TestAcc 0.8238 0.9000
epoch 1900 LossPred 0.1818 LossAtt 0.3418 TrainAcc 0.9500 TestAcc 0.8356 0.9050
epoch 2000 LossPred 0.2151 LossAtt 0.3365 TrainAcc 0.9400 TestAcc 0.8296 0.9100
epoch 2100 LossPred 0.1560 LossAtt 0.3599 TrainAcc 0.9700 TestAcc 0.8263 0.9000
epoch 2200 LossPred 0.1719 LossAtt 0.3456 TrainAcc 0.9600 TestAcc 0.8148 0.9050
epoch 2300 LossPred 0.1612 LossAtt 0.3477 TrainAcc 0.9700 TestAcc 0.8131 0.8950
epoch 2400 LossPred 0.2686 LossAtt 0.3554 TrainAcc 0.9300 TestAcc 0.8058 0.8750
epoch 2500 LossPred 0.1442 LossAtt 0.3506 TrainAcc 0.9700 TestAcc 0.8246 0.9150
Optimization Finished!
********** replication  83  **********
epoch   0 LossPred 1.0796 LossAtt 1.0246 TrainAcc 0.4400 TestAcc 0.4309 0.4400
epoch 100 LossPred 0.9218 LossAtt 0.2921 TrainAcc 0.6200 TestAcc 0.5561 0.6200
epoch 200 LossPred 0.8739 LossAtt 0.2516 TrainAcc 0.6200 TestAcc 0.5736 0.6100
epoch 300 LossPred 0.8169 LossAtt 0.2797 TrainAcc 0.6500 TestAcc 0.5395 0.6600
epoch 400 LossPred 0.7671 LossAtt 0.2906 TrainAcc 0.7100 TestAcc 0.5383 0.6700
epoch 500 LossPred 0.7273 LossAtt 0.3111 TrainAcc 0.7300 TestAcc 0.5298 0.7200
epoch 600 LossPred 0.6954 LossAtt 0.3020 TrainAcc 0.7500 TestAcc 0.5385 0.7200
epoch 700 LossPred 0.6692 LossAtt 0.2788 TrainAcc 0.7700 TestAcc 0.5463 0.7100
epoch 800 LossPred 0.6218 LossAtt 0.2824 TrainAcc 0.7800 TestAcc 0.5561 0.7250
epoch 900 LossPred 0.6145 LossAtt 0.2792 TrainAcc 0.7500 TestAcc 0.5626 0.7450
epoch 1000 LossPred 0.5751 LossAtt 0.2775 TrainAcc 0.8000 TestAcc 0.5468 0.7350
epoch 1100 LossPred 0.5702 LossAtt 0.2798 TrainAcc 0.8300 TestAcc 0.5626 0.7400
epoch 1200 LossPred 0.5398 LossAtt 0.2830 TrainAcc 0.8400 TestAcc 0.5623 0.7550
epoch 1300 LossPred 0.5232 LossAtt 0.2764 TrainAcc 0.8600 TestAcc 0.5591 0.7600
epoch 1400 LossPred 0.5224 LossAtt 0.2819 TrainAcc 0.8600 TestAcc 0.5613 0.7650
epoch 1500 LossPred 0.5464 LossAtt 0.2924 TrainAcc 0.8500 TestAcc 0.5756 0.7750
epoch 1600 LossPred 0.5306 LossAtt 0.2841 TrainAcc 0.8200 TestAcc 0.5788 0.7950
epoch 1700 LossPred 0.5132 LossAtt 0.2821 TrainAcc 0.8300 TestAcc 0.5756 0.7700
epoch 1800 LossPred 0.5301 LossAtt 0.2788 TrainAcc 0.8400 TestAcc 0.5828 0.7650
epoch 1900 LossPred 0.5381 LossAtt 0.2903 TrainAcc 0.8300 TestAcc 0.5768 0.7800
epoch 2000 LossPred 0.5072 LossAtt 0.2721 TrainAcc 0.8500 TestAcc 0.5848 0.7850
epoch 2100 LossPred 0.5241 LossAtt 0.2958 TrainAcc 0.8600 TestAcc 0.5883 0.8000
epoch 2200 LossPred 0.5675 LossAtt 0.2821 TrainAcc 0.8300 TestAcc 0.5958 0.7600
epoch 2300 LossPred 0.5186 LossAtt 0.2751 TrainAcc 0.8400 TestAcc 0.5933 0.8000
epoch 2400 LossPred 0.4868 LossAtt 0.2709 TrainAcc 0.8600 TestAcc 0.5898 0.7950
epoch 2500 LossPred 0.4564 LossAtt 0.2511 TrainAcc 0.8500 TestAcc 0.5903 0.8050
Optimization Finished!
********** replication  84  **********
epoch   0 LossPred 1.2844 LossAtt 1.0194 TrainAcc 0.4400 TestAcc 0.4645 0.4550
epoch 100 LossPred 0.8573 LossAtt 0.3246 TrainAcc 0.6800 TestAcc 0.5921 0.6750
epoch 200 LossPred 0.8269 LossAtt 0.2688 TrainAcc 0.6600 TestAcc 0.5801 0.6700
epoch 300 LossPred 0.6686 LossAtt 0.3111 TrainAcc 0.7700 TestAcc 0.7568 0.7450
epoch 400 LossPred 0.4621 LossAtt 0.2867 TrainAcc 0.8600 TestAcc 0.7820 0.8400
epoch 500 LossPred 0.4364 LossAtt 0.2548 TrainAcc 0.8700 TestAcc 0.7765 0.8450
epoch 600 LossPred 0.4557 LossAtt 0.2330 TrainAcc 0.8400 TestAcc 0.7760 0.8050
epoch 700 LossPred 0.4397 LossAtt 0.2272 TrainAcc 0.8500 TestAcc 0.7740 0.8300
epoch 800 LossPred 0.4205 LossAtt 0.2165 TrainAcc 0.8600 TestAcc 0.7810 0.8500
epoch 900 LossPred 0.4201 LossAtt 0.2215 TrainAcc 0.8700 TestAcc 0.7780 0.8450
epoch 1000 LossPred 0.4150 LossAtt 0.2236 TrainAcc 0.8700 TestAcc 0.7820 0.8400
epoch 1100 LossPred 0.4051 LossAtt 0.2056 TrainAcc 0.8700 TestAcc 0.7795 0.8550
epoch 1200 LossPred 0.4286 LossAtt 0.2244 TrainAcc 0.8700 TestAcc 0.7818 0.8350
epoch 1300 LossPred 0.4302 LossAtt 0.2041 TrainAcc 0.8600 TestAcc 0.7888 0.8450
epoch 1400 LossPred 0.3977 LossAtt 0.2098 TrainAcc 0.8800 TestAcc 0.7953 0.8600
epoch 1500 LossPred 0.3819 LossAtt 0.2063 TrainAcc 0.8900 TestAcc 0.7960 0.8450
epoch 1600 LossPred 0.3684 LossAtt 0.2115 TrainAcc 0.8800 TestAcc 0.8078 0.8550
epoch 1700 LossPred 0.3424 LossAtt 0.2171 TrainAcc 0.8900 TestAcc 0.8156 0.8550
epoch 1800 LossPred 0.3403 LossAtt 0.2375 TrainAcc 0.8900 TestAcc 0.8338 0.8600
epoch 1900 LossPred 0.3518 LossAtt 0.2380 TrainAcc 0.8800 TestAcc 0.8423 0.8550
epoch 2000 LossPred 0.2660 LossAtt 0.2456 TrainAcc 0.8800 TestAcc 0.8629 0.8850
epoch 2100 LossPred 0.2382 LossAtt 0.2439 TrainAcc 0.9200 TestAcc 0.8493 0.8950
epoch 2200 LossPred 0.2358 LossAtt 0.2436 TrainAcc 0.9200 TestAcc 0.8436 0.8900
epoch 2300 LossPred 0.2267 LossAtt 0.2357 TrainAcc 0.9200 TestAcc 0.8584 0.9050
epoch 2400 LossPred 0.2210 LossAtt 0.2353 TrainAcc 0.9200 TestAcc 0.8559 0.9000
epoch 2500 LossPred 0.2272 LossAtt 0.2348 TrainAcc 0.9300 TestAcc 0.8581 0.8850
Optimization Finished!
********** replication  85  **********
epoch   0 LossPred 1.1101 LossAtt 0.9986 TrainAcc 0.3800 TestAcc 0.5018 0.4050
epoch 100 LossPred 0.8488 LossAtt 0.2975 TrainAcc 0.6800 TestAcc 0.5558 0.6800
epoch 200 LossPred 0.7254 LossAtt 0.3677 TrainAcc 0.7200 TestAcc 0.5788 0.7000
epoch 300 LossPred 0.4457 LossAtt 0.3780 TrainAcc 0.8800 TestAcc 0.7450 0.8650
epoch 400 LossPred 0.3622 LossAtt 0.3316 TrainAcc 0.8800 TestAcc 0.7688 0.8800
epoch 500 LossPred 0.3282 LossAtt 0.3158 TrainAcc 0.8900 TestAcc 0.7800 0.8900
epoch 600 LossPred 0.2485 LossAtt 0.3052 TrainAcc 0.9100 TestAcc 0.7845 0.9000
epoch 700 LossPred 0.2358 LossAtt 0.3011 TrainAcc 0.9400 TestAcc 0.7948 0.8950
epoch 800 LossPred 0.3097 LossAtt 0.2892 TrainAcc 0.9200 TestAcc 0.7795 0.9000
epoch 900 LossPred 0.2032 LossAtt 0.2759 TrainAcc 0.9400 TestAcc 0.7773 0.9200
epoch 1000 LossPred 0.2621 LossAtt 0.2798 TrainAcc 0.9300 TestAcc 0.7793 0.9200
epoch 1100 LossPred 0.2148 LossAtt 0.2770 TrainAcc 0.9400 TestAcc 0.7805 0.9200
epoch 1200 LossPred 0.2261 LossAtt 0.2774 TrainAcc 0.9200 TestAcc 0.7785 0.9100
epoch 1300 LossPred 0.2183 LossAtt 0.2607 TrainAcc 0.9300 TestAcc 0.7833 0.9250
epoch 1400 LossPred 0.2242 LossAtt 0.2541 TrainAcc 0.9400 TestAcc 0.7745 0.9200
epoch 1500 LossPred 0.2548 LossAtt 0.2593 TrainAcc 0.9200 TestAcc 0.7798 0.9100
epoch 1600 LossPred 0.2718 LossAtt 0.2532 TrainAcc 0.9100 TestAcc 0.7738 0.9050
epoch 1700 LossPred 0.2110 LossAtt 0.2499 TrainAcc 0.9400 TestAcc 0.7855 0.9400
epoch 1800 LossPred 0.2019 LossAtt 0.2457 TrainAcc 0.9400 TestAcc 0.7788 0.9150
epoch 1900 LossPred 0.1802 LossAtt 0.2437 TrainAcc 0.9400 TestAcc 0.7830 0.9350
epoch 2000 LossPred 0.1697 LossAtt 0.2301 TrainAcc 0.9400 TestAcc 0.7890 0.9300
epoch 2100 LossPred 0.1869 LossAtt 0.2312 TrainAcc 0.9600 TestAcc 0.7835 0.9200
epoch 2200 LossPred 0.2354 LossAtt 0.2266 TrainAcc 0.9400 TestAcc 0.7638 0.8950
epoch 2300 LossPred 0.2331 LossAtt 0.2191 TrainAcc 0.9300 TestAcc 0.7880 0.9450
epoch 2400 LossPred 0.1993 LossAtt 0.2279 TrainAcc 0.9500 TestAcc 0.7800 0.9200
epoch 2500 LossPred 0.4216 LossAtt 0.2184 TrainAcc 0.8700 TestAcc 0.7718 0.8700
Optimization Finished!
********** replication  86  **********
epoch   0 LossPred 0.9771 LossAtt 1.0054 TrainAcc 0.5300 TestAcc 0.5108 0.5250
epoch 100 LossPred 0.9196 LossAtt 0.3237 TrainAcc 0.6400 TestAcc 0.5756 0.6450
epoch 200 LossPred 0.8543 LossAtt 0.3513 TrainAcc 0.6600 TestAcc 0.5626 0.6650
epoch 300 LossPred 0.4045 LossAtt 0.3502 TrainAcc 0.8700 TestAcc 0.7460 0.8450
epoch 400 LossPred 0.2603 LossAtt 0.3559 TrainAcc 0.9100 TestAcc 0.8093 0.8850
epoch 500 LossPred 0.2001 LossAtt 0.3459 TrainAcc 0.9300 TestAcc 0.8306 0.8900
epoch 600 LossPred 0.1614 LossAtt 0.3361 TrainAcc 0.9400 TestAcc 0.8326 0.9050
epoch 700 LossPred 0.1389 LossAtt 0.3235 TrainAcc 0.9400 TestAcc 0.8361 0.9100
epoch 800 LossPred 0.1468 LossAtt 0.3326 TrainAcc 0.9400 TestAcc 0.8303 0.9200
epoch 900 LossPred 0.1651 LossAtt 0.3263 TrainAcc 0.9500 TestAcc 0.8318 0.9150
epoch 1000 LossPred 0.1910 LossAtt 0.3215 TrainAcc 0.9500 TestAcc 0.8251 0.9150
epoch 1100 LossPred 0.1637 LossAtt 0.3221 TrainAcc 0.9400 TestAcc 0.8151 0.9100
epoch 1200 LossPred 0.1650 LossAtt 0.3020 TrainAcc 0.9300 TestAcc 0.8143 0.9100
epoch 1300 LossPred 0.2012 LossAtt 0.3096 TrainAcc 0.9300 TestAcc 0.8008 0.8850
epoch 1400 LossPred 0.2273 LossAtt 0.3116 TrainAcc 0.9300 TestAcc 0.7890 0.8950
epoch 1500 LossPred 0.1673 LossAtt 0.3287 TrainAcc 0.9500 TestAcc 0.8226 0.9150
epoch 1600 LossPred 0.1717 LossAtt 0.3347 TrainAcc 0.9500 TestAcc 0.8266 0.9100
epoch 1700 LossPred 0.2298 LossAtt 0.3228 TrainAcc 0.9200 TestAcc 0.7875 0.8800
epoch 1800 LossPred 0.1738 LossAtt 0.3396 TrainAcc 0.9400 TestAcc 0.8291 0.9400
epoch 1900 LossPred 0.1729 LossAtt 0.3260 TrainAcc 0.9500 TestAcc 0.8161 0.9150
epoch 2000 LossPred 0.2253 LossAtt 0.3290 TrainAcc 0.9200 TestAcc 0.7930 0.8950
epoch 2100 LossPred 0.1460 LossAtt 0.3315 TrainAcc 0.9600 TestAcc 0.8391 0.9400
epoch 2200 LossPred 0.1463 LossAtt 0.3396 TrainAcc 0.9600 TestAcc 0.8253 0.9250
epoch 2300 LossPred 0.2567 LossAtt 0.3297 TrainAcc 0.9200 TestAcc 0.7865 0.9100
epoch 2400 LossPred 0.1385 LossAtt 0.3363 TrainAcc 0.9600 TestAcc 0.8161 0.9350
epoch 2500 LossPred 0.1617 LossAtt 0.3332 TrainAcc 0.9400 TestAcc 0.8293 0.9150
Optimization Finished!
********** replication  87  **********
epoch   0 LossPred 1.2918 LossAtt 1.0224 TrainAcc 0.4000 TestAcc 0.4890 0.4000
epoch 100 LossPred 0.9012 LossAtt 0.2771 TrainAcc 0.6500 TestAcc 0.5863 0.6500
epoch 200 LossPred 0.8915 LossAtt 0.2604 TrainAcc 0.6500 TestAcc 0.5863 0.6500
epoch 300 LossPred 0.8730 LossAtt 0.2847 TrainAcc 0.6700 TestAcc 0.5526 0.7050
epoch 400 LossPred 0.8307 LossAtt 0.2851 TrainAcc 0.7300 TestAcc 0.5438 0.7150
epoch 500 LossPred 0.7694 LossAtt 0.2840 TrainAcc 0.7700 TestAcc 0.5348 0.7050
epoch 600 LossPred 0.7412 LossAtt 0.2751 TrainAcc 0.7700 TestAcc 0.5325 0.7150
epoch 700 LossPred 0.7412 LossAtt 0.2841 TrainAcc 0.7400 TestAcc 0.5305 0.7250
epoch 800 LossPred 0.7108 LossAtt 0.2851 TrainAcc 0.7700 TestAcc 0.5323 0.7200
epoch 900 LossPred 0.6966 LossAtt 0.2982 TrainAcc 0.7400 TestAcc 0.5353 0.7150
epoch 1000 LossPred 0.6613 LossAtt 0.3059 TrainAcc 0.7700 TestAcc 0.5370 0.7450
epoch 1100 LossPred 0.6599 LossAtt 0.3240 TrainAcc 0.7700 TestAcc 0.5335 0.7600
epoch 1200 LossPred 0.7948 LossAtt 0.3334 TrainAcc 0.7100 TestAcc 0.5195 0.7150
epoch 1300 LossPred 0.7193 LossAtt 0.3234 TrainAcc 0.7600 TestAcc 0.5210 0.7450
epoch 1400 LossPred 0.6891 LossAtt 0.3122 TrainAcc 0.8100 TestAcc 0.5153 0.7600
epoch 1500 LossPred 0.6728 LossAtt 0.3143 TrainAcc 0.7900 TestAcc 0.5138 0.7450
epoch 1600 LossPred 0.6528 LossAtt 0.3127 TrainAcc 0.7900 TestAcc 0.5175 0.7400
epoch 1700 LossPred 0.6339 LossAtt 0.3169 TrainAcc 0.8000 TestAcc 0.5140 0.7700
epoch 1800 LossPred 0.6025 LossAtt 0.3080 TrainAcc 0.7900 TestAcc 0.5230 0.7800
epoch 1900 LossPred 0.5376 LossAtt 0.3060 TrainAcc 0.8400 TestAcc 0.5255 0.7800
epoch 2000 LossPred 0.5214 LossAtt 0.2979 TrainAcc 0.8300 TestAcc 0.5238 0.7750
epoch 2100 LossPred 0.5047 LossAtt 0.3017 TrainAcc 0.8500 TestAcc 0.5285 0.7650
epoch 2200 LossPred 0.5155 LossAtt 0.2965 TrainAcc 0.8400 TestAcc 0.5295 0.7800
epoch 2300 LossPred 0.5027 LossAtt 0.2913 TrainAcc 0.8500 TestAcc 0.5295 0.7950
epoch 2400 LossPred 0.5268 LossAtt 0.2870 TrainAcc 0.8300 TestAcc 0.5295 0.7700
epoch 2500 LossPred 0.4904 LossAtt 0.2871 TrainAcc 0.8500 TestAcc 0.5280 0.7750
Optimization Finished!
********** replication  88  **********
epoch   0 LossPred 1.0971 LossAtt 0.9932 TrainAcc 0.4000 TestAcc 0.4457 0.4350
epoch 100 LossPred 0.8828 LossAtt 0.2772 TrainAcc 0.6400 TestAcc 0.5756 0.6400
epoch 200 LossPred 0.6215 LossAtt 0.2906 TrainAcc 0.8000 TestAcc 0.7548 0.7600
epoch 300 LossPred 0.4247 LossAtt 0.2685 TrainAcc 0.8700 TestAcc 0.8483 0.8500
epoch 400 LossPred 0.4194 LossAtt 0.2640 TrainAcc 0.8500 TestAcc 0.8393 0.8450
epoch 500 LossPred 0.4186 LossAtt 0.2525 TrainAcc 0.8900 TestAcc 0.8441 0.8750
epoch 600 LossPred 0.3579 LossAtt 0.2641 TrainAcc 0.9000 TestAcc 0.8614 0.8650
epoch 700 LossPred 0.2709 LossAtt 0.2523 TrainAcc 0.9100 TestAcc 0.8791 0.9000
epoch 800 LossPred 0.6134 LossAtt 0.2604 TrainAcc 0.7600 TestAcc 0.8058 0.7850
epoch 900 LossPred 0.3419 LossAtt 0.2261 TrainAcc 0.8800 TestAcc 0.8696 0.8900
epoch 1000 LossPred 0.6251 LossAtt 0.2201 TrainAcc 0.8000 TestAcc 0.7820 0.8150
epoch 1100 LossPred 0.5201 LossAtt 0.2141 TrainAcc 0.8100 TestAcc 0.8238 0.8450
epoch 1200 LossPred 0.5723 LossAtt 0.1913 TrainAcc 0.8200 TestAcc 0.7658 0.8250
epoch 1300 LossPred 0.4327 LossAtt 0.2022 TrainAcc 0.8700 TestAcc 0.8196 0.8900
epoch 1400 LossPred 0.6185 LossAtt 0.2179 TrainAcc 0.7900 TestAcc 0.7868 0.7650
epoch 1500 LossPred 0.7656 LossAtt 0.1973 TrainAcc 0.7100 TestAcc 0.7032 0.7500
epoch 1600 LossPred 0.3540 LossAtt 0.2242 TrainAcc 0.8800 TestAcc 0.8521 0.8850
epoch 1700 LossPred 0.3565 LossAtt 0.2257 TrainAcc 0.9000 TestAcc 0.8501 0.8900
epoch 1800 LossPred 0.3477 LossAtt 0.2226 TrainAcc 0.8900 TestAcc 0.8231 0.8850
epoch 1900 LossPred 0.2749 LossAtt 0.2314 TrainAcc 0.9100 TestAcc 0.8529 0.9050
epoch 2000 LossPred 0.2954 LossAtt 0.2342 TrainAcc 0.9200 TestAcc 0.8544 0.9000
epoch 2100 LossPred 0.2961 LossAtt 0.2424 TrainAcc 0.9000 TestAcc 0.8534 0.8950
epoch 2200 LossPred 0.5814 LossAtt 0.2446 TrainAcc 0.8000 TestAcc 0.7655 0.8350
epoch 2300 LossPred 0.3107 LossAtt 0.2406 TrainAcc 0.9000 TestAcc 0.8433 0.9050
epoch 2400 LossPred 0.3117 LossAtt 0.2478 TrainAcc 0.8900 TestAcc 0.8378 0.8700
epoch 2500 LossPred 0.1692 LossAtt 0.2517 TrainAcc 0.9500 TestAcc 0.8669 0.9350
Optimization Finished!
********** replication  89  **********
epoch   0 LossPred 1.0759 LossAtt 1.0071 TrainAcc 0.3200 TestAcc 0.4254 0.3300
epoch 100 LossPred 0.8379 LossAtt 0.2547 TrainAcc 0.6900 TestAcc 0.5763 0.7300
epoch 200 LossPred 0.7327 LossAtt 0.2796 TrainAcc 0.7300 TestAcc 0.6632 0.7550
epoch 300 LossPred 0.5236 LossAtt 0.2298 TrainAcc 0.8100 TestAcc 0.7938 0.8050
epoch 400 LossPred 0.6395 LossAtt 0.2378 TrainAcc 0.7600 TestAcc 0.7157 0.7800
epoch 500 LossPred 0.5409 LossAtt 0.2364 TrainAcc 0.7800 TestAcc 0.7565 0.7750
epoch 600 LossPred 0.5924 LossAtt 0.2115 TrainAcc 0.7900 TestAcc 0.7760 0.8050
epoch 700 LossPred 0.5342 LossAtt 0.2186 TrainAcc 0.8100 TestAcc 0.7718 0.7850
epoch 800 LossPred 0.5216 LossAtt 0.2014 TrainAcc 0.8100 TestAcc 0.7720 0.8450
epoch 900 LossPred 0.4977 LossAtt 0.2057 TrainAcc 0.8300 TestAcc 0.7755 0.8450
epoch 1000 LossPred 0.6079 LossAtt 0.1972 TrainAcc 0.7700 TestAcc 0.7360 0.8100
epoch 1100 LossPred 0.5313 LossAtt 0.2063 TrainAcc 0.8100 TestAcc 0.7600 0.8500
epoch 1200 LossPred 0.5236 LossAtt 0.2078 TrainAcc 0.8200 TestAcc 0.7645 0.8500
epoch 1300 LossPred 0.6049 LossAtt 0.2272 TrainAcc 0.7600 TestAcc 0.7135 0.7600
epoch 1400 LossPred 0.5290 LossAtt 0.2111 TrainAcc 0.8100 TestAcc 0.7553 0.7900
epoch 1500 LossPred 0.6527 LossAtt 0.2132 TrainAcc 0.7500 TestAcc 0.6406 0.7550
epoch 1600 LossPred 0.5809 LossAtt 0.2165 TrainAcc 0.7600 TestAcc 0.7145 0.7700
epoch 1700 LossPred 0.5272 LossAtt 0.2122 TrainAcc 0.8200 TestAcc 0.7437 0.8250
epoch 1800 LossPred 0.5226 LossAtt 0.2057 TrainAcc 0.8200 TestAcc 0.7437 0.8250
epoch 1900 LossPred 0.5129 LossAtt 0.2039 TrainAcc 0.8200 TestAcc 0.7525 0.8200
epoch 2000 LossPred 0.5148 LossAtt 0.2070 TrainAcc 0.8300 TestAcc 0.7545 0.8350
epoch 2100 LossPred 0.4840 LossAtt 0.1947 TrainAcc 0.8400 TestAcc 0.7525 0.8400
epoch 2200 LossPred 0.4866 LossAtt 0.1951 TrainAcc 0.8500 TestAcc 0.7472 0.8450
epoch 2300 LossPred 0.4878 LossAtt 0.1922 TrainAcc 0.8400 TestAcc 0.7377 0.8400
epoch 2400 LossPred 0.4834 LossAtt 0.1972 TrainAcc 0.8400 TestAcc 0.7390 0.8400
epoch 2500 LossPred 0.4832 LossAtt 0.1863 TrainAcc 0.8400 TestAcc 0.7342 0.8450
Optimization Finished!
********** replication  90  **********
epoch   0 LossPred 0.9781 LossAtt 1.0333 TrainAcc 0.6000 TestAcc 0.5495 0.5850
epoch 100 LossPred 0.8274 LossAtt 0.3412 TrainAcc 0.6700 TestAcc 0.6241 0.6600
epoch 200 LossPred 0.2731 LossAtt 0.3096 TrainAcc 0.9100 TestAcc 0.8601 0.8350
epoch 300 LossPred 0.4197 LossAtt 0.2845 TrainAcc 0.8600 TestAcc 0.8206 0.8400
epoch 400 LossPred 0.4805 LossAtt 0.2625 TrainAcc 0.8200 TestAcc 0.8036 0.8250
epoch 500 LossPred 0.3028 LossAtt 0.2478 TrainAcc 0.9000 TestAcc 0.8461 0.8800
epoch 600 LossPred 0.2201 LossAtt 0.2331 TrainAcc 0.9100 TestAcc 0.8649 0.9150
epoch 700 LossPred 0.2473 LossAtt 0.2383 TrainAcc 0.8800 TestAcc 0.8483 0.9050
epoch 800 LossPred 0.2319 LossAtt 0.2255 TrainAcc 0.9100 TestAcc 0.8506 0.9050
epoch 900 LossPred 0.2323 LossAtt 0.2169 TrainAcc 0.9200 TestAcc 0.8521 0.8950
epoch 1000 LossPred 0.2579 LossAtt 0.2135 TrainAcc 0.9000 TestAcc 0.8266 0.8850
epoch 1100 LossPred 0.1855 LossAtt 0.2031 TrainAcc 0.9300 TestAcc 0.8549 0.9300
epoch 1200 LossPred 0.1730 LossAtt 0.1992 TrainAcc 0.9500 TestAcc 0.8596 0.9350
epoch 1300 LossPred 0.2588 LossAtt 0.1959 TrainAcc 0.9100 TestAcc 0.8378 0.9150
epoch 1400 LossPred 0.2151 LossAtt 0.1880 TrainAcc 0.9500 TestAcc 0.8541 0.9400
epoch 1500 LossPred 0.3100 LossAtt 0.1868 TrainAcc 0.8700 TestAcc 0.8331 0.8850
epoch 1600 LossPred 0.2593 LossAtt 0.1894 TrainAcc 0.9200 TestAcc 0.8178 0.9050
epoch 1700 LossPred 0.3716 LossAtt 0.1805 TrainAcc 0.8400 TestAcc 0.8176 0.8400
epoch 1800 LossPred 0.3000 LossAtt 0.1790 TrainAcc 0.8900 TestAcc 0.8081 0.8750
epoch 1900 LossPred 0.3485 LossAtt 0.1784 TrainAcc 0.8600 TestAcc 0.8346 0.8650
epoch 2000 LossPred 0.2278 LossAtt 0.1729 TrainAcc 0.9100 TestAcc 0.8514 0.9250
epoch 2100 LossPred 0.2184 LossAtt 0.1735 TrainAcc 0.9200 TestAcc 0.8594 0.9150
epoch 2200 LossPred 0.1844 LossAtt 0.1773 TrainAcc 0.9600 TestAcc 0.8649 0.9350
epoch 2300 LossPred 0.3685 LossAtt 0.1691 TrainAcc 0.8500 TestAcc 0.8208 0.8550
epoch 2400 LossPred 0.2891 LossAtt 0.1683 TrainAcc 0.8900 TestAcc 0.8391 0.8900
epoch 2500 LossPred 0.3572 LossAtt 0.1689 TrainAcc 0.8600 TestAcc 0.8298 0.8700
Optimization Finished!
********** replication  91  **********
epoch   0 LossPred 0.9829 LossAtt 1.0298 TrainAcc 0.5200 TestAcc 0.4967 0.5550
epoch 100 LossPred 0.9015 LossAtt 0.3266 TrainAcc 0.6000 TestAcc 0.6084 0.5900
epoch 200 LossPred 0.7236 LossAtt 0.2959 TrainAcc 0.7700 TestAcc 0.7603 0.7450
epoch 300 LossPred 0.8657 LossAtt 0.2546 TrainAcc 0.6500 TestAcc 0.6274 0.6450
epoch 400 LossPred 0.9184 LossAtt 0.2298 TrainAcc 0.6100 TestAcc 0.5453 0.5950
epoch 500 LossPred 0.9500 LossAtt 0.2125 TrainAcc 0.6100 TestAcc 0.6134 0.5950
epoch 600 LossPred 0.8943 LossAtt 0.2135 TrainAcc 0.6300 TestAcc 0.6066 0.6100
epoch 700 LossPred 0.8973 LossAtt 0.2174 TrainAcc 0.6300 TestAcc 0.6029 0.6200
epoch 800 LossPred 0.8609 LossAtt 0.1920 TrainAcc 0.6400 TestAcc 0.6089 0.6300
epoch 900 LossPred 0.8464 LossAtt 0.1863 TrainAcc 0.6400 TestAcc 0.6094 0.6400
epoch 1000 LossPred 0.8288 LossAtt 0.2022 TrainAcc 0.6400 TestAcc 0.6074 0.6450
epoch 1100 LossPred 0.8528 LossAtt 0.1990 TrainAcc 0.6300 TestAcc 0.6059 0.6450
epoch 1200 LossPred 0.8064 LossAtt 0.2055 TrainAcc 0.6500 TestAcc 0.6009 0.6500
epoch 1300 LossPred 0.7934 LossAtt 0.1996 TrainAcc 0.6600 TestAcc 0.5998 0.6450
epoch 1400 LossPred 0.7894 LossAtt 0.1973 TrainAcc 0.6500 TestAcc 0.6016 0.6500
epoch 1500 LossPred 0.8636 LossAtt 0.2057 TrainAcc 0.6400 TestAcc 0.6306 0.6150
epoch 1600 LossPred 0.8429 LossAtt 0.2034 TrainAcc 0.6600 TestAcc 0.6384 0.7050
epoch 1700 LossPred 0.8056 LossAtt 0.2132 TrainAcc 0.6500 TestAcc 0.5991 0.6600
epoch 1800 LossPred 0.7942 LossAtt 0.1844 TrainAcc 0.6500 TestAcc 0.5961 0.6800
epoch 1900 LossPred 0.7951 LossAtt 0.1830 TrainAcc 0.6800 TestAcc 0.6274 0.6700
epoch 2000 LossPred 0.7909 LossAtt 0.1928 TrainAcc 0.6800 TestAcc 0.6454 0.6650
epoch 2100 LossPred 0.7699 LossAtt 0.1816 TrainAcc 0.6900 TestAcc 0.6294 0.6650
epoch 2200 LossPred 0.9219 LossAtt 0.1721 TrainAcc 0.6200 TestAcc 0.5893 0.6200
epoch 2300 LossPred 0.8923 LossAtt 0.1865 TrainAcc 0.6300 TestAcc 0.6036 0.6300
epoch 2400 LossPred 0.7899 LossAtt 0.1773 TrainAcc 0.6800 TestAcc 0.6239 0.6750
epoch 2500 LossPred 0.8256 LossAtt 0.1668 TrainAcc 0.6600 TestAcc 0.6179 0.6500
Optimization Finished!
********** replication  92  **********
epoch   0 LossPred 1.1531 LossAtt 1.0331 TrainAcc 0.5500 TestAcc 0.5365 0.5550
epoch 100 LossPred 0.8957 LossAtt 0.2797 TrainAcc 0.5700 TestAcc 0.5033 0.6050
epoch 200 LossPred 0.8772 LossAtt 0.2351 TrainAcc 0.6400 TestAcc 0.5458 0.6400
epoch 300 LossPred 0.8687 LossAtt 0.2363 TrainAcc 0.6400 TestAcc 0.5748 0.6500
epoch 400 LossPred 0.8668 LossAtt 0.2264 TrainAcc 0.6400 TestAcc 0.5708 0.6550
epoch 500 LossPred 0.8523 LossAtt 0.2279 TrainAcc 0.6400 TestAcc 0.5713 0.6400
epoch 600 LossPred 0.8080 LossAtt 0.3002 TrainAcc 0.6900 TestAcc 0.5711 0.6800
epoch 700 LossPred 0.7400 LossAtt 0.4249 TrainAcc 0.7100 TestAcc 0.5878 0.7250
epoch 800 LossPred 0.6827 LossAtt 0.4126 TrainAcc 0.7700 TestAcc 0.5851 0.7650
epoch 900 LossPred 0.6699 LossAtt 0.4133 TrainAcc 0.7900 TestAcc 0.5933 0.7500
epoch 1000 LossPred 0.5836 LossAtt 0.4133 TrainAcc 0.8000 TestAcc 0.5871 0.8050
epoch 1100 LossPred 0.5649 LossAtt 0.3934 TrainAcc 0.8100 TestAcc 0.5923 0.8050
epoch 1200 LossPred 0.5962 LossAtt 0.4075 TrainAcc 0.8100 TestAcc 0.5821 0.7900
epoch 1300 LossPred 0.5455 LossAtt 0.4047 TrainAcc 0.8300 TestAcc 0.5796 0.7900
epoch 1400 LossPred 0.5752 LossAtt 0.3942 TrainAcc 0.8000 TestAcc 0.5706 0.7550
epoch 1500 LossPred 0.5271 LossAtt 0.3848 TrainAcc 0.8200 TestAcc 0.5806 0.7900
epoch 1600 LossPred 0.5393 LossAtt 0.3953 TrainAcc 0.8100 TestAcc 0.5946 0.7750
epoch 1700 LossPred 0.5548 LossAtt 0.3936 TrainAcc 0.8200 TestAcc 0.5693 0.7650
epoch 1800 LossPred 0.5819 LossAtt 0.3993 TrainAcc 0.8100 TestAcc 0.5708 0.7600
epoch 1900 LossPred 0.5610 LossAtt 0.3871 TrainAcc 0.8100 TestAcc 0.5703 0.7900
epoch 2000 LossPred 0.5456 LossAtt 0.3806 TrainAcc 0.8200 TestAcc 0.5758 0.7950
epoch 2100 LossPred 0.5882 LossAtt 0.3522 TrainAcc 0.8200 TestAcc 0.5916 0.7700
epoch 2200 LossPred 0.5360 LossAtt 0.3641 TrainAcc 0.8200 TestAcc 0.5741 0.7550
epoch 2300 LossPred 0.5342 LossAtt 0.3458 TrainAcc 0.8100 TestAcc 0.5723 0.7750
epoch 2400 LossPred 0.6022 LossAtt 0.3396 TrainAcc 0.7800 TestAcc 0.5746 0.7750
epoch 2500 LossPred 0.5393 LossAtt 0.3317 TrainAcc 0.8300 TestAcc 0.5806 0.7900
Optimization Finished!
********** replication  93  **********
epoch   0 LossPred 1.1211 LossAtt 1.0049 TrainAcc 0.4800 TestAcc 0.4550 0.4900
epoch 100 LossPred 0.9920 LossAtt 0.2394 TrainAcc 0.4900 TestAcc 0.5063 0.5400
epoch 200 LossPred 0.9714 LossAtt 0.2203 TrainAcc 0.6000 TestAcc 0.5563 0.6150
epoch 300 LossPred 0.9467 LossAtt 0.1942 TrainAcc 0.5900 TestAcc 0.5420 0.5900
epoch 400 LossPred 0.8952 LossAtt 0.2547 TrainAcc 0.6700 TestAcc 0.5608 0.6700
epoch 500 LossPred 1.1066 LossAtt 0.2559 TrainAcc 0.5600 TestAcc 0.5413 0.5400
epoch 600 LossPred 0.9450 LossAtt 0.2345 TrainAcc 0.6200 TestAcc 0.6299 0.6200
epoch 700 LossPred 0.4918 LossAtt 0.2158 TrainAcc 0.8400 TestAcc 0.7773 0.8350
epoch 800 LossPred 0.8074 LossAtt 0.2116 TrainAcc 0.7400 TestAcc 0.6854 0.7400
epoch 900 LossPred 0.6515 LossAtt 0.2108 TrainAcc 0.7600 TestAcc 0.7525 0.7650
epoch 1000 LossPred 0.6059 LossAtt 0.2106 TrainAcc 0.7800 TestAcc 0.7555 0.7600
epoch 1100 LossPred 0.3568 LossAtt 0.2179 TrainAcc 0.9000 TestAcc 0.8298 0.8700
epoch 1200 LossPred 0.2613 LossAtt 0.2290 TrainAcc 0.9000 TestAcc 0.8308 0.9000
epoch 1300 LossPred 0.2854 LossAtt 0.2380 TrainAcc 0.9000 TestAcc 0.8176 0.8950
epoch 1400 LossPred 0.2446 LossAtt 0.2323 TrainAcc 0.9000 TestAcc 0.8451 0.8950
epoch 1500 LossPred 0.2391 LossAtt 0.2349 TrainAcc 0.9200 TestAcc 0.8413 0.8900
epoch 1600 LossPred 0.3627 LossAtt 0.2369 TrainAcc 0.8700 TestAcc 0.7965 0.8650
epoch 1700 LossPred 0.2348 LossAtt 0.2365 TrainAcc 0.9100 TestAcc 0.8386 0.9250
epoch 1800 LossPred 0.4102 LossAtt 0.2264 TrainAcc 0.8500 TestAcc 0.8258 0.8400
epoch 1900 LossPred 0.2630 LossAtt 0.2304 TrainAcc 0.9200 TestAcc 0.8478 0.9100
epoch 2000 LossPred 0.2906 LossAtt 0.2254 TrainAcc 0.9000 TestAcc 0.8318 0.8900
epoch 2100 LossPred 0.2605 LossAtt 0.2283 TrainAcc 0.9200 TestAcc 0.8448 0.9050
epoch 2200 LossPred 0.2197 LossAtt 0.2260 TrainAcc 0.9400 TestAcc 0.8406 0.9400
epoch 2300 LossPred 0.3655 LossAtt 0.2251 TrainAcc 0.8700 TestAcc 0.7930 0.8600
epoch 2400 LossPred 0.2057 LossAtt 0.2200 TrainAcc 0.9500 TestAcc 0.8396 0.9350
epoch 2500 LossPred 0.2127 LossAtt 0.2186 TrainAcc 0.9400 TestAcc 0.8366 0.9400
Optimization Finished!
********** replication  94  **********
epoch   0 LossPred 1.1587 LossAtt 1.0089 TrainAcc 0.5400 TestAcc 0.4697 0.5150
epoch 100 LossPred 0.9283 LossAtt 0.2938 TrainAcc 0.5500 TestAcc 0.5165 0.5400
epoch 200 LossPred 0.9104 LossAtt 0.2280 TrainAcc 0.5300 TestAcc 0.5601 0.5350
epoch 300 LossPred 0.8978 LossAtt 0.2136 TrainAcc 0.5600 TestAcc 0.5751 0.5500
epoch 400 LossPred 0.8907 LossAtt 0.2127 TrainAcc 0.5800 TestAcc 0.5653 0.5700
epoch 500 LossPred 0.8886 LossAtt 0.2227 TrainAcc 0.5900 TestAcc 0.5215 0.5700
epoch 600 LossPred 0.8415 LossAtt 0.3045 TrainAcc 0.6700 TestAcc 0.5410 0.6450
epoch 700 LossPred 0.7786 LossAtt 0.3357 TrainAcc 0.6900 TestAcc 0.5538 0.6650
epoch 800 LossPred 0.7232 LossAtt 0.3615 TrainAcc 0.7300 TestAcc 0.5551 0.7250
epoch 900 LossPred 0.6754 LossAtt 0.4363 TrainAcc 0.7500 TestAcc 0.5811 0.7500
epoch 1000 LossPred 0.6330 LossAtt 0.4575 TrainAcc 0.8000 TestAcc 0.6592 0.7700
epoch 1100 LossPred 0.4123 LossAtt 0.4561 TrainAcc 0.8700 TestAcc 0.7090 0.8250
epoch 1200 LossPred 0.3566 LossAtt 0.4613 TrainAcc 0.8600 TestAcc 0.6939 0.8550
epoch 1300 LossPred 0.2572 LossAtt 0.4390 TrainAcc 0.9300 TestAcc 0.6907 0.8600
epoch 1400 LossPred 0.2328 LossAtt 0.4380 TrainAcc 0.9300 TestAcc 0.7035 0.8450
epoch 1500 LossPred 0.2252 LossAtt 0.4242 TrainAcc 0.9300 TestAcc 0.7065 0.8650
epoch 1600 LossPred 0.2075 LossAtt 0.4067 TrainAcc 0.9400 TestAcc 0.7095 0.8600
epoch 1700 LossPred 0.1967 LossAtt 0.4176 TrainAcc 0.9600 TestAcc 0.7027 0.8300
epoch 1800 LossPred 0.2038 LossAtt 0.4075 TrainAcc 0.9500 TestAcc 0.7032 0.8450
epoch 1900 LossPred 0.2010 LossAtt 0.3929 TrainAcc 0.9400 TestAcc 0.7047 0.8550
epoch 2000 LossPred 0.1951 LossAtt 0.4059 TrainAcc 0.9100 TestAcc 0.7042 0.8550
epoch 2100 LossPred 0.2277 LossAtt 0.4026 TrainAcc 0.9200 TestAcc 0.7110 0.8600
epoch 2200 LossPred 0.2600 LossAtt 0.3969 TrainAcc 0.9000 TestAcc 0.7090 0.8850
epoch 2300 LossPred 0.9032 LossAtt 0.4017 TrainAcc 0.7000 TestAcc 0.6406 0.7000
epoch 2400 LossPred 0.7361 LossAtt 0.3943 TrainAcc 0.7700 TestAcc 0.6149 0.7450
epoch 2500 LossPred 0.6640 LossAtt 0.3794 TrainAcc 0.8000 TestAcc 0.6231 0.7650
Optimization Finished!
********** replication  95  **********
epoch   0 LossPred 0.9498 LossAtt 1.0310 TrainAcc 0.5600 TestAcc 0.4997 0.5650
epoch 100 LossPred 0.8388 LossAtt 0.2977 TrainAcc 0.6900 TestAcc 0.6076 0.7050
epoch 200 LossPred 0.6706 LossAtt 0.3127 TrainAcc 0.7400 TestAcc 0.7102 0.7000
epoch 300 LossPred 0.5026 LossAtt 0.2764 TrainAcc 0.8200 TestAcc 0.7860 0.8000
epoch 400 LossPred 0.4256 LossAtt 0.2640 TrainAcc 0.8700 TestAcc 0.8051 0.8350
epoch 500 LossPred 0.4404 LossAtt 0.2605 TrainAcc 0.8600 TestAcc 0.7985 0.8250
epoch 600 LossPred 0.4253 LossAtt 0.2447 TrainAcc 0.8700 TestAcc 0.8028 0.8400
epoch 700 LossPred 0.4214 LossAtt 0.2472 TrainAcc 0.8700 TestAcc 0.8063 0.8350
epoch 800 LossPred 0.4358 LossAtt 0.2523 TrainAcc 0.8600 TestAcc 0.8158 0.8350
epoch 900 LossPred 0.4198 LossAtt 0.2460 TrainAcc 0.8700 TestAcc 0.8128 0.8350
epoch 1000 LossPred 0.4040 LossAtt 0.2311 TrainAcc 0.8700 TestAcc 0.8121 0.8200
epoch 1100 LossPred 0.4181 LossAtt 0.2367 TrainAcc 0.8700 TestAcc 0.8086 0.8300
epoch 1200 LossPred 0.4135 LossAtt 0.2311 TrainAcc 0.8600 TestAcc 0.8046 0.8250
epoch 1300 LossPred 0.4104 LossAtt 0.2285 TrainAcc 0.8700 TestAcc 0.8158 0.8350
epoch 1400 LossPred 0.6126 LossAtt 0.2286 TrainAcc 0.7600 TestAcc 0.7760 0.7750
epoch 1500 LossPred 0.3971 LossAtt 0.2287 TrainAcc 0.8800 TestAcc 0.8131 0.8300
epoch 1600 LossPred 0.3883 LossAtt 0.2214 TrainAcc 0.8700 TestAcc 0.8238 0.8350
epoch 1700 LossPred 0.6095 LossAtt 0.2354 TrainAcc 0.7800 TestAcc 0.7555 0.7650
epoch 1800 LossPred 0.4566 LossAtt 0.2363 TrainAcc 0.8500 TestAcc 0.8191 0.8300
epoch 1900 LossPred 0.4293 LossAtt 0.2288 TrainAcc 0.8400 TestAcc 0.8138 0.8350
epoch 2000 LossPred 0.4088 LossAtt 0.2203 TrainAcc 0.8800 TestAcc 0.8176 0.8400
epoch 2100 LossPred 0.6078 LossAtt 0.2183 TrainAcc 0.8000 TestAcc 0.8308 0.8150
epoch 2200 LossPred 0.3967 LossAtt 0.2185 TrainAcc 0.8800 TestAcc 0.8146 0.8300
epoch 2300 LossPred 0.3953 LossAtt 0.2145 TrainAcc 0.8600 TestAcc 0.8193 0.8150
epoch 2400 LossPred 0.4661 LossAtt 0.2182 TrainAcc 0.8200 TestAcc 0.8038 0.8000
epoch 2500 LossPred 0.4026 LossAtt 0.2154 TrainAcc 0.8400 TestAcc 0.8091 0.8100
Optimization Finished!
********** replication  96  **********
epoch   0 LossPred 1.1235 LossAtt 1.0080 TrainAcc 0.3900 TestAcc 0.4474 0.4050
epoch 100 LossPred 0.9480 LossAtt 0.2202 TrainAcc 0.6100 TestAcc 0.5816 0.6100
epoch 200 LossPred 0.9323 LossAtt 0.2178 TrainAcc 0.6200 TestAcc 0.6056 0.6100
epoch 300 LossPred 0.8208 LossAtt 0.3069 TrainAcc 0.7300 TestAcc 0.5976 0.7300
epoch 400 LossPred 0.4545 LossAtt 0.2922 TrainAcc 0.8600 TestAcc 0.8071 0.8800
epoch 500 LossPred 0.2975 LossAtt 0.2847 TrainAcc 0.9200 TestAcc 0.8326 0.9100
epoch 600 LossPred 0.2808 LossAtt 0.2746 TrainAcc 0.9200 TestAcc 0.8163 0.8950
epoch 700 LossPred 0.2249 LossAtt 0.2633 TrainAcc 0.9400 TestAcc 0.8514 0.9350
epoch 800 LossPred 0.1749 LossAtt 0.2601 TrainAcc 0.9500 TestAcc 0.8539 0.9300
epoch 900 LossPred 0.1413 LossAtt 0.2632 TrainAcc 0.9700 TestAcc 0.8634 0.9300
epoch 1000 LossPred 0.1644 LossAtt 0.2714 TrainAcc 0.9500 TestAcc 0.8579 0.9100
epoch 1100 LossPred 0.4192 LossAtt 0.2587 TrainAcc 0.8700 TestAcc 0.8068 0.8800
epoch 1200 LossPred 0.2853 LossAtt 0.2478 TrainAcc 0.9300 TestAcc 0.8331 0.8850
epoch 1300 LossPred 0.2099 LossAtt 0.2545 TrainAcc 0.9400 TestAcc 0.8534 0.9200
epoch 1400 LossPred 0.1659 LossAtt 0.2486 TrainAcc 0.9500 TestAcc 0.8473 0.9200
epoch 1500 LossPred 0.1184 LossAtt 0.2487 TrainAcc 0.9600 TestAcc 0.8631 0.9200
epoch 1600 LossPred 0.1145 LossAtt 0.2351 TrainAcc 0.9700 TestAcc 0.8666 0.9200
epoch 1700 LossPred 0.2445 LossAtt 0.2410 TrainAcc 0.9000 TestAcc 0.8411 0.9050
epoch 1800 LossPred 0.0838 LossAtt 0.2322 TrainAcc 0.9800 TestAcc 0.8671 0.9350
epoch 1900 LossPred 0.0948 LossAtt 0.2302 TrainAcc 0.9800 TestAcc 0.8656 0.9350
epoch 2000 LossPred 0.1417 LossAtt 0.2394 TrainAcc 0.9400 TestAcc 0.8491 0.9300
epoch 2100 LossPred 0.1619 LossAtt 0.2307 TrainAcc 0.9300 TestAcc 0.8514 0.9150
epoch 2200 LossPred 0.4536 LossAtt 0.2312 TrainAcc 0.8400 TestAcc 0.7815 0.8600
epoch 2300 LossPred 0.0922 LossAtt 0.2170 TrainAcc 0.9700 TestAcc 0.8483 0.9450
epoch 2400 LossPred 0.0805 LossAtt 0.2268 TrainAcc 0.9800 TestAcc 0.8589 0.9400
epoch 2500 LossPred 0.0769 LossAtt 0.2192 TrainAcc 0.9800 TestAcc 0.8644 0.9550
Optimization Finished!
********** replication  97  **********
epoch   0 LossPred 1.0513 LossAtt 1.0220 TrainAcc 0.3600 TestAcc 0.4259 0.3700
epoch 100 LossPred 0.8904 LossAtt 0.2875 TrainAcc 0.6400 TestAcc 0.5741 0.6250
epoch 200 LossPred 0.6609 LossAtt 0.3576 TrainAcc 0.7600 TestAcc 0.7515 0.7600
epoch 300 LossPred 0.5531 LossAtt 0.2661 TrainAcc 0.8400 TestAcc 0.8086 0.8400
epoch 400 LossPred 0.5330 LossAtt 0.2468 TrainAcc 0.8300 TestAcc 0.8013 0.8400
epoch 500 LossPred 0.4260 LossAtt 0.2391 TrainAcc 0.8700 TestAcc 0.8173 0.8350
epoch 600 LossPred 0.4362 LossAtt 0.2214 TrainAcc 0.8700 TestAcc 0.8323 0.8500
epoch 700 LossPred 0.4479 LossAtt 0.2228 TrainAcc 0.8500 TestAcc 0.8296 0.8650
epoch 800 LossPred 0.3864 LossAtt 0.2143 TrainAcc 0.8900 TestAcc 0.8428 0.8750
epoch 900 LossPred 0.3693 LossAtt 0.2088 TrainAcc 0.8900 TestAcc 0.8493 0.8650
epoch 1000 LossPred 0.3495 LossAtt 0.2060 TrainAcc 0.8900 TestAcc 0.8566 0.8600
epoch 1100 LossPred 0.2942 LossAtt 0.2076 TrainAcc 0.9000 TestAcc 0.8689 0.8850
epoch 1200 LossPred 0.2776 LossAtt 0.1981 TrainAcc 0.9200 TestAcc 0.8694 0.8800
epoch 1300 LossPred 0.3013 LossAtt 0.2010 TrainAcc 0.8900 TestAcc 0.8566 0.8750
epoch 1400 LossPred 0.2747 LossAtt 0.1919 TrainAcc 0.9000 TestAcc 0.8609 0.8850
epoch 1500 LossPred 0.2463 LossAtt 0.1855 TrainAcc 0.9000 TestAcc 0.8701 0.8900
epoch 1600 LossPred 0.2423 LossAtt 0.1753 TrainAcc 0.9200 TestAcc 0.8706 0.8850
epoch 1700 LossPred 0.2431 LossAtt 0.1724 TrainAcc 0.9100 TestAcc 0.8701 0.9000
epoch 1800 LossPred 0.2839 LossAtt 0.1735 TrainAcc 0.9000 TestAcc 0.8541 0.8850
epoch 1900 LossPred 0.2822 LossAtt 0.1724 TrainAcc 0.9000 TestAcc 0.8493 0.8850
epoch 2000 LossPred 0.2205 LossAtt 0.1823 TrainAcc 0.9200 TestAcc 0.8721 0.9100
epoch 2100 LossPred 0.2358 LossAtt 0.1704 TrainAcc 0.9200 TestAcc 0.8684 0.9000
epoch 2200 LossPred 0.2863 LossAtt 0.1673 TrainAcc 0.9000 TestAcc 0.8498 0.9100
epoch 2300 LossPred 0.2310 LossAtt 0.1607 TrainAcc 0.9200 TestAcc 0.8716 0.9050
epoch 2400 LossPred 0.2456 LossAtt 0.1609 TrainAcc 0.9200 TestAcc 0.8639 0.8950
epoch 2500 LossPred 0.2182 LossAtt 0.1597 TrainAcc 0.9400 TestAcc 0.8669 0.9100
Optimization Finished!
********** replication  98  **********
epoch   0 LossPred 1.0644 LossAtt 1.0372 TrainAcc 0.5300 TestAcc 0.5726 0.5200
epoch 100 LossPred 0.9224 LossAtt 0.2650 TrainAcc 0.6300 TestAcc 0.5390 0.6350
epoch 200 LossPred 0.9149 LossAtt 0.2028 TrainAcc 0.6400 TestAcc 0.5255 0.6350
epoch 300 LossPred 0.9059 LossAtt 0.1932 TrainAcc 0.6400 TestAcc 0.5478 0.6400
epoch 400 LossPred 0.9018 LossAtt 0.2051 TrainAcc 0.6400 TestAcc 0.5478 0.6400
epoch 500 LossPred 0.8959 LossAtt 0.2268 TrainAcc 0.6400 TestAcc 0.5508 0.6450
epoch 600 LossPred 0.8375 LossAtt 0.3302 TrainAcc 0.6500 TestAcc 0.5395 0.6400
epoch 700 LossPred 0.7815 LossAtt 0.2710 TrainAcc 0.6900 TestAcc 0.5430 0.6950
epoch 800 LossPred 0.7453 LossAtt 0.2792 TrainAcc 0.7000 TestAcc 0.5390 0.7150
epoch 900 LossPred 0.7494 LossAtt 0.2961 TrainAcc 0.7300 TestAcc 0.5288 0.7150
epoch 1000 LossPred 0.6487 LossAtt 0.2929 TrainAcc 0.7500 TestAcc 0.5303 0.7300
epoch 1100 LossPred 0.7053 LossAtt 0.2900 TrainAcc 0.7300 TestAcc 0.5318 0.7000
epoch 1200 LossPred 0.6054 LossAtt 0.2848 TrainAcc 0.7900 TestAcc 0.5445 0.7250
epoch 1300 LossPred 0.6187 LossAtt 0.2770 TrainAcc 0.7900 TestAcc 0.5378 0.7350
epoch 1400 LossPred 0.6290 LossAtt 0.2849 TrainAcc 0.7800 TestAcc 0.5458 0.7050
epoch 1500 LossPred 0.5969 LossAtt 0.3045 TrainAcc 0.7900 TestAcc 0.5425 0.7400
epoch 1600 LossPred 0.6563 LossAtt 0.3079 TrainAcc 0.7800 TestAcc 0.5445 0.7550
epoch 1700 LossPred 0.5979 LossAtt 0.3014 TrainAcc 0.7900 TestAcc 0.5393 0.7450
epoch 1800 LossPred 0.5736 LossAtt 0.2948 TrainAcc 0.8000 TestAcc 0.5318 0.7400
epoch 1900 LossPred 0.5594 LossAtt 0.3016 TrainAcc 0.7900 TestAcc 0.5258 0.7500
epoch 2000 LossPred 0.5595 LossAtt 0.3132 TrainAcc 0.7900 TestAcc 0.5235 0.7250
epoch 2100 LossPred 0.5570 LossAtt 0.2973 TrainAcc 0.8000 TestAcc 0.5253 0.7200
epoch 2200 LossPred 0.5582 LossAtt 0.3085 TrainAcc 0.8000 TestAcc 0.5220 0.7300
epoch 2300 LossPred 0.5482 LossAtt 0.3036 TrainAcc 0.8100 TestAcc 0.5293 0.7300
epoch 2400 LossPred 0.5552 LossAtt 0.2923 TrainAcc 0.8200 TestAcc 0.5358 0.7150
epoch 2500 LossPred 0.5858 LossAtt 0.2809 TrainAcc 0.8000 TestAcc 0.5348 0.7200
Optimization Finished!
********** replication  99  **********
epoch   0 LossPred 1.0009 LossAtt 0.9998 TrainAcc 0.5400 TestAcc 0.5228 0.5350
epoch 100 LossPred 0.9322 LossAtt 0.2730 TrainAcc 0.6200 TestAcc 0.5278 0.6200
epoch 200 LossPred 0.8694 LossAtt 0.2724 TrainAcc 0.6700 TestAcc 0.5370 0.6750
epoch 300 LossPred 0.8250 LossAtt 0.2804 TrainAcc 0.7000 TestAcc 0.5403 0.7000
epoch 400 LossPred 0.8131 LossAtt 0.3211 TrainAcc 0.6900 TestAcc 0.5428 0.7000
epoch 500 LossPred 0.7536 LossAtt 0.3396 TrainAcc 0.7100 TestAcc 0.5473 0.6600
epoch 600 LossPred 0.7388 LossAtt 0.3246 TrainAcc 0.7300 TestAcc 0.5373 0.6850
epoch 700 LossPred 0.7334 LossAtt 0.3060 TrainAcc 0.7300 TestAcc 0.5370 0.7150
epoch 800 LossPred 0.7148 LossAtt 0.3084 TrainAcc 0.7300 TestAcc 0.5325 0.7000
epoch 900 LossPred 0.7161 LossAtt 0.2991 TrainAcc 0.7600 TestAcc 0.5405 0.7250
epoch 1000 LossPred 0.7001 LossAtt 0.2977 TrainAcc 0.7700 TestAcc 0.5345 0.6900
epoch 1100 LossPred 0.8115 LossAtt 0.3103 TrainAcc 0.6900 TestAcc 0.5255 0.6350
epoch 1200 LossPred 0.6959 LossAtt 0.2957 TrainAcc 0.7400 TestAcc 0.5298 0.6950
epoch 1300 LossPred 0.7468 LossAtt 0.2944 TrainAcc 0.7200 TestAcc 0.5290 0.6750
epoch 1400 LossPred 0.6869 LossAtt 0.2774 TrainAcc 0.7800 TestAcc 0.5373 0.6800
epoch 1500 LossPred 0.6919 LossAtt 0.2756 TrainAcc 0.8100 TestAcc 0.5315 0.6850
epoch 1600 LossPred 0.7240 LossAtt 0.2713 TrainAcc 0.7300 TestAcc 0.5218 0.7150
epoch 1700 LossPred 0.6565 LossAtt 0.2616 TrainAcc 0.7800 TestAcc 0.5380 0.7000
epoch 1800 LossPred 0.6375 LossAtt 0.2732 TrainAcc 0.7900 TestAcc 0.5365 0.7350
epoch 1900 LossPred 0.6082 LossAtt 0.2627 TrainAcc 0.7900 TestAcc 0.5378 0.7350
epoch 2000 LossPred 0.6088 LossAtt 0.2566 TrainAcc 0.7900 TestAcc 0.5313 0.7300
epoch 2100 LossPred 0.6247 LossAtt 0.2593 TrainAcc 0.7800 TestAcc 0.5370 0.7150
epoch 2200 LossPred 0.7306 LossAtt 0.2713 TrainAcc 0.7400 TestAcc 0.5395 0.6750
epoch 2300 LossPred 0.6230 LossAtt 0.2557 TrainAcc 0.7700 TestAcc 0.5263 0.7400
epoch 2400 LossPred 0.6066 LossAtt 0.2640 TrainAcc 0.8000 TestAcc 0.5300 0.7150
epoch 2500 LossPred 0.6123 LossAtt 0.2558 TrainAcc 0.7800 TestAcc 0.5303 0.7150
Optimization Finished!
********************************************************************
Namespace(arch='tanh', batch_size=256, display_epoch=100, input_noise_level=0.15, latent_attractor_space=True, loss_switch_frequency=0, lrate_attractor=0.002, lrate_prediction=0.002, lrate_wt_penalty=0.0, n_attractor_hidden=20, n_attractor_steps=5, n_hidden=10, n_replications=100, noise_level=0.5, report_best_train_performance=True, seq_len=25, task='majority', train_attr_weights_on_prediction=False, training_epochs=2500)
********************************************************************
mean train accuracy 0.9032
indiv runs  [0.9, 0.97, 0.94, 0.97, 0.97, 0.96, 0.92, 0.91, 0.95, 0.86, 0.92, 0.85, 0.86, 0.99, 0.95, 0.89, 0.94, 0.91, 0.9, 0.91, 0.95, 0.9, 0.96, 0.9, 0.71, 0.89, 0.9, 0.86, 0.99, 0.93, 0.92, 0.91, 0.89, 0.97, 0.82, 0.93, 0.95, 0.96, 0.91, 0.91, 0.93, 0.79, 0.93, 0.86, 0.91, 0.91, 0.9, 0.81, 0.91, 0.86, 0.84, 0.88, 0.94, 0.74, 0.96, 0.81, 0.96, 0.95, 0.92, 0.97, 0.85, 0.93, 0.99, 0.95, 0.97, 0.93, 0.86, 0.86, 0.88, 0.89, 0.98, 0.8, 0.96, 0.79, 0.74, 0.91, 0.93, 0.9, 0.85, 0.96, 0.86, 0.89, 0.97, 0.86, 0.93, 0.96, 0.96, 0.85, 0.95, 0.85, 0.96, 0.77, 0.83, 0.95, 0.96, 0.88, 0.98, 0.94, 0.82, 0.81]
mean epoch nan
indiv epochs  []
test1 accuracy mean  0.7803104  median  0.820946
test2 accuracy mean  0.8625  median  0.8775
test1 indiv runs  [0.8180681, 0.8330831, 0.8683684, 0.8721221, 0.8068068, 0.8180681, 0.8593594, 0.8536036, 0.8738739, 0.5185185, 0.8498498, 0.7217217, 0.8563564, 0.8521021, 0.8293293, 0.748999, 0.9041542, 0.7987988, 0.8518519, 0.8310811, 0.8413413, 0.8095596, 0.8736236, 0.7932933, 0.6383884, 0.8468468, 0.8561061, 0.769019, 0.8313313, 0.8455956, 0.8498498, 0.5665666, 0.5618118, 0.8133133, 0.7847848, 0.8148148, 0.8723724, 0.8541041, 0.8463463, 0.8020521, 0.8033033, 0.6686687, 0.8771271, 0.5392893, 0.8315816, 0.8548549, 0.779029, 0.5022523, 0.8333333, 0.8205706, 0.7532533, 0.8375876, 0.8648649, 0.7374875, 0.7972973, 0.792042, 0.7442442, 0.8068068, 0.8213213, 0.8666166, 0.7967968, 0.8811311, 0.8430931, 0.8495996, 0.8355856, 0.5272773, 0.8053053, 0.8596096, 0.8000501, 0.8170671, 0.8691191, 0.6996997, 0.8791291, 0.5342843, 0.5665666, 0.6206206, 0.8490991, 0.8483483, 0.7942943, 0.8618619, 0.8285786, 0.525025, 0.8263263, 0.5590591, 0.8581081, 0.7835335, 0.8390891, 0.5285285, 0.8668669, 0.7472472, 0.8648649, 0.7602603, 0.5795796, 0.8395896, 0.7027027, 0.8130631, 0.8671171, 0.8668669, 0.5357858, 0.5315315]
test2 indiv runs  [0.845, 0.88, 0.91, 0.965, 0.95, 0.915, 0.905, 0.835, 0.94, 0.78, 0.88, 0.815, 0.855, 0.97, 0.915, 0.89, 0.935, 0.87, 0.855, 0.87, 0.905, 0.875, 0.94, 0.89, 0.695, 0.875, 0.9, 0.835, 0.93, 0.86, 0.85, 0.79, 0.77, 0.95, 0.765, 0.88, 0.92, 0.935, 0.905, 0.85, 0.895, 0.81, 0.93, 0.785, 0.885, 0.895, 0.875, 0.68, 0.845, 0.815, 0.825, 0.825, 0.945, 0.72, 0.91, 0.805, 0.885, 0.89, 0.88, 0.935, 0.8, 0.905, 0.945, 0.925, 0.935, 0.855, 0.82, 0.805, 0.835, 0.87, 0.94, 0.79, 0.905, 0.745, 0.7, 0.83, 0.9, 0.885, 0.845, 0.955, 0.865, 0.8, 0.9, 0.76, 0.885, 0.92, 0.94, 0.765, 0.935, 0.845, 0.935, 0.745, 0.79, 0.935, 0.83, 0.83, 0.935, 0.91, 0.715, 0.685]
