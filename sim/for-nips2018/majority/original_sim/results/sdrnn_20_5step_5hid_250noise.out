Namespace(arch='tanh', batch_size=256, display_epoch=100, input_noise_level=0.15, latent_attractor_space=True, loss_switch_frequency=0, lrate_attractor=0.002, lrate_prediction=0.002, lrate_wt_penalty=0.0, n_attractor_hidden=10, n_attractor_steps=5, n_hidden=5, n_replications=100, noise_level=0.25, report_best_train_performance=True, seq_len=20, task='majority', train_attr_weights_on_prediction=False, training_epochs=2500)
TRAINING ON 100 EXAMPLES, TESTING ON 3996
********** replication  0  **********
epoch   0 LossPred 1.0475 LossAtt 1.0462 TrainAcc 0.5300 TestAcc 0.4820 0.5050
epoch 100 LossPred 0.8781 LossAtt 0.5790 TrainAcc 0.6500 TestAcc 0.5916 0.6500
epoch 200 LossPred 0.7753 LossAtt 0.5422 TrainAcc 0.7000 TestAcc 0.6111 0.7050
epoch 300 LossPred 0.3529 LossAtt 0.6655 TrainAcc 0.8800 TestAcc 0.8584 0.8550
epoch 400 LossPred 0.3373 LossAtt 0.6712 TrainAcc 0.8800 TestAcc 0.8378 0.8400
epoch 500 LossPred 0.2127 LossAtt 0.6811 TrainAcc 0.9500 TestAcc 0.8809 0.8750
epoch 600 LossPred 0.2746 LossAtt 0.6896 TrainAcc 0.9000 TestAcc 0.8416 0.8550
epoch 700 LossPred 0.1360 LossAtt 0.6491 TrainAcc 0.9600 TestAcc 0.8739 0.8900
epoch 800 LossPred 0.1406 LossAtt 0.6176 TrainAcc 0.9700 TestAcc 0.8739 0.8900
epoch 900 LossPred 0.2513 LossAtt 0.6279 TrainAcc 0.9300 TestAcc 0.8609 0.8900
epoch 1000 LossPred 0.2517 LossAtt 0.6052 TrainAcc 0.9200 TestAcc 0.8451 0.8350
epoch 1100 LossPred 0.2790 LossAtt 0.6321 TrainAcc 0.9100 TestAcc 0.8396 0.8500
epoch 1200 LossPred 0.1256 LossAtt 0.6349 TrainAcc 0.9700 TestAcc 0.8686 0.8700
epoch 1300 LossPred 0.1504 LossAtt 0.6237 TrainAcc 0.9400 TestAcc 0.8649 0.8900
epoch 1400 LossPred 0.1055 LossAtt 0.6166 TrainAcc 0.9700 TestAcc 0.8714 0.8900
epoch 1500 LossPred 0.1134 LossAtt 0.5967 TrainAcc 0.9600 TestAcc 0.8686 0.8900
epoch 1600 LossPred 0.0941 LossAtt 0.5846 TrainAcc 0.9800 TestAcc 0.8656 0.8800
epoch 1700 LossPred 0.1082 LossAtt 0.5877 TrainAcc 0.9700 TestAcc 0.8546 0.8700
epoch 1800 LossPred 0.1394 LossAtt 0.5598 TrainAcc 0.9400 TestAcc 0.8549 0.8750
epoch 1900 LossPred 0.1265 LossAtt 0.5818 TrainAcc 0.9600 TestAcc 0.8534 0.8900
epoch 2000 LossPred 0.2587 LossAtt 0.5832 TrainAcc 0.9300 TestAcc 0.8448 0.8750
epoch 2100 LossPred 0.1373 LossAtt 0.5808 TrainAcc 0.9500 TestAcc 0.8458 0.8550
epoch 2200 LossPred 0.2777 LossAtt 0.5769 TrainAcc 0.9100 TestAcc 0.8406 0.8650
epoch 2300 LossPred 0.1293 LossAtt 0.5651 TrainAcc 0.9400 TestAcc 0.8481 0.8900
epoch 2400 LossPred 0.0887 LossAtt 0.5696 TrainAcc 0.9800 TestAcc 0.8601 0.8950
epoch 2500 LossPred 0.0841 LossAtt 0.5559 TrainAcc 0.9800 TestAcc 0.8646 0.9100
Optimization Finished!
********** replication  1  **********
epoch   0 LossPred 1.5202 LossAtt 1.0072 TrainAcc 0.3400 TestAcc 0.4782 0.3450
epoch 100 LossPred 1.0336 LossAtt 0.3813 TrainAcc 0.5400 TestAcc 0.5838 0.5400
epoch 200 LossPred 0.8317 LossAtt 0.3091 TrainAcc 0.7200 TestAcc 0.5906 0.7200
epoch 300 LossPred 0.7909 LossAtt 0.1229 TrainAcc 0.7200 TestAcc 0.5906 0.7200
epoch 400 LossPred 0.7072 LossAtt 0.3583 TrainAcc 0.7900 TestAcc 0.6559 0.8050
epoch 500 LossPred 0.3126 LossAtt 0.5021 TrainAcc 0.9300 TestAcc 0.8666 0.8900
epoch 600 LossPred 0.2189 LossAtt 0.4830 TrainAcc 0.9600 TestAcc 0.8966 0.9100
epoch 700 LossPred 0.1957 LossAtt 0.4855 TrainAcc 0.9500 TestAcc 0.9009 0.8800
epoch 800 LossPred 0.1943 LossAtt 0.4637 TrainAcc 0.9600 TestAcc 0.9009 0.9150
epoch 900 LossPred 0.1803 LossAtt 0.4652 TrainAcc 0.9500 TestAcc 0.8936 0.9200
epoch 1000 LossPred 0.1600 LossAtt 0.4544 TrainAcc 0.9600 TestAcc 0.9102 0.9200
epoch 1100 LossPred 0.1622 LossAtt 0.4436 TrainAcc 0.9500 TestAcc 0.9064 0.9250
epoch 1200 LossPred 0.1402 LossAtt 0.4226 TrainAcc 0.9700 TestAcc 0.9197 0.9300
epoch 1300 LossPred 0.1351 LossAtt 0.4073 TrainAcc 0.9700 TestAcc 0.9254 0.9250
epoch 1400 LossPred 0.1348 LossAtt 0.4095 TrainAcc 0.9500 TestAcc 0.9187 0.9300
epoch 1500 LossPred 0.1194 LossAtt 0.3845 TrainAcc 0.9500 TestAcc 0.9274 0.9300
epoch 1600 LossPred 0.1074 LossAtt 0.3745 TrainAcc 0.9700 TestAcc 0.9367 0.9450
epoch 1700 LossPred 0.0925 LossAtt 0.3623 TrainAcc 0.9700 TestAcc 0.9339 0.9400
epoch 1800 LossPred 0.0937 LossAtt 0.3640 TrainAcc 0.9900 TestAcc 0.9392 0.9500
epoch 1900 LossPred 0.1024 LossAtt 0.3591 TrainAcc 0.9600 TestAcc 0.9164 0.9400
epoch 2000 LossPred 0.0777 LossAtt 0.3254 TrainAcc 0.9800 TestAcc 0.9304 0.9400
epoch 2100 LossPred 0.0773 LossAtt 0.3342 TrainAcc 0.9800 TestAcc 0.9267 0.9500
epoch 2200 LossPred 0.1073 LossAtt 0.3469 TrainAcc 1.0000 TestAcc 0.9264 0.9400
Optimization Finished!
********** replication  2  **********
epoch   0 LossPred 1.0882 LossAtt 1.0293 TrainAcc 0.4400 TestAcc 0.4652 0.5000
epoch 100 LossPred 0.9641 LossAtt 0.4128 TrainAcc 0.5700 TestAcc 0.5921 0.5650
epoch 200 LossPred 0.9264 LossAtt 0.4292 TrainAcc 0.5800 TestAcc 0.5741 0.5550
epoch 300 LossPred 0.8885 LossAtt 0.4469 TrainAcc 0.6100 TestAcc 0.5003 0.6350
epoch 400 LossPred 0.8808 LossAtt 0.4256 TrainAcc 0.6100 TestAcc 0.5010 0.6150
epoch 500 LossPred 0.8407 LossAtt 0.4668 TrainAcc 0.6100 TestAcc 0.5118 0.6050
epoch 600 LossPred 0.8072 LossAtt 0.4753 TrainAcc 0.6800 TestAcc 0.5095 0.6500
epoch 700 LossPred 0.7745 LossAtt 0.4912 TrainAcc 0.7000 TestAcc 0.5063 0.6850
epoch 800 LossPred 0.7571 LossAtt 0.4842 TrainAcc 0.7100 TestAcc 0.4887 0.6650
epoch 900 LossPred 0.7552 LossAtt 0.5032 TrainAcc 0.7100 TestAcc 0.4860 0.6750
epoch 1000 LossPred 0.7560 LossAtt 0.4827 TrainAcc 0.7100 TestAcc 0.4862 0.6750
epoch 1100 LossPred 0.7531 LossAtt 0.4991 TrainAcc 0.7100 TestAcc 0.4820 0.6800
epoch 1200 LossPred 0.7472 LossAtt 0.4764 TrainAcc 0.7100 TestAcc 0.4840 0.6750
epoch 1300 LossPred 0.7474 LossAtt 0.4751 TrainAcc 0.7400 TestAcc 0.4807 0.6600
epoch 1400 LossPred 0.7512 LossAtt 0.4414 TrainAcc 0.7100 TestAcc 0.4877 0.6750
epoch 1500 LossPred 0.7406 LossAtt 0.4413 TrainAcc 0.7100 TestAcc 0.4820 0.6650
epoch 1600 LossPred 0.7451 LossAtt 0.4099 TrainAcc 0.7100 TestAcc 0.4872 0.6850
epoch 1700 LossPred 0.7464 LossAtt 0.3971 TrainAcc 0.7100 TestAcc 0.4860 0.6850
epoch 1800 LossPred 0.7451 LossAtt 0.4026 TrainAcc 0.7100 TestAcc 0.4885 0.6800
epoch 1900 LossPred 0.7532 LossAtt 0.3753 TrainAcc 0.7000 TestAcc 0.4852 0.6850
epoch 2000 LossPred 0.7810 LossAtt 0.3842 TrainAcc 0.6900 TestAcc 0.4910 0.6650
epoch 2100 LossPred 0.7680 LossAtt 0.4679 TrainAcc 0.7100 TestAcc 0.4825 0.6550
epoch 2200 LossPred 0.7622 LossAtt 0.4345 TrainAcc 0.7100 TestAcc 0.4915 0.6700
epoch 2300 LossPred 0.7456 LossAtt 0.4412 TrainAcc 0.7400 TestAcc 0.4777 0.6800
epoch 2400 LossPred 0.7381 LossAtt 0.4038 TrainAcc 0.7500 TestAcc 0.4875 0.6800
epoch 2500 LossPred 0.7613 LossAtt 0.4016 TrainAcc 0.7300 TestAcc 0.4920 0.6600
Optimization Finished!
********** replication  3  **********
epoch   0 LossPred 1.1259 LossAtt 1.0251 TrainAcc 0.4400 TestAcc 0.4630 0.4500
epoch 100 LossPred 0.9782 LossAtt 0.3513 TrainAcc 0.6100 TestAcc 0.5916 0.6050
epoch 200 LossPred 0.9558 LossAtt 0.1738 TrainAcc 0.6100 TestAcc 0.5916 0.6100
epoch 300 LossPred 0.9604 LossAtt 0.1202 TrainAcc 0.6100 TestAcc 0.5916 0.6100
epoch 400 LossPred 0.9702 LossAtt 0.1453 TrainAcc 0.6100 TestAcc 0.5916 0.6100
epoch 500 LossPred 0.9572 LossAtt 0.2440 TrainAcc 0.6100 TestAcc 0.5916 0.6100
epoch 600 LossPred 0.9286 LossAtt 0.4203 TrainAcc 0.6100 TestAcc 0.5916 0.6100
epoch 700 LossPred 0.5853 LossAtt 0.5315 TrainAcc 0.7800 TestAcc 0.7670 0.7600
epoch 800 LossPred 0.4301 LossAtt 0.5041 TrainAcc 0.8500 TestAcc 0.8228 0.8250
epoch 900 LossPred 0.4103 LossAtt 0.5141 TrainAcc 0.8400 TestAcc 0.8331 0.8350
epoch 1000 LossPred 0.3913 LossAtt 0.5081 TrainAcc 0.8600 TestAcc 0.8446 0.8400
epoch 1100 LossPred 0.3707 LossAtt 0.5218 TrainAcc 0.8700 TestAcc 0.8561 0.8550
epoch 1200 LossPred 0.3770 LossAtt 0.5273 TrainAcc 0.8700 TestAcc 0.8529 0.8500
epoch 1300 LossPred 0.3553 LossAtt 0.5383 TrainAcc 0.9000 TestAcc 0.8704 0.8650
epoch 1400 LossPred 0.2969 LossAtt 0.5540 TrainAcc 0.9100 TestAcc 0.8749 0.8700
epoch 1500 LossPred 0.2589 LossAtt 0.5593 TrainAcc 0.9200 TestAcc 0.8779 0.8800
epoch 1600 LossPred 0.2406 LossAtt 0.5518 TrainAcc 0.9300 TestAcc 0.8839 0.8950
epoch 1700 LossPred 0.2909 LossAtt 0.5662 TrainAcc 0.9100 TestAcc 0.8626 0.8750
epoch 1800 LossPred 0.2419 LossAtt 0.5528 TrainAcc 0.9100 TestAcc 0.8751 0.8850
epoch 1900 LossPred 0.2166 LossAtt 0.5712 TrainAcc 0.9300 TestAcc 0.8839 0.9100
epoch 2000 LossPred 0.2071 LossAtt 0.5330 TrainAcc 0.9300 TestAcc 0.8891 0.9150
epoch 2100 LossPred 0.2033 LossAtt 0.5590 TrainAcc 0.9400 TestAcc 0.8941 0.9050
epoch 2200 LossPred 0.2082 LossAtt 0.5361 TrainAcc 0.9400 TestAcc 0.8956 0.9200
epoch 2300 LossPred 0.3361 LossAtt 0.5661 TrainAcc 0.8600 TestAcc 0.8604 0.8850
epoch 2400 LossPred 0.1896 LossAtt 0.5322 TrainAcc 0.9300 TestAcc 0.8956 0.9200
epoch 2500 LossPred 0.1941 LossAtt 0.5360 TrainAcc 0.9400 TestAcc 0.9014 0.9050
Optimization Finished!
********** replication  4  **********
epoch   0 LossPred 1.1668 LossAtt 1.0108 TrainAcc 0.5100 TestAcc 0.4740 0.5050
epoch 100 LossPred 0.9981 LossAtt 0.5561 TrainAcc 0.5600 TestAcc 0.5053 0.5550
epoch 200 LossPred 0.9612 LossAtt 0.6007 TrainAcc 0.5800 TestAcc 0.4942 0.5700
epoch 300 LossPred 0.8950 LossAtt 0.6097 TrainAcc 0.6900 TestAcc 0.5395 0.6850
epoch 400 LossPred 0.8299 LossAtt 0.5689 TrainAcc 0.7300 TestAcc 0.5633 0.6900
epoch 500 LossPred 0.7714 LossAtt 0.6314 TrainAcc 0.7600 TestAcc 0.5871 0.7150
epoch 600 LossPred 0.7124 LossAtt 0.6585 TrainAcc 0.7700 TestAcc 0.6089 0.7300
epoch 700 LossPred 0.5964 LossAtt 0.7600 TrainAcc 0.8000 TestAcc 0.6577 0.7500
epoch 800 LossPred 0.4008 LossAtt 0.7056 TrainAcc 0.8300 TestAcc 0.7988 0.8100
epoch 900 LossPred 0.2734 LossAtt 0.6766 TrainAcc 0.9400 TestAcc 0.8253 0.8600
epoch 1000 LossPred 0.2475 LossAtt 0.6864 TrainAcc 0.9300 TestAcc 0.8261 0.8500
epoch 1100 LossPred 0.2282 LossAtt 0.6602 TrainAcc 0.9300 TestAcc 0.8286 0.8350
epoch 1200 LossPred 0.2225 LossAtt 0.6317 TrainAcc 0.9300 TestAcc 0.8346 0.8300
epoch 1300 LossPred 0.3926 LossAtt 0.6373 TrainAcc 0.8700 TestAcc 0.7920 0.8350
epoch 1400 LossPred 0.2405 LossAtt 0.6118 TrainAcc 0.9200 TestAcc 0.8333 0.8300
epoch 1500 LossPred 0.2441 LossAtt 0.6168 TrainAcc 0.9100 TestAcc 0.8368 0.8300
epoch 1600 LossPred 0.2271 LossAtt 0.6243 TrainAcc 0.9200 TestAcc 0.8291 0.8300
epoch 1700 LossPred 0.2321 LossAtt 0.6117 TrainAcc 0.9200 TestAcc 0.8356 0.8500
epoch 1800 LossPred 0.2129 LossAtt 0.6235 TrainAcc 0.9200 TestAcc 0.8356 0.8250
epoch 1900 LossPred 0.2050 LossAtt 0.6256 TrainAcc 0.9300 TestAcc 0.8361 0.8400
epoch 2000 LossPred 0.2091 LossAtt 0.6112 TrainAcc 0.9300 TestAcc 0.8413 0.8400
epoch 2100 LossPred 0.2088 LossAtt 0.6093 TrainAcc 0.9400 TestAcc 0.8491 0.8350
epoch 2200 LossPred 0.2042 LossAtt 0.5955 TrainAcc 0.9400 TestAcc 0.8423 0.8500
epoch 2300 LossPred 0.2065 LossAtt 0.6141 TrainAcc 0.9300 TestAcc 0.8456 0.8650
epoch 2400 LossPred 0.1945 LossAtt 0.5917 TrainAcc 0.9300 TestAcc 0.8416 0.8450
epoch 2500 LossPred 0.2041 LossAtt 0.6004 TrainAcc 0.9300 TestAcc 0.8451 0.8650
Optimization Finished!
********** replication  5  **********
epoch   0 LossPred 1.0477 LossAtt 1.0110 TrainAcc 0.5200 TestAcc 0.4992 0.5150
epoch 100 LossPred 0.9357 LossAtt 0.5577 TrainAcc 0.6300 TestAcc 0.5398 0.6400
epoch 200 LossPred 0.9124 LossAtt 0.5625 TrainAcc 0.6500 TestAcc 0.5563 0.6500
epoch 300 LossPred 0.8765 LossAtt 0.5495 TrainAcc 0.6700 TestAcc 0.5578 0.6750
epoch 400 LossPred 0.8399 LossAtt 0.6391 TrainAcc 0.6900 TestAcc 0.5413 0.6750
epoch 500 LossPred 0.7876 LossAtt 0.6757 TrainAcc 0.6800 TestAcc 0.5440 0.6900
epoch 600 LossPred 0.7837 LossAtt 0.6561 TrainAcc 0.6900 TestAcc 0.5706 0.7050
epoch 700 LossPred 0.5140 LossAtt 0.6063 TrainAcc 0.8400 TestAcc 0.8116 0.8100
epoch 800 LossPred 0.4877 LossAtt 0.6158 TrainAcc 0.8300 TestAcc 0.7823 0.8000
epoch 900 LossPred 0.4644 LossAtt 0.5992 TrainAcc 0.8300 TestAcc 0.8136 0.8200
epoch 1000 LossPred 0.3694 LossAtt 0.5725 TrainAcc 0.8800 TestAcc 0.7963 0.8250
epoch 1100 LossPred 0.3596 LossAtt 0.5833 TrainAcc 0.9000 TestAcc 0.7943 0.8350
epoch 1200 LossPred 0.3184 LossAtt 0.5635 TrainAcc 0.9100 TestAcc 0.8086 0.8350
epoch 1300 LossPred 0.3496 LossAtt 0.5688 TrainAcc 0.9000 TestAcc 0.8161 0.8300
epoch 1400 LossPred 0.3120 LossAtt 0.5713 TrainAcc 0.9100 TestAcc 0.8046 0.8500
epoch 1500 LossPred 0.3328 LossAtt 0.5545 TrainAcc 0.8900 TestAcc 0.8101 0.8250
epoch 1600 LossPred 0.3317 LossAtt 0.5755 TrainAcc 0.9100 TestAcc 0.8128 0.8400
epoch 1700 LossPred 0.3119 LossAtt 0.5406 TrainAcc 0.9100 TestAcc 0.7998 0.8500
epoch 1800 LossPred 0.4000 LossAtt 0.5459 TrainAcc 0.8900 TestAcc 0.7928 0.8100
epoch 1900 LossPred 0.3611 LossAtt 0.5543 TrainAcc 0.8900 TestAcc 0.7925 0.8350
epoch 2000 LossPred 0.2890 LossAtt 0.5259 TrainAcc 0.9200 TestAcc 0.8008 0.8500
epoch 2100 LossPred 0.3116 LossAtt 0.5458 TrainAcc 0.9100 TestAcc 0.8048 0.8600
epoch 2200 LossPred 0.3328 LossAtt 0.5569 TrainAcc 0.9000 TestAcc 0.7928 0.8550
epoch 2300 LossPred 0.2977 LossAtt 0.5308 TrainAcc 0.9100 TestAcc 0.7915 0.8400
epoch 2400 LossPred 0.3029 LossAtt 0.5774 TrainAcc 0.9200 TestAcc 0.7705 0.8450
epoch 2500 LossPred 0.3054 LossAtt 0.5506 TrainAcc 0.9000 TestAcc 0.7918 0.8600
Optimization Finished!
********** replication  6  **********
epoch   0 LossPred 1.0240 LossAtt 1.0180 TrainAcc 0.4800 TestAcc 0.5115 0.4950
epoch 100 LossPred 0.9201 LossAtt 0.5774 TrainAcc 0.6600 TestAcc 0.6301 0.6600
epoch 200 LossPred 0.8707 LossAtt 0.4638 TrainAcc 0.6300 TestAcc 0.6464 0.6350
epoch 300 LossPred 0.7795 LossAtt 0.6297 TrainAcc 0.6800 TestAcc 0.6647 0.7100
epoch 400 LossPred 0.5629 LossAtt 0.6510 TrainAcc 0.8300 TestAcc 0.7690 0.8000
epoch 500 LossPred 0.4591 LossAtt 0.6458 TrainAcc 0.8600 TestAcc 0.7765 0.8350
epoch 600 LossPred 0.5070 LossAtt 0.6649 TrainAcc 0.8300 TestAcc 0.7650 0.8300
epoch 700 LossPred 0.3681 LossAtt 0.6495 TrainAcc 0.8800 TestAcc 0.7870 0.8550
epoch 800 LossPred 0.3694 LossAtt 0.6522 TrainAcc 0.8900 TestAcc 0.7985 0.8750
epoch 900 LossPred 0.2698 LossAtt 0.6802 TrainAcc 0.9400 TestAcc 0.7945 0.8900
epoch 1000 LossPred 0.2995 LossAtt 0.6796 TrainAcc 0.9000 TestAcc 0.7850 0.9000
epoch 1100 LossPred 0.2306 LossAtt 0.6720 TrainAcc 0.9300 TestAcc 0.7903 0.8900
epoch 1200 LossPred 0.2189 LossAtt 0.6861 TrainAcc 0.9400 TestAcc 0.7895 0.9000
epoch 1300 LossPred 0.2211 LossAtt 0.6812 TrainAcc 0.9300 TestAcc 0.7963 0.8850
epoch 1400 LossPred 0.2162 LossAtt 0.6674 TrainAcc 0.9300 TestAcc 0.7950 0.8900
epoch 1500 LossPred 0.1974 LossAtt 0.6751 TrainAcc 0.9600 TestAcc 0.7938 0.9050
epoch 1600 LossPred 0.1953 LossAtt 0.6731 TrainAcc 0.9600 TestAcc 0.7960 0.8950
epoch 1700 LossPred 0.1957 LossAtt 0.6841 TrainAcc 0.9500 TestAcc 0.7945 0.8750
epoch 1800 LossPred 0.1876 LossAtt 0.6604 TrainAcc 0.9600 TestAcc 0.7878 0.9000
epoch 1900 LossPred 0.1803 LossAtt 0.6650 TrainAcc 0.9600 TestAcc 0.7908 0.9000
epoch 2000 LossPred 0.1825 LossAtt 0.6780 TrainAcc 0.9600 TestAcc 0.7913 0.8950
epoch 2100 LossPred 0.1759 LossAtt 0.6927 TrainAcc 0.9600 TestAcc 0.7945 0.8850
epoch 2200 LossPred 0.1715 LossAtt 0.6703 TrainAcc 0.9600 TestAcc 0.7915 0.8850
epoch 2300 LossPred 0.1688 LossAtt 0.6567 TrainAcc 0.9600 TestAcc 0.7918 0.9050
epoch 2400 LossPred 0.1627 LossAtt 0.6838 TrainAcc 0.9600 TestAcc 0.7865 0.8950
epoch 2500 LossPred 0.1600 LossAtt 0.6801 TrainAcc 0.9600 TestAcc 0.7888 0.8900
Optimization Finished!
********** replication  7  **********
epoch   0 LossPred 1.0704 LossAtt 1.0257 TrainAcc 0.4800 TestAcc 0.5070 0.4700
epoch 100 LossPred 0.8735 LossAtt 0.5637 TrainAcc 0.6700 TestAcc 0.5931 0.6700
epoch 200 LossPred 0.8655 LossAtt 0.4932 TrainAcc 0.6700 TestAcc 0.5931 0.6700
epoch 300 LossPred 0.8611 LossAtt 0.3928 TrainAcc 0.6700 TestAcc 0.5931 0.6700
epoch 400 LossPred 0.8513 LossAtt 0.3932 TrainAcc 0.6700 TestAcc 0.5931 0.6700
epoch 500 LossPred 0.5682 LossAtt 0.4328 TrainAcc 0.8400 TestAcc 0.8493 0.8200
epoch 600 LossPred 0.5033 LossAtt 0.4013 TrainAcc 0.8100 TestAcc 0.8806 0.8050
epoch 700 LossPred 0.5663 LossAtt 0.3908 TrainAcc 0.8000 TestAcc 0.8183 0.8050
epoch 800 LossPred 0.4406 LossAtt 0.3735 TrainAcc 0.8100 TestAcc 0.8931 0.8400
epoch 900 LossPred 0.3994 LossAtt 0.3662 TrainAcc 0.8800 TestAcc 0.8944 0.8550
epoch 1000 LossPred 0.4870 LossAtt 0.3650 TrainAcc 0.8400 TestAcc 0.8549 0.8200
epoch 1100 LossPred 0.5113 LossAtt 0.3852 TrainAcc 0.8000 TestAcc 0.8468 0.8250
epoch 1200 LossPred 0.3820 LossAtt 0.3728 TrainAcc 0.8500 TestAcc 0.8979 0.8600
epoch 1300 LossPred 0.4361 LossAtt 0.3739 TrainAcc 0.8400 TestAcc 0.8796 0.8450
epoch 1400 LossPred 0.4973 LossAtt 0.3786 TrainAcc 0.7500 TestAcc 0.8639 0.7650
epoch 1500 LossPred 0.4146 LossAtt 0.3872 TrainAcc 0.8300 TestAcc 0.8939 0.8450
epoch 1600 LossPred 0.3580 LossAtt 0.3620 TrainAcc 0.9000 TestAcc 0.8816 0.8600
epoch 1700 LossPred 0.4007 LossAtt 0.3832 TrainAcc 0.8600 TestAcc 0.8879 0.8650
epoch 1800 LossPred 0.6389 LossAtt 0.3674 TrainAcc 0.8100 TestAcc 0.7893 0.8100
epoch 1900 LossPred 0.4502 LossAtt 0.4105 TrainAcc 0.8700 TestAcc 0.8549 0.8650
epoch 2000 LossPred 0.5206 LossAtt 0.3845 TrainAcc 0.8500 TestAcc 0.8066 0.8300
epoch 2100 LossPred 0.5292 LossAtt 0.3765 TrainAcc 0.8500 TestAcc 0.8026 0.8300
epoch 2200 LossPred 0.4633 LossAtt 0.4011 TrainAcc 0.8600 TestAcc 0.8246 0.8500
epoch 2300 LossPred 0.4002 LossAtt 0.4116 TrainAcc 0.8800 TestAcc 0.8809 0.8900
epoch 2400 LossPred 0.4433 LossAtt 0.3997 TrainAcc 0.8400 TestAcc 0.8724 0.8200
epoch 2500 LossPred 0.3693 LossAtt 0.3939 TrainAcc 0.8700 TestAcc 0.8661 0.8800
Optimization Finished!
********** replication  8  **********
epoch   0 LossPred 1.2534 LossAtt 1.0466 TrainAcc 0.4200 TestAcc 0.4157 0.4200
epoch 100 LossPred 0.9790 LossAtt 0.5449 TrainAcc 0.5800 TestAcc 0.5843 0.5800
epoch 200 LossPred 0.9620 LossAtt 0.4390 TrainAcc 0.5800 TestAcc 0.5843 0.5800
epoch 300 LossPred 0.9447 LossAtt 0.4042 TrainAcc 0.5800 TestAcc 0.5843 0.5700
epoch 400 LossPred 0.9107 LossAtt 0.4345 TrainAcc 0.6400 TestAcc 0.6266 0.6500
epoch 500 LossPred 0.5306 LossAtt 0.6742 TrainAcc 0.8600 TestAcc 0.7688 0.8400
epoch 600 LossPred 0.4105 LossAtt 0.5643 TrainAcc 0.8600 TestAcc 0.8363 0.8350
epoch 700 LossPred 0.3497 LossAtt 0.5670 TrainAcc 0.8700 TestAcc 0.8651 0.8550
epoch 800 LossPred 0.2631 LossAtt 0.5483 TrainAcc 0.9300 TestAcc 0.9032 0.8750
epoch 900 LossPred 0.2235 LossAtt 0.5538 TrainAcc 0.9200 TestAcc 0.9049 0.8900
epoch 1000 LossPred 0.2113 LossAtt 0.5508 TrainAcc 0.9400 TestAcc 0.9084 0.8950
epoch 1100 LossPred 0.2170 LossAtt 0.5616 TrainAcc 0.9200 TestAcc 0.8944 0.9050
epoch 1200 LossPred 0.1965 LossAtt 0.5409 TrainAcc 0.9400 TestAcc 0.9109 0.8900
epoch 1300 LossPred 0.2087 LossAtt 0.5577 TrainAcc 0.9300 TestAcc 0.8921 0.9100
epoch 1400 LossPred 0.1768 LossAtt 0.5530 TrainAcc 0.9500 TestAcc 0.9114 0.9100
epoch 1500 LossPred 0.1985 LossAtt 0.5330 TrainAcc 0.9700 TestAcc 0.9132 0.9200
epoch 1600 LossPred 0.1652 LossAtt 0.5288 TrainAcc 0.9500 TestAcc 0.9134 0.9300
epoch 1700 LossPred 0.1797 LossAtt 0.5518 TrainAcc 0.9500 TestAcc 0.9039 0.9200
epoch 1800 LossPred 0.1786 LossAtt 0.5500 TrainAcc 0.9600 TestAcc 0.8986 0.9350
epoch 1900 LossPred 0.2042 LossAtt 0.5353 TrainAcc 0.9300 TestAcc 0.8789 0.9100
epoch 2000 LossPred 0.1463 LossAtt 0.5163 TrainAcc 0.9500 TestAcc 0.9247 0.9450
epoch 2100 LossPred 0.1431 LossAtt 0.5031 TrainAcc 0.9500 TestAcc 0.9139 0.9450
epoch 2200 LossPred 0.1333 LossAtt 0.5107 TrainAcc 0.9700 TestAcc 0.9409 0.9600
epoch 2300 LossPred 0.2149 LossAtt 0.5009 TrainAcc 0.9300 TestAcc 0.8719 0.9050
epoch 2400 LossPred 0.1774 LossAtt 0.5001 TrainAcc 0.9300 TestAcc 0.8876 0.9550
epoch 2500 LossPred 0.1195 LossAtt 0.4978 TrainAcc 0.9700 TestAcc 0.9429 0.9700
Optimization Finished!
********** replication  9  **********
epoch   0 LossPred 1.0277 LossAtt 1.0108 TrainAcc 0.4900 TestAcc 0.4880 0.4900
epoch 100 LossPred 0.9603 LossAtt 0.3810 TrainAcc 0.5700 TestAcc 0.5933 0.5700
epoch 200 LossPred 0.9600 LossAtt 0.2337 TrainAcc 0.5700 TestAcc 0.5933 0.5700
epoch 300 LossPred 0.9600 LossAtt 0.2188 TrainAcc 0.5700 TestAcc 0.5933 0.5700
epoch 400 LossPred 0.9602 LossAtt 0.1838 TrainAcc 0.5700 TestAcc 0.5933 0.5700
epoch 500 LossPred 0.9601 LossAtt 0.1321 TrainAcc 0.5700 TestAcc 0.5933 0.5700
epoch 600 LossPred 0.9598 LossAtt 0.1082 TrainAcc 0.5700 TestAcc 0.5933 0.5700
epoch 700 LossPred 0.9592 LossAtt 0.1506 TrainAcc 0.5700 TestAcc 0.5933 0.5700
epoch 800 LossPred 0.9593 LossAtt 0.1799 TrainAcc 0.5700 TestAcc 0.5933 0.5700
epoch 900 LossPred 0.9604 LossAtt 0.1480 TrainAcc 0.5700 TestAcc 0.5933 0.5700
epoch 1000 LossPred 0.9577 LossAtt 0.3156 TrainAcc 0.6200 TestAcc 0.6391 0.6000
epoch 1100 LossPred 0.3210 LossAtt 0.4425 TrainAcc 0.8900 TestAcc 0.9024 0.8850
epoch 1200 LossPred 0.2090 LossAtt 0.4052 TrainAcc 0.9600 TestAcc 0.9349 0.9300
epoch 1300 LossPred 0.2105 LossAtt 0.3893 TrainAcc 0.9400 TestAcc 0.8991 0.8900
epoch 1400 LossPred 0.1858 LossAtt 0.3772 TrainAcc 0.9500 TestAcc 0.9287 0.9250
epoch 1500 LossPred 0.2558 LossAtt 0.4021 TrainAcc 0.9100 TestAcc 0.8616 0.8900
epoch 1600 LossPred 0.2054 LossAtt 0.4109 TrainAcc 0.9500 TestAcc 0.9079 0.9300
epoch 1700 LossPred 0.3626 LossAtt 0.4218 TrainAcc 0.8800 TestAcc 0.8606 0.8800
epoch 1800 LossPred 0.2336 LossAtt 0.4009 TrainAcc 0.9200 TestAcc 0.9117 0.9200
epoch 1900 LossPred 0.3333 LossAtt 0.4111 TrainAcc 0.8800 TestAcc 0.8666 0.8900
epoch 2000 LossPred 0.2476 LossAtt 0.4298 TrainAcc 0.9000 TestAcc 0.8651 0.8800
epoch 2100 LossPred 0.1502 LossAtt 0.4439 TrainAcc 0.9600 TestAcc 0.9104 0.9350
epoch 2200 LossPred 0.1754 LossAtt 0.4496 TrainAcc 0.9600 TestAcc 0.9099 0.9300
epoch 2300 LossPred 0.2451 LossAtt 0.4521 TrainAcc 0.9000 TestAcc 0.8498 0.8900
epoch 2400 LossPred 0.1612 LossAtt 0.4516 TrainAcc 0.9500 TestAcc 0.9107 0.9350
epoch 2500 LossPred 0.1424 LossAtt 0.4347 TrainAcc 0.9500 TestAcc 0.9109 0.9400
Optimization Finished!
********** replication  10  **********
epoch   0 LossPred 0.9369 LossAtt 1.0731 TrainAcc 0.6200 TestAcc 0.5881 0.6200
epoch 100 LossPred 0.7705 LossAtt 0.6887 TrainAcc 0.7000 TestAcc 0.6512 0.6850
epoch 200 LossPred 0.3850 LossAtt 0.6863 TrainAcc 0.8800 TestAcc 0.8719 0.8700
epoch 300 LossPred 0.2811 LossAtt 0.6164 TrainAcc 0.9300 TestAcc 0.8626 0.8650
epoch 400 LossPred 0.3205 LossAtt 0.5783 TrainAcc 0.9000 TestAcc 0.8731 0.8800
epoch 500 LossPred 0.2328 LossAtt 0.5201 TrainAcc 0.9400 TestAcc 0.8731 0.8750
epoch 600 LossPred 0.2083 LossAtt 0.5053 TrainAcc 0.9300 TestAcc 0.8851 0.8850
epoch 700 LossPred 0.1977 LossAtt 0.5091 TrainAcc 0.9200 TestAcc 0.8669 0.8600
epoch 800 LossPred 0.2219 LossAtt 0.5028 TrainAcc 0.9200 TestAcc 0.8854 0.8900
epoch 900 LossPred 0.2572 LossAtt 0.4827 TrainAcc 0.9000 TestAcc 0.8819 0.8800
epoch 1000 LossPred 0.1953 LossAtt 0.4963 TrainAcc 0.9300 TestAcc 0.8901 0.8750
epoch 1100 LossPred 0.1934 LossAtt 0.4946 TrainAcc 0.9200 TestAcc 0.8596 0.8650
epoch 1200 LossPred 0.2989 LossAtt 0.4815 TrainAcc 0.9100 TestAcc 0.8726 0.8700
epoch 1300 LossPred 0.2224 LossAtt 0.4646 TrainAcc 0.9200 TestAcc 0.8629 0.8600
epoch 1400 LossPred 0.1848 LossAtt 0.4454 TrainAcc 0.9400 TestAcc 0.8856 0.8950
epoch 1500 LossPred 0.1835 LossAtt 0.4361 TrainAcc 0.9500 TestAcc 0.8896 0.9000
epoch 1600 LossPred 0.2343 LossAtt 0.4393 TrainAcc 0.9100 TestAcc 0.8834 0.9100
epoch 1700 LossPred 0.1906 LossAtt 0.4103 TrainAcc 0.9300 TestAcc 0.8909 0.9250
epoch 1800 LossPred 0.2163 LossAtt 0.4256 TrainAcc 0.9300 TestAcc 0.8754 0.8950
epoch 1900 LossPred 0.4056 LossAtt 0.3928 TrainAcc 0.8700 TestAcc 0.8368 0.8700
epoch 2000 LossPred 0.2342 LossAtt 0.4164 TrainAcc 0.9200 TestAcc 0.8811 0.9100
epoch 2100 LossPred 0.1820 LossAtt 0.4047 TrainAcc 0.9500 TestAcc 0.8924 0.9400
epoch 2200 LossPred 0.1740 LossAtt 0.3820 TrainAcc 0.9500 TestAcc 0.8934 0.9400
epoch 2300 LossPred 0.2194 LossAtt 0.3874 TrainAcc 0.9300 TestAcc 0.8864 0.9150
epoch 2400 LossPred 0.1656 LossAtt 0.3840 TrainAcc 0.9500 TestAcc 0.8959 0.9450
epoch 2500 LossPred 0.1759 LossAtt 0.3855 TrainAcc 0.9400 TestAcc 0.8991 0.9350
Optimization Finished!
********** replication  11  **********
epoch   0 LossPred 1.2261 LossAtt 1.0200 TrainAcc 0.5300 TestAcc 0.5951 0.5150
epoch 100 LossPred 0.9735 LossAtt 0.5091 TrainAcc 0.5600 TestAcc 0.5658 0.5950
epoch 200 LossPred 0.9265 LossAtt 0.5307 TrainAcc 0.6500 TestAcc 0.6476 0.6500
epoch 300 LossPred 0.6357 LossAtt 0.7224 TrainAcc 0.8400 TestAcc 0.8158 0.8250
epoch 400 LossPred 0.4090 LossAtt 0.6329 TrainAcc 0.8700 TestAcc 0.8378 0.8300
epoch 500 LossPred 0.3724 LossAtt 0.6114 TrainAcc 0.8800 TestAcc 0.8471 0.8400
epoch 600 LossPred 0.3456 LossAtt 0.6361 TrainAcc 0.8900 TestAcc 0.8426 0.8450
epoch 700 LossPred 0.3394 LossAtt 0.6493 TrainAcc 0.8900 TestAcc 0.8524 0.8400
epoch 800 LossPred 0.3058 LossAtt 0.6870 TrainAcc 0.9000 TestAcc 0.8504 0.8500
epoch 900 LossPred 0.2660 LossAtt 0.6501 TrainAcc 0.9100 TestAcc 0.8576 0.8550
epoch 1000 LossPred 0.2530 LossAtt 0.6682 TrainAcc 0.9100 TestAcc 0.8531 0.8750
epoch 1100 LossPred 0.2438 LossAtt 0.6757 TrainAcc 0.9100 TestAcc 0.8566 0.8650
epoch 1200 LossPred 0.2323 LossAtt 0.6581 TrainAcc 0.9100 TestAcc 0.8569 0.8750
epoch 1300 LossPred 0.2786 LossAtt 0.6467 TrainAcc 0.9100 TestAcc 0.8574 0.8650
epoch 1400 LossPred 0.2344 LossAtt 0.6194 TrainAcc 0.8900 TestAcc 0.8514 0.8850
epoch 1500 LossPred 0.2205 LossAtt 0.6248 TrainAcc 0.9000 TestAcc 0.8561 0.8850
epoch 1600 LossPred 0.2203 LossAtt 0.6250 TrainAcc 0.9000 TestAcc 0.8536 0.8750
epoch 1700 LossPred 0.2309 LossAtt 0.6425 TrainAcc 0.9100 TestAcc 0.8576 0.8950
epoch 1800 LossPred 0.2293 LossAtt 0.6425 TrainAcc 0.9200 TestAcc 0.8604 0.8950
epoch 1900 LossPred 0.2076 LossAtt 0.6431 TrainAcc 0.9400 TestAcc 0.8649 0.8800
epoch 2000 LossPred 0.2491 LossAtt 0.6122 TrainAcc 0.9200 TestAcc 0.8601 0.8750
epoch 2100 LossPred 0.2121 LossAtt 0.6128 TrainAcc 0.9300 TestAcc 0.8546 0.8850
epoch 2200 LossPred 0.1968 LossAtt 0.6233 TrainAcc 0.9500 TestAcc 0.8624 0.8750
epoch 2300 LossPred 0.2007 LossAtt 0.6054 TrainAcc 0.9400 TestAcc 0.8631 0.8750
epoch 2400 LossPred 0.2112 LossAtt 0.6142 TrainAcc 0.9300 TestAcc 0.8671 0.8600
epoch 2500 LossPred 0.1900 LossAtt 0.6120 TrainAcc 0.9500 TestAcc 0.8646 0.8850
Optimization Finished!
********** replication  12  **********
epoch   0 LossPred 1.3605 LossAtt 1.0104 TrainAcc 0.4900 TestAcc 0.5165 0.4950
epoch 100 LossPred 1.0221 LossAtt 0.6558 TrainAcc 0.5600 TestAcc 0.5135 0.5750
epoch 200 LossPred 0.9179 LossAtt 0.6562 TrainAcc 0.6300 TestAcc 0.5816 0.5850
epoch 300 LossPred 0.8807 LossAtt 0.6953 TrainAcc 0.7100 TestAcc 0.5958 0.6600
epoch 400 LossPred 0.8304 LossAtt 0.7438 TrainAcc 0.7200 TestAcc 0.6206 0.7100
epoch 500 LossPred 0.7685 LossAtt 0.7609 TrainAcc 0.7300 TestAcc 0.6281 0.7250
epoch 600 LossPred 0.3726 LossAtt 0.7950 TrainAcc 0.8800 TestAcc 0.8266 0.8050
epoch 700 LossPred 0.3183 LossAtt 0.7943 TrainAcc 0.9100 TestAcc 0.8386 0.8500
epoch 800 LossPred 0.2845 LossAtt 0.7585 TrainAcc 0.9100 TestAcc 0.8549 0.8500
epoch 900 LossPred 0.2400 LossAtt 0.7205 TrainAcc 0.9500 TestAcc 0.8348 0.8650
epoch 1000 LossPred 0.2182 LossAtt 0.7079 TrainAcc 0.9500 TestAcc 0.8241 0.9000
epoch 1100 LossPred 0.2018 LossAtt 0.6851 TrainAcc 0.9500 TestAcc 0.8348 0.8950
epoch 1200 LossPred 0.1986 LossAtt 0.6720 TrainAcc 0.9500 TestAcc 0.8246 0.9000
epoch 1300 LossPred 0.1798 LossAtt 0.6627 TrainAcc 0.9500 TestAcc 0.8473 0.8950
epoch 1400 LossPred 0.1693 LossAtt 0.7065 TrainAcc 0.9500 TestAcc 0.8466 0.9100
epoch 1500 LossPred 0.1253 LossAtt 0.6713 TrainAcc 0.9700 TestAcc 0.8383 0.9200
epoch 1600 LossPred 0.1383 LossAtt 0.6551 TrainAcc 0.9600 TestAcc 0.8446 0.9200
epoch 1700 LossPred 0.1191 LossAtt 0.6528 TrainAcc 0.9700 TestAcc 0.8268 0.9200
epoch 1800 LossPred 0.1355 LossAtt 0.6556 TrainAcc 0.9700 TestAcc 0.8386 0.9250
epoch 1900 LossPred 0.1471 LossAtt 0.6701 TrainAcc 0.9500 TestAcc 0.8271 0.9300
epoch 2000 LossPred 0.1388 LossAtt 0.6415 TrainAcc 0.9600 TestAcc 0.8493 0.9100
epoch 2100 LossPred 0.1152 LossAtt 0.6535 TrainAcc 0.9700 TestAcc 0.8258 0.9150
epoch 2200 LossPred 0.1132 LossAtt 0.6360 TrainAcc 0.9700 TestAcc 0.8416 0.9200
epoch 2300 LossPred 0.1062 LossAtt 0.6416 TrainAcc 0.9700 TestAcc 0.8343 0.9250
epoch 2400 LossPred 0.1032 LossAtt 0.6183 TrainAcc 0.9700 TestAcc 0.8296 0.9200
epoch 2500 LossPred 0.1031 LossAtt 0.6383 TrainAcc 0.9700 TestAcc 0.8298 0.9200
Optimization Finished!
********** replication  13  **********
epoch   0 LossPred 1.1166 LossAtt 1.0417 TrainAcc 0.4500 TestAcc 0.4782 0.4450
epoch 100 LossPred 0.9292 LossAtt 0.5162 TrainAcc 0.6000 TestAcc 0.5921 0.6300
epoch 200 LossPred 0.9174 LossAtt 0.4499 TrainAcc 0.6400 TestAcc 0.6379 0.6350
epoch 300 LossPred 0.8469 LossAtt 0.5058 TrainAcc 0.6800 TestAcc 0.6904 0.6650
epoch 400 LossPred 0.5136 LossAtt 0.4842 TrainAcc 0.8400 TestAcc 0.8193 0.8050
epoch 500 LossPred 0.5323 LossAtt 0.4038 TrainAcc 0.8400 TestAcc 0.8078 0.8200
epoch 600 LossPred 0.5041 LossAtt 0.3870 TrainAcc 0.8400 TestAcc 0.8323 0.8100
epoch 700 LossPred 0.5076 LossAtt 0.4036 TrainAcc 0.8300 TestAcc 0.8276 0.8100
epoch 800 LossPred 0.6415 LossAtt 0.4128 TrainAcc 0.8000 TestAcc 0.7718 0.7550
epoch 900 LossPred 0.5329 LossAtt 0.4008 TrainAcc 0.8300 TestAcc 0.7928 0.7700
epoch 1000 LossPred 0.5247 LossAtt 0.3978 TrainAcc 0.8300 TestAcc 0.8416 0.7950
epoch 1100 LossPred 0.5242 LossAtt 0.3547 TrainAcc 0.8300 TestAcc 0.8198 0.7950
epoch 1200 LossPred 0.5468 LossAtt 0.3705 TrainAcc 0.8100 TestAcc 0.8308 0.8050
epoch 1300 LossPred 0.5325 LossAtt 0.3422 TrainAcc 0.8100 TestAcc 0.8086 0.7900
epoch 1400 LossPred 0.5257 LossAtt 0.3559 TrainAcc 0.8300 TestAcc 0.8163 0.8250
epoch 1500 LossPred 0.5210 LossAtt 0.3631 TrainAcc 0.8200 TestAcc 0.8238 0.8050
epoch 1600 LossPred 0.5259 LossAtt 0.3697 TrainAcc 0.8100 TestAcc 0.8386 0.8000
epoch 1700 LossPred 0.5285 LossAtt 0.3753 TrainAcc 0.8100 TestAcc 0.8098 0.8050
epoch 1800 LossPred 0.5113 LossAtt 0.3469 TrainAcc 0.8200 TestAcc 0.8311 0.8050
epoch 1900 LossPred 0.4815 LossAtt 0.3622 TrainAcc 0.8300 TestAcc 0.8331 0.8150
epoch 2000 LossPred 0.5148 LossAtt 0.3446 TrainAcc 0.8200 TestAcc 0.8321 0.8100
epoch 2100 LossPred 0.5098 LossAtt 0.3215 TrainAcc 0.8200 TestAcc 0.8253 0.8100
epoch 2200 LossPred 0.4926 LossAtt 0.3204 TrainAcc 0.8300 TestAcc 0.8509 0.8000
epoch 2300 LossPred 0.4798 LossAtt 0.3072 TrainAcc 0.8400 TestAcc 0.8393 0.8200
epoch 2400 LossPred 0.4988 LossAtt 0.2856 TrainAcc 0.8200 TestAcc 0.8326 0.8150
epoch 2500 LossPred 0.4845 LossAtt 0.2774 TrainAcc 0.8300 TestAcc 0.8579 0.8200
Optimization Finished!
********** replication  14  **********
epoch   0 LossPred 1.1624 LossAtt 1.0289 TrainAcc 0.4700 TestAcc 0.4434 0.4500
epoch 100 LossPred 0.9056 LossAtt 0.4342 TrainAcc 0.6200 TestAcc 0.5946 0.6300
epoch 200 LossPred 0.8897 LossAtt 0.3182 TrainAcc 0.6500 TestAcc 0.6171 0.6550
epoch 300 LossPred 0.8155 LossAtt 0.4163 TrainAcc 0.6900 TestAcc 0.6647 0.7000
epoch 400 LossPred 0.3716 LossAtt 0.5324 TrainAcc 0.9100 TestAcc 0.8804 0.8950
epoch 500 LossPred 0.3194 LossAtt 0.5478 TrainAcc 0.8700 TestAcc 0.9079 0.8900
epoch 600 LossPred 0.3000 LossAtt 0.5291 TrainAcc 0.9000 TestAcc 0.8789 0.9150
epoch 700 LossPred 0.2697 LossAtt 0.5321 TrainAcc 0.9100 TestAcc 0.9117 0.9100
epoch 800 LossPred 0.3391 LossAtt 0.5146 TrainAcc 0.8700 TestAcc 0.8876 0.8750
epoch 900 LossPred 0.2494 LossAtt 0.5201 TrainAcc 0.9200 TestAcc 0.8951 0.9150
epoch 1000 LossPred 0.3018 LossAtt 0.5196 TrainAcc 0.9000 TestAcc 0.8689 0.9150
epoch 1100 LossPred 0.2297 LossAtt 0.4944 TrainAcc 0.9300 TestAcc 0.9019 0.9200
epoch 1200 LossPred 0.2142 LossAtt 0.5063 TrainAcc 0.9300 TestAcc 0.8984 0.9250
epoch 1300 LossPred 0.3616 LossAtt 0.5104 TrainAcc 0.8800 TestAcc 0.8178 0.8950
epoch 1400 LossPred 0.2185 LossAtt 0.4628 TrainAcc 0.9400 TestAcc 0.8981 0.9450
epoch 1500 LossPred 0.1838 LossAtt 0.4829 TrainAcc 0.9400 TestAcc 0.8926 0.9400
epoch 1600 LossPred 0.3754 LossAtt 0.4561 TrainAcc 0.8600 TestAcc 0.8736 0.8550
epoch 1700 LossPred 0.1927 LossAtt 0.4622 TrainAcc 0.9500 TestAcc 0.8866 0.9450
epoch 1800 LossPred 0.2405 LossAtt 0.4702 TrainAcc 0.9300 TestAcc 0.8689 0.9250
epoch 1900 LossPred 0.1877 LossAtt 0.4282 TrainAcc 0.9500 TestAcc 0.9029 0.9500
epoch 2000 LossPred 0.1836 LossAtt 0.3953 TrainAcc 0.9500 TestAcc 0.9029 0.9450
epoch 2100 LossPred 0.1867 LossAtt 0.3955 TrainAcc 0.9500 TestAcc 0.8886 0.9550
epoch 2200 LossPred 0.2455 LossAtt 0.3834 TrainAcc 0.9300 TestAcc 0.8836 0.9150
epoch 2300 LossPred 0.1705 LossAtt 0.3849 TrainAcc 0.9600 TestAcc 0.9039 0.9550
epoch 2400 LossPred 0.2568 LossAtt 0.3749 TrainAcc 0.8700 TestAcc 0.8889 0.9100
epoch 2500 LossPred 0.1834 LossAtt 0.3571 TrainAcc 0.9400 TestAcc 0.9077 0.9450
Optimization Finished!
********** replication  15  **********
epoch   0 LossPred 1.1303 LossAtt 1.0653 TrainAcc 0.3700 TestAcc 0.4890 0.3700
epoch 100 LossPred 0.8191 LossAtt 0.5368 TrainAcc 0.7200 TestAcc 0.5926 0.7200
epoch 200 LossPred 0.7492 LossAtt 0.5518 TrainAcc 0.7200 TestAcc 0.5926 0.7200
epoch 300 LossPred 0.6316 LossAtt 0.5037 TrainAcc 0.7500 TestAcc 0.8026 0.7400
epoch 400 LossPred 0.4255 LossAtt 0.4778 TrainAcc 0.8300 TestAcc 0.8516 0.8250
epoch 500 LossPred 0.3539 LossAtt 0.4830 TrainAcc 0.8700 TestAcc 0.8666 0.8550
epoch 600 LossPred 0.3426 LossAtt 0.4597 TrainAcc 0.8900 TestAcc 0.8709 0.8650
epoch 700 LossPred 0.5539 LossAtt 0.4616 TrainAcc 0.8200 TestAcc 0.7367 0.8100
epoch 800 LossPred 0.3701 LossAtt 0.4599 TrainAcc 0.8800 TestAcc 0.8241 0.8600
epoch 900 LossPred 0.2389 LossAtt 0.4633 TrainAcc 0.9100 TestAcc 0.8766 0.8950
epoch 1000 LossPred 0.2181 LossAtt 0.4493 TrainAcc 0.9000 TestAcc 0.8809 0.9100
epoch 1100 LossPred 0.4796 LossAtt 0.4728 TrainAcc 0.8400 TestAcc 0.7563 0.8400
epoch 1200 LossPred 0.2205 LossAtt 0.4352 TrainAcc 0.9300 TestAcc 0.9124 0.8900
epoch 1300 LossPred 0.2205 LossAtt 0.4687 TrainAcc 0.9300 TestAcc 0.8771 0.9150
epoch 1400 LossPred 0.1371 LossAtt 0.4699 TrainAcc 0.9700 TestAcc 0.9427 0.9200
epoch 1500 LossPred 0.1280 LossAtt 0.4385 TrainAcc 0.9700 TestAcc 0.9124 0.9300
epoch 1600 LossPred 0.1731 LossAtt 0.4112 TrainAcc 0.9400 TestAcc 0.8901 0.9050
epoch 1700 LossPred 0.2599 LossAtt 0.3730 TrainAcc 0.9200 TestAcc 0.8456 0.8900
epoch 1800 LossPred 0.1151 LossAtt 0.3705 TrainAcc 0.9800 TestAcc 0.9224 0.9700
epoch 1900 LossPred 0.1198 LossAtt 0.3532 TrainAcc 0.9500 TestAcc 0.9172 0.9600
epoch 2000 LossPred 0.1160 LossAtt 0.3371 TrainAcc 0.9600 TestAcc 0.9242 0.9600
epoch 2100 LossPred 0.0847 LossAtt 0.3475 TrainAcc 0.9800 TestAcc 0.9447 0.9750
epoch 2200 LossPred 0.0887 LossAtt 0.3347 TrainAcc 0.9800 TestAcc 0.9462 0.9750
epoch 2300 LossPred 0.1475 LossAtt 0.3320 TrainAcc 0.9400 TestAcc 0.9047 0.9400
epoch 2400 LossPred 0.1703 LossAtt 0.3366 TrainAcc 0.9300 TestAcc 0.8796 0.9350
epoch 2500 LossPred 0.0785 LossAtt 0.3310 TrainAcc 0.9800 TestAcc 0.9494 0.9750
Optimization Finished!
********** replication  16  **********
epoch   0 LossPred 1.0182 LossAtt 1.0314 TrainAcc 0.5200 TestAcc 0.4872 0.5350
epoch 100 LossPred 0.9372 LossAtt 0.5064 TrainAcc 0.6000 TestAcc 0.5763 0.6000
epoch 200 LossPred 0.9300 LossAtt 0.2754 TrainAcc 0.6000 TestAcc 0.5763 0.6000
epoch 300 LossPred 0.9149 LossAtt 0.3392 TrainAcc 0.6500 TestAcc 0.6324 0.6350
epoch 400 LossPred 0.8794 LossAtt 0.4553 TrainAcc 0.6700 TestAcc 0.6629 0.6950
epoch 500 LossPred 0.9502 LossAtt 0.4368 TrainAcc 0.6700 TestAcc 0.6231 0.6750
epoch 600 LossPred 0.5627 LossAtt 0.4424 TrainAcc 0.8000 TestAcc 0.8091 0.7850
epoch 700 LossPred 0.3313 LossAtt 0.4198 TrainAcc 0.9000 TestAcc 0.8599 0.9050
epoch 800 LossPred 0.3010 LossAtt 0.4117 TrainAcc 0.9100 TestAcc 0.8666 0.8850
epoch 900 LossPred 0.2566 LossAtt 0.4203 TrainAcc 0.9300 TestAcc 0.8849 0.9100
epoch 1000 LossPred 0.2540 LossAtt 0.4001 TrainAcc 0.9100 TestAcc 0.8864 0.9150
epoch 1100 LossPred 0.2908 LossAtt 0.4013 TrainAcc 0.9100 TestAcc 0.8721 0.8950
epoch 1200 LossPred 0.2363 LossAtt 0.3759 TrainAcc 0.9400 TestAcc 0.8744 0.9350
epoch 1300 LossPred 0.3733 LossAtt 0.3842 TrainAcc 0.8700 TestAcc 0.8559 0.8800
epoch 1400 LossPred 0.5068 LossAtt 0.3653 TrainAcc 0.8100 TestAcc 0.8336 0.8400
epoch 1500 LossPred 0.3027 LossAtt 0.3487 TrainAcc 0.9000 TestAcc 0.8759 0.8950
epoch 1600 LossPred 0.5083 LossAtt 0.3318 TrainAcc 0.8300 TestAcc 0.8068 0.8250
epoch 1700 LossPred 0.7614 LossAtt 0.3338 TrainAcc 0.7500 TestAcc 0.7397 0.7500
epoch 1800 LossPred 0.4346 LossAtt 0.3409 TrainAcc 0.8300 TestAcc 0.8471 0.8450
epoch 1900 LossPred 0.5051 LossAtt 0.3321 TrainAcc 0.8300 TestAcc 0.8073 0.8350
epoch 2000 LossPred 0.3834 LossAtt 0.3328 TrainAcc 0.8800 TestAcc 0.8566 0.8700
epoch 2100 LossPred 0.5581 LossAtt 0.3174 TrainAcc 0.8100 TestAcc 0.7825 0.8050
epoch 2200 LossPred 0.3524 LossAtt 0.3241 TrainAcc 0.8800 TestAcc 0.8619 0.8900
epoch 2300 LossPred 0.4638 LossAtt 0.3183 TrainAcc 0.8500 TestAcc 0.8331 0.8600
epoch 2400 LossPred 0.2946 LossAtt 0.3294 TrainAcc 0.8800 TestAcc 0.8779 0.8950
epoch 2500 LossPred 0.2611 LossAtt 0.3330 TrainAcc 0.9100 TestAcc 0.8851 0.8900
Optimization Finished!
********** replication  17  **********
epoch   0 LossPred 1.1286 LossAtt 1.0295 TrainAcc 0.6300 TestAcc 0.5375 0.5900
epoch 100 LossPred 0.9309 LossAtt 0.6286 TrainAcc 0.6100 TestAcc 0.5858 0.6100
epoch 200 LossPred 0.8785 LossAtt 0.7118 TrainAcc 0.5800 TestAcc 0.6154 0.6150
epoch 300 LossPred 0.4151 LossAtt 0.6973 TrainAcc 0.8900 TestAcc 0.8881 0.8700
epoch 400 LossPred 0.2980 LossAtt 0.6710 TrainAcc 0.9200 TestAcc 0.8829 0.8900
epoch 500 LossPred 0.2262 LossAtt 0.6298 TrainAcc 0.9400 TestAcc 0.9079 0.9050
epoch 600 LossPred 0.1815 LossAtt 0.6192 TrainAcc 0.9600 TestAcc 0.9079 0.9250
epoch 700 LossPred 0.1611 LossAtt 0.5875 TrainAcc 0.9800 TestAcc 0.9089 0.9250
epoch 800 LossPred 0.1443 LossAtt 0.5988 TrainAcc 0.9800 TestAcc 0.8881 0.9200
epoch 900 LossPred 0.2095 LossAtt 0.5453 TrainAcc 0.9300 TestAcc 0.9089 0.9150
epoch 1000 LossPred 0.1161 LossAtt 0.5030 TrainAcc 0.9800 TestAcc 0.8909 0.9500
epoch 1100 LossPred 0.1212 LossAtt 0.4897 TrainAcc 0.9800 TestAcc 0.8806 0.9400
epoch 1200 LossPred 0.1102 LossAtt 0.5161 TrainAcc 0.9800 TestAcc 0.8994 0.9600
epoch 1300 LossPred 0.1279 LossAtt 0.4959 TrainAcc 0.9700 TestAcc 0.9099 0.9500
epoch 1400 LossPred 0.1031 LossAtt 0.4923 TrainAcc 0.9800 TestAcc 0.8941 0.9650
epoch 1500 LossPred 0.1302 LossAtt 0.4782 TrainAcc 0.9800 TestAcc 0.8939 0.9550
epoch 1600 LossPred 0.1640 LossAtt 0.4791 TrainAcc 0.9400 TestAcc 0.8696 0.9300
epoch 1700 LossPred 0.0973 LossAtt 0.5023 TrainAcc 0.9800 TestAcc 0.8966 0.9750
epoch 1800 LossPred 0.0948 LossAtt 0.4764 TrainAcc 0.9800 TestAcc 0.9019 0.9750
epoch 1900 LossPred 0.1170 LossAtt 0.4939 TrainAcc 0.9700 TestAcc 0.8946 0.9700
epoch 2000 LossPred 0.0996 LossAtt 0.4613 TrainAcc 0.9800 TestAcc 0.9007 0.9700
epoch 2100 LossPred 0.0939 LossAtt 0.4669 TrainAcc 0.9700 TestAcc 0.9094 0.9650
epoch 2200 LossPred 0.0959 LossAtt 0.4436 TrainAcc 0.9700 TestAcc 0.9144 0.9650
epoch 2300 LossPred 0.0857 LossAtt 0.4439 TrainAcc 0.9800 TestAcc 0.9082 0.9650
epoch 2400 LossPred 0.1965 LossAtt 0.4246 TrainAcc 0.9200 TestAcc 0.8671 0.9300
epoch 2500 LossPred 0.1515 LossAtt 0.4402 TrainAcc 0.9500 TestAcc 0.8826 0.9500
Optimization Finished!
********** replication  18  **********
epoch   0 LossPred 1.2693 LossAtt 1.0218 TrainAcc 0.4700 TestAcc 0.4877 0.4850
epoch 100 LossPred 0.9666 LossAtt 0.5228 TrainAcc 0.6100 TestAcc 0.5766 0.6000
epoch 200 LossPred 0.8697 LossAtt 0.5637 TrainAcc 0.5800 TestAcc 0.5310 0.6150
epoch 300 LossPred 0.8308 LossAtt 0.5263 TrainAcc 0.6600 TestAcc 0.5358 0.6400
epoch 400 LossPred 0.8173 LossAtt 0.3438 TrainAcc 0.6600 TestAcc 0.5358 0.6600
epoch 500 LossPred 0.8116 LossAtt 0.2399 TrainAcc 0.6600 TestAcc 0.5358 0.6600
epoch 600 LossPred 0.8130 LossAtt 0.1677 TrainAcc 0.6600 TestAcc 0.5358 0.6600
epoch 700 LossPred 0.8255 LossAtt 0.1693 TrainAcc 0.6600 TestAcc 0.5358 0.6600
epoch 800 LossPred 0.8317 LossAtt 0.1916 TrainAcc 0.6600 TestAcc 0.5358 0.6600
epoch 900 LossPred 0.8149 LossAtt 0.2311 TrainAcc 0.6600 TestAcc 0.5358 0.6600
epoch 1000 LossPred 0.8114 LossAtt 0.2958 TrainAcc 0.6600 TestAcc 0.5358 0.6750
epoch 1100 LossPred 0.4993 LossAtt 0.6092 TrainAcc 0.8300 TestAcc 0.8153 0.8450
epoch 1200 LossPred 0.2797 LossAtt 0.5797 TrainAcc 0.9300 TestAcc 0.8684 0.8550
epoch 1300 LossPred 0.1859 LossAtt 0.5456 TrainAcc 0.9500 TestAcc 0.8601 0.8950
epoch 1400 LossPred 0.1778 LossAtt 0.5164 TrainAcc 0.9500 TestAcc 0.8546 0.9000
epoch 1500 LossPred 0.2275 LossAtt 0.4670 TrainAcc 0.9100 TestAcc 0.8554 0.8900
epoch 1600 LossPred 0.1756 LossAtt 0.4664 TrainAcc 0.9500 TestAcc 0.8559 0.9200
epoch 1700 LossPred 0.2012 LossAtt 0.4299 TrainAcc 0.9400 TestAcc 0.8601 0.9000
epoch 1800 LossPred 0.1734 LossAtt 0.4156 TrainAcc 0.9500 TestAcc 0.8631 0.9100
epoch 1900 LossPred 0.1830 LossAtt 0.4229 TrainAcc 0.9400 TestAcc 0.8574 0.9150
epoch 2000 LossPred 0.1760 LossAtt 0.4192 TrainAcc 0.9400 TestAcc 0.8541 0.9200
epoch 2100 LossPred 0.1973 LossAtt 0.4124 TrainAcc 0.9400 TestAcc 0.8664 0.9050
epoch 2200 LossPred 0.1646 LossAtt 0.4284 TrainAcc 0.9500 TestAcc 0.8621 0.9250
epoch 2300 LossPred 0.1675 LossAtt 0.4104 TrainAcc 0.9400 TestAcc 0.8609 0.9350
epoch 2400 LossPred 0.1839 LossAtt 0.3885 TrainAcc 0.9300 TestAcc 0.8566 0.9300
epoch 2500 LossPred 0.1577 LossAtt 0.3953 TrainAcc 0.9500 TestAcc 0.8566 0.9450
Optimization Finished!
********** replication  19  **********
epoch   0 LossPred 1.0567 LossAtt 1.0080 TrainAcc 0.4500 TestAcc 0.4877 0.4700
epoch 100 LossPred 0.9528 LossAtt 0.4181 TrainAcc 0.6000 TestAcc 0.5475 0.5650
epoch 200 LossPred 0.9492 LossAtt 0.4031 TrainAcc 0.6300 TestAcc 0.5818 0.5700
epoch 300 LossPred 0.9452 LossAtt 0.4540 TrainAcc 0.6100 TestAcc 0.6379 0.5700
epoch 400 LossPred 0.7727 LossAtt 0.5895 TrainAcc 0.7400 TestAcc 0.7180 0.7250
epoch 500 LossPred 0.4304 LossAtt 0.5840 TrainAcc 0.8700 TestAcc 0.8721 0.8450
epoch 600 LossPred 0.2540 LossAtt 0.5729 TrainAcc 0.9400 TestAcc 0.9119 0.9150
epoch 700 LossPred 0.2268 LossAtt 0.5568 TrainAcc 0.9200 TestAcc 0.9027 0.9200
epoch 800 LossPred 0.2283 LossAtt 0.5483 TrainAcc 0.9400 TestAcc 0.8896 0.9000
epoch 900 LossPred 0.2047 LossAtt 0.5114 TrainAcc 0.9300 TestAcc 0.8946 0.9400
epoch 1000 LossPred 0.1932 LossAtt 0.4830 TrainAcc 0.9300 TestAcc 0.9027 0.9400
epoch 1100 LossPred 0.1811 LossAtt 0.4692 TrainAcc 0.9400 TestAcc 0.8959 0.9450
epoch 1200 LossPred 0.3149 LossAtt 0.4681 TrainAcc 0.8900 TestAcc 0.8859 0.9050
epoch 1300 LossPred 0.1574 LossAtt 0.4435 TrainAcc 0.9600 TestAcc 0.9039 0.9600
epoch 1400 LossPred 0.2364 LossAtt 0.4411 TrainAcc 0.9100 TestAcc 0.8989 0.9150
epoch 1500 LossPred 0.1526 LossAtt 0.4236 TrainAcc 0.9700 TestAcc 0.9047 0.9450
epoch 1600 LossPred 0.1309 LossAtt 0.4123 TrainAcc 0.9900 TestAcc 0.9054 0.9550
epoch 1700 LossPred 0.1426 LossAtt 0.4164 TrainAcc 0.9600 TestAcc 0.8874 0.9250
epoch 1800 LossPred 0.1173 LossAtt 0.4086 TrainAcc 0.9700 TestAcc 0.9027 0.9550
epoch 1900 LossPred 0.1108 LossAtt 0.4102 TrainAcc 0.9700 TestAcc 0.9137 0.9700
epoch 2000 LossPred 0.1203 LossAtt 0.3896 TrainAcc 0.9700 TestAcc 0.9159 0.9400
epoch 2100 LossPred 0.1209 LossAtt 0.4000 TrainAcc 0.9600 TestAcc 0.9044 0.9650
epoch 2200 LossPred 0.1056 LossAtt 0.3998 TrainAcc 0.9800 TestAcc 0.9069 0.9600
epoch 2300 LossPred 0.1098 LossAtt 0.3777 TrainAcc 0.9700 TestAcc 0.9157 0.9600
epoch 2400 LossPred 0.1106 LossAtt 0.3605 TrainAcc 0.9700 TestAcc 0.9072 0.9600
epoch 2500 LossPred 0.1507 LossAtt 0.3437 TrainAcc 0.9400 TestAcc 0.9149 0.9450
Optimization Finished!
********** replication  20  **********
epoch   0 LossPred 1.0600 LossAtt 1.0255 TrainAcc 0.5800 TestAcc 0.5028 0.5950
epoch 100 LossPred 0.8639 LossAtt 0.6110 TrainAcc 0.6200 TestAcc 0.6114 0.6250
epoch 200 LossPred 0.3928 LossAtt 0.6469 TrainAcc 0.8900 TestAcc 0.8473 0.8800
epoch 300 LossPred 0.3094 LossAtt 0.6356 TrainAcc 0.9100 TestAcc 0.8554 0.9100
epoch 400 LossPred 0.2726 LossAtt 0.5934 TrainAcc 0.9200 TestAcc 0.8654 0.9000
epoch 500 LossPred 0.1825 LossAtt 0.5741 TrainAcc 0.9500 TestAcc 0.8534 0.9100
epoch 600 LossPred 0.2085 LossAtt 0.5545 TrainAcc 0.9300 TestAcc 0.8729 0.9200
epoch 700 LossPred 0.1614 LossAtt 0.5694 TrainAcc 0.9600 TestAcc 0.8501 0.9350
epoch 800 LossPred 0.1349 LossAtt 0.5625 TrainAcc 0.9700 TestAcc 0.8701 0.9500
epoch 900 LossPred 0.1266 LossAtt 0.5513 TrainAcc 0.9400 TestAcc 0.8581 0.9300
epoch 1000 LossPred 0.1226 LossAtt 0.5591 TrainAcc 0.9600 TestAcc 0.8736 0.9450
epoch 1100 LossPred 0.1098 LossAtt 0.5415 TrainAcc 0.9600 TestAcc 0.8806 0.9550
epoch 1200 LossPred 0.1342 LossAtt 0.5722 TrainAcc 0.9600 TestAcc 0.8811 0.9350
epoch 1300 LossPred 0.0993 LossAtt 0.5429 TrainAcc 0.9600 TestAcc 0.8574 0.9550
epoch 1400 LossPred 0.1308 LossAtt 0.5610 TrainAcc 0.9600 TestAcc 0.8881 0.9350
epoch 1500 LossPred 0.1746 LossAtt 0.5499 TrainAcc 0.9400 TestAcc 0.8323 0.9250
epoch 1600 LossPred 0.0918 LossAtt 0.5371 TrainAcc 0.9800 TestAcc 0.8624 0.9600
epoch 1700 LossPred 0.0905 LossAtt 0.5430 TrainAcc 0.9700 TestAcc 0.8804 0.9700
epoch 1800 LossPred 0.0933 LossAtt 0.5352 TrainAcc 0.9700 TestAcc 0.8861 0.9650
epoch 1900 LossPred 0.2730 LossAtt 0.5226 TrainAcc 0.9200 TestAcc 0.8669 0.8950
epoch 2000 LossPred 0.0874 LossAtt 0.5160 TrainAcc 0.9800 TestAcc 0.8929 0.9650
epoch 2100 LossPred 0.1412 LossAtt 0.5144 TrainAcc 0.9500 TestAcc 0.8929 0.9500
epoch 2200 LossPred 0.0914 LossAtt 0.5164 TrainAcc 0.9700 TestAcc 0.8794 0.9600
epoch 2300 LossPred 0.0898 LossAtt 0.4727 TrainAcc 0.9700 TestAcc 0.8473 0.9600
epoch 2400 LossPred 0.2846 LossAtt 0.5014 TrainAcc 0.9100 TestAcc 0.7995 0.8900
epoch 2500 LossPred 0.3479 LossAtt 0.5034 TrainAcc 0.8800 TestAcc 0.7895 0.8800
Optimization Finished!
********** replication  21  **********
epoch   0 LossPred 0.9945 LossAtt 0.9990 TrainAcc 0.4700 TestAcc 0.4752 0.4900
epoch 100 LossPred 0.8488 LossAtt 0.4759 TrainAcc 0.6200 TestAcc 0.5923 0.6350
epoch 200 LossPred 0.7950 LossAtt 0.5128 TrainAcc 0.7000 TestAcc 0.6426 0.7000
epoch 300 LossPred 0.4375 LossAtt 0.5184 TrainAcc 0.8600 TestAcc 0.8551 0.8450
epoch 400 LossPred 0.3570 LossAtt 0.5104 TrainAcc 0.8700 TestAcc 0.8806 0.8600
epoch 500 LossPred 0.4444 LossAtt 0.4730 TrainAcc 0.8200 TestAcc 0.8619 0.8350
epoch 600 LossPred 0.3160 LossAtt 0.4811 TrainAcc 0.8800 TestAcc 0.8799 0.8650
epoch 700 LossPred 0.3800 LossAtt 0.4940 TrainAcc 0.8700 TestAcc 0.8388 0.8150
epoch 800 LossPred 0.4026 LossAtt 0.4867 TrainAcc 0.8600 TestAcc 0.8674 0.8450
epoch 900 LossPred 0.2637 LossAtt 0.4512 TrainAcc 0.9200 TestAcc 0.8936 0.8750
epoch 1000 LossPred 0.2504 LossAtt 0.4408 TrainAcc 0.9200 TestAcc 0.8986 0.8700
epoch 1100 LossPred 0.3056 LossAtt 0.4498 TrainAcc 0.8900 TestAcc 0.8749 0.8450
epoch 1200 LossPred 0.2436 LossAtt 0.4632 TrainAcc 0.9400 TestAcc 0.8994 0.8800
epoch 1300 LossPred 0.2757 LossAtt 0.4760 TrainAcc 0.9000 TestAcc 0.8839 0.8650
epoch 1400 LossPred 0.2493 LossAtt 0.4759 TrainAcc 0.9200 TestAcc 0.8794 0.8850
epoch 1500 LossPred 0.2192 LossAtt 0.4778 TrainAcc 0.9300 TestAcc 0.8934 0.8750
epoch 1600 LossPred 0.2686 LossAtt 0.4628 TrainAcc 0.9100 TestAcc 0.8791 0.8650
epoch 1700 LossPred 0.2859 LossAtt 0.4517 TrainAcc 0.9200 TestAcc 0.8726 0.8850
epoch 1800 LossPred 0.2359 LossAtt 0.4400 TrainAcc 0.9200 TestAcc 0.8856 0.9000
epoch 1900 LossPred 0.4311 LossAtt 0.4182 TrainAcc 0.8700 TestAcc 0.8438 0.8250
epoch 2000 LossPred 0.2330 LossAtt 0.4134 TrainAcc 0.9400 TestAcc 0.8974 0.8700
epoch 2100 LossPred 0.1938 LossAtt 0.4160 TrainAcc 0.9500 TestAcc 0.9102 0.8800
epoch 2200 LossPred 0.2730 LossAtt 0.4179 TrainAcc 0.9200 TestAcc 0.8849 0.8750
epoch 2300 LossPred 0.2464 LossAtt 0.4010 TrainAcc 0.9300 TestAcc 0.9044 0.8900
epoch 2400 LossPred 0.3937 LossAtt 0.3862 TrainAcc 0.8500 TestAcc 0.8769 0.8650
epoch 2500 LossPred 0.3795 LossAtt 0.4122 TrainAcc 0.8600 TestAcc 0.8594 0.8400
Optimization Finished!
********** replication  22  **********
epoch   0 LossPred 1.5590 LossAtt 1.0617 TrainAcc 0.3500 TestAcc 0.4217 0.3550
epoch 100 LossPred 0.9723 LossAtt 0.4723 TrainAcc 0.6500 TestAcc 0.5385 0.6500
epoch 200 LossPred 0.9146 LossAtt 0.4130 TrainAcc 0.6500 TestAcc 0.5791 0.6500
epoch 300 LossPred 0.9007 LossAtt 0.3796 TrainAcc 0.6500 TestAcc 0.5791 0.6500
epoch 400 LossPred 0.8921 LossAtt 0.3403 TrainAcc 0.6500 TestAcc 0.5791 0.6500
epoch 500 LossPred 0.8861 LossAtt 0.3181 TrainAcc 0.6500 TestAcc 0.5791 0.6500
epoch 600 LossPred 0.8815 LossAtt 0.3324 TrainAcc 0.6500 TestAcc 0.5791 0.6500
epoch 700 LossPred 0.8774 LossAtt 0.3798 TrainAcc 0.6500 TestAcc 0.5791 0.6500
epoch 800 LossPred 0.4917 LossAtt 0.5045 TrainAcc 0.7900 TestAcc 0.6877 0.7850
epoch 900 LossPred 0.3493 LossAtt 0.5874 TrainAcc 0.9000 TestAcc 0.8639 0.9000
epoch 1000 LossPred 0.3044 LossAtt 0.5942 TrainAcc 0.9200 TestAcc 0.8894 0.9250
epoch 1100 LossPred 0.2112 LossAtt 0.5958 TrainAcc 0.9600 TestAcc 0.8994 0.9450
epoch 1200 LossPred 0.1747 LossAtt 0.6274 TrainAcc 0.9700 TestAcc 0.9144 0.9650
epoch 1300 LossPred 0.1539 LossAtt 0.6068 TrainAcc 0.9700 TestAcc 0.9177 0.9550
epoch 1400 LossPred 0.1235 LossAtt 0.5942 TrainAcc 0.9900 TestAcc 0.9159 0.9700
epoch 1500 LossPred 0.1237 LossAtt 0.6011 TrainAcc 0.9800 TestAcc 0.9139 0.9750
epoch 1600 LossPred 0.1002 LossAtt 0.5973 TrainAcc 0.9800 TestAcc 0.9377 0.9800
epoch 1700 LossPred 0.1150 LossAtt 0.5755 TrainAcc 0.9800 TestAcc 0.9402 0.9850
epoch 1800 LossPred 0.0906 LossAtt 0.5824 TrainAcc 0.9800 TestAcc 0.9409 0.9850
epoch 1900 LossPred 0.0740 LossAtt 0.5711 TrainAcc 0.9900 TestAcc 0.9389 0.9800
epoch 2000 LossPred 0.0882 LossAtt 0.5611 TrainAcc 0.9600 TestAcc 0.9229 0.9800
epoch 2100 LossPred 0.0966 LossAtt 0.5805 TrainAcc 0.9700 TestAcc 0.9097 0.9550
epoch 2200 LossPred 0.0762 LossAtt 0.5761 TrainAcc 1.0000 TestAcc 0.9510 0.9950
Optimization Finished!
********** replication  23  **********
epoch   0 LossPred 1.2187 LossAtt 1.0243 TrainAcc 0.4200 TestAcc 0.4247 0.4450
epoch 100 LossPred 0.9702 LossAtt 0.4868 TrainAcc 0.6300 TestAcc 0.5921 0.6300
epoch 200 LossPred 0.9266 LossAtt 0.4135 TrainAcc 0.6400 TestAcc 0.5961 0.6450
epoch 300 LossPred 0.9047 LossAtt 0.4318 TrainAcc 0.6500 TestAcc 0.5998 0.6500
epoch 400 LossPred 0.8759 LossAtt 0.5022 TrainAcc 0.6500 TestAcc 0.5998 0.6400
epoch 500 LossPred 0.8429 LossAtt 0.6124 TrainAcc 0.6900 TestAcc 0.6131 0.6450
epoch 600 LossPred 0.7837 LossAtt 0.6064 TrainAcc 0.7400 TestAcc 0.6039 0.7100
epoch 700 LossPred 0.7349 LossAtt 0.6254 TrainAcc 0.7500 TestAcc 0.5996 0.7200
epoch 800 LossPred 0.6937 LossAtt 0.6993 TrainAcc 0.7800 TestAcc 0.5881 0.7400
epoch 900 LossPred 0.6794 LossAtt 0.6689 TrainAcc 0.7900 TestAcc 0.5981 0.7450
epoch 1000 LossPred 0.6700 LossAtt 0.6126 TrainAcc 0.7900 TestAcc 0.5983 0.7400
epoch 1100 LossPred 0.6686 LossAtt 0.6287 TrainAcc 0.7900 TestAcc 0.5911 0.7400
epoch 1200 LossPred 0.6674 LossAtt 0.6101 TrainAcc 0.7900 TestAcc 0.5908 0.7400
epoch 1300 LossPred 0.6518 LossAtt 0.6217 TrainAcc 0.7900 TestAcc 0.5953 0.7450
epoch 1400 LossPred 0.6474 LossAtt 0.6080 TrainAcc 0.8000 TestAcc 0.5883 0.7550
epoch 1500 LossPred 0.6394 LossAtt 0.6314 TrainAcc 0.8000 TestAcc 0.5898 0.7400
epoch 1600 LossPred 0.6370 LossAtt 0.6070 TrainAcc 0.8000 TestAcc 0.5893 0.7450
epoch 1700 LossPred 0.6296 LossAtt 0.6564 TrainAcc 0.8000 TestAcc 0.5916 0.7400
epoch 1800 LossPred 0.6107 LossAtt 0.6640 TrainAcc 0.8100 TestAcc 0.5913 0.7350
epoch 1900 LossPred 0.6019 LossAtt 0.6740 TrainAcc 0.8200 TestAcc 0.5931 0.7300
epoch 2000 LossPred 0.5979 LossAtt 0.6737 TrainAcc 0.8000 TestAcc 0.5933 0.7300
epoch 2100 LossPred 0.5916 LossAtt 0.6826 TrainAcc 0.7900 TestAcc 0.5828 0.7500
epoch 2200 LossPred 0.5906 LossAtt 0.6899 TrainAcc 0.8100 TestAcc 0.5806 0.7550
epoch 2300 LossPred 0.5867 LossAtt 0.6742 TrainAcc 0.8000 TestAcc 0.5803 0.7500
epoch 2400 LossPred 0.5936 LossAtt 0.6857 TrainAcc 0.8000 TestAcc 0.5953 0.7300
epoch 2500 LossPred 0.5911 LossAtt 0.6350 TrainAcc 0.8100 TestAcc 0.5911 0.7450
Optimization Finished!
********** replication  24  **********
epoch   0 LossPred 1.1458 LossAtt 1.0270 TrainAcc 0.5600 TestAcc 0.5856 0.5400
epoch 100 LossPred 0.9847 LossAtt 0.4399 TrainAcc 0.5600 TestAcc 0.5953 0.5600
epoch 200 LossPred 0.8628 LossAtt 0.6144 TrainAcc 0.6900 TestAcc 0.7225 0.6950
epoch 300 LossPred 0.7167 LossAtt 0.5463 TrainAcc 0.7700 TestAcc 0.8526 0.7500
epoch 400 LossPred 0.5699 LossAtt 0.5963 TrainAcc 0.8200 TestAcc 0.7980 0.8300
epoch 500 LossPred 0.3209 LossAtt 0.5761 TrainAcc 0.9200 TestAcc 0.8864 0.8950
epoch 600 LossPred 0.2692 LossAtt 0.5446 TrainAcc 0.9300 TestAcc 0.8954 0.9300
epoch 700 LossPred 0.2307 LossAtt 0.5039 TrainAcc 0.9300 TestAcc 0.8894 0.9050
epoch 800 LossPred 0.2391 LossAtt 0.4974 TrainAcc 0.9500 TestAcc 0.8946 0.9100
epoch 900 LossPred 0.2205 LossAtt 0.5011 TrainAcc 0.9500 TestAcc 0.8994 0.9350
epoch 1000 LossPred 0.1820 LossAtt 0.5110 TrainAcc 0.9700 TestAcc 0.9007 0.9350
epoch 1100 LossPred 0.2335 LossAtt 0.4986 TrainAcc 0.9400 TestAcc 0.8764 0.9150
epoch 1200 LossPred 0.1469 LossAtt 0.4870 TrainAcc 0.9700 TestAcc 0.9082 0.9400
epoch 1300 LossPred 0.1646 LossAtt 0.4964 TrainAcc 0.9500 TestAcc 0.8899 0.9400
epoch 1400 LossPred 0.1337 LossAtt 0.4843 TrainAcc 0.9600 TestAcc 0.9009 0.9300
epoch 1500 LossPred 0.1219 LossAtt 0.4953 TrainAcc 0.9700 TestAcc 0.9099 0.9400
epoch 1600 LossPred 0.1518 LossAtt 0.5115 TrainAcc 0.9400 TestAcc 0.8949 0.9300
epoch 1700 LossPred 0.2395 LossAtt 0.4890 TrainAcc 0.9300 TestAcc 0.9052 0.9100
epoch 1800 LossPred 0.1219 LossAtt 0.4970 TrainAcc 0.9800 TestAcc 0.9219 0.9400
epoch 1900 LossPred 0.2717 LossAtt 0.5052 TrainAcc 0.9200 TestAcc 0.8901 0.9300
epoch 2000 LossPred 0.1934 LossAtt 0.4946 TrainAcc 0.9400 TestAcc 0.9084 0.9150
epoch 2100 LossPred 0.1097 LossAtt 0.5325 TrainAcc 0.9800 TestAcc 0.9247 0.9450
epoch 2200 LossPred 0.0973 LossAtt 0.5004 TrainAcc 0.9700 TestAcc 0.9044 0.9600
epoch 2300 LossPred 0.1519 LossAtt 0.5334 TrainAcc 0.9400 TestAcc 0.8906 0.9450
epoch 2400 LossPred 0.0963 LossAtt 0.5097 TrainAcc 0.9800 TestAcc 0.9184 0.9600
epoch 2500 LossPred 0.2059 LossAtt 0.5079 TrainAcc 0.9300 TestAcc 0.8846 0.9300
Optimization Finished!
********** replication  25  **********
epoch   0 LossPred 1.0998 LossAtt 1.0392 TrainAcc 0.5300 TestAcc 0.4635 0.5050
epoch 100 LossPred 0.9093 LossAtt 0.6828 TrainAcc 0.6100 TestAcc 0.5353 0.5650
epoch 200 LossPred 0.8126 LossAtt 0.7291 TrainAcc 0.6900 TestAcc 0.5638 0.7100
epoch 300 LossPred 0.7574 LossAtt 0.6980 TrainAcc 0.7300 TestAcc 0.5811 0.7350
epoch 400 LossPred 0.6883 LossAtt 0.7402 TrainAcc 0.7700 TestAcc 0.5738 0.7400
epoch 500 LossPred 0.6206 LossAtt 0.6923 TrainAcc 0.7900 TestAcc 0.5906 0.7650
epoch 600 LossPred 0.5855 LossAtt 0.7414 TrainAcc 0.8000 TestAcc 0.5886 0.7800
epoch 700 LossPred 0.5623 LossAtt 0.7668 TrainAcc 0.8100 TestAcc 0.5998 0.7650
epoch 800 LossPred 0.5603 LossAtt 0.8058 TrainAcc 0.8000 TestAcc 0.6024 0.7900
epoch 900 LossPred 0.5354 LossAtt 0.7867 TrainAcc 0.8200 TestAcc 0.6044 0.7750
epoch 1000 LossPred 0.5161 LossAtt 0.7864 TrainAcc 0.8300 TestAcc 0.6061 0.7850
epoch 1100 LossPred 0.5085 LossAtt 0.8007 TrainAcc 0.8300 TestAcc 0.6091 0.7850
epoch 1200 LossPred 0.5020 LossAtt 0.8037 TrainAcc 0.8300 TestAcc 0.6146 0.7850
epoch 1300 LossPred 0.4909 LossAtt 0.7863 TrainAcc 0.8400 TestAcc 0.6196 0.7850
epoch 1400 LossPred 0.4837 LossAtt 0.7752 TrainAcc 0.8400 TestAcc 0.6241 0.7950
epoch 1500 LossPred 0.4701 LossAtt 0.7786 TrainAcc 0.8400 TestAcc 0.6291 0.7950
epoch 1600 LossPred 0.4294 LossAtt 0.8249 TrainAcc 0.8600 TestAcc 0.6512 0.8200
epoch 1700 LossPred 0.4327 LossAtt 0.8341 TrainAcc 0.8600 TestAcc 0.6529 0.8200
epoch 1800 LossPred 0.4035 LossAtt 0.8276 TrainAcc 0.8700 TestAcc 0.6627 0.8100
epoch 1900 LossPred 0.3824 LossAtt 0.8101 TrainAcc 0.8700 TestAcc 0.6649 0.8450
epoch 2000 LossPred 0.3713 LossAtt 0.8119 TrainAcc 0.8600 TestAcc 0.6699 0.8450
epoch 2100 LossPred 0.3607 LossAtt 0.7910 TrainAcc 0.8800 TestAcc 0.6719 0.8700
epoch 2200 LossPred 0.3490 LossAtt 0.7968 TrainAcc 0.8900 TestAcc 0.6732 0.8900
epoch 2300 LossPred 0.3404 LossAtt 0.8113 TrainAcc 0.9000 TestAcc 0.6829 0.8500
epoch 2400 LossPred 0.3321 LossAtt 0.7918 TrainAcc 0.9100 TestAcc 0.6817 0.8600
epoch 2500 LossPred 0.2781 LossAtt 0.7953 TrainAcc 0.9200 TestAcc 0.6837 0.8700
Optimization Finished!
********** replication  26  **********
epoch   0 LossPred 1.0280 LossAtt 0.9984 TrainAcc 0.4500 TestAcc 0.5248 0.4550
epoch 100 LossPred 0.8326 LossAtt 0.4427 TrainAcc 0.5800 TestAcc 0.5841 0.5800
epoch 200 LossPred 0.7695 LossAtt 0.3326 TrainAcc 0.6900 TestAcc 0.5931 0.6900
epoch 300 LossPred 0.7206 LossAtt 0.4065 TrainAcc 0.7600 TestAcc 0.6251 0.7350
epoch 400 LossPred 0.4117 LossAtt 0.3834 TrainAcc 0.8500 TestAcc 0.8211 0.8050
epoch 500 LossPred 0.3058 LossAtt 0.3335 TrainAcc 0.9100 TestAcc 0.8268 0.8400
epoch 600 LossPred 0.2955 LossAtt 0.3167 TrainAcc 0.9100 TestAcc 0.8271 0.8250
epoch 700 LossPred 0.2980 LossAtt 0.3208 TrainAcc 0.9100 TestAcc 0.8211 0.8300
epoch 800 LossPred 0.2972 LossAtt 0.3164 TrainAcc 0.9100 TestAcc 0.8328 0.8300
epoch 900 LossPred 0.3035 LossAtt 0.3112 TrainAcc 0.9000 TestAcc 0.8261 0.8300
epoch 1000 LossPred 0.3059 LossAtt 0.2933 TrainAcc 0.9000 TestAcc 0.8201 0.8400
epoch 1100 LossPred 0.2878 LossAtt 0.2711 TrainAcc 0.9100 TestAcc 0.8193 0.8350
epoch 1200 LossPred 0.3013 LossAtt 0.3055 TrainAcc 0.9100 TestAcc 0.8296 0.8350
epoch 1300 LossPred 0.3213 LossAtt 0.2872 TrainAcc 0.9000 TestAcc 0.8253 0.8400
epoch 1400 LossPred 0.3644 LossAtt 0.2945 TrainAcc 0.8900 TestAcc 0.8196 0.8150
epoch 1500 LossPred 0.2928 LossAtt 0.2733 TrainAcc 0.9100 TestAcc 0.8288 0.8300
epoch 1600 LossPred 0.2682 LossAtt 0.2816 TrainAcc 0.9100 TestAcc 0.8316 0.8250
epoch 1700 LossPred 0.2693 LossAtt 0.2800 TrainAcc 0.9100 TestAcc 0.8303 0.8250
epoch 1800 LossPred 0.2942 LossAtt 0.2971 TrainAcc 0.9100 TestAcc 0.8318 0.8250
epoch 1900 LossPred 0.2593 LossAtt 0.2761 TrainAcc 0.9100 TestAcc 0.8321 0.8350
epoch 2000 LossPred 0.2957 LossAtt 0.2668 TrainAcc 0.9100 TestAcc 0.8313 0.8450
epoch 2100 LossPred 0.2604 LossAtt 0.3177 TrainAcc 0.9100 TestAcc 0.8336 0.8350
epoch 2200 LossPred 0.2951 LossAtt 0.2993 TrainAcc 0.9000 TestAcc 0.8361 0.8300
epoch 2300 LossPred 0.2799 LossAtt 0.2830 TrainAcc 0.9200 TestAcc 0.8268 0.8450
epoch 2400 LossPred 0.2503 LossAtt 0.2878 TrainAcc 0.9200 TestAcc 0.8381 0.8300
epoch 2500 LossPred 0.2530 LossAtt 0.2724 TrainAcc 0.9100 TestAcc 0.8336 0.8300
Optimization Finished!
********** replication  27  **********
epoch   0 LossPred 1.0350 LossAtt 1.0922 TrainAcc 0.5800 TestAcc 0.5941 0.5300
epoch 100 LossPred 0.9593 LossAtt 0.5608 TrainAcc 0.5800 TestAcc 0.5941 0.5800
epoch 200 LossPred 0.9495 LossAtt 0.5558 TrainAcc 0.5800 TestAcc 0.5941 0.5850
epoch 300 LossPred 0.9089 LossAtt 0.6093 TrainAcc 0.6000 TestAcc 0.6231 0.6200
epoch 400 LossPred 0.7559 LossAtt 0.6522 TrainAcc 0.7100 TestAcc 0.6547 0.7000
epoch 500 LossPred 0.4282 LossAtt 0.6768 TrainAcc 0.8600 TestAcc 0.7538 0.8350
epoch 600 LossPred 0.2928 LossAtt 0.6788 TrainAcc 0.9300 TestAcc 0.8021 0.8800
epoch 700 LossPred 0.2611 LossAtt 0.6873 TrainAcc 0.9200 TestAcc 0.8271 0.9050
epoch 800 LossPred 0.2454 LossAtt 0.6843 TrainAcc 0.9300 TestAcc 0.8443 0.9150
epoch 900 LossPred 0.2072 LossAtt 0.6503 TrainAcc 0.9500 TestAcc 0.8478 0.9350
epoch 1000 LossPred 0.1469 LossAtt 0.6251 TrainAcc 0.9700 TestAcc 0.8504 0.9400
epoch 1100 LossPred 0.1136 LossAtt 0.6191 TrainAcc 0.9800 TestAcc 0.8649 0.9600
epoch 1200 LossPred 0.1213 LossAtt 0.6163 TrainAcc 0.9400 TestAcc 0.8826 0.9750
epoch 1300 LossPred 0.0613 LossAtt 0.5796 TrainAcc 0.9900 TestAcc 0.8936 0.9800
epoch 1400 LossPred 0.0587 LossAtt 0.6029 TrainAcc 0.9900 TestAcc 0.8909 0.9850
epoch 1500 LossPred 0.0404 LossAtt 0.5841 TrainAcc 0.9900 TestAcc 0.8971 0.9950
epoch 1600 LossPred 0.0489 LossAtt 0.5628 TrainAcc 1.0000 TestAcc 0.8834 0.9850
Optimization Finished!
********** replication  28  **********
epoch   0 LossPred 1.3672 LossAtt 1.0304 TrainAcc 0.5000 TestAcc 0.5428 0.5200
epoch 100 LossPred 0.9960 LossAtt 0.6449 TrainAcc 0.5600 TestAcc 0.5883 0.5600
epoch 200 LossPred 0.8614 LossAtt 0.4753 TrainAcc 0.6800 TestAcc 0.5868 0.7000
epoch 300 LossPred 0.8279 LossAtt 0.3935 TrainAcc 0.6900 TestAcc 0.5921 0.7050
epoch 400 LossPred 0.8064 LossAtt 0.3409 TrainAcc 0.6900 TestAcc 0.5921 0.7000
epoch 500 LossPred 0.7885 LossAtt 0.3929 TrainAcc 0.7300 TestAcc 0.6369 0.7100
epoch 600 LossPred 0.7558 LossAtt 0.4502 TrainAcc 0.7400 TestAcc 0.6514 0.7500
epoch 700 LossPred 0.7297 LossAtt 0.5261 TrainAcc 0.7400 TestAcc 0.6572 0.7500
epoch 800 LossPred 0.5780 LossAtt 0.5759 TrainAcc 0.8000 TestAcc 0.8161 0.8000
epoch 900 LossPred 0.4411 LossAtt 0.5511 TrainAcc 0.8600 TestAcc 0.8574 0.8300
epoch 1000 LossPred 0.3730 LossAtt 0.4599 TrainAcc 0.8700 TestAcc 0.8779 0.8450
epoch 1100 LossPred 0.3812 LossAtt 0.4627 TrainAcc 0.8900 TestAcc 0.8676 0.8650
epoch 1200 LossPred 0.3153 LossAtt 0.4846 TrainAcc 0.9200 TestAcc 0.8669 0.8450
epoch 1300 LossPred 0.3320 LossAtt 0.4278 TrainAcc 0.9100 TestAcc 0.8666 0.8500
epoch 1400 LossPred 0.3226 LossAtt 0.4310 TrainAcc 0.9100 TestAcc 0.8606 0.8600
epoch 1500 LossPred 0.3224 LossAtt 0.3988 TrainAcc 0.8800 TestAcc 0.8634 0.8550
epoch 1600 LossPred 0.3155 LossAtt 0.4198 TrainAcc 0.9100 TestAcc 0.8594 0.8550
epoch 1700 LossPred 0.3104 LossAtt 0.3790 TrainAcc 0.8900 TestAcc 0.8634 0.8450
epoch 1800 LossPred 0.3397 LossAtt 0.4193 TrainAcc 0.8900 TestAcc 0.8561 0.8650
epoch 1900 LossPred 0.3082 LossAtt 0.3999 TrainAcc 0.8800 TestAcc 0.8604 0.8550
epoch 2000 LossPred 0.3481 LossAtt 0.3985 TrainAcc 0.8600 TestAcc 0.8606 0.8400
epoch 2100 LossPred 0.2978 LossAtt 0.4039 TrainAcc 0.9200 TestAcc 0.8569 0.8450
epoch 2200 LossPred 0.3048 LossAtt 0.3954 TrainAcc 0.8800 TestAcc 0.8614 0.8550
epoch 2300 LossPred 0.3113 LossAtt 0.4111 TrainAcc 0.8700 TestAcc 0.8649 0.8500
epoch 2400 LossPred 0.3060 LossAtt 0.4102 TrainAcc 0.8800 TestAcc 0.8606 0.8550
epoch 2500 LossPred 0.3067 LossAtt 0.4357 TrainAcc 0.8700 TestAcc 0.8601 0.8500
Optimization Finished!
********** replication  29  **********
epoch   0 LossPred 1.3028 LossAtt 1.0323 TrainAcc 0.4300 TestAcc 0.4570 0.3950
epoch 100 LossPred 0.9505 LossAtt 0.5866 TrainAcc 0.5800 TestAcc 0.5813 0.5850
epoch 200 LossPred 0.8843 LossAtt 0.6392 TrainAcc 0.6800 TestAcc 0.5758 0.6800
epoch 300 LossPred 0.5756 LossAtt 0.7414 TrainAcc 0.8000 TestAcc 0.7035 0.8100
epoch 400 LossPred 0.2750 LossAtt 0.7306 TrainAcc 0.9400 TestAcc 0.8003 0.8900
epoch 500 LossPred 0.2173 LossAtt 0.7079 TrainAcc 0.9400 TestAcc 0.8128 0.9250
epoch 600 LossPred 0.2067 LossAtt 0.7354 TrainAcc 0.9400 TestAcc 0.8076 0.9200
epoch 700 LossPred 0.1819 LossAtt 0.6969 TrainAcc 0.9400 TestAcc 0.8141 0.9400
epoch 800 LossPred 0.2028 LossAtt 0.6560 TrainAcc 0.9300 TestAcc 0.8048 0.9150
epoch 900 LossPred 0.1599 LossAtt 0.6454 TrainAcc 0.9400 TestAcc 0.8126 0.9300
epoch 1000 LossPred 0.1617 LossAtt 0.6663 TrainAcc 0.9600 TestAcc 0.8236 0.9150
epoch 1100 LossPred 0.1499 LossAtt 0.6403 TrainAcc 0.9600 TestAcc 0.8201 0.9400
epoch 1200 LossPred 0.1424 LossAtt 0.6619 TrainAcc 0.9600 TestAcc 0.8118 0.9300
epoch 1300 LossPred 0.1335 LossAtt 0.6369 TrainAcc 0.9600 TestAcc 0.8178 0.9300
epoch 1400 LossPred 0.1584 LossAtt 0.6214 TrainAcc 0.9600 TestAcc 0.8296 0.9400
epoch 1500 LossPred 0.1263 LossAtt 0.6138 TrainAcc 0.9700 TestAcc 0.8236 0.9300
epoch 1600 LossPred 0.1315 LossAtt 0.6077 TrainAcc 0.9700 TestAcc 0.8251 0.9400
epoch 1700 LossPred 0.1267 LossAtt 0.6022 TrainAcc 0.9600 TestAcc 0.8126 0.9350
epoch 1800 LossPred 0.1116 LossAtt 0.6087 TrainAcc 0.9800 TestAcc 0.8248 0.9550
epoch 1900 LossPred 0.1088 LossAtt 0.6045 TrainAcc 0.9800 TestAcc 0.8258 0.9650
epoch 2000 LossPred 0.1055 LossAtt 0.5829 TrainAcc 0.9800 TestAcc 0.8241 0.9500
epoch 2100 LossPred 0.1067 LossAtt 0.6159 TrainAcc 0.9800 TestAcc 0.8233 0.9550
epoch 2200 LossPred 0.1010 LossAtt 0.5995 TrainAcc 0.9800 TestAcc 0.8238 0.9500
epoch 2300 LossPred 0.0980 LossAtt 0.6076 TrainAcc 0.9800 TestAcc 0.8146 0.9500
epoch 2400 LossPred 0.0988 LossAtt 0.5753 TrainAcc 0.9800 TestAcc 0.8126 0.9550
epoch 2500 LossPred 0.0962 LossAtt 0.5943 TrainAcc 0.9800 TestAcc 0.8166 0.9500
Optimization Finished!
********** replication  30  **********
epoch   0 LossPred 1.7642 LossAtt 1.0272 TrainAcc 0.3200 TestAcc 0.4389 0.3100
epoch 100 LossPred 1.1667 LossAtt 0.5879 TrainAcc 0.5100 TestAcc 0.5753 0.5150
epoch 200 LossPred 0.9042 LossAtt 0.6356 TrainAcc 0.7300 TestAcc 0.5828 0.7150
epoch 300 LossPred 0.8296 LossAtt 0.6283 TrainAcc 0.7300 TestAcc 0.5826 0.7300
epoch 400 LossPred 0.7900 LossAtt 0.6329 TrainAcc 0.7300 TestAcc 0.5826 0.7300
epoch 500 LossPred 0.7411 LossAtt 0.7152 TrainAcc 0.7300 TestAcc 0.5826 0.7300
epoch 600 LossPred 0.4778 LossAtt 0.7068 TrainAcc 0.8700 TestAcc 0.7868 0.8650
epoch 700 LossPred 0.4108 LossAtt 0.6902 TrainAcc 0.8900 TestAcc 0.8436 0.8600
epoch 800 LossPred 0.3463 LossAtt 0.6857 TrainAcc 0.9100 TestAcc 0.8378 0.8800
epoch 900 LossPred 0.3199 LossAtt 0.7029 TrainAcc 0.9000 TestAcc 0.8534 0.8850
epoch 1000 LossPred 0.2934 LossAtt 0.7021 TrainAcc 0.9100 TestAcc 0.8584 0.8900
epoch 1100 LossPred 0.2821 LossAtt 0.6861 TrainAcc 0.9200 TestAcc 0.8353 0.9000
epoch 1200 LossPred 0.2604 LossAtt 0.6636 TrainAcc 0.9400 TestAcc 0.8446 0.9150
epoch 1300 LossPred 0.2414 LossAtt 0.6693 TrainAcc 0.9300 TestAcc 0.8529 0.9050
epoch 1400 LossPred 0.2577 LossAtt 0.6528 TrainAcc 0.9300 TestAcc 0.8664 0.8850
epoch 1500 LossPred 0.3257 LossAtt 0.6613 TrainAcc 0.8900 TestAcc 0.8529 0.8900
epoch 1600 LossPred 0.2072 LossAtt 0.6492 TrainAcc 0.9500 TestAcc 0.8506 0.9200
epoch 1700 LossPred 0.1787 LossAtt 0.6615 TrainAcc 0.9600 TestAcc 0.8511 0.9250
epoch 1800 LossPred 0.1561 LossAtt 0.6411 TrainAcc 0.9700 TestAcc 0.8498 0.9300
epoch 1900 LossPred 0.1599 LossAtt 0.6360 TrainAcc 0.9700 TestAcc 0.8551 0.9300
epoch 2000 LossPred 0.1511 LossAtt 0.6475 TrainAcc 0.9700 TestAcc 0.8541 0.9300
epoch 2100 LossPred 0.1581 LossAtt 0.6289 TrainAcc 0.9700 TestAcc 0.8423 0.9150
epoch 2200 LossPred 0.1459 LossAtt 0.6143 TrainAcc 0.9700 TestAcc 0.8554 0.9300
epoch 2300 LossPred 0.1759 LossAtt 0.6462 TrainAcc 0.9300 TestAcc 0.8388 0.9100
epoch 2400 LossPred 0.1669 LossAtt 0.6327 TrainAcc 0.9600 TestAcc 0.8644 0.9250
epoch 2500 LossPred 0.1543 LossAtt 0.6169 TrainAcc 0.9600 TestAcc 0.8616 0.9250
Optimization Finished!
********** replication  31  **********
epoch   0 LossPred 1.2447 LossAtt 1.0193 TrainAcc 0.4500 TestAcc 0.5023 0.4200
epoch 100 LossPred 0.9356 LossAtt 0.5682 TrainAcc 0.6100 TestAcc 0.5596 0.6200
epoch 200 LossPred 0.8912 LossAtt 0.4673 TrainAcc 0.6400 TestAcc 0.5933 0.6700
epoch 300 LossPred 0.5985 LossAtt 0.4938 TrainAcc 0.8200 TestAcc 0.8233 0.7850
epoch 400 LossPred 0.4849 LossAtt 0.4556 TrainAcc 0.8100 TestAcc 0.8228 0.8150
epoch 500 LossPred 0.3905 LossAtt 0.4236 TrainAcc 0.8600 TestAcc 0.8789 0.8550
epoch 600 LossPred 0.3932 LossAtt 0.3897 TrainAcc 0.8400 TestAcc 0.8584 0.8600
epoch 700 LossPred 0.4670 LossAtt 0.3669 TrainAcc 0.8200 TestAcc 0.8321 0.8150
epoch 800 LossPred 0.3750 LossAtt 0.3660 TrainAcc 0.8600 TestAcc 0.8721 0.8650
epoch 900 LossPred 0.3532 LossAtt 0.3724 TrainAcc 0.8600 TestAcc 0.8716 0.8700
epoch 1000 LossPred 0.4411 LossAtt 0.3598 TrainAcc 0.8300 TestAcc 0.8381 0.8400
epoch 1100 LossPred 0.5388 LossAtt 0.3807 TrainAcc 0.8100 TestAcc 0.8123 0.8250
epoch 1200 LossPred 0.3026 LossAtt 0.3656 TrainAcc 0.9100 TestAcc 0.8744 0.8750
epoch 1300 LossPred 0.2792 LossAtt 0.3727 TrainAcc 0.9300 TestAcc 0.8849 0.8750
epoch 1400 LossPred 0.2825 LossAtt 0.3769 TrainAcc 0.9300 TestAcc 0.8894 0.8900
epoch 1500 LossPred 0.2731 LossAtt 0.3963 TrainAcc 0.9000 TestAcc 0.8739 0.8500
epoch 1600 LossPred 0.3151 LossAtt 0.3733 TrainAcc 0.8800 TestAcc 0.8799 0.8900
epoch 1700 LossPred 0.2566 LossAtt 0.3988 TrainAcc 0.9200 TestAcc 0.8779 0.8650
epoch 1800 LossPred 0.2614 LossAtt 0.3785 TrainAcc 0.9100 TestAcc 0.8859 0.8850
epoch 1900 LossPred 0.3257 LossAtt 0.3819 TrainAcc 0.8700 TestAcc 0.8726 0.8950
epoch 2000 LossPred 0.2624 LossAtt 0.4033 TrainAcc 0.9000 TestAcc 0.8904 0.9000
epoch 2100 LossPred 0.2437 LossAtt 0.4229 TrainAcc 0.9400 TestAcc 0.8919 0.8750
epoch 2200 LossPred 0.4502 LossAtt 0.4641 TrainAcc 0.8300 TestAcc 0.8486 0.8250
epoch 2300 LossPred 0.4782 LossAtt 0.4501 TrainAcc 0.8200 TestAcc 0.8371 0.8100
epoch 2400 LossPred 0.3521 LossAtt 0.4174 TrainAcc 0.8600 TestAcc 0.8649 0.8650
epoch 2500 LossPred 0.3466 LossAtt 0.3952 TrainAcc 0.8700 TestAcc 0.8594 0.8700
Optimization Finished!
********** replication  32  **********
epoch   0 LossPred 1.1964 LossAtt 1.0336 TrainAcc 0.4800 TestAcc 0.4357 0.5100
epoch 100 LossPred 0.9682 LossAtt 0.4923 TrainAcc 0.5700 TestAcc 0.5478 0.6000
epoch 200 LossPred 0.9349 LossAtt 0.5112 TrainAcc 0.5900 TestAcc 0.5996 0.5900
epoch 300 LossPred 0.9147 LossAtt 0.5102 TrainAcc 0.6300 TestAcc 0.5623 0.5800
epoch 400 LossPred 0.8932 LossAtt 0.5432 TrainAcc 0.5900 TestAcc 0.5676 0.6150
epoch 500 LossPred 0.6020 LossAtt 0.7573 TrainAcc 0.8200 TestAcc 0.8078 0.7850
epoch 600 LossPred 0.4698 LossAtt 0.7096 TrainAcc 0.8400 TestAcc 0.7893 0.8000
epoch 700 LossPred 0.2429 LossAtt 0.7024 TrainAcc 0.9300 TestAcc 0.8283 0.8700
epoch 800 LossPred 0.2264 LossAtt 0.6884 TrainAcc 0.9300 TestAcc 0.8271 0.8700
epoch 900 LossPred 0.1947 LossAtt 0.6752 TrainAcc 0.9400 TestAcc 0.8291 0.8800
epoch 1000 LossPred 0.1851 LossAtt 0.6720 TrainAcc 0.9400 TestAcc 0.8273 0.8700
epoch 1100 LossPred 0.1811 LossAtt 0.6796 TrainAcc 0.9600 TestAcc 0.8423 0.9000
epoch 1200 LossPred 0.1702 LossAtt 0.6538 TrainAcc 0.9500 TestAcc 0.8321 0.8950
epoch 1300 LossPred 0.1739 LossAtt 0.6415 TrainAcc 0.9500 TestAcc 0.8403 0.9000
epoch 1400 LossPred 0.1675 LossAtt 0.6173 TrainAcc 0.9500 TestAcc 0.8321 0.9000
epoch 1500 LossPred 0.1755 LossAtt 0.6488 TrainAcc 0.9500 TestAcc 0.8373 0.9000
epoch 1600 LossPred 0.1658 LossAtt 0.6143 TrainAcc 0.9500 TestAcc 0.8273 0.8800
epoch 1700 LossPred 0.1621 LossAtt 0.6297 TrainAcc 0.9600 TestAcc 0.8301 0.8900
epoch 1800 LossPred 0.1624 LossAtt 0.6272 TrainAcc 0.9500 TestAcc 0.8316 0.8800
epoch 1900 LossPred 0.1739 LossAtt 0.5874 TrainAcc 0.9400 TestAcc 0.8253 0.8800
epoch 2000 LossPred 0.1538 LossAtt 0.6079 TrainAcc 0.9500 TestAcc 0.8303 0.8950
epoch 2100 LossPred 0.1634 LossAtt 0.5925 TrainAcc 0.9500 TestAcc 0.8361 0.9000
epoch 2200 LossPred 0.1587 LossAtt 0.5902 TrainAcc 0.9500 TestAcc 0.8261 0.9000
epoch 2300 LossPred 0.2778 LossAtt 0.5877 TrainAcc 0.9200 TestAcc 0.8291 0.8850
epoch 2400 LossPred 0.1527 LossAtt 0.5808 TrainAcc 0.9500 TestAcc 0.8303 0.9050
epoch 2500 LossPred 0.1437 LossAtt 0.5697 TrainAcc 0.9600 TestAcc 0.8323 0.9150
Optimization Finished!
********** replication  33  **********
epoch   0 LossPred 0.9643 LossAtt 1.0206 TrainAcc 0.6100 TestAcc 0.5443 0.6050
epoch 100 LossPred 0.8542 LossAtt 0.5619 TrainAcc 0.6500 TestAcc 0.5546 0.6450
epoch 200 LossPred 0.7112 LossAtt 0.6239 TrainAcc 0.7400 TestAcc 0.5983 0.7300
epoch 300 LossPred 0.3435 LossAtt 0.5123 TrainAcc 0.8900 TestAcc 0.8191 0.8800
epoch 400 LossPred 0.3354 LossAtt 0.5069 TrainAcc 0.8900 TestAcc 0.8298 0.8800
epoch 500 LossPred 0.3299 LossAtt 0.4860 TrainAcc 0.9100 TestAcc 0.8226 0.8750
epoch 600 LossPred 0.3087 LossAtt 0.4602 TrainAcc 0.9000 TestAcc 0.8376 0.8850
epoch 700 LossPred 0.3099 LossAtt 0.4514 TrainAcc 0.8900 TestAcc 0.8443 0.8900
epoch 800 LossPred 0.2708 LossAtt 0.4535 TrainAcc 0.9100 TestAcc 0.8486 0.8900
epoch 900 LossPred 0.2595 LossAtt 0.4423 TrainAcc 0.9000 TestAcc 0.8584 0.8850
epoch 1000 LossPred 0.2407 LossAtt 0.4161 TrainAcc 0.9200 TestAcc 0.8666 0.8850
epoch 1100 LossPred 0.2168 LossAtt 0.4267 TrainAcc 0.9300 TestAcc 0.8661 0.8750
epoch 1200 LossPred 0.2542 LossAtt 0.4188 TrainAcc 0.9200 TestAcc 0.8684 0.8850
epoch 1300 LossPred 0.1943 LossAtt 0.4355 TrainAcc 0.9300 TestAcc 0.8714 0.8950
epoch 1400 LossPred 0.1885 LossAtt 0.4329 TrainAcc 0.9300 TestAcc 0.8744 0.8950
epoch 1500 LossPred 0.2152 LossAtt 0.4611 TrainAcc 0.9300 TestAcc 0.8851 0.9000
epoch 1600 LossPred 0.1770 LossAtt 0.4618 TrainAcc 0.9300 TestAcc 0.8919 0.9000
epoch 1700 LossPred 0.1788 LossAtt 0.4628 TrainAcc 0.9300 TestAcc 0.8949 0.9100
epoch 1800 LossPred 0.1698 LossAtt 0.4530 TrainAcc 0.9400 TestAcc 0.8986 0.9050
epoch 1900 LossPred 0.1554 LossAtt 0.4546 TrainAcc 0.9500 TestAcc 0.9097 0.9150
epoch 2000 LossPred 0.1709 LossAtt 0.4509 TrainAcc 0.9300 TestAcc 0.9119 0.9150
epoch 2100 LossPred 0.1779 LossAtt 0.4442 TrainAcc 0.9400 TestAcc 0.9109 0.9050
epoch 2200 LossPred 0.1254 LossAtt 0.4579 TrainAcc 0.9600 TestAcc 0.9152 0.9400
epoch 2300 LossPred 0.1080 LossAtt 0.4597 TrainAcc 0.9700 TestAcc 0.9104 0.9200
epoch 2400 LossPred 0.1784 LossAtt 0.4317 TrainAcc 0.9400 TestAcc 0.9094 0.9250
epoch 2500 LossPred 0.0973 LossAtt 0.4381 TrainAcc 0.9700 TestAcc 0.9102 0.9250
Optimization Finished!
********** replication  34  **********
epoch   0 LossPred 0.9612 LossAtt 1.0052 TrainAcc 0.6100 TestAcc 0.5883 0.6100
epoch 100 LossPred 0.8670 LossAtt 0.5362 TrainAcc 0.6100 TestAcc 0.5883 0.6100
epoch 200 LossPred 0.5155 LossAtt 0.6279 TrainAcc 0.8200 TestAcc 0.7905 0.8300
epoch 300 LossPred 0.3133 LossAtt 0.5724 TrainAcc 0.9200 TestAcc 0.8774 0.9200
epoch 400 LossPred 0.2902 LossAtt 0.5763 TrainAcc 0.9100 TestAcc 0.8614 0.9050
epoch 500 LossPred 0.2749 LossAtt 0.5674 TrainAcc 0.9400 TestAcc 0.8716 0.9200
epoch 600 LossPred 0.1965 LossAtt 0.5418 TrainAcc 0.9300 TestAcc 0.8921 0.9350
epoch 700 LossPred 0.1872 LossAtt 0.5256 TrainAcc 0.9400 TestAcc 0.8871 0.9350
epoch 800 LossPred 0.1938 LossAtt 0.5364 TrainAcc 0.9400 TestAcc 0.8821 0.9350
epoch 900 LossPred 0.1303 LossAtt 0.5342 TrainAcc 0.9600 TestAcc 0.9009 0.9450
epoch 1000 LossPred 0.1241 LossAtt 0.5325 TrainAcc 0.9500 TestAcc 0.9114 0.9450
epoch 1100 LossPred 0.1221 LossAtt 0.5401 TrainAcc 0.9500 TestAcc 0.9139 0.9550
epoch 1200 LossPred 0.1310 LossAtt 0.5522 TrainAcc 0.9600 TestAcc 0.9047 0.9550
epoch 1300 LossPred 0.0950 LossAtt 0.5370 TrainAcc 0.9900 TestAcc 0.9249 0.9700
epoch 1400 LossPred 0.1092 LossAtt 0.5683 TrainAcc 0.9600 TestAcc 0.9269 0.9700
epoch 1500 LossPred 0.1083 LossAtt 0.5306 TrainAcc 0.9500 TestAcc 0.9179 0.9650
epoch 1600 LossPred 0.0781 LossAtt 0.5076 TrainAcc 0.9800 TestAcc 0.9139 0.9600
epoch 1700 LossPred 0.0775 LossAtt 0.4972 TrainAcc 0.9700 TestAcc 0.9272 0.9700
epoch 1800 LossPred 0.0762 LossAtt 0.4769 TrainAcc 0.9700 TestAcc 0.9172 0.9700
epoch 1900 LossPred 0.0796 LossAtt 0.4499 TrainAcc 0.9700 TestAcc 0.8969 0.9500
epoch 2000 LossPred 0.2178 LossAtt 0.4564 TrainAcc 0.9200 TestAcc 0.8704 0.9300
epoch 2100 LossPred 0.1015 LossAtt 0.4381 TrainAcc 0.9600 TestAcc 0.9104 0.9600
epoch 2200 LossPred 0.0817 LossAtt 0.4151 TrainAcc 0.9800 TestAcc 0.9049 0.9650
epoch 2300 LossPred 0.1161 LossAtt 0.4232 TrainAcc 0.9500 TestAcc 0.9072 0.9650
epoch 2400 LossPred 0.0624 LossAtt 0.3831 TrainAcc 0.9700 TestAcc 0.9047 0.9550
epoch 2500 LossPred 0.0781 LossAtt 0.4135 TrainAcc 0.9700 TestAcc 0.9207 0.9700
Optimization Finished!
********** replication  35  **********
epoch   0 LossPred 1.4172 LossAtt 1.0386 TrainAcc 0.4200 TestAcc 0.5000 0.4450
epoch 100 LossPred 1.0948 LossAtt 0.5671 TrainAcc 0.5200 TestAcc 0.5428 0.5250
epoch 200 LossPred 0.9964 LossAtt 0.5838 TrainAcc 0.5000 TestAcc 0.5263 0.4750
epoch 300 LossPred 0.9531 LossAtt 0.4951 TrainAcc 0.6300 TestAcc 0.5796 0.6350
epoch 400 LossPred 0.7616 LossAtt 0.4970 TrainAcc 0.7300 TestAcc 0.7265 0.7500
epoch 500 LossPred 0.5166 LossAtt 0.5138 TrainAcc 0.8500 TestAcc 0.8453 0.8150
epoch 600 LossPred 0.4558 LossAtt 0.4669 TrainAcc 0.8600 TestAcc 0.8711 0.8350
epoch 700 LossPred 0.4283 LossAtt 0.4551 TrainAcc 0.8900 TestAcc 0.8569 0.8350
epoch 800 LossPred 0.4316 LossAtt 0.4388 TrainAcc 0.8600 TestAcc 0.8381 0.8600
epoch 900 LossPred 0.3402 LossAtt 0.4422 TrainAcc 0.9100 TestAcc 0.8616 0.8750
epoch 1000 LossPred 0.4755 LossAtt 0.4497 TrainAcc 0.8600 TestAcc 0.7913 0.8200
epoch 1100 LossPred 0.3062 LossAtt 0.4347 TrainAcc 0.9100 TestAcc 0.8731 0.8850
epoch 1200 LossPred 0.2895 LossAtt 0.4112 TrainAcc 0.9000 TestAcc 0.8949 0.8750
epoch 1300 LossPred 0.5166 LossAtt 0.3896 TrainAcc 0.8200 TestAcc 0.8659 0.7950
epoch 1400 LossPred 0.2444 LossAtt 0.3939 TrainAcc 0.9200 TestAcc 0.8979 0.9100
epoch 1500 LossPred 0.4563 LossAtt 0.3823 TrainAcc 0.8500 TestAcc 0.7933 0.8350
epoch 1600 LossPred 0.2360 LossAtt 0.3766 TrainAcc 0.9300 TestAcc 0.8959 0.9050
epoch 1700 LossPred 0.2716 LossAtt 0.3713 TrainAcc 0.9000 TestAcc 0.9052 0.9000
epoch 1800 LossPred 0.2899 LossAtt 0.3690 TrainAcc 0.8900 TestAcc 0.9057 0.8850
epoch 1900 LossPred 0.1941 LossAtt 0.3675 TrainAcc 0.9400 TestAcc 0.9052 0.9100
epoch 2000 LossPred 0.1864 LossAtt 0.3521 TrainAcc 0.9500 TestAcc 0.9017 0.9350
epoch 2100 LossPred 0.1682 LossAtt 0.3493 TrainAcc 0.9500 TestAcc 0.9052 0.9250
epoch 2200 LossPred 0.2389 LossAtt 0.3438 TrainAcc 0.9200 TestAcc 0.8634 0.9050
epoch 2300 LossPred 0.1992 LossAtt 0.3446 TrainAcc 0.9300 TestAcc 0.8809 0.9250
epoch 2400 LossPred 0.1607 LossAtt 0.3486 TrainAcc 0.9500 TestAcc 0.9137 0.9200
epoch 2500 LossPred 0.1644 LossAtt 0.3556 TrainAcc 0.9400 TestAcc 0.8979 0.9300
Optimization Finished!
********** replication  36  **********
epoch   0 LossPred 1.1747 LossAtt 1.0547 TrainAcc 0.4700 TestAcc 0.5050 0.4650
epoch 100 LossPred 0.9192 LossAtt 0.5332 TrainAcc 0.6600 TestAcc 0.5901 0.6550
epoch 200 LossPred 0.8928 LossAtt 0.5226 TrainAcc 0.6600 TestAcc 0.5901 0.6600
epoch 300 LossPred 0.8799 LossAtt 0.4977 TrainAcc 0.6600 TestAcc 0.5901 0.6600
epoch 400 LossPred 0.8544 LossAtt 0.4914 TrainAcc 0.6800 TestAcc 0.5963 0.6800
epoch 500 LossPred 0.5493 LossAtt 0.5042 TrainAcc 0.8300 TestAcc 0.8216 0.8300
epoch 600 LossPred 0.3351 LossAtt 0.5104 TrainAcc 0.9000 TestAcc 0.8656 0.8950
epoch 700 LossPred 0.2465 LossAtt 0.5521 TrainAcc 0.9400 TestAcc 0.8944 0.9050
epoch 800 LossPred 0.2194 LossAtt 0.5616 TrainAcc 0.9500 TestAcc 0.9099 0.9300
epoch 900 LossPred 0.1939 LossAtt 0.5630 TrainAcc 0.9600 TestAcc 0.9234 0.9250
epoch 1000 LossPred 0.1852 LossAtt 0.5456 TrainAcc 0.9500 TestAcc 0.9247 0.9200
epoch 1100 LossPred 0.1676 LossAtt 0.5762 TrainAcc 0.9400 TestAcc 0.9319 0.9200
epoch 1200 LossPred 0.1808 LossAtt 0.5762 TrainAcc 0.9600 TestAcc 0.9054 0.9300
epoch 1300 LossPred 0.1390 LossAtt 0.6150 TrainAcc 0.9600 TestAcc 0.9147 0.9450
epoch 1400 LossPred 0.1405 LossAtt 0.5923 TrainAcc 0.9700 TestAcc 0.9244 0.9550
epoch 1500 LossPred 0.1525 LossAtt 0.5814 TrainAcc 0.9600 TestAcc 0.9117 0.9250
epoch 1600 LossPred 0.1302 LossAtt 0.5828 TrainAcc 0.9500 TestAcc 0.9249 0.9450
epoch 1700 LossPred 0.1208 LossAtt 0.5695 TrainAcc 0.9700 TestAcc 0.9117 0.9400
epoch 1800 LossPred 0.0968 LossAtt 0.5975 TrainAcc 0.9900 TestAcc 0.9352 0.9650
epoch 1900 LossPred 0.0751 LossAtt 0.5915 TrainAcc 1.0000 TestAcc 0.9477 0.9700
Optimization Finished!
********** replication  37  **********
epoch   0 LossPred 1.2563 LossAtt 1.0803 TrainAcc 0.3800 TestAcc 0.4169 0.3800
epoch 100 LossPred 0.8970 LossAtt 0.4872 TrainAcc 0.6500 TestAcc 0.6079 0.6100
epoch 200 LossPred 0.8648 LossAtt 0.4473 TrainAcc 0.6700 TestAcc 0.6379 0.6400
epoch 300 LossPred 0.7961 LossAtt 0.5372 TrainAcc 0.7100 TestAcc 0.6537 0.6800
epoch 400 LossPred 0.4777 LossAtt 0.4397 TrainAcc 0.8600 TestAcc 0.7833 0.8550
epoch 500 LossPred 0.2966 LossAtt 0.4109 TrainAcc 0.9200 TestAcc 0.8453 0.8950
epoch 600 LossPred 0.2747 LossAtt 0.3860 TrainAcc 0.9300 TestAcc 0.8466 0.8850
epoch 700 LossPred 0.2828 LossAtt 0.3944 TrainAcc 0.9200 TestAcc 0.8506 0.8900
epoch 800 LossPred 0.2574 LossAtt 0.3985 TrainAcc 0.9300 TestAcc 0.8473 0.8800
epoch 900 LossPred 0.2248 LossAtt 0.4023 TrainAcc 0.9400 TestAcc 0.8486 0.8900
epoch 1000 LossPred 0.2463 LossAtt 0.3909 TrainAcc 0.9300 TestAcc 0.8341 0.8850
epoch 1100 LossPred 0.4039 LossAtt 0.3686 TrainAcc 0.8700 TestAcc 0.8231 0.8650
epoch 1200 LossPred 0.3187 LossAtt 0.3925 TrainAcc 0.9000 TestAcc 0.8426 0.8650
epoch 1300 LossPred 0.2408 LossAtt 0.3696 TrainAcc 0.9400 TestAcc 0.8336 0.8900
epoch 1400 LossPred 0.2425 LossAtt 0.3512 TrainAcc 0.9300 TestAcc 0.8481 0.8900
epoch 1500 LossPred 0.2429 LossAtt 0.3713 TrainAcc 0.9400 TestAcc 0.8371 0.8800
epoch 1600 LossPred 0.2010 LossAtt 0.3499 TrainAcc 0.9400 TestAcc 0.8526 0.8900
epoch 1700 LossPred 0.2361 LossAtt 0.3514 TrainAcc 0.9400 TestAcc 0.8559 0.8900
epoch 1800 LossPred 0.2406 LossAtt 0.3420 TrainAcc 0.9200 TestAcc 0.8383 0.8800
epoch 1900 LossPred 0.2154 LossAtt 0.3580 TrainAcc 0.9400 TestAcc 0.8556 0.8900
epoch 2000 LossPred 0.2426 LossAtt 0.3544 TrainAcc 0.9300 TestAcc 0.8373 0.8900
epoch 2100 LossPred 0.1803 LossAtt 0.3380 TrainAcc 0.9400 TestAcc 0.8569 0.8900
epoch 2200 LossPred 0.1956 LossAtt 0.3496 TrainAcc 0.9400 TestAcc 0.8546 0.8900
epoch 2300 LossPred 0.1378 LossAtt 0.3524 TrainAcc 0.9600 TestAcc 0.8564 0.8900
epoch 2400 LossPred 0.1429 LossAtt 0.3378 TrainAcc 0.9500 TestAcc 0.8486 0.8900
epoch 2500 LossPred 0.1361 LossAtt 0.3448 TrainAcc 0.9600 TestAcc 0.8546 0.8900
Optimization Finished!
********** replication  38  **********
epoch   0 LossPred 1.2529 LossAtt 1.0119 TrainAcc 0.4300 TestAcc 0.4600 0.4250
epoch 100 LossPred 0.9176 LossAtt 0.4442 TrainAcc 0.6400 TestAcc 0.5756 0.6400
epoch 200 LossPred 0.9044 LossAtt 0.3629 TrainAcc 0.6400 TestAcc 0.5756 0.6400
epoch 300 LossPred 0.8986 LossAtt 0.3022 TrainAcc 0.6400 TestAcc 0.5756 0.6400
epoch 400 LossPred 0.8926 LossAtt 0.2952 TrainAcc 0.6400 TestAcc 0.5756 0.6400
epoch 500 LossPred 0.8849 LossAtt 0.2766 TrainAcc 0.6400 TestAcc 0.5756 0.6400
epoch 600 LossPred 0.8753 LossAtt 0.2581 TrainAcc 0.6400 TestAcc 0.5756 0.6500
epoch 700 LossPred 0.8669 LossAtt 0.2649 TrainAcc 0.6900 TestAcc 0.6154 0.6650
epoch 800 LossPred 0.8527 LossAtt 0.2477 TrainAcc 0.7000 TestAcc 0.6296 0.7050
epoch 900 LossPred 0.5122 LossAtt 0.3351 TrainAcc 0.8400 TestAcc 0.8303 0.8050
epoch 1000 LossPred 0.3235 LossAtt 0.2985 TrainAcc 0.9000 TestAcc 0.8699 0.8650
epoch 1100 LossPred 0.3150 LossAtt 0.2809 TrainAcc 0.9000 TestAcc 0.8581 0.8700
epoch 1200 LossPred 0.2885 LossAtt 0.2814 TrainAcc 0.9000 TestAcc 0.8681 0.8700
epoch 1300 LossPred 0.2706 LossAtt 0.2822 TrainAcc 0.9200 TestAcc 0.8786 0.8700
epoch 1400 LossPred 0.2985 LossAtt 0.2798 TrainAcc 0.9000 TestAcc 0.8531 0.8650
epoch 1500 LossPred 0.2414 LossAtt 0.2986 TrainAcc 0.9200 TestAcc 0.8781 0.8800
epoch 1600 LossPred 0.2445 LossAtt 0.3086 TrainAcc 0.9300 TestAcc 0.8744 0.8900
epoch 1700 LossPred 0.3046 LossAtt 0.3074 TrainAcc 0.8700 TestAcc 0.8936 0.8500
epoch 1800 LossPred 0.2338 LossAtt 0.3238 TrainAcc 0.9100 TestAcc 0.8844 0.8950
epoch 1900 LossPred 0.2416 LossAtt 0.3253 TrainAcc 0.9200 TestAcc 0.8709 0.8750
epoch 2000 LossPred 0.1873 LossAtt 0.3324 TrainAcc 0.9200 TestAcc 0.9034 0.9100
epoch 2100 LossPred 0.3204 LossAtt 0.3289 TrainAcc 0.8600 TestAcc 0.8686 0.8550
epoch 2200 LossPred 0.1839 LossAtt 0.3056 TrainAcc 0.9400 TestAcc 0.9007 0.9150
epoch 2300 LossPred 0.2197 LossAtt 0.3131 TrainAcc 0.9200 TestAcc 0.8896 0.8900
epoch 2400 LossPred 0.2057 LossAtt 0.3046 TrainAcc 0.9200 TestAcc 0.9149 0.9150
epoch 2500 LossPred 0.2301 LossAtt 0.3130 TrainAcc 0.9200 TestAcc 0.8774 0.9000
Optimization Finished!
********** replication  39  **********
epoch   0 LossPred 1.1437 LossAtt 0.9963 TrainAcc 0.5100 TestAcc 0.5278 0.5150
epoch 100 LossPred 0.8644 LossAtt 0.5511 TrainAcc 0.5500 TestAcc 0.6024 0.5500
epoch 200 LossPred 0.3800 LossAtt 0.5533 TrainAcc 0.9400 TestAcc 0.9042 0.8700
epoch 300 LossPred 0.2846 LossAtt 0.5618 TrainAcc 0.9700 TestAcc 0.8939 0.9050
epoch 400 LossPred 0.2347 LossAtt 0.5734 TrainAcc 0.9600 TestAcc 0.9024 0.8950
epoch 500 LossPred 0.2139 LossAtt 0.5526 TrainAcc 0.9700 TestAcc 0.8949 0.9100
epoch 600 LossPred 0.1909 LossAtt 0.5564 TrainAcc 0.9500 TestAcc 0.9044 0.8900
epoch 700 LossPred 0.1872 LossAtt 0.5538 TrainAcc 0.9300 TestAcc 0.8806 0.9100
epoch 800 LossPred 0.2099 LossAtt 0.5399 TrainAcc 0.9500 TestAcc 0.9049 0.8900
epoch 900 LossPred 0.3278 LossAtt 0.4845 TrainAcc 0.8900 TestAcc 0.8924 0.8950
epoch 1000 LossPred 0.2282 LossAtt 0.4032 TrainAcc 0.9100 TestAcc 0.8741 0.9100
epoch 1100 LossPred 0.2742 LossAtt 0.3954 TrainAcc 0.9100 TestAcc 0.8266 0.8800
epoch 1200 LossPred 0.1851 LossAtt 0.3816 TrainAcc 0.9600 TestAcc 0.8971 0.9350
epoch 1300 LossPred 0.2221 LossAtt 0.3857 TrainAcc 0.9400 TestAcc 0.8516 0.9000
epoch 1400 LossPred 0.2126 LossAtt 0.3887 TrainAcc 0.9400 TestAcc 0.8631 0.8950
epoch 1500 LossPred 0.1903 LossAtt 0.3725 TrainAcc 0.9400 TestAcc 0.8654 0.9100
epoch 1600 LossPred 0.1589 LossAtt 0.3859 TrainAcc 0.9700 TestAcc 0.8944 0.9350
epoch 1700 LossPred 0.1622 LossAtt 0.3781 TrainAcc 0.9700 TestAcc 0.8869 0.9450
epoch 1800 LossPred 0.2276 LossAtt 0.3962 TrainAcc 0.9100 TestAcc 0.8504 0.9050
epoch 1900 LossPred 0.2016 LossAtt 0.3901 TrainAcc 0.9200 TestAcc 0.8649 0.9050
epoch 2000 LossPred 0.3854 LossAtt 0.3948 TrainAcc 0.8400 TestAcc 0.7913 0.8700
epoch 2100 LossPred 0.1279 LossAtt 0.4020 TrainAcc 0.9800 TestAcc 0.8884 0.9550
epoch 2200 LossPred 0.1735 LossAtt 0.4351 TrainAcc 0.9500 TestAcc 0.8644 0.9250
epoch 2300 LossPred 0.2574 LossAtt 0.4434 TrainAcc 0.9200 TestAcc 0.8453 0.8950
epoch 2400 LossPred 0.1298 LossAtt 0.4304 TrainAcc 0.9800 TestAcc 0.8929 0.9450
epoch 2500 LossPred 0.2627 LossAtt 0.4621 TrainAcc 0.9300 TestAcc 0.8659 0.8850
Optimization Finished!
********** replication  40  **********
epoch   0 LossPred 1.3049 LossAtt 1.0220 TrainAcc 0.5000 TestAcc 0.5818 0.4900
epoch 100 LossPred 0.9237 LossAtt 0.4260 TrainAcc 0.5900 TestAcc 0.6194 0.5850
epoch 200 LossPred 0.6107 LossAtt 0.4015 TrainAcc 0.8700 TestAcc 0.8363 0.8100
epoch 300 LossPred 0.5007 LossAtt 0.3714 TrainAcc 0.8600 TestAcc 0.8371 0.8100
epoch 400 LossPred 0.4532 LossAtt 0.4196 TrainAcc 0.8700 TestAcc 0.8549 0.8250
epoch 500 LossPred 0.4816 LossAtt 0.4782 TrainAcc 0.8300 TestAcc 0.8216 0.7850
epoch 600 LossPred 0.6129 LossAtt 0.4557 TrainAcc 0.7900 TestAcc 0.7720 0.7750
epoch 700 LossPred 0.4026 LossAtt 0.4517 TrainAcc 0.8700 TestAcc 0.8621 0.8300
epoch 800 LossPred 0.4060 LossAtt 0.4279 TrainAcc 0.8700 TestAcc 0.8659 0.8750
epoch 900 LossPred 0.3938 LossAtt 0.4152 TrainAcc 0.8700 TestAcc 0.8634 0.8700
epoch 1000 LossPred 0.4087 LossAtt 0.3971 TrainAcc 0.8500 TestAcc 0.8504 0.8700
epoch 1100 LossPred 0.2979 LossAtt 0.3789 TrainAcc 0.9100 TestAcc 0.8891 0.8800
epoch 1200 LossPred 0.3199 LossAtt 0.3874 TrainAcc 0.8900 TestAcc 0.8869 0.8700
epoch 1300 LossPred 0.2984 LossAtt 0.3501 TrainAcc 0.9000 TestAcc 0.8921 0.8750
epoch 1400 LossPred 0.2784 LossAtt 0.3695 TrainAcc 0.9200 TestAcc 0.8834 0.8800
epoch 1500 LossPred 0.4674 LossAtt 0.3787 TrainAcc 0.8200 TestAcc 0.8311 0.8550
epoch 1600 LossPred 0.4997 LossAtt 0.3598 TrainAcc 0.8400 TestAcc 0.7993 0.8150
epoch 1700 LossPred 0.3656 LossAtt 0.3444 TrainAcc 0.8600 TestAcc 0.8524 0.8750
epoch 1800 LossPred 0.3931 LossAtt 0.3698 TrainAcc 0.8800 TestAcc 0.8496 0.8300
epoch 1900 LossPred 0.2688 LossAtt 0.3444 TrainAcc 0.9400 TestAcc 0.8871 0.8850
epoch 2000 LossPred 0.2937 LossAtt 0.3457 TrainAcc 0.9000 TestAcc 0.8911 0.8850
epoch 2100 LossPred 0.3301 LossAtt 0.3286 TrainAcc 0.8900 TestAcc 0.8789 0.8950
epoch 2200 LossPred 0.2738 LossAtt 0.3488 TrainAcc 0.9100 TestAcc 0.8931 0.8950
epoch 2300 LossPred 0.2514 LossAtt 0.3255 TrainAcc 0.9300 TestAcc 0.8906 0.8950
epoch 2400 LossPred 0.2771 LossAtt 0.3190 TrainAcc 0.9200 TestAcc 0.8929 0.8900
epoch 2500 LossPred 0.3227 LossAtt 0.3212 TrainAcc 0.9000 TestAcc 0.8706 0.8850
Optimization Finished!
********** replication  41  **********
epoch   0 LossPred 1.4904 LossAtt 1.0134 TrainAcc 0.3300 TestAcc 0.4089 0.3300
epoch 100 LossPred 0.8290 LossAtt 0.4880 TrainAcc 0.7200 TestAcc 0.6499 0.7000
epoch 200 LossPred 0.7595 LossAtt 0.5190 TrainAcc 0.7300 TestAcc 0.6489 0.7300
epoch 300 LossPred 0.7337 LossAtt 0.5855 TrainAcc 0.7200 TestAcc 0.6502 0.7350
epoch 400 LossPred 0.7045 LossAtt 0.6313 TrainAcc 0.7500 TestAcc 0.6832 0.7550
epoch 500 LossPred 0.3886 LossAtt 0.6574 TrainAcc 0.8900 TestAcc 0.8343 0.8900
epoch 600 LossPred 0.3653 LossAtt 0.6109 TrainAcc 0.8900 TestAcc 0.8296 0.8700
epoch 700 LossPred 0.3287 LossAtt 0.5776 TrainAcc 0.9000 TestAcc 0.8493 0.8650
epoch 800 LossPred 0.2913 LossAtt 0.5844 TrainAcc 0.9100 TestAcc 0.8463 0.8900
epoch 900 LossPred 0.3360 LossAtt 0.5855 TrainAcc 0.8600 TestAcc 0.8431 0.8600
epoch 1000 LossPred 0.3419 LossAtt 0.5585 TrainAcc 0.8700 TestAcc 0.8281 0.8650
epoch 1100 LossPred 0.2868 LossAtt 0.5700 TrainAcc 0.9000 TestAcc 0.8478 0.8900
epoch 1200 LossPred 0.2548 LossAtt 0.5657 TrainAcc 0.9100 TestAcc 0.8621 0.8850
epoch 1300 LossPred 0.2427 LossAtt 0.5374 TrainAcc 0.9200 TestAcc 0.8609 0.8900
epoch 1400 LossPred 0.2454 LossAtt 0.5663 TrainAcc 0.9200 TestAcc 0.8676 0.8850
epoch 1500 LossPred 0.2874 LossAtt 0.5739 TrainAcc 0.9000 TestAcc 0.8534 0.8900
epoch 1600 LossPred 0.2515 LossAtt 0.5464 TrainAcc 0.9100 TestAcc 0.8546 0.8650
epoch 1700 LossPred 0.2503 LossAtt 0.5585 TrainAcc 0.9100 TestAcc 0.8574 0.8750
epoch 1800 LossPred 0.3352 LossAtt 0.5757 TrainAcc 0.8800 TestAcc 0.8331 0.8400
epoch 1900 LossPred 0.2305 LossAtt 0.5675 TrainAcc 0.9200 TestAcc 0.8756 0.8850
epoch 2000 LossPred 0.2526 LossAtt 0.5572 TrainAcc 0.9000 TestAcc 0.8639 0.8950
epoch 2100 LossPred 0.2063 LossAtt 0.5655 TrainAcc 0.9200 TestAcc 0.8826 0.8950
epoch 2200 LossPred 0.2120 LossAtt 0.5511 TrainAcc 0.9300 TestAcc 0.8834 0.9100
epoch 2300 LossPred 0.2377 LossAtt 0.5485 TrainAcc 0.9100 TestAcc 0.8691 0.9100
epoch 2400 LossPred 0.1814 LossAtt 0.5463 TrainAcc 0.9500 TestAcc 0.8681 0.9150
epoch 2500 LossPred 0.2784 LossAtt 0.5575 TrainAcc 0.9000 TestAcc 0.8453 0.9150
Optimization Finished!
********** replication  42  **********
epoch   0 LossPred 1.0226 LossAtt 0.9747 TrainAcc 0.4800 TestAcc 0.4635 0.5000
epoch 100 LossPred 0.8529 LossAtt 0.5212 TrainAcc 0.6300 TestAcc 0.5941 0.6300
epoch 200 LossPred 0.7925 LossAtt 0.5053 TrainAcc 0.7300 TestAcc 0.6547 0.7250
epoch 300 LossPred 0.4537 LossAtt 0.6238 TrainAcc 0.8800 TestAcc 0.8416 0.8550
epoch 400 LossPred 0.4061 LossAtt 0.6024 TrainAcc 0.8600 TestAcc 0.8504 0.8650
epoch 500 LossPred 0.3522 LossAtt 0.6016 TrainAcc 0.8800 TestAcc 0.8761 0.8550
epoch 600 LossPred 0.3317 LossAtt 0.5856 TrainAcc 0.8900 TestAcc 0.8861 0.8500
epoch 700 LossPred 0.3199 LossAtt 0.5916 TrainAcc 0.9000 TestAcc 0.8859 0.8400
epoch 800 LossPred 0.4139 LossAtt 0.5707 TrainAcc 0.8500 TestAcc 0.8811 0.8400
epoch 900 LossPred 0.3188 LossAtt 0.5707 TrainAcc 0.9000 TestAcc 0.8729 0.8750
epoch 1000 LossPred 0.2969 LossAtt 0.5472 TrainAcc 0.8800 TestAcc 0.8764 0.8650
epoch 1100 LossPred 0.3669 LossAtt 0.5421 TrainAcc 0.8700 TestAcc 0.8569 0.8700
epoch 1200 LossPred 0.2834 LossAtt 0.5332 TrainAcc 0.8900 TestAcc 0.8874 0.8550
epoch 1300 LossPred 0.2806 LossAtt 0.5034 TrainAcc 0.8900 TestAcc 0.8794 0.8700
epoch 1400 LossPred 0.5016 LossAtt 0.5233 TrainAcc 0.8300 TestAcc 0.8146 0.8350
epoch 1500 LossPred 0.2738 LossAtt 0.5089 TrainAcc 0.9000 TestAcc 0.8881 0.8600
epoch 1600 LossPred 0.4180 LossAtt 0.4926 TrainAcc 0.8300 TestAcc 0.8814 0.8350
epoch 1700 LossPred 0.2876 LossAtt 0.5040 TrainAcc 0.8900 TestAcc 0.8721 0.8850
epoch 1800 LossPred 0.2951 LossAtt 0.4707 TrainAcc 0.8800 TestAcc 0.8959 0.8500
epoch 1900 LossPred 0.2539 LossAtt 0.4795 TrainAcc 0.9200 TestAcc 0.8931 0.8650
epoch 2000 LossPred 0.2522 LossAtt 0.4752 TrainAcc 0.9200 TestAcc 0.8924 0.8750
epoch 2100 LossPred 0.2489 LossAtt 0.4654 TrainAcc 0.9200 TestAcc 0.8949 0.8750
epoch 2200 LossPred 0.2601 LossAtt 0.4273 TrainAcc 0.9100 TestAcc 0.9024 0.8750
epoch 2300 LossPred 0.3534 LossAtt 0.4535 TrainAcc 0.8500 TestAcc 0.8986 0.8400
epoch 2400 LossPred 0.2390 LossAtt 0.4500 TrainAcc 0.9400 TestAcc 0.9064 0.8900
epoch 2500 LossPred 0.2687 LossAtt 0.4213 TrainAcc 0.8900 TestAcc 0.9134 0.8650
Optimization Finished!
********** replication  43  **********
epoch   0 LossPred 1.1837 LossAtt 1.0426 TrainAcc 0.4100 TestAcc 0.5098 0.4100
epoch 100 LossPred 0.8488 LossAtt 0.5028 TrainAcc 0.6800 TestAcc 0.6004 0.6750
epoch 200 LossPred 0.4382 LossAtt 0.4793 TrainAcc 0.8900 TestAcc 0.8426 0.8650
epoch 300 LossPred 0.3932 LossAtt 0.4611 TrainAcc 0.8900 TestAcc 0.8516 0.8500
epoch 400 LossPred 0.3519 LossAtt 0.4392 TrainAcc 0.9200 TestAcc 0.8639 0.8400
epoch 500 LossPred 0.2856 LossAtt 0.4300 TrainAcc 0.9200 TestAcc 0.8904 0.8500
epoch 600 LossPred 0.2595 LossAtt 0.2959 TrainAcc 0.8800 TestAcc 0.9004 0.8700
epoch 700 LossPred 0.4881 LossAtt 0.2886 TrainAcc 0.8100 TestAcc 0.8048 0.7850
epoch 800 LossPred 0.3413 LossAtt 0.2998 TrainAcc 0.9000 TestAcc 0.8646 0.8750
epoch 900 LossPred 0.3200 LossAtt 0.2910 TrainAcc 0.8500 TestAcc 0.8776 0.8550
epoch 1000 LossPred 0.2351 LossAtt 0.2925 TrainAcc 0.9300 TestAcc 0.9057 0.8950
epoch 1100 LossPred 0.2543 LossAtt 0.2907 TrainAcc 0.8900 TestAcc 0.8986 0.8700
epoch 1200 LossPred 0.2133 LossAtt 0.2586 TrainAcc 0.9400 TestAcc 0.9004 0.9100
epoch 1300 LossPred 0.2039 LossAtt 0.2362 TrainAcc 0.9400 TestAcc 0.8961 0.9350
epoch 1400 LossPred 0.1974 LossAtt 0.2262 TrainAcc 0.9400 TestAcc 0.9032 0.9400
epoch 1500 LossPred 0.1935 LossAtt 0.2147 TrainAcc 0.9400 TestAcc 0.9042 0.9400
epoch 1600 LossPred 0.1860 LossAtt 0.1838 TrainAcc 0.9300 TestAcc 0.8996 0.9350
epoch 1700 LossPred 0.2189 LossAtt 0.1940 TrainAcc 0.9100 TestAcc 0.9064 0.9100
epoch 1800 LossPred 0.1825 LossAtt 0.1857 TrainAcc 0.9400 TestAcc 0.9037 0.9350
epoch 1900 LossPred 0.1867 LossAtt 0.1918 TrainAcc 0.9200 TestAcc 0.8984 0.9500
epoch 2000 LossPred 0.1763 LossAtt 0.2022 TrainAcc 0.9400 TestAcc 0.9087 0.9500
epoch 2100 LossPred 0.1716 LossAtt 0.1857 TrainAcc 0.9600 TestAcc 0.9122 0.9550
epoch 2200 LossPred 0.1919 LossAtt 0.1980 TrainAcc 0.9200 TestAcc 0.9174 0.9450
epoch 2300 LossPred 0.1716 LossAtt 0.2209 TrainAcc 0.9500 TestAcc 0.9072 0.9600
epoch 2400 LossPred 0.1878 LossAtt 0.2387 TrainAcc 0.9500 TestAcc 0.9032 0.9600
epoch 2500 LossPred 0.1572 LossAtt 0.2523 TrainAcc 0.9400 TestAcc 0.9244 0.9650
Optimization Finished!
********** replication  44  **********
epoch   0 LossPred 1.2338 LossAtt 1.0465 TrainAcc 0.4900 TestAcc 0.4922 0.4900
epoch 100 LossPred 1.0121 LossAtt 0.5532 TrainAcc 0.5400 TestAcc 0.5618 0.5500
epoch 200 LossPred 0.9801 LossAtt 0.5345 TrainAcc 0.5400 TestAcc 0.5636 0.5050
epoch 300 LossPred 0.9702 LossAtt 0.4517 TrainAcc 0.5400 TestAcc 0.5673 0.5350
epoch 400 LossPred 0.9622 LossAtt 0.4412 TrainAcc 0.6000 TestAcc 0.6211 0.5800
epoch 500 LossPred 0.9119 LossAtt 0.4605 TrainAcc 0.6700 TestAcc 0.6389 0.6700
epoch 600 LossPred 0.5761 LossAtt 0.5179 TrainAcc 0.8200 TestAcc 0.7810 0.8300
epoch 700 LossPred 0.4238 LossAtt 0.4257 TrainAcc 0.8600 TestAcc 0.7928 0.8750
epoch 800 LossPred 0.3334 LossAtt 0.3931 TrainAcc 0.9000 TestAcc 0.7968 0.8800
epoch 900 LossPred 0.3456 LossAtt 0.3677 TrainAcc 0.8800 TestAcc 0.7960 0.8850
epoch 1000 LossPred 0.4950 LossAtt 0.3558 TrainAcc 0.8500 TestAcc 0.7653 0.8200
epoch 1100 LossPred 0.4849 LossAtt 0.3632 TrainAcc 0.8500 TestAcc 0.7703 0.8300
epoch 1200 LossPred 0.4705 LossAtt 0.3827 TrainAcc 0.8500 TestAcc 0.7708 0.8350
epoch 1300 LossPred 0.4690 LossAtt 0.3579 TrainAcc 0.8500 TestAcc 0.7778 0.8350
epoch 1400 LossPred 0.4639 LossAtt 0.3463 TrainAcc 0.8500 TestAcc 0.7793 0.8450
epoch 1500 LossPred 0.4167 LossAtt 0.3507 TrainAcc 0.8700 TestAcc 0.7800 0.8650
epoch 1600 LossPred 0.4267 LossAtt 0.3310 TrainAcc 0.8700 TestAcc 0.7873 0.8600
epoch 1700 LossPred 0.4133 LossAtt 0.3318 TrainAcc 0.8600 TestAcc 0.7858 0.8650
epoch 1800 LossPred 0.5427 LossAtt 0.3647 TrainAcc 0.8100 TestAcc 0.7415 0.8050
epoch 1900 LossPred 0.5479 LossAtt 0.3575 TrainAcc 0.8100 TestAcc 0.7405 0.8050
epoch 2000 LossPred 0.5438 LossAtt 0.3560 TrainAcc 0.8100 TestAcc 0.7425 0.8100
epoch 2100 LossPred 0.5420 LossAtt 0.3376 TrainAcc 0.8100 TestAcc 0.7437 0.8050
epoch 2200 LossPred 0.4469 LossAtt 0.3503 TrainAcc 0.8500 TestAcc 0.7605 0.8450
epoch 2300 LossPred 0.4432 LossAtt 0.3648 TrainAcc 0.8500 TestAcc 0.7605 0.8400
epoch 2400 LossPred 0.4351 LossAtt 0.3561 TrainAcc 0.8600 TestAcc 0.7610 0.8400
epoch 2500 LossPred 0.4367 LossAtt 0.3480 TrainAcc 0.8600 TestAcc 0.7618 0.8450
Optimization Finished!
********** replication  45  **********
epoch   0 LossPred 1.3236 LossAtt 0.9952 TrainAcc 0.4400 TestAcc 0.4817 0.4350
epoch 100 LossPred 0.9736 LossAtt 0.4856 TrainAcc 0.5500 TestAcc 0.5333 0.5500
epoch 200 LossPred 0.8937 LossAtt 0.5271 TrainAcc 0.6600 TestAcc 0.5793 0.6600
epoch 300 LossPred 0.4723 LossAtt 0.6818 TrainAcc 0.8500 TestAcc 0.8664 0.8100
epoch 400 LossPred 0.3884 LossAtt 0.6470 TrainAcc 0.8700 TestAcc 0.8819 0.7900
epoch 500 LossPred 0.3884 LossAtt 0.6712 TrainAcc 0.8700 TestAcc 0.8599 0.8100
epoch 600 LossPred 0.3335 LossAtt 0.6602 TrainAcc 0.8700 TestAcc 0.9007 0.8350
epoch 700 LossPred 0.3132 LossAtt 0.6647 TrainAcc 0.8900 TestAcc 0.9044 0.8350
epoch 800 LossPred 0.2588 LossAtt 0.6503 TrainAcc 0.9100 TestAcc 0.9237 0.8350
epoch 900 LossPred 0.2465 LossAtt 0.6095 TrainAcc 0.9000 TestAcc 0.9332 0.8550
epoch 1000 LossPred 0.2828 LossAtt 0.5734 TrainAcc 0.9100 TestAcc 0.8846 0.8250
epoch 1100 LossPred 0.4509 LossAtt 0.5396 TrainAcc 0.8400 TestAcc 0.8126 0.8200
epoch 1200 LossPred 0.3890 LossAtt 0.5477 TrainAcc 0.8500 TestAcc 0.8809 0.8450
epoch 1300 LossPred 0.2238 LossAtt 0.5408 TrainAcc 0.9200 TestAcc 0.9289 0.8550
epoch 1400 LossPred 0.1947 LossAtt 0.5146 TrainAcc 0.9100 TestAcc 0.9377 0.9000
epoch 1500 LossPred 0.1675 LossAtt 0.4993 TrainAcc 0.9500 TestAcc 0.9419 0.8800
epoch 1600 LossPred 0.1762 LossAtt 0.5017 TrainAcc 0.9400 TestAcc 0.9349 0.8800
epoch 1700 LossPred 0.3710 LossAtt 0.5029 TrainAcc 0.8700 TestAcc 0.8471 0.8250
epoch 1800 LossPred 0.1700 LossAtt 0.5253 TrainAcc 0.9400 TestAcc 0.9527 0.9250
epoch 1900 LossPred 0.1530 LossAtt 0.4952 TrainAcc 0.9500 TestAcc 0.9560 0.9300
epoch 2000 LossPred 0.1390 LossAtt 0.4972 TrainAcc 0.9500 TestAcc 0.9547 0.9300
epoch 2100 LossPred 0.1544 LossAtt 0.4812 TrainAcc 0.9500 TestAcc 0.9327 0.8800
epoch 2200 LossPred 0.1332 LossAtt 0.4838 TrainAcc 0.9400 TestAcc 0.9577 0.9350
epoch 2300 LossPred 0.1984 LossAtt 0.4861 TrainAcc 0.9300 TestAcc 0.9244 0.9000
epoch 2400 LossPred 0.1269 LossAtt 0.4671 TrainAcc 0.9600 TestAcc 0.9575 0.9200
epoch 2500 LossPred 0.2234 LossAtt 0.4740 TrainAcc 0.9100 TestAcc 0.9067 0.8750
Optimization Finished!
********** replication  46  **********
epoch   0 LossPred 0.9162 LossAtt 1.0513 TrainAcc 0.6600 TestAcc 0.5878 0.6550
epoch 100 LossPred 0.8561 LossAtt 0.3637 TrainAcc 0.6600 TestAcc 0.5888 0.6600
epoch 200 LossPred 0.8552 LossAtt 0.2967 TrainAcc 0.6600 TestAcc 0.5888 0.6600
epoch 300 LossPred 0.8546 LossAtt 0.2941 TrainAcc 0.6600 TestAcc 0.5888 0.6600
epoch 400 LossPred 0.8552 LossAtt 0.2778 TrainAcc 0.6600 TestAcc 0.5888 0.6600
epoch 500 LossPred 0.8559 LossAtt 0.3061 TrainAcc 0.6600 TestAcc 0.5888 0.6600
epoch 600 LossPred 0.8536 LossAtt 0.2604 TrainAcc 0.6600 TestAcc 0.5888 0.6600
epoch 700 LossPred 0.8523 LossAtt 0.2354 TrainAcc 0.6600 TestAcc 0.5888 0.6600
epoch 800 LossPred 0.8517 LossAtt 0.1980 TrainAcc 0.6600 TestAcc 0.5888 0.6600
epoch 900 LossPred 0.8514 LossAtt 0.1655 TrainAcc 0.6600 TestAcc 0.5888 0.6600
epoch 1000 LossPred 0.8513 LossAtt 0.1548 TrainAcc 0.6600 TestAcc 0.5888 0.6600
epoch 1100 LossPred 0.8513 LossAtt 0.1359 TrainAcc 0.6600 TestAcc 0.5888 0.6600
epoch 1200 LossPred 0.8512 LossAtt 0.1214 TrainAcc 0.6600 TestAcc 0.5888 0.6600
epoch 1300 LossPred 0.8512 LossAtt 0.1157 TrainAcc 0.6600 TestAcc 0.5888 0.6600
epoch 1400 LossPred 0.8511 LossAtt 0.1227 TrainAcc 0.6600 TestAcc 0.5888 0.6600
epoch 1500 LossPred 0.8510 LossAtt 0.1156 TrainAcc 0.6600 TestAcc 0.5888 0.6600
epoch 1600 LossPred 0.8510 LossAtt 0.1148 TrainAcc 0.6600 TestAcc 0.5888 0.6600
epoch 1700 LossPred 0.8510 LossAtt 0.0882 TrainAcc 0.6600 TestAcc 0.5888 0.6600
epoch 1800 LossPred 0.8510 LossAtt 0.1014 TrainAcc 0.6600 TestAcc 0.5888 0.6600
epoch 1900 LossPred 0.8509 LossAtt 0.1031 TrainAcc 0.6600 TestAcc 0.5888 0.6600
epoch 2000 LossPred 0.8509 LossAtt 0.0771 TrainAcc 0.6600 TestAcc 0.5888 0.6600
epoch 2100 LossPred 0.8509 LossAtt 0.0768 TrainAcc 0.6600 TestAcc 0.5888 0.6600
epoch 2200 LossPred 0.8509 LossAtt 0.0856 TrainAcc 0.6600 TestAcc 0.5888 0.6600
epoch 2300 LossPred 0.8509 LossAtt 0.0758 TrainAcc 0.6600 TestAcc 0.5888 0.6600
epoch 2400 LossPred 0.8509 LossAtt 0.0796 TrainAcc 0.6600 TestAcc 0.5888 0.6600
epoch 2500 LossPred 0.8509 LossAtt 0.0948 TrainAcc 0.6600 TestAcc 0.5888 0.6600
Optimization Finished!
********** replication  47  **********
epoch   0 LossPred 1.1456 LossAtt 1.0254 TrainAcc 0.4800 TestAcc 0.5185 0.4500
epoch 100 LossPred 0.9984 LossAtt 0.3522 TrainAcc 0.5400 TestAcc 0.6081 0.5400
epoch 200 LossPred 0.9783 LossAtt 0.2840 TrainAcc 0.5400 TestAcc 0.6081 0.5400
epoch 300 LossPred 0.9125 LossAtt 0.5053 TrainAcc 0.6200 TestAcc 0.6537 0.6100
epoch 400 LossPred 0.5058 LossAtt 0.4866 TrainAcc 0.8300 TestAcc 0.8273 0.8000
epoch 500 LossPred 0.4109 LossAtt 0.4808 TrainAcc 0.9000 TestAcc 0.8351 0.8400
epoch 600 LossPred 0.4475 LossAtt 0.4284 TrainAcc 0.8800 TestAcc 0.8358 0.8450
epoch 700 LossPred 0.3212 LossAtt 0.4215 TrainAcc 0.8900 TestAcc 0.8401 0.8650
epoch 800 LossPred 0.3591 LossAtt 0.4353 TrainAcc 0.8600 TestAcc 0.8463 0.8650
epoch 900 LossPred 0.3199 LossAtt 0.4403 TrainAcc 0.9100 TestAcc 0.8416 0.8800
epoch 1000 LossPred 0.2930 LossAtt 0.4174 TrainAcc 0.9000 TestAcc 0.8451 0.8800
epoch 1100 LossPred 0.2560 LossAtt 0.4328 TrainAcc 0.9100 TestAcc 0.8441 0.8850
epoch 1200 LossPred 0.7390 LossAtt 0.4988 TrainAcc 0.7500 TestAcc 0.6687 0.7250
epoch 1300 LossPred 0.3336 LossAtt 0.4327 TrainAcc 0.9100 TestAcc 0.8481 0.8750
epoch 1400 LossPred 0.7147 LossAtt 0.4218 TrainAcc 0.7400 TestAcc 0.7102 0.7500
epoch 1500 LossPred 0.5203 LossAtt 0.4309 TrainAcc 0.8000 TestAcc 0.7482 0.7900
epoch 1600 LossPred 0.2980 LossAtt 0.4354 TrainAcc 0.9200 TestAcc 0.8476 0.8950
epoch 1700 LossPred 0.2394 LossAtt 0.4367 TrainAcc 0.9300 TestAcc 0.8471 0.9050
epoch 1800 LossPred 0.2874 LossAtt 0.4314 TrainAcc 0.9100 TestAcc 0.8524 0.8900
epoch 1900 LossPred 0.4159 LossAtt 0.4050 TrainAcc 0.8500 TestAcc 0.7828 0.8050
epoch 2000 LossPred 0.4321 LossAtt 0.4260 TrainAcc 0.8900 TestAcc 0.8146 0.8650
epoch 2100 LossPred 0.2851 LossAtt 0.4419 TrainAcc 0.9100 TestAcc 0.8478 0.8800
epoch 2200 LossPred 0.3255 LossAtt 0.4415 TrainAcc 0.8700 TestAcc 0.8383 0.8550
epoch 2300 LossPred 0.2287 LossAtt 0.4290 TrainAcc 0.9400 TestAcc 0.8509 0.9050
epoch 2400 LossPred 0.2397 LossAtt 0.4508 TrainAcc 0.9300 TestAcc 0.8401 0.9050
epoch 2500 LossPred 0.2415 LossAtt 0.4401 TrainAcc 0.9300 TestAcc 0.8514 0.9050
Optimization Finished!
********** replication  48  **********
epoch   0 LossPred 1.1853 LossAtt 1.0740 TrainAcc 0.4600 TestAcc 0.4692 0.4700
epoch 100 LossPred 0.9630 LossAtt 0.5500 TrainAcc 0.5600 TestAcc 0.5896 0.5600
epoch 200 LossPred 0.9431 LossAtt 0.4826 TrainAcc 0.5900 TestAcc 0.5916 0.5900
epoch 300 LossPred 0.9413 LossAtt 0.3581 TrainAcc 0.5900 TestAcc 0.5916 0.5900
epoch 400 LossPred 0.9390 LossAtt 0.3684 TrainAcc 0.5900 TestAcc 0.5916 0.5900
epoch 500 LossPred 0.9373 LossAtt 0.3603 TrainAcc 0.5900 TestAcc 0.5916 0.5750
epoch 600 LossPred 0.9347 LossAtt 0.3846 TrainAcc 0.5900 TestAcc 0.5708 0.5650
epoch 700 LossPred 0.7899 LossAtt 0.5454 TrainAcc 0.6300 TestAcc 0.7280 0.6450
epoch 800 LossPred 0.5609 LossAtt 0.4485 TrainAcc 0.8400 TestAcc 0.8378 0.8300
epoch 900 LossPred 0.4652 LossAtt 0.4097 TrainAcc 0.8700 TestAcc 0.8361 0.8450
epoch 1000 LossPred 0.4210 LossAtt 0.4027 TrainAcc 0.9100 TestAcc 0.8353 0.8750
epoch 1100 LossPred 0.3932 LossAtt 0.4533 TrainAcc 0.9000 TestAcc 0.8373 0.8750
epoch 1200 LossPred 0.3247 LossAtt 0.5364 TrainAcc 0.8900 TestAcc 0.8569 0.8550
epoch 1300 LossPred 0.2288 LossAtt 0.5391 TrainAcc 0.9300 TestAcc 0.8806 0.8850
epoch 1400 LossPred 0.2283 LossAtt 0.5570 TrainAcc 0.9400 TestAcc 0.8816 0.8900
epoch 1500 LossPred 0.1979 LossAtt 0.5814 TrainAcc 0.9500 TestAcc 0.8819 0.8850
epoch 1600 LossPred 0.1779 LossAtt 0.5930 TrainAcc 0.9600 TestAcc 0.8859 0.8900
epoch 1700 LossPred 0.1571 LossAtt 0.5797 TrainAcc 0.9600 TestAcc 0.8864 0.8900
epoch 1800 LossPred 0.1494 LossAtt 0.5661 TrainAcc 0.9500 TestAcc 0.8911 0.8850
epoch 1900 LossPred 0.1482 LossAtt 0.5767 TrainAcc 0.9600 TestAcc 0.8886 0.8850
epoch 2000 LossPred 0.1433 LossAtt 0.5884 TrainAcc 0.9600 TestAcc 0.8891 0.8850
epoch 2100 LossPred 0.1292 LossAtt 0.5782 TrainAcc 0.9700 TestAcc 0.8889 0.8900
epoch 2200 LossPred 0.1326 LossAtt 0.5677 TrainAcc 0.9600 TestAcc 0.8869 0.8950
epoch 2300 LossPred 0.1392 LossAtt 0.5718 TrainAcc 0.9600 TestAcc 0.8944 0.8850
epoch 2400 LossPred 0.1736 LossAtt 0.5460 TrainAcc 0.9400 TestAcc 0.8789 0.8900
epoch 2500 LossPred 0.1159 LossAtt 0.5713 TrainAcc 0.9800 TestAcc 0.8906 0.8800
Optimization Finished!
********** replication  49  **********
epoch   0 LossPred 1.0929 LossAtt 1.0254 TrainAcc 0.5200 TestAcc 0.4805 0.5100
epoch 100 LossPred 0.9337 LossAtt 0.5630 TrainAcc 0.6100 TestAcc 0.5736 0.6100
epoch 200 LossPred 0.9237 LossAtt 0.5130 TrainAcc 0.6100 TestAcc 0.5736 0.6100
epoch 300 LossPred 0.7718 LossAtt 0.5004 TrainAcc 0.7600 TestAcc 0.7873 0.7000
epoch 400 LossPred 0.5177 LossAtt 0.4901 TrainAcc 0.8700 TestAcc 0.8539 0.8500
epoch 500 LossPred 0.4345 LossAtt 0.4814 TrainAcc 0.8800 TestAcc 0.8581 0.8550
epoch 600 LossPred 0.4577 LossAtt 0.4988 TrainAcc 0.8500 TestAcc 0.8483 0.8600
epoch 700 LossPred 0.3911 LossAtt 0.4766 TrainAcc 0.8900 TestAcc 0.8561 0.8700
epoch 800 LossPred 0.4056 LossAtt 0.4610 TrainAcc 0.8800 TestAcc 0.8516 0.8700
epoch 900 LossPred 0.3985 LossAtt 0.4381 TrainAcc 0.8900 TestAcc 0.8666 0.8750
epoch 1000 LossPred 0.4842 LossAtt 0.4391 TrainAcc 0.8400 TestAcc 0.8128 0.8250
epoch 1100 LossPred 0.3568 LossAtt 0.4385 TrainAcc 0.9000 TestAcc 0.8514 0.8550
epoch 1200 LossPred 0.3744 LossAtt 0.4199 TrainAcc 0.8900 TestAcc 0.8706 0.8800
epoch 1300 LossPred 0.3408 LossAtt 0.3941 TrainAcc 0.8900 TestAcc 0.8646 0.8650
epoch 1400 LossPred 0.3575 LossAtt 0.4046 TrainAcc 0.8900 TestAcc 0.8689 0.8850
epoch 1500 LossPred 0.3862 LossAtt 0.4471 TrainAcc 0.8800 TestAcc 0.8606 0.8650
epoch 1600 LossPred 0.3538 LossAtt 0.4433 TrainAcc 0.8900 TestAcc 0.8671 0.8650
epoch 1700 LossPred 0.4290 LossAtt 0.4458 TrainAcc 0.8700 TestAcc 0.8433 0.8600
epoch 1800 LossPred 0.4075 LossAtt 0.4437 TrainAcc 0.8700 TestAcc 0.8594 0.8750
epoch 1900 LossPred 0.3516 LossAtt 0.4534 TrainAcc 0.8900 TestAcc 0.8786 0.8900
epoch 2000 LossPred 0.3138 LossAtt 0.4370 TrainAcc 0.9100 TestAcc 0.8649 0.8900
epoch 2100 LossPred 0.4849 LossAtt 0.4512 TrainAcc 0.8400 TestAcc 0.8156 0.8400
epoch 2200 LossPred 0.3157 LossAtt 0.4285 TrainAcc 0.9000 TestAcc 0.8824 0.9050
epoch 2300 LossPred 0.3016 LossAtt 0.4290 TrainAcc 0.8900 TestAcc 0.8831 0.8950
epoch 2400 LossPred 0.3350 LossAtt 0.4326 TrainAcc 0.9100 TestAcc 0.8556 0.8900
epoch 2500 LossPred 0.3082 LossAtt 0.4150 TrainAcc 0.9100 TestAcc 0.8561 0.8950
Optimization Finished!
********** replication  50  **********
epoch   0 LossPred 1.0537 LossAtt 1.0031 TrainAcc 0.4500 TestAcc 0.4817 0.4500
epoch 100 LossPred 0.9114 LossAtt 0.4267 TrainAcc 0.6300 TestAcc 0.5628 0.6400
epoch 200 LossPred 0.8945 LossAtt 0.3313 TrainAcc 0.6400 TestAcc 0.5403 0.6400
epoch 300 LossPred 0.8747 LossAtt 0.3504 TrainAcc 0.6400 TestAcc 0.5418 0.6400
epoch 400 LossPred 0.8537 LossAtt 0.3543 TrainAcc 0.6400 TestAcc 0.5438 0.6400
epoch 500 LossPred 0.8205 LossAtt 0.4004 TrainAcc 0.6800 TestAcc 0.5541 0.6700
epoch 600 LossPred 0.7990 LossAtt 0.3559 TrainAcc 0.7000 TestAcc 0.6231 0.6650
epoch 700 LossPred 0.7596 LossAtt 0.3744 TrainAcc 0.6800 TestAcc 0.6324 0.6800
epoch 800 LossPred 0.7347 LossAtt 0.3654 TrainAcc 0.6900 TestAcc 0.6341 0.6800
epoch 900 LossPred 0.7314 LossAtt 0.3501 TrainAcc 0.6800 TestAcc 0.6459 0.6850
epoch 1000 LossPred 0.7067 LossAtt 0.3578 TrainAcc 0.7200 TestAcc 0.6682 0.7000
epoch 1100 LossPred 0.6122 LossAtt 0.3681 TrainAcc 0.7600 TestAcc 0.7457 0.7600
epoch 1200 LossPred 0.5224 LossAtt 0.3644 TrainAcc 0.8100 TestAcc 0.8118 0.8100
epoch 1300 LossPred 0.4783 LossAtt 0.3973 TrainAcc 0.8500 TestAcc 0.8211 0.8200
epoch 1400 LossPred 0.5155 LossAtt 0.3495 TrainAcc 0.8200 TestAcc 0.8108 0.7950
epoch 1500 LossPred 0.4137 LossAtt 0.3836 TrainAcc 0.8500 TestAcc 0.8196 0.8200
epoch 1600 LossPred 0.4577 LossAtt 0.3770 TrainAcc 0.8600 TestAcc 0.8196 0.8300
epoch 1700 LossPred 0.4764 LossAtt 0.4567 TrainAcc 0.8700 TestAcc 0.8053 0.8150
epoch 1800 LossPred 0.4949 LossAtt 0.4748 TrainAcc 0.8400 TestAcc 0.8196 0.8200
epoch 1900 LossPred 0.4156 LossAtt 0.4678 TrainAcc 0.8800 TestAcc 0.8251 0.8300
epoch 2000 LossPred 0.4782 LossAtt 0.4567 TrainAcc 0.8400 TestAcc 0.8311 0.8150
epoch 2100 LossPred 0.4763 LossAtt 0.4365 TrainAcc 0.8500 TestAcc 0.8046 0.8350
epoch 2200 LossPred 0.6312 LossAtt 0.4630 TrainAcc 0.8100 TestAcc 0.7673 0.8250
epoch 2300 LossPred 0.3785 LossAtt 0.4488 TrainAcc 0.9000 TestAcc 0.8233 0.8250
epoch 2400 LossPred 0.5000 LossAtt 0.4772 TrainAcc 0.8300 TestAcc 0.7945 0.8400
epoch 2500 LossPred 0.3772 LossAtt 0.4620 TrainAcc 0.8800 TestAcc 0.8203 0.8000
Optimization Finished!
********** replication  51  **********
epoch   0 LossPred 1.1976 LossAtt 1.0154 TrainAcc 0.4500 TestAcc 0.4690 0.4500
epoch 100 LossPred 0.9033 LossAtt 0.6133 TrainAcc 0.6100 TestAcc 0.5413 0.6200
epoch 200 LossPred 0.8152 LossAtt 0.5748 TrainAcc 0.6900 TestAcc 0.5801 0.6900
epoch 300 LossPred 0.7081 LossAtt 0.5439 TrainAcc 0.7700 TestAcc 0.6166 0.7400
epoch 400 LossPred 0.5754 LossAtt 0.5899 TrainAcc 0.8200 TestAcc 0.6547 0.8100
epoch 500 LossPred 0.5393 LossAtt 0.5162 TrainAcc 0.8100 TestAcc 0.6522 0.8100
epoch 600 LossPred 0.5253 LossAtt 0.4489 TrainAcc 0.8100 TestAcc 0.6532 0.8150
epoch 700 LossPred 0.5124 LossAtt 0.4145 TrainAcc 0.8100 TestAcc 0.6547 0.8100
epoch 800 LossPred 0.5027 LossAtt 0.3839 TrainAcc 0.8100 TestAcc 0.6544 0.8100
epoch 900 LossPred 0.4957 LossAtt 0.3330 TrainAcc 0.8200 TestAcc 0.6582 0.8100
epoch 1000 LossPred 0.4904 LossAtt 0.3287 TrainAcc 0.8200 TestAcc 0.6562 0.8200
epoch 1100 LossPred 0.4868 LossAtt 0.3200 TrainAcc 0.8200 TestAcc 0.6572 0.8150
epoch 1200 LossPred 0.4837 LossAtt 0.3136 TrainAcc 0.8300 TestAcc 0.6476 0.8250
epoch 1300 LossPred 0.4813 LossAtt 0.3250 TrainAcc 0.8300 TestAcc 0.6481 0.8250
epoch 1400 LossPred 0.4799 LossAtt 0.2989 TrainAcc 0.8300 TestAcc 0.6484 0.8250
epoch 1500 LossPred 0.4782 LossAtt 0.3035 TrainAcc 0.8300 TestAcc 0.6474 0.8200
epoch 1600 LossPred 0.4774 LossAtt 0.3230 TrainAcc 0.8300 TestAcc 0.6479 0.8200
epoch 1700 LossPred 0.4766 LossAtt 0.3130 TrainAcc 0.8300 TestAcc 0.6484 0.8200
epoch 1800 LossPred 0.4828 LossAtt 0.4258 TrainAcc 0.8200 TestAcc 0.6579 0.8100
epoch 1900 LossPred 0.4724 LossAtt 0.3815 TrainAcc 0.8300 TestAcc 0.6481 0.8200
epoch 2000 LossPred 0.4712 LossAtt 0.3716 TrainAcc 0.8300 TestAcc 0.6481 0.8250
epoch 2100 LossPred 0.4706 LossAtt 0.3405 TrainAcc 0.8300 TestAcc 0.6481 0.8250
epoch 2200 LossPred 0.4718 LossAtt 0.3690 TrainAcc 0.8300 TestAcc 0.6451 0.8250
epoch 2300 LossPred 0.4697 LossAtt 0.3375 TrainAcc 0.8300 TestAcc 0.6481 0.8300
epoch 2400 LossPred 0.4702 LossAtt 0.3460 TrainAcc 0.8300 TestAcc 0.6484 0.8250
epoch 2500 LossPred 0.4689 LossAtt 0.3359 TrainAcc 0.8300 TestAcc 0.6484 0.8250
Optimization Finished!
********** replication  52  **********
epoch   0 LossPred 1.0111 LossAtt 1.0360 TrainAcc 0.5200 TestAcc 0.5050 0.5000
epoch 100 LossPred 0.8907 LossAtt 0.5803 TrainAcc 0.6200 TestAcc 0.6344 0.6200
epoch 200 LossPred 0.7928 LossAtt 0.5306 TrainAcc 0.6600 TestAcc 0.6842 0.6750
epoch 300 LossPred 0.7111 LossAtt 0.4503 TrainAcc 0.7000 TestAcc 0.7205 0.7250
epoch 400 LossPred 0.5810 LossAtt 0.4029 TrainAcc 0.8000 TestAcc 0.8033 0.7900
epoch 500 LossPred 1.0078 LossAtt 0.4197 TrainAcc 0.5900 TestAcc 0.5480 0.5850
epoch 600 LossPred 0.5511 LossAtt 0.3544 TrainAcc 0.8100 TestAcc 0.8058 0.8350
epoch 700 LossPred 0.5339 LossAtt 0.3503 TrainAcc 0.8200 TestAcc 0.7930 0.7950
epoch 800 LossPred 0.5475 LossAtt 0.3313 TrainAcc 0.8300 TestAcc 0.8143 0.8050
epoch 900 LossPred 0.6329 LossAtt 0.3150 TrainAcc 0.7600 TestAcc 0.7270 0.7300
epoch 1000 LossPred 0.5206 LossAtt 0.3193 TrainAcc 0.8300 TestAcc 0.8076 0.8250
epoch 1100 LossPred 0.5700 LossAtt 0.3341 TrainAcc 0.8100 TestAcc 0.8138 0.8250
epoch 1200 LossPred 0.5416 LossAtt 0.3568 TrainAcc 0.8200 TestAcc 0.7908 0.7900
epoch 1300 LossPred 0.5338 LossAtt 0.3564 TrainAcc 0.8200 TestAcc 0.7935 0.7900
epoch 1400 LossPred 0.4916 LossAtt 0.3680 TrainAcc 0.8400 TestAcc 0.7985 0.8000
epoch 1500 LossPred 0.6626 LossAtt 0.3931 TrainAcc 0.7700 TestAcc 0.7645 0.7600
epoch 1600 LossPred 0.6861 LossAtt 0.3883 TrainAcc 0.7600 TestAcc 0.7653 0.7650
epoch 1700 LossPred 0.5606 LossAtt 0.3840 TrainAcc 0.8100 TestAcc 0.7850 0.7750
epoch 1800 LossPred 0.5490 LossAtt 0.3365 TrainAcc 0.8300 TestAcc 0.7990 0.8250
epoch 1900 LossPred 0.6674 LossAtt 0.3288 TrainAcc 0.7800 TestAcc 0.7595 0.7700
epoch 2000 LossPred 0.4908 LossAtt 0.3623 TrainAcc 0.8400 TestAcc 0.7995 0.8000
epoch 2100 LossPred 0.5439 LossAtt 0.3185 TrainAcc 0.8400 TestAcc 0.8123 0.8300
epoch 2200 LossPred 0.4803 LossAtt 0.3436 TrainAcc 0.8300 TestAcc 0.8031 0.7900
epoch 2300 LossPred 0.8399 LossAtt 0.3444 TrainAcc 0.7100 TestAcc 0.7077 0.7050
epoch 2400 LossPred 0.5235 LossAtt 0.3325 TrainAcc 0.8200 TestAcc 0.7965 0.7900
epoch 2500 LossPred 0.4718 LossAtt 0.3310 TrainAcc 0.8500 TestAcc 0.8286 0.8100
Optimization Finished!
********** replication  53  **********
epoch   0 LossPred 1.1604 LossAtt 1.0225 TrainAcc 0.4200 TestAcc 0.4752 0.3800
epoch 100 LossPred 0.9403 LossAtt 0.6061 TrainAcc 0.5900 TestAcc 0.6059 0.5900
epoch 200 LossPred 0.9003 LossAtt 0.4525 TrainAcc 0.6200 TestAcc 0.5611 0.6000
epoch 300 LossPred 0.8919 LossAtt 0.3794 TrainAcc 0.6300 TestAcc 0.5741 0.6400
epoch 400 LossPred 0.8926 LossAtt 0.3295 TrainAcc 0.6300 TestAcc 0.5741 0.6300
epoch 500 LossPred 0.8906 LossAtt 0.3037 TrainAcc 0.6300 TestAcc 0.5741 0.6300
epoch 600 LossPred 0.8903 LossAtt 0.3007 TrainAcc 0.6300 TestAcc 0.5741 0.6300
epoch 700 LossPred 0.8900 LossAtt 0.3143 TrainAcc 0.6300 TestAcc 0.5741 0.6300
epoch 800 LossPred 0.8884 LossAtt 0.2684 TrainAcc 0.6300 TestAcc 0.5741 0.6300
epoch 900 LossPred 0.8857 LossAtt 0.2540 TrainAcc 0.6300 TestAcc 0.5741 0.6300
epoch 1000 LossPred 0.8842 LossAtt 0.1903 TrainAcc 0.6300 TestAcc 0.5741 0.6300
epoch 1100 LossPred 0.8838 LossAtt 0.1622 TrainAcc 0.6300 TestAcc 0.5741 0.6300
epoch 1200 LossPred 0.8846 LossAtt 0.1556 TrainAcc 0.6300 TestAcc 0.5741 0.6300
epoch 1300 LossPred 0.8842 LossAtt 0.1106 TrainAcc 0.6300 TestAcc 0.5741 0.6300
epoch 1400 LossPred 0.8839 LossAtt 0.1161 TrainAcc 0.6300 TestAcc 0.5741 0.6300
epoch 1500 LossPred 0.8837 LossAtt 0.1014 TrainAcc 0.6300 TestAcc 0.5741 0.6300
epoch 1600 LossPred 0.8836 LossAtt 0.1044 TrainAcc 0.6300 TestAcc 0.5741 0.6300
epoch 1700 LossPred 0.8834 LossAtt 0.1010 TrainAcc 0.6300 TestAcc 0.5741 0.6300
epoch 1800 LossPred 0.8830 LossAtt 0.0994 TrainAcc 0.6300 TestAcc 0.5741 0.6300
epoch 1900 LossPred 0.8817 LossAtt 0.1174 TrainAcc 0.6300 TestAcc 0.5741 0.6300
epoch 2000 LossPred 0.8792 LossAtt 0.1469 TrainAcc 0.6300 TestAcc 0.5741 0.6300
epoch 2100 LossPred 0.8787 LossAtt 0.1463 TrainAcc 0.6300 TestAcc 0.5741 0.6300
epoch 2200 LossPred 0.8778 LossAtt 0.1551 TrainAcc 0.6300 TestAcc 0.5741 0.6300
epoch 2300 LossPred 0.8755 LossAtt 0.1696 TrainAcc 0.6300 TestAcc 0.5741 0.6300
epoch 2400 LossPred 0.8755 LossAtt 0.1188 TrainAcc 0.6300 TestAcc 0.5741 0.6300
epoch 2500 LossPred 0.8749 LossAtt 0.0803 TrainAcc 0.6300 TestAcc 0.5741 0.6300
Optimization Finished!
********** replication  54  **********
epoch   0 LossPred 1.0357 LossAtt 1.0043 TrainAcc 0.3800 TestAcc 0.4660 0.3800
epoch 100 LossPred 0.8679 LossAtt 0.2428 TrainAcc 0.6700 TestAcc 0.5828 0.6700
epoch 200 LossPred 0.8547 LossAtt 0.1800 TrainAcc 0.6700 TestAcc 0.5828 0.6700
epoch 300 LossPred 0.8472 LossAtt 0.1238 TrainAcc 0.6700 TestAcc 0.5828 0.6700
epoch 400 LossPred 0.8444 LossAtt 0.1226 TrainAcc 0.6700 TestAcc 0.5828 0.6700
epoch 500 LossPred 0.8441 LossAtt 0.1777 TrainAcc 0.6700 TestAcc 0.5828 0.6700
epoch 600 LossPred 0.8407 LossAtt 0.1526 TrainAcc 0.6700 TestAcc 0.5828 0.6700
epoch 700 LossPred 0.8384 LossAtt 0.1285 TrainAcc 0.6700 TestAcc 0.5828 0.6700
epoch 800 LossPred 0.8371 LossAtt 0.1194 TrainAcc 0.6700 TestAcc 0.5828 0.6700
epoch 900 LossPred 0.8359 LossAtt 0.1191 TrainAcc 0.6700 TestAcc 0.5828 0.6700
epoch 1000 LossPred 0.8274 LossAtt 0.2860 TrainAcc 0.6700 TestAcc 0.5828 0.6700
epoch 1100 LossPred 0.6260 LossAtt 0.2897 TrainAcc 0.7900 TestAcc 0.7045 0.7950
epoch 1200 LossPred 0.4933 LossAtt 0.2592 TrainAcc 0.8200 TestAcc 0.7528 0.8200
epoch 1300 LossPred 0.4514 LossAtt 0.2786 TrainAcc 0.8700 TestAcc 0.8106 0.8350
epoch 1400 LossPred 0.4445 LossAtt 0.2813 TrainAcc 0.8700 TestAcc 0.8016 0.8450
epoch 1500 LossPred 0.4302 LossAtt 0.2819 TrainAcc 0.8600 TestAcc 0.8323 0.8400
epoch 1600 LossPred 0.4057 LossAtt 0.3199 TrainAcc 0.8600 TestAcc 0.8381 0.8750
epoch 1700 LossPred 0.4071 LossAtt 0.3375 TrainAcc 0.8500 TestAcc 0.8406 0.8600
epoch 1800 LossPred 0.4015 LossAtt 0.3445 TrainAcc 0.8500 TestAcc 0.8391 0.8550
epoch 1900 LossPred 0.3777 LossAtt 0.3322 TrainAcc 0.8500 TestAcc 0.8386 0.8650
epoch 2000 LossPred 0.3600 LossAtt 0.3290 TrainAcc 0.8900 TestAcc 0.8448 0.8600
epoch 2100 LossPred 0.3538 LossAtt 0.3287 TrainAcc 0.8900 TestAcc 0.8408 0.8600
epoch 2200 LossPred 0.3540 LossAtt 0.3346 TrainAcc 0.8800 TestAcc 0.8408 0.8750
epoch 2300 LossPred 0.3843 LossAtt 0.3341 TrainAcc 0.8500 TestAcc 0.8381 0.8600
epoch 2400 LossPred 0.3549 LossAtt 0.3268 TrainAcc 0.8500 TestAcc 0.8488 0.8700
epoch 2500 LossPred 0.3404 LossAtt 0.3327 TrainAcc 0.9000 TestAcc 0.8476 0.8700
Optimization Finished!
********** replication  55  **********
epoch   0 LossPred 1.0702 LossAtt 1.0102 TrainAcc 0.4400 TestAcc 0.4207 0.4400
epoch 100 LossPred 0.9041 LossAtt 0.2862 TrainAcc 0.6200 TestAcc 0.5901 0.6200
epoch 200 LossPred 0.9005 LossAtt 0.2380 TrainAcc 0.6200 TestAcc 0.5901 0.6200
epoch 300 LossPred 0.8980 LossAtt 0.2845 TrainAcc 0.6200 TestAcc 0.5901 0.6200
epoch 400 LossPred 0.8951 LossAtt 0.2778 TrainAcc 0.6200 TestAcc 0.5901 0.6200
epoch 500 LossPred 0.8938 LossAtt 0.2172 TrainAcc 0.6200 TestAcc 0.5901 0.6200
epoch 600 LossPred 0.8933 LossAtt 0.1656 TrainAcc 0.6200 TestAcc 0.5901 0.6200
epoch 700 LossPred 0.8927 LossAtt 0.1380 TrainAcc 0.6200 TestAcc 0.5901 0.6200
epoch 800 LossPred 0.8921 LossAtt 0.1269 TrainAcc 0.6200 TestAcc 0.5901 0.6200
epoch 900 LossPred 0.8921 LossAtt 0.1793 TrainAcc 0.6200 TestAcc 0.5901 0.6200
epoch 1000 LossPred 0.9067 LossAtt 0.5387 TrainAcc 0.6400 TestAcc 0.6441 0.6250
epoch 1100 LossPred 0.9630 LossAtt 0.5665 TrainAcc 0.6200 TestAcc 0.5911 0.6200
epoch 1200 LossPred 1.2751 LossAtt 0.5595 TrainAcc 0.5500 TestAcc 0.5591 0.5350
epoch 1300 LossPred 0.5436 LossAtt 0.5150 TrainAcc 0.8400 TestAcc 0.7372 0.8300
epoch 1400 LossPred 0.6054 LossAtt 0.5079 TrainAcc 0.7900 TestAcc 0.7232 0.8000
epoch 1500 LossPred 0.6454 LossAtt 0.5069 TrainAcc 0.7600 TestAcc 0.7235 0.7500
epoch 1600 LossPred 0.9161 LossAtt 0.3110 TrainAcc 0.6200 TestAcc 0.5901 0.6200
epoch 1700 LossPred 0.9112 LossAtt 0.3018 TrainAcc 0.6200 TestAcc 0.5901 0.6200
epoch 1800 LossPred 0.9089 LossAtt 0.2658 TrainAcc 0.6200 TestAcc 0.5901 0.6200
epoch 1900 LossPred 0.9066 LossAtt 0.2547 TrainAcc 0.6200 TestAcc 0.5901 0.6200
epoch 2000 LossPred 0.9042 LossAtt 0.2405 TrainAcc 0.6200 TestAcc 0.5901 0.6200
epoch 2100 LossPred 0.9032 LossAtt 0.2300 TrainAcc 0.6200 TestAcc 0.5901 0.6200
epoch 2200 LossPred 0.9026 LossAtt 0.2587 TrainAcc 0.6200 TestAcc 0.5901 0.6200
epoch 2300 LossPred 0.9015 LossAtt 0.2684 TrainAcc 0.6200 TestAcc 0.5901 0.6200
epoch 2400 LossPred 0.9007 LossAtt 0.2331 TrainAcc 0.6200 TestAcc 0.5901 0.6200
epoch 2500 LossPred 0.9006 LossAtt 0.2565 TrainAcc 0.6200 TestAcc 0.5901 0.6200
Optimization Finished!
********** replication  56  **********
epoch   0 LossPred 1.0972 LossAtt 1.0169 TrainAcc 0.5300 TestAcc 0.5268 0.4950
epoch 100 LossPred 0.9919 LossAtt 0.4656 TrainAcc 0.5300 TestAcc 0.5018 0.5250
epoch 200 LossPred 0.9801 LossAtt 0.4754 TrainAcc 0.6600 TestAcc 0.5968 0.6050
epoch 300 LossPred 0.9052 LossAtt 0.5389 TrainAcc 0.6600 TestAcc 0.5708 0.6200
epoch 400 LossPred 0.8504 LossAtt 0.5799 TrainAcc 0.6600 TestAcc 0.5858 0.6550
epoch 500 LossPred 0.6329 LossAtt 0.6103 TrainAcc 0.8000 TestAcc 0.7700 0.8000
epoch 600 LossPred 0.2756 LossAtt 0.5962 TrainAcc 0.8900 TestAcc 0.8576 0.8950
epoch 700 LossPred 0.2641 LossAtt 0.6254 TrainAcc 0.8900 TestAcc 0.8756 0.8950
epoch 800 LossPred 0.1989 LossAtt 0.6123 TrainAcc 0.9200 TestAcc 0.8689 0.9200
epoch 900 LossPred 0.1786 LossAtt 0.6136 TrainAcc 0.9400 TestAcc 0.8844 0.9250
epoch 1000 LossPred 0.2330 LossAtt 0.5945 TrainAcc 0.9300 TestAcc 0.8806 0.9150
epoch 1100 LossPred 0.1369 LossAtt 0.5360 TrainAcc 0.9500 TestAcc 0.8909 0.9400
epoch 1200 LossPred 0.1323 LossAtt 0.5340 TrainAcc 0.9600 TestAcc 0.9004 0.9400
epoch 1300 LossPred 0.1120 LossAtt 0.5129 TrainAcc 0.9800 TestAcc 0.8961 0.9400
epoch 1400 LossPred 0.1085 LossAtt 0.5190 TrainAcc 0.9700 TestAcc 0.8986 0.9500
epoch 1500 LossPred 0.1019 LossAtt 0.4893 TrainAcc 0.9800 TestAcc 0.8969 0.9650
epoch 1600 LossPred 0.0920 LossAtt 0.4515 TrainAcc 0.9800 TestAcc 0.8911 0.9700
epoch 1700 LossPred 0.1096 LossAtt 0.4466 TrainAcc 0.9600 TestAcc 0.8931 0.9500
epoch 1800 LossPred 0.1754 LossAtt 0.4578 TrainAcc 0.9300 TestAcc 0.8749 0.9550
epoch 1900 LossPred 0.0770 LossAtt 0.4421 TrainAcc 0.9900 TestAcc 0.8874 0.9750
epoch 2000 LossPred 0.0869 LossAtt 0.4273 TrainAcc 0.9700 TestAcc 0.8829 0.9650
epoch 2100 LossPred 0.0877 LossAtt 0.4360 TrainAcc 0.9900 TestAcc 0.8854 0.9700
epoch 2200 LossPred 0.0744 LossAtt 0.4348 TrainAcc 0.9800 TestAcc 0.8869 0.9750
epoch 2300 LossPred 0.0731 LossAtt 0.4310 TrainAcc 0.9900 TestAcc 0.8869 0.9750
epoch 2400 LossPred 0.0705 LossAtt 0.4393 TrainAcc 0.9900 TestAcc 0.8896 0.9750
epoch 2500 LossPred 0.1072 LossAtt 0.4348 TrainAcc 0.9700 TestAcc 0.8914 0.9550
Optimization Finished!
********** replication  57  **********
epoch   0 LossPred 0.9856 LossAtt 1.0341 TrainAcc 0.5900 TestAcc 0.5621 0.5950
epoch 100 LossPred 0.8411 LossAtt 0.4459 TrainAcc 0.6300 TestAcc 0.6049 0.6450
epoch 200 LossPred 0.7640 LossAtt 0.5288 TrainAcc 0.6700 TestAcc 0.6304 0.6750
epoch 300 LossPred 0.2853 LossAtt 0.4925 TrainAcc 0.9200 TestAcc 0.8799 0.9300
epoch 400 LossPred 0.3300 LossAtt 0.4455 TrainAcc 0.8700 TestAcc 0.8468 0.8950
epoch 500 LossPred 0.4639 LossAtt 0.4409 TrainAcc 0.8500 TestAcc 0.8171 0.8550
epoch 600 LossPred 0.4212 LossAtt 0.4359 TrainAcc 0.8400 TestAcc 0.8549 0.8400
epoch 700 LossPred 0.2112 LossAtt 0.4462 TrainAcc 0.9200 TestAcc 0.9167 0.8850
epoch 800 LossPred 0.1467 LossAtt 0.4824 TrainAcc 0.9500 TestAcc 0.9369 0.9300
epoch 900 LossPred 0.1565 LossAtt 0.4848 TrainAcc 0.9400 TestAcc 0.9219 0.9250
epoch 1000 LossPred 0.1192 LossAtt 0.4571 TrainAcc 0.9600 TestAcc 0.9319 0.9400
epoch 1100 LossPred 0.1217 LossAtt 0.4313 TrainAcc 0.9500 TestAcc 0.9317 0.9500
epoch 1200 LossPred 0.3189 LossAtt 0.3948 TrainAcc 0.8700 TestAcc 0.8491 0.8900
epoch 1300 LossPred 0.1374 LossAtt 0.3897 TrainAcc 0.9400 TestAcc 0.9157 0.9350
epoch 1400 LossPred 0.1119 LossAtt 0.4038 TrainAcc 0.9500 TestAcc 0.9229 0.9400
epoch 1500 LossPred 0.0998 LossAtt 0.4040 TrainAcc 0.9700 TestAcc 0.9342 0.9550
epoch 1600 LossPred 0.1562 LossAtt 0.3992 TrainAcc 0.9500 TestAcc 0.9097 0.9300
epoch 1700 LossPred 0.0951 LossAtt 0.3895 TrainAcc 0.9700 TestAcc 0.9304 0.9500
epoch 1800 LossPred 0.1735 LossAtt 0.3890 TrainAcc 0.9300 TestAcc 0.8931 0.9250
epoch 1900 LossPred 0.3721 LossAtt 0.3837 TrainAcc 0.8600 TestAcc 0.8601 0.8650
epoch 2000 LossPred 0.2009 LossAtt 0.3813 TrainAcc 0.9200 TestAcc 0.8839 0.9100
epoch 2100 LossPred 0.2672 LossAtt 0.3974 TrainAcc 0.9100 TestAcc 0.8769 0.8850
epoch 2200 LossPred 0.1073 LossAtt 0.3776 TrainAcc 0.9700 TestAcc 0.9239 0.9450
epoch 2300 LossPred 0.1075 LossAtt 0.3765 TrainAcc 0.9600 TestAcc 0.9339 0.9600
epoch 2400 LossPred 0.1468 LossAtt 0.3811 TrainAcc 0.9400 TestAcc 0.9047 0.9300
epoch 2500 LossPred 0.2754 LossAtt 0.3790 TrainAcc 0.9100 TestAcc 0.8754 0.9050
Optimization Finished!
********** replication  58  **********
epoch   0 LossPred 1.0104 LossAtt 1.0070 TrainAcc 0.5600 TestAcc 0.5591 0.5900
epoch 100 LossPred 0.8616 LossAtt 0.4430 TrainAcc 0.6900 TestAcc 0.6316 0.6350
epoch 200 LossPred 0.8257 LossAtt 0.4399 TrainAcc 0.6800 TestAcc 0.6602 0.6650
epoch 300 LossPred 0.6529 LossAtt 0.4834 TrainAcc 0.7700 TestAcc 0.7342 0.7500
epoch 400 LossPred 0.5952 LossAtt 0.4162 TrainAcc 0.7900 TestAcc 0.7362 0.7700
epoch 500 LossPred 0.5722 LossAtt 0.4031 TrainAcc 0.8000 TestAcc 0.7868 0.7700
epoch 600 LossPred 0.4613 LossAtt 0.3859 TrainAcc 0.8400 TestAcc 0.8331 0.8300
epoch 700 LossPred 0.5031 LossAtt 0.3625 TrainAcc 0.8000 TestAcc 0.8158 0.8000
epoch 800 LossPred 0.8537 LossAtt 0.4191 TrainAcc 0.6800 TestAcc 0.6577 0.6900
epoch 900 LossPred 0.3999 LossAtt 0.3481 TrainAcc 0.8600 TestAcc 0.8478 0.8400
epoch 1000 LossPred 0.4942 LossAtt 0.3772 TrainAcc 0.8400 TestAcc 0.8131 0.8600
epoch 1100 LossPred 0.4164 LossAtt 0.3852 TrainAcc 0.8500 TestAcc 0.8316 0.8450
epoch 1200 LossPred 0.3569 LossAtt 0.3764 TrainAcc 0.8600 TestAcc 0.8498 0.8450
epoch 1300 LossPred 0.3470 LossAtt 0.3640 TrainAcc 0.8600 TestAcc 0.8456 0.8600
epoch 1400 LossPred 0.4605 LossAtt 0.3744 TrainAcc 0.8500 TestAcc 0.8051 0.8400
epoch 1500 LossPred 0.3660 LossAtt 0.3882 TrainAcc 0.8900 TestAcc 0.8561 0.8750
epoch 1600 LossPred 0.2760 LossAtt 0.4015 TrainAcc 0.9000 TestAcc 0.8601 0.8800
epoch 1700 LossPred 0.3521 LossAtt 0.3873 TrainAcc 0.8700 TestAcc 0.8581 0.8900
epoch 1800 LossPred 0.3461 LossAtt 0.3876 TrainAcc 0.8800 TestAcc 0.8571 0.9050
epoch 1900 LossPred 0.2806 LossAtt 0.3991 TrainAcc 0.8900 TestAcc 0.8596 0.9050
epoch 2000 LossPred 0.3344 LossAtt 0.3897 TrainAcc 0.8900 TestAcc 0.8521 0.8700
epoch 2100 LossPred 0.3617 LossAtt 0.3506 TrainAcc 0.9000 TestAcc 0.8351 0.8700
epoch 2200 LossPred 0.3633 LossAtt 0.3317 TrainAcc 0.8900 TestAcc 0.8308 0.8750
epoch 2300 LossPred 0.4505 LossAtt 0.3167 TrainAcc 0.8400 TestAcc 0.8078 0.8400
epoch 2400 LossPred 0.3513 LossAtt 0.3095 TrainAcc 0.8800 TestAcc 0.8501 0.8700
epoch 2500 LossPred 0.3963 LossAtt 0.2983 TrainAcc 0.8700 TestAcc 0.8488 0.8700
Optimization Finished!
********** replication  59  **********
epoch   0 LossPred 1.1175 LossAtt 1.0093 TrainAcc 0.4900 TestAcc 0.5278 0.4900
epoch 100 LossPred 0.9528 LossAtt 0.3072 TrainAcc 0.6000 TestAcc 0.5811 0.6000
epoch 200 LossPred 0.9445 LossAtt 0.1588 TrainAcc 0.6000 TestAcc 0.5811 0.6000
epoch 300 LossPred 0.9438 LossAtt 0.1051 TrainAcc 0.6000 TestAcc 0.5811 0.6000
epoch 400 LossPred 0.9438 LossAtt 0.1518 TrainAcc 0.6000 TestAcc 0.5811 0.6000
epoch 500 LossPred 0.9424 LossAtt 0.1390 TrainAcc 0.6000 TestAcc 0.5811 0.6000
epoch 600 LossPred 0.9378 LossAtt 0.1943 TrainAcc 0.6000 TestAcc 0.5811 0.6000
epoch 700 LossPred 0.9269 LossAtt 0.2799 TrainAcc 0.6000 TestAcc 0.5811 0.6000
epoch 800 LossPred 0.8902 LossAtt 0.4258 TrainAcc 0.6000 TestAcc 0.5811 0.6000
epoch 900 LossPred 0.5569 LossAtt 0.6155 TrainAcc 0.8500 TestAcc 0.7593 0.8400
epoch 1000 LossPred 0.2004 LossAtt 0.5342 TrainAcc 0.9300 TestAcc 0.8749 0.9300
epoch 1100 LossPred 0.2023 LossAtt 0.4881 TrainAcc 0.9300 TestAcc 0.8911 0.9400
epoch 1200 LossPred 0.1764 LossAtt 0.4867 TrainAcc 0.9600 TestAcc 0.8969 0.9350
epoch 1300 LossPred 0.1777 LossAtt 0.5402 TrainAcc 0.9400 TestAcc 0.8871 0.9150
epoch 1400 LossPred 0.1326 LossAtt 0.5441 TrainAcc 0.9700 TestAcc 0.9007 0.9600
epoch 1500 LossPred 0.1104 LossAtt 0.5033 TrainAcc 0.9800 TestAcc 0.8986 0.9650
epoch 1600 LossPred 0.1203 LossAtt 0.5074 TrainAcc 0.9700 TestAcc 0.8911 0.9600
epoch 1700 LossPred 0.2198 LossAtt 0.4546 TrainAcc 0.9300 TestAcc 0.8529 0.9300
epoch 1800 LossPred 0.4444 LossAtt 0.3792 TrainAcc 0.8600 TestAcc 0.8051 0.8650
epoch 1900 LossPred 0.2901 LossAtt 0.3746 TrainAcc 0.8800 TestAcc 0.8421 0.9050
epoch 2000 LossPred 0.1364 LossAtt 0.3572 TrainAcc 0.9700 TestAcc 0.8766 0.9500
epoch 2100 LossPred 0.1343 LossAtt 0.3542 TrainAcc 0.9600 TestAcc 0.8729 0.9650
epoch 2200 LossPred 0.1303 LossAtt 0.3435 TrainAcc 0.9600 TestAcc 0.8791 0.9650
epoch 2300 LossPred 0.1154 LossAtt 0.3463 TrainAcc 0.9600 TestAcc 0.8771 0.9650
epoch 2400 LossPred 0.1148 LossAtt 0.3452 TrainAcc 0.9600 TestAcc 0.8776 0.9650
epoch 2500 LossPred 0.1404 LossAtt 0.3226 TrainAcc 0.9500 TestAcc 0.8696 0.9700
Optimization Finished!
********** replication  60  **********
epoch   0 LossPred 0.9494 LossAtt 1.0039 TrainAcc 0.6400 TestAcc 0.5878 0.6300
epoch 100 LossPred 0.8564 LossAtt 0.5533 TrainAcc 0.6500 TestAcc 0.5956 0.6500
epoch 200 LossPred 0.7884 LossAtt 0.5716 TrainAcc 0.7500 TestAcc 0.6444 0.7450
epoch 300 LossPred 0.7569 LossAtt 0.5463 TrainAcc 0.7700 TestAcc 0.6579 0.7450
epoch 400 LossPred 0.7334 LossAtt 0.5349 TrainAcc 0.7500 TestAcc 0.6507 0.7550
epoch 500 LossPred 0.7213 LossAtt 0.5217 TrainAcc 0.7600 TestAcc 0.6491 0.7550
epoch 600 LossPred 0.7077 LossAtt 0.4816 TrainAcc 0.7700 TestAcc 0.6504 0.7550
epoch 700 LossPred 0.6817 LossAtt 0.4724 TrainAcc 0.7700 TestAcc 0.6584 0.7500
epoch 800 LossPred 0.6594 LossAtt 0.4382 TrainAcc 0.7700 TestAcc 0.6411 0.7550
epoch 900 LossPred 0.6515 LossAtt 0.4519 TrainAcc 0.7700 TestAcc 0.6356 0.7600
epoch 1000 LossPred 0.6247 LossAtt 0.4623 TrainAcc 0.7800 TestAcc 0.6366 0.7600
epoch 1100 LossPred 0.6111 LossAtt 0.4464 TrainAcc 0.7800 TestAcc 0.6386 0.7700
epoch 1200 LossPred 0.6154 LossAtt 0.4918 TrainAcc 0.7500 TestAcc 0.6154 0.7300
epoch 1300 LossPred 0.6062 LossAtt 0.4492 TrainAcc 0.8000 TestAcc 0.6439 0.7650
epoch 1400 LossPred 0.6027 LossAtt 0.4310 TrainAcc 0.8000 TestAcc 0.6401 0.7600
epoch 1500 LossPred 0.5921 LossAtt 0.4296 TrainAcc 0.8100 TestAcc 0.6522 0.7750
epoch 1600 LossPred 0.6135 LossAtt 0.4034 TrainAcc 0.8100 TestAcc 0.6557 0.7800
epoch 1700 LossPred 0.5973 LossAtt 0.3857 TrainAcc 0.8000 TestAcc 0.6707 0.7850
epoch 1800 LossPred 0.5737 LossAtt 0.3841 TrainAcc 0.8200 TestAcc 0.6769 0.8000
epoch 1900 LossPred 0.5626 LossAtt 0.3837 TrainAcc 0.8200 TestAcc 0.6772 0.8000
epoch 2000 LossPred 0.5538 LossAtt 0.3733 TrainAcc 0.8100 TestAcc 0.6817 0.7950
epoch 2100 LossPred 0.5480 LossAtt 0.4049 TrainAcc 0.8200 TestAcc 0.6889 0.7900
epoch 2200 LossPred 0.5425 LossAtt 0.3712 TrainAcc 0.8100 TestAcc 0.6869 0.7950
epoch 2300 LossPred 0.5391 LossAtt 0.3823 TrainAcc 0.8100 TestAcc 0.6839 0.7900
epoch 2400 LossPred 0.5330 LossAtt 0.3611 TrainAcc 0.8200 TestAcc 0.6872 0.7950
epoch 2500 LossPred 0.5304 LossAtt 0.3604 TrainAcc 0.8200 TestAcc 0.6882 0.7900
Optimization Finished!
********** replication  61  **********
epoch   0 LossPred 1.1052 LossAtt 1.0329 TrainAcc 0.4600 TestAcc 0.4732 0.4500
epoch 100 LossPred 0.9473 LossAtt 0.4364 TrainAcc 0.6000 TestAcc 0.5390 0.6300
epoch 200 LossPred 0.9330 LossAtt 0.2692 TrainAcc 0.6100 TestAcc 0.5833 0.6100
epoch 300 LossPred 0.9239 LossAtt 0.3668 TrainAcc 0.6100 TestAcc 0.5833 0.6100
epoch 400 LossPred 0.9199 LossAtt 0.3334 TrainAcc 0.6100 TestAcc 0.5833 0.6100
epoch 500 LossPred 0.8158 LossAtt 0.4464 TrainAcc 0.7100 TestAcc 0.7112 0.6950
epoch 600 LossPred 0.4716 LossAtt 0.5522 TrainAcc 0.8600 TestAcc 0.8493 0.8450
epoch 700 LossPred 0.2973 LossAtt 0.5141 TrainAcc 0.9000 TestAcc 0.8759 0.8750
epoch 800 LossPred 0.2270 LossAtt 0.4868 TrainAcc 0.9400 TestAcc 0.8844 0.9100
epoch 900 LossPred 0.3421 LossAtt 0.4765 TrainAcc 0.8700 TestAcc 0.8529 0.8600
epoch 1000 LossPred 0.2955 LossAtt 0.4444 TrainAcc 0.8800 TestAcc 0.8606 0.8750
epoch 1100 LossPred 0.1862 LossAtt 0.4501 TrainAcc 0.9500 TestAcc 0.8844 0.9050
epoch 1200 LossPred 0.2992 LossAtt 0.4328 TrainAcc 0.8900 TestAcc 0.8584 0.8800
epoch 1300 LossPred 0.1929 LossAtt 0.4423 TrainAcc 0.9400 TestAcc 0.8794 0.8900
epoch 1400 LossPred 0.1733 LossAtt 0.4431 TrainAcc 0.9500 TestAcc 0.8801 0.8900
epoch 1500 LossPred 0.1892 LossAtt 0.4420 TrainAcc 0.9400 TestAcc 0.8846 0.9050
epoch 1600 LossPred 0.1522 LossAtt 0.4367 TrainAcc 0.9400 TestAcc 0.8911 0.9000
epoch 1700 LossPred 0.1573 LossAtt 0.4338 TrainAcc 0.9300 TestAcc 0.8916 0.9200
epoch 1800 LossPred 0.2366 LossAtt 0.4308 TrainAcc 0.9200 TestAcc 0.8731 0.8850
epoch 1900 LossPred 0.2251 LossAtt 0.4177 TrainAcc 0.9200 TestAcc 0.8789 0.8900
epoch 2000 LossPred 0.1495 LossAtt 0.4159 TrainAcc 0.9600 TestAcc 0.8859 0.9050
epoch 2100 LossPred 0.2458 LossAtt 0.4126 TrainAcc 0.9200 TestAcc 0.8761 0.8850
epoch 2200 LossPred 0.1347 LossAtt 0.3879 TrainAcc 0.9600 TestAcc 0.8974 0.9150
epoch 2300 LossPred 0.1398 LossAtt 0.3831 TrainAcc 0.9400 TestAcc 0.9047 0.9200
epoch 2400 LossPred 0.1252 LossAtt 0.3801 TrainAcc 0.9700 TestAcc 0.8919 0.9150
epoch 2500 LossPred 0.1571 LossAtt 0.3867 TrainAcc 0.9400 TestAcc 0.9009 0.9150
Optimization Finished!
********** replication  62  **********
epoch   0 LossPred 1.1741 LossAtt 1.0870 TrainAcc 0.4600 TestAcc 0.4577 0.4500
epoch 100 LossPred 0.9463 LossAtt 0.5594 TrainAcc 0.6000 TestAcc 0.5801 0.5950
epoch 200 LossPred 0.9228 LossAtt 0.4694 TrainAcc 0.6000 TestAcc 0.5801 0.6000
epoch 300 LossPred 0.9153 LossAtt 0.4304 TrainAcc 0.6000 TestAcc 0.5801 0.6000
epoch 400 LossPred 0.9153 LossAtt 0.3616 TrainAcc 0.6000 TestAcc 0.5801 0.6000
epoch 500 LossPred 0.9144 LossAtt 0.3410 TrainAcc 0.6000 TestAcc 0.5801 0.6000
epoch 600 LossPred 0.9113 LossAtt 0.3539 TrainAcc 0.5800 TestAcc 0.6404 0.6000
epoch 700 LossPred 0.8883 LossAtt 0.4392 TrainAcc 0.6500 TestAcc 0.6574 0.6350
epoch 800 LossPred 0.3130 LossAtt 0.5407 TrainAcc 0.9400 TestAcc 0.9019 0.9250
epoch 900 LossPred 0.2366 LossAtt 0.4869 TrainAcc 0.9600 TestAcc 0.9324 0.9150
epoch 1000 LossPred 0.2380 LossAtt 0.4713 TrainAcc 0.9300 TestAcc 0.9327 0.9200
epoch 1100 LossPred 0.1859 LossAtt 0.4565 TrainAcc 0.9700 TestAcc 0.9124 0.9350
epoch 1200 LossPred 0.2328 LossAtt 0.4309 TrainAcc 0.9300 TestAcc 0.9294 0.9200
epoch 1300 LossPred 0.1723 LossAtt 0.4247 TrainAcc 0.9600 TestAcc 0.9472 0.9300
epoch 1400 LossPred 0.1411 LossAtt 0.4209 TrainAcc 0.9800 TestAcc 0.9317 0.9300
epoch 1500 LossPred 0.1703 LossAtt 0.4130 TrainAcc 0.9500 TestAcc 0.8991 0.9150
epoch 1600 LossPred 0.1356 LossAtt 0.3946 TrainAcc 0.9700 TestAcc 0.9525 0.9350
epoch 1700 LossPred 0.1677 LossAtt 0.3897 TrainAcc 0.9400 TestAcc 0.8971 0.8950
epoch 1800 LossPred 0.1298 LossAtt 0.3963 TrainAcc 0.9700 TestAcc 0.9189 0.9250
epoch 1900 LossPred 0.1227 LossAtt 0.3898 TrainAcc 0.9700 TestAcc 0.9274 0.9400
epoch 2000 LossPred 0.1321 LossAtt 0.4011 TrainAcc 0.9600 TestAcc 0.9525 0.9300
epoch 2100 LossPred 0.1135 LossAtt 0.4063 TrainAcc 0.9700 TestAcc 0.9464 0.9450
epoch 2200 LossPred 0.1259 LossAtt 0.4114 TrainAcc 0.9600 TestAcc 0.9497 0.9450
epoch 2300 LossPred 0.1295 LossAtt 0.4222 TrainAcc 0.9600 TestAcc 0.9109 0.9300
epoch 2400 LossPred 0.1982 LossAtt 0.4085 TrainAcc 0.9300 TestAcc 0.8729 0.9050
epoch 2500 LossPred 0.1262 LossAtt 0.4194 TrainAcc 0.9700 TestAcc 0.9232 0.9150
Optimization Finished!
********** replication  63  **********
epoch   0 LossPred 1.0976 LossAtt 1.0218 TrainAcc 0.4800 TestAcc 0.5308 0.4650
epoch 100 LossPred 0.9265 LossAtt 0.5071 TrainAcc 0.6400 TestAcc 0.5435 0.6350
epoch 200 LossPred 0.8892 LossAtt 0.3343 TrainAcc 0.6300 TestAcc 0.5921 0.6300
epoch 300 LossPred 0.8461 LossAtt 0.5339 TrainAcc 0.6500 TestAcc 0.6111 0.6950
epoch 400 LossPred 0.4146 LossAtt 0.6092 TrainAcc 0.8900 TestAcc 0.8836 0.8900
epoch 500 LossPred 0.2753 LossAtt 0.5751 TrainAcc 0.9500 TestAcc 0.8831 0.9200
epoch 600 LossPred 0.2231 LossAtt 0.5284 TrainAcc 0.9500 TestAcc 0.8739 0.9400
epoch 700 LossPred 0.1816 LossAtt 0.5045 TrainAcc 0.9600 TestAcc 0.8781 0.9400
epoch 800 LossPred 0.1682 LossAtt 0.4720 TrainAcc 0.9700 TestAcc 0.8751 0.9700
epoch 900 LossPred 0.1704 LossAtt 0.5080 TrainAcc 0.9500 TestAcc 0.8659 0.9700
epoch 1000 LossPred 0.1561 LossAtt 0.5084 TrainAcc 0.9600 TestAcc 0.8704 0.9650
epoch 1100 LossPred 0.1528 LossAtt 0.5222 TrainAcc 0.9600 TestAcc 0.8659 0.9700
epoch 1200 LossPred 0.1569 LossAtt 0.5025 TrainAcc 0.9600 TestAcc 0.8594 0.9650
epoch 1300 LossPred 0.1178 LossAtt 0.4972 TrainAcc 0.9800 TestAcc 0.8691 0.9850
epoch 1400 LossPred 0.1135 LossAtt 0.4790 TrainAcc 0.9800 TestAcc 0.8696 0.9850
epoch 1500 LossPred 0.1160 LossAtt 0.4836 TrainAcc 0.9700 TestAcc 0.8654 0.9800
epoch 1600 LossPred 0.1199 LossAtt 0.4485 TrainAcc 0.9800 TestAcc 0.8661 0.9750
epoch 1700 LossPred 0.1041 LossAtt 0.4408 TrainAcc 0.9800 TestAcc 0.8724 0.9800
epoch 1800 LossPred 0.1129 LossAtt 0.4365 TrainAcc 0.9700 TestAcc 0.8686 0.9750
epoch 1900 LossPred 0.1640 LossAtt 0.4227 TrainAcc 0.9600 TestAcc 0.8679 0.9400
epoch 2000 LossPred 0.1378 LossAtt 0.4065 TrainAcc 0.9600 TestAcc 0.8721 0.9600
epoch 2100 LossPred 0.0920 LossAtt 0.4208 TrainAcc 0.9900 TestAcc 0.8774 0.9800
epoch 2200 LossPred 0.0888 LossAtt 0.4419 TrainAcc 0.9900 TestAcc 0.8741 0.9850
epoch 2300 LossPred 0.0969 LossAtt 0.4134 TrainAcc 0.9800 TestAcc 0.8739 0.9800
epoch 2400 LossPred 0.1244 LossAtt 0.4053 TrainAcc 0.9700 TestAcc 0.8676 0.9550
epoch 2500 LossPred 0.1052 LossAtt 0.4013 TrainAcc 0.9700 TestAcc 0.8734 0.9750
Optimization Finished!
********** replication  64  **********
epoch   0 LossPred 1.0344 LossAtt 1.0016 TrainAcc 0.5500 TestAcc 0.5293 0.5450
epoch 100 LossPred 0.9308 LossAtt 0.4424 TrainAcc 0.6200 TestAcc 0.5903 0.6200
epoch 200 LossPred 0.9237 LossAtt 0.3888 TrainAcc 0.6200 TestAcc 0.5903 0.6200
epoch 300 LossPred 0.9134 LossAtt 0.2251 TrainAcc 0.6200 TestAcc 0.5903 0.6200
epoch 400 LossPred 0.8848 LossAtt 0.3839 TrainAcc 0.6200 TestAcc 0.5958 0.6100
epoch 500 LossPred 0.5388 LossAtt 0.7319 TrainAcc 0.8400 TestAcc 0.7978 0.7850
epoch 600 LossPred 0.3061 LossAtt 0.6086 TrainAcc 0.9200 TestAcc 0.8744 0.8500
epoch 700 LossPred 0.2073 LossAtt 0.6142 TrainAcc 0.9300 TestAcc 0.9044 0.9050
epoch 800 LossPred 0.1881 LossAtt 0.6008 TrainAcc 0.9600 TestAcc 0.8944 0.8950
epoch 900 LossPred 0.1636 LossAtt 0.5611 TrainAcc 0.9500 TestAcc 0.8974 0.9250
epoch 1000 LossPred 0.1450 LossAtt 0.5481 TrainAcc 0.9600 TestAcc 0.9037 0.9400
epoch 1100 LossPred 0.1547 LossAtt 0.5644 TrainAcc 0.9600 TestAcc 0.8949 0.9600
epoch 1200 LossPred 0.1397 LossAtt 0.5636 TrainAcc 0.9700 TestAcc 0.9067 0.9550
epoch 1300 LossPred 0.1064 LossAtt 0.5590 TrainAcc 0.9900 TestAcc 0.9082 0.9700
epoch 1400 LossPred 0.1224 LossAtt 0.5747 TrainAcc 0.9800 TestAcc 0.9114 0.9550
epoch 1500 LossPred 0.1038 LossAtt 0.5889 TrainAcc 0.9900 TestAcc 0.9179 0.9600
epoch 1600 LossPred 0.0842 LossAtt 0.5491 TrainAcc 0.9900 TestAcc 0.9189 0.9850
epoch 1700 LossPred 0.1049 LossAtt 0.5798 TrainAcc 0.9800 TestAcc 0.9089 0.9750
epoch 1800 LossPred 0.0957 LossAtt 0.5591 TrainAcc 0.9800 TestAcc 0.9094 0.9750
epoch 1900 LossPred 0.0843 LossAtt 0.5514 TrainAcc 0.9800 TestAcc 0.9197 0.9600
epoch 2000 LossPred 0.1178 LossAtt 0.5488 TrainAcc 0.9600 TestAcc 0.9052 0.9550
epoch 2100 LossPred 0.0725 LossAtt 0.5657 TrainAcc 0.9900 TestAcc 0.9202 0.9800
epoch 2200 LossPred 0.0789 LossAtt 0.5594 TrainAcc 0.9900 TestAcc 0.9172 0.9850
epoch 2300 LossPred 0.0679 LossAtt 0.5481 TrainAcc 0.9900 TestAcc 0.9167 0.9800
epoch 2400 LossPred 0.0898 LossAtt 0.5701 TrainAcc 0.9800 TestAcc 0.9122 0.9750
epoch 2500 LossPred 0.0781 LossAtt 0.5659 TrainAcc 0.9800 TestAcc 0.9142 0.9800
Optimization Finished!
********** replication  65  **********
epoch   0 LossPred 1.1895 LossAtt 1.0140 TrainAcc 0.4500 TestAcc 0.4790 0.4450
epoch 100 LossPred 0.8919 LossAtt 0.5592 TrainAcc 0.6200 TestAcc 0.6109 0.6450
epoch 200 LossPred 0.8369 LossAtt 0.4804 TrainAcc 0.6300 TestAcc 0.6319 0.6350
epoch 300 LossPred 0.3684 LossAtt 0.5299 TrainAcc 0.8900 TestAcc 0.8616 0.8800
epoch 400 LossPred 0.2463 LossAtt 0.4706 TrainAcc 0.9300 TestAcc 0.9162 0.9250
epoch 500 LossPred 0.2183 LossAtt 0.4672 TrainAcc 0.9400 TestAcc 0.9002 0.9200
epoch 600 LossPred 0.1913 LossAtt 0.4312 TrainAcc 0.9500 TestAcc 0.9272 0.9050
epoch 700 LossPred 0.1853 LossAtt 0.4238 TrainAcc 0.9400 TestAcc 0.9082 0.9300
epoch 800 LossPred 0.1542 LossAtt 0.3935 TrainAcc 0.9700 TestAcc 0.9337 0.9300
epoch 900 LossPred 0.1429 LossAtt 0.4182 TrainAcc 0.9600 TestAcc 0.9477 0.9300
epoch 1000 LossPred 0.1703 LossAtt 0.4401 TrainAcc 0.9300 TestAcc 0.9372 0.9050
epoch 1100 LossPred 0.1850 LossAtt 0.4563 TrainAcc 0.9400 TestAcc 0.9042 0.9250
epoch 1200 LossPred 0.1425 LossAtt 0.4315 TrainAcc 0.9700 TestAcc 0.9312 0.9050
epoch 1300 LossPred 0.1400 LossAtt 0.4372 TrainAcc 0.9600 TestAcc 0.9299 0.9000
epoch 1400 LossPred 0.1777 LossAtt 0.4319 TrainAcc 0.9300 TestAcc 0.9272 0.8800
epoch 1500 LossPred 0.1339 LossAtt 0.4086 TrainAcc 0.9600 TestAcc 0.9379 0.8850
epoch 1600 LossPred 0.2116 LossAtt 0.4065 TrainAcc 0.9200 TestAcc 0.9192 0.8650
epoch 1700 LossPred 0.1986 LossAtt 0.3997 TrainAcc 0.9300 TestAcc 0.8894 0.9100
epoch 1800 LossPred 0.1740 LossAtt 0.3962 TrainAcc 0.9400 TestAcc 0.9042 0.9050
epoch 1900 LossPred 0.2550 LossAtt 0.4021 TrainAcc 0.9100 TestAcc 0.8784 0.8850
epoch 2000 LossPred 0.1217 LossAtt 0.3766 TrainAcc 0.9600 TestAcc 0.9279 0.9250
epoch 2100 LossPred 0.2036 LossAtt 0.3750 TrainAcc 0.9200 TestAcc 0.9204 0.8650
epoch 2200 LossPred 0.2605 LossAtt 0.4102 TrainAcc 0.9000 TestAcc 0.9067 0.8750
epoch 2300 LossPred 0.2510 LossAtt 0.4142 TrainAcc 0.9100 TestAcc 0.8624 0.9100
epoch 2400 LossPred 0.1554 LossAtt 0.4111 TrainAcc 0.9400 TestAcc 0.9049 0.9350
epoch 2500 LossPred 0.2952 LossAtt 0.4057 TrainAcc 0.8900 TestAcc 0.8889 0.8700
Optimization Finished!
********** replication  66  **********
epoch   0 LossPred 1.2082 LossAtt 1.0274 TrainAcc 0.4300 TestAcc 0.4037 0.4250
epoch 100 LossPred 0.9044 LossAtt 0.3834 TrainAcc 0.5700 TestAcc 0.6351 0.5900
epoch 200 LossPred 0.7630 LossAtt 0.4268 TrainAcc 0.7400 TestAcc 0.7380 0.7200
epoch 300 LossPred 0.5654 LossAtt 0.4459 TrainAcc 0.8000 TestAcc 0.8413 0.8150
epoch 400 LossPred 0.4722 LossAtt 0.4333 TrainAcc 0.8500 TestAcc 0.8403 0.8300
epoch 500 LossPred 0.4642 LossAtt 0.4394 TrainAcc 0.8400 TestAcc 0.8393 0.8400
epoch 600 LossPred 0.4794 LossAtt 0.4238 TrainAcc 0.8300 TestAcc 0.8551 0.8500
epoch 700 LossPred 0.5727 LossAtt 0.4233 TrainAcc 0.7800 TestAcc 0.8388 0.8200
epoch 800 LossPred 0.5009 LossAtt 0.4077 TrainAcc 0.8400 TestAcc 0.7845 0.8100
epoch 900 LossPred 0.4389 LossAtt 0.4213 TrainAcc 0.8500 TestAcc 0.8413 0.8350
epoch 1000 LossPred 0.4717 LossAtt 0.4308 TrainAcc 0.8400 TestAcc 0.8238 0.8400
epoch 1100 LossPred 0.4515 LossAtt 0.3987 TrainAcc 0.8400 TestAcc 0.8443 0.8400
epoch 1200 LossPred 0.4286 LossAtt 0.3724 TrainAcc 0.8600 TestAcc 0.8256 0.8300
epoch 1300 LossPred 0.4946 LossAtt 0.3842 TrainAcc 0.8300 TestAcc 0.8223 0.8350
epoch 1400 LossPred 0.4354 LossAtt 0.3829 TrainAcc 0.8500 TestAcc 0.8318 0.8450
epoch 1500 LossPred 0.4514 LossAtt 0.3708 TrainAcc 0.8500 TestAcc 0.8428 0.8600
epoch 1600 LossPred 0.5066 LossAtt 0.3637 TrainAcc 0.8100 TestAcc 0.8286 0.8350
epoch 1700 LossPred 0.4471 LossAtt 0.3704 TrainAcc 0.8500 TestAcc 0.8231 0.8450
epoch 1800 LossPred 0.4667 LossAtt 0.3894 TrainAcc 0.8500 TestAcc 0.8256 0.8400
epoch 1900 LossPred 0.4647 LossAtt 0.3701 TrainAcc 0.8200 TestAcc 0.8491 0.8450
epoch 2000 LossPred 0.4808 LossAtt 0.3745 TrainAcc 0.8200 TestAcc 0.8438 0.8400
epoch 2100 LossPred 0.4338 LossAtt 0.3486 TrainAcc 0.8500 TestAcc 0.8301 0.8400
epoch 2200 LossPred 0.4791 LossAtt 0.3641 TrainAcc 0.8400 TestAcc 0.8158 0.8500
epoch 2300 LossPred 0.4440 LossAtt 0.3783 TrainAcc 0.8600 TestAcc 0.8376 0.8450
epoch 2400 LossPred 0.4628 LossAtt 0.3459 TrainAcc 0.8200 TestAcc 0.8426 0.8400
epoch 2500 LossPred 0.4553 LossAtt 0.3465 TrainAcc 0.8300 TestAcc 0.8281 0.8600
Optimization Finished!
********** replication  67  **********
epoch   0 LossPred 0.9475 LossAtt 1.0169 TrainAcc 0.5500 TestAcc 0.5363 0.5400
epoch 100 LossPred 0.8200 LossAtt 0.5354 TrainAcc 0.6900 TestAcc 0.5878 0.6900
epoch 200 LossPred 0.7880 LossAtt 0.5271 TrainAcc 0.6900 TestAcc 0.5878 0.6900
epoch 300 LossPred 0.7251 LossAtt 0.4879 TrainAcc 0.7500 TestAcc 0.6316 0.7550
epoch 400 LossPred 0.4611 LossAtt 0.6903 TrainAcc 0.8600 TestAcc 0.7885 0.8650
epoch 500 LossPred 0.2956 LossAtt 0.5909 TrainAcc 0.9000 TestAcc 0.8554 0.8850
epoch 600 LossPred 0.2693 LossAtt 0.5442 TrainAcc 0.9200 TestAcc 0.8616 0.9100
epoch 700 LossPred 0.1953 LossAtt 0.5154 TrainAcc 0.9600 TestAcc 0.9037 0.9200
epoch 800 LossPred 0.1712 LossAtt 0.5130 TrainAcc 0.9500 TestAcc 0.8989 0.9300
epoch 900 LossPred 0.1886 LossAtt 0.4977 TrainAcc 0.9400 TestAcc 0.9052 0.9250
epoch 1000 LossPred 0.1358 LossAtt 0.4987 TrainAcc 0.9500 TestAcc 0.9002 0.9250
epoch 1100 LossPred 0.2165 LossAtt 0.4899 TrainAcc 0.9100 TestAcc 0.8834 0.9000
epoch 1200 LossPred 0.1985 LossAtt 0.5015 TrainAcc 0.9500 TestAcc 0.8976 0.9300
epoch 1300 LossPred 0.1970 LossAtt 0.5099 TrainAcc 0.9500 TestAcc 0.8974 0.9300
epoch 1400 LossPred 0.1995 LossAtt 0.5029 TrainAcc 0.9500 TestAcc 0.8914 0.9300
epoch 1500 LossPred 0.1487 LossAtt 0.4809 TrainAcc 0.9500 TestAcc 0.9109 0.9400
epoch 1600 LossPred 0.1418 LossAtt 0.4942 TrainAcc 0.9600 TestAcc 0.9112 0.9400
epoch 1700 LossPred 0.1348 LossAtt 0.5060 TrainAcc 0.9600 TestAcc 0.9172 0.9450
epoch 1800 LossPred 0.1286 LossAtt 0.4741 TrainAcc 0.9600 TestAcc 0.9159 0.9500
epoch 1900 LossPred 0.0975 LossAtt 0.4956 TrainAcc 0.9700 TestAcc 0.9317 0.9450
epoch 2000 LossPred 0.1063 LossAtt 0.4687 TrainAcc 0.9700 TestAcc 0.9272 0.9500
epoch 2100 LossPred 0.0990 LossAtt 0.4990 TrainAcc 0.9700 TestAcc 0.9272 0.9450
epoch 2200 LossPred 0.0876 LossAtt 0.4817 TrainAcc 0.9700 TestAcc 0.9359 0.9500
epoch 2300 LossPred 0.1200 LossAtt 0.5068 TrainAcc 0.9700 TestAcc 0.9109 0.9550
epoch 2400 LossPred 0.0825 LossAtt 0.4979 TrainAcc 0.9800 TestAcc 0.9364 0.9600
epoch 2500 LossPred 0.0701 LossAtt 0.5115 TrainAcc 0.9800 TestAcc 0.9399 0.9650
Optimization Finished!
********** replication  68  **********
epoch   0 LossPred 1.0264 LossAtt 1.0016 TrainAcc 0.5700 TestAcc 0.5796 0.5850
epoch 100 LossPred 0.9113 LossAtt 0.5979 TrainAcc 0.5900 TestAcc 0.5878 0.6350
epoch 200 LossPred 0.8441 LossAtt 0.6718 TrainAcc 0.7000 TestAcc 0.5165 0.7000
epoch 300 LossPred 0.8004 LossAtt 0.6381 TrainAcc 0.7000 TestAcc 0.5643 0.7200
epoch 400 LossPred 0.6772 LossAtt 0.7119 TrainAcc 0.7500 TestAcc 0.6979 0.7350
epoch 500 LossPred 0.4747 LossAtt 0.6897 TrainAcc 0.8500 TestAcc 0.8426 0.8400
epoch 600 LossPred 0.4359 LossAtt 0.6804 TrainAcc 0.8400 TestAcc 0.8433 0.8500
epoch 700 LossPred 0.3594 LossAtt 0.6583 TrainAcc 0.8800 TestAcc 0.8621 0.8600
epoch 800 LossPred 0.3323 LossAtt 0.6693 TrainAcc 0.8900 TestAcc 0.8659 0.8500
epoch 900 LossPred 0.3449 LossAtt 0.6688 TrainAcc 0.8800 TestAcc 0.8451 0.8650
epoch 1000 LossPred 0.3960 LossAtt 0.6565 TrainAcc 0.8500 TestAcc 0.8236 0.8550
epoch 1100 LossPred 0.3379 LossAtt 0.6502 TrainAcc 0.8800 TestAcc 0.8498 0.8650
epoch 1200 LossPred 0.3567 LossAtt 0.6412 TrainAcc 0.8600 TestAcc 0.8483 0.8650
epoch 1300 LossPred 0.2742 LossAtt 0.6358 TrainAcc 0.9100 TestAcc 0.8609 0.8750
epoch 1400 LossPred 0.2659 LossAtt 0.6389 TrainAcc 0.9100 TestAcc 0.8654 0.8600
epoch 1500 LossPred 0.2724 LossAtt 0.6265 TrainAcc 0.8900 TestAcc 0.8569 0.8700
epoch 1600 LossPred 0.2545 LossAtt 0.6631 TrainAcc 0.9100 TestAcc 0.8676 0.8700
epoch 1700 LossPred 0.2699 LossAtt 0.6143 TrainAcc 0.9100 TestAcc 0.8666 0.9050
epoch 1800 LossPred 0.2430 LossAtt 0.6218 TrainAcc 0.9200 TestAcc 0.8721 0.8850
epoch 1900 LossPred 0.3235 LossAtt 0.6379 TrainAcc 0.8800 TestAcc 0.8408 0.8400
epoch 2000 LossPred 0.2601 LossAtt 0.6200 TrainAcc 0.9400 TestAcc 0.8706 0.8950
epoch 2100 LossPred 0.2358 LossAtt 0.6168 TrainAcc 0.9300 TestAcc 0.8746 0.9000
epoch 2200 LossPred 0.2320 LossAtt 0.6269 TrainAcc 0.9500 TestAcc 0.8726 0.9000
epoch 2300 LossPred 0.2427 LossAtt 0.6322 TrainAcc 0.9400 TestAcc 0.8694 0.9000
epoch 2400 LossPred 0.2831 LossAtt 0.6420 TrainAcc 0.9000 TestAcc 0.8704 0.8850
epoch 2500 LossPred 0.4474 LossAtt 0.6498 TrainAcc 0.8500 TestAcc 0.8133 0.8350
Optimization Finished!
********** replication  69  **********
epoch   0 LossPred 1.2737 LossAtt 1.0613 TrainAcc 0.5000 TestAcc 0.5040 0.4900
epoch 100 LossPred 0.9895 LossAtt 0.5146 TrainAcc 0.5300 TestAcc 0.5228 0.5200
epoch 200 LossPred 0.8853 LossAtt 0.4089 TrainAcc 0.6000 TestAcc 0.5408 0.6000
epoch 300 LossPred 0.8576 LossAtt 0.3780 TrainAcc 0.6200 TestAcc 0.5636 0.6100
epoch 400 LossPred 0.8479 LossAtt 0.3894 TrainAcc 0.6100 TestAcc 0.5631 0.6050
epoch 500 LossPred 0.8411 LossAtt 0.4133 TrainAcc 0.6300 TestAcc 0.5978 0.6400
epoch 600 LossPred 0.8214 LossAtt 0.4417 TrainAcc 0.6600 TestAcc 0.6146 0.6500
epoch 700 LossPred 0.5517 LossAtt 0.5620 TrainAcc 0.8400 TestAcc 0.8186 0.8450
epoch 800 LossPred 0.4827 LossAtt 0.5827 TrainAcc 0.8400 TestAcc 0.8313 0.8500
epoch 900 LossPred 0.4642 LossAtt 0.5690 TrainAcc 0.8500 TestAcc 0.8431 0.8450
epoch 1000 LossPred 0.4108 LossAtt 0.5817 TrainAcc 0.8500 TestAcc 0.8521 0.8550
epoch 1100 LossPred 0.3867 LossAtt 0.6176 TrainAcc 0.9000 TestAcc 0.8308 0.8750
epoch 1200 LossPred 0.3709 LossAtt 0.6259 TrainAcc 0.8900 TestAcc 0.8524 0.8850
epoch 1300 LossPred 0.3420 LossAtt 0.6426 TrainAcc 0.8800 TestAcc 0.8366 0.8800
epoch 1400 LossPred 0.3516 LossAtt 0.6287 TrainAcc 0.8900 TestAcc 0.8451 0.8900
epoch 1500 LossPred 0.2985 LossAtt 0.6406 TrainAcc 0.9200 TestAcc 0.8436 0.9000
epoch 1600 LossPred 0.2886 LossAtt 0.6217 TrainAcc 0.9200 TestAcc 0.8398 0.8850
epoch 1700 LossPred 0.2716 LossAtt 0.6461 TrainAcc 0.9300 TestAcc 0.8361 0.8950
epoch 1800 LossPred 0.2821 LossAtt 0.6452 TrainAcc 0.9300 TestAcc 0.8213 0.9200
epoch 1900 LossPred 0.2566 LossAtt 0.6472 TrainAcc 0.9300 TestAcc 0.8308 0.9050
epoch 2000 LossPred 0.2428 LossAtt 0.6297 TrainAcc 0.9500 TestAcc 0.8241 0.9150
epoch 2100 LossPred 0.2749 LossAtt 0.6365 TrainAcc 0.9200 TestAcc 0.8156 0.9200
epoch 2200 LossPred 0.2284 LossAtt 0.6149 TrainAcc 0.9300 TestAcc 0.8296 0.9100
epoch 2300 LossPred 0.2195 LossAtt 0.6475 TrainAcc 0.9500 TestAcc 0.8306 0.9100
epoch 2400 LossPred 0.1842 LossAtt 0.6189 TrainAcc 0.9500 TestAcc 0.8301 0.9200
epoch 2500 LossPred 0.1874 LossAtt 0.6108 TrainAcc 0.9400 TestAcc 0.8283 0.9250
Optimization Finished!
********** replication  70  **********
epoch   0 LossPred 1.1018 LossAtt 1.0474 TrainAcc 0.5600 TestAcc 0.5128 0.5800
epoch 100 LossPred 0.9435 LossAtt 0.6201 TrainAcc 0.6200 TestAcc 0.5916 0.6100
epoch 200 LossPred 0.9257 LossAtt 0.5688 TrainAcc 0.6200 TestAcc 0.5916 0.6200
epoch 300 LossPred 0.7192 LossAtt 0.5506 TrainAcc 0.7200 TestAcc 0.7150 0.7050
epoch 400 LossPred 0.3974 LossAtt 0.4387 TrainAcc 0.8500 TestAcc 0.8316 0.8750
epoch 500 LossPred 0.3526 LossAtt 0.4717 TrainAcc 0.8900 TestAcc 0.8391 0.8750
epoch 600 LossPred 0.3279 LossAtt 0.5000 TrainAcc 0.9000 TestAcc 0.8343 0.8750
epoch 700 LossPred 0.2731 LossAtt 0.5557 TrainAcc 0.9200 TestAcc 0.8323 0.8750
epoch 800 LossPred 0.2555 LossAtt 0.5668 TrainAcc 0.9200 TestAcc 0.8271 0.8800
epoch 900 LossPred 0.2637 LossAtt 0.5702 TrainAcc 0.9100 TestAcc 0.8421 0.8950
epoch 1000 LossPred 0.2409 LossAtt 0.5713 TrainAcc 0.9200 TestAcc 0.8221 0.8750
epoch 1100 LossPred 0.2345 LossAtt 0.5611 TrainAcc 0.9200 TestAcc 0.8353 0.9000
epoch 1200 LossPred 0.2367 LossAtt 0.5640 TrainAcc 0.9000 TestAcc 0.8281 0.8900
epoch 1300 LossPred 0.2304 LossAtt 0.5335 TrainAcc 0.9200 TestAcc 0.8381 0.9100
epoch 1400 LossPred 0.2294 LossAtt 0.5513 TrainAcc 0.9300 TestAcc 0.8391 0.9150
epoch 1500 LossPred 0.2088 LossAtt 0.5461 TrainAcc 0.9300 TestAcc 0.8218 0.9050
epoch 1600 LossPred 0.2176 LossAtt 0.5427 TrainAcc 0.9400 TestAcc 0.8221 0.9300
epoch 1700 LossPred 0.1831 LossAtt 0.5468 TrainAcc 0.9400 TestAcc 0.8446 0.9100
epoch 1800 LossPred 0.1692 LossAtt 0.5292 TrainAcc 0.9400 TestAcc 0.8366 0.9000
epoch 1900 LossPred 0.2231 LossAtt 0.5190 TrainAcc 0.9200 TestAcc 0.8316 0.9350
epoch 2000 LossPred 0.1904 LossAtt 0.5197 TrainAcc 0.9300 TestAcc 0.8266 0.9050
epoch 2100 LossPred 0.1495 LossAtt 0.5212 TrainAcc 0.9500 TestAcc 0.8403 0.9200
epoch 2200 LossPred 0.1374 LossAtt 0.5142 TrainAcc 0.9600 TestAcc 0.8433 0.9300
epoch 2300 LossPred 0.1533 LossAtt 0.5303 TrainAcc 0.9600 TestAcc 0.8333 0.9250
epoch 2400 LossPred 0.1289 LossAtt 0.5165 TrainAcc 0.9700 TestAcc 0.8478 0.9400
epoch 2500 LossPred 0.1298 LossAtt 0.5249 TrainAcc 0.9700 TestAcc 0.8509 0.9450
Optimization Finished!
********** replication  71  **********
epoch   0 LossPred 1.0281 LossAtt 1.0048 TrainAcc 0.5700 TestAcc 0.5253 0.5800
epoch 100 LossPred 0.8316 LossAtt 0.5600 TrainAcc 0.6900 TestAcc 0.5888 0.6450
epoch 200 LossPred 0.7375 LossAtt 0.5137 TrainAcc 0.7500 TestAcc 0.6409 0.7600
epoch 300 LossPred 0.3149 LossAtt 0.6234 TrainAcc 0.9200 TestAcc 0.8291 0.9000
epoch 400 LossPred 0.2766 LossAtt 0.5629 TrainAcc 0.9400 TestAcc 0.8554 0.8900
epoch 500 LossPred 0.2283 LossAtt 0.5616 TrainAcc 0.9400 TestAcc 0.8611 0.9050
epoch 600 LossPred 0.3033 LossAtt 0.5517 TrainAcc 0.9000 TestAcc 0.8166 0.8500
epoch 700 LossPred 0.2618 LossAtt 0.5360 TrainAcc 0.9200 TestAcc 0.8293 0.9050
epoch 800 LossPred 0.2601 LossAtt 0.5005 TrainAcc 0.9300 TestAcc 0.8521 0.9200
epoch 900 LossPred 0.1724 LossAtt 0.4955 TrainAcc 0.9600 TestAcc 0.8519 0.9250
epoch 1000 LossPred 0.1674 LossAtt 0.4704 TrainAcc 0.9500 TestAcc 0.8674 0.9400
epoch 1100 LossPred 0.1862 LossAtt 0.4445 TrainAcc 0.9500 TestAcc 0.8674 0.9250
epoch 1200 LossPred 0.1646 LossAtt 0.4425 TrainAcc 0.9500 TestAcc 0.8681 0.9450
epoch 1300 LossPred 0.1748 LossAtt 0.4278 TrainAcc 0.9400 TestAcc 0.8714 0.9400
epoch 1400 LossPred 0.3179 LossAtt 0.4507 TrainAcc 0.8800 TestAcc 0.8253 0.8800
epoch 1500 LossPred 0.1519 LossAtt 0.4581 TrainAcc 0.9600 TestAcc 0.8634 0.9300
epoch 1600 LossPred 0.1485 LossAtt 0.4625 TrainAcc 0.9600 TestAcc 0.8704 0.9350
epoch 1700 LossPred 0.1438 LossAtt 0.4514 TrainAcc 0.9500 TestAcc 0.8819 0.9500
epoch 1800 LossPred 0.1314 LossAtt 0.4580 TrainAcc 0.9600 TestAcc 0.8916 0.9600
epoch 1900 LossPred 0.1566 LossAtt 0.5150 TrainAcc 0.9600 TestAcc 0.8784 0.9400
epoch 2000 LossPred 0.1148 LossAtt 0.5406 TrainAcc 0.9800 TestAcc 0.8849 0.9500
epoch 2100 LossPred 0.2046 LossAtt 0.5529 TrainAcc 0.9300 TestAcc 0.8744 0.9350
epoch 2200 LossPred 0.3222 LossAtt 0.5749 TrainAcc 0.8700 TestAcc 0.8483 0.8850
epoch 2300 LossPred 0.1295 LossAtt 0.5540 TrainAcc 0.9600 TestAcc 0.8804 0.9350
epoch 2400 LossPred 0.4059 LossAtt 0.5593 TrainAcc 0.8300 TestAcc 0.7933 0.8450
epoch 2500 LossPred 0.2794 LossAtt 0.5621 TrainAcc 0.9000 TestAcc 0.8328 0.8850
Optimization Finished!
********** replication  72  **********
epoch   0 LossPred 1.2643 LossAtt 1.0046 TrainAcc 0.3800 TestAcc 0.5080 0.3700
epoch 100 LossPred 0.8111 LossAtt 0.4234 TrainAcc 0.7400 TestAcc 0.5836 0.7400
epoch 200 LossPred 0.7589 LossAtt 0.2988 TrainAcc 0.7400 TestAcc 0.5836 0.7400
epoch 300 LossPred 0.7463 LossAtt 0.2840 TrainAcc 0.7400 TestAcc 0.5836 0.7400
epoch 400 LossPred 0.7367 LossAtt 0.3138 TrainAcc 0.7400 TestAcc 0.5836 0.7400
epoch 500 LossPred 0.7336 LossAtt 0.2928 TrainAcc 0.7400 TestAcc 0.5836 0.7400
epoch 600 LossPred 0.7323 LossAtt 0.2783 TrainAcc 0.7400 TestAcc 0.5836 0.7400
epoch 700 LossPred 0.7309 LossAtt 0.2787 TrainAcc 0.7400 TestAcc 0.5836 0.7400
epoch 800 LossPred 0.7293 LossAtt 0.2809 TrainAcc 0.7400 TestAcc 0.5836 0.7400
epoch 900 LossPred 0.7223 LossAtt 0.3522 TrainAcc 0.7400 TestAcc 0.5836 0.7400
epoch 1000 LossPred 0.6990 LossAtt 0.3925 TrainAcc 0.7500 TestAcc 0.5485 0.7450
epoch 1100 LossPred 0.6831 LossAtt 0.3500 TrainAcc 0.7700 TestAcc 0.5383 0.7600
epoch 1200 LossPred 0.6709 LossAtt 0.3975 TrainAcc 0.7700 TestAcc 0.5238 0.7600
epoch 1300 LossPred 0.6598 LossAtt 0.4522 TrainAcc 0.8000 TestAcc 0.5198 0.7850
epoch 1400 LossPred 0.6390 LossAtt 0.4668 TrainAcc 0.8000 TestAcc 0.5218 0.7800
epoch 1500 LossPred 0.6248 LossAtt 0.4932 TrainAcc 0.7900 TestAcc 0.5195 0.7800
epoch 1600 LossPred 0.6004 LossAtt 0.5623 TrainAcc 0.8000 TestAcc 0.5188 0.7700
epoch 1700 LossPred 0.5941 LossAtt 0.5468 TrainAcc 0.7900 TestAcc 0.5220 0.7800
epoch 1800 LossPred 0.5685 LossAtt 0.5709 TrainAcc 0.8000 TestAcc 0.5235 0.7850
epoch 1900 LossPred 0.5206 LossAtt 0.5985 TrainAcc 0.8000 TestAcc 0.5338 0.7800
epoch 2000 LossPred 0.4670 LossAtt 0.6007 TrainAcc 0.8500 TestAcc 0.6089 0.8300
epoch 2100 LossPred 0.3062 LossAtt 0.5760 TrainAcc 0.9100 TestAcc 0.7135 0.8700
epoch 2200 LossPred 0.2775 LossAtt 0.5529 TrainAcc 0.8900 TestAcc 0.7623 0.8850
epoch 2300 LossPred 0.2624 LossAtt 0.5481 TrainAcc 0.9100 TestAcc 0.7643 0.9000
epoch 2400 LossPred 0.6034 LossAtt 0.5585 TrainAcc 0.7600 TestAcc 0.6677 0.7250
epoch 2500 LossPred 0.2833 LossAtt 0.5325 TrainAcc 0.9100 TestAcc 0.7575 0.8950
Optimization Finished!
********** replication  73  **********
epoch   0 LossPred 1.1667 LossAtt 1.0166 TrainAcc 0.4600 TestAcc 0.5405 0.4800
epoch 100 LossPred 0.9898 LossAtt 0.5105 TrainAcc 0.5700 TestAcc 0.5676 0.5550
epoch 200 LossPred 0.9655 LossAtt 0.5198 TrainAcc 0.5800 TestAcc 0.5568 0.5800
epoch 300 LossPred 0.9520 LossAtt 0.5166 TrainAcc 0.5800 TestAcc 0.5543 0.5950
epoch 400 LossPred 0.9467 LossAtt 0.5038 TrainAcc 0.6100 TestAcc 0.5203 0.6000
epoch 500 LossPred 0.9202 LossAtt 0.5160 TrainAcc 0.6200 TestAcc 0.6301 0.6150
epoch 600 LossPred 0.6085 LossAtt 0.4601 TrainAcc 0.8100 TestAcc 0.8458 0.7950
epoch 700 LossPred 0.5567 LossAtt 0.4346 TrainAcc 0.8100 TestAcc 0.8201 0.7800
epoch 800 LossPred 0.4927 LossAtt 0.4625 TrainAcc 0.8300 TestAcc 0.8256 0.7950
epoch 900 LossPred 0.4559 LossAtt 0.4646 TrainAcc 0.8600 TestAcc 0.8383 0.7950
epoch 1000 LossPred 0.4480 LossAtt 0.4459 TrainAcc 0.8500 TestAcc 0.8293 0.7900
epoch 1100 LossPred 0.4484 LossAtt 0.4362 TrainAcc 0.8400 TestAcc 0.8283 0.7900
epoch 1200 LossPred 0.5352 LossAtt 0.4569 TrainAcc 0.8300 TestAcc 0.8451 0.8150
epoch 1300 LossPred 0.4238 LossAtt 0.4567 TrainAcc 0.8500 TestAcc 0.8391 0.8100
epoch 1400 LossPred 0.3797 LossAtt 0.4695 TrainAcc 0.8800 TestAcc 0.8626 0.8050
epoch 1500 LossPred 0.5607 LossAtt 0.4272 TrainAcc 0.8300 TestAcc 0.7988 0.7900
epoch 1600 LossPred 0.5806 LossAtt 0.4995 TrainAcc 0.8300 TestAcc 0.8058 0.7550
epoch 1700 LossPred 0.4929 LossAtt 0.4251 TrainAcc 0.8400 TestAcc 0.8203 0.7950
epoch 1800 LossPred 0.3168 LossAtt 0.4547 TrainAcc 0.9300 TestAcc 0.8428 0.8150
epoch 1900 LossPred 0.5687 LossAtt 0.4617 TrainAcc 0.8300 TestAcc 0.8118 0.7500
epoch 2000 LossPred 0.4789 LossAtt 0.4730 TrainAcc 0.8500 TestAcc 0.8363 0.7850
epoch 2100 LossPred 0.4546 LossAtt 0.4779 TrainAcc 0.8700 TestAcc 0.8496 0.8100
epoch 2200 LossPred 0.4630 LossAtt 0.4850 TrainAcc 0.8600 TestAcc 0.8356 0.8000
epoch 2300 LossPred 0.4085 LossAtt 0.4843 TrainAcc 0.8800 TestAcc 0.8388 0.7950
epoch 2400 LossPred 0.3563 LossAtt 0.4840 TrainAcc 0.8600 TestAcc 0.8614 0.8300
epoch 2500 LossPred 0.3249 LossAtt 0.4792 TrainAcc 0.9000 TestAcc 0.8574 0.8350
Optimization Finished!
********** replication  74  **********
epoch   0 LossPred 1.0465 LossAtt 1.0040 TrainAcc 0.4400 TestAcc 0.4707 0.4500
epoch 100 LossPred 0.9369 LossAtt 0.4597 TrainAcc 0.6100 TestAcc 0.5771 0.6100
epoch 200 LossPred 0.9152 LossAtt 0.5012 TrainAcc 0.6500 TestAcc 0.6029 0.6550
epoch 300 LossPred 0.8926 LossAtt 0.4420 TrainAcc 0.6400 TestAcc 0.6019 0.6350
epoch 400 LossPred 0.8582 LossAtt 0.3722 TrainAcc 0.6800 TestAcc 0.6266 0.6650
epoch 500 LossPred 0.8513 LossAtt 0.3671 TrainAcc 0.6600 TestAcc 0.6141 0.6750
epoch 600 LossPred 0.8402 LossAtt 0.3726 TrainAcc 0.6800 TestAcc 0.6266 0.6600
epoch 700 LossPred 0.8112 LossAtt 0.4698 TrainAcc 0.6900 TestAcc 0.6211 0.6550
epoch 800 LossPred 0.7869 LossAtt 0.4859 TrainAcc 0.6800 TestAcc 0.5656 0.6500
epoch 900 LossPred 0.7467 LossAtt 0.7533 TrainAcc 0.6800 TestAcc 0.5931 0.6650
epoch 1000 LossPred 0.6881 LossAtt 0.6087 TrainAcc 0.7300 TestAcc 0.6221 0.7400
epoch 1100 LossPred 0.6736 LossAtt 0.5867 TrainAcc 0.7600 TestAcc 0.5896 0.7250
epoch 1200 LossPred 0.6712 LossAtt 0.5759 TrainAcc 0.7700 TestAcc 0.5991 0.7400
epoch 1300 LossPred 0.6602 LossAtt 0.5586 TrainAcc 0.7900 TestAcc 0.5941 0.7450
epoch 1400 LossPred 0.6440 LossAtt 0.5431 TrainAcc 0.8000 TestAcc 0.6146 0.7500
epoch 1500 LossPred 0.6389 LossAtt 0.5564 TrainAcc 0.7800 TestAcc 0.6154 0.7300
epoch 1600 LossPred 0.6333 LossAtt 0.5115 TrainAcc 0.7800 TestAcc 0.6164 0.7400
epoch 1700 LossPred 0.6376 LossAtt 0.5237 TrainAcc 0.8000 TestAcc 0.6169 0.7450
epoch 1800 LossPred 0.6366 LossAtt 0.4909 TrainAcc 0.7900 TestAcc 0.6119 0.7350
epoch 1900 LossPred 0.6350 LossAtt 0.4855 TrainAcc 0.7900 TestAcc 0.6176 0.7450
epoch 2000 LossPred 0.6412 LossAtt 0.4889 TrainAcc 0.8000 TestAcc 0.6171 0.7550
epoch 2100 LossPred 0.6639 LossAtt 0.4896 TrainAcc 0.7900 TestAcc 0.6144 0.7300
epoch 2200 LossPred 0.6833 LossAtt 0.4874 TrainAcc 0.7700 TestAcc 0.6171 0.7300
epoch 2300 LossPred 0.6984 LossAtt 0.5333 TrainAcc 0.7700 TestAcc 0.6164 0.7400
epoch 2400 LossPred 0.6994 LossAtt 0.5227 TrainAcc 0.7700 TestAcc 0.6191 0.7400
epoch 2500 LossPred 0.6817 LossAtt 0.5195 TrainAcc 0.7900 TestAcc 0.6219 0.7250
Optimization Finished!
********** replication  75  **********
epoch   0 LossPred 0.9993 LossAtt 1.0155 TrainAcc 0.6800 TestAcc 0.5878 0.6600
epoch 100 LossPred 0.8858 LossAtt 0.4848 TrainAcc 0.6800 TestAcc 0.5878 0.6800
epoch 200 LossPred 0.8677 LossAtt 0.3842 TrainAcc 0.6800 TestAcc 0.5878 0.6800
epoch 300 LossPred 0.8579 LossAtt 0.3405 TrainAcc 0.6800 TestAcc 0.5878 0.6800
epoch 400 LossPred 0.8388 LossAtt 0.3248 TrainAcc 0.6800 TestAcc 0.5878 0.6800
epoch 500 LossPred 0.5782 LossAtt 0.4708 TrainAcc 0.8100 TestAcc 0.7808 0.7750
epoch 600 LossPred 0.3662 LossAtt 0.4451 TrainAcc 0.9500 TestAcc 0.8834 0.9150
epoch 700 LossPred 0.3432 LossAtt 0.4574 TrainAcc 0.8900 TestAcc 0.8794 0.9150
epoch 800 LossPred 0.2193 LossAtt 0.5306 TrainAcc 0.9400 TestAcc 0.8721 0.9300
epoch 900 LossPred 0.1808 LossAtt 0.5542 TrainAcc 0.9500 TestAcc 0.8886 0.9350
epoch 1000 LossPred 0.1337 LossAtt 0.5522 TrainAcc 0.9800 TestAcc 0.8944 0.9550
epoch 1100 LossPred 0.1257 LossAtt 0.5771 TrainAcc 0.9700 TestAcc 0.8949 0.9400
epoch 1200 LossPred 0.2425 LossAtt 0.5838 TrainAcc 0.9500 TestAcc 0.8544 0.9250
epoch 1300 LossPred 0.1075 LossAtt 0.5669 TrainAcc 0.9800 TestAcc 0.8969 0.9400
epoch 1400 LossPred 0.1929 LossAtt 0.5588 TrainAcc 0.9400 TestAcc 0.8651 0.9250
epoch 1500 LossPred 0.1548 LossAtt 0.5728 TrainAcc 0.9400 TestAcc 0.8821 0.9150
epoch 1600 LossPred 0.1104 LossAtt 0.5799 TrainAcc 0.9600 TestAcc 0.8886 0.9500
epoch 1700 LossPred 0.1262 LossAtt 0.5428 TrainAcc 0.9600 TestAcc 0.8761 0.9450
epoch 1800 LossPred 0.1988 LossAtt 0.5732 TrainAcc 0.9300 TestAcc 0.8639 0.9250
epoch 1900 LossPred 0.0869 LossAtt 0.5569 TrainAcc 0.9800 TestAcc 0.9007 0.9450
epoch 2000 LossPred 0.1060 LossAtt 0.5254 TrainAcc 0.9600 TestAcc 0.8796 0.9500
epoch 2100 LossPred 0.1417 LossAtt 0.5686 TrainAcc 0.9500 TestAcc 0.8836 0.9300
epoch 2200 LossPred 0.0923 LossAtt 0.5521 TrainAcc 0.9800 TestAcc 0.8834 0.9750
epoch 2300 LossPred 0.2087 LossAtt 0.5343 TrainAcc 0.9300 TestAcc 0.8496 0.9300
epoch 2400 LossPred 0.0884 LossAtt 0.5442 TrainAcc 0.9900 TestAcc 0.8846 0.9700
epoch 2500 LossPred 0.0709 LossAtt 0.5629 TrainAcc 0.9800 TestAcc 0.8996 0.9450
Optimization Finished!
********** replication  76  **********
epoch   0 LossPred 1.0971 LossAtt 0.9748 TrainAcc 0.5400 TestAcc 0.4890 0.5050
epoch 100 LossPred 0.9334 LossAtt 0.5311 TrainAcc 0.6200 TestAcc 0.5928 0.6200
epoch 200 LossPred 0.9023 LossAtt 0.5418 TrainAcc 0.6800 TestAcc 0.6341 0.6200
epoch 300 LossPred 0.8724 LossAtt 0.5483 TrainAcc 0.6800 TestAcc 0.6389 0.6600
epoch 400 LossPred 0.8340 LossAtt 0.5392 TrainAcc 0.7100 TestAcc 0.6431 0.6800
epoch 500 LossPred 0.8046 LossAtt 0.5934 TrainAcc 0.7000 TestAcc 0.6499 0.6950
epoch 600 LossPred 0.7892 LossAtt 0.6383 TrainAcc 0.7200 TestAcc 0.6496 0.7050
epoch 700 LossPred 0.7223 LossAtt 0.6461 TrainAcc 0.7700 TestAcc 0.6504 0.7300
epoch 800 LossPred 0.6944 LossAtt 0.6215 TrainAcc 0.8000 TestAcc 0.6366 0.7400
epoch 900 LossPred 0.6888 LossAtt 0.5780 TrainAcc 0.7900 TestAcc 0.6379 0.7300
epoch 1000 LossPred 0.6752 LossAtt 0.5683 TrainAcc 0.7800 TestAcc 0.6406 0.7250
epoch 1100 LossPred 0.6642 LossAtt 0.5747 TrainAcc 0.7800 TestAcc 0.6356 0.7400
epoch 1200 LossPred 0.6579 LossAtt 0.5315 TrainAcc 0.7800 TestAcc 0.6364 0.7350
epoch 1300 LossPred 0.6640 LossAtt 0.5306 TrainAcc 0.7800 TestAcc 0.6356 0.7400
epoch 1400 LossPred 0.6636 LossAtt 0.5213 TrainAcc 0.7800 TestAcc 0.6356 0.7350
epoch 1500 LossPred 0.6538 LossAtt 0.5130 TrainAcc 0.7900 TestAcc 0.6384 0.7400
epoch 1600 LossPred 0.6501 LossAtt 0.4977 TrainAcc 0.7800 TestAcc 0.6376 0.7500
epoch 1700 LossPred 0.6674 LossAtt 0.5019 TrainAcc 0.7700 TestAcc 0.6381 0.7550
epoch 1800 LossPred 0.6646 LossAtt 0.5140 TrainAcc 0.7800 TestAcc 0.6381 0.7450
epoch 1900 LossPred 0.6615 LossAtt 0.5082 TrainAcc 0.7800 TestAcc 0.6379 0.7350
epoch 2000 LossPred 0.6585 LossAtt 0.4854 TrainAcc 0.7900 TestAcc 0.6404 0.7500
epoch 2100 LossPred 0.6558 LossAtt 0.4912 TrainAcc 0.7900 TestAcc 0.6389 0.7450
epoch 2200 LossPred 0.6659 LossAtt 0.4910 TrainAcc 0.7900 TestAcc 0.6401 0.7450
epoch 2300 LossPred 0.6525 LossAtt 0.4952 TrainAcc 0.7900 TestAcc 0.6391 0.7500
epoch 2400 LossPred 0.6625 LossAtt 0.4997 TrainAcc 0.7900 TestAcc 0.6396 0.7500
epoch 2500 LossPred 0.6657 LossAtt 0.4904 TrainAcc 0.7900 TestAcc 0.6376 0.7350
Optimization Finished!
********** replication  77  **********
epoch   0 LossPred 0.9988 LossAtt 1.0080 TrainAcc 0.5800 TestAcc 0.5048 0.5900
epoch 100 LossPred 0.8285 LossAtt 0.5874 TrainAcc 0.6500 TestAcc 0.5868 0.6400
epoch 200 LossPred 0.7965 LossAtt 0.6228 TrainAcc 0.6500 TestAcc 0.5908 0.6450
epoch 300 LossPred 0.4633 LossAtt 0.6832 TrainAcc 0.9100 TestAcc 0.7905 0.8500
epoch 400 LossPred 0.3365 LossAtt 0.6357 TrainAcc 0.9200 TestAcc 0.8108 0.9050
epoch 500 LossPred 0.2943 LossAtt 0.6280 TrainAcc 0.9300 TestAcc 0.8033 0.9000
epoch 600 LossPred 0.3251 LossAtt 0.6045 TrainAcc 0.8900 TestAcc 0.8036 0.9000
epoch 700 LossPred 0.2675 LossAtt 0.6111 TrainAcc 0.9200 TestAcc 0.7978 0.9050
epoch 800 LossPred 0.2428 LossAtt 0.6155 TrainAcc 0.9400 TestAcc 0.8273 0.8850
epoch 900 LossPred 0.2292 LossAtt 0.6074 TrainAcc 0.9500 TestAcc 0.8166 0.9050
epoch 1000 LossPred 0.2864 LossAtt 0.6054 TrainAcc 0.9100 TestAcc 0.8156 0.8950
epoch 1100 LossPred 0.2044 LossAtt 0.6159 TrainAcc 0.9500 TestAcc 0.8191 0.9000
epoch 1200 LossPred 0.2810 LossAtt 0.5890 TrainAcc 0.9200 TestAcc 0.8321 0.8650
epoch 1300 LossPred 0.1975 LossAtt 0.5867 TrainAcc 0.9500 TestAcc 0.8311 0.9150
epoch 1400 LossPred 0.1940 LossAtt 0.6165 TrainAcc 0.9500 TestAcc 0.8161 0.9000
epoch 1500 LossPred 0.1880 LossAtt 0.6190 TrainAcc 0.9500 TestAcc 0.8328 0.9000
epoch 1600 LossPred 0.2176 LossAtt 0.5982 TrainAcc 0.9400 TestAcc 0.8303 0.8950
epoch 1700 LossPred 0.2415 LossAtt 0.5954 TrainAcc 0.9200 TestAcc 0.8296 0.8850
epoch 1800 LossPred 0.1802 LossAtt 0.6052 TrainAcc 0.9600 TestAcc 0.8293 0.8950
epoch 1900 LossPred 0.1730 LossAtt 0.6137 TrainAcc 0.9600 TestAcc 0.8313 0.8950
epoch 2000 LossPred 0.1722 LossAtt 0.6173 TrainAcc 0.9500 TestAcc 0.8286 0.9050
epoch 2100 LossPred 0.1559 LossAtt 0.6079 TrainAcc 0.9600 TestAcc 0.8233 0.9000
epoch 2200 LossPred 0.1733 LossAtt 0.6199 TrainAcc 0.9500 TestAcc 0.8236 0.9000
epoch 2300 LossPred 0.1708 LossAtt 0.6201 TrainAcc 0.9400 TestAcc 0.8163 0.9000
epoch 2400 LossPred 0.1779 LossAtt 0.5962 TrainAcc 0.9300 TestAcc 0.8131 0.9050
epoch 2500 LossPred 0.2271 LossAtt 0.6041 TrainAcc 0.9200 TestAcc 0.8288 0.8850
Optimization Finished!
********** replication  78  **********
epoch   0 LossPred 1.1237 LossAtt 0.9952 TrainAcc 0.4600 TestAcc 0.4997 0.4750
epoch 100 LossPred 0.8122 LossAtt 0.5039 TrainAcc 0.6000 TestAcc 0.6406 0.6250
epoch 200 LossPred 0.6324 LossAtt 0.4097 TrainAcc 0.8000 TestAcc 0.7435 0.7900
epoch 300 LossPred 0.3739 LossAtt 0.4396 TrainAcc 0.8900 TestAcc 0.8641 0.8900
epoch 400 LossPred 0.3391 LossAtt 0.4347 TrainAcc 0.8900 TestAcc 0.8639 0.9000
epoch 500 LossPred 0.3263 LossAtt 0.3801 TrainAcc 0.9000 TestAcc 0.8576 0.8850
epoch 600 LossPred 0.3028 LossAtt 0.4076 TrainAcc 0.9100 TestAcc 0.8438 0.9100
epoch 700 LossPred 0.2719 LossAtt 0.4588 TrainAcc 0.9100 TestAcc 0.8766 0.9050
epoch 800 LossPred 0.2240 LossAtt 0.4477 TrainAcc 0.9300 TestAcc 0.8766 0.9300
epoch 900 LossPred 0.2366 LossAtt 0.4561 TrainAcc 0.9300 TestAcc 0.8719 0.9250
epoch 1000 LossPred 0.1941 LossAtt 0.4597 TrainAcc 0.9300 TestAcc 0.8864 0.9400
epoch 1100 LossPred 0.1744 LossAtt 0.4403 TrainAcc 0.9600 TestAcc 0.9002 0.9200
epoch 1200 LossPred 0.3777 LossAtt 0.4129 TrainAcc 0.8800 TestAcc 0.8053 0.8550
epoch 1300 LossPred 0.3313 LossAtt 0.4167 TrainAcc 0.9000 TestAcc 0.8539 0.8550
epoch 1400 LossPred 0.2630 LossAtt 0.4003 TrainAcc 0.9000 TestAcc 0.8403 0.9150
epoch 1500 LossPred 0.2793 LossAtt 0.4083 TrainAcc 0.9100 TestAcc 0.8388 0.9100
epoch 1600 LossPred 0.1866 LossAtt 0.4121 TrainAcc 0.9400 TestAcc 0.8944 0.9400
epoch 1700 LossPred 0.2361 LossAtt 0.4079 TrainAcc 0.9400 TestAcc 0.8939 0.9050
epoch 1800 LossPred 0.1620 LossAtt 0.3870 TrainAcc 0.9500 TestAcc 0.8959 0.9450
epoch 1900 LossPred 0.1604 LossAtt 0.3827 TrainAcc 0.9500 TestAcc 0.9022 0.9500
epoch 2000 LossPred 0.1504 LossAtt 0.4052 TrainAcc 0.9600 TestAcc 0.9022 0.9450
epoch 2100 LossPred 0.1430 LossAtt 0.3940 TrainAcc 0.9600 TestAcc 0.9107 0.9550
epoch 2200 LossPred 0.1309 LossAtt 0.3846 TrainAcc 0.9700 TestAcc 0.9104 0.9500
epoch 2300 LossPred 0.3447 LossAtt 0.3940 TrainAcc 0.8800 TestAcc 0.8146 0.8700
epoch 2400 LossPred 0.1390 LossAtt 0.3787 TrainAcc 0.9500 TestAcc 0.9164 0.9600
epoch 2500 LossPred 0.1542 LossAtt 0.3719 TrainAcc 0.9400 TestAcc 0.9162 0.9700
Optimization Finished!
********** replication  79  **********
epoch   0 LossPred 1.1385 LossAtt 1.0515 TrainAcc 0.4500 TestAcc 0.4494 0.4600
epoch 100 LossPred 0.8725 LossAtt 0.4884 TrainAcc 0.7000 TestAcc 0.6371 0.6650
epoch 200 LossPred 0.7865 LossAtt 0.4583 TrainAcc 0.7400 TestAcc 0.6299 0.7400
epoch 300 LossPred 0.7585 LossAtt 0.3962 TrainAcc 0.7400 TestAcc 0.6299 0.7400
epoch 400 LossPred 0.7439 LossAtt 0.3487 TrainAcc 0.7400 TestAcc 0.6299 0.7450
epoch 500 LossPred 0.7330 LossAtt 0.3503 TrainAcc 0.7400 TestAcc 0.6299 0.7450
epoch 600 LossPred 0.7273 LossAtt 0.2981 TrainAcc 0.7400 TestAcc 0.6299 0.7450
epoch 700 LossPred 0.7256 LossAtt 0.3020 TrainAcc 0.7400 TestAcc 0.6299 0.7450
epoch 800 LossPred 0.7340 LossAtt 0.2844 TrainAcc 0.7400 TestAcc 0.6299 0.7400
epoch 900 LossPred 0.7538 LossAtt 0.3785 TrainAcc 0.7400 TestAcc 0.6299 0.7500
epoch 1000 LossPred 0.4875 LossAtt 0.7770 TrainAcc 0.8600 TestAcc 0.7177 0.8450
epoch 1100 LossPred 0.3390 LossAtt 0.7300 TrainAcc 0.8800 TestAcc 0.8243 0.8900
epoch 1200 LossPred 0.2641 LossAtt 0.6773 TrainAcc 0.9000 TestAcc 0.8711 0.8950
epoch 1300 LossPred 0.2090 LossAtt 0.6398 TrainAcc 0.9400 TestAcc 0.9069 0.9150
epoch 1400 LossPred 0.1486 LossAtt 0.7027 TrainAcc 0.9600 TestAcc 0.9207 0.9000
epoch 1500 LossPred 0.1157 LossAtt 0.6541 TrainAcc 0.9700 TestAcc 0.9309 0.9100
epoch 1600 LossPred 0.1066 LossAtt 0.6693 TrainAcc 0.9900 TestAcc 0.9242 0.9050
epoch 1700 LossPred 0.1055 LossAtt 0.6521 TrainAcc 0.9700 TestAcc 0.9264 0.9000
epoch 1800 LossPred 0.1014 LossAtt 0.6715 TrainAcc 0.9800 TestAcc 0.9237 0.9250
epoch 1900 LossPred 0.1057 LossAtt 0.6537 TrainAcc 0.9700 TestAcc 0.9232 0.9150
epoch 2000 LossPred 0.0958 LossAtt 0.6576 TrainAcc 0.9700 TestAcc 0.9299 0.9150
epoch 2100 LossPred 0.0803 LossAtt 0.6233 TrainAcc 0.9900 TestAcc 0.9347 0.9200
epoch 2200 LossPred 0.0772 LossAtt 0.6294 TrainAcc 1.0000 TestAcc 0.9344 0.9150
Optimization Finished!
********** replication  80  **********
epoch   0 LossPred 1.1048 LossAtt 1.0222 TrainAcc 0.5200 TestAcc 0.5033 0.4900
epoch 100 LossPred 0.9650 LossAtt 0.6036 TrainAcc 0.6000 TestAcc 0.5721 0.5850
epoch 200 LossPred 0.9246 LossAtt 0.5184 TrainAcc 0.6000 TestAcc 0.5966 0.6000
epoch 300 LossPred 0.9112 LossAtt 0.3269 TrainAcc 0.6000 TestAcc 0.5966 0.6000
epoch 400 LossPred 0.9016 LossAtt 0.4262 TrainAcc 0.6300 TestAcc 0.6514 0.6350
epoch 500 LossPred 0.5044 LossAtt 0.4412 TrainAcc 0.8500 TestAcc 0.8431 0.7950
epoch 600 LossPred 0.4250 LossAtt 0.4863 TrainAcc 0.8600 TestAcc 0.8621 0.8300
epoch 700 LossPred 0.3984 LossAtt 0.4692 TrainAcc 0.8800 TestAcc 0.8756 0.8250
epoch 800 LossPred 0.3694 LossAtt 0.4580 TrainAcc 0.8800 TestAcc 0.8656 0.8400
epoch 900 LossPred 0.3912 LossAtt 0.4614 TrainAcc 0.8800 TestAcc 0.8894 0.8400
epoch 1000 LossPred 0.5422 LossAtt 0.5193 TrainAcc 0.8200 TestAcc 0.8091 0.8100
epoch 1100 LossPred 0.3954 LossAtt 0.5367 TrainAcc 0.8400 TestAcc 0.8689 0.8150
epoch 1200 LossPred 0.3960 LossAtt 0.5498 TrainAcc 0.8700 TestAcc 0.8674 0.8600
epoch 1300 LossPred 0.3607 LossAtt 0.5371 TrainAcc 0.8900 TestAcc 0.8689 0.8850
epoch 1400 LossPred 0.2196 LossAtt 0.5520 TrainAcc 0.9100 TestAcc 0.9067 0.9000
epoch 1500 LossPred 0.2364 LossAtt 0.5637 TrainAcc 0.9200 TestAcc 0.8986 0.8850
epoch 1600 LossPred 0.2103 LossAtt 0.5479 TrainAcc 0.9400 TestAcc 0.9044 0.8900
epoch 1700 LossPred 0.2575 LossAtt 0.5279 TrainAcc 0.9200 TestAcc 0.8904 0.9100
epoch 1800 LossPred 0.2219 LossAtt 0.5453 TrainAcc 0.9200 TestAcc 0.9122 0.8850
epoch 1900 LossPred 0.2005 LossAtt 0.5099 TrainAcc 0.9400 TestAcc 0.9027 0.9100
epoch 2000 LossPred 0.2492 LossAtt 0.5313 TrainAcc 0.9100 TestAcc 0.8941 0.8900
epoch 2100 LossPred 0.3036 LossAtt 0.5239 TrainAcc 0.8900 TestAcc 0.8731 0.8850
epoch 2200 LossPred 0.1992 LossAtt 0.5419 TrainAcc 0.9500 TestAcc 0.9034 0.8950
epoch 2300 LossPred 0.1843 LossAtt 0.5192 TrainAcc 0.9300 TestAcc 0.9064 0.9050
epoch 2400 LossPred 0.2286 LossAtt 0.5389 TrainAcc 0.9100 TestAcc 0.8989 0.8950
epoch 2500 LossPred 0.2298 LossAtt 0.5122 TrainAcc 0.9300 TestAcc 0.8966 0.8900
Optimization Finished!
********** replication  81  **********
epoch   0 LossPred 0.9698 LossAtt 1.0142 TrainAcc 0.5900 TestAcc 0.5668 0.6000
epoch 100 LossPred 0.8222 LossAtt 0.4769 TrainAcc 0.6600 TestAcc 0.6031 0.6600
epoch 200 LossPred 0.7905 LossAtt 0.4743 TrainAcc 0.7100 TestAcc 0.6441 0.7150
epoch 300 LossPred 0.7533 LossAtt 0.5198 TrainAcc 0.7400 TestAcc 0.6434 0.7400
epoch 400 LossPred 0.6296 LossAtt 0.5517 TrainAcc 0.8400 TestAcc 0.7355 0.8000
epoch 500 LossPred 0.4225 LossAtt 0.4749 TrainAcc 0.9000 TestAcc 0.8746 0.8750
epoch 600 LossPred 0.3871 LossAtt 0.4582 TrainAcc 0.8900 TestAcc 0.8819 0.8800
epoch 700 LossPred 0.4358 LossAtt 0.4143 TrainAcc 0.8400 TestAcc 0.8278 0.8550
epoch 800 LossPred 0.3369 LossAtt 0.3949 TrainAcc 0.9100 TestAcc 0.8709 0.8950
epoch 900 LossPred 0.2993 LossAtt 0.4040 TrainAcc 0.9100 TestAcc 0.8746 0.9000
epoch 1000 LossPred 0.2818 LossAtt 0.3972 TrainAcc 0.9000 TestAcc 0.8984 0.8950
epoch 1100 LossPred 0.2517 LossAtt 0.4037 TrainAcc 0.9000 TestAcc 0.8931 0.8850
epoch 1200 LossPred 0.2880 LossAtt 0.4169 TrainAcc 0.9100 TestAcc 0.8666 0.9150
epoch 1300 LossPred 0.3148 LossAtt 0.4159 TrainAcc 0.8900 TestAcc 0.8438 0.8850
epoch 1400 LossPred 0.2328 LossAtt 0.4307 TrainAcc 0.9200 TestAcc 0.8996 0.9100
epoch 1500 LossPred 0.2397 LossAtt 0.4392 TrainAcc 0.9300 TestAcc 0.8896 0.8900
epoch 1600 LossPred 0.2641 LossAtt 0.4293 TrainAcc 0.9100 TestAcc 0.8979 0.8800
epoch 1700 LossPred 0.2962 LossAtt 0.4146 TrainAcc 0.9000 TestAcc 0.8774 0.9000
epoch 1800 LossPred 0.4509 LossAtt 0.3940 TrainAcc 0.8500 TestAcc 0.8121 0.8700
epoch 1900 LossPred 0.2689 LossAtt 0.3875 TrainAcc 0.9100 TestAcc 0.8879 0.8900
epoch 2000 LossPred 0.2844 LossAtt 0.3784 TrainAcc 0.9000 TestAcc 0.8831 0.8850
epoch 2100 LossPred 0.3152 LossAtt 0.3518 TrainAcc 0.9100 TestAcc 0.8654 0.8850
epoch 2200 LossPred 0.2721 LossAtt 0.3630 TrainAcc 0.9000 TestAcc 0.8891 0.8850
epoch 2300 LossPred 0.2554 LossAtt 0.3675 TrainAcc 0.9100 TestAcc 0.8904 0.9050
epoch 2400 LossPred 0.2363 LossAtt 0.3835 TrainAcc 0.9200 TestAcc 0.8919 0.9050
epoch 2500 LossPred 0.2144 LossAtt 0.3943 TrainAcc 0.9300 TestAcc 0.9012 0.9250
Optimization Finished!
********** replication  82  **********
epoch   0 LossPred 1.2252 LossAtt 1.0000 TrainAcc 0.4200 TestAcc 0.4152 0.4350
epoch 100 LossPred 0.8928 LossAtt 0.3520 TrainAcc 0.6100 TestAcc 0.6099 0.6150
epoch 200 LossPred 0.8652 LossAtt 0.2894 TrainAcc 0.6600 TestAcc 0.6406 0.6450
epoch 300 LossPred 0.4905 LossAtt 0.4066 TrainAcc 0.8900 TestAcc 0.8864 0.8600
epoch 400 LossPred 0.3702 LossAtt 0.3598 TrainAcc 0.9000 TestAcc 0.8971 0.8700
epoch 500 LossPred 0.3493 LossAtt 0.3268 TrainAcc 0.9000 TestAcc 0.8924 0.8650
epoch 600 LossPred 0.3418 LossAtt 0.3228 TrainAcc 0.9100 TestAcc 0.8961 0.8800
epoch 700 LossPred 0.5458 LossAtt 0.3181 TrainAcc 0.7900 TestAcc 0.7820 0.7950
epoch 800 LossPred 0.4069 LossAtt 0.3056 TrainAcc 0.8700 TestAcc 0.8669 0.8550
epoch 900 LossPred 0.4322 LossAtt 0.3148 TrainAcc 0.8800 TestAcc 0.8348 0.8650
epoch 1000 LossPred 0.3700 LossAtt 0.2978 TrainAcc 0.8800 TestAcc 0.8676 0.8750
epoch 1100 LossPred 0.3334 LossAtt 0.2922 TrainAcc 0.9100 TestAcc 0.8809 0.8750
epoch 1200 LossPred 0.4052 LossAtt 0.2924 TrainAcc 0.8800 TestAcc 0.8398 0.8650
epoch 1300 LossPred 0.5124 LossAtt 0.2748 TrainAcc 0.8100 TestAcc 0.8303 0.8100
epoch 1400 LossPred 0.3898 LossAtt 0.2768 TrainAcc 0.8900 TestAcc 0.8599 0.8600
epoch 1500 LossPred 0.4432 LossAtt 0.2942 TrainAcc 0.8700 TestAcc 0.8268 0.8400
epoch 1600 LossPred 0.5868 LossAtt 0.2876 TrainAcc 0.8100 TestAcc 0.7788 0.8000
epoch 1700 LossPred 0.4891 LossAtt 0.2917 TrainAcc 0.8500 TestAcc 0.8041 0.8200
epoch 1800 LossPred 0.3216 LossAtt 0.2632 TrainAcc 0.9100 TestAcc 0.8699 0.8900
epoch 1900 LossPred 0.3624 LossAtt 0.2922 TrainAcc 0.9000 TestAcc 0.8596 0.8650
epoch 2000 LossPred 0.3078 LossAtt 0.2767 TrainAcc 0.9300 TestAcc 0.8731 0.8950
epoch 2100 LossPred 0.5535 LossAtt 0.2724 TrainAcc 0.8200 TestAcc 0.7883 0.8200
epoch 2200 LossPred 0.4019 LossAtt 0.2793 TrainAcc 0.8800 TestAcc 0.8428 0.8650
epoch 2300 LossPred 0.3184 LossAtt 0.2780 TrainAcc 0.9300 TestAcc 0.8681 0.9050
epoch 2400 LossPred 0.3178 LossAtt 0.2758 TrainAcc 0.9000 TestAcc 0.8689 0.9000
epoch 2500 LossPred 0.4157 LossAtt 0.2560 TrainAcc 0.8600 TestAcc 0.8483 0.8600
Optimization Finished!
********** replication  83  **********
epoch   0 LossPred 1.1692 LossAtt 1.0125 TrainAcc 0.5100 TestAcc 0.5581 0.5000
epoch 100 LossPred 0.9354 LossAtt 0.4953 TrainAcc 0.5800 TestAcc 0.5538 0.5850
epoch 200 LossPred 0.8908 LossAtt 0.5178 TrainAcc 0.6600 TestAcc 0.6046 0.6600
epoch 300 LossPred 0.4398 LossAtt 0.6401 TrainAcc 0.9000 TestAcc 0.8493 0.8700
epoch 400 LossPred 0.3266 LossAtt 0.6257 TrainAcc 0.9200 TestAcc 0.8644 0.8850
epoch 500 LossPred 0.2541 LossAtt 0.6147 TrainAcc 0.9300 TestAcc 0.8861 0.8850
epoch 600 LossPred 0.2265 LossAtt 0.6031 TrainAcc 0.9300 TestAcc 0.8921 0.8950
epoch 700 LossPred 0.2151 LossAtt 0.6024 TrainAcc 0.9400 TestAcc 0.8894 0.8900
epoch 800 LossPred 0.1868 LossAtt 0.5651 TrainAcc 0.9500 TestAcc 0.9042 0.9150
epoch 900 LossPred 0.1681 LossAtt 0.5320 TrainAcc 0.9500 TestAcc 0.9154 0.9300
epoch 1000 LossPred 0.1728 LossAtt 0.5308 TrainAcc 0.9500 TestAcc 0.9012 0.9400
epoch 1100 LossPred 0.1711 LossAtt 0.5111 TrainAcc 0.9500 TestAcc 0.9122 0.9350
epoch 1200 LossPred 0.1534 LossAtt 0.5046 TrainAcc 0.9400 TestAcc 0.9059 0.9200
epoch 1300 LossPred 0.1724 LossAtt 0.4846 TrainAcc 0.9400 TestAcc 0.8991 0.9150
epoch 1400 LossPred 0.1379 LossAtt 0.5165 TrainAcc 0.9500 TestAcc 0.9082 0.9350
epoch 1500 LossPred 0.1203 LossAtt 0.5045 TrainAcc 0.9800 TestAcc 0.9164 0.9400
epoch 1600 LossPred 0.1168 LossAtt 0.5171 TrainAcc 0.9700 TestAcc 0.9154 0.9350
epoch 1700 LossPred 0.1262 LossAtt 0.4938 TrainAcc 0.9600 TestAcc 0.9102 0.9350
epoch 1800 LossPred 0.1056 LossAtt 0.4911 TrainAcc 0.9800 TestAcc 0.9172 0.9400
epoch 1900 LossPred 0.1119 LossAtt 0.4901 TrainAcc 0.9800 TestAcc 0.9154 0.9450
epoch 2000 LossPred 0.1282 LossAtt 0.4836 TrainAcc 0.9700 TestAcc 0.9092 0.9450
epoch 2100 LossPred 0.0965 LossAtt 0.4720 TrainAcc 0.9800 TestAcc 0.9129 0.9550
epoch 2200 LossPred 0.1190 LossAtt 0.4685 TrainAcc 0.9700 TestAcc 0.9074 0.9400
epoch 2300 LossPred 0.2107 LossAtt 0.4599 TrainAcc 0.9100 TestAcc 0.8981 0.9350
epoch 2400 LossPred 0.1766 LossAtt 0.4539 TrainAcc 0.9500 TestAcc 0.8881 0.9350
epoch 2500 LossPred 0.1145 LossAtt 0.4529 TrainAcc 0.9800 TestAcc 0.9154 0.9400
Optimization Finished!
********** replication  84  **********
epoch   0 LossPred 1.0321 LossAtt 1.0293 TrainAcc 0.5200 TestAcc 0.4832 0.4950
epoch 100 LossPred 0.8878 LossAtt 0.3409 TrainAcc 0.6800 TestAcc 0.5948 0.6800
epoch 200 LossPred 0.8460 LossAtt 0.2216 TrainAcc 0.6800 TestAcc 0.5948 0.6800
epoch 300 LossPred 0.8091 LossAtt 0.3052 TrainAcc 0.6800 TestAcc 0.5948 0.6800
epoch 400 LossPred 0.5415 LossAtt 0.4887 TrainAcc 0.8200 TestAcc 0.8051 0.8500
epoch 500 LossPred 0.5054 LossAtt 0.4063 TrainAcc 0.8400 TestAcc 0.7487 0.8350
epoch 600 LossPred 0.3745 LossAtt 0.3891 TrainAcc 0.8800 TestAcc 0.7995 0.8900
epoch 700 LossPred 0.4599 LossAtt 0.3790 TrainAcc 0.8400 TestAcc 0.7953 0.8450
epoch 800 LossPred 0.3275 LossAtt 0.3517 TrainAcc 0.9000 TestAcc 0.7948 0.8950
epoch 900 LossPred 0.3123 LossAtt 0.3485 TrainAcc 0.9100 TestAcc 0.8018 0.9050
epoch 1000 LossPred 0.2960 LossAtt 0.3371 TrainAcc 0.9200 TestAcc 0.7978 0.9050
epoch 1100 LossPred 0.3055 LossAtt 0.3455 TrainAcc 0.9100 TestAcc 0.8006 0.9000
epoch 1200 LossPred 0.2822 LossAtt 0.3341 TrainAcc 0.9100 TestAcc 0.8203 0.8900
epoch 1300 LossPred 0.3637 LossAtt 0.3393 TrainAcc 0.8700 TestAcc 0.8098 0.8850
epoch 1400 LossPred 0.3715 LossAtt 0.3166 TrainAcc 0.8700 TestAcc 0.8086 0.8800
epoch 1500 LossPred 0.2667 LossAtt 0.3023 TrainAcc 0.9300 TestAcc 0.8098 0.9200
epoch 1600 LossPred 0.3170 LossAtt 0.3028 TrainAcc 0.8900 TestAcc 0.7830 0.8900
epoch 1700 LossPred 0.2739 LossAtt 0.2994 TrainAcc 0.9100 TestAcc 0.7973 0.9100
epoch 1800 LossPred 0.2675 LossAtt 0.2999 TrainAcc 0.9200 TestAcc 0.8126 0.9150
epoch 1900 LossPred 0.3379 LossAtt 0.2799 TrainAcc 0.9000 TestAcc 0.7668 0.8750
epoch 2000 LossPred 0.3056 LossAtt 0.3030 TrainAcc 0.8900 TestAcc 0.8076 0.8950
epoch 2100 LossPred 0.2590 LossAtt 0.3114 TrainAcc 0.9200 TestAcc 0.8066 0.9150
epoch 2200 LossPred 0.5129 LossAtt 0.3076 TrainAcc 0.8300 TestAcc 0.7390 0.8450
epoch 2300 LossPred 0.2776 LossAtt 0.2848 TrainAcc 0.9100 TestAcc 0.7960 0.9200
epoch 2400 LossPred 0.2508 LossAtt 0.3105 TrainAcc 0.9100 TestAcc 0.8128 0.9200
epoch 2500 LossPred 0.2856 LossAtt 0.3034 TrainAcc 0.9100 TestAcc 0.7815 0.9050
Optimization Finished!
********** replication  85  **********
epoch   0 LossPred 1.1283 LossAtt 1.0929 TrainAcc 0.4700 TestAcc 0.5235 0.4650
epoch 100 LossPred 0.9220 LossAtt 0.3461 TrainAcc 0.6600 TestAcc 0.5968 0.6600
epoch 200 LossPred 0.8580 LossAtt 0.3919 TrainAcc 0.6600 TestAcc 0.5968 0.6600
epoch 300 LossPred 0.7929 LossAtt 0.3421 TrainAcc 0.6700 TestAcc 0.6141 0.6750
epoch 400 LossPred 0.5309 LossAtt 0.5401 TrainAcc 0.8200 TestAcc 0.8133 0.7750
epoch 500 LossPred 0.4222 LossAtt 0.4814 TrainAcc 0.8600 TestAcc 0.8418 0.8450
epoch 600 LossPred 0.3965 LossAtt 0.4460 TrainAcc 0.8700 TestAcc 0.8531 0.8550
epoch 700 LossPred 0.3376 LossAtt 0.3615 TrainAcc 0.8900 TestAcc 0.8811 0.8900
epoch 800 LossPred 0.3212 LossAtt 0.2847 TrainAcc 0.9200 TestAcc 0.8764 0.9150
epoch 900 LossPred 0.3037 LossAtt 0.2653 TrainAcc 0.9000 TestAcc 0.8874 0.9050
epoch 1000 LossPred 0.2771 LossAtt 0.2472 TrainAcc 0.9000 TestAcc 0.9037 0.9300
epoch 1100 LossPred 0.2353 LossAtt 0.2466 TrainAcc 0.9500 TestAcc 0.9209 0.9350
epoch 1200 LossPred 0.2080 LossAtt 0.2476 TrainAcc 0.9700 TestAcc 0.9217 0.9500
epoch 1300 LossPred 0.2001 LossAtt 0.2414 TrainAcc 0.9700 TestAcc 0.9277 0.9500
epoch 1400 LossPred 0.3002 LossAtt 0.2427 TrainAcc 0.8700 TestAcc 0.8636 0.8800
epoch 1500 LossPred 0.2101 LossAtt 0.2371 TrainAcc 0.9400 TestAcc 0.9199 0.9350
epoch 1600 LossPred 0.2696 LossAtt 0.2329 TrainAcc 0.9100 TestAcc 0.8989 0.9250
epoch 1700 LossPred 0.2194 LossAtt 0.2463 TrainAcc 0.9500 TestAcc 0.9044 0.9350
epoch 1800 LossPred 0.2254 LossAtt 0.2402 TrainAcc 0.9300 TestAcc 0.8981 0.9400
epoch 1900 LossPred 0.3468 LossAtt 0.2485 TrainAcc 0.8700 TestAcc 0.8323 0.8750
epoch 2000 LossPred 0.2234 LossAtt 0.2560 TrainAcc 0.9400 TestAcc 0.8954 0.9300
epoch 2100 LossPred 0.2295 LossAtt 0.2508 TrainAcc 0.9300 TestAcc 0.9109 0.9400
epoch 2200 LossPred 0.4175 LossAtt 0.2593 TrainAcc 0.8500 TestAcc 0.8241 0.8500
epoch 2300 LossPred 0.2752 LossAtt 0.2689 TrainAcc 0.8800 TestAcc 0.8991 0.9050
epoch 2400 LossPred 0.4174 LossAtt 0.2717 TrainAcc 0.8500 TestAcc 0.8251 0.8600
epoch 2500 LossPred 0.2960 LossAtt 0.2829 TrainAcc 0.8800 TestAcc 0.8919 0.8800
Optimization Finished!
********** replication  86  **********
epoch   0 LossPred 1.1301 LossAtt 1.0269 TrainAcc 0.3600 TestAcc 0.4184 0.4150
epoch 100 LossPred 0.9318 LossAtt 0.5278 TrainAcc 0.6400 TestAcc 0.6261 0.6200
epoch 200 LossPred 0.8656 LossAtt 0.5122 TrainAcc 0.6700 TestAcc 0.6224 0.6650
epoch 300 LossPred 0.5013 LossAtt 0.5524 TrainAcc 0.8200 TestAcc 0.8093 0.7750
epoch 400 LossPred 0.3793 LossAtt 0.5859 TrainAcc 0.8700 TestAcc 0.8181 0.8400
epoch 500 LossPred 0.3017 LossAtt 0.5815 TrainAcc 0.9000 TestAcc 0.8458 0.8750
epoch 600 LossPred 0.2801 LossAtt 0.5926 TrainAcc 0.9000 TestAcc 0.8291 0.8700
epoch 700 LossPred 0.2272 LossAtt 0.5852 TrainAcc 0.9300 TestAcc 0.8594 0.8850
epoch 800 LossPred 0.2897 LossAtt 0.5707 TrainAcc 0.9100 TestAcc 0.8443 0.8850
epoch 900 LossPred 0.1819 LossAtt 0.5840 TrainAcc 0.9500 TestAcc 0.8626 0.9000
epoch 1000 LossPred 0.1652 LossAtt 0.5493 TrainAcc 0.9700 TestAcc 0.8599 0.9250
epoch 1100 LossPred 0.1505 LossAtt 0.5661 TrainAcc 0.9600 TestAcc 0.8834 0.9250
epoch 1200 LossPred 0.1389 LossAtt 0.5579 TrainAcc 0.9700 TestAcc 0.8824 0.9400
epoch 1300 LossPred 0.1393 LossAtt 0.5540 TrainAcc 0.9500 TestAcc 0.8844 0.9200
epoch 1400 LossPred 0.1386 LossAtt 0.5750 TrainAcc 0.9700 TestAcc 0.8856 0.9300
epoch 1500 LossPred 0.1608 LossAtt 0.5686 TrainAcc 0.9600 TestAcc 0.8871 0.9150
epoch 1600 LossPred 0.1504 LossAtt 0.5669 TrainAcc 0.9800 TestAcc 0.8899 0.9300
epoch 1700 LossPred 0.1314 LossAtt 0.5753 TrainAcc 0.9700 TestAcc 0.8749 0.9250
epoch 1800 LossPred 0.1425 LossAtt 0.5439 TrainAcc 0.9600 TestAcc 0.8776 0.9300
epoch 1900 LossPred 0.1251 LossAtt 0.5491 TrainAcc 0.9700 TestAcc 0.8844 0.9300
epoch 2000 LossPred 0.1916 LossAtt 0.5436 TrainAcc 0.9500 TestAcc 0.8539 0.9250
epoch 2100 LossPred 0.1572 LossAtt 0.5409 TrainAcc 0.9600 TestAcc 0.8696 0.9450
epoch 2200 LossPred 0.1365 LossAtt 0.5364 TrainAcc 0.9600 TestAcc 0.8671 0.9400
epoch 2300 LossPred 0.1409 LossAtt 0.5348 TrainAcc 0.9700 TestAcc 0.8791 0.9450
epoch 2400 LossPred 0.1652 LossAtt 0.5343 TrainAcc 0.9600 TestAcc 0.8601 0.9250
epoch 2500 LossPred 0.1908 LossAtt 0.5398 TrainAcc 0.9300 TestAcc 0.8731 0.9150
Optimization Finished!
********** replication  87  **********
epoch   0 LossPred 1.3268 LossAtt 1.0468 TrainAcc 0.4700 TestAcc 0.5165 0.4650
epoch 100 LossPred 0.9444 LossAtt 0.5202 TrainAcc 0.5900 TestAcc 0.6286 0.5950
epoch 200 LossPred 0.8947 LossAtt 0.5336 TrainAcc 0.6400 TestAcc 0.6194 0.6300
epoch 300 LossPred 0.8663 LossAtt 0.6329 TrainAcc 0.6300 TestAcc 0.6364 0.6250
epoch 400 LossPred 0.8179 LossAtt 0.7119 TrainAcc 0.6000 TestAcc 0.6399 0.6150
epoch 500 LossPred 0.5343 LossAtt 0.6394 TrainAcc 0.8600 TestAcc 0.8273 0.8450
epoch 600 LossPred 0.4813 LossAtt 0.5614 TrainAcc 0.8300 TestAcc 0.8208 0.8450
epoch 700 LossPred 0.3902 LossAtt 0.5141 TrainAcc 0.8600 TestAcc 0.8071 0.8450
epoch 800 LossPred 0.3445 LossAtt 0.5333 TrainAcc 0.9000 TestAcc 0.8258 0.8350
epoch 900 LossPred 0.3184 LossAtt 0.4994 TrainAcc 0.9200 TestAcc 0.8243 0.8600
epoch 1000 LossPred 0.3113 LossAtt 0.4996 TrainAcc 0.9000 TestAcc 0.8303 0.8650
epoch 1100 LossPred 0.2998 LossAtt 0.4759 TrainAcc 0.9200 TestAcc 0.8348 0.8750
epoch 1200 LossPred 0.2918 LossAtt 0.5080 TrainAcc 0.9200 TestAcc 0.8306 0.8800
epoch 1300 LossPred 0.2904 LossAtt 0.5023 TrainAcc 0.9200 TestAcc 0.8373 0.8900
epoch 1400 LossPred 0.2882 LossAtt 0.5053 TrainAcc 0.9200 TestAcc 0.8358 0.8800
epoch 1500 LossPred 0.2871 LossAtt 0.4953 TrainAcc 0.9200 TestAcc 0.8413 0.9000
epoch 1600 LossPred 0.2786 LossAtt 0.5012 TrainAcc 0.9300 TestAcc 0.8348 0.8900
epoch 1700 LossPred 0.2815 LossAtt 0.5202 TrainAcc 0.9200 TestAcc 0.8351 0.8850
epoch 1800 LossPred 0.2686 LossAtt 0.5084 TrainAcc 0.9300 TestAcc 0.8436 0.9150
epoch 1900 LossPred 0.2692 LossAtt 0.5106 TrainAcc 0.9300 TestAcc 0.8463 0.9150
epoch 2000 LossPred 0.2702 LossAtt 0.5211 TrainAcc 0.9300 TestAcc 0.8463 0.9050
epoch 2100 LossPred 0.2720 LossAtt 0.5171 TrainAcc 0.9200 TestAcc 0.8411 0.9050
epoch 2200 LossPred 0.2613 LossAtt 0.5326 TrainAcc 0.9300 TestAcc 0.8431 0.8950
epoch 2300 LossPred 0.3292 LossAtt 0.5320 TrainAcc 0.9100 TestAcc 0.8138 0.8650
epoch 2400 LossPred 0.2472 LossAtt 0.5462 TrainAcc 0.9400 TestAcc 0.8436 0.9100
epoch 2500 LossPred 0.2430 LossAtt 0.5509 TrainAcc 0.9400 TestAcc 0.8298 0.8900
Optimization Finished!
********** replication  88  **********
epoch   0 LossPred 1.1387 LossAtt 1.0201 TrainAcc 0.4900 TestAcc 0.4449 0.5000
epoch 100 LossPred 0.9211 LossAtt 0.5099 TrainAcc 0.6600 TestAcc 0.5871 0.6600
epoch 200 LossPred 0.8579 LossAtt 0.5292 TrainAcc 0.6600 TestAcc 0.5871 0.6600
epoch 300 LossPred 0.8422 LossAtt 0.4821 TrainAcc 0.6600 TestAcc 0.5871 0.6600
epoch 400 LossPred 0.8233 LossAtt 0.5316 TrainAcc 0.6600 TestAcc 0.5871 0.6600
epoch 500 LossPred 0.3793 LossAtt 0.5418 TrainAcc 0.9000 TestAcc 0.7875 0.8650
epoch 600 LossPred 0.4873 LossAtt 0.5067 TrainAcc 0.8500 TestAcc 0.7380 0.8450
epoch 700 LossPred 0.3224 LossAtt 0.4589 TrainAcc 0.9100 TestAcc 0.7985 0.8750
epoch 800 LossPred 0.3443 LossAtt 0.4519 TrainAcc 0.8900 TestAcc 0.7830 0.8600
epoch 900 LossPred 0.3046 LossAtt 0.4276 TrainAcc 0.9100 TestAcc 0.7948 0.8800
epoch 1000 LossPred 0.3108 LossAtt 0.4206 TrainAcc 0.9000 TestAcc 0.7903 0.8750
epoch 1100 LossPred 0.2897 LossAtt 0.4319 TrainAcc 0.9100 TestAcc 0.7965 0.8800
epoch 1200 LossPred 0.3514 LossAtt 0.4143 TrainAcc 0.8900 TestAcc 0.7870 0.8950
epoch 1300 LossPred 0.2595 LossAtt 0.3960 TrainAcc 0.9200 TestAcc 0.7998 0.8950
epoch 1400 LossPred 0.2719 LossAtt 0.3979 TrainAcc 0.9200 TestAcc 0.7963 0.9000
epoch 1500 LossPred 0.2673 LossAtt 0.4000 TrainAcc 0.9200 TestAcc 0.8161 0.9050
epoch 1600 LossPred 0.2804 LossAtt 0.3787 TrainAcc 0.9000 TestAcc 0.8161 0.9050
epoch 1700 LossPred 0.2852 LossAtt 0.4039 TrainAcc 0.9000 TestAcc 0.8258 0.9100
epoch 1800 LossPred 0.2503 LossAtt 0.3872 TrainAcc 0.9300 TestAcc 0.8186 0.9250
epoch 1900 LossPred 0.3187 LossAtt 0.3932 TrainAcc 0.9000 TestAcc 0.8341 0.9050
epoch 2000 LossPred 0.2528 LossAtt 0.3785 TrainAcc 0.9200 TestAcc 0.8246 0.9250
epoch 2100 LossPred 0.2913 LossAtt 0.4114 TrainAcc 0.8900 TestAcc 0.8376 0.9200
epoch 2200 LossPred 0.2351 LossAtt 0.4212 TrainAcc 0.9200 TestAcc 0.8336 0.9300
epoch 2300 LossPred 0.2630 LossAtt 0.3952 TrainAcc 0.9200 TestAcc 0.8188 0.9000
epoch 2400 LossPred 0.2452 LossAtt 0.4274 TrainAcc 0.9100 TestAcc 0.8468 0.9050
epoch 2500 LossPred 0.2240 LossAtt 0.3983 TrainAcc 0.9200 TestAcc 0.8511 0.9100
Optimization Finished!
********** replication  89  **********
epoch   0 LossPred 0.9344 LossAtt 1.0053 TrainAcc 0.6200 TestAcc 0.5828 0.5750
epoch 100 LossPred 0.7209 LossAtt 0.6331 TrainAcc 0.7500 TestAcc 0.6421 0.7600
epoch 200 LossPred 0.5857 LossAtt 0.6390 TrainAcc 0.8200 TestAcc 0.7095 0.8250
epoch 300 LossPred 0.3467 LossAtt 0.6600 TrainAcc 0.9000 TestAcc 0.8529 0.8650
epoch 400 LossPred 0.2743 LossAtt 0.6346 TrainAcc 0.9200 TestAcc 0.8679 0.8800
epoch 500 LossPred 0.2877 LossAtt 0.6203 TrainAcc 0.9100 TestAcc 0.8511 0.8950
epoch 600 LossPred 0.2489 LossAtt 0.6050 TrainAcc 0.9200 TestAcc 0.8649 0.8900
epoch 700 LossPred 0.2276 LossAtt 0.6044 TrainAcc 0.9300 TestAcc 0.8601 0.9050
epoch 800 LossPred 0.2379 LossAtt 0.5940 TrainAcc 0.9000 TestAcc 0.8629 0.9000
epoch 900 LossPred 0.2280 LossAtt 0.5591 TrainAcc 0.9200 TestAcc 0.8671 0.8900
epoch 1000 LossPred 0.2106 LossAtt 0.5893 TrainAcc 0.9300 TestAcc 0.8398 0.9000
epoch 1100 LossPred 0.2141 LossAtt 0.5762 TrainAcc 0.9100 TestAcc 0.8644 0.9000
epoch 1200 LossPred 0.2419 LossAtt 0.5802 TrainAcc 0.8900 TestAcc 0.8536 0.8950
epoch 1300 LossPred 0.1774 LossAtt 0.5883 TrainAcc 0.9300 TestAcc 0.8586 0.9200
epoch 1400 LossPred 0.1815 LossAtt 0.5702 TrainAcc 0.9400 TestAcc 0.8406 0.9050
epoch 1500 LossPred 0.3272 LossAtt 0.5644 TrainAcc 0.8700 TestAcc 0.8281 0.8850
epoch 1600 LossPred 0.1673 LossAtt 0.5913 TrainAcc 0.9400 TestAcc 0.8524 0.9150
epoch 1700 LossPred 0.2597 LossAtt 0.5906 TrainAcc 0.9100 TestAcc 0.8031 0.8750
epoch 1800 LossPred 0.2365 LossAtt 0.5655 TrainAcc 0.9200 TestAcc 0.8098 0.8750
epoch 1900 LossPred 0.1463 LossAtt 0.5644 TrainAcc 0.9600 TestAcc 0.8579 0.9200
epoch 2000 LossPred 0.2451 LossAtt 0.5724 TrainAcc 0.9100 TestAcc 0.8086 0.8900
epoch 2100 LossPred 0.2317 LossAtt 0.5745 TrainAcc 0.9100 TestAcc 0.8131 0.8800
epoch 2200 LossPred 0.3277 LossAtt 0.5793 TrainAcc 0.8800 TestAcc 0.7878 0.8500
epoch 2300 LossPred 0.2254 LossAtt 0.5529 TrainAcc 0.9000 TestAcc 0.8368 0.9050
epoch 2400 LossPred 0.2134 LossAtt 0.5842 TrainAcc 0.9200 TestAcc 0.8198 0.8900
epoch 2500 LossPred 0.2026 LossAtt 0.5893 TrainAcc 0.9400 TestAcc 0.8208 0.8950
Optimization Finished!
********** replication  90  **********
epoch   0 LossPred 1.0203 LossAtt 1.0181 TrainAcc 0.6000 TestAcc 0.5123 0.5850
epoch 100 LossPred 0.9438 LossAtt 0.3093 TrainAcc 0.6200 TestAcc 0.5863 0.6200
epoch 200 LossPred 0.9429 LossAtt 0.3071 TrainAcc 0.6200 TestAcc 0.5863 0.6200
epoch 300 LossPred 0.9416 LossAtt 0.2223 TrainAcc 0.6200 TestAcc 0.5863 0.6200
epoch 400 LossPred 0.9414 LossAtt 0.2196 TrainAcc 0.6200 TestAcc 0.5863 0.6200
epoch 500 LossPred 0.9413 LossAtt 0.2226 TrainAcc 0.6200 TestAcc 0.5863 0.6200
epoch 600 LossPred 0.9400 LossAtt 0.3149 TrainAcc 0.6200 TestAcc 0.5863 0.6200
epoch 700 LossPred 0.6489 LossAtt 0.5202 TrainAcc 0.7900 TestAcc 0.7540 0.8000
epoch 800 LossPred 0.4192 LossAtt 0.5586 TrainAcc 0.8700 TestAcc 0.8496 0.8700
epoch 900 LossPred 0.3136 LossAtt 0.5713 TrainAcc 0.8900 TestAcc 0.8714 0.8850
epoch 1000 LossPred 0.3012 LossAtt 0.5671 TrainAcc 0.9000 TestAcc 0.8656 0.8900
epoch 1100 LossPred 0.3307 LossAtt 0.5388 TrainAcc 0.8900 TestAcc 0.8566 0.8850
epoch 1200 LossPred 0.3454 LossAtt 0.5376 TrainAcc 0.8900 TestAcc 0.8441 0.8800
epoch 1300 LossPred 0.3468 LossAtt 0.5389 TrainAcc 0.8900 TestAcc 0.8463 0.8950
epoch 1400 LossPred 0.2953 LossAtt 0.5210 TrainAcc 0.9000 TestAcc 0.8521 0.9050
epoch 1500 LossPred 0.2070 LossAtt 0.5116 TrainAcc 0.9400 TestAcc 0.8596 0.9050
epoch 1600 LossPred 0.1950 LossAtt 0.4961 TrainAcc 0.9500 TestAcc 0.8579 0.9050
epoch 1700 LossPred 0.1825 LossAtt 0.4839 TrainAcc 0.9500 TestAcc 0.8591 0.9200
epoch 1800 LossPred 0.1759 LossAtt 0.4577 TrainAcc 0.9600 TestAcc 0.8586 0.9200
epoch 1900 LossPred 0.1731 LossAtt 0.4451 TrainAcc 0.9700 TestAcc 0.8619 0.9300
epoch 2000 LossPred 0.1737 LossAtt 0.4309 TrainAcc 0.9500 TestAcc 0.8571 0.9400
epoch 2100 LossPred 0.1791 LossAtt 0.4224 TrainAcc 0.9400 TestAcc 0.8561 0.9350
epoch 2200 LossPred 0.2250 LossAtt 0.4317 TrainAcc 0.9300 TestAcc 0.8606 0.9300
epoch 2300 LossPred 0.1809 LossAtt 0.4058 TrainAcc 0.9400 TestAcc 0.8566 0.9300
epoch 2400 LossPred 0.1825 LossAtt 0.4149 TrainAcc 0.9400 TestAcc 0.8581 0.9350
epoch 2500 LossPred 0.1952 LossAtt 0.4304 TrainAcc 0.9500 TestAcc 0.8516 0.9250
Optimization Finished!
********** replication  91  **********
epoch   0 LossPred 0.9632 LossAtt 0.9946 TrainAcc 0.5600 TestAcc 0.5413 0.5500
epoch 100 LossPred 0.9301 LossAtt 0.6233 TrainAcc 0.5800 TestAcc 0.5958 0.5800
epoch 200 LossPred 0.8748 LossAtt 0.6253 TrainAcc 0.6400 TestAcc 0.6517 0.6250
epoch 300 LossPred 0.6275 LossAtt 0.5112 TrainAcc 0.7700 TestAcc 0.8111 0.7850
epoch 400 LossPred 0.4301 LossAtt 0.4823 TrainAcc 0.8800 TestAcc 0.8348 0.8650
epoch 500 LossPred 0.3733 LossAtt 0.4497 TrainAcc 0.8900 TestAcc 0.8536 0.8850
epoch 600 LossPred 0.3574 LossAtt 0.4554 TrainAcc 0.8900 TestAcc 0.8473 0.8800
epoch 700 LossPred 0.3288 LossAtt 0.4703 TrainAcc 0.9000 TestAcc 0.8646 0.8850
epoch 800 LossPred 0.3051 LossAtt 0.4727 TrainAcc 0.9000 TestAcc 0.8619 0.9000
epoch 900 LossPred 0.3098 LossAtt 0.4537 TrainAcc 0.9200 TestAcc 0.8684 0.9050
epoch 1000 LossPred 0.2762 LossAtt 0.4712 TrainAcc 0.9100 TestAcc 0.8646 0.9150
epoch 1100 LossPred 0.2666 LossAtt 0.4729 TrainAcc 0.9300 TestAcc 0.8664 0.9150
epoch 1200 LossPred 0.3176 LossAtt 0.4663 TrainAcc 0.9100 TestAcc 0.8646 0.9000
epoch 1300 LossPred 0.2846 LossAtt 0.4998 TrainAcc 0.9300 TestAcc 0.8701 0.9150
epoch 1400 LossPred 0.2761 LossAtt 0.4755 TrainAcc 0.9100 TestAcc 0.8719 0.9200
epoch 1500 LossPred 0.3008 LossAtt 0.5077 TrainAcc 0.9200 TestAcc 0.8674 0.9000
epoch 1600 LossPred 0.2571 LossAtt 0.4961 TrainAcc 0.9300 TestAcc 0.8676 0.9250
epoch 1700 LossPred 0.2712 LossAtt 0.4869 TrainAcc 0.9300 TestAcc 0.8714 0.9200
epoch 1800 LossPred 0.3003 LossAtt 0.4820 TrainAcc 0.9200 TestAcc 0.8694 0.9100
epoch 1900 LossPred 0.2518 LossAtt 0.4732 TrainAcc 0.9300 TestAcc 0.8664 0.9300
epoch 2000 LossPred 0.2676 LossAtt 0.4844 TrainAcc 0.9300 TestAcc 0.8714 0.9300
epoch 2100 LossPred 0.3289 LossAtt 0.4644 TrainAcc 0.9000 TestAcc 0.8629 0.8800
epoch 2200 LossPred 0.2611 LossAtt 0.4819 TrainAcc 0.9200 TestAcc 0.8709 0.9200
epoch 2300 LossPred 0.3079 LossAtt 0.4632 TrainAcc 0.9100 TestAcc 0.8584 0.9050
epoch 2400 LossPred 0.3984 LossAtt 0.4625 TrainAcc 0.8800 TestAcc 0.8363 0.8700
epoch 2500 LossPred 0.2635 LossAtt 0.4937 TrainAcc 0.9300 TestAcc 0.8649 0.9200
Optimization Finished!
********** replication  92  **********
epoch   0 LossPred 1.3000 LossAtt 1.0082 TrainAcc 0.5000 TestAcc 0.4737 0.5050
epoch 100 LossPred 0.9733 LossAtt 0.6212 TrainAcc 0.5400 TestAcc 0.4990 0.5750
epoch 200 LossPred 0.7455 LossAtt 0.6722 TrainAcc 0.7200 TestAcc 0.6394 0.7300
epoch 300 LossPred 0.3966 LossAtt 0.6545 TrainAcc 0.9200 TestAcc 0.8326 0.8800
epoch 400 LossPred 0.3621 LossAtt 0.6079 TrainAcc 0.9200 TestAcc 0.8529 0.8650
epoch 500 LossPred 0.2669 LossAtt 0.5719 TrainAcc 0.9200 TestAcc 0.8556 0.8700
epoch 600 LossPred 0.2374 LossAtt 0.5515 TrainAcc 0.9400 TestAcc 0.8739 0.8800
epoch 700 LossPred 0.2774 LossAtt 0.5466 TrainAcc 0.9100 TestAcc 0.8744 0.9000
epoch 800 LossPred 0.2220 LossAtt 0.5159 TrainAcc 0.9500 TestAcc 0.8854 0.9050
epoch 900 LossPred 0.1961 LossAtt 0.5018 TrainAcc 0.9500 TestAcc 0.8821 0.9050
epoch 1000 LossPred 0.2188 LossAtt 0.4774 TrainAcc 0.9400 TestAcc 0.8844 0.9050
epoch 1100 LossPred 0.1865 LossAtt 0.4732 TrainAcc 0.9500 TestAcc 0.8804 0.9150
epoch 1200 LossPred 0.1909 LossAtt 0.4639 TrainAcc 0.9500 TestAcc 0.8676 0.9200
epoch 1300 LossPred 0.1867 LossAtt 0.4623 TrainAcc 0.9500 TestAcc 0.8816 0.9200
epoch 1400 LossPred 0.1757 LossAtt 0.4515 TrainAcc 0.9500 TestAcc 0.8831 0.9250
epoch 1500 LossPred 0.1838 LossAtt 0.4355 TrainAcc 0.9400 TestAcc 0.8769 0.9300
epoch 1600 LossPred 0.1746 LossAtt 0.4413 TrainAcc 0.9500 TestAcc 0.8914 0.9300
epoch 1700 LossPred 0.1892 LossAtt 0.4437 TrainAcc 0.9500 TestAcc 0.8961 0.9250
epoch 1800 LossPred 0.1561 LossAtt 0.4160 TrainAcc 0.9500 TestAcc 0.8936 0.9350
epoch 1900 LossPred 0.1406 LossAtt 0.4324 TrainAcc 0.9600 TestAcc 0.9182 0.9500
epoch 2000 LossPred 0.1817 LossAtt 0.4203 TrainAcc 0.9400 TestAcc 0.9034 0.9300
epoch 2100 LossPred 0.1349 LossAtt 0.4210 TrainAcc 0.9600 TestAcc 0.9234 0.9500
epoch 2200 LossPred 0.1426 LossAtt 0.4270 TrainAcc 0.9700 TestAcc 0.9004 0.9450
epoch 2300 LossPred 0.1628 LossAtt 0.4393 TrainAcc 0.9600 TestAcc 0.9074 0.9550
epoch 2400 LossPred 0.1439 LossAtt 0.4586 TrainAcc 0.9700 TestAcc 0.9044 0.9500
epoch 2500 LossPred 0.1317 LossAtt 0.4732 TrainAcc 0.9700 TestAcc 0.9209 0.9550
Optimization Finished!
********** replication  93  **********
epoch   0 LossPred 1.1357 LossAtt 1.0372 TrainAcc 0.5200 TestAcc 0.5063 0.5300
epoch 100 LossPred 0.9741 LossAtt 0.4522 TrainAcc 0.5900 TestAcc 0.5878 0.5950
epoch 200 LossPred 0.9565 LossAtt 0.3941 TrainAcc 0.5900 TestAcc 0.5878 0.5800
epoch 300 LossPred 0.9528 LossAtt 0.2248 TrainAcc 0.5900 TestAcc 0.5878 0.5900
epoch 400 LossPred 0.9507 LossAtt 0.1080 TrainAcc 0.5900 TestAcc 0.5878 0.5900
epoch 500 LossPred 0.9505 LossAtt 0.0818 TrainAcc 0.5900 TestAcc 0.5878 0.5900
epoch 600 LossPred 0.9503 LossAtt 0.0951 TrainAcc 0.5900 TestAcc 0.5878 0.5900
epoch 700 LossPred 0.9501 LossAtt 0.1409 TrainAcc 0.5900 TestAcc 0.5878 0.5900
epoch 800 LossPred 0.9497 LossAtt 0.1782 TrainAcc 0.5900 TestAcc 0.5878 0.5900
epoch 900 LossPred 0.9486 LossAtt 0.1972 TrainAcc 0.5900 TestAcc 0.5878 0.5900
epoch 1000 LossPred 0.9470 LossAtt 0.2129 TrainAcc 0.5900 TestAcc 0.5878 0.5900
epoch 1100 LossPred 0.8898 LossAtt 0.5751 TrainAcc 0.6200 TestAcc 0.6562 0.6550
epoch 1200 LossPred 0.3795 LossAtt 0.5097 TrainAcc 0.8900 TestAcc 0.8759 0.8650
epoch 1300 LossPred 0.2706 LossAtt 0.4786 TrainAcc 0.9100 TestAcc 0.8871 0.8950
epoch 1400 LossPred 0.1997 LossAtt 0.4796 TrainAcc 0.9300 TestAcc 0.9299 0.9250
epoch 1500 LossPred 0.1404 LossAtt 0.4803 TrainAcc 0.9800 TestAcc 0.9327 0.9600
epoch 1600 LossPred 0.1465 LossAtt 0.4734 TrainAcc 0.9700 TestAcc 0.9367 0.9500
epoch 1700 LossPred 0.1439 LossAtt 0.4575 TrainAcc 0.9800 TestAcc 0.9332 0.9500
epoch 1800 LossPred 0.1647 LossAtt 0.4322 TrainAcc 0.9500 TestAcc 0.9227 0.9300
epoch 1900 LossPred 0.1377 LossAtt 0.4571 TrainAcc 0.9600 TestAcc 0.9267 0.9350
epoch 2000 LossPred 0.1486 LossAtt 0.4182 TrainAcc 0.9600 TestAcc 0.9199 0.9450
epoch 2100 LossPred 0.1343 LossAtt 0.4208 TrainAcc 0.9700 TestAcc 0.9267 0.9550
epoch 2200 LossPred 0.1272 LossAtt 0.4035 TrainAcc 0.9600 TestAcc 0.9212 0.9500
epoch 2300 LossPred 0.1515 LossAtt 0.4036 TrainAcc 0.9200 TestAcc 0.9119 0.9400
epoch 2400 LossPred 0.1835 LossAtt 0.3761 TrainAcc 0.9300 TestAcc 0.9114 0.9350
epoch 2500 LossPred 0.2622 LossAtt 0.4177 TrainAcc 0.9000 TestAcc 0.8488 0.9150
Optimization Finished!
********** replication  94  **********
epoch   0 LossPred 1.0721 LossAtt 0.9976 TrainAcc 0.4000 TestAcc 0.4149 0.4000
epoch 100 LossPred 0.9229 LossAtt 0.5190 TrainAcc 0.6900 TestAcc 0.5418 0.6650
epoch 200 LossPred 0.8723 LossAtt 0.5322 TrainAcc 0.6400 TestAcc 0.5350 0.6700
epoch 300 LossPred 0.8297 LossAtt 0.5780 TrainAcc 0.6800 TestAcc 0.5648 0.6700
epoch 400 LossPred 0.3970 LossAtt 0.7278 TrainAcc 0.9000 TestAcc 0.7980 0.8550
epoch 500 LossPred 0.2480 LossAtt 0.7295 TrainAcc 0.9500 TestAcc 0.8293 0.9100
epoch 600 LossPred 0.1376 LossAtt 0.6642 TrainAcc 0.9600 TestAcc 0.8306 0.9300
epoch 700 LossPred 0.1263 LossAtt 0.6074 TrainAcc 0.9700 TestAcc 0.8321 0.9400
epoch 800 LossPred 0.0929 LossAtt 0.6170 TrainAcc 0.9900 TestAcc 0.8378 0.9300
epoch 900 LossPred 0.1011 LossAtt 0.6120 TrainAcc 0.9700 TestAcc 0.8511 0.9600
epoch 1000 LossPred 0.0639 LossAtt 0.5853 TrainAcc 1.0000 TestAcc 0.8446 0.9700
Optimization Finished!
********** replication  95  **********
epoch   0 LossPred 1.1766 LossAtt 0.9908 TrainAcc 0.4600 TestAcc 0.4855 0.4550
epoch 100 LossPred 0.9069 LossAtt 0.4029 TrainAcc 0.6300 TestAcc 0.5921 0.6300
epoch 200 LossPred 0.8343 LossAtt 0.4178 TrainAcc 0.7100 TestAcc 0.6454 0.7250
epoch 300 LossPred 0.3609 LossAtt 0.4561 TrainAcc 0.9100 TestAcc 0.8651 0.8900
epoch 400 LossPred 0.3080 LossAtt 0.4419 TrainAcc 0.9100 TestAcc 0.8654 0.8800
epoch 500 LossPred 0.2872 LossAtt 0.4323 TrainAcc 0.9200 TestAcc 0.8666 0.8500
epoch 600 LossPred 0.3103 LossAtt 0.4204 TrainAcc 0.9000 TestAcc 0.8631 0.8600
epoch 700 LossPred 0.2304 LossAtt 0.4119 TrainAcc 0.9300 TestAcc 0.8631 0.8600
epoch 800 LossPred 0.3062 LossAtt 0.4034 TrainAcc 0.9000 TestAcc 0.8641 0.8650
epoch 900 LossPred 0.2185 LossAtt 0.4134 TrainAcc 0.9300 TestAcc 0.8561 0.8550
epoch 1000 LossPred 0.2620 LossAtt 0.3790 TrainAcc 0.9200 TestAcc 0.8549 0.8650
epoch 1100 LossPred 0.3443 LossAtt 0.4161 TrainAcc 0.8900 TestAcc 0.8569 0.8550
epoch 1200 LossPred 0.2872 LossAtt 0.3971 TrainAcc 0.9000 TestAcc 0.8666 0.8650
epoch 1300 LossPred 0.3515 LossAtt 0.3881 TrainAcc 0.8700 TestAcc 0.8574 0.8700
epoch 1400 LossPred 0.3874 LossAtt 0.3785 TrainAcc 0.8800 TestAcc 0.8253 0.8050
epoch 1500 LossPred 0.2243 LossAtt 0.3917 TrainAcc 0.9300 TestAcc 0.8744 0.8850
epoch 1600 LossPred 0.2516 LossAtt 0.4100 TrainAcc 0.9200 TestAcc 0.8699 0.8850
epoch 1700 LossPred 0.2068 LossAtt 0.4021 TrainAcc 0.9200 TestAcc 0.8711 0.8800
epoch 1800 LossPred 0.2929 LossAtt 0.4257 TrainAcc 0.9000 TestAcc 0.8689 0.8800
epoch 1900 LossPred 0.2472 LossAtt 0.4442 TrainAcc 0.9200 TestAcc 0.8769 0.8850
epoch 2000 LossPred 0.2561 LossAtt 0.4357 TrainAcc 0.9100 TestAcc 0.8739 0.8750
epoch 2100 LossPred 0.1769 LossAtt 0.4471 TrainAcc 0.9500 TestAcc 0.8634 0.8850
epoch 2200 LossPred 0.1985 LossAtt 0.4675 TrainAcc 0.9400 TestAcc 0.8764 0.9050
epoch 2300 LossPred 0.3807 LossAtt 0.4701 TrainAcc 0.8800 TestAcc 0.8158 0.8250
epoch 2400 LossPred 0.2350 LossAtt 0.4868 TrainAcc 0.9200 TestAcc 0.8456 0.8750
epoch 2500 LossPred 0.2157 LossAtt 0.4932 TrainAcc 0.9400 TestAcc 0.8504 0.8850
Optimization Finished!
********** replication  96  **********
epoch   0 LossPred 1.2236 LossAtt 1.0148 TrainAcc 0.4300 TestAcc 0.3996 0.4350
epoch 100 LossPred 1.0109 LossAtt 0.5806 TrainAcc 0.4700 TestAcc 0.4987 0.4600
epoch 200 LossPred 0.9666 LossAtt 0.5747 TrainAcc 0.5800 TestAcc 0.6016 0.5500
epoch 300 LossPred 0.5657 LossAtt 0.7359 TrainAcc 0.8700 TestAcc 0.8694 0.8300
epoch 400 LossPred 0.4220 LossAtt 0.7060 TrainAcc 0.8800 TestAcc 0.8729 0.8550
epoch 500 LossPred 0.2864 LossAtt 0.6796 TrainAcc 0.9300 TestAcc 0.9127 0.9050
epoch 600 LossPred 0.2382 LossAtt 0.6966 TrainAcc 0.9400 TestAcc 0.9184 0.8900
epoch 700 LossPred 0.2308 LossAtt 0.6329 TrainAcc 0.9500 TestAcc 0.9054 0.9150
epoch 800 LossPred 0.1638 LossAtt 0.5936 TrainAcc 0.9500 TestAcc 0.9244 0.9200
epoch 900 LossPred 0.2095 LossAtt 0.5722 TrainAcc 0.9300 TestAcc 0.8994 0.9100
epoch 1000 LossPred 0.1804 LossAtt 0.5635 TrainAcc 0.9500 TestAcc 0.8984 0.9150
epoch 1100 LossPred 0.1457 LossAtt 0.5393 TrainAcc 0.9700 TestAcc 0.9204 0.9400
epoch 1200 LossPred 0.1333 LossAtt 0.5409 TrainAcc 0.9600 TestAcc 0.9189 0.9500
epoch 1300 LossPred 0.1402 LossAtt 0.5312 TrainAcc 0.9700 TestAcc 0.9149 0.9450
epoch 1400 LossPred 0.1350 LossAtt 0.5219 TrainAcc 0.9700 TestAcc 0.9107 0.9500
epoch 1500 LossPred 0.1286 LossAtt 0.5359 TrainAcc 0.9500 TestAcc 0.9204 0.9550
epoch 1600 LossPred 0.1095 LossAtt 0.5228 TrainAcc 0.9700 TestAcc 0.9269 0.9650
epoch 1700 LossPred 0.1121 LossAtt 0.5282 TrainAcc 0.9800 TestAcc 0.9102 0.9500
epoch 1800 LossPred 0.1007 LossAtt 0.5125 TrainAcc 0.9800 TestAcc 0.9282 0.9750
epoch 1900 LossPred 0.1578 LossAtt 0.4980 TrainAcc 0.9600 TestAcc 0.8861 0.9200
epoch 2000 LossPred 0.1331 LossAtt 0.4976 TrainAcc 0.9600 TestAcc 0.9249 0.9450
epoch 2100 LossPred 0.1031 LossAtt 0.4860 TrainAcc 0.9800 TestAcc 0.9252 0.9650
epoch 2200 LossPred 0.0979 LossAtt 0.4822 TrainAcc 0.9800 TestAcc 0.9264 0.9700
epoch 2300 LossPred 0.1973 LossAtt 0.5001 TrainAcc 0.9300 TestAcc 0.9007 0.9250
epoch 2400 LossPred 0.0935 LossAtt 0.4888 TrainAcc 0.9700 TestAcc 0.9287 0.9700
epoch 2500 LossPred 0.0864 LossAtt 0.5012 TrainAcc 0.9800 TestAcc 0.9384 0.9800
Optimization Finished!
********** replication  97  **********
epoch   0 LossPred 1.0313 LossAtt 1.0090 TrainAcc 0.5200 TestAcc 0.5240 0.5450
epoch 100 LossPred 0.9610 LossAtt 0.3983 TrainAcc 0.5900 TestAcc 0.6051 0.5900
epoch 200 LossPred 0.9530 LossAtt 0.3045 TrainAcc 0.5900 TestAcc 0.6051 0.5900
epoch 300 LossPred 0.9449 LossAtt 0.3867 TrainAcc 0.5900 TestAcc 0.6051 0.5900
epoch 400 LossPred 0.9373 LossAtt 0.4032 TrainAcc 0.6300 TestAcc 0.6181 0.6300
epoch 500 LossPred 0.9203 LossAtt 0.4500 TrainAcc 0.6500 TestAcc 0.6289 0.6450
epoch 600 LossPred 0.4100 LossAtt 0.5301 TrainAcc 0.8900 TestAcc 0.8056 0.8300
epoch 700 LossPred 0.3314 LossAtt 0.5245 TrainAcc 0.9000 TestAcc 0.8031 0.8450
epoch 800 LossPred 0.3125 LossAtt 0.5025 TrainAcc 0.9300 TestAcc 0.8253 0.8750
epoch 900 LossPred 0.2925 LossAtt 0.5143 TrainAcc 0.9400 TestAcc 0.8253 0.8700
epoch 1000 LossPred 0.2732 LossAtt 0.5182 TrainAcc 0.9300 TestAcc 0.8331 0.8750
epoch 1100 LossPred 0.2732 LossAtt 0.5103 TrainAcc 0.9300 TestAcc 0.8363 0.8750
epoch 1200 LossPred 0.2489 LossAtt 0.5042 TrainAcc 0.9400 TestAcc 0.8443 0.8850
epoch 1300 LossPred 0.2396 LossAtt 0.4992 TrainAcc 0.9500 TestAcc 0.8436 0.8750
epoch 1400 LossPred 0.2223 LossAtt 0.5041 TrainAcc 0.9400 TestAcc 0.8421 0.8750
epoch 1500 LossPred 0.2331 LossAtt 0.4754 TrainAcc 0.9400 TestAcc 0.8441 0.8800
epoch 1600 LossPred 0.2096 LossAtt 0.5159 TrainAcc 0.9400 TestAcc 0.8406 0.8750
epoch 1700 LossPred 0.2786 LossAtt 0.4809 TrainAcc 0.9200 TestAcc 0.8436 0.8850
epoch 1800 LossPred 0.2246 LossAtt 0.4941 TrainAcc 0.9400 TestAcc 0.8478 0.8900
epoch 1900 LossPred 0.2035 LossAtt 0.4592 TrainAcc 0.9600 TestAcc 0.8481 0.8950
epoch 2000 LossPred 0.1938 LossAtt 0.4732 TrainAcc 0.9600 TestAcc 0.8448 0.8900
epoch 2100 LossPred 0.1939 LossAtt 0.4744 TrainAcc 0.9600 TestAcc 0.8431 0.8900
epoch 2200 LossPred 0.2240 LossAtt 0.4578 TrainAcc 0.9300 TestAcc 0.8456 0.9100
epoch 2300 LossPred 0.1991 LossAtt 0.4529 TrainAcc 0.9500 TestAcc 0.8526 0.9050
epoch 2400 LossPred 0.2333 LossAtt 0.4878 TrainAcc 0.9100 TestAcc 0.8496 0.9050
epoch 2500 LossPred 0.1871 LossAtt 0.4489 TrainAcc 0.9600 TestAcc 0.8531 0.9050
Optimization Finished!
********** replication  98  **********
epoch   0 LossPred 1.2242 LossAtt 1.0280 TrainAcc 0.3900 TestAcc 0.4637 0.4050
epoch 100 LossPred 0.9237 LossAtt 0.5129 TrainAcc 0.5900 TestAcc 0.5465 0.6050
epoch 200 LossPred 0.8986 LossAtt 0.4150 TrainAcc 0.6500 TestAcc 0.5951 0.6500
epoch 300 LossPred 0.8883 LossAtt 0.3484 TrainAcc 0.6500 TestAcc 0.5951 0.6500
epoch 400 LossPred 0.8863 LossAtt 0.3143 TrainAcc 0.6500 TestAcc 0.5951 0.6500
epoch 500 LossPred 0.8897 LossAtt 0.2254 TrainAcc 0.6500 TestAcc 0.5951 0.6500
epoch 600 LossPred 0.8974 LossAtt 0.2130 TrainAcc 0.6500 TestAcc 0.5951 0.6500
epoch 700 LossPred 0.8993 LossAtt 0.2135 TrainAcc 0.6500 TestAcc 0.5951 0.6500
epoch 800 LossPred 0.8817 LossAtt 0.2566 TrainAcc 0.6500 TestAcc 0.5951 0.6500
epoch 900 LossPred 0.7751 LossAtt 0.4353 TrainAcc 0.7100 TestAcc 0.6599 0.7050
epoch 1000 LossPred 0.2747 LossAtt 0.4253 TrainAcc 0.9300 TestAcc 0.8824 0.8800
epoch 1100 LossPred 0.1939 LossAtt 0.4538 TrainAcc 0.9500 TestAcc 0.8821 0.9050
epoch 1200 LossPred 0.1454 LossAtt 0.4455 TrainAcc 0.9600 TestAcc 0.8866 0.9100
epoch 1300 LossPred 0.1386 LossAtt 0.4527 TrainAcc 0.9600 TestAcc 0.8774 0.9000
epoch 1400 LossPred 0.1290 LossAtt 0.4584 TrainAcc 0.9600 TestAcc 0.8826 0.9000
epoch 1500 LossPred 0.1263 LossAtt 0.4858 TrainAcc 0.9700 TestAcc 0.8901 0.9100
epoch 1600 LossPred 0.1139 LossAtt 0.4957 TrainAcc 0.9700 TestAcc 0.8964 0.9100
epoch 1700 LossPred 0.2614 LossAtt 0.5007 TrainAcc 0.9300 TestAcc 0.8979 0.8850
epoch 1800 LossPred 0.1065 LossAtt 0.5154 TrainAcc 0.9800 TestAcc 0.9014 0.9200
epoch 1900 LossPred 0.1141 LossAtt 0.5231 TrainAcc 0.9700 TestAcc 0.9044 0.9200
epoch 2000 LossPred 0.1173 LossAtt 0.5152 TrainAcc 0.9700 TestAcc 0.9057 0.9300
epoch 2100 LossPred 0.1408 LossAtt 0.5130 TrainAcc 0.9500 TestAcc 0.8841 0.9350
epoch 2200 LossPred 0.0868 LossAtt 0.5215 TrainAcc 0.9900 TestAcc 0.9102 0.9500
epoch 2300 LossPred 0.0649 LossAtt 0.5392 TrainAcc 1.0000 TestAcc 0.9312 0.9600
Optimization Finished!
********** replication  99  **********
epoch   0 LossPred 1.1210 LossAtt 1.0263 TrainAcc 0.4300 TestAcc 0.4517 0.4400
epoch 100 LossPred 0.9178 LossAtt 0.3983 TrainAcc 0.6400 TestAcc 0.6244 0.5950
epoch 200 LossPred 0.5810 LossAtt 0.4370 TrainAcc 0.7700 TestAcc 0.7908 0.7700
epoch 300 LossPred 0.5006 LossAtt 0.3655 TrainAcc 0.8900 TestAcc 0.8276 0.8450
epoch 400 LossPred 0.7157 LossAtt 0.4316 TrainAcc 0.7100 TestAcc 0.7455 0.7200
epoch 500 LossPred 0.4930 LossAtt 0.4064 TrainAcc 0.8400 TestAcc 0.7908 0.8350
epoch 600 LossPred 0.5940 LossAtt 0.4077 TrainAcc 0.7900 TestAcc 0.7830 0.7700
epoch 700 LossPred 0.4489 LossAtt 0.3637 TrainAcc 0.8600 TestAcc 0.8066 0.8450
epoch 800 LossPred 0.3449 LossAtt 0.3586 TrainAcc 0.8900 TestAcc 0.8759 0.8800
epoch 900 LossPred 0.5133 LossAtt 0.3556 TrainAcc 0.8100 TestAcc 0.8123 0.7700
epoch 1000 LossPred 0.3009 LossAtt 0.3489 TrainAcc 0.9200 TestAcc 0.8739 0.9000
epoch 1100 LossPred 0.3042 LossAtt 0.3497 TrainAcc 0.9200 TestAcc 0.8829 0.8850
epoch 1200 LossPred 0.3046 LossAtt 0.3313 TrainAcc 0.9200 TestAcc 0.8664 0.8850
epoch 1300 LossPred 0.2746 LossAtt 0.3472 TrainAcc 0.9200 TestAcc 0.8844 0.9050
epoch 1400 LossPred 0.3428 LossAtt 0.3244 TrainAcc 0.9000 TestAcc 0.8421 0.8600
epoch 1500 LossPred 0.5586 LossAtt 0.3448 TrainAcc 0.8100 TestAcc 0.7520 0.8150
epoch 1600 LossPred 0.4292 LossAtt 0.3311 TrainAcc 0.8500 TestAcc 0.8006 0.8400
epoch 1700 LossPred 0.3433 LossAtt 0.3448 TrainAcc 0.8900 TestAcc 0.8679 0.8800
epoch 1800 LossPred 0.6441 LossAtt 0.3315 TrainAcc 0.7600 TestAcc 0.7080 0.7850
epoch 1900 LossPred 0.4661 LossAtt 0.3135 TrainAcc 0.8500 TestAcc 0.7878 0.8400
epoch 2000 LossPred 0.3785 LossAtt 0.3317 TrainAcc 0.9000 TestAcc 0.8273 0.8700
epoch 2100 LossPred 0.4289 LossAtt 0.3237 TrainAcc 0.8500 TestAcc 0.8096 0.8350
epoch 2200 LossPred 0.4596 LossAtt 0.3128 TrainAcc 0.8300 TestAcc 0.7968 0.8250
epoch 2300 LossPred 0.4832 LossAtt 0.3252 TrainAcc 0.8300 TestAcc 0.8061 0.8100
epoch 2400 LossPred 0.4942 LossAtt 0.3306 TrainAcc 0.8100 TestAcc 0.8131 0.8150
epoch 2500 LossPred 0.3714 LossAtt 0.3166 TrainAcc 0.8800 TestAcc 0.8311 0.8700
Optimization Finished!
********************************************************************
Namespace(arch='tanh', batch_size=256, display_epoch=100, input_noise_level=0.15, latent_attractor_space=True, loss_switch_frequency=0, lrate_attractor=0.002, lrate_prediction=0.002, lrate_wt_penalty=0.0, n_attractor_hidden=10, n_attractor_steps=5, n_hidden=5, n_replications=100, noise_level=0.25, report_best_train_performance=True, seq_len=20, task='majority', train_attr_weights_on_prediction=False, training_epochs=2500)
********************************************************************
mean train accuracy 0.93820006
indiv runs  [0.98, 1.0, 0.75, 0.94, 0.94, 0.92, 0.96, 0.9, 0.97, 0.96, 0.95, 0.95, 0.97, 0.84, 0.96, 0.98, 0.94, 0.98, 0.95, 0.99, 0.98, 0.95, 1.0, 0.82, 0.98, 0.92, 0.92, 1.0, 0.92, 0.98, 0.97, 0.94, 0.96, 0.97, 0.99, 0.95, 1.0, 0.96, 0.94, 0.98, 0.94, 0.95, 0.94, 0.96, 0.9, 0.96, 0.66, 0.94, 0.98, 0.91, 0.9, 0.83, 0.85, 0.63, 0.9, 0.84, 0.99, 0.97, 0.9, 0.98, 0.82, 0.97, 0.98, 0.99, 0.99, 0.97, 0.86, 0.98, 0.95, 0.95, 0.97, 0.98, 0.91, 0.93, 0.8, 0.99, 0.8, 0.96, 0.97, 1.0, 0.95, 0.93, 0.93, 0.98, 0.93, 0.97, 0.98, 0.94, 0.93, 0.96, 0.97, 0.93, 0.97, 0.98, 1.0, 0.95, 0.98, 0.96, 1.0, 0.92]
mean epoch 1915.28571429
indiv epochs  [2201, 2201, 1601, 1901, 2201, 1001, 2301]
test1 accuracy mean  0.8524149  median  0.8734985
test2 accuracy mean  0.8988999  median  0.915
test1 indiv runs  [0.8656156, 0.9264264, 0.4874875, 0.8941441, 0.8253253, 0.8008008, 0.7937938, 0.8816316, 0.9131632, 0.9349349, 0.8896396, 0.8623624, 0.8383383, 0.8193193, 0.9039039, 0.9224224, 0.8743744, 0.9089089, 0.8601101, 0.9054054, 0.8623624, 0.9101602, 0.950951, 0.5930931, 0.9219219, 0.6836837, 0.8268268, 0.8833834, 0.8668669, 0.8248248, 0.8498498, 0.8918919, 0.8423423, 0.9104104, 0.9249249, 0.9016517, 0.9476977, 0.8563564, 0.9006507, 0.8883884, 0.8871371, 0.8681181, 0.9064064, 0.9121622, 0.7967968, 0.9574575, 0.5878378, 0.8508509, 0.8906406, 0.8648649, 0.8233233, 0.6476476, 0.8285786, 0.5740741, 0.8475976, 0.7372372, 0.8873874, 0.9341842, 0.8601101, 0.8986486, 0.6769269, 0.8918919, 0.9316817, 0.8773774, 0.9081582, 0.9336837, 0.8255756, 0.9364364, 0.8726226, 0.8240741, 0.8478478, 0.8848849, 0.7134635, 0.8428428, 0.6146146, 0.8846346, 0.6366366, 0.8293293, 0.9104104, 0.9344344, 0.9034034, 0.8896396, 0.8731231, 0.9164164, 0.8098098, 0.9216717, 0.8898899, 0.8435936, 0.8185686, 0.8578579, 0.8618619, 0.8663664, 0.9004004, 0.9326827, 0.8445946, 0.8633634, 0.9101602, 0.8480981, 0.9311812, 0.8738739]
test2 indiv runs  [0.88, 0.94, 0.68, 0.905, 0.86, 0.85, 0.905, 0.86, 0.92, 0.93, 0.9, 0.875, 0.92, 0.805, 0.955, 0.97, 0.935, 0.925, 0.895, 0.955, 0.96, 0.88, 0.995, 0.73, 0.94, 0.87, 0.845, 0.985, 0.845, 0.955, 0.93, 0.875, 0.9, 0.92, 0.97, 0.935, 0.97, 0.89, 0.915, 0.955, 0.885, 0.915, 0.89, 0.955, 0.88, 0.92, 0.655, 0.905, 0.88, 0.89, 0.825, 0.825, 0.81, 0.64, 0.87, 0.83, 0.975, 0.955, 0.88, 0.965, 0.8, 0.915, 0.93, 0.98, 0.97, 0.93, 0.83, 0.96, 0.9, 0.915, 0.94, 0.95, 0.87, 0.815, 0.75, 0.97, 0.74, 0.895, 0.95, 0.915, 0.895, 0.89, 0.895, 0.94, 0.92, 0.95, 0.93, 0.91, 0.925, 0.92, 0.93, 0.915, 0.945, 0.96, 0.97, 0.885, 0.95, 0.895, 0.96, 0.9]
