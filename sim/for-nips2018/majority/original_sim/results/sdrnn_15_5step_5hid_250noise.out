Namespace(arch='tanh', batch_size=256, display_epoch=100, input_noise_level=0.15, latent_attractor_space=True, loss_switch_frequency=0, lrate_attractor=0.002, lrate_prediction=0.002, lrate_wt_penalty=0.0, n_attractor_hidden=10, n_attractor_steps=5, n_hidden=5, n_replications=100, noise_level=0.25, report_best_train_performance=True, seq_len=15, task='majority', train_attr_weights_on_prediction=False, training_epochs=2500)
TRAINING ON 100 EXAMPLES, TESTING ON 3996
********** replication  0  **********
epoch   0 LossPred 1.0637 LossAtt 1.0438 TrainAcc 0.5100 TestAcc 0.5305 0.5000
epoch 100 LossPred 0.9481 LossAtt 0.5412 TrainAcc 0.6100 TestAcc 0.5498 0.6050
epoch 200 LossPred 0.9331 LossAtt 0.4787 TrainAcc 0.6100 TestAcc 0.5463 0.6300
epoch 300 LossPred 0.8983 LossAtt 0.4944 TrainAcc 0.6300 TestAcc 0.5808 0.6200
epoch 400 LossPred 0.4672 LossAtt 0.4940 TrainAcc 0.8500 TestAcc 0.8121 0.8400
epoch 500 LossPred 0.4141 LossAtt 0.4404 TrainAcc 0.8600 TestAcc 0.8228 0.8400
epoch 600 LossPred 0.3968 LossAtt 0.4438 TrainAcc 0.8600 TestAcc 0.8226 0.8350
epoch 700 LossPred 0.3921 LossAtt 0.4531 TrainAcc 0.8600 TestAcc 0.8183 0.8350
epoch 800 LossPred 0.3936 LossAtt 0.4508 TrainAcc 0.8500 TestAcc 0.8296 0.8450
epoch 900 LossPred 0.3795 LossAtt 0.4314 TrainAcc 0.8600 TestAcc 0.8218 0.8550
epoch 1000 LossPred 0.4183 LossAtt 0.4323 TrainAcc 0.8300 TestAcc 0.8391 0.8400
epoch 1100 LossPred 0.3824 LossAtt 0.4347 TrainAcc 0.8500 TestAcc 0.8298 0.8450
epoch 1200 LossPred 0.3885 LossAtt 0.4490 TrainAcc 0.8500 TestAcc 0.8371 0.8450
epoch 1300 LossPred 0.3578 LossAtt 0.4491 TrainAcc 0.8600 TestAcc 0.8288 0.8450
epoch 1400 LossPred 0.3720 LossAtt 0.4802 TrainAcc 0.8600 TestAcc 0.8438 0.8550
epoch 1500 LossPred 0.3518 LossAtt 0.4469 TrainAcc 0.8600 TestAcc 0.8366 0.8500
epoch 1600 LossPred 0.3268 LossAtt 0.4630 TrainAcc 0.8700 TestAcc 0.8326 0.8500
epoch 1700 LossPred 0.3606 LossAtt 0.4483 TrainAcc 0.8700 TestAcc 0.8303 0.8600
epoch 1800 LossPred 0.3335 LossAtt 0.4593 TrainAcc 0.8700 TestAcc 0.8486 0.8700
epoch 1900 LossPred 0.3233 LossAtt 0.4767 TrainAcc 0.8700 TestAcc 0.8418 0.8650
epoch 2000 LossPred 0.3155 LossAtt 0.4565 TrainAcc 0.8800 TestAcc 0.8426 0.8700
epoch 2100 LossPred 0.3398 LossAtt 0.4528 TrainAcc 0.8900 TestAcc 0.8546 0.8800
epoch 2200 LossPred 0.3249 LossAtt 0.4646 TrainAcc 0.8700 TestAcc 0.8504 0.8800
epoch 2300 LossPred 0.3186 LossAtt 0.4563 TrainAcc 0.8800 TestAcc 0.8423 0.8700
epoch 2400 LossPred 0.2825 LossAtt 0.4325 TrainAcc 0.9100 TestAcc 0.8604 0.8850
epoch 2500 LossPred 0.3027 LossAtt 0.4260 TrainAcc 0.9100 TestAcc 0.8666 0.8850
Optimization Finished!
********** replication  1  **********
epoch   0 LossPred 1.4913 LossAtt 1.0239 TrainAcc 0.3800 TestAcc 0.4474 0.3800
epoch 100 LossPred 1.0663 LossAtt 0.3931 TrainAcc 0.4300 TestAcc 0.4907 0.4350
epoch 200 LossPred 0.8670 LossAtt 0.2741 TrainAcc 0.7100 TestAcc 0.6074 0.7100
epoch 300 LossPred 0.8442 LossAtt 0.1897 TrainAcc 0.7100 TestAcc 0.6074 0.7100
epoch 400 LossPred 0.8352 LossAtt 0.2064 TrainAcc 0.7100 TestAcc 0.6074 0.7100
epoch 500 LossPred 0.8016 LossAtt 0.3038 TrainAcc 0.7100 TestAcc 0.6074 0.6950
epoch 600 LossPred 0.7744 LossAtt 0.4996 TrainAcc 0.7400 TestAcc 0.6211 0.7000
epoch 700 LossPred 0.7290 LossAtt 0.6527 TrainAcc 0.7100 TestAcc 0.7072 0.6900
epoch 800 LossPred 0.3081 LossAtt 0.6397 TrainAcc 0.9100 TestAcc 0.8589 0.8750
epoch 900 LossPred 0.2763 LossAtt 0.6368 TrainAcc 0.9100 TestAcc 0.8621 0.8850
epoch 1000 LossPred 0.2516 LossAtt 0.5966 TrainAcc 0.9200 TestAcc 0.8599 0.8850
epoch 1100 LossPred 0.2785 LossAtt 0.6159 TrainAcc 0.8900 TestAcc 0.8629 0.8750
epoch 1200 LossPred 0.2530 LossAtt 0.5809 TrainAcc 0.9200 TestAcc 0.8556 0.8900
epoch 1300 LossPred 0.2583 LossAtt 0.5687 TrainAcc 0.9200 TestAcc 0.8551 0.8750
epoch 1400 LossPred 0.2215 LossAtt 0.5830 TrainAcc 0.9300 TestAcc 0.8569 0.8900
epoch 1500 LossPred 0.2153 LossAtt 0.5900 TrainAcc 0.9400 TestAcc 0.8511 0.8900
epoch 1600 LossPred 0.2209 LossAtt 0.5863 TrainAcc 0.9300 TestAcc 0.8589 0.9000
epoch 1700 LossPred 0.2140 LossAtt 0.5986 TrainAcc 0.9300 TestAcc 0.8463 0.8900
epoch 1800 LossPred 0.2170 LossAtt 0.6145 TrainAcc 0.9300 TestAcc 0.8524 0.9000
epoch 1900 LossPred 0.2117 LossAtt 0.6025 TrainAcc 0.9400 TestAcc 0.8631 0.8950
epoch 2000 LossPred 0.2017 LossAtt 0.5966 TrainAcc 0.9300 TestAcc 0.8561 0.8850
epoch 2100 LossPred 0.2033 LossAtt 0.6152 TrainAcc 0.9400 TestAcc 0.8661 0.9000
epoch 2200 LossPred 0.2249 LossAtt 0.6373 TrainAcc 0.9100 TestAcc 0.8481 0.8900
epoch 2300 LossPred 0.2051 LossAtt 0.6270 TrainAcc 0.9200 TestAcc 0.8654 0.9050
epoch 2400 LossPred 0.1921 LossAtt 0.6200 TrainAcc 0.9400 TestAcc 0.8614 0.9000
epoch 2500 LossPred 0.1886 LossAtt 0.5862 TrainAcc 0.9400 TestAcc 0.8604 0.8850
Optimization Finished!
********** replication  2  **********
epoch   0 LossPred 1.1972 LossAtt 1.0318 TrainAcc 0.4000 TestAcc 0.3951 0.4100
epoch 100 LossPred 0.9907 LossAtt 0.3501 TrainAcc 0.5500 TestAcc 0.4957 0.5500
epoch 200 LossPred 0.9670 LossAtt 0.3287 TrainAcc 0.5800 TestAcc 0.5563 0.5750
epoch 300 LossPred 0.9583 LossAtt 0.3399 TrainAcc 0.6000 TestAcc 0.6049 0.6050
epoch 400 LossPred 0.9557 LossAtt 0.3790 TrainAcc 0.5700 TestAcc 0.6054 0.6000
epoch 500 LossPred 0.9539 LossAtt 0.3982 TrainAcc 0.6000 TestAcc 0.6076 0.6050
epoch 600 LossPred 0.9502 LossAtt 0.4064 TrainAcc 0.6000 TestAcc 0.6086 0.6100
epoch 700 LossPred 0.9126 LossAtt 0.5325 TrainAcc 0.6500 TestAcc 0.6024 0.6300
epoch 800 LossPred 0.8767 LossAtt 0.4692 TrainAcc 0.6700 TestAcc 0.5846 0.6400
epoch 900 LossPred 0.8293 LossAtt 0.4762 TrainAcc 0.6700 TestAcc 0.5823 0.6400
epoch 1000 LossPred 0.7266 LossAtt 0.5476 TrainAcc 0.7400 TestAcc 0.6284 0.6700
epoch 1100 LossPred 0.6125 LossAtt 0.5204 TrainAcc 0.8300 TestAcc 0.6939 0.7650
epoch 1200 LossPred 0.4966 LossAtt 0.4979 TrainAcc 0.8300 TestAcc 0.7520 0.8150
epoch 1300 LossPred 0.4272 LossAtt 0.4399 TrainAcc 0.8700 TestAcc 0.8048 0.8500
epoch 1400 LossPred 0.4001 LossAtt 0.3976 TrainAcc 0.8800 TestAcc 0.8056 0.8500
epoch 1500 LossPred 0.3652 LossAtt 0.3872 TrainAcc 0.9000 TestAcc 0.8011 0.8600
epoch 1600 LossPred 0.3430 LossAtt 0.3767 TrainAcc 0.9100 TestAcc 0.8291 0.8550
epoch 1700 LossPred 0.3473 LossAtt 0.3760 TrainAcc 0.9100 TestAcc 0.8028 0.8700
epoch 1800 LossPred 0.3376 LossAtt 0.3845 TrainAcc 0.9100 TestAcc 0.8203 0.8700
epoch 1900 LossPred 0.3326 LossAtt 0.3692 TrainAcc 0.9100 TestAcc 0.8083 0.8650
epoch 2000 LossPred 0.3075 LossAtt 0.4100 TrainAcc 0.9200 TestAcc 0.8056 0.8700
epoch 2100 LossPred 0.3220 LossAtt 0.4008 TrainAcc 0.8900 TestAcc 0.8251 0.8750
epoch 2200 LossPred 0.2925 LossAtt 0.4047 TrainAcc 0.9000 TestAcc 0.8286 0.8650
epoch 2300 LossPred 0.2866 LossAtt 0.3908 TrainAcc 0.9200 TestAcc 0.8178 0.8850
epoch 2400 LossPred 0.2870 LossAtt 0.4002 TrainAcc 0.9100 TestAcc 0.8353 0.8700
epoch 2500 LossPred 0.2859 LossAtt 0.3686 TrainAcc 0.9200 TestAcc 0.8276 0.8750
Optimization Finished!
********** replication  3  **********
epoch   0 LossPred 1.1285 LossAtt 1.0234 TrainAcc 0.3800 TestAcc 0.3999 0.4250
epoch 100 LossPred 0.9398 LossAtt 0.3693 TrainAcc 0.6200 TestAcc 0.6001 0.6200
epoch 200 LossPred 0.5542 LossAtt 0.4623 TrainAcc 0.8900 TestAcc 0.8293 0.8900
epoch 300 LossPred 0.3780 LossAtt 0.4408 TrainAcc 0.9100 TestAcc 0.8471 0.9050
epoch 400 LossPred 0.3237 LossAtt 0.4132 TrainAcc 0.9200 TestAcc 0.8478 0.9000
epoch 500 LossPred 0.2960 LossAtt 0.4202 TrainAcc 0.9100 TestAcc 0.8403 0.8850
epoch 600 LossPred 0.2721 LossAtt 0.4043 TrainAcc 0.9200 TestAcc 0.8353 0.8850
epoch 700 LossPred 0.2656 LossAtt 0.3953 TrainAcc 0.9200 TestAcc 0.8378 0.8900
epoch 800 LossPred 0.2529 LossAtt 0.3954 TrainAcc 0.9200 TestAcc 0.8353 0.8850
epoch 900 LossPred 0.2712 LossAtt 0.3823 TrainAcc 0.9200 TestAcc 0.8418 0.8900
epoch 1000 LossPred 0.2457 LossAtt 0.4234 TrainAcc 0.9300 TestAcc 0.8363 0.9000
epoch 1100 LossPred 0.2464 LossAtt 0.4061 TrainAcc 0.9200 TestAcc 0.8363 0.9050
epoch 1200 LossPred 0.2354 LossAtt 0.4131 TrainAcc 0.9200 TestAcc 0.8401 0.9100
epoch 1300 LossPred 0.2154 LossAtt 0.4187 TrainAcc 0.9300 TestAcc 0.8423 0.9050
epoch 1400 LossPred 0.1960 LossAtt 0.4200 TrainAcc 0.9300 TestAcc 0.8446 0.9300
epoch 1500 LossPred 0.2149 LossAtt 0.4146 TrainAcc 0.9400 TestAcc 0.8373 0.9250
epoch 1600 LossPred 0.2360 LossAtt 0.4239 TrainAcc 0.9200 TestAcc 0.8376 0.9050
epoch 1700 LossPred 0.1920 LossAtt 0.4146 TrainAcc 0.9400 TestAcc 0.8476 0.9250
epoch 1800 LossPred 0.2503 LossAtt 0.4129 TrainAcc 0.9200 TestAcc 0.8411 0.9250
epoch 1900 LossPred 0.1977 LossAtt 0.4009 TrainAcc 0.9400 TestAcc 0.8448 0.9300
epoch 2000 LossPred 0.2108 LossAtt 0.4109 TrainAcc 0.9400 TestAcc 0.8451 0.9300
epoch 2100 LossPred 0.2295 LossAtt 0.4165 TrainAcc 0.9200 TestAcc 0.8398 0.9000
epoch 2200 LossPred 0.1828 LossAtt 0.4132 TrainAcc 0.9400 TestAcc 0.8486 0.9350
epoch 2300 LossPred 0.2070 LossAtt 0.4247 TrainAcc 0.9400 TestAcc 0.8476 0.9350
epoch 2400 LossPred 0.2056 LossAtt 0.4355 TrainAcc 0.9400 TestAcc 0.8539 0.9250
epoch 2500 LossPred 0.1766 LossAtt 0.4082 TrainAcc 0.9500 TestAcc 0.8546 0.9300
Optimization Finished!
********** replication  4  **********
epoch   0 LossPred 1.1347 LossAtt 1.0170 TrainAcc 0.5600 TestAcc 0.4274 0.5550
epoch 100 LossPred 0.9804 LossAtt 0.5267 TrainAcc 0.5800 TestAcc 0.4875 0.5900
epoch 200 LossPred 0.9696 LossAtt 0.4168 TrainAcc 0.5900 TestAcc 0.5175 0.5950
epoch 300 LossPred 0.9673 LossAtt 0.3486 TrainAcc 0.5800 TestAcc 0.4847 0.5950
epoch 400 LossPred 0.9614 LossAtt 0.2953 TrainAcc 0.5900 TestAcc 0.5175 0.5900
epoch 500 LossPred 0.9584 LossAtt 0.2544 TrainAcc 0.5900 TestAcc 0.5175 0.5900
epoch 600 LossPred 0.9585 LossAtt 0.2814 TrainAcc 0.5900 TestAcc 0.5175 0.5900
epoch 700 LossPred 0.9564 LossAtt 0.3162 TrainAcc 0.5900 TestAcc 0.5175 0.5900
epoch 800 LossPred 0.9547 LossAtt 0.3423 TrainAcc 0.5900 TestAcc 0.5175 0.5900
epoch 900 LossPred 0.9536 LossAtt 0.3385 TrainAcc 0.5900 TestAcc 0.5175 0.5900
epoch 1000 LossPred 0.9533 LossAtt 0.2507 TrainAcc 0.5900 TestAcc 0.5175 0.5900
epoch 1100 LossPred 0.9533 LossAtt 0.2171 TrainAcc 0.5900 TestAcc 0.5175 0.5900
epoch 1200 LossPred 0.9533 LossAtt 0.1781 TrainAcc 0.5900 TestAcc 0.5175 0.5900
epoch 1300 LossPred 0.9533 LossAtt 0.1520 TrainAcc 0.5900 TestAcc 0.5175 0.5900
epoch 1400 LossPred 0.9535 LossAtt 0.1111 TrainAcc 0.5900 TestAcc 0.5175 0.5900
epoch 1500 LossPred 0.9535 LossAtt 0.1049 TrainAcc 0.5900 TestAcc 0.5175 0.5900
epoch 1600 LossPred 0.9537 LossAtt 0.0673 TrainAcc 0.5900 TestAcc 0.5175 0.5900
epoch 1700 LossPred 0.9540 LossAtt 0.0734 TrainAcc 0.5900 TestAcc 0.5175 0.5900
epoch 1800 LossPred 0.9538 LossAtt 0.0687 TrainAcc 0.5900 TestAcc 0.5175 0.5900
epoch 1900 LossPred 0.9700 LossAtt 0.1875 TrainAcc 0.5500 TestAcc 0.5981 0.5650
epoch 2000 LossPred 0.9387 LossAtt 0.5214 TrainAcc 0.6200 TestAcc 0.5868 0.6200
epoch 2100 LossPred 0.7483 LossAtt 0.6564 TrainAcc 0.7900 TestAcc 0.7680 0.7300
epoch 2200 LossPred 0.4569 LossAtt 0.6220 TrainAcc 0.8600 TestAcc 0.8654 0.8400
epoch 2300 LossPred 0.3208 LossAtt 0.6191 TrainAcc 0.9200 TestAcc 0.8719 0.8750
epoch 2400 LossPred 0.2918 LossAtt 0.5465 TrainAcc 0.9300 TestAcc 0.8511 0.9000
epoch 2500 LossPred 0.2880 LossAtt 0.5187 TrainAcc 0.9300 TestAcc 0.8443 0.8950
Optimization Finished!
********** replication  5  **********
epoch   0 LossPred 1.1030 LossAtt 1.0093 TrainAcc 0.5300 TestAcc 0.5661 0.5400
epoch 100 LossPred 0.9477 LossAtt 0.4569 TrainAcc 0.5700 TestAcc 0.6094 0.5800
epoch 200 LossPred 0.8469 LossAtt 0.5771 TrainAcc 0.6600 TestAcc 0.6689 0.6600
epoch 300 LossPred 0.2777 LossAtt 0.5961 TrainAcc 0.9500 TestAcc 0.8826 0.9250
epoch 400 LossPred 0.1727 LossAtt 0.5835 TrainAcc 0.9700 TestAcc 0.8766 0.9300
epoch 500 LossPred 0.1257 LossAtt 0.6170 TrainAcc 0.9800 TestAcc 0.8866 0.9350
epoch 600 LossPred 0.0942 LossAtt 0.6182 TrainAcc 0.9800 TestAcc 0.8911 0.9350
epoch 700 LossPred 0.0751 LossAtt 0.6355 TrainAcc 0.9800 TestAcc 0.8949 0.9350
epoch 800 LossPred 0.0972 LossAtt 0.6043 TrainAcc 0.9600 TestAcc 0.8901 0.9400
epoch 900 LossPred 0.0802 LossAtt 0.6345 TrainAcc 0.9800 TestAcc 0.9032 0.9400
epoch 1000 LossPred 0.0699 LossAtt 0.5965 TrainAcc 0.9800 TestAcc 0.8974 0.9450
epoch 1100 LossPred 0.0462 LossAtt 0.6143 TrainAcc 0.9900 TestAcc 0.9014 0.9400
epoch 1200 LossPred 0.0462 LossAtt 0.6305 TrainAcc 0.9900 TestAcc 0.8981 0.9450
epoch 1300 LossPred 0.0676 LossAtt 0.6021 TrainAcc 0.9900 TestAcc 0.9034 0.9400
epoch 1400 LossPred 0.0394 LossAtt 0.5781 TrainAcc 0.9900 TestAcc 0.8984 0.9450
epoch 1500 LossPred 0.0385 LossAtt 0.5945 TrainAcc 0.9900 TestAcc 0.8914 0.9450
epoch 1600 LossPred 0.0334 LossAtt 0.5833 TrainAcc 0.9900 TestAcc 0.8991 0.9500
epoch 1700 LossPred 0.0264 LossAtt 0.5659 TrainAcc 0.9900 TestAcc 0.8949 0.9400
epoch 1800 LossPred 0.0181 LossAtt 0.5773 TrainAcc 1.0000 TestAcc 0.8959 0.9450
Optimization Finished!
********** replication  6  **********
epoch   0 LossPred 1.1017 LossAtt 1.0103 TrainAcc 0.4100 TestAcc 0.4697 0.4150
epoch 100 LossPred 0.8497 LossAtt 0.6001 TrainAcc 0.7100 TestAcc 0.6069 0.7100
epoch 200 LossPred 0.7465 LossAtt 0.5552 TrainAcc 0.7300 TestAcc 0.6319 0.7300
epoch 300 LossPred 0.6305 LossAtt 0.5639 TrainAcc 0.8000 TestAcc 0.7357 0.7950
epoch 400 LossPred 0.2923 LossAtt 0.6100 TrainAcc 0.9300 TestAcc 0.8796 0.8750
epoch 500 LossPred 0.2546 LossAtt 0.6142 TrainAcc 0.9300 TestAcc 0.8819 0.8900
epoch 600 LossPred 0.2207 LossAtt 0.6255 TrainAcc 0.9500 TestAcc 0.8919 0.9000
epoch 700 LossPred 0.2352 LossAtt 0.6326 TrainAcc 0.9200 TestAcc 0.8824 0.9050
epoch 800 LossPred 0.2083 LossAtt 0.6079 TrainAcc 0.9300 TestAcc 0.8796 0.9000
epoch 900 LossPred 0.1863 LossAtt 0.6092 TrainAcc 0.9500 TestAcc 0.8944 0.9100
epoch 1000 LossPred 0.1724 LossAtt 0.6166 TrainAcc 0.9400 TestAcc 0.8931 0.9150
epoch 1100 LossPred 0.1644 LossAtt 0.6225 TrainAcc 0.9600 TestAcc 0.9007 0.9250
epoch 1200 LossPred 0.1451 LossAtt 0.6354 TrainAcc 0.9600 TestAcc 0.8964 0.9200
epoch 1300 LossPred 0.1395 LossAtt 0.6426 TrainAcc 0.9600 TestAcc 0.8974 0.9250
epoch 1400 LossPred 0.2150 LossAtt 0.6294 TrainAcc 0.9100 TestAcc 0.8676 0.8650
epoch 1500 LossPred 0.1401 LossAtt 0.6617 TrainAcc 0.9400 TestAcc 0.8941 0.9150
epoch 1600 LossPred 0.1236 LossAtt 0.6732 TrainAcc 0.9600 TestAcc 0.8929 0.9200
epoch 1700 LossPred 0.1223 LossAtt 0.6670 TrainAcc 0.9700 TestAcc 0.8906 0.9250
epoch 1800 LossPred 0.0938 LossAtt 0.6804 TrainAcc 0.9700 TestAcc 0.8876 0.9350
epoch 1900 LossPred 0.0825 LossAtt 0.6761 TrainAcc 0.9900 TestAcc 0.8786 0.9250
epoch 2000 LossPred 0.1187 LossAtt 0.6554 TrainAcc 0.9600 TestAcc 0.8714 0.9200
epoch 2100 LossPred 0.0653 LossAtt 0.6699 TrainAcc 0.9900 TestAcc 0.8891 0.9400
epoch 2200 LossPred 0.0793 LossAtt 0.6777 TrainAcc 0.9800 TestAcc 0.8836 0.9350
epoch 2300 LossPred 0.0713 LossAtt 0.6622 TrainAcc 1.0000 TestAcc 0.8789 0.9100
Optimization Finished!
********** replication  7  **********
epoch   0 LossPred 1.0656 LossAtt 1.0209 TrainAcc 0.5100 TestAcc 0.5756 0.5100
epoch 100 LossPred 0.8654 LossAtt 0.6629 TrainAcc 0.7100 TestAcc 0.6281 0.7000
epoch 200 LossPred 0.6882 LossAtt 0.7194 TrainAcc 0.7500 TestAcc 0.6912 0.7350
epoch 300 LossPred 0.3424 LossAtt 0.7711 TrainAcc 0.8800 TestAcc 0.8351 0.8500
epoch 400 LossPred 0.2696 LossAtt 0.7442 TrainAcc 0.9200 TestAcc 0.8506 0.8600
epoch 500 LossPred 0.2255 LossAtt 0.7630 TrainAcc 0.9400 TestAcc 0.8526 0.8650
epoch 600 LossPred 0.1978 LossAtt 0.7079 TrainAcc 0.9500 TestAcc 0.8491 0.8550
epoch 700 LossPred 0.1917 LossAtt 0.7064 TrainAcc 0.9400 TestAcc 0.8328 0.8750
epoch 800 LossPred 0.1779 LossAtt 0.7392 TrainAcc 0.9500 TestAcc 0.8586 0.9150
epoch 900 LossPred 0.2047 LossAtt 0.7371 TrainAcc 0.9200 TestAcc 0.8531 0.8800
epoch 1000 LossPred 0.1219 LossAtt 0.7172 TrainAcc 0.9700 TestAcc 0.8854 0.9100
epoch 1100 LossPred 0.1107 LossAtt 0.7054 TrainAcc 0.9700 TestAcc 0.8789 0.9250
epoch 1200 LossPred 0.1121 LossAtt 0.6780 TrainAcc 0.9800 TestAcc 0.8869 0.9350
epoch 1300 LossPred 0.1007 LossAtt 0.6426 TrainAcc 0.9800 TestAcc 0.8774 0.9200
epoch 1400 LossPred 0.1201 LossAtt 0.6523 TrainAcc 0.9700 TestAcc 0.8606 0.9150
epoch 1500 LossPred 0.0985 LossAtt 0.6681 TrainAcc 0.9800 TestAcc 0.8831 0.9350
epoch 1600 LossPred 0.0912 LossAtt 0.6552 TrainAcc 0.9800 TestAcc 0.8846 0.9300
epoch 1700 LossPred 0.0874 LossAtt 0.6653 TrainAcc 0.9700 TestAcc 0.8836 0.9300
epoch 1800 LossPred 0.0976 LossAtt 0.6331 TrainAcc 0.9800 TestAcc 0.8681 0.9100
epoch 1900 LossPred 0.0830 LossAtt 0.6517 TrainAcc 0.9700 TestAcc 0.8841 0.9400
epoch 2000 LossPred 0.1155 LossAtt 0.6436 TrainAcc 0.9700 TestAcc 0.8954 0.9200
epoch 2100 LossPred 0.0846 LossAtt 0.6344 TrainAcc 0.9800 TestAcc 0.8861 0.9300
epoch 2200 LossPred 0.0706 LossAtt 0.6632 TrainAcc 0.9800 TestAcc 0.8941 0.9300
epoch 2300 LossPred 0.0791 LossAtt 0.6736 TrainAcc 0.9900 TestAcc 0.9099 0.9200
epoch 2400 LossPred 0.0683 LossAtt 0.6642 TrainAcc 0.9900 TestAcc 0.8891 0.9200
epoch 2500 LossPred 0.0615 LossAtt 0.6446 TrainAcc 0.9900 TestAcc 0.9082 0.9350
Optimization Finished!
********** replication  8  **********
epoch   0 LossPred 1.0834 LossAtt 1.0548 TrainAcc 0.5300 TestAcc 0.4937 0.5300
epoch 100 LossPred 0.9484 LossAtt 0.5676 TrainAcc 0.6300 TestAcc 0.5483 0.6200
epoch 200 LossPred 0.9167 LossAtt 0.5587 TrainAcc 0.6300 TestAcc 0.5483 0.6300
epoch 300 LossPred 0.4130 LossAtt 0.6811 TrainAcc 0.9000 TestAcc 0.8336 0.8650
epoch 400 LossPred 0.2864 LossAtt 0.6536 TrainAcc 0.9100 TestAcc 0.8431 0.9000
epoch 500 LossPred 0.2099 LossAtt 0.6668 TrainAcc 0.9200 TestAcc 0.8423 0.9300
epoch 600 LossPred 0.1775 LossAtt 0.6604 TrainAcc 0.9400 TestAcc 0.8514 0.9300
epoch 700 LossPred 0.1717 LossAtt 0.6514 TrainAcc 0.9200 TestAcc 0.8524 0.9050
epoch 800 LossPred 0.1776 LossAtt 0.6639 TrainAcc 0.9400 TestAcc 0.8609 0.9050
epoch 900 LossPred 0.1510 LossAtt 0.5623 TrainAcc 0.9500 TestAcc 0.8519 0.9450
epoch 1000 LossPred 0.1221 LossAtt 0.5612 TrainAcc 0.9800 TestAcc 0.8691 0.9400
epoch 1100 LossPred 0.1187 LossAtt 0.5234 TrainAcc 0.9700 TestAcc 0.8646 0.9550
epoch 1200 LossPred 0.1314 LossAtt 0.5486 TrainAcc 0.9800 TestAcc 0.8611 0.9500
epoch 1300 LossPred 0.1010 LossAtt 0.5636 TrainAcc 0.9700 TestAcc 0.8701 0.9350
epoch 1400 LossPred 0.0979 LossAtt 0.5390 TrainAcc 0.9700 TestAcc 0.8691 0.9500
epoch 1500 LossPred 0.0906 LossAtt 0.5588 TrainAcc 0.9800 TestAcc 0.8724 0.9400
epoch 1600 LossPred 0.1458 LossAtt 0.5492 TrainAcc 0.9600 TestAcc 0.8631 0.9250
epoch 1700 LossPred 0.0822 LossAtt 0.5463 TrainAcc 0.9800 TestAcc 0.8836 0.9500
epoch 1800 LossPred 0.0888 LossAtt 0.5346 TrainAcc 0.9700 TestAcc 0.8759 0.9350
epoch 1900 LossPred 0.2830 LossAtt 0.5588 TrainAcc 0.9200 TestAcc 0.8326 0.8900
epoch 2000 LossPred 0.0786 LossAtt 0.5764 TrainAcc 0.9800 TestAcc 0.8819 0.9500
epoch 2100 LossPred 0.0751 LossAtt 0.5711 TrainAcc 0.9700 TestAcc 0.8781 0.9500
epoch 2200 LossPred 0.0469 LossAtt 0.5526 TrainAcc 0.9900 TestAcc 0.8814 0.9450
epoch 2300 LossPred 0.0628 LossAtt 0.5482 TrainAcc 0.9700 TestAcc 0.8774 0.9500
epoch 2400 LossPred 0.1656 LossAtt 0.5871 TrainAcc 0.9600 TestAcc 0.8551 0.8900
epoch 2500 LossPred 0.1394 LossAtt 0.5803 TrainAcc 0.9600 TestAcc 0.8564 0.9100
Optimization Finished!
********** replication  9  **********
epoch   0 LossPred 0.9661 LossAtt 1.0115 TrainAcc 0.5500 TestAcc 0.5508 0.5450
epoch 100 LossPred 0.8364 LossAtt 0.5474 TrainAcc 0.6300 TestAcc 0.6016 0.6450
epoch 200 LossPred 0.6820 LossAtt 0.5632 TrainAcc 0.7400 TestAcc 0.6964 0.7200
epoch 300 LossPred 0.2640 LossAtt 0.5733 TrainAcc 0.9400 TestAcc 0.8754 0.9000
epoch 400 LossPred 0.3278 LossAtt 0.5492 TrainAcc 0.8800 TestAcc 0.8283 0.8750
epoch 500 LossPred 0.2095 LossAtt 0.5469 TrainAcc 0.9300 TestAcc 0.8996 0.9150
epoch 600 LossPred 0.3298 LossAtt 0.5605 TrainAcc 0.9000 TestAcc 0.8063 0.8600
epoch 700 LossPred 0.3532 LossAtt 0.5319 TrainAcc 0.8700 TestAcc 0.8068 0.8500
epoch 800 LossPred 0.3102 LossAtt 0.5135 TrainAcc 0.9000 TestAcc 0.8128 0.8750
epoch 900 LossPred 0.2590 LossAtt 0.5614 TrainAcc 0.9000 TestAcc 0.9052 0.8950
epoch 1000 LossPred 0.1871 LossAtt 0.5391 TrainAcc 0.9200 TestAcc 0.9037 0.9300
epoch 1100 LossPred 0.1839 LossAtt 0.5473 TrainAcc 0.9300 TestAcc 0.8939 0.9300
epoch 1200 LossPred 0.2100 LossAtt 0.5563 TrainAcc 0.9100 TestAcc 0.9119 0.9200
epoch 1300 LossPred 0.3478 LossAtt 0.5679 TrainAcc 0.8800 TestAcc 0.8981 0.8600
epoch 1400 LossPred 0.1783 LossAtt 0.5636 TrainAcc 0.9300 TestAcc 0.8751 0.9150
epoch 1500 LossPred 0.1955 LossAtt 0.5468 TrainAcc 0.9300 TestAcc 0.8531 0.9150
epoch 1600 LossPred 0.1629 LossAtt 0.5806 TrainAcc 0.9400 TestAcc 0.8951 0.9450
epoch 1700 LossPred 0.1686 LossAtt 0.5704 TrainAcc 0.9400 TestAcc 0.8969 0.9500
epoch 1800 LossPred 0.1544 LossAtt 0.5527 TrainAcc 0.9500 TestAcc 0.8864 0.9400
epoch 1900 LossPred 0.1590 LossAtt 0.5768 TrainAcc 0.9500 TestAcc 0.9009 0.9500
epoch 2000 LossPred 0.1463 LossAtt 0.5630 TrainAcc 0.9500 TestAcc 0.8876 0.9450
epoch 2100 LossPred 0.1694 LossAtt 0.5653 TrainAcc 0.9300 TestAcc 0.9034 0.9450
epoch 2200 LossPred 0.1665 LossAtt 0.5787 TrainAcc 0.9300 TestAcc 0.8659 0.9300
epoch 2300 LossPred 0.1632 LossAtt 0.5541 TrainAcc 0.9600 TestAcc 0.8704 0.9250
epoch 2400 LossPred 0.1710 LossAtt 0.5382 TrainAcc 0.9400 TestAcc 0.8986 0.9450
epoch 2500 LossPred 0.1553 LossAtt 0.5461 TrainAcc 0.9500 TestAcc 0.8674 0.9150
Optimization Finished!
********** replication  10  **********
epoch   0 LossPred 1.0659 LossAtt 1.0548 TrainAcc 0.5500 TestAcc 0.6049 0.5500
epoch 100 LossPred 0.8126 LossAtt 0.7174 TrainAcc 0.6500 TestAcc 0.6644 0.6550
epoch 200 LossPred 0.4579 LossAtt 0.6826 TrainAcc 0.8900 TestAcc 0.8651 0.8550
epoch 300 LossPred 0.3567 LossAtt 0.6704 TrainAcc 0.9000 TestAcc 0.8906 0.8850
epoch 400 LossPred 0.2549 LossAtt 0.6866 TrainAcc 0.9400 TestAcc 0.9372 0.8750
epoch 500 LossPred 0.2120 LossAtt 0.7073 TrainAcc 0.9600 TestAcc 0.9389 0.9100
epoch 600 LossPred 0.2076 LossAtt 0.7018 TrainAcc 0.9400 TestAcc 0.9357 0.9100
epoch 700 LossPred 0.1747 LossAtt 0.6311 TrainAcc 0.9600 TestAcc 0.9372 0.9300
epoch 800 LossPred 0.1410 LossAtt 0.5682 TrainAcc 0.9800 TestAcc 0.9507 0.9500
epoch 900 LossPred 0.1378 LossAtt 0.5522 TrainAcc 0.9700 TestAcc 0.9520 0.9650
epoch 1000 LossPred 0.1319 LossAtt 0.5489 TrainAcc 0.9800 TestAcc 0.9364 0.9600
epoch 1100 LossPred 0.0935 LossAtt 0.5453 TrainAcc 1.0000 TestAcc 0.9537 0.9800
Optimization Finished!
********** replication  11  **********
epoch   0 LossPred 1.4109 LossAtt 1.0252 TrainAcc 0.4300 TestAcc 0.4955 0.4150
epoch 100 LossPred 1.0047 LossAtt 0.5738 TrainAcc 0.5900 TestAcc 0.5803 0.5150
epoch 200 LossPred 0.8448 LossAtt 0.6177 TrainAcc 0.7000 TestAcc 0.6609 0.6800
epoch 300 LossPred 0.3619 LossAtt 0.5693 TrainAcc 0.9500 TestAcc 0.8939 0.9100
epoch 400 LossPred 0.2455 LossAtt 0.5792 TrainAcc 0.9600 TestAcc 0.9047 0.9350
epoch 500 LossPred 0.1850 LossAtt 0.5636 TrainAcc 0.9900 TestAcc 0.9219 0.9500
epoch 600 LossPred 0.1125 LossAtt 0.5475 TrainAcc 1.0000 TestAcc 0.9164 0.9300
Optimization Finished!
********** replication  12  **********
epoch   0 LossPred 1.0170 LossAtt 1.0171 TrainAcc 0.6300 TestAcc 0.5313 0.6000
epoch 100 LossPred 0.8922 LossAtt 0.6092 TrainAcc 0.6500 TestAcc 0.5410 0.6450
epoch 200 LossPred 0.8691 LossAtt 0.6367 TrainAcc 0.6500 TestAcc 0.5453 0.6750
epoch 300 LossPred 0.8396 LossAtt 0.6823 TrainAcc 0.6900 TestAcc 0.5463 0.6450
epoch 400 LossPred 0.8070 LossAtt 0.6346 TrainAcc 0.6900 TestAcc 0.5398 0.6850
epoch 500 LossPred 0.7772 LossAtt 0.6159 TrainAcc 0.7200 TestAcc 0.5546 0.7100
epoch 600 LossPred 0.7549 LossAtt 0.5729 TrainAcc 0.7200 TestAcc 0.5566 0.7100
epoch 700 LossPred 0.7340 LossAtt 0.5534 TrainAcc 0.7500 TestAcc 0.5921 0.7300
epoch 800 LossPred 0.7241 LossAtt 0.5566 TrainAcc 0.7500 TestAcc 0.5881 0.7350
epoch 900 LossPred 0.7141 LossAtt 0.5277 TrainAcc 0.7500 TestAcc 0.5891 0.7400
epoch 1000 LossPred 0.7150 LossAtt 0.4828 TrainAcc 0.7500 TestAcc 0.5946 0.7500
epoch 1100 LossPred 0.6935 LossAtt 0.4614 TrainAcc 0.7700 TestAcc 0.5973 0.7350
epoch 1200 LossPred 0.6901 LossAtt 0.4828 TrainAcc 0.7500 TestAcc 0.6001 0.7350
epoch 1300 LossPred 0.6832 LossAtt 0.4773 TrainAcc 0.7800 TestAcc 0.6064 0.7300
epoch 1400 LossPred 0.6903 LossAtt 0.4857 TrainAcc 0.7700 TestAcc 0.5998 0.7400
epoch 1500 LossPred 0.6878 LossAtt 0.4701 TrainAcc 0.7700 TestAcc 0.6014 0.7400
epoch 1600 LossPred 0.6792 LossAtt 0.4957 TrainAcc 0.7800 TestAcc 0.5996 0.7250
epoch 1700 LossPred 0.6864 LossAtt 0.4869 TrainAcc 0.7700 TestAcc 0.5991 0.7350
epoch 1800 LossPred 0.6815 LossAtt 0.4687 TrainAcc 0.7800 TestAcc 0.5991 0.7450
epoch 1900 LossPred 0.6760 LossAtt 0.4748 TrainAcc 0.7800 TestAcc 0.5996 0.7400
epoch 2000 LossPred 0.6726 LossAtt 0.4686 TrainAcc 0.7800 TestAcc 0.6009 0.7300
epoch 2100 LossPred 0.6880 LossAtt 0.4789 TrainAcc 0.7400 TestAcc 0.5941 0.7400
epoch 2200 LossPred 0.6932 LossAtt 0.4716 TrainAcc 0.7400 TestAcc 0.5913 0.7400
epoch 2300 LossPred 0.6651 LossAtt 0.4607 TrainAcc 0.7600 TestAcc 0.5958 0.7500
epoch 2400 LossPred 0.6801 LossAtt 0.4691 TrainAcc 0.7800 TestAcc 0.5918 0.7350
epoch 2500 LossPred 0.6766 LossAtt 0.4305 TrainAcc 0.7500 TestAcc 0.5923 0.7350
Optimization Finished!
********** replication  13  **********
epoch   0 LossPred 1.1058 LossAtt 1.0459 TrainAcc 0.5000 TestAcc 0.5480 0.4950
epoch 100 LossPred 0.9532 LossAtt 0.4894 TrainAcc 0.5700 TestAcc 0.6119 0.5650
epoch 200 LossPred 0.7485 LossAtt 0.6264 TrainAcc 0.7700 TestAcc 0.7200 0.7700
epoch 300 LossPred 0.4438 LossAtt 0.5074 TrainAcc 0.8700 TestAcc 0.8729 0.8350
epoch 400 LossPred 0.3865 LossAtt 0.5451 TrainAcc 0.8900 TestAcc 0.8674 0.8600
epoch 500 LossPred 0.2865 LossAtt 0.5446 TrainAcc 0.9200 TestAcc 0.8781 0.8850
epoch 600 LossPred 0.2555 LossAtt 0.5404 TrainAcc 0.9200 TestAcc 0.8604 0.8650
epoch 700 LossPred 0.2196 LossAtt 0.5315 TrainAcc 0.9400 TestAcc 0.8696 0.9050
epoch 800 LossPred 0.3981 LossAtt 0.5018 TrainAcc 0.8400 TestAcc 0.8443 0.8500
epoch 900 LossPred 0.3931 LossAtt 0.4758 TrainAcc 0.8600 TestAcc 0.8123 0.8300
epoch 1000 LossPred 0.2981 LossAtt 0.4520 TrainAcc 0.8900 TestAcc 0.8581 0.8750
epoch 1100 LossPred 0.2451 LossAtt 0.4113 TrainAcc 0.9100 TestAcc 0.8496 0.8800
epoch 1200 LossPred 0.2671 LossAtt 0.4071 TrainAcc 0.8900 TestAcc 0.8689 0.8900
epoch 1300 LossPred 0.2342 LossAtt 0.4097 TrainAcc 0.9100 TestAcc 0.8619 0.9050
epoch 1400 LossPred 0.1960 LossAtt 0.4110 TrainAcc 0.9300 TestAcc 0.8659 0.9100
epoch 1500 LossPred 0.2332 LossAtt 0.4016 TrainAcc 0.9100 TestAcc 0.8498 0.8800
epoch 1600 LossPred 0.2075 LossAtt 0.4053 TrainAcc 0.9200 TestAcc 0.8809 0.9100
epoch 1700 LossPred 0.2505 LossAtt 0.4012 TrainAcc 0.9100 TestAcc 0.8516 0.9000
epoch 1800 LossPred 0.2660 LossAtt 0.4175 TrainAcc 0.9100 TestAcc 0.8526 0.8800
epoch 1900 LossPred 0.1769 LossAtt 0.3923 TrainAcc 0.9400 TestAcc 0.8724 0.9300
epoch 2000 LossPred 0.2000 LossAtt 0.4059 TrainAcc 0.9400 TestAcc 0.8674 0.9150
epoch 2100 LossPred 0.1787 LossAtt 0.3868 TrainAcc 0.9400 TestAcc 0.8771 0.9300
epoch 2200 LossPred 0.1838 LossAtt 0.3973 TrainAcc 0.9300 TestAcc 0.8849 0.9350
epoch 2300 LossPred 0.2098 LossAtt 0.4061 TrainAcc 0.9200 TestAcc 0.8724 0.9250
epoch 2400 LossPred 0.1921 LossAtt 0.3840 TrainAcc 0.9200 TestAcc 0.8711 0.9100
epoch 2500 LossPred 0.1665 LossAtt 0.3773 TrainAcc 0.9500 TestAcc 0.8789 0.9250
Optimization Finished!
********** replication  14  **********
epoch   0 LossPred 1.1899 LossAtt 1.0335 TrainAcc 0.4800 TestAcc 0.5143 0.4850
epoch 100 LossPred 0.7581 LossAtt 0.5303 TrainAcc 0.7400 TestAcc 0.5936 0.7400
epoch 200 LossPred 0.7247 LossAtt 0.4776 TrainAcc 0.7400 TestAcc 0.5936 0.7400
epoch 300 LossPred 0.6659 LossAtt 0.5834 TrainAcc 0.7400 TestAcc 0.6229 0.7550
epoch 400 LossPred 0.2783 LossAtt 0.6255 TrainAcc 0.9400 TestAcc 0.9062 0.9300
epoch 500 LossPred 0.2581 LossAtt 0.5508 TrainAcc 0.9300 TestAcc 0.8654 0.9350
epoch 600 LossPred 0.1748 LossAtt 0.5409 TrainAcc 0.9600 TestAcc 0.9137 0.9550
epoch 700 LossPred 0.1596 LossAtt 0.5263 TrainAcc 0.9700 TestAcc 0.9159 0.9650
epoch 800 LossPred 0.1619 LossAtt 0.5101 TrainAcc 0.9600 TestAcc 0.9089 0.9550
epoch 900 LossPred 0.2679 LossAtt 0.4997 TrainAcc 0.9100 TestAcc 0.8754 0.9000
epoch 1000 LossPred 0.1996 LossAtt 0.5238 TrainAcc 0.9300 TestAcc 0.8846 0.9400
epoch 1100 LossPred 0.1451 LossAtt 0.4958 TrainAcc 0.9500 TestAcc 0.9149 0.9550
epoch 1200 LossPred 0.2417 LossAtt 0.4553 TrainAcc 0.9200 TestAcc 0.8819 0.9050
epoch 1300 LossPred 0.1505 LossAtt 0.4474 TrainAcc 0.9600 TestAcc 0.9164 0.9500
epoch 1400 LossPred 0.1230 LossAtt 0.4411 TrainAcc 0.9700 TestAcc 0.9254 0.9500
epoch 1500 LossPred 0.1839 LossAtt 0.4176 TrainAcc 0.9500 TestAcc 0.8966 0.9250
epoch 1600 LossPred 0.1098 LossAtt 0.4308 TrainAcc 0.9700 TestAcc 0.9209 0.9550
epoch 1700 LossPred 0.1535 LossAtt 0.4103 TrainAcc 0.9500 TestAcc 0.8991 0.9450
epoch 1800 LossPred 0.1010 LossAtt 0.4001 TrainAcc 0.9800 TestAcc 0.9222 0.9600
epoch 1900 LossPred 0.1352 LossAtt 0.4140 TrainAcc 0.9700 TestAcc 0.9174 0.9400
epoch 2000 LossPred 0.1002 LossAtt 0.4169 TrainAcc 0.9800 TestAcc 0.9229 0.9700
epoch 2100 LossPred 0.0970 LossAtt 0.3978 TrainAcc 0.9800 TestAcc 0.9242 0.9700
epoch 2200 LossPred 0.1306 LossAtt 0.4087 TrainAcc 0.9600 TestAcc 0.9159 0.9450
epoch 2300 LossPred 0.1059 LossAtt 0.4053 TrainAcc 0.9800 TestAcc 0.9297 0.9400
epoch 2400 LossPred 0.0951 LossAtt 0.4148 TrainAcc 0.9800 TestAcc 0.9262 0.9700
epoch 2500 LossPred 0.0841 LossAtt 0.3997 TrainAcc 0.9800 TestAcc 0.9319 0.9750
Optimization Finished!
********** replication  15  **********
epoch   0 LossPred 0.9908 LossAtt 1.0759 TrainAcc 0.6000 TestAcc 0.5703 0.5650
epoch 100 LossPred 0.9155 LossAtt 0.5584 TrainAcc 0.5900 TestAcc 0.6206 0.6000
epoch 200 LossPred 0.4060 LossAtt 0.6039 TrainAcc 0.8600 TestAcc 0.8028 0.8950
epoch 300 LossPred 0.1816 LossAtt 0.5758 TrainAcc 0.9500 TestAcc 0.9282 0.9200
epoch 400 LossPred 0.1537 LossAtt 0.5836 TrainAcc 0.9700 TestAcc 0.9399 0.9250
epoch 500 LossPred 0.1511 LossAtt 0.5655 TrainAcc 0.9500 TestAcc 0.9014 0.9350
epoch 600 LossPred 0.1644 LossAtt 0.5793 TrainAcc 0.9500 TestAcc 0.8851 0.9350
epoch 700 LossPred 0.1319 LossAtt 0.5888 TrainAcc 0.9800 TestAcc 0.9337 0.9400
epoch 800 LossPred 0.1579 LossAtt 0.5700 TrainAcc 0.9300 TestAcc 0.9287 0.9500
epoch 900 LossPred 0.0974 LossAtt 0.5530 TrainAcc 0.9800 TestAcc 0.9349 0.9550
epoch 1000 LossPred 0.1063 LossAtt 0.5377 TrainAcc 0.9600 TestAcc 0.9099 0.9450
epoch 1100 LossPred 0.0854 LossAtt 0.5215 TrainAcc 0.9900 TestAcc 0.9357 0.9500
epoch 1200 LossPred 0.1313 LossAtt 0.5205 TrainAcc 0.9600 TestAcc 0.9292 0.9400
epoch 1300 LossPred 0.0975 LossAtt 0.5114 TrainAcc 0.9700 TestAcc 0.9062 0.9500
epoch 1400 LossPred 0.0823 LossAtt 0.5140 TrainAcc 0.9800 TestAcc 0.9202 0.9400
epoch 1500 LossPred 0.0797 LossAtt 0.5067 TrainAcc 0.9800 TestAcc 0.9167 0.9450
epoch 1600 LossPred 0.1161 LossAtt 0.4866 TrainAcc 0.9600 TestAcc 0.8859 0.9300
epoch 1700 LossPred 0.1005 LossAtt 0.5004 TrainAcc 0.9800 TestAcc 0.8911 0.9500
epoch 1800 LossPred 0.1075 LossAtt 0.4969 TrainAcc 0.9600 TestAcc 0.8866 0.9300
epoch 1900 LossPred 0.0891 LossAtt 0.4763 TrainAcc 0.9800 TestAcc 0.8989 0.9350
epoch 2000 LossPred 0.0742 LossAtt 0.4407 TrainAcc 0.9800 TestAcc 0.9044 0.9450
epoch 2100 LossPred 0.1156 LossAtt 0.4275 TrainAcc 0.9600 TestAcc 0.8849 0.9300
epoch 2200 LossPred 0.1857 LossAtt 0.4263 TrainAcc 0.9300 TestAcc 0.9122 0.9350
epoch 2300 LossPred 0.0649 LossAtt 0.4265 TrainAcc 0.9900 TestAcc 0.9067 0.9550
epoch 2400 LossPred 0.1091 LossAtt 0.4166 TrainAcc 0.9700 TestAcc 0.8724 0.9300
epoch 2500 LossPred 0.0648 LossAtt 0.4192 TrainAcc 0.9800 TestAcc 0.9007 0.9450
Optimization Finished!
********** replication  16  **********
epoch   0 LossPred 0.9924 LossAtt 1.0294 TrainAcc 0.5200 TestAcc 0.5218 0.5450
epoch 100 LossPred 0.9293 LossAtt 0.4732 TrainAcc 0.6200 TestAcc 0.6114 0.6200
epoch 200 LossPred 0.9002 LossAtt 0.4114 TrainAcc 0.6300 TestAcc 0.6336 0.6300
epoch 300 LossPred 0.4552 LossAtt 0.4896 TrainAcc 0.8900 TestAcc 0.8681 0.8900
epoch 400 LossPred 0.3197 LossAtt 0.4716 TrainAcc 0.9000 TestAcc 0.9042 0.8750
epoch 500 LossPred 0.2352 LossAtt 0.5102 TrainAcc 0.9300 TestAcc 0.9059 0.8950
epoch 600 LossPred 0.1903 LossAtt 0.5056 TrainAcc 0.9600 TestAcc 0.8974 0.8750
epoch 700 LossPred 0.1929 LossAtt 0.5143 TrainAcc 0.9300 TestAcc 0.9199 0.9000
epoch 800 LossPred 0.1663 LossAtt 0.4941 TrainAcc 0.9600 TestAcc 0.9034 0.8800
epoch 900 LossPred 0.1509 LossAtt 0.5010 TrainAcc 0.9500 TestAcc 0.9307 0.8900
epoch 1000 LossPred 0.1442 LossAtt 0.5042 TrainAcc 0.9600 TestAcc 0.9279 0.8850
epoch 1100 LossPred 0.1495 LossAtt 0.5116 TrainAcc 0.9600 TestAcc 0.9369 0.8900
epoch 1200 LossPred 0.1288 LossAtt 0.4821 TrainAcc 0.9700 TestAcc 0.9264 0.9050
epoch 1300 LossPred 0.1231 LossAtt 0.5149 TrainAcc 0.9700 TestAcc 0.9259 0.9050
epoch 1400 LossPred 0.1219 LossAtt 0.4921 TrainAcc 0.9600 TestAcc 0.9277 0.9000
epoch 1500 LossPred 0.1312 LossAtt 0.5007 TrainAcc 0.9500 TestAcc 0.9077 0.9100
epoch 1600 LossPred 0.1450 LossAtt 0.5014 TrainAcc 0.9400 TestAcc 0.8949 0.8950
epoch 1700 LossPred 0.2091 LossAtt 0.5021 TrainAcc 0.9200 TestAcc 0.8721 0.8700
epoch 1800 LossPred 0.1165 LossAtt 0.5309 TrainAcc 0.9700 TestAcc 0.9172 0.9150
epoch 1900 LossPred 0.1312 LossAtt 0.5434 TrainAcc 0.9700 TestAcc 0.9087 0.8900
epoch 2000 LossPred 0.1081 LossAtt 0.5841 TrainAcc 0.9700 TestAcc 0.9249 0.9100
epoch 2100 LossPred 0.1042 LossAtt 0.6038 TrainAcc 0.9800 TestAcc 0.9344 0.9100
epoch 2200 LossPred 0.1231 LossAtt 0.6203 TrainAcc 0.9700 TestAcc 0.9329 0.9150
epoch 2300 LossPred 0.1684 LossAtt 0.6315 TrainAcc 0.9400 TestAcc 0.9257 0.9100
epoch 2400 LossPred 0.0913 LossAtt 0.6255 TrainAcc 0.9800 TestAcc 0.9207 0.9200
epoch 2500 LossPred 0.1592 LossAtt 0.5972 TrainAcc 0.9300 TestAcc 0.8919 0.9100
Optimization Finished!
********** replication  17  **********
epoch   0 LossPred 1.3429 LossAtt 1.0277 TrainAcc 0.5000 TestAcc 0.5868 0.4600
epoch 100 LossPred 1.0040 LossAtt 0.6781 TrainAcc 0.5200 TestAcc 0.6116 0.5200
epoch 200 LossPred 0.3552 LossAtt 0.7385 TrainAcc 0.9700 TestAcc 0.9179 0.9400
epoch 300 LossPred 0.2036 LossAtt 0.7171 TrainAcc 0.9800 TestAcc 0.9204 0.9450
epoch 400 LossPred 0.1414 LossAtt 0.6764 TrainAcc 0.9800 TestAcc 0.9232 0.9550
epoch 500 LossPred 0.1022 LossAtt 0.6190 TrainAcc 0.9800 TestAcc 0.9212 0.9750
epoch 600 LossPred 0.0826 LossAtt 0.6536 TrainAcc 0.9800 TestAcc 0.9012 0.9700
epoch 700 LossPred 0.0638 LossAtt 0.5878 TrainAcc 0.9900 TestAcc 0.9142 0.9800
epoch 800 LossPred 0.0563 LossAtt 0.5595 TrainAcc 0.9900 TestAcc 0.9192 0.9750
epoch 900 LossPred 0.9634 LossAtt 0.6868 TrainAcc 0.7300 TestAcc 0.6804 0.7300
epoch 1000 LossPred 0.3544 LossAtt 0.6330 TrainAcc 0.8800 TestAcc 0.8183 0.8700
epoch 1100 LossPred 0.4084 LossAtt 0.6612 TrainAcc 0.8500 TestAcc 0.8471 0.8600
epoch 1200 LossPred 0.1608 LossAtt 0.6177 TrainAcc 0.9400 TestAcc 0.8846 0.9150
epoch 1300 LossPred 0.0814 LossAtt 0.5688 TrainAcc 0.9900 TestAcc 0.9397 0.9700
epoch 1400 LossPred 0.0859 LossAtt 0.5478 TrainAcc 0.9800 TestAcc 0.9472 0.9650
epoch 1500 LossPred 0.0923 LossAtt 0.4663 TrainAcc 0.9700 TestAcc 0.9379 0.9750
epoch 1600 LossPred 0.0828 LossAtt 0.4793 TrainAcc 0.9800 TestAcc 0.9312 0.9750
epoch 1700 LossPred 0.0761 LossAtt 0.4418 TrainAcc 0.9900 TestAcc 0.9357 0.9800
epoch 1800 LossPred 0.0580 LossAtt 0.4541 TrainAcc 0.9800 TestAcc 0.9359 0.9850
epoch 1900 LossPred 0.0545 LossAtt 0.4349 TrainAcc 0.9800 TestAcc 0.9377 0.9700
epoch 2000 LossPred 0.0445 LossAtt 0.4282 TrainAcc 0.9900 TestAcc 0.9337 0.9750
epoch 2100 LossPred 0.0385 LossAtt 0.4087 TrainAcc 0.9900 TestAcc 0.9364 0.9800
epoch 2200 LossPred 0.0276 LossAtt 0.4112 TrainAcc 1.0000 TestAcc 0.9279 0.9750
Optimization Finished!
********** replication  18  **********
epoch   0 LossPred 1.3176 LossAtt 1.0130 TrainAcc 0.4500 TestAcc 0.5400 0.4650
epoch 100 LossPred 0.9852 LossAtt 0.5737 TrainAcc 0.5600 TestAcc 0.6061 0.5600
epoch 200 LossPred 0.9082 LossAtt 0.5019 TrainAcc 0.6500 TestAcc 0.5813 0.6750
epoch 300 LossPred 0.8808 LossAtt 0.4436 TrainAcc 0.6700 TestAcc 0.5968 0.6700
epoch 400 LossPred 0.8612 LossAtt 0.4316 TrainAcc 0.6700 TestAcc 0.5968 0.6600
epoch 500 LossPred 0.8450 LossAtt 0.4443 TrainAcc 0.6700 TestAcc 0.5968 0.6500
epoch 600 LossPred 0.7712 LossAtt 0.5458 TrainAcc 0.6900 TestAcc 0.6374 0.6850
epoch 700 LossPred 0.1848 LossAtt 0.5306 TrainAcc 0.9400 TestAcc 0.9109 0.9450
epoch 800 LossPred 0.1825 LossAtt 0.4762 TrainAcc 0.9700 TestAcc 0.9032 0.9250
epoch 900 LossPred 0.1777 LossAtt 0.4841 TrainAcc 0.9300 TestAcc 0.9024 0.9150
epoch 1000 LossPred 0.1317 LossAtt 0.4295 TrainAcc 0.9800 TestAcc 0.8949 0.9150
epoch 1100 LossPred 0.1252 LossAtt 0.4198 TrainAcc 0.9800 TestAcc 0.8996 0.9300
epoch 1200 LossPred 0.1162 LossAtt 0.4080 TrainAcc 0.9700 TestAcc 0.8924 0.9400
epoch 1300 LossPred 0.1160 LossAtt 0.4142 TrainAcc 0.9600 TestAcc 0.9134 0.9300
epoch 1400 LossPred 0.1056 LossAtt 0.4685 TrainAcc 0.9800 TestAcc 0.9209 0.9350
epoch 1500 LossPred 0.0935 LossAtt 0.4345 TrainAcc 0.9800 TestAcc 0.9287 0.9400
epoch 1600 LossPred 0.0909 LossAtt 0.4481 TrainAcc 0.9900 TestAcc 0.9147 0.9500
epoch 1700 LossPred 0.1086 LossAtt 0.4567 TrainAcc 0.9500 TestAcc 0.9134 0.9450
epoch 1800 LossPred 0.0886 LossAtt 0.4536 TrainAcc 0.9800 TestAcc 0.9309 0.9500
epoch 1900 LossPred 0.0741 LossAtt 0.4668 TrainAcc 0.9900 TestAcc 0.9334 0.9500
epoch 2000 LossPred 0.0734 LossAtt 0.4948 TrainAcc 0.9900 TestAcc 0.9232 0.9650
epoch 2100 LossPred 0.0626 LossAtt 0.5079 TrainAcc 0.9900 TestAcc 0.9409 0.9650
epoch 2200 LossPred 0.0479 LossAtt 0.4945 TrainAcc 0.9900 TestAcc 0.9552 0.9600
epoch 2300 LossPred 0.0894 LossAtt 0.4678 TrainAcc 0.9700 TestAcc 0.9259 0.9650
epoch 2400 LossPred 0.0660 LossAtt 0.4740 TrainAcc 0.9900 TestAcc 0.9249 0.9700
epoch 2500 LossPred 0.0323 LossAtt 0.4780 TrainAcc 1.0000 TestAcc 0.9615 0.9800
Optimization Finished!
********** replication  19  **********
epoch   0 LossPred 1.0122 LossAtt 1.0102 TrainAcc 0.4800 TestAcc 0.5295 0.4900
epoch 100 LossPred 0.8931 LossAtt 0.5947 TrainAcc 0.6600 TestAcc 0.6384 0.6450
epoch 200 LossPred 0.3501 LossAtt 0.6874 TrainAcc 0.9500 TestAcc 0.8956 0.9000
epoch 300 LossPred 0.2568 LossAtt 0.6594 TrainAcc 0.9400 TestAcc 0.8976 0.8850
epoch 400 LossPred 0.1780 LossAtt 0.6003 TrainAcc 0.9400 TestAcc 0.8879 0.9300
epoch 500 LossPred 0.1430 LossAtt 0.5298 TrainAcc 0.9700 TestAcc 0.9174 0.9600
epoch 600 LossPred 0.1330 LossAtt 0.4387 TrainAcc 0.9700 TestAcc 0.9217 0.9650
epoch 700 LossPred 0.1511 LossAtt 0.3691 TrainAcc 0.9600 TestAcc 0.9237 0.9650
epoch 800 LossPred 0.1164 LossAtt 0.3641 TrainAcc 0.9600 TestAcc 0.9194 0.9550
epoch 900 LossPred 0.1568 LossAtt 0.3535 TrainAcc 0.9400 TestAcc 0.8961 0.9400
epoch 1000 LossPred 0.1166 LossAtt 0.3495 TrainAcc 0.9600 TestAcc 0.9097 0.9450
epoch 1100 LossPred 0.1115 LossAtt 0.3563 TrainAcc 0.9700 TestAcc 0.9174 0.9450
epoch 1200 LossPred 0.1151 LossAtt 0.3464 TrainAcc 0.9600 TestAcc 0.9124 0.9400
epoch 1300 LossPred 0.1205 LossAtt 0.3659 TrainAcc 0.9700 TestAcc 0.9262 0.9550
epoch 1400 LossPred 0.1027 LossAtt 0.3505 TrainAcc 0.9700 TestAcc 0.9212 0.9600
epoch 1500 LossPred 0.0943 LossAtt 0.3707 TrainAcc 0.9800 TestAcc 0.9429 0.9650
epoch 1600 LossPred 0.1176 LossAtt 0.3613 TrainAcc 0.9600 TestAcc 0.9049 0.9450
epoch 1700 LossPred 0.0987 LossAtt 0.3763 TrainAcc 0.9700 TestAcc 0.9212 0.9550
epoch 1800 LossPred 0.0847 LossAtt 0.3398 TrainAcc 0.9800 TestAcc 0.9482 0.9650
epoch 1900 LossPred 0.2196 LossAtt 0.3324 TrainAcc 0.9300 TestAcc 0.8974 0.9350
epoch 2000 LossPred 0.0812 LossAtt 0.3417 TrainAcc 0.9700 TestAcc 0.9274 0.9650
epoch 2100 LossPred 0.1066 LossAtt 0.3362 TrainAcc 0.9600 TestAcc 0.9022 0.9500
epoch 2200 LossPred 0.0983 LossAtt 0.3469 TrainAcc 0.9700 TestAcc 0.9117 0.9550
epoch 2300 LossPred 0.1024 LossAtt 0.3281 TrainAcc 0.9600 TestAcc 0.9409 0.9650
epoch 2400 LossPred 0.0792 LossAtt 0.3149 TrainAcc 0.9800 TestAcc 0.9449 0.9650
epoch 2500 LossPred 0.1053 LossAtt 0.3282 TrainAcc 0.9700 TestAcc 0.9169 0.9500
Optimization Finished!
********** replication  20  **********
epoch   0 LossPred 1.0595 LossAtt 1.0322 TrainAcc 0.5500 TestAcc 0.5608 0.5500
epoch 100 LossPred 0.8635 LossAtt 0.5722 TrainAcc 0.6600 TestAcc 0.6459 0.6600
epoch 200 LossPred 0.4734 LossAtt 0.5622 TrainAcc 0.8900 TestAcc 0.8734 0.8450
epoch 300 LossPred 0.3450 LossAtt 0.5287 TrainAcc 0.9300 TestAcc 0.9032 0.8800
epoch 400 LossPred 0.3409 LossAtt 0.4469 TrainAcc 0.9200 TestAcc 0.9004 0.8800
epoch 500 LossPred 0.4334 LossAtt 0.4652 TrainAcc 0.8500 TestAcc 0.8493 0.8550
epoch 600 LossPred 0.3719 LossAtt 0.4858 TrainAcc 0.9100 TestAcc 0.8634 0.8800
epoch 700 LossPred 0.4388 LossAtt 0.4935 TrainAcc 0.8500 TestAcc 0.8326 0.8350
epoch 800 LossPred 0.4326 LossAtt 0.4916 TrainAcc 0.8300 TestAcc 0.8308 0.8350
epoch 900 LossPred 0.3645 LossAtt 0.4454 TrainAcc 0.9000 TestAcc 0.8551 0.8750
epoch 1000 LossPred 0.4624 LossAtt 0.4956 TrainAcc 0.8300 TestAcc 0.8238 0.8300
epoch 1100 LossPred 0.4762 LossAtt 0.4688 TrainAcc 0.8200 TestAcc 0.8006 0.8200
epoch 1200 LossPred 0.3854 LossAtt 0.4452 TrainAcc 0.8800 TestAcc 0.8438 0.8550
epoch 1300 LossPred 0.3880 LossAtt 0.4760 TrainAcc 0.8400 TestAcc 0.8564 0.8600
epoch 1400 LossPred 0.3063 LossAtt 0.4404 TrainAcc 0.9300 TestAcc 0.8769 0.8850
epoch 1500 LossPred 0.3409 LossAtt 0.4430 TrainAcc 0.9000 TestAcc 0.8709 0.8900
epoch 1600 LossPred 0.4675 LossAtt 0.4309 TrainAcc 0.8000 TestAcc 0.8273 0.8400
epoch 1700 LossPred 0.3074 LossAtt 0.4149 TrainAcc 0.9000 TestAcc 0.8844 0.9050
epoch 1800 LossPred 0.3711 LossAtt 0.3956 TrainAcc 0.8600 TestAcc 0.8569 0.8650
epoch 1900 LossPred 0.3247 LossAtt 0.4184 TrainAcc 0.9100 TestAcc 0.8704 0.8900
epoch 2000 LossPred 0.2813 LossAtt 0.4206 TrainAcc 0.9100 TestAcc 0.8876 0.8950
epoch 2100 LossPred 0.3181 LossAtt 0.4500 TrainAcc 0.9200 TestAcc 0.8736 0.8850
epoch 2200 LossPred 0.2888 LossAtt 0.4567 TrainAcc 0.9100 TestAcc 0.8866 0.9000
epoch 2300 LossPred 0.4153 LossAtt 0.4993 TrainAcc 0.8500 TestAcc 0.8351 0.8650
epoch 2400 LossPred 0.2598 LossAtt 0.4718 TrainAcc 0.9300 TestAcc 0.8926 0.9000
epoch 2500 LossPred 0.4376 LossAtt 0.4884 TrainAcc 0.8400 TestAcc 0.8243 0.8350
Optimization Finished!
********** replication  21  **********
epoch   0 LossPred 0.9585 LossAtt 1.0000 TrainAcc 0.5700 TestAcc 0.5285 0.5900
epoch 100 LossPred 0.8627 LossAtt 0.6075 TrainAcc 0.6400 TestAcc 0.5811 0.6400
epoch 200 LossPred 0.3591 LossAtt 0.6449 TrainAcc 0.9300 TestAcc 0.8784 0.9250
epoch 300 LossPred 0.2455 LossAtt 0.6178 TrainAcc 0.9400 TestAcc 0.8674 0.9200
epoch 400 LossPred 0.2299 LossAtt 0.6278 TrainAcc 0.9200 TestAcc 0.8679 0.9300
epoch 500 LossPred 0.2098 LossAtt 0.6215 TrainAcc 0.9400 TestAcc 0.8696 0.9150
epoch 600 LossPred 0.1924 LossAtt 0.6407 TrainAcc 0.9600 TestAcc 0.8676 0.9400
epoch 700 LossPred 0.1944 LossAtt 0.6577 TrainAcc 0.9400 TestAcc 0.8619 0.9150
epoch 800 LossPred 0.1875 LossAtt 0.6482 TrainAcc 0.9400 TestAcc 0.8701 0.9200
epoch 900 LossPred 0.1748 LossAtt 0.6563 TrainAcc 0.9400 TestAcc 0.8741 0.9250
epoch 1000 LossPred 0.2021 LossAtt 0.6501 TrainAcc 0.9400 TestAcc 0.8671 0.9300
epoch 1100 LossPred 0.1206 LossAtt 0.6800 TrainAcc 0.9600 TestAcc 0.8756 0.9400
epoch 1200 LossPred 0.1135 LossAtt 0.6710 TrainAcc 0.9700 TestAcc 0.8676 0.9600
epoch 1300 LossPred 0.1195 LossAtt 0.6826 TrainAcc 0.9700 TestAcc 0.8709 0.9550
epoch 1400 LossPred 0.0831 LossAtt 0.6711 TrainAcc 0.9800 TestAcc 0.8689 0.9600
epoch 1500 LossPred 0.1057 LossAtt 0.6801 TrainAcc 0.9600 TestAcc 0.8554 0.9550
epoch 1600 LossPred 0.0764 LossAtt 0.6119 TrainAcc 0.9800 TestAcc 0.8691 0.9700
epoch 1700 LossPred 0.0748 LossAtt 0.6468 TrainAcc 0.9900 TestAcc 0.8661 0.9650
epoch 1800 LossPred 0.0708 LossAtt 0.6458 TrainAcc 0.9800 TestAcc 0.8724 0.9700
epoch 1900 LossPred 0.0763 LossAtt 0.6109 TrainAcc 0.9800 TestAcc 0.8639 0.9700
epoch 2000 LossPred 0.0767 LossAtt 0.6070 TrainAcc 0.9800 TestAcc 0.8739 0.9700
epoch 2100 LossPred 0.0662 LossAtt 0.6271 TrainAcc 0.9900 TestAcc 0.8751 0.9700
epoch 2200 LossPred 0.0666 LossAtt 0.6306 TrainAcc 0.9900 TestAcc 0.8819 0.9600
epoch 2300 LossPred 0.0775 LossAtt 0.6265 TrainAcc 0.9900 TestAcc 0.8729 0.9400
epoch 2400 LossPred 0.0631 LossAtt 0.6252 TrainAcc 0.9900 TestAcc 0.8816 0.9650
epoch 2500 LossPred 0.0608 LossAtt 0.6024 TrainAcc 0.9900 TestAcc 0.8799 0.9650
Optimization Finished!
********** replication  22  **********
epoch   0 LossPred 1.3257 LossAtt 1.0502 TrainAcc 0.4800 TestAcc 0.5063 0.4800
epoch 100 LossPred 0.9932 LossAtt 0.4646 TrainAcc 0.5200 TestAcc 0.5753 0.4900
epoch 200 LossPred 0.9797 LossAtt 0.4713 TrainAcc 0.5300 TestAcc 0.6001 0.5300
epoch 300 LossPred 0.8920 LossAtt 0.5441 TrainAcc 0.7400 TestAcc 0.6799 0.7250
epoch 400 LossPred 0.4060 LossAtt 0.5994 TrainAcc 0.8700 TestAcc 0.8691 0.8700
epoch 500 LossPred 0.2980 LossAtt 0.5393 TrainAcc 0.9400 TestAcc 0.8879 0.9050
epoch 600 LossPred 0.2267 LossAtt 0.5504 TrainAcc 0.9600 TestAcc 0.9257 0.9200
epoch 700 LossPred 0.1768 LossAtt 0.5261 TrainAcc 0.9700 TestAcc 0.9477 0.9350
epoch 800 LossPred 0.1463 LossAtt 0.4780 TrainAcc 0.9800 TestAcc 0.9535 0.9500
epoch 900 LossPred 0.1346 LossAtt 0.3692 TrainAcc 0.9600 TestAcc 0.9655 0.9450
epoch 1000 LossPred 0.1090 LossAtt 0.3399 TrainAcc 0.9800 TestAcc 0.9637 0.9800
epoch 1100 LossPred 0.1032 LossAtt 0.3298 TrainAcc 0.9900 TestAcc 0.9635 0.9850
epoch 1200 LossPred 0.0924 LossAtt 0.3273 TrainAcc 0.9800 TestAcc 0.9690 0.9850
epoch 1300 LossPred 0.0895 LossAtt 0.3224 TrainAcc 0.9800 TestAcc 0.9650 0.9750
epoch 1400 LossPred 0.3206 LossAtt 0.3194 TrainAcc 0.8700 TestAcc 0.8899 0.8900
epoch 1500 LossPred 0.1734 LossAtt 0.3308 TrainAcc 0.9300 TestAcc 0.9367 0.9450
epoch 1600 LossPred 0.0794 LossAtt 0.3276 TrainAcc 0.9900 TestAcc 0.9660 0.9650
epoch 1700 LossPred 0.0763 LossAtt 0.3093 TrainAcc 0.9900 TestAcc 0.9655 0.9800
epoch 1800 LossPred 0.2062 LossAtt 0.2995 TrainAcc 0.9200 TestAcc 0.9259 0.9300
epoch 1900 LossPred 0.1391 LossAtt 0.3287 TrainAcc 0.9500 TestAcc 0.9367 0.9400
epoch 2000 LossPred 0.2942 LossAtt 0.3494 TrainAcc 0.8600 TestAcc 0.8396 0.8800
epoch 2100 LossPred 0.1212 LossAtt 0.3456 TrainAcc 0.9800 TestAcc 0.9487 0.9500
epoch 2200 LossPred 0.1872 LossAtt 0.3464 TrainAcc 0.9300 TestAcc 0.9292 0.9300
epoch 2300 LossPred 0.1148 LossAtt 0.3421 TrainAcc 0.9800 TestAcc 0.9494 0.9550
epoch 2400 LossPred 0.1638 LossAtt 0.3424 TrainAcc 0.9400 TestAcc 0.9289 0.9450
epoch 2500 LossPred 0.1010 LossAtt 0.3409 TrainAcc 0.9900 TestAcc 0.9540 0.9650
Optimization Finished!
********** replication  23  **********
epoch   0 LossPred 1.2801 LossAtt 1.0320 TrainAcc 0.4100 TestAcc 0.4084 0.4550
epoch 100 LossPred 0.9640 LossAtt 0.6100 TrainAcc 0.5600 TestAcc 0.5308 0.5600
epoch 200 LossPred 0.8598 LossAtt 0.4937 TrainAcc 0.6500 TestAcc 0.5798 0.6500
epoch 300 LossPred 0.8198 LossAtt 0.5183 TrainAcc 0.7200 TestAcc 0.6069 0.7150
epoch 400 LossPred 0.7339 LossAtt 0.6809 TrainAcc 0.7300 TestAcc 0.5971 0.7050
epoch 500 LossPred 0.6667 LossAtt 0.6906 TrainAcc 0.7500 TestAcc 0.6146 0.7200
epoch 600 LossPred 0.6277 LossAtt 0.7094 TrainAcc 0.7800 TestAcc 0.6266 0.7700
epoch 700 LossPred 0.5807 LossAtt 0.6858 TrainAcc 0.8100 TestAcc 0.6011 0.7550
epoch 800 LossPred 0.5517 LossAtt 0.6232 TrainAcc 0.8100 TestAcc 0.6049 0.7600
epoch 900 LossPred 0.5265 LossAtt 0.6400 TrainAcc 0.8200 TestAcc 0.5981 0.7600
epoch 1000 LossPred 0.5033 LossAtt 0.6415 TrainAcc 0.8300 TestAcc 0.5998 0.7250
epoch 1100 LossPred 0.4854 LossAtt 0.6291 TrainAcc 0.8500 TestAcc 0.5968 0.7600
epoch 1200 LossPred 0.4749 LossAtt 0.6283 TrainAcc 0.8500 TestAcc 0.5961 0.7750
epoch 1300 LossPred 0.4694 LossAtt 0.5759 TrainAcc 0.8500 TestAcc 0.5981 0.7800
epoch 1400 LossPred 0.4619 LossAtt 0.5766 TrainAcc 0.8600 TestAcc 0.6061 0.7500
epoch 1500 LossPred 0.4525 LossAtt 0.5807 TrainAcc 0.8600 TestAcc 0.6079 0.7700
epoch 1600 LossPred 0.4462 LossAtt 0.5577 TrainAcc 0.8600 TestAcc 0.6011 0.7900
epoch 1700 LossPred 0.4442 LossAtt 0.5440 TrainAcc 0.8700 TestAcc 0.6046 0.7850
epoch 1800 LossPred 0.4293 LossAtt 0.5669 TrainAcc 0.8700 TestAcc 0.6046 0.7800
epoch 1900 LossPred 0.4262 LossAtt 0.5425 TrainAcc 0.8800 TestAcc 0.6001 0.8050
epoch 2000 LossPred 0.4221 LossAtt 0.5630 TrainAcc 0.8800 TestAcc 0.5941 0.7800
epoch 2100 LossPred 0.4159 LossAtt 0.5326 TrainAcc 0.8700 TestAcc 0.5943 0.7600
epoch 2200 LossPred 0.4122 LossAtt 0.5305 TrainAcc 0.8700 TestAcc 0.5846 0.7650
epoch 2300 LossPred 0.4172 LossAtt 0.5487 TrainAcc 0.8600 TestAcc 0.5983 0.7550
epoch 2400 LossPred 0.4015 LossAtt 0.5250 TrainAcc 0.8700 TestAcc 0.5946 0.7400
epoch 2500 LossPred 0.4052 LossAtt 0.5166 TrainAcc 0.8600 TestAcc 0.5933 0.7600
Optimization Finished!
********** replication  24  **********
epoch   0 LossPred 1.4308 LossAtt 1.0264 TrainAcc 0.4400 TestAcc 0.4837 0.4100
epoch 100 LossPred 1.0134 LossAtt 0.5326 TrainAcc 0.4500 TestAcc 0.4950 0.4500
epoch 200 LossPred 0.8439 LossAtt 0.6103 TrainAcc 0.7300 TestAcc 0.6091 0.7300
epoch 300 LossPred 0.6394 LossAtt 0.6775 TrainAcc 0.8800 TestAcc 0.8253 0.8650
epoch 400 LossPred 0.5272 LossAtt 0.6700 TrainAcc 0.8700 TestAcc 0.8504 0.8450
epoch 500 LossPred 0.4481 LossAtt 0.5999 TrainAcc 0.8800 TestAcc 0.8666 0.8900
epoch 600 LossPred 0.4051 LossAtt 0.6097 TrainAcc 0.8800 TestAcc 0.8816 0.8800
epoch 700 LossPred 0.3807 LossAtt 0.5971 TrainAcc 0.8600 TestAcc 0.8338 0.8300
epoch 800 LossPred 0.3389 LossAtt 0.5858 TrainAcc 0.9300 TestAcc 0.8859 0.8900
epoch 900 LossPred 0.4378 LossAtt 0.5511 TrainAcc 0.8400 TestAcc 0.8866 0.8250
epoch 1000 LossPred 0.3053 LossAtt 0.5334 TrainAcc 0.9000 TestAcc 0.8584 0.8900
epoch 1100 LossPred 0.4207 LossAtt 0.4943 TrainAcc 0.8600 TestAcc 0.8886 0.8300
epoch 1200 LossPred 0.3103 LossAtt 0.4891 TrainAcc 0.8900 TestAcc 0.8511 0.8950
epoch 1300 LossPred 0.2809 LossAtt 0.4342 TrainAcc 0.9200 TestAcc 0.8584 0.9100
epoch 1400 LossPred 0.3000 LossAtt 0.4463 TrainAcc 0.8800 TestAcc 0.8551 0.8900
epoch 1500 LossPred 0.3192 LossAtt 0.4031 TrainAcc 0.9000 TestAcc 0.9309 0.8950
epoch 1600 LossPred 0.2593 LossAtt 0.4066 TrainAcc 0.9300 TestAcc 0.9259 0.9100
epoch 1700 LossPred 0.2657 LossAtt 0.3917 TrainAcc 0.9000 TestAcc 0.8876 0.9000
epoch 1800 LossPred 0.2006 LossAtt 0.4080 TrainAcc 0.9300 TestAcc 0.9442 0.9350
epoch 1900 LossPred 0.2217 LossAtt 0.4161 TrainAcc 0.9300 TestAcc 0.9197 0.9250
epoch 2000 LossPred 0.2478 LossAtt 0.4163 TrainAcc 0.9200 TestAcc 0.9164 0.9050
epoch 2100 LossPred 0.1904 LossAtt 0.4254 TrainAcc 0.9400 TestAcc 0.9444 0.9400
epoch 2200 LossPred 0.2245 LossAtt 0.4556 TrainAcc 0.9200 TestAcc 0.9369 0.9050
epoch 2300 LossPred 0.2200 LossAtt 0.4747 TrainAcc 0.9200 TestAcc 0.9209 0.9250
epoch 2400 LossPred 0.1680 LossAtt 0.4963 TrainAcc 0.9700 TestAcc 0.9452 0.9450
epoch 2500 LossPred 0.1429 LossAtt 0.4790 TrainAcc 0.9700 TestAcc 0.9527 0.9500
Optimization Finished!
********** replication  25  **********
epoch   0 LossPred 1.2842 LossAtt 1.0458 TrainAcc 0.4000 TestAcc 0.4655 0.4000
epoch 100 LossPred 0.9684 LossAtt 0.6801 TrainAcc 0.5800 TestAcc 0.5868 0.5750
epoch 200 LossPred 0.8737 LossAtt 0.7779 TrainAcc 0.7000 TestAcc 0.5490 0.6600
epoch 300 LossPred 0.8033 LossAtt 0.8449 TrainAcc 0.6900 TestAcc 0.5298 0.6850
epoch 400 LossPred 0.6944 LossAtt 0.7986 TrainAcc 0.7500 TestAcc 0.5503 0.7550
epoch 500 LossPred 0.6074 LossAtt 0.7322 TrainAcc 0.7700 TestAcc 0.6034 0.7750
epoch 600 LossPred 0.5351 LossAtt 0.8064 TrainAcc 0.8200 TestAcc 0.6109 0.8050
epoch 700 LossPred 0.4787 LossAtt 0.8163 TrainAcc 0.8600 TestAcc 0.6129 0.8100
epoch 800 LossPred 0.3364 LossAtt 0.9057 TrainAcc 0.9200 TestAcc 0.7080 0.8700
epoch 900 LossPred 0.2236 LossAtt 0.8766 TrainAcc 0.9600 TestAcc 0.7573 0.8950
epoch 1000 LossPred 0.2027 LossAtt 0.8841 TrainAcc 0.9600 TestAcc 0.7703 0.8950
epoch 1100 LossPred 0.2102 LossAtt 0.8854 TrainAcc 0.9500 TestAcc 0.7610 0.9000
epoch 1200 LossPred 0.1788 LossAtt 0.8860 TrainAcc 0.9500 TestAcc 0.7798 0.9200
epoch 1300 LossPred 0.1781 LossAtt 0.8759 TrainAcc 0.9500 TestAcc 0.7823 0.9050
epoch 1400 LossPred 0.1625 LossAtt 0.8769 TrainAcc 0.9500 TestAcc 0.7780 0.9200
epoch 1500 LossPred 0.1365 LossAtt 0.8586 TrainAcc 0.9700 TestAcc 0.7843 0.9100
epoch 1600 LossPred 0.1957 LossAtt 0.8621 TrainAcc 0.9400 TestAcc 0.7870 0.8950
epoch 1700 LossPred 0.1271 LossAtt 0.8377 TrainAcc 0.9700 TestAcc 0.7888 0.9200
epoch 1800 LossPred 0.1279 LossAtt 0.8418 TrainAcc 0.9700 TestAcc 0.7783 0.9200
epoch 1900 LossPred 0.1219 LossAtt 0.8387 TrainAcc 0.9700 TestAcc 0.7768 0.9200
epoch 2000 LossPred 0.1026 LossAtt 0.8479 TrainAcc 0.9800 TestAcc 0.7748 0.9250
epoch 2100 LossPred 0.1355 LossAtt 0.8142 TrainAcc 0.9700 TestAcc 0.7810 0.9100
epoch 2200 LossPred 0.0985 LossAtt 0.8313 TrainAcc 0.9800 TestAcc 0.7853 0.9250
epoch 2300 LossPred 0.1064 LossAtt 0.8191 TrainAcc 0.9700 TestAcc 0.7743 0.9250
epoch 2400 LossPred 0.1002 LossAtt 0.8172 TrainAcc 0.9800 TestAcc 0.7838 0.9250
epoch 2500 LossPred 0.1096 LossAtt 0.7983 TrainAcc 0.9700 TestAcc 0.7825 0.9450
Optimization Finished!
********** replication  26  **********
epoch   0 LossPred 0.9789 LossAtt 1.0013 TrainAcc 0.5000 TestAcc 0.4810 0.5050
epoch 100 LossPred 0.9342 LossAtt 0.5160 TrainAcc 0.6100 TestAcc 0.5626 0.6100
epoch 200 LossPred 0.8474 LossAtt 0.6527 TrainAcc 0.7100 TestAcc 0.6179 0.6850
epoch 300 LossPred 0.7039 LossAtt 0.7174 TrainAcc 0.7700 TestAcc 0.6216 0.7550
epoch 400 LossPred 0.6757 LossAtt 0.7111 TrainAcc 0.7800 TestAcc 0.6091 0.7550
epoch 500 LossPred 0.6632 LossAtt 0.6920 TrainAcc 0.7900 TestAcc 0.6136 0.7600
epoch 600 LossPred 0.6533 LossAtt 0.6590 TrainAcc 0.7900 TestAcc 0.6229 0.7600
epoch 700 LossPred 0.6372 LossAtt 0.6839 TrainAcc 0.8000 TestAcc 0.6131 0.7500
epoch 800 LossPred 0.6172 LossAtt 0.6417 TrainAcc 0.8000 TestAcc 0.5991 0.7650
epoch 900 LossPred 0.5951 LossAtt 0.6762 TrainAcc 0.8100 TestAcc 0.6096 0.7600
epoch 1000 LossPred 0.5757 LossAtt 0.6767 TrainAcc 0.8100 TestAcc 0.6029 0.7700
epoch 1100 LossPred 0.5735 LossAtt 0.6745 TrainAcc 0.8100 TestAcc 0.5973 0.7700
epoch 1200 LossPred 0.5739 LossAtt 0.6571 TrainAcc 0.8100 TestAcc 0.5991 0.7800
epoch 1300 LossPred 0.5690 LossAtt 0.6574 TrainAcc 0.8100 TestAcc 0.5996 0.7700
epoch 1400 LossPred 0.5679 LossAtt 0.6288 TrainAcc 0.8100 TestAcc 0.5996 0.7700
epoch 1500 LossPred 0.5657 LossAtt 0.6076 TrainAcc 0.8100 TestAcc 0.5973 0.7600
epoch 1600 LossPred 0.5621 LossAtt 0.6501 TrainAcc 0.8100 TestAcc 0.5968 0.7550
epoch 1700 LossPred 0.5583 LossAtt 0.6256 TrainAcc 0.8100 TestAcc 0.5916 0.7650
epoch 1800 LossPred 0.5581 LossAtt 0.6035 TrainAcc 0.8000 TestAcc 0.5866 0.7500
epoch 1900 LossPred 0.5550 LossAtt 0.6216 TrainAcc 0.8100 TestAcc 0.5938 0.7650
epoch 2000 LossPred 0.5501 LossAtt 0.5832 TrainAcc 0.8200 TestAcc 0.5946 0.7750
epoch 2100 LossPred 0.5397 LossAtt 0.6118 TrainAcc 0.8200 TestAcc 0.5988 0.7650
epoch 2200 LossPred 0.5418 LossAtt 0.5775 TrainAcc 0.8200 TestAcc 0.5946 0.7900
epoch 2300 LossPred 0.5457 LossAtt 0.6014 TrainAcc 0.8200 TestAcc 0.5931 0.7900
epoch 2400 LossPred 0.5346 LossAtt 0.6287 TrainAcc 0.8200 TestAcc 0.5991 0.7750
epoch 2500 LossPred 0.5359 LossAtt 0.6296 TrainAcc 0.8200 TestAcc 0.6024 0.7800
Optimization Finished!
********** replication  27  **********
epoch   0 LossPred 1.0737 LossAtt 1.0957 TrainAcc 0.5500 TestAcc 0.6026 0.5600
epoch 100 LossPred 0.8882 LossAtt 0.5725 TrainAcc 0.6500 TestAcc 0.5465 0.6750
epoch 200 LossPred 0.8280 LossAtt 0.5377 TrainAcc 0.6900 TestAcc 0.5353 0.6850
epoch 300 LossPred 0.8082 LossAtt 0.4855 TrainAcc 0.6900 TestAcc 0.5393 0.6800
epoch 400 LossPred 0.7920 LossAtt 0.4484 TrainAcc 0.7100 TestAcc 0.5746 0.6900
epoch 500 LossPred 0.7684 LossAtt 0.5593 TrainAcc 0.7200 TestAcc 0.6079 0.7050
epoch 600 LossPred 0.4301 LossAtt 0.6895 TrainAcc 0.8700 TestAcc 0.7988 0.8350
epoch 700 LossPred 0.2793 LossAtt 0.6968 TrainAcc 0.9100 TestAcc 0.8326 0.8900
epoch 800 LossPred 0.1876 LossAtt 0.6896 TrainAcc 0.9600 TestAcc 0.8308 0.9100
epoch 900 LossPred 0.1876 LossAtt 0.6801 TrainAcc 0.9600 TestAcc 0.8408 0.9100
epoch 1000 LossPred 0.1385 LossAtt 0.6667 TrainAcc 0.9700 TestAcc 0.8398 0.9400
epoch 1100 LossPred 0.1621 LossAtt 0.6816 TrainAcc 0.9600 TestAcc 0.8323 0.9200
epoch 1200 LossPred 0.1490 LossAtt 0.6777 TrainAcc 0.9800 TestAcc 0.8491 0.9550
epoch 1300 LossPred 0.0969 LossAtt 0.6803 TrainAcc 0.9800 TestAcc 0.8423 0.9600
epoch 1400 LossPred 0.0853 LossAtt 0.6412 TrainAcc 0.9800 TestAcc 0.8403 0.9650
epoch 1500 LossPred 0.0728 LossAtt 0.6215 TrainAcc 0.9800 TestAcc 0.8323 0.9750
epoch 1600 LossPred 0.0783 LossAtt 0.6305 TrainAcc 0.9800 TestAcc 0.8321 0.9650
epoch 1700 LossPred 0.0750 LossAtt 0.6557 TrainAcc 0.9700 TestAcc 0.8321 0.9650
epoch 1800 LossPred 0.0582 LossAtt 0.6356 TrainAcc 0.9900 TestAcc 0.8331 0.9650
epoch 1900 LossPred 0.1146 LossAtt 0.6307 TrainAcc 0.9500 TestAcc 0.8238 0.9300
epoch 2000 LossPred 0.0453 LossAtt 0.6247 TrainAcc 0.9900 TestAcc 0.8308 0.9700
epoch 2100 LossPred 0.0511 LossAtt 0.6385 TrainAcc 0.9900 TestAcc 0.8291 0.9650
epoch 2200 LossPred 0.0698 LossAtt 0.6387 TrainAcc 0.9800 TestAcc 0.8213 0.9500
epoch 2300 LossPred 0.0552 LossAtt 0.6122 TrainAcc 0.9900 TestAcc 0.8208 0.9700
epoch 2400 LossPred 0.0402 LossAtt 0.6315 TrainAcc 0.9900 TestAcc 0.8321 0.9700
epoch 2500 LossPred 0.0484 LossAtt 0.6765 TrainAcc 0.9900 TestAcc 0.8208 0.9550
Optimization Finished!
********** replication  28  **********
epoch   0 LossPred 1.5932 LossAtt 1.0234 TrainAcc 0.4000 TestAcc 0.4414 0.4100
epoch 100 LossPred 1.1056 LossAtt 0.5533 TrainAcc 0.3600 TestAcc 0.4119 0.3650
epoch 200 LossPred 0.9161 LossAtt 0.5085 TrainAcc 0.6800 TestAcc 0.5998 0.6800
epoch 300 LossPred 0.8630 LossAtt 0.3982 TrainAcc 0.6800 TestAcc 0.5998 0.6800
epoch 400 LossPred 0.8462 LossAtt 0.3505 TrainAcc 0.6800 TestAcc 0.5998 0.6800
epoch 500 LossPred 0.8366 LossAtt 0.3586 TrainAcc 0.6800 TestAcc 0.5998 0.6800
epoch 600 LossPred 0.8014 LossAtt 0.3842 TrainAcc 0.7000 TestAcc 0.6336 0.7000
epoch 700 LossPred 0.4365 LossAtt 0.4351 TrainAcc 0.8900 TestAcc 0.8361 0.8600
epoch 800 LossPred 0.4687 LossAtt 0.4112 TrainAcc 0.8500 TestAcc 0.8526 0.8650
epoch 900 LossPred 0.3488 LossAtt 0.4090 TrainAcc 0.8900 TestAcc 0.8356 0.8700
epoch 1000 LossPred 0.3340 LossAtt 0.3707 TrainAcc 0.9000 TestAcc 0.8501 0.8800
epoch 1100 LossPred 0.3010 LossAtt 0.3879 TrainAcc 0.8900 TestAcc 0.8391 0.8900
epoch 1200 LossPred 0.3115 LossAtt 0.3742 TrainAcc 0.9000 TestAcc 0.8446 0.8900
epoch 1300 LossPred 0.2822 LossAtt 0.3277 TrainAcc 0.9100 TestAcc 0.8566 0.8750
epoch 1400 LossPred 0.2758 LossAtt 0.3285 TrainAcc 0.9000 TestAcc 0.8316 0.8850
epoch 1500 LossPred 0.3096 LossAtt 0.3342 TrainAcc 0.9000 TestAcc 0.8541 0.8800
epoch 1600 LossPred 0.2994 LossAtt 0.3204 TrainAcc 0.8900 TestAcc 0.8609 0.8800
epoch 1700 LossPred 0.2737 LossAtt 0.3244 TrainAcc 0.9100 TestAcc 0.8586 0.8950
epoch 1800 LossPred 0.2903 LossAtt 0.3269 TrainAcc 0.9200 TestAcc 0.8769 0.8950
epoch 1900 LossPred 0.2508 LossAtt 0.2996 TrainAcc 0.9200 TestAcc 0.8634 0.8900
epoch 2000 LossPred 0.3036 LossAtt 0.3189 TrainAcc 0.8800 TestAcc 0.8238 0.8850
epoch 2100 LossPred 0.2784 LossAtt 0.3155 TrainAcc 0.9100 TestAcc 0.8586 0.8900
epoch 2200 LossPred 0.3201 LossAtt 0.3170 TrainAcc 0.8900 TestAcc 0.8416 0.8850
epoch 2300 LossPred 0.2871 LossAtt 0.3395 TrainAcc 0.9200 TestAcc 0.9022 0.9000
epoch 2400 LossPred 0.2016 LossAtt 0.3549 TrainAcc 0.9300 TestAcc 0.8859 0.8900
epoch 2500 LossPred 0.1825 LossAtt 0.3427 TrainAcc 0.9400 TestAcc 0.9097 0.9300
Optimization Finished!
********** replication  29  **********
epoch   0 LossPred 1.0216 LossAtt 1.0310 TrainAcc 0.6000 TestAcc 0.5270 0.5900
epoch 100 LossPred 0.8255 LossAtt 0.6652 TrainAcc 0.7200 TestAcc 0.6234 0.7150
epoch 200 LossPred 0.7479 LossAtt 0.6490 TrainAcc 0.7200 TestAcc 0.6234 0.7200
epoch 300 LossPred 0.6757 LossAtt 0.6577 TrainAcc 0.7800 TestAcc 0.6494 0.7750
epoch 400 LossPred 0.3654 LossAtt 0.6965 TrainAcc 0.8800 TestAcc 0.8388 0.8650
epoch 500 LossPred 0.2787 LossAtt 0.6205 TrainAcc 0.9100 TestAcc 0.8584 0.8650
epoch 600 LossPred 0.2140 LossAtt 0.6465 TrainAcc 0.9200 TestAcc 0.9017 0.9000
epoch 700 LossPred 0.1364 LossAtt 0.6485 TrainAcc 0.9700 TestAcc 0.9197 0.9300
epoch 800 LossPred 0.1212 LossAtt 0.6588 TrainAcc 0.9700 TestAcc 0.9234 0.9400
epoch 900 LossPred 0.0929 LossAtt 0.6309 TrainAcc 0.9700 TestAcc 0.9339 0.9500
epoch 1000 LossPred 0.0686 LossAtt 0.5724 TrainAcc 0.9800 TestAcc 0.9482 0.9800
epoch 1100 LossPred 0.3249 LossAtt 0.5364 TrainAcc 0.8800 TestAcc 0.8461 0.8900
epoch 1200 LossPred 0.0679 LossAtt 0.5265 TrainAcc 0.9900 TestAcc 0.9522 0.9800
epoch 1300 LossPred 0.0562 LossAtt 0.5108 TrainAcc 0.9900 TestAcc 0.9472 0.9850
epoch 1400 LossPred 0.0614 LossAtt 0.5361 TrainAcc 0.9900 TestAcc 0.9457 0.9800
epoch 1500 LossPred 0.1320 LossAtt 0.4826 TrainAcc 0.9600 TestAcc 0.9132 0.9550
epoch 1600 LossPred 0.0679 LossAtt 0.4979 TrainAcc 0.9900 TestAcc 0.9444 0.9750
epoch 1700 LossPred 0.0546 LossAtt 0.5042 TrainAcc 0.9900 TestAcc 0.9439 0.9800
epoch 1800 LossPred 0.0461 LossAtt 0.4794 TrainAcc 0.9900 TestAcc 0.9449 0.9900
epoch 1900 LossPred 0.0510 LossAtt 0.4821 TrainAcc 0.9900 TestAcc 0.9507 0.9900
epoch 2000 LossPred 0.1096 LossAtt 0.4739 TrainAcc 0.9600 TestAcc 0.9307 0.9550
epoch 2100 LossPred 0.0863 LossAtt 0.4939 TrainAcc 0.9800 TestAcc 0.9374 0.9650
epoch 2200 LossPred 0.0470 LossAtt 0.4934 TrainAcc 0.9900 TestAcc 0.9427 0.9750
epoch 2300 LossPred 0.0411 LossAtt 0.5008 TrainAcc 0.9900 TestAcc 0.9422 0.9900
epoch 2400 LossPred 0.0436 LossAtt 0.4757 TrainAcc 0.9900 TestAcc 0.9449 0.9900
epoch 2500 LossPred 0.0387 LossAtt 0.4671 TrainAcc 0.9900 TestAcc 0.9372 0.9900
Optimization Finished!
********** replication  30  **********
epoch   0 LossPred 1.2882 LossAtt 1.0264 TrainAcc 0.4700 TestAcc 0.5253 0.4800
epoch 100 LossPred 0.9904 LossAtt 0.6058 TrainAcc 0.6200 TestAcc 0.5958 0.6200
epoch 200 LossPred 0.9188 LossAtt 0.6514 TrainAcc 0.6600 TestAcc 0.6216 0.6350
epoch 300 LossPred 0.8838 LossAtt 0.6587 TrainAcc 0.6700 TestAcc 0.6204 0.6500
epoch 400 LossPred 0.8304 LossAtt 0.6901 TrainAcc 0.7000 TestAcc 0.6679 0.6800
epoch 500 LossPred 0.4857 LossAtt 0.7627 TrainAcc 0.8500 TestAcc 0.8611 0.8400
epoch 600 LossPred 0.3752 LossAtt 0.7140 TrainAcc 0.8700 TestAcc 0.8581 0.8550
epoch 700 LossPred 0.3521 LossAtt 0.7162 TrainAcc 0.8800 TestAcc 0.8599 0.8450
epoch 800 LossPred 0.3435 LossAtt 0.6867 TrainAcc 0.9000 TestAcc 0.8646 0.8550
epoch 900 LossPred 0.2861 LossAtt 0.6714 TrainAcc 0.9200 TestAcc 0.8604 0.8700
epoch 1000 LossPred 0.2578 LossAtt 0.6608 TrainAcc 0.9400 TestAcc 0.8774 0.8800
epoch 1100 LossPred 0.2394 LossAtt 0.6898 TrainAcc 0.9100 TestAcc 0.8974 0.8900
epoch 1200 LossPred 0.2039 LossAtt 0.6580 TrainAcc 0.9300 TestAcc 0.8881 0.9050
epoch 1300 LossPred 0.1900 LossAtt 0.6586 TrainAcc 0.9300 TestAcc 0.8884 0.9050
epoch 1400 LossPred 0.1901 LossAtt 0.6682 TrainAcc 0.9500 TestAcc 0.8969 0.8950
epoch 1500 LossPred 0.1669 LossAtt 0.6464 TrainAcc 0.9400 TestAcc 0.8891 0.9350
epoch 1600 LossPred 0.1525 LossAtt 0.6756 TrainAcc 0.9500 TestAcc 0.8939 0.9150
epoch 1700 LossPred 0.1912 LossAtt 0.6605 TrainAcc 0.9400 TestAcc 0.8789 0.9300
epoch 1800 LossPred 0.2017 LossAtt 0.6424 TrainAcc 0.9300 TestAcc 0.8769 0.9350
epoch 1900 LossPred 0.1622 LossAtt 0.6203 TrainAcc 0.9600 TestAcc 0.8694 0.9300
epoch 2000 LossPred 0.1478 LossAtt 0.6268 TrainAcc 0.9700 TestAcc 0.8706 0.9450
epoch 2100 LossPred 0.1482 LossAtt 0.6296 TrainAcc 0.9500 TestAcc 0.8671 0.9550
epoch 2200 LossPred 0.1316 LossAtt 0.6266 TrainAcc 0.9700 TestAcc 0.8661 0.9500
epoch 2300 LossPred 0.1285 LossAtt 0.5899 TrainAcc 0.9600 TestAcc 0.8674 0.9650
epoch 2400 LossPred 0.1206 LossAtt 0.6052 TrainAcc 0.9700 TestAcc 0.8651 0.9550
epoch 2500 LossPred 0.1165 LossAtt 0.6190 TrainAcc 0.9800 TestAcc 0.8731 0.9650
Optimization Finished!
********** replication  31  **********
epoch   0 LossPred 1.0003 LossAtt 1.0198 TrainAcc 0.6300 TestAcc 0.5658 0.6300
epoch 100 LossPred 0.8585 LossAtt 0.4847 TrainAcc 0.6600 TestAcc 0.5993 0.6600
epoch 200 LossPred 0.4032 LossAtt 0.5318 TrainAcc 0.9100 TestAcc 0.8614 0.8800
epoch 300 LossPred 0.3161 LossAtt 0.5306 TrainAcc 0.9300 TestAcc 0.8921 0.9050
epoch 400 LossPred 0.2448 LossAtt 0.5150 TrainAcc 0.9300 TestAcc 0.9082 0.9050
epoch 500 LossPred 0.1769 LossAtt 0.4691 TrainAcc 0.9600 TestAcc 0.8994 0.8900
epoch 600 LossPred 0.1656 LossAtt 0.3711 TrainAcc 0.9700 TestAcc 0.8969 0.9050
epoch 700 LossPred 0.1581 LossAtt 0.3666 TrainAcc 0.9700 TestAcc 0.9039 0.9200
epoch 800 LossPred 0.1498 LossAtt 0.3851 TrainAcc 0.9900 TestAcc 0.8981 0.9050
epoch 900 LossPred 0.1460 LossAtt 0.3906 TrainAcc 0.9700 TestAcc 0.8891 0.9050
epoch 1000 LossPred 0.1793 LossAtt 0.3670 TrainAcc 0.9500 TestAcc 0.8961 0.9050
epoch 1100 LossPred 0.2656 LossAtt 0.3754 TrainAcc 0.8900 TestAcc 0.8756 0.8800
epoch 1200 LossPred 0.1236 LossAtt 0.3854 TrainAcc 0.9700 TestAcc 0.9012 0.9150
epoch 1300 LossPred 0.1185 LossAtt 0.3942 TrainAcc 0.9600 TestAcc 0.8996 0.9300
epoch 1400 LossPred 0.1238 LossAtt 0.3830 TrainAcc 0.9700 TestAcc 0.8961 0.9300
epoch 1500 LossPred 0.1405 LossAtt 0.3944 TrainAcc 0.9500 TestAcc 0.8884 0.9350
epoch 1600 LossPred 0.1412 LossAtt 0.3529 TrainAcc 0.9700 TestAcc 0.9039 0.9400
epoch 1700 LossPred 0.2475 LossAtt 0.3730 TrainAcc 0.9200 TestAcc 0.8714 0.8950
epoch 1800 LossPred 0.2993 LossAtt 0.3198 TrainAcc 0.8900 TestAcc 0.8166 0.8600
epoch 1900 LossPred 0.2517 LossAtt 0.2944 TrainAcc 0.9300 TestAcc 0.8506 0.9050
epoch 2000 LossPred 0.1686 LossAtt 0.2934 TrainAcc 0.9600 TestAcc 0.8844 0.9200
epoch 2100 LossPred 0.1865 LossAtt 0.2925 TrainAcc 0.9400 TestAcc 0.8739 0.9050
epoch 2200 LossPred 0.1096 LossAtt 0.2932 TrainAcc 0.9700 TestAcc 0.9074 0.9450
epoch 2300 LossPred 0.2013 LossAtt 0.2864 TrainAcc 0.9400 TestAcc 0.8936 0.9050
epoch 2400 LossPred 0.1234 LossAtt 0.2675 TrainAcc 0.9800 TestAcc 0.9134 0.9500
epoch 2500 LossPred 0.1483 LossAtt 0.2822 TrainAcc 0.9500 TestAcc 0.8809 0.9250
Optimization Finished!
********** replication  32  **********
epoch   0 LossPred 1.3162 LossAtt 1.0366 TrainAcc 0.4100 TestAcc 0.5393 0.4750
epoch 100 LossPred 1.0057 LossAtt 0.3842 TrainAcc 0.5200 TestAcc 0.5413 0.5350
epoch 200 LossPred 0.9556 LossAtt 0.4891 TrainAcc 0.5700 TestAcc 0.4982 0.5750
epoch 300 LossPred 0.9421 LossAtt 0.4709 TrainAcc 0.5700 TestAcc 0.4715 0.5950
epoch 400 LossPred 0.9011 LossAtt 0.7130 TrainAcc 0.5100 TestAcc 0.4407 0.5200
epoch 500 LossPred 0.8364 LossAtt 0.8005 TrainAcc 0.6800 TestAcc 0.6154 0.6700
epoch 600 LossPred 0.7408 LossAtt 0.7654 TrainAcc 0.7900 TestAcc 0.6139 0.7350
epoch 700 LossPred 0.6166 LossAtt 0.7140 TrainAcc 0.8500 TestAcc 0.6351 0.7550
epoch 800 LossPred 0.4991 LossAtt 0.7040 TrainAcc 0.8800 TestAcc 0.6304 0.8150
epoch 900 LossPred 0.4447 LossAtt 0.6862 TrainAcc 0.8900 TestAcc 0.6399 0.8150
epoch 1000 LossPred 0.4387 LossAtt 0.6413 TrainAcc 0.8900 TestAcc 0.6429 0.8100
epoch 1100 LossPred 0.3932 LossAtt 0.6583 TrainAcc 0.9100 TestAcc 0.6254 0.8350
epoch 1200 LossPred 0.3985 LossAtt 0.6345 TrainAcc 0.8900 TestAcc 0.6409 0.8450
epoch 1300 LossPred 0.3890 LossAtt 0.6064 TrainAcc 0.8800 TestAcc 0.6406 0.8350
epoch 1400 LossPred 0.3520 LossAtt 0.6096 TrainAcc 0.9100 TestAcc 0.6329 0.8450
epoch 1500 LossPred 0.3516 LossAtt 0.6002 TrainAcc 0.9000 TestAcc 0.6439 0.8450
epoch 1600 LossPred 0.3425 LossAtt 0.6257 TrainAcc 0.9100 TestAcc 0.6394 0.8300
epoch 1700 LossPred 0.3244 LossAtt 0.5965 TrainAcc 0.9200 TestAcc 0.6391 0.8350
epoch 1800 LossPred 0.3056 LossAtt 0.6219 TrainAcc 0.9200 TestAcc 0.6299 0.8250
epoch 1900 LossPred 0.3013 LossAtt 0.6044 TrainAcc 0.9200 TestAcc 0.6309 0.8450
epoch 2000 LossPred 0.2972 LossAtt 0.6043 TrainAcc 0.9200 TestAcc 0.6364 0.8550
epoch 2100 LossPred 0.3808 LossAtt 0.6414 TrainAcc 0.8700 TestAcc 0.6354 0.8250
epoch 2200 LossPred 0.2859 LossAtt 0.6283 TrainAcc 0.9200 TestAcc 0.6381 0.8500
epoch 2300 LossPred 0.2884 LossAtt 0.6332 TrainAcc 0.9200 TestAcc 0.6246 0.8250
epoch 2400 LossPred 0.2349 LossAtt 0.6416 TrainAcc 0.9300 TestAcc 0.6356 0.8550
epoch 2500 LossPred 0.2538 LossAtt 0.6401 TrainAcc 0.9300 TestAcc 0.6444 0.8450
Optimization Finished!
********** replication  33  **********
epoch   0 LossPred 1.1173 LossAtt 1.0153 TrainAcc 0.5200 TestAcc 0.5638 0.4750
epoch 100 LossPred 0.9600 LossAtt 0.5929 TrainAcc 0.6600 TestAcc 0.6144 0.6200
epoch 200 LossPred 0.7831 LossAtt 0.5373 TrainAcc 0.7000 TestAcc 0.6879 0.6950
epoch 300 LossPred 0.3685 LossAtt 0.4559 TrainAcc 0.9000 TestAcc 0.8504 0.8700
epoch 400 LossPred 0.3042 LossAtt 0.4208 TrainAcc 0.9200 TestAcc 0.8686 0.8700
epoch 500 LossPred 0.2176 LossAtt 0.3831 TrainAcc 0.9300 TestAcc 0.8761 0.8950
epoch 600 LossPred 0.1968 LossAtt 0.3980 TrainAcc 0.9400 TestAcc 0.8811 0.9100
epoch 700 LossPred 0.1861 LossAtt 0.4220 TrainAcc 0.9500 TestAcc 0.8916 0.9100
epoch 800 LossPred 0.1735 LossAtt 0.4401 TrainAcc 0.9600 TestAcc 0.8989 0.9100
epoch 900 LossPred 0.1652 LossAtt 0.4467 TrainAcc 0.9600 TestAcc 0.9124 0.9250
epoch 1000 LossPred 0.1537 LossAtt 0.4515 TrainAcc 0.9700 TestAcc 0.9202 0.9300
epoch 1100 LossPred 0.1287 LossAtt 0.4627 TrainAcc 0.9800 TestAcc 0.9224 0.9450
epoch 1200 LossPred 0.1138 LossAtt 0.4247 TrainAcc 0.9800 TestAcc 0.9209 0.9550
epoch 1300 LossPred 0.1059 LossAtt 0.4174 TrainAcc 0.9700 TestAcc 0.9184 0.9350
epoch 1400 LossPred 0.1006 LossAtt 0.4358 TrainAcc 0.9700 TestAcc 0.9182 0.9300
epoch 1500 LossPred 0.1111 LossAtt 0.4450 TrainAcc 0.9700 TestAcc 0.9177 0.9300
epoch 1600 LossPred 0.1078 LossAtt 0.4398 TrainAcc 0.9700 TestAcc 0.9167 0.9050
epoch 1700 LossPred 0.0886 LossAtt 0.4433 TrainAcc 0.9800 TestAcc 0.9177 0.9350
epoch 1800 LossPred 0.0978 LossAtt 0.4452 TrainAcc 0.9800 TestAcc 0.9217 0.9500
epoch 1900 LossPred 0.0838 LossAtt 0.4231 TrainAcc 0.9800 TestAcc 0.9184 0.9050
epoch 2000 LossPred 0.0801 LossAtt 0.4127 TrainAcc 0.9800 TestAcc 0.9152 0.9050
epoch 2100 LossPred 0.1913 LossAtt 0.4411 TrainAcc 0.9300 TestAcc 0.9039 0.8950
epoch 2200 LossPred 0.0763 LossAtt 0.4233 TrainAcc 0.9900 TestAcc 0.9249 0.9200
epoch 2300 LossPred 0.0763 LossAtt 0.4285 TrainAcc 0.9800 TestAcc 0.9202 0.9050
epoch 2400 LossPred 0.0875 LossAtt 0.4194 TrainAcc 0.9800 TestAcc 0.9222 0.9250
epoch 2500 LossPred 0.0723 LossAtt 0.4207 TrainAcc 0.9800 TestAcc 0.9187 0.9050
Optimization Finished!
********** replication  34  **********
epoch   0 LossPred 1.0091 LossAtt 1.0124 TrainAcc 0.5200 TestAcc 0.5045 0.5200
epoch 100 LossPred 0.8410 LossAtt 0.5387 TrainAcc 0.6800 TestAcc 0.6139 0.6900
epoch 200 LossPred 0.3816 LossAtt 0.6439 TrainAcc 0.9500 TestAcc 0.9014 0.8900
epoch 300 LossPred 0.3109 LossAtt 0.6924 TrainAcc 0.9300 TestAcc 0.9042 0.8850
epoch 400 LossPred 0.6352 LossAtt 0.7189 TrainAcc 0.7900 TestAcc 0.7878 0.7600
epoch 500 LossPred 0.4995 LossAtt 0.6387 TrainAcc 0.8000 TestAcc 0.8153 0.8200
epoch 600 LossPred 0.2584 LossAtt 0.6321 TrainAcc 0.9100 TestAcc 0.8966 0.8700
epoch 700 LossPred 0.2603 LossAtt 0.6391 TrainAcc 0.9300 TestAcc 0.8994 0.8950
epoch 800 LossPred 0.2589 LossAtt 0.6480 TrainAcc 0.9000 TestAcc 0.9047 0.8700
epoch 900 LossPred 0.3419 LossAtt 0.6667 TrainAcc 0.8700 TestAcc 0.8854 0.8600
epoch 1000 LossPred 0.1900 LossAtt 0.6145 TrainAcc 0.9300 TestAcc 0.9264 0.9050
epoch 1100 LossPred 0.1600 LossAtt 0.6238 TrainAcc 0.9700 TestAcc 0.9374 0.9150
epoch 1200 LossPred 0.1924 LossAtt 0.6209 TrainAcc 0.9400 TestAcc 0.9122 0.9300
epoch 1300 LossPred 0.1375 LossAtt 0.6282 TrainAcc 0.9700 TestAcc 0.9337 0.9350
epoch 1400 LossPred 0.1323 LossAtt 0.6395 TrainAcc 0.9700 TestAcc 0.9399 0.9350
epoch 1500 LossPred 0.1278 LossAtt 0.6361 TrainAcc 0.9700 TestAcc 0.9462 0.9250
epoch 1600 LossPred 0.1360 LossAtt 0.6161 TrainAcc 0.9700 TestAcc 0.9407 0.9450
epoch 1700 LossPred 0.1239 LossAtt 0.6204 TrainAcc 0.9700 TestAcc 0.9469 0.9300
epoch 1800 LossPred 0.1281 LossAtt 0.6097 TrainAcc 0.9600 TestAcc 0.9452 0.9250
epoch 1900 LossPred 0.1137 LossAtt 0.6203 TrainAcc 0.9700 TestAcc 0.9469 0.9400
epoch 2000 LossPred 0.1109 LossAtt 0.6281 TrainAcc 0.9700 TestAcc 0.9502 0.9300
epoch 2100 LossPred 0.1044 LossAtt 0.6174 TrainAcc 0.9900 TestAcc 0.9497 0.9600
epoch 2200 LossPred 0.1408 LossAtt 0.6255 TrainAcc 0.9500 TestAcc 0.9354 0.9350
epoch 2300 LossPred 0.1030 LossAtt 0.6126 TrainAcc 0.9800 TestAcc 0.9494 0.9650
epoch 2400 LossPred 0.0895 LossAtt 0.6085 TrainAcc 0.9800 TestAcc 0.9520 0.9500
epoch 2500 LossPred 0.0861 LossAtt 0.6040 TrainAcc 0.9700 TestAcc 0.9397 0.9550
Optimization Finished!
********** replication  35  **********
epoch   0 LossPred 1.4581 LossAtt 1.0455 TrainAcc 0.4500 TestAcc 0.4344 0.4750
epoch 100 LossPred 1.1180 LossAtt 0.5954 TrainAcc 0.5200 TestAcc 0.4822 0.5000
epoch 200 LossPred 0.9901 LossAtt 0.4968 TrainAcc 0.6100 TestAcc 0.5716 0.5850
epoch 300 LossPred 0.9718 LossAtt 0.4587 TrainAcc 0.6100 TestAcc 0.6069 0.5900
epoch 400 LossPred 0.9615 LossAtt 0.4573 TrainAcc 0.6100 TestAcc 0.6069 0.6100
epoch 500 LossPred 0.9561 LossAtt 0.4492 TrainAcc 0.6100 TestAcc 0.6069 0.6100
epoch 600 LossPred 0.9517 LossAtt 0.4264 TrainAcc 0.6100 TestAcc 0.6069 0.6100
epoch 700 LossPred 0.9416 LossAtt 0.4657 TrainAcc 0.6100 TestAcc 0.6069 0.6100
epoch 800 LossPred 0.9060 LossAtt 0.5427 TrainAcc 0.6700 TestAcc 0.5881 0.6550
epoch 900 LossPred 0.8653 LossAtt 0.5859 TrainAcc 0.6500 TestAcc 0.5490 0.6450
epoch 1000 LossPred 0.8497 LossAtt 0.5677 TrainAcc 0.6700 TestAcc 0.5626 0.6750
epoch 1100 LossPred 0.8197 LossAtt 0.6067 TrainAcc 0.7000 TestAcc 0.5588 0.6750
epoch 1200 LossPred 0.8043 LossAtt 0.5618 TrainAcc 0.7000 TestAcc 0.5551 0.6800
epoch 1300 LossPred 0.8030 LossAtt 0.5642 TrainAcc 0.6900 TestAcc 0.5553 0.6750
epoch 1400 LossPred 0.8024 LossAtt 0.5093 TrainAcc 0.7000 TestAcc 0.5571 0.6700
epoch 1500 LossPred 0.7990 LossAtt 0.4620 TrainAcc 0.7100 TestAcc 0.5581 0.6700
epoch 1600 LossPred 0.7985 LossAtt 0.4579 TrainAcc 0.7000 TestAcc 0.5593 0.6700
epoch 1700 LossPred 0.8017 LossAtt 0.4696 TrainAcc 0.7000 TestAcc 0.5581 0.6700
epoch 1800 LossPred 0.8024 LossAtt 0.4828 TrainAcc 0.7000 TestAcc 0.5611 0.6550
epoch 1900 LossPred 0.8044 LossAtt 0.4706 TrainAcc 0.6900 TestAcc 0.5538 0.6550
epoch 2000 LossPred 0.8141 LossAtt 0.4647 TrainAcc 0.6700 TestAcc 0.5523 0.6500
epoch 2100 LossPred 0.8067 LossAtt 0.4345 TrainAcc 0.6900 TestAcc 0.5558 0.6450
epoch 2200 LossPred 0.8027 LossAtt 0.4266 TrainAcc 0.7000 TestAcc 0.5631 0.6600
epoch 2300 LossPred 0.8033 LossAtt 0.3971 TrainAcc 0.7000 TestAcc 0.5633 0.6500
epoch 2400 LossPred 0.8062 LossAtt 0.4160 TrainAcc 0.6900 TestAcc 0.5561 0.6550
epoch 2500 LossPred 0.8139 LossAtt 0.4251 TrainAcc 0.6800 TestAcc 0.5521 0.6600
Optimization Finished!
********** replication  36  **********
epoch   0 LossPred 0.9766 LossAtt 1.0582 TrainAcc 0.6100 TestAcc 0.5713 0.6200
epoch 100 LossPred 0.8703 LossAtt 0.4733 TrainAcc 0.6600 TestAcc 0.5983 0.6500
epoch 200 LossPred 0.7997 LossAtt 0.4555 TrainAcc 0.7400 TestAcc 0.6171 0.7400
epoch 300 LossPred 0.7846 LossAtt 0.4692 TrainAcc 0.7400 TestAcc 0.6309 0.7300
epoch 400 LossPred 0.7594 LossAtt 0.4754 TrainAcc 0.7500 TestAcc 0.6459 0.7150
epoch 500 LossPred 0.7612 LossAtt 0.4907 TrainAcc 0.7500 TestAcc 0.6527 0.7200
epoch 600 LossPred 0.7596 LossAtt 0.4820 TrainAcc 0.7500 TestAcc 0.6532 0.7200
epoch 700 LossPred 0.7491 LossAtt 0.4853 TrainAcc 0.7500 TestAcc 0.6574 0.7050
epoch 800 LossPred 0.7419 LossAtt 0.4563 TrainAcc 0.7600 TestAcc 0.6579 0.7050
epoch 900 LossPred 0.7430 LossAtt 0.4540 TrainAcc 0.7400 TestAcc 0.6602 0.7100
epoch 1000 LossPred 0.7410 LossAtt 0.4441 TrainAcc 0.7600 TestAcc 0.6554 0.6950
epoch 1100 LossPred 0.7392 LossAtt 0.4492 TrainAcc 0.7400 TestAcc 0.6602 0.7000
epoch 1200 LossPred 0.7393 LossAtt 0.4261 TrainAcc 0.7600 TestAcc 0.6744 0.7150
epoch 1300 LossPred 0.7327 LossAtt 0.4216 TrainAcc 0.7500 TestAcc 0.6732 0.7050
epoch 1400 LossPred 0.7457 LossAtt 0.4010 TrainAcc 0.7500 TestAcc 0.6664 0.7050
epoch 1500 LossPred 0.7338 LossAtt 0.3818 TrainAcc 0.7600 TestAcc 0.6739 0.7100
epoch 1600 LossPred 0.7568 LossAtt 0.3890 TrainAcc 0.7400 TestAcc 0.6709 0.7400
epoch 1700 LossPred 0.7272 LossAtt 0.3782 TrainAcc 0.7500 TestAcc 0.6757 0.7200
epoch 1800 LossPred 0.7324 LossAtt 0.3919 TrainAcc 0.7500 TestAcc 0.6674 0.7250
epoch 1900 LossPred 0.7257 LossAtt 0.3812 TrainAcc 0.7500 TestAcc 0.6672 0.7400
epoch 2000 LossPred 0.7649 LossAtt 0.4027 TrainAcc 0.7500 TestAcc 0.6757 0.7500
epoch 2100 LossPred 0.7206 LossAtt 0.3844 TrainAcc 0.7600 TestAcc 0.6764 0.7550
epoch 2200 LossPred 0.7120 LossAtt 0.3821 TrainAcc 0.7700 TestAcc 0.6762 0.7450
epoch 2300 LossPred 0.7292 LossAtt 0.3820 TrainAcc 0.7600 TestAcc 0.6649 0.7500
epoch 2400 LossPred 0.7174 LossAtt 0.3747 TrainAcc 0.7400 TestAcc 0.6599 0.7200
epoch 2500 LossPred 0.7073 LossAtt 0.3900 TrainAcc 0.7300 TestAcc 0.6454 0.7250
Optimization Finished!
********** replication  37  **********
epoch   0 LossPred 1.2438 LossAtt 1.0559 TrainAcc 0.3800 TestAcc 0.5073 0.3800
epoch 100 LossPred 0.9029 LossAtt 0.4984 TrainAcc 0.6400 TestAcc 0.6086 0.6550
epoch 200 LossPred 0.8747 LossAtt 0.5178 TrainAcc 0.6500 TestAcc 0.6206 0.6600
epoch 300 LossPred 0.8122 LossAtt 0.5220 TrainAcc 0.7100 TestAcc 0.6537 0.7400
epoch 400 LossPred 0.3282 LossAtt 0.3696 TrainAcc 0.9200 TestAcc 0.8861 0.9200
epoch 500 LossPred 0.2827 LossAtt 0.3257 TrainAcc 0.9300 TestAcc 0.8966 0.9000
epoch 600 LossPred 0.2985 LossAtt 0.3183 TrainAcc 0.9300 TestAcc 0.8686 0.9200
epoch 700 LossPred 0.2166 LossAtt 0.3324 TrainAcc 0.9300 TestAcc 0.9004 0.9100
epoch 800 LossPred 0.1794 LossAtt 0.3283 TrainAcc 0.9500 TestAcc 0.9034 0.9200
epoch 900 LossPred 0.1982 LossAtt 0.3294 TrainAcc 0.9500 TestAcc 0.8989 0.9150
epoch 1000 LossPred 0.1581 LossAtt 0.3219 TrainAcc 0.9500 TestAcc 0.9169 0.9100
epoch 1100 LossPred 0.1771 LossAtt 0.3202 TrainAcc 0.9300 TestAcc 0.9212 0.9100
epoch 1200 LossPred 0.1441 LossAtt 0.3360 TrainAcc 0.9600 TestAcc 0.9244 0.9100
epoch 1300 LossPred 0.1244 LossAtt 0.3145 TrainAcc 0.9600 TestAcc 0.9314 0.9100
epoch 1400 LossPred 0.1135 LossAtt 0.3185 TrainAcc 0.9700 TestAcc 0.9277 0.9200
epoch 1500 LossPred 0.1236 LossAtt 0.3118 TrainAcc 0.9600 TestAcc 0.9262 0.9400
epoch 1600 LossPred 0.3635 LossAtt 0.3449 TrainAcc 0.8900 TestAcc 0.8308 0.8750
epoch 1700 LossPred 0.1064 LossAtt 0.3382 TrainAcc 0.9700 TestAcc 0.9257 0.9450
epoch 1800 LossPred 0.1151 LossAtt 0.2987 TrainAcc 0.9500 TestAcc 0.9417 0.9100
epoch 1900 LossPred 0.2693 LossAtt 0.2999 TrainAcc 0.9100 TestAcc 0.9034 0.8950
epoch 2000 LossPred 0.0899 LossAtt 0.2990 TrainAcc 0.9700 TestAcc 0.9627 0.9150
epoch 2100 LossPred 0.0965 LossAtt 0.3158 TrainAcc 0.9700 TestAcc 0.9434 0.9400
epoch 2200 LossPred 0.0925 LossAtt 0.3015 TrainAcc 0.9800 TestAcc 0.9322 0.9450
epoch 2300 LossPred 0.0707 LossAtt 0.2948 TrainAcc 0.9700 TestAcc 0.9655 0.9250
epoch 2400 LossPred 0.1454 LossAtt 0.2912 TrainAcc 0.9400 TestAcc 0.9354 0.9150
epoch 2500 LossPred 0.2310 LossAtt 0.2933 TrainAcc 0.9200 TestAcc 0.8671 0.9000
Optimization Finished!
********** replication  38  **********
epoch   0 LossPred 1.0750 LossAtt 1.0179 TrainAcc 0.5300 TestAcc 0.5546 0.5100
epoch 100 LossPred 0.8485 LossAtt 0.4484 TrainAcc 0.7100 TestAcc 0.5986 0.7100
epoch 200 LossPred 0.8261 LossAtt 0.4278 TrainAcc 0.7100 TestAcc 0.5986 0.7100
epoch 300 LossPred 0.8090 LossAtt 0.4415 TrainAcc 0.7100 TestAcc 0.5986 0.7100
epoch 400 LossPred 0.7913 LossAtt 0.4325 TrainAcc 0.7100 TestAcc 0.5986 0.7100
epoch 500 LossPred 0.7621 LossAtt 0.3930 TrainAcc 0.7100 TestAcc 0.5986 0.7100
epoch 600 LossPred 0.2545 LossAtt 0.3004 TrainAcc 0.9200 TestAcc 0.8726 0.9150
epoch 700 LossPred 0.1608 LossAtt 0.2924 TrainAcc 0.9600 TestAcc 0.9092 0.9250
epoch 800 LossPred 0.1356 LossAtt 0.2975 TrainAcc 0.9700 TestAcc 0.9132 0.9150
epoch 900 LossPred 0.1368 LossAtt 0.3006 TrainAcc 0.9700 TestAcc 0.9274 0.9350
epoch 1000 LossPred 0.1254 LossAtt 0.3274 TrainAcc 0.9700 TestAcc 0.9157 0.9250
epoch 1100 LossPred 0.1719 LossAtt 0.3276 TrainAcc 0.9400 TestAcc 0.9094 0.9300
epoch 1200 LossPred 0.1556 LossAtt 0.3761 TrainAcc 0.9700 TestAcc 0.9087 0.9150
epoch 1300 LossPred 0.1601 LossAtt 0.3522 TrainAcc 0.9600 TestAcc 0.9134 0.9200
epoch 1400 LossPred 0.2029 LossAtt 0.3298 TrainAcc 0.9400 TestAcc 0.8974 0.9250
epoch 1500 LossPred 0.1253 LossAtt 0.3498 TrainAcc 0.9700 TestAcc 0.9324 0.9300
epoch 1600 LossPred 0.1116 LossAtt 0.3568 TrainAcc 0.9600 TestAcc 0.9222 0.9350
epoch 1700 LossPred 0.1106 LossAtt 0.3402 TrainAcc 0.9600 TestAcc 0.9242 0.9300
epoch 1800 LossPred 0.0977 LossAtt 0.3380 TrainAcc 0.9700 TestAcc 0.9377 0.9400
epoch 1900 LossPred 0.1042 LossAtt 0.3451 TrainAcc 0.9700 TestAcc 0.9322 0.9400
epoch 2000 LossPred 0.1153 LossAtt 0.3508 TrainAcc 0.9700 TestAcc 0.9387 0.9350
epoch 2100 LossPred 0.1341 LossAtt 0.3379 TrainAcc 0.9700 TestAcc 0.9297 0.9500
epoch 2200 LossPred 0.1699 LossAtt 0.3552 TrainAcc 0.9500 TestAcc 0.9084 0.9300
epoch 2300 LossPred 0.1044 LossAtt 0.3501 TrainAcc 0.9700 TestAcc 0.9214 0.9150
epoch 2400 LossPred 0.1311 LossAtt 0.3630 TrainAcc 0.9600 TestAcc 0.9187 0.9100
epoch 2500 LossPred 0.1045 LossAtt 0.3613 TrainAcc 0.9700 TestAcc 0.9349 0.9450
Optimization Finished!
********** replication  39  **********
epoch   0 LossPred 1.3421 LossAtt 0.9925 TrainAcc 0.3300 TestAcc 0.4377 0.3700
epoch 100 LossPred 0.9391 LossAtt 0.4627 TrainAcc 0.7000 TestAcc 0.5538 0.6950
epoch 200 LossPred 0.7272 LossAtt 0.6035 TrainAcc 0.7700 TestAcc 0.6797 0.7450
epoch 300 LossPred 0.2888 LossAtt 0.5937 TrainAcc 0.9700 TestAcc 0.8956 0.9250
epoch 400 LossPred 0.2288 LossAtt 0.6094 TrainAcc 0.9600 TestAcc 0.8969 0.9300
epoch 500 LossPred 0.2049 LossAtt 0.5916 TrainAcc 0.9600 TestAcc 0.8969 0.9300
epoch 600 LossPred 0.1905 LossAtt 0.5810 TrainAcc 0.9600 TestAcc 0.8906 0.9300
epoch 700 LossPred 0.1737 LossAtt 0.5727 TrainAcc 0.9600 TestAcc 0.8956 0.9200
epoch 800 LossPred 0.1739 LossAtt 0.5720 TrainAcc 0.9300 TestAcc 0.8956 0.9000
epoch 900 LossPred 0.1582 LossAtt 0.5445 TrainAcc 0.9600 TestAcc 0.9029 0.9050
epoch 1000 LossPred 0.1764 LossAtt 0.5412 TrainAcc 0.9700 TestAcc 0.9142 0.9100
epoch 1100 LossPred 0.1520 LossAtt 0.5047 TrainAcc 0.9500 TestAcc 0.8991 0.9250
epoch 1200 LossPred 0.1873 LossAtt 0.4955 TrainAcc 0.9200 TestAcc 0.9132 0.9050
epoch 1300 LossPred 0.1427 LossAtt 0.4735 TrainAcc 0.9600 TestAcc 0.9027 0.9100
epoch 1400 LossPred 0.1409 LossAtt 0.4863 TrainAcc 0.9600 TestAcc 0.8926 0.9200
epoch 1500 LossPred 0.1416 LossAtt 0.4525 TrainAcc 0.9500 TestAcc 0.9017 0.9300
epoch 1600 LossPred 0.2037 LossAtt 0.4615 TrainAcc 0.9300 TestAcc 0.9222 0.8900
epoch 1700 LossPred 0.1984 LossAtt 0.4686 TrainAcc 0.9200 TestAcc 0.8819 0.9100
epoch 1800 LossPred 0.1245 LossAtt 0.4502 TrainAcc 0.9600 TestAcc 0.9039 0.9400
epoch 1900 LossPred 0.1306 LossAtt 0.4831 TrainAcc 0.9600 TestAcc 0.9202 0.9400
epoch 2000 LossPred 0.1262 LossAtt 0.4751 TrainAcc 0.9400 TestAcc 0.9044 0.9450
epoch 2100 LossPred 0.1148 LossAtt 0.4557 TrainAcc 0.9700 TestAcc 0.9332 0.9300
epoch 2200 LossPred 0.1207 LossAtt 0.4988 TrainAcc 0.9700 TestAcc 0.9214 0.9300
epoch 2300 LossPred 0.1097 LossAtt 0.4601 TrainAcc 0.9700 TestAcc 0.9264 0.9400
epoch 2400 LossPred 0.1063 LossAtt 0.4775 TrainAcc 0.9600 TestAcc 0.9159 0.9500
epoch 2500 LossPred 0.1680 LossAtt 0.4756 TrainAcc 0.9400 TestAcc 0.9382 0.9250
Optimization Finished!
********** replication  40  **********
epoch   0 LossPred 1.0849 LossAtt 1.0203 TrainAcc 0.5900 TestAcc 0.5883 0.5750
epoch 100 LossPred 0.9259 LossAtt 0.5230 TrainAcc 0.6000 TestAcc 0.5913 0.6050
epoch 200 LossPred 0.5495 LossAtt 0.4422 TrainAcc 0.8500 TestAcc 0.8534 0.8550
epoch 300 LossPred 0.3432 LossAtt 0.3548 TrainAcc 0.9200 TestAcc 0.8969 0.8700
epoch 400 LossPred 0.3043 LossAtt 0.3545 TrainAcc 0.9400 TestAcc 0.8859 0.8650
epoch 500 LossPred 0.3934 LossAtt 0.3687 TrainAcc 0.8700 TestAcc 0.8126 0.8450
epoch 600 LossPred 0.3084 LossAtt 0.3620 TrainAcc 0.9100 TestAcc 0.8468 0.8850
epoch 700 LossPred 0.2597 LossAtt 0.3599 TrainAcc 0.9200 TestAcc 0.8774 0.9000
epoch 800 LossPred 0.1490 LossAtt 0.3661 TrainAcc 0.9600 TestAcc 0.9464 0.9150
epoch 900 LossPred 0.1531 LossAtt 0.3923 TrainAcc 0.9600 TestAcc 0.9242 0.9050
epoch 1000 LossPred 0.1488 LossAtt 0.3680 TrainAcc 0.9700 TestAcc 0.9127 0.9400
epoch 1100 LossPred 0.2799 LossAtt 0.3840 TrainAcc 0.9100 TestAcc 0.8443 0.8750
epoch 1200 LossPred 0.1743 LossAtt 0.3705 TrainAcc 0.9400 TestAcc 0.8921 0.9250
epoch 1300 LossPred 0.2943 LossAtt 0.3607 TrainAcc 0.9000 TestAcc 0.8286 0.8850
epoch 1400 LossPred 0.2349 LossAtt 0.3465 TrainAcc 0.9400 TestAcc 0.8529 0.9150
epoch 1500 LossPred 0.1170 LossAtt 0.3545 TrainAcc 0.9700 TestAcc 0.9457 0.9450
epoch 1600 LossPred 0.0857 LossAtt 0.3602 TrainAcc 0.9800 TestAcc 0.9557 0.9500
epoch 1700 LossPred 0.0644 LossAtt 0.3328 TrainAcc 0.9900 TestAcc 0.9602 0.9600
epoch 1800 LossPred 0.0582 LossAtt 0.3415 TrainAcc 0.9900 TestAcc 0.9650 0.9650
epoch 1900 LossPred 0.0857 LossAtt 0.3455 TrainAcc 0.9800 TestAcc 0.9337 0.9700
epoch 2000 LossPred 0.0558 LossAtt 0.3373 TrainAcc 0.9900 TestAcc 0.9620 0.9700
epoch 2100 LossPred 0.0569 LossAtt 0.3268 TrainAcc 0.9900 TestAcc 0.9697 0.9600
epoch 2200 LossPred 0.0852 LossAtt 0.3132 TrainAcc 0.9800 TestAcc 0.9637 0.9550
epoch 2300 LossPred 0.0823 LossAtt 0.3015 TrainAcc 0.9700 TestAcc 0.9414 0.9450
epoch 2400 LossPred 0.0631 LossAtt 0.3096 TrainAcc 0.9900 TestAcc 0.9657 0.9500
epoch 2500 LossPred 0.1022 LossAtt 0.3260 TrainAcc 0.9700 TestAcc 0.9207 0.9650
Optimization Finished!
********** replication  41  **********
epoch   0 LossPred 1.1944 LossAtt 1.0139 TrainAcc 0.4600 TestAcc 0.4990 0.4600
epoch 100 LossPred 0.8500 LossAtt 0.5756 TrainAcc 0.6900 TestAcc 0.6021 0.6900
epoch 200 LossPred 0.7546 LossAtt 0.6253 TrainAcc 0.7100 TestAcc 0.6406 0.7050
epoch 300 LossPred 0.5484 LossAtt 0.5821 TrainAcc 0.8000 TestAcc 0.7733 0.8100
epoch 400 LossPred 0.4981 LossAtt 0.4904 TrainAcc 0.8100 TestAcc 0.8203 0.8250
epoch 500 LossPred 0.4565 LossAtt 0.3456 TrainAcc 0.8400 TestAcc 0.8486 0.8450
epoch 600 LossPred 0.4420 LossAtt 0.4195 TrainAcc 0.8500 TestAcc 0.8606 0.8750
epoch 700 LossPred 0.3721 LossAtt 0.4540 TrainAcc 0.9300 TestAcc 0.8874 0.8950
epoch 800 LossPred 0.2422 LossAtt 0.4921 TrainAcc 0.9500 TestAcc 0.9127 0.9100
epoch 900 LossPred 0.4230 LossAtt 0.4599 TrainAcc 0.8500 TestAcc 0.8196 0.8600
epoch 1000 LossPred 0.2884 LossAtt 0.4475 TrainAcc 0.9100 TestAcc 0.8919 0.8950
epoch 1100 LossPred 0.3766 LossAtt 0.4437 TrainAcc 0.8700 TestAcc 0.8456 0.8850
epoch 1200 LossPred 0.2989 LossAtt 0.4339 TrainAcc 0.9000 TestAcc 0.8884 0.9100
epoch 1300 LossPred 0.2537 LossAtt 0.4295 TrainAcc 0.9000 TestAcc 0.9054 0.8950
epoch 1400 LossPred 0.2427 LossAtt 0.4125 TrainAcc 0.9100 TestAcc 0.8939 0.9150
epoch 1500 LossPred 0.2815 LossAtt 0.4111 TrainAcc 0.9200 TestAcc 0.8939 0.8950
epoch 1600 LossPred 0.2745 LossAtt 0.3985 TrainAcc 0.9200 TestAcc 0.8904 0.9050
epoch 1700 LossPred 0.2213 LossAtt 0.3534 TrainAcc 0.9200 TestAcc 0.9162 0.9200
epoch 1800 LossPred 0.2354 LossAtt 0.3516 TrainAcc 0.9200 TestAcc 0.9064 0.9200
epoch 1900 LossPred 0.2251 LossAtt 0.3635 TrainAcc 0.9300 TestAcc 0.9179 0.9150
epoch 2000 LossPred 0.1943 LossAtt 0.3661 TrainAcc 0.9300 TestAcc 0.9084 0.9250
epoch 2100 LossPred 0.1811 LossAtt 0.3375 TrainAcc 0.9500 TestAcc 0.9399 0.9300
epoch 2200 LossPred 0.1884 LossAtt 0.3444 TrainAcc 0.9400 TestAcc 0.9467 0.9400
epoch 2300 LossPred 0.2069 LossAtt 0.3250 TrainAcc 0.9300 TestAcc 0.9162 0.9300
epoch 2400 LossPred 0.1536 LossAtt 0.3202 TrainAcc 0.9700 TestAcc 0.9547 0.9500
epoch 2500 LossPred 0.1578 LossAtt 0.3250 TrainAcc 0.9600 TestAcc 0.9697 0.9550
Optimization Finished!
********** replication  42  **********
epoch   0 LossPred 1.0679 LossAtt 0.9795 TrainAcc 0.3300 TestAcc 0.3899 0.3400
epoch 100 LossPred 0.9125 LossAtt 0.4771 TrainAcc 0.6700 TestAcc 0.6294 0.6600
epoch 200 LossPred 0.7297 LossAtt 0.5613 TrainAcc 0.7400 TestAcc 0.7252 0.7300
epoch 300 LossPred 0.3314 LossAtt 0.5356 TrainAcc 0.9000 TestAcc 0.8601 0.8900
epoch 400 LossPred 0.3103 LossAtt 0.5114 TrainAcc 0.8900 TestAcc 0.8541 0.8800
epoch 500 LossPred 0.2535 LossAtt 0.5298 TrainAcc 0.9300 TestAcc 0.8769 0.8950
epoch 600 LossPred 0.2313 LossAtt 0.5180 TrainAcc 0.9300 TestAcc 0.8839 0.9100
epoch 700 LossPred 0.2103 LossAtt 0.4911 TrainAcc 0.9400 TestAcc 0.8934 0.9100
epoch 800 LossPred 0.2128 LossAtt 0.4827 TrainAcc 0.9400 TestAcc 0.8761 0.9250
epoch 900 LossPred 0.1895 LossAtt 0.5119 TrainAcc 0.9500 TestAcc 0.8849 0.9200
epoch 1000 LossPred 0.1783 LossAtt 0.5009 TrainAcc 0.9500 TestAcc 0.8821 0.9200
epoch 1100 LossPred 0.1686 LossAtt 0.4669 TrainAcc 0.9500 TestAcc 0.9047 0.9200
epoch 1200 LossPred 0.1874 LossAtt 0.4561 TrainAcc 0.9500 TestAcc 0.9324 0.9150
epoch 1300 LossPred 0.1644 LossAtt 0.4588 TrainAcc 0.9600 TestAcc 0.9187 0.9250
epoch 1400 LossPred 0.1554 LossAtt 0.4689 TrainAcc 0.9600 TestAcc 0.9119 0.9250
epoch 1500 LossPred 0.1693 LossAtt 0.4527 TrainAcc 0.9500 TestAcc 0.8804 0.9250
epoch 1600 LossPred 0.1480 LossAtt 0.4554 TrainAcc 0.9600 TestAcc 0.8986 0.9350
epoch 1700 LossPred 0.1420 LossAtt 0.4456 TrainAcc 0.9600 TestAcc 0.9059 0.9400
epoch 1800 LossPred 0.1237 LossAtt 0.4161 TrainAcc 0.9600 TestAcc 0.9249 0.9500
epoch 1900 LossPred 0.1189 LossAtt 0.4293 TrainAcc 0.9700 TestAcc 0.9427 0.9500
epoch 2000 LossPred 0.1280 LossAtt 0.4059 TrainAcc 0.9600 TestAcc 0.9489 0.9350
epoch 2100 LossPred 0.0827 LossAtt 0.3933 TrainAcc 0.9900 TestAcc 0.9407 0.9750
epoch 2200 LossPred 0.0885 LossAtt 0.4047 TrainAcc 0.9800 TestAcc 0.9570 0.9650
epoch 2300 LossPred 0.0783 LossAtt 0.4091 TrainAcc 0.9800 TestAcc 0.9279 0.9700
epoch 2400 LossPred 0.0835 LossAtt 0.3947 TrainAcc 0.9900 TestAcc 0.9532 0.9600
epoch 2500 LossPred 0.0797 LossAtt 0.3714 TrainAcc 0.9900 TestAcc 0.9482 0.9600
Optimization Finished!
********** replication  43  **********
epoch   0 LossPred 1.1016 LossAtt 1.0487 TrainAcc 0.4700 TestAcc 0.5383 0.4650
epoch 100 LossPred 0.8614 LossAtt 0.5473 TrainAcc 0.6900 TestAcc 0.6049 0.7100
epoch 200 LossPred 0.6191 LossAtt 0.6776 TrainAcc 0.7600 TestAcc 0.7007 0.7450
epoch 300 LossPred 0.2654 LossAtt 0.6816 TrainAcc 0.9400 TestAcc 0.9102 0.9100
epoch 400 LossPred 0.1847 LossAtt 0.6756 TrainAcc 0.9600 TestAcc 0.9437 0.9150
epoch 500 LossPred 0.1332 LossAtt 0.6184 TrainAcc 0.9800 TestAcc 0.9492 0.9250
epoch 600 LossPred 0.1024 LossAtt 0.5694 TrainAcc 0.9900 TestAcc 0.9494 0.9400
epoch 700 LossPred 0.0916 LossAtt 0.5682 TrainAcc 0.9800 TestAcc 0.9477 0.9500
epoch 800 LossPred 0.0795 LossAtt 0.5478 TrainAcc 0.9900 TestAcc 0.9477 0.9500
epoch 900 LossPred 0.0842 LossAtt 0.5422 TrainAcc 0.9800 TestAcc 0.9357 0.9500
epoch 1000 LossPred 0.0702 LossAtt 0.5450 TrainAcc 0.9800 TestAcc 0.9407 0.9650
epoch 1100 LossPred 0.0717 LossAtt 0.5341 TrainAcc 0.9900 TestAcc 0.9377 0.9550
epoch 1200 LossPred 0.0751 LossAtt 0.5396 TrainAcc 0.9800 TestAcc 0.9439 0.9400
epoch 1300 LossPred 0.0630 LossAtt 0.5338 TrainAcc 0.9900 TestAcc 0.9394 0.9500
epoch 1400 LossPred 0.0601 LossAtt 0.5154 TrainAcc 0.9900 TestAcc 0.9397 0.9500
epoch 1500 LossPred 0.0593 LossAtt 0.5353 TrainAcc 0.9800 TestAcc 0.9392 0.9500
epoch 1600 LossPred 0.0559 LossAtt 0.5460 TrainAcc 0.9900 TestAcc 0.9374 0.9500
epoch 1700 LossPred 0.0541 LossAtt 0.5137 TrainAcc 0.9900 TestAcc 0.9359 0.9550
epoch 1800 LossPred 0.1022 LossAtt 0.5428 TrainAcc 0.9800 TestAcc 0.9262 0.9250
epoch 1900 LossPred 0.0568 LossAtt 0.5395 TrainAcc 0.9900 TestAcc 0.9224 0.9500
epoch 2000 LossPred 0.0626 LossAtt 0.5198 TrainAcc 0.9800 TestAcc 0.9162 0.9500
epoch 2100 LossPred 0.0528 LossAtt 0.5154 TrainAcc 0.9900 TestAcc 0.9207 0.9550
epoch 2200 LossPred 0.0499 LossAtt 0.5173 TrainAcc 0.9900 TestAcc 0.9192 0.9550
epoch 2300 LossPred 0.0482 LossAtt 0.4958 TrainAcc 0.9900 TestAcc 0.9222 0.9500
epoch 2400 LossPred 0.0509 LossAtt 0.5189 TrainAcc 0.9900 TestAcc 0.9127 0.9450
epoch 2500 LossPred 0.0482 LossAtt 0.5239 TrainAcc 0.9900 TestAcc 0.9159 0.9600
Optimization Finished!
********** replication  44  **********
epoch   0 LossPred 1.0833 LossAtt 1.0366 TrainAcc 0.5900 TestAcc 0.5566 0.5850
epoch 100 LossPred 0.9561 LossAtt 0.5178 TrainAcc 0.6200 TestAcc 0.5591 0.6200
epoch 200 LossPred 0.8878 LossAtt 0.5595 TrainAcc 0.6700 TestAcc 0.5756 0.6600
epoch 300 LossPred 0.7467 LossAtt 0.5754 TrainAcc 0.7600 TestAcc 0.5833 0.7100
epoch 400 LossPred 0.7205 LossAtt 0.5638 TrainAcc 0.7500 TestAcc 0.5908 0.7200
epoch 500 LossPred 0.7006 LossAtt 0.5748 TrainAcc 0.7500 TestAcc 0.5873 0.7250
epoch 600 LossPred 0.6904 LossAtt 0.5460 TrainAcc 0.7700 TestAcc 0.5868 0.7450
epoch 700 LossPred 0.6806 LossAtt 0.5266 TrainAcc 0.8000 TestAcc 0.5956 0.7600
epoch 800 LossPred 0.6709 LossAtt 0.5282 TrainAcc 0.8100 TestAcc 0.5963 0.7550
epoch 900 LossPred 0.6647 LossAtt 0.5080 TrainAcc 0.8100 TestAcc 0.5961 0.7700
epoch 1000 LossPred 0.6565 LossAtt 0.5127 TrainAcc 0.8100 TestAcc 0.5978 0.7700
epoch 1100 LossPred 0.6380 LossAtt 0.5203 TrainAcc 0.8000 TestAcc 0.5941 0.7600
epoch 1200 LossPred 0.6223 LossAtt 0.5290 TrainAcc 0.8000 TestAcc 0.5908 0.7700
epoch 1300 LossPred 0.6067 LossAtt 0.5425 TrainAcc 0.8000 TestAcc 0.5948 0.7650
epoch 1400 LossPred 0.5970 LossAtt 0.5645 TrainAcc 0.8000 TestAcc 0.5941 0.7600
epoch 1500 LossPred 0.5948 LossAtt 0.5348 TrainAcc 0.7800 TestAcc 0.5951 0.7750
epoch 1600 LossPred 0.5788 LossAtt 0.5734 TrainAcc 0.8000 TestAcc 0.5931 0.7750
epoch 1700 LossPred 0.5765 LossAtt 0.5069 TrainAcc 0.8200 TestAcc 0.5941 0.7900
epoch 1800 LossPred 0.5684 LossAtt 0.5318 TrainAcc 0.8200 TestAcc 0.5928 0.7750
epoch 1900 LossPred 0.5678 LossAtt 0.5012 TrainAcc 0.8200 TestAcc 0.5941 0.7800
epoch 2000 LossPred 0.5622 LossAtt 0.5073 TrainAcc 0.8200 TestAcc 0.5928 0.7900
epoch 2100 LossPred 0.5604 LossAtt 0.4840 TrainAcc 0.8200 TestAcc 0.5948 0.7900
epoch 2200 LossPred 0.5680 LossAtt 0.5229 TrainAcc 0.8300 TestAcc 0.5898 0.8050
epoch 2300 LossPred 0.5425 LossAtt 0.5118 TrainAcc 0.8300 TestAcc 0.5871 0.8000
epoch 2400 LossPred 0.5511 LossAtt 0.5148 TrainAcc 0.8200 TestAcc 0.5886 0.7950
epoch 2500 LossPred 0.5338 LossAtt 0.5523 TrainAcc 0.8300 TestAcc 0.5891 0.7900
Optimization Finished!
********** replication  45  **********
epoch   0 LossPred 1.1104 LossAtt 0.9984 TrainAcc 0.5400 TestAcc 0.5165 0.5450
epoch 100 LossPred 0.9019 LossAtt 0.4956 TrainAcc 0.6400 TestAcc 0.5953 0.6350
epoch 200 LossPred 0.8566 LossAtt 0.4934 TrainAcc 0.6400 TestAcc 0.5953 0.6400
epoch 300 LossPred 0.4775 LossAtt 0.5702 TrainAcc 0.8500 TestAcc 0.8308 0.8550
epoch 400 LossPred 0.3224 LossAtt 0.5235 TrainAcc 0.9000 TestAcc 0.8874 0.9100
epoch 500 LossPred 0.1859 LossAtt 0.4920 TrainAcc 0.9600 TestAcc 0.9132 0.9450
epoch 600 LossPred 0.1630 LossAtt 0.4900 TrainAcc 0.9500 TestAcc 0.9107 0.9500
epoch 700 LossPred 0.1707 LossAtt 0.4984 TrainAcc 0.9500 TestAcc 0.8911 0.9150
epoch 800 LossPred 0.1712 LossAtt 0.4979 TrainAcc 0.9400 TestAcc 0.8859 0.9150
epoch 900 LossPred 0.2077 LossAtt 0.4859 TrainAcc 0.9300 TestAcc 0.8694 0.8850
epoch 1000 LossPred 0.1159 LossAtt 0.4816 TrainAcc 0.9700 TestAcc 0.9402 0.9450
epoch 1100 LossPred 0.1209 LossAtt 0.4953 TrainAcc 0.9700 TestAcc 0.9454 0.9600
epoch 1200 LossPred 0.0859 LossAtt 0.4755 TrainAcc 0.9900 TestAcc 0.9627 0.9650
epoch 1300 LossPred 0.0766 LossAtt 0.4901 TrainAcc 0.9900 TestAcc 0.9652 0.9650
epoch 1400 LossPred 0.0839 LossAtt 0.5005 TrainAcc 0.9900 TestAcc 0.9582 0.9700
epoch 1500 LossPred 0.0815 LossAtt 0.4954 TrainAcc 0.9800 TestAcc 0.9550 0.9700
epoch 1600 LossPred 0.0611 LossAtt 0.5123 TrainAcc 0.9900 TestAcc 0.9695 0.9700
epoch 1700 LossPred 0.0435 LossAtt 0.5183 TrainAcc 1.0000 TestAcc 0.9710 0.9850
Optimization Finished!
********** replication  46  **********
epoch   0 LossPred 1.0489 LossAtt 1.0611 TrainAcc 0.5000 TestAcc 0.5115 0.4800
epoch 100 LossPred 0.8712 LossAtt 0.3642 TrainAcc 0.7000 TestAcc 0.6009 0.7000
epoch 200 LossPred 0.8418 LossAtt 0.2957 TrainAcc 0.7000 TestAcc 0.6009 0.7000
epoch 300 LossPred 0.8232 LossAtt 0.3072 TrainAcc 0.7000 TestAcc 0.6009 0.7000
epoch 400 LossPred 0.7663 LossAtt 0.4811 TrainAcc 0.7000 TestAcc 0.6009 0.7000
epoch 500 LossPred 0.3815 LossAtt 0.5160 TrainAcc 0.8700 TestAcc 0.8458 0.8250
epoch 600 LossPred 0.3512 LossAtt 0.4577 TrainAcc 0.8700 TestAcc 0.8526 0.8150
epoch 700 LossPred 0.3392 LossAtt 0.4252 TrainAcc 0.8900 TestAcc 0.8468 0.8200
epoch 800 LossPred 0.2954 LossAtt 0.4512 TrainAcc 0.8700 TestAcc 0.8483 0.8400
epoch 900 LossPred 0.3054 LossAtt 0.3972 TrainAcc 0.8800 TestAcc 0.8516 0.8300
epoch 1000 LossPred 0.2872 LossAtt 0.3892 TrainAcc 0.8800 TestAcc 0.8493 0.8350
epoch 1100 LossPred 0.2858 LossAtt 0.3774 TrainAcc 0.8800 TestAcc 0.8509 0.8350
epoch 1200 LossPred 0.2919 LossAtt 0.3692 TrainAcc 0.8800 TestAcc 0.8516 0.8200
epoch 1300 LossPred 0.2899 LossAtt 0.3881 TrainAcc 0.8800 TestAcc 0.8516 0.8350
epoch 1400 LossPred 0.3049 LossAtt 0.3680 TrainAcc 0.8800 TestAcc 0.8496 0.8350
epoch 1500 LossPred 0.2725 LossAtt 0.3542 TrainAcc 0.8900 TestAcc 0.8526 0.8300
epoch 1600 LossPred 0.3104 LossAtt 0.3696 TrainAcc 0.8700 TestAcc 0.8493 0.8450
epoch 1700 LossPred 0.2669 LossAtt 0.3478 TrainAcc 0.8800 TestAcc 0.8564 0.8400
epoch 1800 LossPred 0.2895 LossAtt 0.3822 TrainAcc 0.8800 TestAcc 0.8534 0.8450
epoch 1900 LossPred 0.2466 LossAtt 0.3792 TrainAcc 0.9000 TestAcc 0.8629 0.8550
epoch 2000 LossPred 0.2498 LossAtt 0.3710 TrainAcc 0.9200 TestAcc 0.8694 0.8450
epoch 2100 LossPred 0.2610 LossAtt 0.3887 TrainAcc 0.8800 TestAcc 0.8609 0.8550
epoch 2200 LossPred 0.2408 LossAtt 0.3833 TrainAcc 0.9000 TestAcc 0.8649 0.8800
epoch 2300 LossPred 0.2338 LossAtt 0.3853 TrainAcc 0.9000 TestAcc 0.8681 0.8800
epoch 2400 LossPred 0.2332 LossAtt 0.3587 TrainAcc 0.9000 TestAcc 0.8664 0.8700
epoch 2500 LossPred 0.2259 LossAtt 0.3592 TrainAcc 0.9000 TestAcc 0.8671 0.8850
Optimization Finished!
********** replication  47  **********
epoch   0 LossPred 1.1804 LossAtt 1.0280 TrainAcc 0.4700 TestAcc 0.4462 0.4350
epoch 100 LossPred 0.9775 LossAtt 0.3931 TrainAcc 0.5900 TestAcc 0.6044 0.5850
epoch 200 LossPred 0.9435 LossAtt 0.3829 TrainAcc 0.5900 TestAcc 0.6044 0.6000
epoch 300 LossPred 0.8717 LossAtt 0.4571 TrainAcc 0.6500 TestAcc 0.6376 0.6100
epoch 400 LossPred 0.4569 LossAtt 0.4261 TrainAcc 0.8600 TestAcc 0.8641 0.8650
epoch 500 LossPred 0.3973 LossAtt 0.4367 TrainAcc 0.8700 TestAcc 0.8699 0.8600
epoch 600 LossPred 0.3661 LossAtt 0.4134 TrainAcc 0.8700 TestAcc 0.8641 0.8850
epoch 700 LossPred 0.3445 LossAtt 0.4536 TrainAcc 0.8700 TestAcc 0.8789 0.8900
epoch 800 LossPred 0.3043 LossAtt 0.4106 TrainAcc 0.8800 TestAcc 0.8906 0.8900
epoch 900 LossPred 0.3531 LossAtt 0.4270 TrainAcc 0.9100 TestAcc 0.8443 0.8700
epoch 1000 LossPred 0.2407 LossAtt 0.4170 TrainAcc 0.9200 TestAcc 0.9117 0.9350
epoch 1100 LossPred 0.1933 LossAtt 0.4190 TrainAcc 0.9300 TestAcc 0.9209 0.9400
epoch 1200 LossPred 0.1927 LossAtt 0.4427 TrainAcc 0.9400 TestAcc 0.9099 0.9300
epoch 1300 LossPred 0.3169 LossAtt 0.4522 TrainAcc 0.8800 TestAcc 0.8699 0.8600
epoch 1400 LossPred 0.1690 LossAtt 0.4446 TrainAcc 0.9600 TestAcc 0.9454 0.9500
epoch 1500 LossPred 0.3321 LossAtt 0.4495 TrainAcc 0.8900 TestAcc 0.8556 0.8750
epoch 1600 LossPred 0.1448 LossAtt 0.4322 TrainAcc 0.9600 TestAcc 0.9294 0.9450
epoch 1700 LossPred 0.2614 LossAtt 0.4597 TrainAcc 0.9100 TestAcc 0.8989 0.8950
epoch 1800 LossPred 0.1006 LossAtt 0.4429 TrainAcc 0.9800 TestAcc 0.9532 0.9550
epoch 1900 LossPred 0.1350 LossAtt 0.4376 TrainAcc 0.9500 TestAcc 0.9307 0.9350
epoch 2000 LossPred 0.2116 LossAtt 0.4352 TrainAcc 0.9500 TestAcc 0.9114 0.9050
epoch 2100 LossPred 0.2017 LossAtt 0.4330 TrainAcc 0.9200 TestAcc 0.8991 0.9050
epoch 2200 LossPred 0.0638 LossAtt 0.4359 TrainAcc 0.9800 TestAcc 0.9655 0.9650
epoch 2300 LossPred 0.2557 LossAtt 0.4336 TrainAcc 0.9100 TestAcc 0.8724 0.8750
epoch 2400 LossPred 0.2407 LossAtt 0.4538 TrainAcc 0.9200 TestAcc 0.8799 0.9050
epoch 2500 LossPred 0.0869 LossAtt 0.4209 TrainAcc 0.9900 TestAcc 0.9482 0.9700
Optimization Finished!
********** replication  48  **********
epoch   0 LossPred 1.0448 LossAtt 1.0630 TrainAcc 0.5800 TestAcc 0.5733 0.5650
epoch 100 LossPred 0.9101 LossAtt 0.6194 TrainAcc 0.6000 TestAcc 0.5996 0.6200
epoch 200 LossPred 0.8755 LossAtt 0.6830 TrainAcc 0.6100 TestAcc 0.5458 0.6050
epoch 300 LossPred 0.7830 LossAtt 0.7556 TrainAcc 0.6700 TestAcc 0.6341 0.6800
epoch 400 LossPred 0.3048 LossAtt 0.6908 TrainAcc 0.9100 TestAcc 0.8278 0.8900
epoch 500 LossPred 0.1230 LossAtt 0.7193 TrainAcc 0.9800 TestAcc 0.9052 0.9400
epoch 600 LossPred 0.1080 LossAtt 0.7139 TrainAcc 0.9700 TestAcc 0.8861 0.9500
epoch 700 LossPred 0.0988 LossAtt 0.6917 TrainAcc 0.9800 TestAcc 0.8789 0.9500
epoch 800 LossPred 0.0873 LossAtt 0.7046 TrainAcc 0.9700 TestAcc 0.8896 0.9550
epoch 900 LossPred 0.1365 LossAtt 0.6803 TrainAcc 0.9600 TestAcc 0.8644 0.9350
epoch 1000 LossPred 0.0490 LossAtt 0.6785 TrainAcc 0.9900 TestAcc 0.9084 0.9550
epoch 1100 LossPred 0.0559 LossAtt 0.6752 TrainAcc 0.9800 TestAcc 0.8994 0.9450
epoch 1200 LossPred 0.0444 LossAtt 0.6774 TrainAcc 0.9900 TestAcc 0.9007 0.9550
epoch 1300 LossPred 0.0434 LossAtt 0.6545 TrainAcc 0.9900 TestAcc 0.9017 0.9500
epoch 1400 LossPred 0.0478 LossAtt 0.6790 TrainAcc 0.9800 TestAcc 0.9129 0.9550
epoch 1500 LossPred 0.0628 LossAtt 0.6346 TrainAcc 0.9700 TestAcc 0.8941 0.9500
epoch 1600 LossPred 0.0838 LossAtt 0.6454 TrainAcc 0.9700 TestAcc 0.8909 0.9650
epoch 1700 LossPred 0.0404 LossAtt 0.5947 TrainAcc 0.9900 TestAcc 0.8976 0.9750
epoch 1800 LossPred 0.1517 LossAtt 0.5947 TrainAcc 0.9600 TestAcc 0.8654 0.9300
epoch 1900 LossPred 0.0372 LossAtt 0.5626 TrainAcc 0.9900 TestAcc 0.8894 0.9700
epoch 2000 LossPred 0.1941 LossAtt 0.5642 TrainAcc 0.9200 TestAcc 0.8956 0.9150
epoch 2100 LossPred 0.0383 LossAtt 0.5557 TrainAcc 0.9900 TestAcc 0.8969 0.9650
epoch 2200 LossPred 0.0365 LossAtt 0.5507 TrainAcc 0.9900 TestAcc 0.8944 0.9750
epoch 2300 LossPred 0.0652 LossAtt 0.5316 TrainAcc 0.9800 TestAcc 0.8966 0.9600
epoch 2400 LossPred 0.0516 LossAtt 0.5221 TrainAcc 0.9800 TestAcc 0.9074 0.9700
epoch 2500 LossPred 0.0991 LossAtt 0.5124 TrainAcc 0.9600 TestAcc 0.8904 0.9700
Optimization Finished!
********** replication  49  **********
epoch   0 LossPred 1.0724 LossAtt 1.0198 TrainAcc 0.5400 TestAcc 0.4772 0.5400
epoch 100 LossPred 0.9799 LossAtt 0.5221 TrainAcc 0.5500 TestAcc 0.5173 0.5500
epoch 200 LossPred 0.8742 LossAtt 0.5267 TrainAcc 0.7200 TestAcc 0.7165 0.7100
epoch 300 LossPred 0.4249 LossAtt 0.5832 TrainAcc 0.9100 TestAcc 0.8736 0.9000
epoch 400 LossPred 0.3428 LossAtt 0.5656 TrainAcc 0.9100 TestAcc 0.8724 0.9050
epoch 500 LossPred 0.3094 LossAtt 0.5147 TrainAcc 0.9200 TestAcc 0.8756 0.9150
epoch 600 LossPred 0.2881 LossAtt 0.4516 TrainAcc 0.9200 TestAcc 0.8659 0.9250
epoch 700 LossPred 0.3640 LossAtt 0.4432 TrainAcc 0.8800 TestAcc 0.8579 0.9000
epoch 800 LossPred 0.2820 LossAtt 0.4405 TrainAcc 0.9000 TestAcc 0.8674 0.9300
epoch 900 LossPred 0.2644 LossAtt 0.4250 TrainAcc 0.9100 TestAcc 0.8669 0.9250
epoch 1000 LossPred 0.2927 LossAtt 0.4478 TrainAcc 0.9100 TestAcc 0.8809 0.9200
epoch 1100 LossPred 0.2734 LossAtt 0.4095 TrainAcc 0.9100 TestAcc 0.8684 0.9200
epoch 1200 LossPred 0.3388 LossAtt 0.3868 TrainAcc 0.8800 TestAcc 0.8511 0.9000
epoch 1300 LossPred 0.2673 LossAtt 0.3864 TrainAcc 0.9000 TestAcc 0.8819 0.9250
epoch 1400 LossPred 0.3324 LossAtt 0.4062 TrainAcc 0.8900 TestAcc 0.8594 0.8650
epoch 1500 LossPred 0.2985 LossAtt 0.4046 TrainAcc 0.8800 TestAcc 0.8629 0.8800
epoch 1600 LossPred 0.2689 LossAtt 0.3842 TrainAcc 0.9000 TestAcc 0.8679 0.8800
epoch 1700 LossPred 0.2541 LossAtt 0.3795 TrainAcc 0.9100 TestAcc 0.8854 0.9100
epoch 1800 LossPred 0.2757 LossAtt 0.3749 TrainAcc 0.9000 TestAcc 0.8709 0.9100
epoch 1900 LossPred 0.2237 LossAtt 0.3648 TrainAcc 0.9300 TestAcc 0.8849 0.9150
epoch 2000 LossPred 0.2436 LossAtt 0.3622 TrainAcc 0.8900 TestAcc 0.8939 0.9150
epoch 2100 LossPred 0.2434 LossAtt 0.3280 TrainAcc 0.9000 TestAcc 0.8819 0.9250
epoch 2200 LossPred 0.2562 LossAtt 0.3283 TrainAcc 0.9000 TestAcc 0.8859 0.9300
epoch 2300 LossPred 0.2229 LossAtt 0.3526 TrainAcc 0.9200 TestAcc 0.8764 0.8950
epoch 2400 LossPred 0.2006 LossAtt 0.3114 TrainAcc 0.9200 TestAcc 0.8836 0.8950
epoch 2500 LossPred 0.1875 LossAtt 0.3309 TrainAcc 0.9300 TestAcc 0.9017 0.9350
Optimization Finished!
********** replication  50  **********
epoch   0 LossPred 1.0417 LossAtt 0.9985 TrainAcc 0.5100 TestAcc 0.5490 0.5100
epoch 100 LossPred 0.9599 LossAtt 0.3801 TrainAcc 0.6000 TestAcc 0.5958 0.6000
epoch 200 LossPred 0.9439 LossAtt 0.3524 TrainAcc 0.6000 TestAcc 0.5958 0.6000
epoch 300 LossPred 0.7768 LossAtt 0.4682 TrainAcc 0.7500 TestAcc 0.6954 0.7100
epoch 400 LossPred 0.2366 LossAtt 0.3316 TrainAcc 0.9300 TestAcc 0.8639 0.8900
epoch 500 LossPred 0.2021 LossAtt 0.2635 TrainAcc 0.9300 TestAcc 0.8719 0.9000
epoch 600 LossPred 0.1927 LossAtt 0.2527 TrainAcc 0.9400 TestAcc 0.8769 0.9000
epoch 700 LossPred 0.1871 LossAtt 0.2402 TrainAcc 0.9300 TestAcc 0.8766 0.8950
epoch 800 LossPred 0.1924 LossAtt 0.2327 TrainAcc 0.9400 TestAcc 0.8709 0.8950
epoch 900 LossPred 0.1810 LossAtt 0.2319 TrainAcc 0.9400 TestAcc 0.8814 0.9050
epoch 1000 LossPred 0.1885 LossAtt 0.2440 TrainAcc 0.9400 TestAcc 0.8706 0.8950
epoch 1100 LossPred 0.1800 LossAtt 0.2427 TrainAcc 0.9400 TestAcc 0.8729 0.9050
epoch 1200 LossPred 0.1927 LossAtt 0.2418 TrainAcc 0.9500 TestAcc 0.8706 0.9000
epoch 1300 LossPred 0.1853 LossAtt 0.2274 TrainAcc 0.9400 TestAcc 0.8791 0.8950
epoch 1400 LossPred 0.1793 LossAtt 0.2402 TrainAcc 0.9400 TestAcc 0.8741 0.9050
epoch 1500 LossPred 0.1806 LossAtt 0.2622 TrainAcc 0.9400 TestAcc 0.8731 0.9050
epoch 1600 LossPred 0.1799 LossAtt 0.2401 TrainAcc 0.9300 TestAcc 0.8806 0.9050
epoch 1700 LossPred 0.1865 LossAtt 0.2411 TrainAcc 0.9500 TestAcc 0.8714 0.9000
epoch 1800 LossPred 0.1964 LossAtt 0.2374 TrainAcc 0.9300 TestAcc 0.8679 0.8950
epoch 1900 LossPred 0.1808 LossAtt 0.2546 TrainAcc 0.9400 TestAcc 0.8796 0.9100
epoch 2000 LossPred 0.1777 LossAtt 0.2383 TrainAcc 0.9400 TestAcc 0.8771 0.9100
epoch 2100 LossPred 0.1767 LossAtt 0.2439 TrainAcc 0.9400 TestAcc 0.8786 0.9050
epoch 2200 LossPred 0.1763 LossAtt 0.2814 TrainAcc 0.9400 TestAcc 0.8771 0.9050
epoch 2300 LossPred 0.1931 LossAtt 0.2703 TrainAcc 0.9300 TestAcc 0.8781 0.9000
epoch 2400 LossPred 0.1790 LossAtt 0.2699 TrainAcc 0.9500 TestAcc 0.8804 0.9150
epoch 2500 LossPred 0.1790 LossAtt 0.2804 TrainAcc 0.9400 TestAcc 0.8816 0.9050
Optimization Finished!
********** replication  51  **********
epoch   0 LossPred 1.2370 LossAtt 1.0161 TrainAcc 0.4300 TestAcc 0.4307 0.4400
epoch 100 LossPred 0.9895 LossAtt 0.5156 TrainAcc 0.5600 TestAcc 0.5470 0.5650
epoch 200 LossPred 0.9213 LossAtt 0.5190 TrainAcc 0.6400 TestAcc 0.6026 0.6300
epoch 300 LossPred 0.8841 LossAtt 0.6122 TrainAcc 0.6300 TestAcc 0.6076 0.6150
epoch 400 LossPred 0.8616 LossAtt 0.6426 TrainAcc 0.6100 TestAcc 0.6036 0.6200
epoch 500 LossPred 0.8320 LossAtt 0.7043 TrainAcc 0.6800 TestAcc 0.5868 0.6700
epoch 600 LossPred 0.7834 LossAtt 0.6446 TrainAcc 0.7100 TestAcc 0.5833 0.7000
epoch 700 LossPred 0.7646 LossAtt 0.6365 TrainAcc 0.7200 TestAcc 0.5988 0.6900
epoch 800 LossPred 0.7344 LossAtt 0.6261 TrainAcc 0.7300 TestAcc 0.5853 0.7050
epoch 900 LossPred 0.6845 LossAtt 0.6449 TrainAcc 0.7800 TestAcc 0.5768 0.7150
epoch 1000 LossPred 0.6511 LossAtt 0.6318 TrainAcc 0.7800 TestAcc 0.5788 0.7050
epoch 1100 LossPred 0.6496 LossAtt 0.6598 TrainAcc 0.7800 TestAcc 0.5701 0.7100
epoch 1200 LossPred 0.6443 LossAtt 0.6726 TrainAcc 0.7800 TestAcc 0.5638 0.7400
epoch 1300 LossPred 0.6204 LossAtt 0.6315 TrainAcc 0.8000 TestAcc 0.5788 0.7150
epoch 1400 LossPred 0.6081 LossAtt 0.6668 TrainAcc 0.7900 TestAcc 0.5758 0.7100
epoch 1500 LossPred 0.6020 LossAtt 0.6558 TrainAcc 0.7900 TestAcc 0.5766 0.7150
epoch 1600 LossPred 0.6018 LossAtt 0.6505 TrainAcc 0.8000 TestAcc 0.5756 0.7100
epoch 1700 LossPred 0.5774 LossAtt 0.6658 TrainAcc 0.8000 TestAcc 0.5801 0.7200
epoch 1800 LossPred 0.5753 LossAtt 0.6973 TrainAcc 0.8200 TestAcc 0.5886 0.7250
epoch 1900 LossPred 0.5739 LossAtt 0.7085 TrainAcc 0.8000 TestAcc 0.5913 0.7200
epoch 2000 LossPred 0.6159 LossAtt 0.6705 TrainAcc 0.8000 TestAcc 0.5881 0.7350
epoch 2100 LossPred 0.6127 LossAtt 0.6687 TrainAcc 0.7900 TestAcc 0.5933 0.7150
epoch 2200 LossPred 0.6074 LossAtt 0.6556 TrainAcc 0.8000 TestAcc 0.5993 0.7000
epoch 2300 LossPred 0.6012 LossAtt 0.6658 TrainAcc 0.7900 TestAcc 0.5958 0.7200
epoch 2400 LossPred 0.5790 LossAtt 0.6860 TrainAcc 0.8000 TestAcc 0.5976 0.7050
epoch 2500 LossPred 0.5571 LossAtt 0.6639 TrainAcc 0.7800 TestAcc 0.5896 0.7250
Optimization Finished!
********** replication  52  **********
epoch   0 LossPred 0.9975 LossAtt 1.0257 TrainAcc 0.5500 TestAcc 0.5518 0.5250
epoch 100 LossPred 0.9594 LossAtt 0.6119 TrainAcc 0.6000 TestAcc 0.5976 0.6000
epoch 200 LossPred 0.9558 LossAtt 0.5546 TrainAcc 0.6000 TestAcc 0.5976 0.6000
epoch 300 LossPred 0.9162 LossAtt 0.6877 TrainAcc 0.6000 TestAcc 0.5726 0.6150
epoch 400 LossPred 0.7926 LossAtt 0.5375 TrainAcc 0.7200 TestAcc 0.5145 0.6900
epoch 500 LossPred 0.7519 LossAtt 0.5522 TrainAcc 0.7500 TestAcc 0.5228 0.7200
epoch 600 LossPred 0.7197 LossAtt 0.5670 TrainAcc 0.7500 TestAcc 0.5195 0.7150
epoch 700 LossPred 0.6980 LossAtt 0.5617 TrainAcc 0.8000 TestAcc 0.5233 0.7200
epoch 800 LossPred 0.6827 LossAtt 0.5901 TrainAcc 0.7900 TestAcc 0.5210 0.7400
epoch 900 LossPred 0.6710 LossAtt 0.6201 TrainAcc 0.7900 TestAcc 0.5203 0.7450
epoch 1000 LossPred 0.6575 LossAtt 0.5985 TrainAcc 0.8000 TestAcc 0.5185 0.7450
epoch 1100 LossPred 0.6647 LossAtt 0.6251 TrainAcc 0.7800 TestAcc 0.5228 0.7300
epoch 1200 LossPred 0.6585 LossAtt 0.6021 TrainAcc 0.7900 TestAcc 0.5200 0.7450
epoch 1300 LossPred 0.6723 LossAtt 0.6082 TrainAcc 0.7800 TestAcc 0.5210 0.7200
epoch 1400 LossPred 0.6466 LossAtt 0.5882 TrainAcc 0.7700 TestAcc 0.5160 0.7350
epoch 1500 LossPred 0.6132 LossAtt 0.5721 TrainAcc 0.8100 TestAcc 0.5188 0.7350
epoch 1600 LossPred 0.6024 LossAtt 0.5866 TrainAcc 0.7900 TestAcc 0.5188 0.7600
epoch 1700 LossPred 0.6045 LossAtt 0.5773 TrainAcc 0.8000 TestAcc 0.5203 0.7650
epoch 1800 LossPred 0.6175 LossAtt 0.5408 TrainAcc 0.8000 TestAcc 0.5208 0.7500
epoch 1900 LossPred 0.5960 LossAtt 0.5519 TrainAcc 0.8100 TestAcc 0.5178 0.7600
epoch 2000 LossPred 0.5928 LossAtt 0.5427 TrainAcc 0.8100 TestAcc 0.5168 0.7600
epoch 2100 LossPred 0.5953 LossAtt 0.5879 TrainAcc 0.8000 TestAcc 0.5193 0.7500
epoch 2200 LossPred 0.5923 LossAtt 0.5872 TrainAcc 0.8000 TestAcc 0.5145 0.7650
epoch 2300 LossPred 0.5953 LossAtt 0.5639 TrainAcc 0.8100 TestAcc 0.5213 0.7400
epoch 2400 LossPred 0.6276 LossAtt 0.5712 TrainAcc 0.7900 TestAcc 0.5170 0.7450
epoch 2500 LossPred 0.6420 LossAtt 0.5954 TrainAcc 0.8000 TestAcc 0.5195 0.7450
Optimization Finished!
********** replication  53  **********
epoch   0 LossPred 1.0409 LossAtt 1.0312 TrainAcc 0.4500 TestAcc 0.4317 0.4150
epoch 100 LossPred 0.9214 LossAtt 0.6252 TrainAcc 0.6400 TestAcc 0.5983 0.6250
epoch 200 LossPred 0.9033 LossAtt 0.6404 TrainAcc 0.6400 TestAcc 0.5983 0.6400
epoch 300 LossPred 0.8652 LossAtt 0.5979 TrainAcc 0.6400 TestAcc 0.5983 0.6400
epoch 400 LossPred 0.8294 LossAtt 0.5059 TrainAcc 0.6700 TestAcc 0.6284 0.6600
epoch 500 LossPred 0.8073 LossAtt 0.4799 TrainAcc 0.6900 TestAcc 0.6446 0.6900
epoch 600 LossPred 0.7742 LossAtt 0.5803 TrainAcc 0.7200 TestAcc 0.6344 0.6850
epoch 700 LossPred 0.7248 LossAtt 0.6747 TrainAcc 0.7500 TestAcc 0.5858 0.7250
epoch 800 LossPred 0.6934 LossAtt 0.6557 TrainAcc 0.7600 TestAcc 0.5791 0.7150
epoch 900 LossPred 0.6698 LossAtt 0.6307 TrainAcc 0.7500 TestAcc 0.5816 0.7250
epoch 1000 LossPred 0.6639 LossAtt 0.6299 TrainAcc 0.7500 TestAcc 0.5828 0.7250
epoch 1100 LossPred 0.6485 LossAtt 0.5989 TrainAcc 0.7600 TestAcc 0.5811 0.7500
epoch 1200 LossPred 0.6396 LossAtt 0.6018 TrainAcc 0.7700 TestAcc 0.5838 0.7400
epoch 1300 LossPred 0.6454 LossAtt 0.6137 TrainAcc 0.7600 TestAcc 0.5873 0.7450
epoch 1400 LossPred 0.6402 LossAtt 0.6080 TrainAcc 0.7800 TestAcc 0.5851 0.7500
epoch 1500 LossPred 0.6336 LossAtt 0.6148 TrainAcc 0.7800 TestAcc 0.5846 0.7450
epoch 1600 LossPred 0.6164 LossAtt 0.6019 TrainAcc 0.7800 TestAcc 0.5843 0.7550
epoch 1700 LossPred 0.6095 LossAtt 0.5934 TrainAcc 0.7800 TestAcc 0.5813 0.7500
epoch 1800 LossPred 0.6298 LossAtt 0.5806 TrainAcc 0.7900 TestAcc 0.5868 0.7550
epoch 1900 LossPred 0.6330 LossAtt 0.5637 TrainAcc 0.7700 TestAcc 0.5871 0.7450
epoch 2000 LossPred 0.6091 LossAtt 0.5677 TrainAcc 0.7800 TestAcc 0.5861 0.7500
epoch 2100 LossPred 0.6058 LossAtt 0.5663 TrainAcc 0.7800 TestAcc 0.5876 0.7600
epoch 2200 LossPred 0.6076 LossAtt 0.5146 TrainAcc 0.7900 TestAcc 0.5893 0.7400
epoch 2300 LossPred 0.6064 LossAtt 0.5770 TrainAcc 0.8000 TestAcc 0.5858 0.7450
epoch 2400 LossPred 0.5975 LossAtt 0.5761 TrainAcc 0.8000 TestAcc 0.5906 0.7550
epoch 2500 LossPred 0.6171 LossAtt 0.5497 TrainAcc 0.7900 TestAcc 0.5863 0.7400
Optimization Finished!
********** replication  54  **********
epoch   0 LossPred 0.9981 LossAtt 1.0020 TrainAcc 0.6000 TestAcc 0.5485 0.5900
epoch 100 LossPred 0.8910 LossAtt 0.4311 TrainAcc 0.6500 TestAcc 0.5811 0.6400
epoch 200 LossPred 0.7100 LossAtt 0.4904 TrainAcc 0.7600 TestAcc 0.6849 0.7450
epoch 300 LossPred 0.3693 LossAtt 0.3973 TrainAcc 0.8800 TestAcc 0.8519 0.8900
epoch 400 LossPred 0.3361 LossAtt 0.3985 TrainAcc 0.8900 TestAcc 0.8636 0.8950
epoch 500 LossPred 0.3031 LossAtt 0.4078 TrainAcc 0.9100 TestAcc 0.8651 0.8750
epoch 600 LossPred 0.2296 LossAtt 0.3695 TrainAcc 0.9300 TestAcc 0.8709 0.8750
epoch 700 LossPred 0.2413 LossAtt 0.3736 TrainAcc 0.9100 TestAcc 0.8749 0.8800
epoch 800 LossPred 0.2158 LossAtt 0.3511 TrainAcc 0.9300 TestAcc 0.8804 0.9050
epoch 900 LossPred 0.1729 LossAtt 0.3588 TrainAcc 0.9500 TestAcc 0.8734 0.8850
epoch 1000 LossPred 0.1687 LossAtt 0.3894 TrainAcc 0.9500 TestAcc 0.8814 0.8900
epoch 1100 LossPred 0.1663 LossAtt 0.3558 TrainAcc 0.9500 TestAcc 0.8831 0.8850
epoch 1200 LossPred 0.1895 LossAtt 0.3454 TrainAcc 0.9400 TestAcc 0.8714 0.9050
epoch 1300 LossPred 0.1649 LossAtt 0.3421 TrainAcc 0.9500 TestAcc 0.8831 0.8950
epoch 1400 LossPred 0.1665 LossAtt 0.3615 TrainAcc 0.9500 TestAcc 0.8879 0.8950
epoch 1500 LossPred 0.1636 LossAtt 0.3366 TrainAcc 0.9500 TestAcc 0.8846 0.8950
epoch 1600 LossPred 0.1566 LossAtt 0.3690 TrainAcc 0.9500 TestAcc 0.8864 0.8850
epoch 1700 LossPred 0.1629 LossAtt 0.3586 TrainAcc 0.9500 TestAcc 0.8894 0.9000
epoch 1800 LossPred 0.1578 LossAtt 0.3474 TrainAcc 0.9500 TestAcc 0.8891 0.8950
epoch 1900 LossPred 0.1560 LossAtt 0.3516 TrainAcc 0.9600 TestAcc 0.8899 0.9000
epoch 2000 LossPred 0.1556 LossAtt 0.3143 TrainAcc 0.9500 TestAcc 0.8894 0.9000
epoch 2100 LossPred 0.1675 LossAtt 0.3526 TrainAcc 0.9600 TestAcc 0.8874 0.9000
epoch 2200 LossPred 0.1812 LossAtt 0.3477 TrainAcc 0.9400 TestAcc 0.8981 0.9100
epoch 2300 LossPred 0.1574 LossAtt 0.3318 TrainAcc 0.9600 TestAcc 0.8939 0.9050
epoch 2400 LossPred 0.1517 LossAtt 0.3319 TrainAcc 0.9600 TestAcc 0.8896 0.9100
epoch 2500 LossPred 0.1531 LossAtt 0.3566 TrainAcc 0.9600 TestAcc 0.8904 0.9100
Optimization Finished!
********** replication  55  **********
epoch   0 LossPred 1.0973 LossAtt 1.0124 TrainAcc 0.3600 TestAcc 0.3934 0.3600
epoch 100 LossPred 0.9111 LossAtt 0.4330 TrainAcc 0.6400 TestAcc 0.6066 0.6400
epoch 200 LossPred 0.9096 LossAtt 0.2870 TrainAcc 0.6400 TestAcc 0.6066 0.6400
epoch 300 LossPred 0.9070 LossAtt 0.2092 TrainAcc 0.6400 TestAcc 0.6066 0.6400
epoch 400 LossPred 0.9036 LossAtt 0.1941 TrainAcc 0.6400 TestAcc 0.6066 0.6400
epoch 500 LossPred 0.8015 LossAtt 0.4783 TrainAcc 0.7200 TestAcc 0.6451 0.7250
epoch 600 LossPred 0.3488 LossAtt 0.5134 TrainAcc 0.8600 TestAcc 0.8691 0.8850
epoch 700 LossPred 0.2073 LossAtt 0.5099 TrainAcc 0.9400 TestAcc 0.9229 0.9400
epoch 800 LossPred 0.2540 LossAtt 0.5264 TrainAcc 0.9000 TestAcc 0.8841 0.8650
epoch 900 LossPred 0.1776 LossAtt 0.5442 TrainAcc 0.9400 TestAcc 0.9007 0.8900
epoch 1000 LossPred 0.1567 LossAtt 0.5064 TrainAcc 0.9600 TestAcc 0.9322 0.9600
epoch 1100 LossPred 0.0943 LossAtt 0.5240 TrainAcc 0.9800 TestAcc 0.9319 0.9600
epoch 1200 LossPred 0.1021 LossAtt 0.5080 TrainAcc 0.9800 TestAcc 0.9292 0.9350
epoch 1300 LossPred 0.2996 LossAtt 0.5244 TrainAcc 0.9000 TestAcc 0.8644 0.8550
epoch 1400 LossPred 0.2153 LossAtt 0.5101 TrainAcc 0.9200 TestAcc 0.8894 0.8850
epoch 1500 LossPred 0.1473 LossAtt 0.5170 TrainAcc 0.9500 TestAcc 0.9127 0.9100
epoch 1600 LossPred 0.2259 LossAtt 0.4954 TrainAcc 0.9300 TestAcc 0.8829 0.9150
epoch 1700 LossPred 0.1017 LossAtt 0.4818 TrainAcc 0.9700 TestAcc 0.9279 0.9450
epoch 1800 LossPred 0.1144 LossAtt 0.4845 TrainAcc 0.9700 TestAcc 0.9407 0.9700
epoch 1900 LossPred 0.1599 LossAtt 0.4655 TrainAcc 0.9300 TestAcc 0.9057 0.9150
epoch 2000 LossPred 0.0930 LossAtt 0.4481 TrainAcc 0.9700 TestAcc 0.9279 0.9650
epoch 2100 LossPred 0.2381 LossAtt 0.4543 TrainAcc 0.9100 TestAcc 0.8776 0.9050
epoch 2200 LossPred 0.0827 LossAtt 0.4394 TrainAcc 0.9800 TestAcc 0.9194 0.9750
epoch 2300 LossPred 0.0957 LossAtt 0.4617 TrainAcc 0.9700 TestAcc 0.9314 0.9550
epoch 2400 LossPred 0.0816 LossAtt 0.4489 TrainAcc 0.9600 TestAcc 0.9132 0.9700
epoch 2500 LossPred 0.0897 LossAtt 0.4549 TrainAcc 0.9700 TestAcc 0.9117 0.9650
Optimization Finished!
********** replication  56  **********
epoch   0 LossPred 1.2513 LossAtt 1.0205 TrainAcc 0.4100 TestAcc 0.4580 0.3850
epoch 100 LossPred 0.9214 LossAtt 0.3086 TrainAcc 0.6800 TestAcc 0.6001 0.6800
epoch 200 LossPred 0.8822 LossAtt 0.2347 TrainAcc 0.6800 TestAcc 0.6001 0.6800
epoch 300 LossPred 0.8598 LossAtt 0.2478 TrainAcc 0.6800 TestAcc 0.6001 0.6800
epoch 400 LossPred 0.8392 LossAtt 0.2649 TrainAcc 0.6800 TestAcc 0.6001 0.6800
epoch 500 LossPred 0.8232 LossAtt 0.2579 TrainAcc 0.6800 TestAcc 0.6001 0.6800
epoch 600 LossPred 0.8011 LossAtt 0.3066 TrainAcc 0.6800 TestAcc 0.6001 0.6850
epoch 700 LossPred 0.4274 LossAtt 0.3880 TrainAcc 0.8700 TestAcc 0.8739 0.8550
epoch 800 LossPred 0.4403 LossAtt 0.3746 TrainAcc 0.8300 TestAcc 0.8786 0.8450
epoch 900 LossPred 0.3164 LossAtt 0.3414 TrainAcc 0.9100 TestAcc 0.9084 0.8650
epoch 1000 LossPred 0.3345 LossAtt 0.3805 TrainAcc 0.9100 TestAcc 0.9059 0.8700
epoch 1100 LossPred 0.3013 LossAtt 0.3941 TrainAcc 0.9200 TestAcc 0.9074 0.8600
epoch 1200 LossPred 0.2978 LossAtt 0.4214 TrainAcc 0.9100 TestAcc 0.8916 0.8650
epoch 1300 LossPred 0.2813 LossAtt 0.3979 TrainAcc 0.9200 TestAcc 0.8969 0.8550
epoch 1400 LossPred 0.2698 LossAtt 0.4192 TrainAcc 0.9500 TestAcc 0.8979 0.8700
epoch 1500 LossPred 0.2729 LossAtt 0.4037 TrainAcc 0.8900 TestAcc 0.8999 0.8800
epoch 1600 LossPred 0.3368 LossAtt 0.4086 TrainAcc 0.8700 TestAcc 0.8979 0.8750
epoch 1700 LossPred 0.2649 LossAtt 0.3809 TrainAcc 0.9200 TestAcc 0.8879 0.8900
epoch 1800 LossPred 0.2408 LossAtt 0.3728 TrainAcc 0.9400 TestAcc 0.8944 0.8950
epoch 1900 LossPred 0.2384 LossAtt 0.3660 TrainAcc 0.9300 TestAcc 0.8949 0.8950
epoch 2000 LossPred 0.2370 LossAtt 0.3465 TrainAcc 0.9600 TestAcc 0.9004 0.8850
epoch 2100 LossPred 0.2680 LossAtt 0.3626 TrainAcc 0.9000 TestAcc 0.8836 0.8900
epoch 2200 LossPred 0.2341 LossAtt 0.3522 TrainAcc 0.9400 TestAcc 0.9012 0.9000
epoch 2300 LossPred 0.2168 LossAtt 0.3616 TrainAcc 0.9400 TestAcc 0.9104 0.9100
epoch 2400 LossPred 0.3218 LossAtt 0.3749 TrainAcc 0.9000 TestAcc 0.9054 0.8700
epoch 2500 LossPred 0.2702 LossAtt 0.3648 TrainAcc 0.8900 TestAcc 0.8769 0.9100
Optimization Finished!
********** replication  57  **********
epoch   0 LossPred 0.9864 LossAtt 1.0319 TrainAcc 0.5400 TestAcc 0.5818 0.5800
epoch 100 LossPred 0.9064 LossAtt 0.4823 TrainAcc 0.6200 TestAcc 0.5888 0.6200
epoch 200 LossPred 0.7872 LossAtt 0.5438 TrainAcc 0.7100 TestAcc 0.6206 0.7050
epoch 300 LossPred 0.2388 LossAtt 0.5204 TrainAcc 0.9600 TestAcc 0.9527 0.9200
epoch 400 LossPred 0.1586 LossAtt 0.4510 TrainAcc 0.9600 TestAcc 0.9767 0.9100
epoch 500 LossPred 0.1364 LossAtt 0.4468 TrainAcc 0.9700 TestAcc 0.9775 0.9200
epoch 600 LossPred 0.1551 LossAtt 0.3964 TrainAcc 0.9600 TestAcc 0.9214 0.9050
epoch 700 LossPred 0.3185 LossAtt 0.3734 TrainAcc 0.8800 TestAcc 0.9049 0.8650
epoch 800 LossPred 0.1227 LossAtt 0.3436 TrainAcc 0.9700 TestAcc 0.9787 0.9200
epoch 900 LossPred 0.1485 LossAtt 0.3367 TrainAcc 0.9700 TestAcc 0.9742 0.9150
epoch 1000 LossPred 0.1700 LossAtt 0.3531 TrainAcc 0.9300 TestAcc 0.9457 0.9150
epoch 1100 LossPred 0.1814 LossAtt 0.3444 TrainAcc 0.9300 TestAcc 0.9349 0.9000
epoch 1200 LossPred 0.0840 LossAtt 0.3298 TrainAcc 0.9800 TestAcc 0.9775 0.9300
epoch 1300 LossPred 0.1298 LossAtt 0.3360 TrainAcc 0.9600 TestAcc 0.9332 0.9050
epoch 1400 LossPred 0.1692 LossAtt 0.3603 TrainAcc 0.9500 TestAcc 0.9217 0.8850
epoch 1500 LossPred 0.0926 LossAtt 0.3457 TrainAcc 0.9700 TestAcc 0.9692 0.9250
epoch 1600 LossPred 0.1183 LossAtt 0.3329 TrainAcc 0.9600 TestAcc 0.9499 0.9200
epoch 1700 LossPred 0.1500 LossAtt 0.3300 TrainAcc 0.9600 TestAcc 0.9439 0.9000
epoch 1800 LossPred 0.0745 LossAtt 0.3283 TrainAcc 0.9800 TestAcc 0.9782 0.9300
epoch 1900 LossPred 0.1029 LossAtt 0.3360 TrainAcc 0.9700 TestAcc 0.9725 0.9250
epoch 2000 LossPred 0.0787 LossAtt 0.3336 TrainAcc 0.9800 TestAcc 0.9725 0.9500
epoch 2100 LossPred 0.1564 LossAtt 0.3294 TrainAcc 0.9600 TestAcc 0.9542 0.9350
epoch 2200 LossPred 0.1536 LossAtt 0.3380 TrainAcc 0.9600 TestAcc 0.9525 0.9250
epoch 2300 LossPred 0.1338 LossAtt 0.3244 TrainAcc 0.9600 TestAcc 0.9404 0.9250
epoch 2400 LossPred 0.0857 LossAtt 0.3392 TrainAcc 0.9600 TestAcc 0.9695 0.9250
epoch 2500 LossPred 0.1135 LossAtt 0.3273 TrainAcc 0.9500 TestAcc 0.9449 0.9300
Optimization Finished!
********** replication  58  **********
epoch   0 LossPred 0.9701 LossAtt 1.0088 TrainAcc 0.5700 TestAcc 0.5483 0.5750
epoch 100 LossPred 0.8372 LossAtt 0.5345 TrainAcc 0.6900 TestAcc 0.6141 0.6950
epoch 200 LossPred 0.4835 LossAtt 0.6732 TrainAcc 0.8800 TestAcc 0.8303 0.8600
epoch 300 LossPred 0.2732 LossAtt 0.6291 TrainAcc 0.9200 TestAcc 0.8951 0.8900
epoch 400 LossPred 0.2227 LossAtt 0.5647 TrainAcc 0.9500 TestAcc 0.8934 0.8900
epoch 500 LossPred 0.1874 LossAtt 0.5163 TrainAcc 0.9600 TestAcc 0.9152 0.8900
epoch 600 LossPred 0.1548 LossAtt 0.5058 TrainAcc 0.9600 TestAcc 0.9297 0.9350
epoch 700 LossPred 0.1475 LossAtt 0.4953 TrainAcc 0.9700 TestAcc 0.9179 0.9200
epoch 800 LossPred 0.1286 LossAtt 0.4899 TrainAcc 0.9700 TestAcc 0.9227 0.9400
epoch 900 LossPred 0.1133 LossAtt 0.4997 TrainAcc 0.9800 TestAcc 0.9309 0.9350
epoch 1000 LossPred 0.1179 LossAtt 0.5051 TrainAcc 0.9800 TestAcc 0.9327 0.9400
epoch 1100 LossPred 0.1441 LossAtt 0.4974 TrainAcc 0.9700 TestAcc 0.9164 0.9350
epoch 1200 LossPred 0.1094 LossAtt 0.5093 TrainAcc 0.9900 TestAcc 0.9342 0.9350
epoch 1300 LossPred 0.1061 LossAtt 0.5241 TrainAcc 0.9800 TestAcc 0.9294 0.9350
epoch 1400 LossPred 0.1020 LossAtt 0.5471 TrainAcc 0.9800 TestAcc 0.9417 0.9350
epoch 1500 LossPred 0.0968 LossAtt 0.5109 TrainAcc 0.9900 TestAcc 0.9429 0.9400
epoch 1600 LossPred 0.0969 LossAtt 0.5140 TrainAcc 0.9900 TestAcc 0.9422 0.9300
epoch 1700 LossPred 0.0946 LossAtt 0.4974 TrainAcc 0.9800 TestAcc 0.9344 0.9400
epoch 1800 LossPred 0.1192 LossAtt 0.5093 TrainAcc 0.9700 TestAcc 0.9402 0.9150
epoch 1900 LossPred 0.0903 LossAtt 0.5273 TrainAcc 0.9900 TestAcc 0.9447 0.9300
epoch 2000 LossPred 0.0815 LossAtt 0.5053 TrainAcc 0.9700 TestAcc 0.9402 0.9300
epoch 2100 LossPred 0.1050 LossAtt 0.5043 TrainAcc 0.9900 TestAcc 0.9384 0.9350
epoch 2200 LossPred 0.0814 LossAtt 0.5213 TrainAcc 0.9900 TestAcc 0.9422 0.9350
epoch 2300 LossPred 0.0850 LossAtt 0.5312 TrainAcc 0.9800 TestAcc 0.9347 0.9400
epoch 2400 LossPred 0.0883 LossAtt 0.5141 TrainAcc 0.9900 TestAcc 0.9459 0.9400
epoch 2500 LossPred 0.0682 LossAtt 0.5341 TrainAcc 0.9900 TestAcc 0.9510 0.9450
Optimization Finished!
********** replication  59  **********
epoch   0 LossPred 1.2111 LossAtt 1.0101 TrainAcc 0.4800 TestAcc 0.4432 0.4600
epoch 100 LossPred 0.9783 LossAtt 0.3936 TrainAcc 0.5800 TestAcc 0.6139 0.5800
epoch 200 LossPred 0.9258 LossAtt 0.3614 TrainAcc 0.5800 TestAcc 0.5826 0.6000
epoch 300 LossPred 0.8798 LossAtt 0.4335 TrainAcc 0.6800 TestAcc 0.5633 0.6750
epoch 400 LossPred 0.8556 LossAtt 0.4500 TrainAcc 0.7000 TestAcc 0.5776 0.7100
epoch 500 LossPred 0.8285 LossAtt 0.5058 TrainAcc 0.7000 TestAcc 0.5801 0.7050
epoch 600 LossPred 0.4511 LossAtt 0.6819 TrainAcc 0.8500 TestAcc 0.8651 0.9000
epoch 700 LossPred 0.2801 LossAtt 0.6108 TrainAcc 0.9100 TestAcc 0.8694 0.9300
epoch 800 LossPred 0.2154 LossAtt 0.6077 TrainAcc 0.9600 TestAcc 0.8541 0.9300
epoch 900 LossPred 0.2062 LossAtt 0.5722 TrainAcc 0.9600 TestAcc 0.8651 0.9600
epoch 1000 LossPred 0.2120 LossAtt 0.5556 TrainAcc 0.9300 TestAcc 0.8699 0.9450
epoch 1100 LossPred 0.2029 LossAtt 0.5691 TrainAcc 0.9400 TestAcc 0.8864 0.9400
epoch 1200 LossPred 0.1654 LossAtt 0.5550 TrainAcc 0.9600 TestAcc 0.8656 0.9350
epoch 1300 LossPred 0.1487 LossAtt 0.5407 TrainAcc 0.9500 TestAcc 0.8801 0.9700
epoch 1400 LossPred 0.1504 LossAtt 0.5633 TrainAcc 0.9500 TestAcc 0.8756 0.9350
epoch 1500 LossPred 0.1535 LossAtt 0.5515 TrainAcc 0.9500 TestAcc 0.8656 0.9300
epoch 1600 LossPred 0.1343 LossAtt 0.5251 TrainAcc 0.9800 TestAcc 0.8749 0.9500
epoch 1700 LossPred 0.1199 LossAtt 0.5553 TrainAcc 0.9700 TestAcc 0.8551 0.9450
epoch 1800 LossPred 0.1282 LossAtt 0.5380 TrainAcc 0.9800 TestAcc 0.8696 0.9600
epoch 1900 LossPred 0.1853 LossAtt 0.5454 TrainAcc 0.9400 TestAcc 0.8629 0.9550
epoch 2000 LossPred 0.1042 LossAtt 0.5351 TrainAcc 0.9800 TestAcc 0.8694 0.9650
epoch 2100 LossPred 0.1310 LossAtt 0.5225 TrainAcc 0.9700 TestAcc 0.8488 0.9400
epoch 2200 LossPred 0.0989 LossAtt 0.5211 TrainAcc 0.9800 TestAcc 0.8488 0.9450
epoch 2300 LossPred 0.0975 LossAtt 0.5304 TrainAcc 0.9800 TestAcc 0.8569 0.9450
epoch 2400 LossPred 0.2881 LossAtt 0.5185 TrainAcc 0.9100 TestAcc 0.8754 0.9100
epoch 2500 LossPred 0.6781 LossAtt 0.5035 TrainAcc 0.8000 TestAcc 0.8221 0.7800
Optimization Finished!
********** replication  60  **********
epoch   0 LossPred 0.9953 LossAtt 1.0137 TrainAcc 0.5100 TestAcc 0.4955 0.5050
epoch 100 LossPred 0.9416 LossAtt 0.5700 TrainAcc 0.6000 TestAcc 0.6324 0.6100
epoch 200 LossPred 0.7019 LossAtt 0.5718 TrainAcc 0.7800 TestAcc 0.7768 0.7950
epoch 300 LossPred 0.4339 LossAtt 0.5870 TrainAcc 0.8800 TestAcc 0.8689 0.8650
epoch 400 LossPred 0.4284 LossAtt 0.5834 TrainAcc 0.8600 TestAcc 0.8691 0.8500
epoch 500 LossPred 0.4146 LossAtt 0.5800 TrainAcc 0.8500 TestAcc 0.8679 0.8650
epoch 600 LossPred 0.3560 LossAtt 0.5619 TrainAcc 0.9000 TestAcc 0.8839 0.8800
epoch 700 LossPred 0.3509 LossAtt 0.5482 TrainAcc 0.9100 TestAcc 0.8836 0.8750
epoch 800 LossPred 0.3472 LossAtt 0.5449 TrainAcc 0.8900 TestAcc 0.8829 0.8750
epoch 900 LossPred 0.3426 LossAtt 0.5069 TrainAcc 0.9100 TestAcc 0.8819 0.8750
epoch 1000 LossPred 0.3450 LossAtt 0.5183 TrainAcc 0.9000 TestAcc 0.8851 0.8700
epoch 1100 LossPred 0.3393 LossAtt 0.4526 TrainAcc 0.9100 TestAcc 0.8849 0.8750
epoch 1200 LossPred 0.3346 LossAtt 0.4658 TrainAcc 0.9000 TestAcc 0.8816 0.8750
epoch 1300 LossPred 0.3335 LossAtt 0.4600 TrainAcc 0.9000 TestAcc 0.8809 0.8700
epoch 1400 LossPred 0.3366 LossAtt 0.4347 TrainAcc 0.8900 TestAcc 0.8806 0.8750
epoch 1500 LossPred 0.3270 LossAtt 0.4369 TrainAcc 0.9000 TestAcc 0.8846 0.8750
epoch 1600 LossPred 0.3223 LossAtt 0.4494 TrainAcc 0.9000 TestAcc 0.8836 0.8800
epoch 1700 LossPred 0.3231 LossAtt 0.4284 TrainAcc 0.8900 TestAcc 0.8861 0.8800
epoch 1800 LossPred 0.3479 LossAtt 0.4086 TrainAcc 0.8700 TestAcc 0.8844 0.8700
epoch 1900 LossPred 0.3229 LossAtt 0.4190 TrainAcc 0.8900 TestAcc 0.8886 0.8850
epoch 2000 LossPred 0.3041 LossAtt 0.4060 TrainAcc 0.9000 TestAcc 0.8939 0.8850
epoch 2100 LossPred 0.3276 LossAtt 0.4280 TrainAcc 0.8800 TestAcc 0.8951 0.8700
epoch 2200 LossPred 0.3216 LossAtt 0.4085 TrainAcc 0.8700 TestAcc 0.8969 0.8650
epoch 2300 LossPred 0.3000 LossAtt 0.4054 TrainAcc 0.8800 TestAcc 0.9089 0.8850
epoch 2400 LossPred 0.2814 LossAtt 0.3987 TrainAcc 0.9200 TestAcc 0.9167 0.9000
epoch 2500 LossPred 0.2743 LossAtt 0.4083 TrainAcc 0.9000 TestAcc 0.9172 0.8750
Optimization Finished!
********** replication  61  **********
epoch   0 LossPred 1.1584 LossAtt 1.0293 TrainAcc 0.4500 TestAcc 0.5135 0.4650
epoch 100 LossPred 0.9691 LossAtt 0.4521 TrainAcc 0.5800 TestAcc 0.5430 0.5800
epoch 200 LossPred 0.8982 LossAtt 0.3857 TrainAcc 0.5300 TestAcc 0.5373 0.5500
epoch 300 LossPred 0.8443 LossAtt 0.3991 TrainAcc 0.6800 TestAcc 0.6206 0.6650
epoch 400 LossPred 0.8056 LossAtt 0.3762 TrainAcc 0.6800 TestAcc 0.6206 0.6800
epoch 500 LossPred 0.3292 LossAtt 0.5116 TrainAcc 0.9200 TestAcc 0.8986 0.9050
epoch 600 LossPred 0.2962 LossAtt 0.4883 TrainAcc 0.9200 TestAcc 0.9184 0.8900
epoch 700 LossPred 0.3189 LossAtt 0.4562 TrainAcc 0.9000 TestAcc 0.8826 0.8800
epoch 800 LossPred 0.3104 LossAtt 0.4601 TrainAcc 0.9000 TestAcc 0.9019 0.8800
epoch 900 LossPred 0.3600 LossAtt 0.4416 TrainAcc 0.8900 TestAcc 0.8463 0.8750
epoch 1000 LossPred 0.2779 LossAtt 0.4290 TrainAcc 0.9300 TestAcc 0.9174 0.9000
epoch 1100 LossPred 0.2422 LossAtt 0.4250 TrainAcc 0.9400 TestAcc 0.9297 0.8950
epoch 1200 LossPred 0.2359 LossAtt 0.4291 TrainAcc 0.9300 TestAcc 0.9334 0.9050
epoch 1300 LossPred 0.2393 LossAtt 0.3931 TrainAcc 0.9400 TestAcc 0.9227 0.8750
epoch 1400 LossPred 0.2969 LossAtt 0.3951 TrainAcc 0.8700 TestAcc 0.9087 0.8750
epoch 1500 LossPred 0.2126 LossAtt 0.3750 TrainAcc 0.9400 TestAcc 0.9452 0.8950
epoch 1600 LossPred 0.2816 LossAtt 0.3764 TrainAcc 0.9100 TestAcc 0.9197 0.8850
epoch 1700 LossPred 0.2649 LossAtt 0.3778 TrainAcc 0.9100 TestAcc 0.9309 0.8900
epoch 1800 LossPred 0.2310 LossAtt 0.3902 TrainAcc 0.9200 TestAcc 0.9414 0.8850
epoch 1900 LossPred 0.1938 LossAtt 0.3831 TrainAcc 0.9500 TestAcc 0.9580 0.8950
epoch 2000 LossPred 0.1813 LossAtt 0.3553 TrainAcc 0.9500 TestAcc 0.9642 0.8900
epoch 2100 LossPred 0.2217 LossAtt 0.3954 TrainAcc 0.9300 TestAcc 0.9489 0.9100
epoch 2200 LossPred 0.1712 LossAtt 0.3984 TrainAcc 0.9700 TestAcc 0.9717 0.8900
epoch 2300 LossPred 0.4087 LossAtt 0.3984 TrainAcc 0.8500 TestAcc 0.8268 0.8250
epoch 2400 LossPred 0.1920 LossAtt 0.4232 TrainAcc 0.9400 TestAcc 0.9522 0.9050
epoch 2500 LossPred 0.2162 LossAtt 0.4340 TrainAcc 0.9200 TestAcc 0.9037 0.8550
Optimization Finished!
********** replication  62  **********
epoch   0 LossPred 1.2972 LossAtt 1.0779 TrainAcc 0.4100 TestAcc 0.4530 0.4150
epoch 100 LossPred 0.9230 LossAtt 0.6364 TrainAcc 0.6200 TestAcc 0.5953 0.6100
epoch 200 LossPred 0.8705 LossAtt 0.5636 TrainAcc 0.6600 TestAcc 0.6364 0.6800
epoch 300 LossPred 0.8497 LossAtt 0.4403 TrainAcc 0.6600 TestAcc 0.6364 0.6750
epoch 400 LossPred 0.8415 LossAtt 0.4320 TrainAcc 0.6700 TestAcc 0.5941 0.6600
epoch 500 LossPred 0.8343 LossAtt 0.4221 TrainAcc 0.6700 TestAcc 0.5941 0.6650
epoch 600 LossPred 0.8242 LossAtt 0.4015 TrainAcc 0.6900 TestAcc 0.6259 0.6900
epoch 700 LossPred 0.7904 LossAtt 0.3689 TrainAcc 0.6900 TestAcc 0.6289 0.6850
epoch 800 LossPred 0.4643 LossAtt 0.6103 TrainAcc 0.8600 TestAcc 0.8636 0.8250
epoch 900 LossPred 0.1740 LossAtt 0.5447 TrainAcc 0.9600 TestAcc 0.9112 0.9100
epoch 1000 LossPred 0.1415 LossAtt 0.5640 TrainAcc 0.9600 TestAcc 0.9184 0.9300
epoch 1100 LossPred 0.0879 LossAtt 0.5761 TrainAcc 0.9800 TestAcc 0.9317 0.9400
epoch 1200 LossPred 0.0732 LossAtt 0.5923 TrainAcc 0.9900 TestAcc 0.9334 0.9350
epoch 1300 LossPred 0.0604 LossAtt 0.5416 TrainAcc 1.0000 TestAcc 0.9344 0.9500
Optimization Finished!
********** replication  63  **********
epoch   0 LossPred 1.1431 LossAtt 1.0207 TrainAcc 0.4200 TestAcc 0.4692 0.4600
epoch 100 LossPred 0.8828 LossAtt 0.5012 TrainAcc 0.7000 TestAcc 0.6089 0.6900
epoch 200 LossPred 0.8364 LossAtt 0.3886 TrainAcc 0.7000 TestAcc 0.6089 0.7000
epoch 300 LossPred 0.8169 LossAtt 0.3589 TrainAcc 0.7000 TestAcc 0.6089 0.7000
epoch 400 LossPred 0.8001 LossAtt 0.3591 TrainAcc 0.7000 TestAcc 0.6089 0.7000
epoch 500 LossPred 0.7922 LossAtt 0.4149 TrainAcc 0.7600 TestAcc 0.6064 0.7250
epoch 600 LossPred 0.7617 LossAtt 0.5367 TrainAcc 0.7600 TestAcc 0.6116 0.7300
epoch 700 LossPred 0.4203 LossAtt 0.7196 TrainAcc 0.8700 TestAcc 0.8363 0.8650
epoch 800 LossPred 0.2489 LossAtt 0.6212 TrainAcc 0.9500 TestAcc 0.8834 0.9100
epoch 900 LossPred 0.1804 LossAtt 0.5721 TrainAcc 0.9800 TestAcc 0.8916 0.9150
epoch 1000 LossPred 0.1596 LossAtt 0.5588 TrainAcc 0.9900 TestAcc 0.9004 0.9150
epoch 1100 LossPred 0.1355 LossAtt 0.5241 TrainAcc 0.9800 TestAcc 0.8939 0.9100
epoch 1200 LossPred 0.1328 LossAtt 0.5321 TrainAcc 0.9600 TestAcc 0.8886 0.9100
epoch 1300 LossPred 0.1675 LossAtt 0.5295 TrainAcc 0.9400 TestAcc 0.8844 0.9150
epoch 1400 LossPred 0.1759 LossAtt 0.5295 TrainAcc 0.9400 TestAcc 0.8766 0.9100
epoch 1500 LossPred 0.1244 LossAtt 0.5359 TrainAcc 0.9700 TestAcc 0.8959 0.9300
epoch 1600 LossPred 0.0999 LossAtt 0.5016 TrainAcc 0.9900 TestAcc 0.8881 0.9300
epoch 1700 LossPred 0.0944 LossAtt 0.4628 TrainAcc 0.9900 TestAcc 0.8979 0.9250
epoch 1800 LossPred 0.1025 LossAtt 0.4242 TrainAcc 0.9900 TestAcc 0.9067 0.9250
epoch 1900 LossPred 0.0832 LossAtt 0.4264 TrainAcc 0.9900 TestAcc 0.8956 0.9250
epoch 2000 LossPred 0.0771 LossAtt 0.4235 TrainAcc 0.9900 TestAcc 0.9042 0.9450
epoch 2100 LossPred 0.0942 LossAtt 0.4215 TrainAcc 0.9700 TestAcc 0.8841 0.9350
epoch 2200 LossPred 0.0718 LossAtt 0.4173 TrainAcc 0.9900 TestAcc 0.9107 0.9550
epoch 2300 LossPred 0.1067 LossAtt 0.4221 TrainAcc 0.9700 TestAcc 0.8921 0.9350
epoch 2400 LossPred 0.0823 LossAtt 0.4046 TrainAcc 0.9900 TestAcc 0.9079 0.9550
epoch 2500 LossPred 0.0752 LossAtt 0.3923 TrainAcc 0.9900 TestAcc 0.9034 0.9500
Optimization Finished!
********** replication  64  **********
epoch   0 LossPred 1.1997 LossAtt 0.9956 TrainAcc 0.4400 TestAcc 0.4512 0.4450
epoch 100 LossPred 0.9218 LossAtt 0.4745 TrainAcc 0.6700 TestAcc 0.6184 0.6700
epoch 200 LossPred 0.8512 LossAtt 0.4965 TrainAcc 0.6700 TestAcc 0.6184 0.6750
epoch 300 LossPred 0.8343 LossAtt 0.3564 TrainAcc 0.6700 TestAcc 0.6184 0.6600
epoch 400 LossPred 0.8274 LossAtt 0.3624 TrainAcc 0.6700 TestAcc 0.6184 0.6700
epoch 500 LossPred 0.4897 LossAtt 0.6123 TrainAcc 0.8600 TestAcc 0.8258 0.8700
epoch 600 LossPred 0.2233 LossAtt 0.5864 TrainAcc 0.9300 TestAcc 0.9152 0.9350
epoch 700 LossPred 0.1639 LossAtt 0.6077 TrainAcc 0.9500 TestAcc 0.9274 0.9450
epoch 800 LossPred 0.1298 LossAtt 0.5901 TrainAcc 0.9700 TestAcc 0.9505 0.9500
epoch 900 LossPred 0.1475 LossAtt 0.5549 TrainAcc 0.9700 TestAcc 0.9249 0.9350
epoch 1000 LossPred 0.0777 LossAtt 0.5193 TrainAcc 0.9900 TestAcc 0.9605 0.9450
epoch 1100 LossPred 0.0530 LossAtt 0.4654 TrainAcc 0.9900 TestAcc 0.9705 0.9600
epoch 1200 LossPred 0.1663 LossAtt 0.4506 TrainAcc 0.9600 TestAcc 0.9112 0.9100
epoch 1300 LossPred 0.1083 LossAtt 0.4476 TrainAcc 0.9700 TestAcc 0.9570 0.9400
epoch 1400 LossPred 0.1669 LossAtt 0.4383 TrainAcc 0.9500 TestAcc 0.9264 0.9500
epoch 1500 LossPred 0.0689 LossAtt 0.4303 TrainAcc 0.9800 TestAcc 0.9677 0.9550
epoch 1600 LossPred 0.0378 LossAtt 0.4450 TrainAcc 1.0000 TestAcc 0.9637 0.9600
Optimization Finished!
********** replication  65  **********
epoch   0 LossPred 1.2790 LossAtt 1.0105 TrainAcc 0.3900 TestAcc 0.4687 0.3900
epoch 100 LossPred 0.9485 LossAtt 0.5097 TrainAcc 0.5400 TestAcc 0.5948 0.5800
epoch 200 LossPred 0.8861 LossAtt 0.4343 TrainAcc 0.6200 TestAcc 0.5878 0.6250
epoch 300 LossPred 0.8510 LossAtt 0.4072 TrainAcc 0.7300 TestAcc 0.6719 0.7300
epoch 400 LossPred 0.4126 LossAtt 0.6179 TrainAcc 0.9400 TestAcc 0.9119 0.9000
epoch 500 LossPred 0.2245 LossAtt 0.4791 TrainAcc 0.9700 TestAcc 0.9447 0.9100
epoch 600 LossPred 0.1482 LossAtt 0.4730 TrainAcc 0.9900 TestAcc 0.9269 0.9350
epoch 700 LossPred 0.0961 LossAtt 0.4657 TrainAcc 0.9900 TestAcc 0.9374 0.9650
epoch 800 LossPred 0.0710 LossAtt 0.4228 TrainAcc 1.0000 TestAcc 0.9477 0.9600
Optimization Finished!
********** replication  66  **********
epoch   0 LossPred 1.1852 LossAtt 1.0227 TrainAcc 0.3400 TestAcc 0.3929 0.3350
epoch 100 LossPred 0.8715 LossAtt 0.3792 TrainAcc 0.6200 TestAcc 0.6319 0.6350
epoch 200 LossPred 0.8431 LossAtt 0.3690 TrainAcc 0.6400 TestAcc 0.6431 0.6500
epoch 300 LossPred 0.3795 LossAtt 0.4017 TrainAcc 0.8900 TestAcc 0.8749 0.8700
epoch 400 LossPred 0.3884 LossAtt 0.3979 TrainAcc 0.8900 TestAcc 0.8466 0.8550
epoch 500 LossPred 0.3277 LossAtt 0.4097 TrainAcc 0.9100 TestAcc 0.8939 0.8700
epoch 600 LossPred 0.3098 LossAtt 0.4222 TrainAcc 0.9200 TestAcc 0.8901 0.8850
epoch 700 LossPred 0.3157 LossAtt 0.4182 TrainAcc 0.9100 TestAcc 0.8941 0.8800
epoch 800 LossPred 0.2903 LossAtt 0.4107 TrainAcc 0.9300 TestAcc 0.8999 0.8850
epoch 900 LossPred 0.3952 LossAtt 0.4550 TrainAcc 0.8600 TestAcc 0.8138 0.8700
epoch 1000 LossPred 0.2425 LossAtt 0.4481 TrainAcc 0.9400 TestAcc 0.9089 0.9050
epoch 1100 LossPred 0.2305 LossAtt 0.4475 TrainAcc 0.9400 TestAcc 0.9024 0.9100
epoch 1200 LossPred 0.2474 LossAtt 0.4587 TrainAcc 0.9400 TestAcc 0.9142 0.9150
epoch 1300 LossPred 0.2630 LossAtt 0.4769 TrainAcc 0.9200 TestAcc 0.8916 0.8900
epoch 1400 LossPred 0.2292 LossAtt 0.4533 TrainAcc 0.9400 TestAcc 0.8986 0.9050
epoch 1500 LossPred 0.2439 LossAtt 0.4604 TrainAcc 0.9300 TestAcc 0.9062 0.9150
epoch 1600 LossPred 0.3349 LossAtt 0.4683 TrainAcc 0.9000 TestAcc 0.8596 0.8800
epoch 1700 LossPred 0.2143 LossAtt 0.4612 TrainAcc 0.9500 TestAcc 0.8964 0.9100
epoch 1800 LossPred 0.2256 LossAtt 0.4483 TrainAcc 0.9400 TestAcc 0.9059 0.9250
epoch 1900 LossPred 0.2420 LossAtt 0.4747 TrainAcc 0.9200 TestAcc 0.9057 0.9200
epoch 2000 LossPred 0.2113 LossAtt 0.5019 TrainAcc 0.9500 TestAcc 0.8971 0.9150
epoch 2100 LossPred 0.2777 LossAtt 0.4928 TrainAcc 0.9200 TestAcc 0.8884 0.8850
epoch 2200 LossPred 0.1962 LossAtt 0.5230 TrainAcc 0.9400 TestAcc 0.8789 0.9100
epoch 2300 LossPred 0.1827 LossAtt 0.5407 TrainAcc 0.9500 TestAcc 0.8874 0.9300
epoch 2400 LossPred 0.1826 LossAtt 0.5286 TrainAcc 0.9500 TestAcc 0.8911 0.9250
epoch 2500 LossPred 0.1838 LossAtt 0.5422 TrainAcc 0.9400 TestAcc 0.8899 0.9300
Optimization Finished!
********** replication  67  **********
epoch   0 LossPred 1.0016 LossAtt 1.0221 TrainAcc 0.6100 TestAcc 0.5683 0.6050
epoch 100 LossPred 0.8622 LossAtt 0.3882 TrainAcc 0.6800 TestAcc 0.6071 0.6650
epoch 200 LossPred 0.8239 LossAtt 0.2866 TrainAcc 0.6800 TestAcc 0.6071 0.6800
epoch 300 LossPred 0.7020 LossAtt 0.3830 TrainAcc 0.7500 TestAcc 0.6652 0.7600
epoch 400 LossPred 0.2402 LossAtt 0.3223 TrainAcc 0.9300 TestAcc 0.8614 0.9100
epoch 500 LossPred 0.2136 LossAtt 0.2777 TrainAcc 0.9400 TestAcc 0.8636 0.9050
epoch 600 LossPred 0.1990 LossAtt 0.2674 TrainAcc 0.9400 TestAcc 0.8631 0.9050
epoch 700 LossPred 0.1934 LossAtt 0.2544 TrainAcc 0.9400 TestAcc 0.8649 0.9000
epoch 800 LossPred 0.1829 LossAtt 0.2475 TrainAcc 0.9500 TestAcc 0.8629 0.9000
epoch 900 LossPred 0.1839 LossAtt 0.2514 TrainAcc 0.9500 TestAcc 0.8689 0.9000
epoch 1000 LossPred 0.1756 LossAtt 0.2521 TrainAcc 0.9500 TestAcc 0.8704 0.9000
epoch 1100 LossPred 0.1715 LossAtt 0.2589 TrainAcc 0.9500 TestAcc 0.8736 0.8950
epoch 1200 LossPred 0.1804 LossAtt 0.2452 TrainAcc 0.9500 TestAcc 0.8694 0.9000
epoch 1300 LossPred 0.1734 LossAtt 0.2341 TrainAcc 0.9400 TestAcc 0.8739 0.8950
epoch 1400 LossPred 0.1865 LossAtt 0.2505 TrainAcc 0.9400 TestAcc 0.8754 0.9050
epoch 1500 LossPred 0.2435 LossAtt 0.2461 TrainAcc 0.9100 TestAcc 0.8654 0.8850
epoch 1600 LossPred 0.1941 LossAtt 0.2348 TrainAcc 0.9300 TestAcc 0.8751 0.9100
epoch 1700 LossPred 0.1686 LossAtt 0.2457 TrainAcc 0.9500 TestAcc 0.8771 0.9000
epoch 1800 LossPred 0.1746 LossAtt 0.2502 TrainAcc 0.9500 TestAcc 0.8814 0.9000
epoch 1900 LossPred 0.1621 LossAtt 0.2387 TrainAcc 0.9500 TestAcc 0.8784 0.9050
epoch 2000 LossPred 0.1691 LossAtt 0.2486 TrainAcc 0.9500 TestAcc 0.8849 0.9050
epoch 2100 LossPred 0.1676 LossAtt 0.2362 TrainAcc 0.9500 TestAcc 0.8764 0.9000
epoch 2200 LossPred 0.1602 LossAtt 0.2210 TrainAcc 0.9500 TestAcc 0.8876 0.9050
epoch 2300 LossPred 0.1613 LossAtt 0.2560 TrainAcc 0.9500 TestAcc 0.8824 0.9150
epoch 2400 LossPred 0.1598 LossAtt 0.2494 TrainAcc 0.9300 TestAcc 0.8824 0.9200
epoch 2500 LossPred 0.1565 LossAtt 0.2448 TrainAcc 0.9500 TestAcc 0.8844 0.9150
Optimization Finished!
********** replication  68  **********
epoch   0 LossPred 1.0125 LossAtt 1.0062 TrainAcc 0.5700 TestAcc 0.5893 0.5700
epoch 100 LossPred 0.9308 LossAtt 0.6290 TrainAcc 0.6100 TestAcc 0.5393 0.6000
epoch 200 LossPred 0.8817 LossAtt 0.6587 TrainAcc 0.6600 TestAcc 0.6086 0.6500
epoch 300 LossPred 0.8562 LossAtt 0.6738 TrainAcc 0.6400 TestAcc 0.6094 0.6500
epoch 400 LossPred 0.8264 LossAtt 0.6730 TrainAcc 0.6800 TestAcc 0.6144 0.6550
epoch 500 LossPred 0.7574 LossAtt 0.7234 TrainAcc 0.7200 TestAcc 0.5781 0.7050
epoch 600 LossPred 0.7375 LossAtt 0.6906 TrainAcc 0.7500 TestAcc 0.5663 0.7300
epoch 700 LossPred 0.7155 LossAtt 0.6587 TrainAcc 0.7400 TestAcc 0.5508 0.7400
epoch 800 LossPred 0.7120 LossAtt 0.6662 TrainAcc 0.7500 TestAcc 0.5508 0.7350
epoch 900 LossPred 0.7011 LossAtt 0.6749 TrainAcc 0.7600 TestAcc 0.5528 0.7250
epoch 1000 LossPred 0.6970 LossAtt 0.6413 TrainAcc 0.7500 TestAcc 0.5433 0.7250
epoch 1100 LossPred 0.6745 LossAtt 0.6605 TrainAcc 0.7800 TestAcc 0.5368 0.7300
epoch 1200 LossPred 0.6542 LossAtt 0.6288 TrainAcc 0.7800 TestAcc 0.5358 0.7450
epoch 1300 LossPred 0.6314 LossAtt 0.6608 TrainAcc 0.7900 TestAcc 0.5425 0.7650
epoch 1400 LossPred 0.6162 LossAtt 0.6533 TrainAcc 0.8000 TestAcc 0.5465 0.7600
epoch 1500 LossPred 0.5990 LossAtt 0.6860 TrainAcc 0.8300 TestAcc 0.5468 0.7750
epoch 1600 LossPred 0.5767 LossAtt 0.6327 TrainAcc 0.8400 TestAcc 0.5390 0.7550
epoch 1700 LossPred 0.5760 LossAtt 0.6953 TrainAcc 0.8100 TestAcc 0.5418 0.7700
epoch 1800 LossPred 0.5289 LossAtt 0.6680 TrainAcc 0.8600 TestAcc 0.5275 0.7500
epoch 1900 LossPred 0.5149 LossAtt 0.6754 TrainAcc 0.8500 TestAcc 0.5300 0.7650
epoch 2000 LossPred 0.5260 LossAtt 0.7068 TrainAcc 0.8400 TestAcc 0.5275 0.7750
epoch 2100 LossPred 0.4825 LossAtt 0.6918 TrainAcc 0.8500 TestAcc 0.5178 0.7600
epoch 2200 LossPred 0.5036 LossAtt 0.7018 TrainAcc 0.8300 TestAcc 0.5170 0.7350
epoch 2300 LossPred 0.4936 LossAtt 0.6982 TrainAcc 0.8500 TestAcc 0.5240 0.7700
epoch 2400 LossPred 0.4637 LossAtt 0.6553 TrainAcc 0.8600 TestAcc 0.5145 0.7600
epoch 2500 LossPred 0.4579 LossAtt 0.7215 TrainAcc 0.8500 TestAcc 0.5190 0.7550
Optimization Finished!
********** replication  69  **********
epoch   0 LossPred 1.4445 LossAtt 1.0669 TrainAcc 0.4200 TestAcc 0.4489 0.4250
epoch 100 LossPred 1.0071 LossAtt 0.6589 TrainAcc 0.5800 TestAcc 0.4900 0.5700
epoch 200 LossPred 0.8364 LossAtt 0.7284 TrainAcc 0.7300 TestAcc 0.5746 0.7150
epoch 300 LossPred 0.4874 LossAtt 0.7196 TrainAcc 0.9000 TestAcc 0.7990 0.8400
epoch 400 LossPred 0.3063 LossAtt 0.6926 TrainAcc 0.9400 TestAcc 0.8691 0.9100
epoch 500 LossPred 0.2236 LossAtt 0.6650 TrainAcc 0.9400 TestAcc 0.8839 0.9300
epoch 600 LossPred 0.1983 LossAtt 0.6167 TrainAcc 0.9400 TestAcc 0.8904 0.9150
epoch 700 LossPred 0.1857 LossAtt 0.5790 TrainAcc 0.9500 TestAcc 0.8934 0.8950
epoch 800 LossPred 0.1538 LossAtt 0.5688 TrainAcc 0.9500 TestAcc 0.9002 0.9250
epoch 900 LossPred 0.1402 LossAtt 0.5533 TrainAcc 0.9500 TestAcc 0.9054 0.9350
epoch 1000 LossPred 0.1344 LossAtt 0.5657 TrainAcc 0.9700 TestAcc 0.9172 0.9400
epoch 1100 LossPred 0.1090 LossAtt 0.5438 TrainAcc 0.9700 TestAcc 0.9202 0.9400
epoch 1200 LossPred 0.1121 LossAtt 0.5470 TrainAcc 0.9800 TestAcc 0.9164 0.9350
epoch 1300 LossPred 0.0907 LossAtt 0.5424 TrainAcc 0.9900 TestAcc 0.9139 0.9600
epoch 1400 LossPred 0.0813 LossAtt 0.5451 TrainAcc 0.9900 TestAcc 0.9219 0.9450
epoch 1500 LossPred 0.0780 LossAtt 0.5336 TrainAcc 0.9900 TestAcc 0.9209 0.9400
epoch 1600 LossPred 0.0895 LossAtt 0.5056 TrainAcc 0.9700 TestAcc 0.9129 0.9300
epoch 1700 LossPred 0.1378 LossAtt 0.5292 TrainAcc 0.9600 TestAcc 0.8966 0.9400
epoch 1800 LossPred 0.0665 LossAtt 0.5245 TrainAcc 0.9900 TestAcc 0.9154 0.9600
epoch 1900 LossPred 0.0589 LossAtt 0.5229 TrainAcc 0.9900 TestAcc 0.9132 0.9700
epoch 2000 LossPred 0.0511 LossAtt 0.5205 TrainAcc 1.0000 TestAcc 0.9134 0.9650
Optimization Finished!
********** replication  70  **********
epoch   0 LossPred 1.1315 LossAtt 1.0332 TrainAcc 0.5700 TestAcc 0.5568 0.5500
epoch 100 LossPred 0.9326 LossAtt 0.6623 TrainAcc 0.6200 TestAcc 0.5578 0.6350
epoch 200 LossPred 0.8951 LossAtt 0.6445 TrainAcc 0.6600 TestAcc 0.5581 0.6650
epoch 300 LossPred 0.8386 LossAtt 0.6536 TrainAcc 0.6800 TestAcc 0.5808 0.6850
epoch 400 LossPred 0.7493 LossAtt 0.6753 TrainAcc 0.6900 TestAcc 0.6321 0.6850
epoch 500 LossPred 0.4492 LossAtt 0.7115 TrainAcc 0.8800 TestAcc 0.8163 0.8450
epoch 600 LossPred 0.3853 LossAtt 0.6702 TrainAcc 0.9100 TestAcc 0.8201 0.8350
epoch 700 LossPred 0.3641 LossAtt 0.6784 TrainAcc 0.8900 TestAcc 0.8228 0.8550
epoch 800 LossPred 0.3413 LossAtt 0.6576 TrainAcc 0.8900 TestAcc 0.8153 0.8600
epoch 900 LossPred 0.3203 LossAtt 0.6237 TrainAcc 0.9200 TestAcc 0.8118 0.8750
epoch 1000 LossPred 0.3209 LossAtt 0.6220 TrainAcc 0.9200 TestAcc 0.7980 0.8600
epoch 1100 LossPred 0.3024 LossAtt 0.6100 TrainAcc 0.9200 TestAcc 0.8136 0.8850
epoch 1200 LossPred 0.3074 LossAtt 0.6379 TrainAcc 0.9200 TestAcc 0.8111 0.8700
epoch 1300 LossPred 0.2878 LossAtt 0.6400 TrainAcc 0.9300 TestAcc 0.7995 0.8700
epoch 1400 LossPred 0.2814 LossAtt 0.6605 TrainAcc 0.9100 TestAcc 0.8061 0.8600
epoch 1500 LossPred 0.2646 LossAtt 0.6312 TrainAcc 0.9200 TestAcc 0.8008 0.8600
epoch 1600 LossPred 0.2744 LossAtt 0.6288 TrainAcc 0.9200 TestAcc 0.8181 0.9000
epoch 1700 LossPred 0.2536 LossAtt 0.6355 TrainAcc 0.9200 TestAcc 0.7940 0.8600
epoch 1800 LossPred 0.2602 LossAtt 0.6405 TrainAcc 0.9100 TestAcc 0.7985 0.8650
epoch 1900 LossPred 0.2493 LossAtt 0.6240 TrainAcc 0.9400 TestAcc 0.8078 0.8900
epoch 2000 LossPred 0.2287 LossAtt 0.6706 TrainAcc 0.9300 TestAcc 0.8061 0.8750
epoch 2100 LossPred 0.2215 LossAtt 0.6416 TrainAcc 0.9300 TestAcc 0.8056 0.8800
epoch 2200 LossPred 0.2300 LossAtt 0.6177 TrainAcc 0.9300 TestAcc 0.8101 0.8900
epoch 2300 LossPred 0.2136 LossAtt 0.6543 TrainAcc 0.9400 TestAcc 0.8063 0.8800
epoch 2400 LossPred 0.2170 LossAtt 0.6325 TrainAcc 0.9300 TestAcc 0.7968 0.8650
epoch 2500 LossPred 0.2404 LossAtt 0.6422 TrainAcc 0.9200 TestAcc 0.8148 0.9000
Optimization Finished!
********** replication  71  **********
epoch   0 LossPred 1.0481 LossAtt 1.0079 TrainAcc 0.5400 TestAcc 0.5440 0.5650
epoch 100 LossPred 0.9685 LossAtt 0.5958 TrainAcc 0.5800 TestAcc 0.5836 0.5650
epoch 200 LossPred 0.9300 LossAtt 0.5533 TrainAcc 0.6200 TestAcc 0.5938 0.6150
epoch 300 LossPred 0.7683 LossAtt 0.6360 TrainAcc 0.7700 TestAcc 0.6872 0.7450
epoch 400 LossPred 0.4806 LossAtt 0.5064 TrainAcc 0.8500 TestAcc 0.8739 0.8300
epoch 500 LossPred 0.4072 LossAtt 0.6120 TrainAcc 0.8700 TestAcc 0.8956 0.8800
epoch 600 LossPred 0.3198 LossAtt 0.6467 TrainAcc 0.8800 TestAcc 0.9242 0.8700
epoch 700 LossPred 0.2360 LossAtt 0.6530 TrainAcc 0.9500 TestAcc 0.9752 0.9000
epoch 800 LossPred 0.1421 LossAtt 0.6555 TrainAcc 0.9700 TestAcc 0.9452 0.9350
epoch 900 LossPred 0.1184 LossAtt 0.6254 TrainAcc 0.9700 TestAcc 0.9292 0.9600
epoch 1000 LossPred 0.1007 LossAtt 0.6145 TrainAcc 0.9700 TestAcc 0.9199 0.9550
epoch 1100 LossPred 0.0787 LossAtt 0.6011 TrainAcc 1.0000 TestAcc 0.9207 0.9600
Optimization Finished!
********** replication  72  **********
epoch   0 LossPred 1.0229 LossAtt 0.9942 TrainAcc 0.5400 TestAcc 0.5571 0.5350
epoch 100 LossPred 0.8727 LossAtt 0.5796 TrainAcc 0.6400 TestAcc 0.5976 0.6350
epoch 200 LossPred 0.5495 LossAtt 0.6988 TrainAcc 0.8200 TestAcc 0.7893 0.8050
epoch 300 LossPred 0.3114 LossAtt 0.6350 TrainAcc 0.9000 TestAcc 0.8611 0.8900
epoch 400 LossPred 0.1656 LossAtt 0.6088 TrainAcc 0.9600 TestAcc 0.9254 0.9400
epoch 500 LossPred 0.1408 LossAtt 0.5998 TrainAcc 0.9600 TestAcc 0.9277 0.9450
epoch 600 LossPred 0.2664 LossAtt 0.5282 TrainAcc 0.9200 TestAcc 0.8341 0.8900
epoch 700 LossPred 0.1381 LossAtt 0.4675 TrainAcc 0.9800 TestAcc 0.9464 0.9600
epoch 800 LossPred 0.1180 LossAtt 0.4421 TrainAcc 0.9600 TestAcc 0.9249 0.9650
epoch 900 LossPred 0.1057 LossAtt 0.4186 TrainAcc 0.9600 TestAcc 0.9282 0.9550
epoch 1000 LossPred 0.0998 LossAtt 0.4095 TrainAcc 0.9700 TestAcc 0.9342 0.9600
epoch 1100 LossPred 0.1048 LossAtt 0.3773 TrainAcc 0.9900 TestAcc 0.9484 0.9700
epoch 1200 LossPred 0.2124 LossAtt 0.3652 TrainAcc 0.9100 TestAcc 0.8911 0.9150
epoch 1300 LossPred 0.1137 LossAtt 0.3472 TrainAcc 0.9900 TestAcc 0.9109 0.9700
epoch 1400 LossPred 0.1027 LossAtt 0.3366 TrainAcc 0.9700 TestAcc 0.9444 0.9500
epoch 1500 LossPred 0.0895 LossAtt 0.3251 TrainAcc 0.9800 TestAcc 0.9577 0.9750
epoch 1600 LossPred 0.1077 LossAtt 0.3290 TrainAcc 0.9700 TestAcc 0.9482 0.9550
epoch 1700 LossPred 0.0947 LossAtt 0.3294 TrainAcc 0.9900 TestAcc 0.9174 0.9550
epoch 1800 LossPred 0.0736 LossAtt 0.3111 TrainAcc 0.9900 TestAcc 0.9262 0.9600
epoch 1900 LossPred 0.0669 LossAtt 0.3150 TrainAcc 0.9800 TestAcc 0.9535 0.9900
epoch 2000 LossPred 0.2768 LossAtt 0.3177 TrainAcc 0.9100 TestAcc 0.8746 0.8900
epoch 2100 LossPred 0.0974 LossAtt 0.3079 TrainAcc 0.9700 TestAcc 0.8924 0.9400
epoch 2200 LossPred 0.1785 LossAtt 0.3283 TrainAcc 0.9400 TestAcc 0.8591 0.9150
epoch 2300 LossPred 0.0685 LossAtt 0.3224 TrainAcc 0.9800 TestAcc 0.9404 0.9700
epoch 2400 LossPred 0.0753 LossAtt 0.3041 TrainAcc 0.9900 TestAcc 0.9322 0.9800
epoch 2500 LossPred 0.0786 LossAtt 0.3077 TrainAcc 0.9800 TestAcc 0.9499 0.9650
Optimization Finished!
********** replication  73  **********
epoch   0 LossPred 1.1427 LossAtt 1.0227 TrainAcc 0.5100 TestAcc 0.5766 0.4550
epoch 100 LossPred 0.9788 LossAtt 0.4116 TrainAcc 0.5500 TestAcc 0.6086 0.5500
epoch 200 LossPred 0.9682 LossAtt 0.3723 TrainAcc 0.5500 TestAcc 0.6261 0.5550
epoch 300 LossPred 0.9520 LossAtt 0.4594 TrainAcc 0.5600 TestAcc 0.6527 0.5600
epoch 400 LossPred 0.5413 LossAtt 0.5300 TrainAcc 0.8400 TestAcc 0.7930 0.8500
epoch 500 LossPred 0.4631 LossAtt 0.5214 TrainAcc 0.8600 TestAcc 0.8063 0.8400
epoch 600 LossPred 0.4971 LossAtt 0.4982 TrainAcc 0.8400 TestAcc 0.7918 0.8350
epoch 700 LossPred 0.4140 LossAtt 0.5048 TrainAcc 0.8700 TestAcc 0.8253 0.8400
epoch 800 LossPred 0.4166 LossAtt 0.4808 TrainAcc 0.8400 TestAcc 0.8191 0.8550
epoch 900 LossPred 0.4439 LossAtt 0.4803 TrainAcc 0.8700 TestAcc 0.8323 0.8600
epoch 1000 LossPred 0.4122 LossAtt 0.4673 TrainAcc 0.8500 TestAcc 0.8198 0.8400
epoch 1100 LossPred 0.3706 LossAtt 0.4625 TrainAcc 0.8900 TestAcc 0.8436 0.8600
epoch 1200 LossPred 0.3220 LossAtt 0.4458 TrainAcc 0.9100 TestAcc 0.8381 0.8700
epoch 1300 LossPred 0.3209 LossAtt 0.4652 TrainAcc 0.9200 TestAcc 0.8448 0.8700
epoch 1400 LossPred 0.2937 LossAtt 0.4295 TrainAcc 0.9200 TestAcc 0.8441 0.8650
epoch 1500 LossPred 0.2907 LossAtt 0.4388 TrainAcc 0.9200 TestAcc 0.8468 0.8600
epoch 1600 LossPred 0.3115 LossAtt 0.4305 TrainAcc 0.9000 TestAcc 0.8441 0.8750
epoch 1700 LossPred 0.2964 LossAtt 0.4352 TrainAcc 0.9100 TestAcc 0.8428 0.8850
epoch 1800 LossPred 0.3332 LossAtt 0.4343 TrainAcc 0.9100 TestAcc 0.8481 0.8550
epoch 1900 LossPred 0.2938 LossAtt 0.4234 TrainAcc 0.9100 TestAcc 0.8353 0.8700
epoch 2000 LossPred 0.2973 LossAtt 0.3965 TrainAcc 0.9100 TestAcc 0.8446 0.8850
epoch 2100 LossPred 0.3288 LossAtt 0.4153 TrainAcc 0.9100 TestAcc 0.8353 0.8550
epoch 2200 LossPred 0.3071 LossAtt 0.4011 TrainAcc 0.9100 TestAcc 0.8278 0.8750
epoch 2300 LossPred 0.2935 LossAtt 0.3991 TrainAcc 0.9100 TestAcc 0.8308 0.8800
epoch 2400 LossPred 0.2953 LossAtt 0.3951 TrainAcc 0.9100 TestAcc 0.8371 0.8850
epoch 2500 LossPred 0.2966 LossAtt 0.4141 TrainAcc 0.9100 TestAcc 0.8436 0.8800
Optimization Finished!
********** replication  74  **********
epoch   0 LossPred 1.0143 LossAtt 1.0032 TrainAcc 0.5100 TestAcc 0.4677 0.5350
epoch 100 LossPred 0.8898 LossAtt 0.4436 TrainAcc 0.6600 TestAcc 0.6136 0.6550
epoch 200 LossPred 0.8789 LossAtt 0.3944 TrainAcc 0.6600 TestAcc 0.6136 0.6600
epoch 300 LossPred 0.8656 LossAtt 0.4155 TrainAcc 0.6600 TestAcc 0.6136 0.6600
epoch 400 LossPred 0.8407 LossAtt 0.5652 TrainAcc 0.6600 TestAcc 0.6136 0.6600
epoch 500 LossPred 0.7372 LossAtt 0.6089 TrainAcc 0.7200 TestAcc 0.6419 0.7200
epoch 600 LossPred 0.2666 LossAtt 0.6661 TrainAcc 0.9300 TestAcc 0.8511 0.9300
epoch 700 LossPred 0.1251 LossAtt 0.5788 TrainAcc 0.9700 TestAcc 0.9199 0.9750
epoch 800 LossPred 0.0885 LossAtt 0.5620 TrainAcc 0.9900 TestAcc 0.9237 0.9750
epoch 900 LossPred 0.0662 LossAtt 0.5637 TrainAcc 0.9900 TestAcc 0.9247 0.9800
epoch 1000 LossPred 0.0555 LossAtt 0.5884 TrainAcc 0.9900 TestAcc 0.9192 0.9850
epoch 1100 LossPred 0.0501 LossAtt 0.5659 TrainAcc 0.9900 TestAcc 0.9204 0.9900
epoch 1200 LossPred 0.0527 LossAtt 0.5536 TrainAcc 0.9900 TestAcc 0.9272 0.9800
epoch 1300 LossPred 0.0440 LossAtt 0.5411 TrainAcc 0.9900 TestAcc 0.9192 0.9900
epoch 1400 LossPred 0.0423 LossAtt 0.5537 TrainAcc 0.9900 TestAcc 0.9217 0.9900
epoch 1500 LossPred 0.0326 LossAtt 0.5156 TrainAcc 0.9900 TestAcc 0.9234 0.9900
epoch 1600 LossPred 0.0382 LossAtt 0.5443 TrainAcc 0.9900 TestAcc 0.9364 0.9800
epoch 1700 LossPred 0.0218 LossAtt 0.5261 TrainAcc 1.0000 TestAcc 0.9277 0.9900
Optimization Finished!
********** replication  75  **********
epoch   0 LossPred 1.4474 LossAtt 1.0106 TrainAcc 0.4500 TestAcc 0.5153 0.4450
epoch 100 LossPred 1.0983 LossAtt 0.7147 TrainAcc 0.5200 TestAcc 0.5363 0.4900
epoch 200 LossPred 0.9866 LossAtt 0.7282 TrainAcc 0.5600 TestAcc 0.6231 0.5800
epoch 300 LossPred 0.8390 LossAtt 0.8629 TrainAcc 0.6700 TestAcc 0.6869 0.6600
epoch 400 LossPred 0.4683 LossAtt 0.7713 TrainAcc 0.8700 TestAcc 0.8331 0.8750
epoch 500 LossPred 0.3240 LossAtt 0.7426 TrainAcc 0.9300 TestAcc 0.8834 0.9100
epoch 600 LossPred 0.2924 LossAtt 0.7283 TrainAcc 0.9200 TestAcc 0.8814 0.9150
epoch 700 LossPred 0.2639 LossAtt 0.7013 TrainAcc 0.9300 TestAcc 0.8861 0.9150
epoch 800 LossPred 0.2772 LossAtt 0.6958 TrainAcc 0.9200 TestAcc 0.8766 0.9000
epoch 900 LossPred 0.3200 LossAtt 0.6759 TrainAcc 0.9100 TestAcc 0.8556 0.8950
epoch 1000 LossPred 0.2014 LossAtt 0.6331 TrainAcc 0.9400 TestAcc 0.8931 0.9250
epoch 1100 LossPred 0.2026 LossAtt 0.6648 TrainAcc 0.9500 TestAcc 0.8939 0.9400
epoch 1200 LossPred 0.2012 LossAtt 0.6423 TrainAcc 0.9400 TestAcc 0.8916 0.9250
epoch 1300 LossPred 0.1895 LossAtt 0.6354 TrainAcc 0.9400 TestAcc 0.8924 0.9400
epoch 1400 LossPred 0.1796 LossAtt 0.6322 TrainAcc 0.9600 TestAcc 0.8966 0.9400
epoch 1500 LossPred 0.1769 LossAtt 0.6547 TrainAcc 0.9400 TestAcc 0.8881 0.9300
epoch 1600 LossPred 0.1637 LossAtt 0.6586 TrainAcc 0.9400 TestAcc 0.8884 0.9400
epoch 1700 LossPred 0.1696 LossAtt 0.6398 TrainAcc 0.9500 TestAcc 0.8871 0.9250
epoch 1800 LossPred 0.1907 LossAtt 0.6403 TrainAcc 0.9300 TestAcc 0.8826 0.9150
epoch 1900 LossPred 0.1698 LossAtt 0.6430 TrainAcc 0.9500 TestAcc 0.8821 0.9200
epoch 2000 LossPred 0.1337 LossAtt 0.6114 TrainAcc 0.9700 TestAcc 0.8941 0.9400
epoch 2100 LossPred 0.1605 LossAtt 0.6152 TrainAcc 0.9600 TestAcc 0.8816 0.9450
epoch 2200 LossPred 0.1342 LossAtt 0.6159 TrainAcc 0.9700 TestAcc 0.8906 0.9450
epoch 2300 LossPred 0.2017 LossAtt 0.6322 TrainAcc 0.9400 TestAcc 0.8751 0.9250
epoch 2400 LossPred 0.1969 LossAtt 0.5969 TrainAcc 0.9400 TestAcc 0.8829 0.9200
epoch 2500 LossPred 0.3398 LossAtt 0.6129 TrainAcc 0.8800 TestAcc 0.8581 0.8850
Optimization Finished!
********** replication  76  **********
epoch   0 LossPred 1.1065 LossAtt 0.9742 TrainAcc 0.5100 TestAcc 0.5533 0.5350
epoch 100 LossPred 0.8965 LossAtt 0.4864 TrainAcc 0.6700 TestAcc 0.6274 0.6800
epoch 200 LossPred 0.8500 LossAtt 0.4430 TrainAcc 0.7600 TestAcc 0.6464 0.7500
epoch 300 LossPred 0.8007 LossAtt 0.4185 TrainAcc 0.7400 TestAcc 0.6226 0.7450
epoch 400 LossPred 0.7361 LossAtt 0.4316 TrainAcc 0.7600 TestAcc 0.6532 0.7650
epoch 500 LossPred 0.6800 LossAtt 0.4312 TrainAcc 0.7700 TestAcc 0.6534 0.7750
epoch 600 LossPred 0.6402 LossAtt 0.5146 TrainAcc 0.7700 TestAcc 0.6554 0.7750
epoch 700 LossPred 0.4653 LossAtt 0.7707 TrainAcc 0.8400 TestAcc 0.7007 0.8000
epoch 800 LossPred 0.1747 LossAtt 0.7454 TrainAcc 0.9500 TestAcc 0.8626 0.9000
epoch 900 LossPred 0.1298 LossAtt 0.7324 TrainAcc 0.9500 TestAcc 0.8716 0.9100
epoch 1000 LossPred 0.0908 LossAtt 0.7190 TrainAcc 0.9800 TestAcc 0.8759 0.9200
epoch 1100 LossPred 0.1071 LossAtt 0.7328 TrainAcc 0.9600 TestAcc 0.8696 0.9300
epoch 1200 LossPred 0.0723 LossAtt 0.7032 TrainAcc 0.9900 TestAcc 0.8831 0.9400
epoch 1300 LossPred 0.0598 LossAtt 0.6805 TrainAcc 0.9900 TestAcc 0.8829 0.9600
epoch 1400 LossPred 0.0573 LossAtt 0.6490 TrainAcc 0.9900 TestAcc 0.8844 0.9600
epoch 1500 LossPred 0.0577 LossAtt 0.6544 TrainAcc 0.9800 TestAcc 0.8789 0.9600
epoch 1600 LossPred 0.0519 LossAtt 0.6697 TrainAcc 0.9900 TestAcc 0.8789 0.9550
epoch 1700 LossPred 0.0263 LossAtt 0.6733 TrainAcc 1.0000 TestAcc 0.8884 0.9650
Optimization Finished!
********** replication  77  **********
epoch   0 LossPred 0.9805 LossAtt 1.0074 TrainAcc 0.5600 TestAcc 0.5748 0.5600
epoch 100 LossPred 0.8882 LossAtt 0.6394 TrainAcc 0.6700 TestAcc 0.6519 0.6350
epoch 200 LossPred 0.6556 LossAtt 0.6994 TrainAcc 0.7800 TestAcc 0.7863 0.7950
epoch 300 LossPred 0.3535 LossAtt 0.6667 TrainAcc 0.9100 TestAcc 0.9039 0.8600
epoch 400 LossPred 0.2892 LossAtt 0.6435 TrainAcc 0.9300 TestAcc 0.9274 0.8950
epoch 500 LossPred 0.2222 LossAtt 0.6391 TrainAcc 0.9600 TestAcc 0.9389 0.9200
epoch 600 LossPred 0.1838 LossAtt 0.6178 TrainAcc 0.9800 TestAcc 0.9374 0.9250
epoch 700 LossPred 0.1563 LossAtt 0.6027 TrainAcc 0.9700 TestAcc 0.9402 0.9300
epoch 800 LossPred 0.1564 LossAtt 0.5659 TrainAcc 0.9700 TestAcc 0.9289 0.9100
epoch 900 LossPred 0.1298 LossAtt 0.5643 TrainAcc 0.9800 TestAcc 0.9434 0.9400
epoch 1000 LossPred 0.1269 LossAtt 0.5378 TrainAcc 0.9800 TestAcc 0.9402 0.9350
epoch 1100 LossPred 0.1276 LossAtt 0.5440 TrainAcc 0.9800 TestAcc 0.9342 0.9150
epoch 1200 LossPred 0.0929 LossAtt 0.5614 TrainAcc 0.9900 TestAcc 0.9384 0.9200
epoch 1300 LossPred 0.0819 LossAtt 0.5869 TrainAcc 1.0000 TestAcc 0.9349 0.9250
Optimization Finished!
********** replication  78  **********
epoch   0 LossPred 0.9202 LossAtt 0.9921 TrainAcc 0.6200 TestAcc 0.5753 0.6150
epoch 100 LossPred 0.7552 LossAtt 0.6527 TrainAcc 0.7300 TestAcc 0.6542 0.7200
epoch 200 LossPred 0.3152 LossAtt 0.5300 TrainAcc 0.9200 TestAcc 0.8699 0.8700
epoch 300 LossPred 0.2525 LossAtt 0.5156 TrainAcc 0.9200 TestAcc 0.8766 0.8400
epoch 400 LossPred 0.2213 LossAtt 0.5590 TrainAcc 0.9400 TestAcc 0.9122 0.8700
epoch 500 LossPred 0.1800 LossAtt 0.5587 TrainAcc 0.9500 TestAcc 0.8961 0.9050
epoch 600 LossPred 0.1748 LossAtt 0.5712 TrainAcc 0.9300 TestAcc 0.9202 0.9100
epoch 700 LossPred 0.1671 LossAtt 0.5450 TrainAcc 0.9600 TestAcc 0.9339 0.9200
epoch 800 LossPred 0.3056 LossAtt 0.5090 TrainAcc 0.8800 TestAcc 0.8453 0.8750
epoch 900 LossPred 0.2271 LossAtt 0.5112 TrainAcc 0.9100 TestAcc 0.8721 0.8800
epoch 1000 LossPred 0.1549 LossAtt 0.4926 TrainAcc 0.9300 TestAcc 0.9154 0.9100
epoch 1100 LossPred 0.1104 LossAtt 0.4964 TrainAcc 0.9800 TestAcc 0.9552 0.9250
epoch 1200 LossPred 0.1080 LossAtt 0.4717 TrainAcc 0.9700 TestAcc 0.9492 0.9300
epoch 1300 LossPred 0.0934 LossAtt 0.4490 TrainAcc 0.9800 TestAcc 0.9497 0.9350
epoch 1400 LossPred 0.0683 LossAtt 0.4344 TrainAcc 0.9700 TestAcc 0.9447 0.9600
epoch 1500 LossPred 0.0579 LossAtt 0.4346 TrainAcc 0.9800 TestAcc 0.9499 0.9650
epoch 1600 LossPred 0.0388 LossAtt 0.4154 TrainAcc 1.0000 TestAcc 0.9640 0.9900
Optimization Finished!
********** replication  79  **********
epoch   0 LossPred 1.2078 LossAtt 1.0543 TrainAcc 0.4000 TestAcc 0.4710 0.4150
epoch 100 LossPred 0.9016 LossAtt 0.5434 TrainAcc 0.6600 TestAcc 0.6214 0.6450
epoch 200 LossPred 0.8014 LossAtt 0.5952 TrainAcc 0.7200 TestAcc 0.6627 0.6650
epoch 300 LossPred 0.3084 LossAtt 0.6039 TrainAcc 0.9100 TestAcc 0.8911 0.9000
epoch 400 LossPred 0.2359 LossAtt 0.5773 TrainAcc 0.9400 TestAcc 0.9109 0.8750
epoch 500 LossPred 0.1770 LossAtt 0.5089 TrainAcc 0.9500 TestAcc 0.9247 0.9150
epoch 600 LossPred 0.1522 LossAtt 0.4790 TrainAcc 0.9600 TestAcc 0.9349 0.9450
epoch 700 LossPred 0.2695 LossAtt 0.4427 TrainAcc 0.8900 TestAcc 0.8879 0.8750
epoch 800 LossPred 0.1861 LossAtt 0.4525 TrainAcc 0.9300 TestAcc 0.9232 0.9100
epoch 900 LossPred 0.1241 LossAtt 0.4378 TrainAcc 0.9800 TestAcc 0.9457 0.9350
epoch 1000 LossPred 0.1441 LossAtt 0.4489 TrainAcc 0.9600 TestAcc 0.9322 0.9450
epoch 1100 LossPred 0.1382 LossAtt 0.4397 TrainAcc 0.9600 TestAcc 0.9329 0.9300
epoch 1200 LossPred 0.1490 LossAtt 0.4415 TrainAcc 0.9600 TestAcc 0.9294 0.9350
epoch 1300 LossPred 0.1106 LossAtt 0.4394 TrainAcc 0.9600 TestAcc 0.9482 0.9550
epoch 1400 LossPred 0.1187 LossAtt 0.4345 TrainAcc 0.9600 TestAcc 0.9407 0.9500
epoch 1500 LossPred 0.1683 LossAtt 0.4517 TrainAcc 0.9300 TestAcc 0.9309 0.9150
epoch 1600 LossPred 0.2510 LossAtt 0.4386 TrainAcc 0.9100 TestAcc 0.8876 0.8850
epoch 1700 LossPred 0.1170 LossAtt 0.4338 TrainAcc 0.9600 TestAcc 0.9417 0.9550
epoch 1800 LossPred 0.1251 LossAtt 0.4221 TrainAcc 0.9600 TestAcc 0.9407 0.9350
epoch 1900 LossPred 0.1317 LossAtt 0.4547 TrainAcc 0.9500 TestAcc 0.9297 0.9350
epoch 2000 LossPred 0.1546 LossAtt 0.4322 TrainAcc 0.9500 TestAcc 0.9172 0.9400
epoch 2100 LossPred 0.1233 LossAtt 0.4278 TrainAcc 0.9600 TestAcc 0.9409 0.9300
epoch 2200 LossPred 0.0965 LossAtt 0.4419 TrainAcc 0.9800 TestAcc 0.9512 0.9550
epoch 2300 LossPred 0.0865 LossAtt 0.4502 TrainAcc 0.9800 TestAcc 0.9557 0.9650
epoch 2400 LossPred 0.1082 LossAtt 0.4399 TrainAcc 0.9700 TestAcc 0.9387 0.9350
epoch 2500 LossPred 0.2310 LossAtt 0.4513 TrainAcc 0.9100 TestAcc 0.9014 0.9100
Optimization Finished!
********** replication  80  **********
epoch   0 LossPred 1.0892 LossAtt 1.0241 TrainAcc 0.4800 TestAcc 0.4379 0.4600
epoch 100 LossPred 0.9745 LossAtt 0.6760 TrainAcc 0.6000 TestAcc 0.5310 0.5850
epoch 200 LossPred 0.8943 LossAtt 0.7412 TrainAcc 0.6300 TestAcc 0.5998 0.6450
epoch 300 LossPred 0.4976 LossAtt 0.7766 TrainAcc 0.8600 TestAcc 0.8088 0.8400
epoch 400 LossPred 0.3526 LossAtt 0.6656 TrainAcc 0.9000 TestAcc 0.8506 0.8900
epoch 500 LossPred 0.2404 LossAtt 0.5590 TrainAcc 0.9400 TestAcc 0.8694 0.9000
epoch 600 LossPred 0.2733 LossAtt 0.5146 TrainAcc 0.9000 TestAcc 0.8771 0.8750
epoch 700 LossPred 0.2263 LossAtt 0.4918 TrainAcc 0.9500 TestAcc 0.8796 0.9100
epoch 800 LossPred 0.1721 LossAtt 0.4762 TrainAcc 0.9600 TestAcc 0.8979 0.9150
epoch 900 LossPred 0.1141 LossAtt 0.4311 TrainAcc 0.9800 TestAcc 0.9297 0.9350
epoch 1000 LossPred 0.1791 LossAtt 0.4114 TrainAcc 0.9300 TestAcc 0.9199 0.8900
epoch 1100 LossPred 0.0950 LossAtt 0.4249 TrainAcc 0.9900 TestAcc 0.9367 0.9550
epoch 1200 LossPred 0.1359 LossAtt 0.4195 TrainAcc 0.9700 TestAcc 0.9389 0.9300
epoch 1300 LossPred 0.0900 LossAtt 0.4445 TrainAcc 0.9800 TestAcc 0.9364 0.9600
epoch 1400 LossPred 0.1402 LossAtt 0.4327 TrainAcc 0.9700 TestAcc 0.9447 0.9200
epoch 1500 LossPred 0.2359 LossAtt 0.4241 TrainAcc 0.9300 TestAcc 0.9327 0.8850
epoch 1600 LossPred 0.3281 LossAtt 0.4368 TrainAcc 0.9100 TestAcc 0.8571 0.8800
epoch 1700 LossPred 0.1806 LossAtt 0.4113 TrainAcc 0.9500 TestAcc 0.9364 0.9000
epoch 1800 LossPred 0.1588 LossAtt 0.4015 TrainAcc 0.9500 TestAcc 0.9079 0.9250
epoch 1900 LossPred 0.1065 LossAtt 0.4005 TrainAcc 0.9700 TestAcc 0.9224 0.9550
epoch 2000 LossPred 0.1374 LossAtt 0.4134 TrainAcc 0.9600 TestAcc 0.9412 0.9300
epoch 2100 LossPred 0.2109 LossAtt 0.3970 TrainAcc 0.9400 TestAcc 0.9062 0.9450
epoch 2200 LossPred 0.1838 LossAtt 0.3685 TrainAcc 0.9500 TestAcc 0.9242 0.8750
epoch 2300 LossPred 0.1191 LossAtt 0.3915 TrainAcc 0.9600 TestAcc 0.9079 0.9500
epoch 2400 LossPred 0.4033 LossAtt 0.3921 TrainAcc 0.8700 TestAcc 0.8496 0.8800
epoch 2500 LossPred 0.0915 LossAtt 0.4093 TrainAcc 0.9700 TestAcc 0.9409 0.9550
Optimization Finished!
********** replication  81  **********
epoch   0 LossPred 1.1048 LossAtt 1.0142 TrainAcc 0.5200 TestAcc 0.4492 0.4800
epoch 100 LossPred 0.9630 LossAtt 0.4276 TrainAcc 0.5900 TestAcc 0.6096 0.5900
epoch 200 LossPred 0.9478 LossAtt 0.3946 TrainAcc 0.5900 TestAcc 0.6096 0.5900
epoch 300 LossPred 0.9166 LossAtt 0.3334 TrainAcc 0.5900 TestAcc 0.6374 0.6050
epoch 400 LossPred 0.4234 LossAtt 0.4497 TrainAcc 0.8600 TestAcc 0.8343 0.8750
epoch 500 LossPred 0.3184 LossAtt 0.4216 TrainAcc 0.9100 TestAcc 0.8509 0.9200
epoch 600 LossPred 0.4999 LossAtt 0.4084 TrainAcc 0.8100 TestAcc 0.7830 0.8250
epoch 700 LossPred 0.2661 LossAtt 0.4161 TrainAcc 0.9100 TestAcc 0.8721 0.9300
epoch 800 LossPred 0.2937 LossAtt 0.4097 TrainAcc 0.9100 TestAcc 0.8919 0.9100
epoch 900 LossPred 0.2182 LossAtt 0.3807 TrainAcc 0.9200 TestAcc 0.9059 0.9400
epoch 1000 LossPred 0.2580 LossAtt 0.3783 TrainAcc 0.9200 TestAcc 0.8406 0.9250
epoch 1100 LossPred 0.1325 LossAtt 0.3719 TrainAcc 0.9500 TestAcc 0.9184 0.9750
epoch 1200 LossPred 0.1594 LossAtt 0.3700 TrainAcc 0.9400 TestAcc 0.9167 0.9550
epoch 1300 LossPred 0.2800 LossAtt 0.3923 TrainAcc 0.9100 TestAcc 0.8291 0.9150
epoch 1400 LossPred 0.2375 LossAtt 0.3740 TrainAcc 0.9200 TestAcc 0.9057 0.9350
epoch 1500 LossPred 0.4130 LossAtt 0.3881 TrainAcc 0.8500 TestAcc 0.8684 0.8750
epoch 1600 LossPred 0.2099 LossAtt 0.3778 TrainAcc 0.9400 TestAcc 0.9032 0.9400
epoch 1700 LossPred 0.1989 LossAtt 0.3851 TrainAcc 0.9400 TestAcc 0.8909 0.9500
epoch 1800 LossPred 0.3584 LossAtt 0.3661 TrainAcc 0.8800 TestAcc 0.7958 0.9100
epoch 1900 LossPred 0.2770 LossAtt 0.3496 TrainAcc 0.9200 TestAcc 0.8471 0.9200
epoch 2000 LossPred 0.1396 LossAtt 0.3338 TrainAcc 0.9600 TestAcc 0.9229 0.9650
epoch 2100 LossPred 0.2055 LossAtt 0.3301 TrainAcc 0.9400 TestAcc 0.9022 0.9250
epoch 2200 LossPred 0.1848 LossAtt 0.3216 TrainAcc 0.9200 TestAcc 0.8824 0.9400
epoch 2300 LossPred 0.2939 LossAtt 0.3157 TrainAcc 0.9000 TestAcc 0.8228 0.9100
epoch 2400 LossPred 0.3282 LossAtt 0.3186 TrainAcc 0.9000 TestAcc 0.8744 0.8950
epoch 2500 LossPred 0.2060 LossAtt 0.3233 TrainAcc 0.9200 TestAcc 0.8844 0.9350
Optimization Finished!
********** replication  82  **********
epoch   0 LossPred 1.1019 LossAtt 0.9960 TrainAcc 0.5100 TestAcc 0.5000 0.5200
epoch 100 LossPred 0.8178 LossAtt 0.3698 TrainAcc 0.7000 TestAcc 0.6361 0.6550
epoch 200 LossPred 0.6455 LossAtt 0.3984 TrainAcc 0.7800 TestAcc 0.7002 0.7700
epoch 300 LossPred 0.3481 LossAtt 0.3823 TrainAcc 0.8800 TestAcc 0.8604 0.8800
epoch 400 LossPred 0.2390 LossAtt 0.3782 TrainAcc 0.9500 TestAcc 0.9257 0.9200
epoch 500 LossPred 0.2685 LossAtt 0.3527 TrainAcc 0.9100 TestAcc 0.8926 0.9050
epoch 600 LossPred 0.5085 LossAtt 0.3934 TrainAcc 0.8100 TestAcc 0.7635 0.8000
epoch 700 LossPred 0.4231 LossAtt 0.3880 TrainAcc 0.8400 TestAcc 0.8098 0.8500
epoch 800 LossPred 0.2995 LossAtt 0.3784 TrainAcc 0.8900 TestAcc 0.8536 0.8950
epoch 900 LossPred 0.3954 LossAtt 0.3770 TrainAcc 0.8700 TestAcc 0.8101 0.8500
epoch 1000 LossPred 0.2646 LossAtt 0.4014 TrainAcc 0.8900 TestAcc 0.8804 0.9050
epoch 1100 LossPred 0.1992 LossAtt 0.3999 TrainAcc 0.9500 TestAcc 0.9317 0.9250
epoch 1200 LossPred 0.1892 LossAtt 0.3944 TrainAcc 0.9500 TestAcc 0.9307 0.9200
epoch 1300 LossPred 0.1891 LossAtt 0.3927 TrainAcc 0.9400 TestAcc 0.9279 0.9050
epoch 1400 LossPred 0.1893 LossAtt 0.3866 TrainAcc 0.9600 TestAcc 0.9207 0.9450
epoch 1500 LossPred 0.1543 LossAtt 0.3949 TrainAcc 0.9700 TestAcc 0.9267 0.9550
epoch 1600 LossPred 0.3010 LossAtt 0.3813 TrainAcc 0.9000 TestAcc 0.8811 0.8850
epoch 1700 LossPred 0.2934 LossAtt 0.3825 TrainAcc 0.8800 TestAcc 0.8771 0.8850
epoch 1800 LossPred 0.1224 LossAtt 0.4228 TrainAcc 0.9700 TestAcc 0.9472 0.9550
epoch 1900 LossPred 0.1791 LossAtt 0.4065 TrainAcc 0.9300 TestAcc 0.9199 0.9300
epoch 2000 LossPred 0.2018 LossAtt 0.3950 TrainAcc 0.9200 TestAcc 0.9109 0.9400
epoch 2100 LossPred 0.2571 LossAtt 0.4182 TrainAcc 0.8900 TestAcc 0.9017 0.8750
epoch 2200 LossPred 0.1309 LossAtt 0.4181 TrainAcc 0.9700 TestAcc 0.9304 0.9500
epoch 2300 LossPred 0.0728 LossAtt 0.4110 TrainAcc 0.9900 TestAcc 0.9565 0.9850
epoch 2400 LossPred 0.1506 LossAtt 0.4035 TrainAcc 0.9400 TestAcc 0.9237 0.9450
epoch 2500 LossPred 0.3803 LossAtt 0.4056 TrainAcc 0.8600 TestAcc 0.8403 0.8600
Optimization Finished!
********** replication  83  **********
epoch   0 LossPred 1.0227 LossAtt 1.0152 TrainAcc 0.6000 TestAcc 0.5718 0.5750
epoch 100 LossPred 0.9231 LossAtt 0.5046 TrainAcc 0.6100 TestAcc 0.5883 0.6100
epoch 200 LossPred 0.8404 LossAtt 0.5783 TrainAcc 0.6900 TestAcc 0.6444 0.6500
epoch 300 LossPred 0.2995 LossAtt 0.6386 TrainAcc 0.9200 TestAcc 0.9142 0.8950
epoch 400 LossPred 0.2319 LossAtt 0.6233 TrainAcc 0.9400 TestAcc 0.9382 0.8950
epoch 500 LossPred 0.2055 LossAtt 0.6098 TrainAcc 0.9500 TestAcc 0.9167 0.8800
epoch 600 LossPred 0.1892 LossAtt 0.5949 TrainAcc 0.9600 TestAcc 0.9489 0.9000
epoch 700 LossPred 0.1757 LossAtt 0.5960 TrainAcc 0.9600 TestAcc 0.9352 0.9100
epoch 800 LossPred 0.1769 LossAtt 0.5846 TrainAcc 0.9500 TestAcc 0.9144 0.9000
epoch 900 LossPred 0.1672 LossAtt 0.5421 TrainAcc 0.9500 TestAcc 0.9657 0.9300
epoch 1000 LossPred 0.1774 LossAtt 0.5331 TrainAcc 0.9400 TestAcc 0.9379 0.9200
epoch 1100 LossPred 0.1576 LossAtt 0.5329 TrainAcc 0.9500 TestAcc 0.9637 0.9300
epoch 1200 LossPred 0.1401 LossAtt 0.5363 TrainAcc 0.9600 TestAcc 0.9487 0.9500
epoch 1300 LossPred 0.1782 LossAtt 0.5212 TrainAcc 0.9400 TestAcc 0.9597 0.9150
epoch 1400 LossPred 0.1502 LossAtt 0.5021 TrainAcc 0.9400 TestAcc 0.9587 0.9150
epoch 1500 LossPred 0.1634 LossAtt 0.5137 TrainAcc 0.9400 TestAcc 0.9662 0.9150
epoch 1600 LossPred 0.2870 LossAtt 0.5252 TrainAcc 0.8600 TestAcc 0.9194 0.8800
epoch 1700 LossPred 0.1368 LossAtt 0.5232 TrainAcc 0.9600 TestAcc 0.9530 0.9400
epoch 1800 LossPred 0.1245 LossAtt 0.5249 TrainAcc 0.9700 TestAcc 0.9597 0.9500
epoch 1900 LossPred 0.1279 LossAtt 0.5349 TrainAcc 0.9600 TestAcc 0.9422 0.9450
epoch 2000 LossPred 0.1184 LossAtt 0.5185 TrainAcc 0.9700 TestAcc 0.9642 0.9500
epoch 2100 LossPred 0.2865 LossAtt 0.5357 TrainAcc 0.8800 TestAcc 0.8824 0.8800
epoch 2200 LossPred 0.1972 LossAtt 0.5183 TrainAcc 0.9200 TestAcc 0.9034 0.8950
epoch 2300 LossPred 0.1113 LossAtt 0.5064 TrainAcc 0.9600 TestAcc 0.9407 0.9450
epoch 2400 LossPred 0.1017 LossAtt 0.5167 TrainAcc 0.9800 TestAcc 0.9642 0.9600
epoch 2500 LossPred 0.1860 LossAtt 0.5240 TrainAcc 0.9400 TestAcc 0.9462 0.9350
Optimization Finished!
********** replication  84  **********
epoch   0 LossPred 1.1065 LossAtt 1.0197 TrainAcc 0.5000 TestAcc 0.4570 0.5200
epoch 100 LossPred 0.9309 LossAtt 0.5715 TrainAcc 0.6000 TestAcc 0.5843 0.6000
epoch 200 LossPred 0.9004 LossAtt 0.5267 TrainAcc 0.6300 TestAcc 0.5628 0.6050
epoch 300 LossPred 0.8789 LossAtt 0.5628 TrainAcc 0.6500 TestAcc 0.5636 0.6300
epoch 400 LossPred 0.8588 LossAtt 0.5846 TrainAcc 0.6700 TestAcc 0.5703 0.6350
epoch 500 LossPred 0.8398 LossAtt 0.5816 TrainAcc 0.6700 TestAcc 0.5706 0.6400
epoch 600 LossPred 0.8278 LossAtt 0.5537 TrainAcc 0.6700 TestAcc 0.5703 0.6550
epoch 700 LossPred 0.8050 LossAtt 0.5439 TrainAcc 0.6800 TestAcc 0.5628 0.6850
epoch 800 LossPred 0.7890 LossAtt 0.6174 TrainAcc 0.7000 TestAcc 0.5613 0.6850
epoch 900 LossPred 0.7575 LossAtt 0.5971 TrainAcc 0.7200 TestAcc 0.5791 0.6900
epoch 1000 LossPred 0.7206 LossAtt 0.5773 TrainAcc 0.7600 TestAcc 0.6211 0.7050
epoch 1100 LossPred 0.7019 LossAtt 0.5750 TrainAcc 0.7600 TestAcc 0.6266 0.7250
epoch 1200 LossPred 0.6860 LossAtt 0.5679 TrainAcc 0.7800 TestAcc 0.6301 0.7300
epoch 1300 LossPred 0.6703 LossAtt 0.5696 TrainAcc 0.7800 TestAcc 0.6299 0.7450
epoch 1400 LossPred 0.6576 LossAtt 0.5648 TrainAcc 0.7800 TestAcc 0.6274 0.7450
epoch 1500 LossPred 0.6521 LossAtt 0.5441 TrainAcc 0.7800 TestAcc 0.6154 0.7350
epoch 1600 LossPred 0.6542 LossAtt 0.5545 TrainAcc 0.7600 TestAcc 0.6149 0.7450
epoch 1700 LossPred 0.6394 LossAtt 0.5350 TrainAcc 0.7700 TestAcc 0.6169 0.7500
epoch 1800 LossPred 0.6624 LossAtt 0.5603 TrainAcc 0.7600 TestAcc 0.6159 0.7500
epoch 1900 LossPred 0.6308 LossAtt 0.5195 TrainAcc 0.7700 TestAcc 0.6181 0.7500
epoch 2000 LossPred 0.6458 LossAtt 0.5075 TrainAcc 0.7700 TestAcc 0.6224 0.7550
epoch 2100 LossPred 0.6301 LossAtt 0.4601 TrainAcc 0.7900 TestAcc 0.6111 0.7700
epoch 2200 LossPred 0.6322 LossAtt 0.4677 TrainAcc 0.7700 TestAcc 0.6099 0.7700
epoch 2300 LossPred 0.6805 LossAtt 0.4647 TrainAcc 0.7500 TestAcc 0.6116 0.7200
epoch 2400 LossPred 0.7045 LossAtt 0.5141 TrainAcc 0.7500 TestAcc 0.6169 0.7000
epoch 2500 LossPred 0.6677 LossAtt 0.4563 TrainAcc 0.7600 TestAcc 0.6076 0.6950
Optimization Finished!
********** replication  85  **********
epoch   0 LossPred 1.1725 LossAtt 1.0936 TrainAcc 0.4500 TestAcc 0.4882 0.4250
epoch 100 LossPred 0.9147 LossAtt 0.3540 TrainAcc 0.6600 TestAcc 0.6049 0.6200
epoch 200 LossPred 0.8885 LossAtt 0.4109 TrainAcc 0.6600 TestAcc 0.6049 0.6600
epoch 300 LossPred 0.8538 LossAtt 0.3347 TrainAcc 0.6600 TestAcc 0.6049 0.6600
epoch 400 LossPred 0.4039 LossAtt 0.3953 TrainAcc 0.8800 TestAcc 0.8251 0.8800
epoch 500 LossPred 0.2418 LossAtt 0.3857 TrainAcc 0.9400 TestAcc 0.8516 0.9050
epoch 600 LossPred 0.2166 LossAtt 0.3654 TrainAcc 0.9500 TestAcc 0.8556 0.9100
epoch 700 LossPred 0.2103 LossAtt 0.3580 TrainAcc 0.9500 TestAcc 0.8564 0.9150
epoch 800 LossPred 0.2080 LossAtt 0.3419 TrainAcc 0.9500 TestAcc 0.8589 0.9050
epoch 900 LossPred 0.2053 LossAtt 0.3593 TrainAcc 0.9500 TestAcc 0.8534 0.9200
epoch 1000 LossPred 0.2041 LossAtt 0.3342 TrainAcc 0.9400 TestAcc 0.8521 0.9050
epoch 1100 LossPred 0.1986 LossAtt 0.3465 TrainAcc 0.9500 TestAcc 0.8591 0.9050
epoch 1200 LossPred 0.2010 LossAtt 0.3592 TrainAcc 0.9300 TestAcc 0.8463 0.9100
epoch 1300 LossPred 0.2002 LossAtt 0.3528 TrainAcc 0.9400 TestAcc 0.8554 0.9050
epoch 1400 LossPred 0.1921 LossAtt 0.3378 TrainAcc 0.9500 TestAcc 0.8501 0.9100
epoch 1500 LossPred 0.1997 LossAtt 0.3528 TrainAcc 0.9500 TestAcc 0.8453 0.9000
epoch 1600 LossPred 0.1905 LossAtt 0.3493 TrainAcc 0.9400 TestAcc 0.8486 0.9100
epoch 1700 LossPred 0.1904 LossAtt 0.3563 TrainAcc 0.9500 TestAcc 0.8544 0.9100
epoch 1800 LossPred 0.1865 LossAtt 0.3525 TrainAcc 0.9500 TestAcc 0.8571 0.9100
epoch 1900 LossPred 0.1854 LossAtt 0.3578 TrainAcc 0.9500 TestAcc 0.8576 0.9100
epoch 2000 LossPred 0.1962 LossAtt 0.3750 TrainAcc 0.9400 TestAcc 0.8529 0.9000
epoch 2100 LossPred 0.1885 LossAtt 0.3403 TrainAcc 0.9500 TestAcc 0.8536 0.9100
epoch 2200 LossPred 0.3040 LossAtt 0.3718 TrainAcc 0.9100 TestAcc 0.8078 0.8750
epoch 2300 LossPred 0.1946 LossAtt 0.3601 TrainAcc 0.9300 TestAcc 0.8556 0.9100
epoch 2400 LossPred 0.1852 LossAtt 0.3394 TrainAcc 0.9500 TestAcc 0.8571 0.9100
epoch 2500 LossPred 0.1848 LossAtt 0.3471 TrainAcc 0.9500 TestAcc 0.8531 0.9050
Optimization Finished!
********** replication  86  **********
epoch   0 LossPred 1.0814 LossAtt 1.0247 TrainAcc 0.3900 TestAcc 0.3881 0.4650
epoch 100 LossPred 0.8907 LossAtt 0.5400 TrainAcc 0.6200 TestAcc 0.5606 0.6150
epoch 200 LossPred 0.8511 LossAtt 0.5098 TrainAcc 0.6600 TestAcc 0.5836 0.6650
epoch 300 LossPred 0.7743 LossAtt 0.5716 TrainAcc 0.7500 TestAcc 0.6441 0.7350
epoch 400 LossPred 0.2391 LossAtt 0.6069 TrainAcc 0.9500 TestAcc 0.8624 0.9050
epoch 500 LossPred 0.1796 LossAtt 0.5653 TrainAcc 0.9500 TestAcc 0.8676 0.9200
epoch 600 LossPred 0.1447 LossAtt 0.5768 TrainAcc 0.9600 TestAcc 0.8644 0.9200
epoch 700 LossPred 0.1845 LossAtt 0.5741 TrainAcc 0.9400 TestAcc 0.8669 0.9200
epoch 800 LossPred 0.1289 LossAtt 0.5284 TrainAcc 0.9500 TestAcc 0.8488 0.9250
epoch 900 LossPred 0.1430 LossAtt 0.5403 TrainAcc 0.9500 TestAcc 0.8566 0.9150
epoch 1000 LossPred 0.1007 LossAtt 0.5147 TrainAcc 0.9700 TestAcc 0.8591 0.9250
epoch 1100 LossPred 0.0945 LossAtt 0.5198 TrainAcc 0.9600 TestAcc 0.8564 0.9350
epoch 1200 LossPred 0.0851 LossAtt 0.4954 TrainAcc 0.9700 TestAcc 0.8576 0.9350
epoch 1300 LossPred 0.0944 LossAtt 0.4735 TrainAcc 0.9700 TestAcc 0.8511 0.9300
epoch 1400 LossPred 0.1015 LossAtt 0.4746 TrainAcc 0.9600 TestAcc 0.8504 0.9300
epoch 1500 LossPred 0.0866 LossAtt 0.4522 TrainAcc 0.9700 TestAcc 0.8596 0.9350
epoch 1600 LossPred 0.0788 LossAtt 0.4628 TrainAcc 0.9900 TestAcc 0.8493 0.9200
epoch 1700 LossPred 0.0812 LossAtt 0.4553 TrainAcc 0.9800 TestAcc 0.8521 0.9350
epoch 1800 LossPred 0.1533 LossAtt 0.4382 TrainAcc 0.9400 TestAcc 0.8436 0.9300
epoch 1900 LossPred 0.1386 LossAtt 0.4182 TrainAcc 0.9700 TestAcc 0.8554 0.9200
epoch 2000 LossPred 0.1431 LossAtt 0.4335 TrainAcc 0.9600 TestAcc 0.8539 0.9250
epoch 2100 LossPred 0.0680 LossAtt 0.4342 TrainAcc 0.9800 TestAcc 0.8566 0.9300
epoch 2200 LossPred 0.0666 LossAtt 0.4342 TrainAcc 0.9800 TestAcc 0.8579 0.9350
epoch 2300 LossPred 0.0729 LossAtt 0.4037 TrainAcc 0.9600 TestAcc 0.8551 0.9300
epoch 2400 LossPred 0.0661 LossAtt 0.4094 TrainAcc 0.9800 TestAcc 0.8576 0.9300
epoch 2500 LossPred 0.0658 LossAtt 0.4171 TrainAcc 0.9800 TestAcc 0.8679 0.9300
Optimization Finished!
********** replication  87  **********
epoch   0 LossPred 1.0487 LossAtt 1.0512 TrainAcc 0.5600 TestAcc 0.5458 0.5600
epoch 100 LossPred 0.8580 LossAtt 0.5773 TrainAcc 0.6400 TestAcc 0.5936 0.6450
epoch 200 LossPred 0.7780 LossAtt 0.6363 TrainAcc 0.6900 TestAcc 0.6381 0.6500
epoch 300 LossPred 0.3731 LossAtt 0.5497 TrainAcc 0.8800 TestAcc 0.8366 0.8500
epoch 400 LossPred 0.3368 LossAtt 0.4629 TrainAcc 0.8800 TestAcc 0.8351 0.8650
epoch 500 LossPred 0.3106 LossAtt 0.4583 TrainAcc 0.8900 TestAcc 0.8401 0.8650
epoch 600 LossPred 0.3685 LossAtt 0.4833 TrainAcc 0.8500 TestAcc 0.8231 0.8450
epoch 700 LossPred 0.2888 LossAtt 0.4547 TrainAcc 0.9100 TestAcc 0.8516 0.8700
epoch 800 LossPred 0.2936 LossAtt 0.4581 TrainAcc 0.8800 TestAcc 0.8514 0.8400
epoch 900 LossPred 0.2657 LossAtt 0.4359 TrainAcc 0.9100 TestAcc 0.8521 0.8650
epoch 1000 LossPred 0.2611 LossAtt 0.4134 TrainAcc 0.9000 TestAcc 0.8504 0.8750
epoch 1100 LossPred 0.2525 LossAtt 0.4518 TrainAcc 0.9100 TestAcc 0.8416 0.8750
epoch 1200 LossPred 0.2463 LossAtt 0.4263 TrainAcc 0.9100 TestAcc 0.8431 0.8750
epoch 1300 LossPred 0.2575 LossAtt 0.4218 TrainAcc 0.9000 TestAcc 0.8346 0.8750
epoch 1400 LossPred 0.2485 LossAtt 0.4335 TrainAcc 0.9000 TestAcc 0.8381 0.8700
epoch 1500 LossPred 0.2326 LossAtt 0.4113 TrainAcc 0.9200 TestAcc 0.8408 0.8750
epoch 1600 LossPred 0.2310 LossAtt 0.4165 TrainAcc 0.9200 TestAcc 0.8438 0.8700
epoch 1700 LossPred 0.2299 LossAtt 0.4186 TrainAcc 0.9200 TestAcc 0.8241 0.8850
epoch 1800 LossPred 0.2435 LossAtt 0.4458 TrainAcc 0.9300 TestAcc 0.8301 0.8700
epoch 1900 LossPred 0.2374 LossAtt 0.4361 TrainAcc 0.9100 TestAcc 0.8371 0.8700
epoch 2000 LossPred 0.2275 LossAtt 0.4324 TrainAcc 0.9200 TestAcc 0.8236 0.8700
epoch 2100 LossPred 0.2245 LossAtt 0.4320 TrainAcc 0.9300 TestAcc 0.8308 0.8750
epoch 2200 LossPred 0.2420 LossAtt 0.3974 TrainAcc 0.9100 TestAcc 0.8241 0.8750
epoch 2300 LossPred 0.2370 LossAtt 0.4535 TrainAcc 0.9200 TestAcc 0.8346 0.8600
epoch 2400 LossPred 0.2202 LossAtt 0.4380 TrainAcc 0.9200 TestAcc 0.8076 0.8800
epoch 2500 LossPred 0.2261 LossAtt 0.4365 TrainAcc 0.9200 TestAcc 0.8058 0.8850
Optimization Finished!
********** replication  88  **********
epoch   0 LossPred 1.5357 LossAtt 1.0255 TrainAcc 0.3600 TestAcc 0.4047 0.3450
epoch 100 LossPred 0.9411 LossAtt 0.5685 TrainAcc 0.6500 TestAcc 0.5638 0.6500
epoch 200 LossPred 0.8303 LossAtt 0.5139 TrainAcc 0.6800 TestAcc 0.5633 0.6600
epoch 300 LossPred 0.7860 LossAtt 0.4659 TrainAcc 0.7000 TestAcc 0.5711 0.7050
epoch 400 LossPred 0.7576 LossAtt 0.4167 TrainAcc 0.7400 TestAcc 0.6099 0.7400
epoch 500 LossPred 0.7366 LossAtt 0.3851 TrainAcc 0.7400 TestAcc 0.6099 0.7400
epoch 600 LossPred 0.7139 LossAtt 0.3908 TrainAcc 0.7400 TestAcc 0.6099 0.7400
epoch 700 LossPred 0.5577 LossAtt 0.4715 TrainAcc 0.8100 TestAcc 0.7397 0.7950
epoch 800 LossPred 0.2345 LossAtt 0.5370 TrainAcc 0.9500 TestAcc 0.9064 0.9150
epoch 900 LossPred 0.1988 LossAtt 0.5235 TrainAcc 0.9400 TestAcc 0.8971 0.9400
epoch 1000 LossPred 0.1847 LossAtt 0.5560 TrainAcc 0.9500 TestAcc 0.9269 0.9300
epoch 1100 LossPred 0.1341 LossAtt 0.6045 TrainAcc 0.9600 TestAcc 0.9384 0.9300
epoch 1200 LossPred 0.1287 LossAtt 0.5670 TrainAcc 0.9800 TestAcc 0.9159 0.9450
epoch 1300 LossPred 0.1060 LossAtt 0.5488 TrainAcc 0.9800 TestAcc 0.9432 0.9600
epoch 1400 LossPred 0.0787 LossAtt 0.5178 TrainAcc 0.9800 TestAcc 0.9447 0.9700
epoch 1500 LossPred 0.0741 LossAtt 0.4898 TrainAcc 0.9900 TestAcc 0.9560 0.9850
epoch 1600 LossPred 0.1198 LossAtt 0.4905 TrainAcc 0.9700 TestAcc 0.9054 0.9450
epoch 1700 LossPred 0.0684 LossAtt 0.4649 TrainAcc 0.9800 TestAcc 0.9555 0.9850
epoch 1800 LossPred 0.0658 LossAtt 0.4375 TrainAcc 0.9900 TestAcc 0.9537 0.9700
epoch 1900 LossPred 0.0607 LossAtt 0.4346 TrainAcc 0.9900 TestAcc 0.9535 0.9800
epoch 2000 LossPred 0.0683 LossAtt 0.4267 TrainAcc 0.9900 TestAcc 0.9627 0.9900
epoch 2100 LossPred 0.0792 LossAtt 0.4234 TrainAcc 0.9700 TestAcc 0.9507 0.9750
epoch 2200 LossPred 0.0533 LossAtt 0.4103 TrainAcc 0.9900 TestAcc 0.9600 0.9750
epoch 2300 LossPred 0.0507 LossAtt 0.4157 TrainAcc 0.9900 TestAcc 0.9567 0.9750
epoch 2400 LossPred 0.0464 LossAtt 0.4138 TrainAcc 1.0000 TestAcc 0.9565 0.9650
Optimization Finished!
********** replication  89  **********
epoch   0 LossPred 0.9767 LossAtt 1.0014 TrainAcc 0.5900 TestAcc 0.5125 0.5800
epoch 100 LossPred 0.8781 LossAtt 0.6307 TrainAcc 0.6500 TestAcc 0.6314 0.6400
epoch 200 LossPred 0.5543 LossAtt 0.6382 TrainAcc 0.8500 TestAcc 0.7710 0.8400
epoch 300 LossPred 0.2933 LossAtt 0.6513 TrainAcc 0.9300 TestAcc 0.8906 0.9400
epoch 400 LossPred 0.2374 LossAtt 0.6227 TrainAcc 0.9600 TestAcc 0.8924 0.9400
epoch 500 LossPred 0.2009 LossAtt 0.6088 TrainAcc 0.9600 TestAcc 0.9002 0.9550
epoch 600 LossPred 0.1962 LossAtt 0.5414 TrainAcc 0.9400 TestAcc 0.9027 0.9400
epoch 700 LossPred 0.1485 LossAtt 0.4586 TrainAcc 0.9800 TestAcc 0.9139 0.9650
epoch 800 LossPred 0.1342 LossAtt 0.4114 TrainAcc 0.9700 TestAcc 0.9204 0.9650
epoch 900 LossPred 0.1205 LossAtt 0.3638 TrainAcc 0.9900 TestAcc 0.9177 0.9650
epoch 1000 LossPred 0.1129 LossAtt 0.3501 TrainAcc 0.9900 TestAcc 0.9209 0.9600
epoch 1100 LossPred 0.1033 LossAtt 0.3434 TrainAcc 0.9800 TestAcc 0.9159 0.9650
epoch 1200 LossPred 0.0990 LossAtt 0.3366 TrainAcc 0.9900 TestAcc 0.9169 0.9600
epoch 1300 LossPred 0.0922 LossAtt 0.3754 TrainAcc 0.9700 TestAcc 0.9179 0.9650
epoch 1400 LossPred 0.1320 LossAtt 0.3756 TrainAcc 0.9400 TestAcc 0.9052 0.9450
epoch 1500 LossPred 0.0764 LossAtt 0.4057 TrainAcc 0.9900 TestAcc 0.9212 0.9600
epoch 1600 LossPred 0.0763 LossAtt 0.4194 TrainAcc 0.9900 TestAcc 0.9232 0.9600
epoch 1700 LossPred 0.0687 LossAtt 0.4066 TrainAcc 0.9900 TestAcc 0.9229 0.9650
epoch 1800 LossPred 0.0836 LossAtt 0.4073 TrainAcc 0.9900 TestAcc 0.9157 0.9500
epoch 1900 LossPred 0.0680 LossAtt 0.3972 TrainAcc 0.9900 TestAcc 0.9192 0.9600
epoch 2000 LossPred 0.0757 LossAtt 0.4105 TrainAcc 0.9800 TestAcc 0.9169 0.9550
epoch 2100 LossPred 0.0625 LossAtt 0.4200 TrainAcc 0.9900 TestAcc 0.9189 0.9600
epoch 2200 LossPred 0.0744 LossAtt 0.3942 TrainAcc 0.9900 TestAcc 0.9197 0.9700
epoch 2300 LossPred 0.0619 LossAtt 0.3911 TrainAcc 0.9900 TestAcc 0.9217 0.9700
epoch 2400 LossPred 0.1004 LossAtt 0.3834 TrainAcc 0.9700 TestAcc 0.9142 0.9550
epoch 2500 LossPred 0.0621 LossAtt 0.4218 TrainAcc 0.9900 TestAcc 0.9212 0.9600
Optimization Finished!
********** replication  90  **********
epoch   0 LossPred 1.3842 LossAtt 1.0162 TrainAcc 0.4300 TestAcc 0.4464 0.4350
epoch 100 LossPred 1.0363 LossAtt 0.3586 TrainAcc 0.4700 TestAcc 0.5008 0.4700
epoch 200 LossPred 0.9212 LossAtt 0.4158 TrainAcc 0.6500 TestAcc 0.5866 0.6500
epoch 300 LossPred 0.9029 LossAtt 0.3674 TrainAcc 0.6500 TestAcc 0.5866 0.6500
epoch 400 LossPred 0.8997 LossAtt 0.3351 TrainAcc 0.6500 TestAcc 0.5866 0.6500
epoch 500 LossPred 0.8898 LossAtt 0.3558 TrainAcc 0.6500 TestAcc 0.5866 0.6550
epoch 600 LossPred 0.4526 LossAtt 0.5537 TrainAcc 0.9100 TestAcc 0.8564 0.8650
epoch 700 LossPred 0.3626 LossAtt 0.5762 TrainAcc 0.9000 TestAcc 0.8911 0.8800
epoch 800 LossPred 0.2939 LossAtt 0.5952 TrainAcc 0.9200 TestAcc 0.8726 0.8850
epoch 900 LossPred 0.2548 LossAtt 0.5777 TrainAcc 0.9300 TestAcc 0.8909 0.8900
epoch 1000 LossPred 0.2281 LossAtt 0.5511 TrainAcc 0.9400 TestAcc 0.8946 0.8800
epoch 1100 LossPred 0.2070 LossAtt 0.5671 TrainAcc 0.9300 TestAcc 0.9042 0.8900
epoch 1200 LossPred 0.1852 LossAtt 0.5641 TrainAcc 0.9700 TestAcc 0.9064 0.9050
epoch 1300 LossPred 0.1828 LossAtt 0.5363 TrainAcc 0.9600 TestAcc 0.9522 0.9100
epoch 1400 LossPred 0.1883 LossAtt 0.5002 TrainAcc 0.9500 TestAcc 0.9007 0.8950
epoch 1500 LossPred 0.2930 LossAtt 0.4935 TrainAcc 0.9100 TestAcc 0.9242 0.8450
epoch 1600 LossPred 0.2673 LossAtt 0.4496 TrainAcc 0.9100 TestAcc 0.8576 0.8850
epoch 1700 LossPred 0.3097 LossAtt 0.4457 TrainAcc 0.8900 TestAcc 0.8448 0.8800
epoch 1800 LossPred 0.1326 LossAtt 0.4225 TrainAcc 0.9800 TestAcc 0.9439 0.8650
epoch 1900 LossPred 0.1665 LossAtt 0.4262 TrainAcc 0.9500 TestAcc 0.9510 0.8750
epoch 2000 LossPred 0.1444 LossAtt 0.4195 TrainAcc 0.9700 TestAcc 0.9069 0.8500
epoch 2100 LossPred 0.3493 LossAtt 0.4150 TrainAcc 0.8800 TestAcc 0.9209 0.8100
epoch 2200 LossPred 0.1638 LossAtt 0.4359 TrainAcc 0.9500 TestAcc 0.9344 0.8650
epoch 2300 LossPred 0.2048 LossAtt 0.4072 TrainAcc 0.9200 TestAcc 0.8714 0.8600
epoch 2400 LossPred 0.2374 LossAtt 0.3922 TrainAcc 0.9100 TestAcc 0.9324 0.8550
epoch 2500 LossPred 0.1968 LossAtt 0.4126 TrainAcc 0.9400 TestAcc 0.9317 0.8650
Optimization Finished!
********** replication  91  **********
epoch   0 LossPred 1.0195 LossAtt 0.9914 TrainAcc 0.4800 TestAcc 0.4977 0.4500
epoch 100 LossPred 0.8749 LossAtt 0.6229 TrainAcc 0.6700 TestAcc 0.6141 0.6700
epoch 200 LossPred 0.8383 LossAtt 0.5904 TrainAcc 0.6700 TestAcc 0.6667 0.6850
epoch 300 LossPred 0.3363 LossAtt 0.5363 TrainAcc 0.9500 TestAcc 0.9029 0.9100
epoch 400 LossPred 0.6317 LossAtt 0.4472 TrainAcc 0.7800 TestAcc 0.7693 0.7200
epoch 500 LossPred 0.3408 LossAtt 0.4817 TrainAcc 0.9000 TestAcc 0.8594 0.8500
epoch 600 LossPred 0.2360 LossAtt 0.4828 TrainAcc 0.9300 TestAcc 0.8846 0.9150
epoch 700 LossPred 0.3107 LossAtt 0.5064 TrainAcc 0.9000 TestAcc 0.8671 0.8400
epoch 800 LossPred 0.4865 LossAtt 0.5220 TrainAcc 0.8300 TestAcc 0.8624 0.8250
epoch 900 LossPred 0.3664 LossAtt 0.5344 TrainAcc 0.8700 TestAcc 0.8784 0.8300
epoch 1000 LossPred 0.5337 LossAtt 0.5179 TrainAcc 0.8100 TestAcc 0.8316 0.7900
epoch 1100 LossPred 0.5243 LossAtt 0.5311 TrainAcc 0.8300 TestAcc 0.7993 0.7750
epoch 1200 LossPred 0.6289 LossAtt 0.5017 TrainAcc 0.7600 TestAcc 0.8071 0.7700
epoch 1300 LossPred 0.4119 LossAtt 0.5151 TrainAcc 0.8400 TestAcc 0.8288 0.8200
epoch 1400 LossPred 0.4302 LossAtt 0.5021 TrainAcc 0.8100 TestAcc 0.8791 0.8300
epoch 1500 LossPred 0.4098 LossAtt 0.5208 TrainAcc 0.8500 TestAcc 0.8296 0.8350
epoch 1600 LossPred 0.2254 LossAtt 0.5077 TrainAcc 0.9200 TestAcc 0.9182 0.8900
epoch 1700 LossPred 0.2922 LossAtt 0.5081 TrainAcc 0.9100 TestAcc 0.8629 0.8750
epoch 1800 LossPred 0.2613 LossAtt 0.5222 TrainAcc 0.9000 TestAcc 0.9087 0.8650
epoch 1900 LossPred 0.2345 LossAtt 0.5028 TrainAcc 0.9100 TestAcc 0.9022 0.9100
epoch 2000 LossPred 0.2242 LossAtt 0.5102 TrainAcc 0.9300 TestAcc 0.9169 0.8800
epoch 2100 LossPred 0.5684 LossAtt 0.5018 TrainAcc 0.7900 TestAcc 0.8258 0.7900
epoch 2200 LossPred 0.2190 LossAtt 0.5194 TrainAcc 0.9300 TestAcc 0.9037 0.9150
epoch 2300 LossPred 0.1981 LossAtt 0.5177 TrainAcc 0.9400 TestAcc 0.9212 0.9250
epoch 2400 LossPred 0.4267 LossAtt 0.5044 TrainAcc 0.8200 TestAcc 0.8704 0.8300
epoch 2500 LossPred 0.3155 LossAtt 0.4789 TrainAcc 0.8800 TestAcc 0.9002 0.8600
Optimization Finished!
********** replication  92  **********
epoch   0 LossPred 1.4841 LossAtt 1.0048 TrainAcc 0.3900 TestAcc 0.4442 0.4000
epoch 100 LossPred 0.9553 LossAtt 0.6229 TrainAcc 0.6100 TestAcc 0.5475 0.6050
epoch 200 LossPred 0.8075 LossAtt 0.5303 TrainAcc 0.7000 TestAcc 0.6041 0.7050
epoch 300 LossPred 0.6731 LossAtt 0.6087 TrainAcc 0.7500 TestAcc 0.6944 0.7700
epoch 400 LossPred 0.4795 LossAtt 0.6558 TrainAcc 0.8700 TestAcc 0.8671 0.8250
epoch 500 LossPred 0.3452 LossAtt 0.5858 TrainAcc 0.9300 TestAcc 0.8829 0.8650
epoch 600 LossPred 0.2976 LossAtt 0.6071 TrainAcc 0.9500 TestAcc 0.8891 0.8750
epoch 700 LossPred 0.2691 LossAtt 0.5887 TrainAcc 0.9400 TestAcc 0.8954 0.8900
epoch 800 LossPred 0.2731 LossAtt 0.5874 TrainAcc 0.9300 TestAcc 0.9082 0.8800
epoch 900 LossPred 0.2508 LossAtt 0.5891 TrainAcc 0.9400 TestAcc 0.9124 0.8950
epoch 1000 LossPred 0.2368 LossAtt 0.5445 TrainAcc 0.9300 TestAcc 0.8954 0.8800
epoch 1100 LossPred 0.2135 LossAtt 0.4827 TrainAcc 0.9500 TestAcc 0.9009 0.8800
epoch 1200 LossPred 0.1887 LossAtt 0.4198 TrainAcc 0.9800 TestAcc 0.9202 0.8950
epoch 1300 LossPred 0.1759 LossAtt 0.4424 TrainAcc 0.9800 TestAcc 0.9277 0.9150
epoch 1400 LossPred 0.1760 LossAtt 0.4417 TrainAcc 0.9600 TestAcc 0.9525 0.9350
epoch 1500 LossPred 0.1562 LossAtt 0.4466 TrainAcc 0.9800 TestAcc 0.9289 0.9450
epoch 1600 LossPred 0.1764 LossAtt 0.4328 TrainAcc 0.9800 TestAcc 0.9012 0.9350
epoch 1700 LossPred 0.1460 LossAtt 0.4164 TrainAcc 0.9800 TestAcc 0.9419 0.9450
epoch 1800 LossPred 0.1348 LossAtt 0.4133 TrainAcc 0.9800 TestAcc 0.9182 0.9650
epoch 1900 LossPred 0.1285 LossAtt 0.4094 TrainAcc 0.9800 TestAcc 0.9379 0.9700
epoch 2000 LossPred 0.1206 LossAtt 0.4213 TrainAcc 0.9800 TestAcc 0.9327 0.9650
epoch 2100 LossPred 0.1228 LossAtt 0.4156 TrainAcc 0.9800 TestAcc 0.9232 0.9550
epoch 2200 LossPred 0.1402 LossAtt 0.4255 TrainAcc 0.9800 TestAcc 0.9680 0.9450
epoch 2300 LossPred 0.1051 LossAtt 0.3860 TrainAcc 0.9800 TestAcc 0.9439 0.9800
epoch 2400 LossPred 0.1051 LossAtt 0.3949 TrainAcc 0.9800 TestAcc 0.9209 0.9650
epoch 2500 LossPred 0.0962 LossAtt 0.3867 TrainAcc 0.9800 TestAcc 0.9432 0.9650
Optimization Finished!
********** replication  93  **********
epoch   0 LossPred 1.1157 LossAtt 1.0420 TrainAcc 0.5300 TestAcc 0.5483 0.5100
epoch 100 LossPred 0.9995 LossAtt 0.6042 TrainAcc 0.5500 TestAcc 0.5033 0.5350
epoch 200 LossPred 0.9739 LossAtt 0.5725 TrainAcc 0.5700 TestAcc 0.4640 0.5750
epoch 300 LossPred 0.9474 LossAtt 0.6008 TrainAcc 0.6000 TestAcc 0.4690 0.6050
epoch 400 LossPred 0.9029 LossAtt 0.6653 TrainAcc 0.6300 TestAcc 0.4607 0.6100
epoch 500 LossPred 0.8752 LossAtt 0.6179 TrainAcc 0.6300 TestAcc 0.4812 0.6200
epoch 600 LossPred 0.8588 LossAtt 0.5994 TrainAcc 0.6300 TestAcc 0.4785 0.6050
epoch 700 LossPred 0.8460 LossAtt 0.5897 TrainAcc 0.6500 TestAcc 0.4827 0.6050
epoch 800 LossPred 0.8373 LossAtt 0.6190 TrainAcc 0.6600 TestAcc 0.4822 0.6150
epoch 900 LossPred 0.8275 LossAtt 0.5537 TrainAcc 0.6900 TestAcc 0.4870 0.6150
epoch 1000 LossPred 0.8154 LossAtt 0.5678 TrainAcc 0.7000 TestAcc 0.4847 0.6350
epoch 1100 LossPred 0.8032 LossAtt 0.5732 TrainAcc 0.7000 TestAcc 0.4770 0.6500
epoch 1200 LossPred 0.7973 LossAtt 0.5394 TrainAcc 0.7100 TestAcc 0.4680 0.6700
epoch 1300 LossPred 0.7810 LossAtt 0.5176 TrainAcc 0.7000 TestAcc 0.4670 0.6800
epoch 1400 LossPred 0.7712 LossAtt 0.5211 TrainAcc 0.7000 TestAcc 0.4515 0.6700
epoch 1500 LossPred 0.7604 LossAtt 0.5224 TrainAcc 0.7200 TestAcc 0.4735 0.6650
epoch 1600 LossPred 0.7444 LossAtt 0.5270 TrainAcc 0.7200 TestAcc 0.4705 0.6950
epoch 1700 LossPred 0.7250 LossAtt 0.5052 TrainAcc 0.7200 TestAcc 0.4780 0.7050
epoch 1800 LossPred 0.7084 LossAtt 0.5206 TrainAcc 0.7300 TestAcc 0.4800 0.7150
epoch 1900 LossPred 0.7072 LossAtt 0.5173 TrainAcc 0.7100 TestAcc 0.4750 0.6750
epoch 2000 LossPred 0.6819 LossAtt 0.5153 TrainAcc 0.7600 TestAcc 0.5488 0.7000
epoch 2100 LossPred 0.6696 LossAtt 0.5478 TrainAcc 0.7700 TestAcc 0.5498 0.7250
epoch 2200 LossPred 0.6600 LossAtt 0.5095 TrainAcc 0.7300 TestAcc 0.5511 0.7000
epoch 2300 LossPred 0.6449 LossAtt 0.5090 TrainAcc 0.7500 TestAcc 0.5546 0.7050
epoch 2400 LossPred 0.6313 LossAtt 0.5407 TrainAcc 0.7300 TestAcc 0.5593 0.7100
epoch 2500 LossPred 0.6288 LossAtt 0.5531 TrainAcc 0.7400 TestAcc 0.5633 0.7150
Optimization Finished!
********** replication  94  **********
epoch   0 LossPred 1.0391 LossAtt 0.9943 TrainAcc 0.4100 TestAcc 0.4357 0.4100
epoch 100 LossPred 0.8958 LossAtt 0.4914 TrainAcc 0.6400 TestAcc 0.5648 0.6700
epoch 200 LossPred 0.8440 LossAtt 0.4789 TrainAcc 0.6700 TestAcc 0.5858 0.6700
epoch 300 LossPred 0.4223 LossAtt 0.5359 TrainAcc 0.9000 TestAcc 0.8821 0.8900
epoch 400 LossPred 0.2966 LossAtt 0.5511 TrainAcc 0.9100 TestAcc 0.9219 0.8950
epoch 500 LossPred 0.2065 LossAtt 0.4947 TrainAcc 0.9400 TestAcc 0.9209 0.9150
epoch 600 LossPred 0.1795 LossAtt 0.4295 TrainAcc 0.9500 TestAcc 0.9412 0.9500
epoch 700 LossPred 0.1689 LossAtt 0.3834 TrainAcc 0.9600 TestAcc 0.9540 0.9550
epoch 800 LossPred 0.1530 LossAtt 0.3631 TrainAcc 0.9600 TestAcc 0.9582 0.9550
epoch 900 LossPred 0.1412 LossAtt 0.3781 TrainAcc 0.9700 TestAcc 0.9672 0.9600
epoch 1000 LossPred 0.1314 LossAtt 0.3600 TrainAcc 0.9800 TestAcc 0.9655 0.9700
epoch 1100 LossPred 0.1649 LossAtt 0.3522 TrainAcc 0.9600 TestAcc 0.9530 0.9650
epoch 1200 LossPred 0.1423 LossAtt 0.3623 TrainAcc 0.9500 TestAcc 0.9447 0.9650
epoch 1300 LossPred 0.1202 LossAtt 0.3601 TrainAcc 0.9800 TestAcc 0.9617 0.9700
epoch 1400 LossPred 0.1107 LossAtt 0.3649 TrainAcc 0.9800 TestAcc 0.9687 0.9750
epoch 1500 LossPred 0.1294 LossAtt 0.3817 TrainAcc 0.9700 TestAcc 0.9597 0.9700
epoch 1600 LossPred 0.1079 LossAtt 0.3839 TrainAcc 0.9800 TestAcc 0.9617 0.9750
epoch 1700 LossPred 0.0985 LossAtt 0.3936 TrainAcc 0.9800 TestAcc 0.9687 0.9750
epoch 1800 LossPred 0.0942 LossAtt 0.3759 TrainAcc 0.9800 TestAcc 0.9707 0.9800
epoch 1900 LossPred 0.0883 LossAtt 0.3862 TrainAcc 0.9800 TestAcc 0.9695 0.9800
epoch 2000 LossPred 0.0835 LossAtt 0.3951 TrainAcc 0.9900 TestAcc 0.9702 0.9800
epoch 2100 LossPred 0.0988 LossAtt 0.3823 TrainAcc 0.9800 TestAcc 0.9635 0.9750
epoch 2200 LossPred 0.1579 LossAtt 0.3665 TrainAcc 0.9500 TestAcc 0.9239 0.9550
epoch 2300 LossPred 0.1561 LossAtt 0.3968 TrainAcc 0.9400 TestAcc 0.9229 0.9500
epoch 2400 LossPred 0.0825 LossAtt 0.3611 TrainAcc 0.9800 TestAcc 0.9602 0.9800
epoch 2500 LossPred 0.0862 LossAtt 0.3679 TrainAcc 0.9800 TestAcc 0.9565 0.9750
Optimization Finished!
********** replication  95  **********
epoch   0 LossPred 1.1350 LossAtt 0.9907 TrainAcc 0.4800 TestAcc 0.4702 0.4700
epoch 100 LossPred 0.9494 LossAtt 0.3922 TrainAcc 0.6000 TestAcc 0.5938 0.6000
epoch 200 LossPred 0.9093 LossAtt 0.4497 TrainAcc 0.6000 TestAcc 0.6119 0.6050
epoch 300 LossPred 0.4617 LossAtt 0.5035 TrainAcc 0.8800 TestAcc 0.8799 0.8650
epoch 400 LossPred 0.4212 LossAtt 0.4719 TrainAcc 0.8800 TestAcc 0.8764 0.8650
epoch 500 LossPred 0.3691 LossAtt 0.4423 TrainAcc 0.8900 TestAcc 0.8741 0.8500
epoch 600 LossPred 0.3300 LossAtt 0.4435 TrainAcc 0.9100 TestAcc 0.8874 0.8650
epoch 700 LossPred 0.3023 LossAtt 0.4617 TrainAcc 0.9200 TestAcc 0.9034 0.8750
epoch 800 LossPred 0.3318 LossAtt 0.4740 TrainAcc 0.9000 TestAcc 0.9034 0.8650
epoch 900 LossPred 0.4128 LossAtt 0.4664 TrainAcc 0.8800 TestAcc 0.8751 0.8650
epoch 1000 LossPred 0.3589 LossAtt 0.4630 TrainAcc 0.9000 TestAcc 0.9199 0.8950
epoch 1100 LossPred 0.2984 LossAtt 0.4547 TrainAcc 0.9200 TestAcc 0.9474 0.9050
epoch 1200 LossPred 0.3867 LossAtt 0.4546 TrainAcc 0.8600 TestAcc 0.8774 0.8400
epoch 1300 LossPred 0.4180 LossAtt 0.4734 TrainAcc 0.8800 TestAcc 0.8696 0.8750
epoch 1400 LossPred 0.2626 LossAtt 0.4483 TrainAcc 0.9200 TestAcc 0.8964 0.9150
epoch 1500 LossPred 0.4109 LossAtt 0.4471 TrainAcc 0.8700 TestAcc 0.8624 0.8600
epoch 1600 LossPred 0.2913 LossAtt 0.4608 TrainAcc 0.9100 TestAcc 0.8946 0.8900
epoch 1700 LossPred 0.2253 LossAtt 0.4611 TrainAcc 0.9200 TestAcc 0.9279 0.9350
epoch 1800 LossPred 0.3222 LossAtt 0.4659 TrainAcc 0.9000 TestAcc 0.8831 0.8800
epoch 1900 LossPred 0.2952 LossAtt 0.4580 TrainAcc 0.9000 TestAcc 0.8904 0.8950
epoch 2000 LossPred 0.2130 LossAtt 0.4856 TrainAcc 0.9600 TestAcc 0.9352 0.9450
epoch 2100 LossPred 0.2079 LossAtt 0.4841 TrainAcc 0.9200 TestAcc 0.9307 0.9500
epoch 2200 LossPred 0.2698 LossAtt 0.5022 TrainAcc 0.9100 TestAcc 0.8996 0.9000
epoch 2300 LossPred 0.2319 LossAtt 0.4911 TrainAcc 0.9300 TestAcc 0.9204 0.9300
epoch 2400 LossPred 0.2272 LossAtt 0.5135 TrainAcc 0.9400 TestAcc 0.9312 0.9350
epoch 2500 LossPred 0.2089 LossAtt 0.5509 TrainAcc 0.9200 TestAcc 0.9317 0.9250
Optimization Finished!
********** replication  96  **********
epoch   0 LossPred 1.1808 LossAtt 1.0149 TrainAcc 0.4500 TestAcc 0.4962 0.4500
epoch 100 LossPred 0.9589 LossAtt 0.5627 TrainAcc 0.6000 TestAcc 0.5626 0.5950
epoch 200 LossPred 0.9062 LossAtt 0.5731 TrainAcc 0.6200 TestAcc 0.5928 0.6200
epoch 300 LossPred 0.6663 LossAtt 0.6881 TrainAcc 0.7700 TestAcc 0.7220 0.7700
epoch 400 LossPred 0.2243 LossAtt 0.6249 TrainAcc 0.9500 TestAcc 0.8979 0.9200
epoch 500 LossPred 0.4379 LossAtt 0.6498 TrainAcc 0.8400 TestAcc 0.7940 0.8200
epoch 600 LossPred 0.2059 LossAtt 0.6588 TrainAcc 0.9600 TestAcc 0.8934 0.9100
epoch 700 LossPred 0.1395 LossAtt 0.6643 TrainAcc 0.9700 TestAcc 0.9092 0.9250
epoch 800 LossPred 0.1197 LossAtt 0.6214 TrainAcc 0.9700 TestAcc 0.9059 0.9350
epoch 900 LossPred 0.1199 LossAtt 0.6120 TrainAcc 0.9700 TestAcc 0.8999 0.9250
epoch 1000 LossPred 0.1396 LossAtt 0.6032 TrainAcc 0.9600 TestAcc 0.8854 0.9300
epoch 1100 LossPred 0.0974 LossAtt 0.5761 TrainAcc 0.9800 TestAcc 0.8994 0.9250
epoch 1200 LossPred 0.1387 LossAtt 0.6020 TrainAcc 0.9500 TestAcc 0.9037 0.9300
epoch 1300 LossPred 0.0856 LossAtt 0.6207 TrainAcc 0.9700 TestAcc 0.9159 0.9400
epoch 1400 LossPred 0.0548 LossAtt 0.5934 TrainAcc 0.9900 TestAcc 0.9149 0.9500
epoch 1500 LossPred 0.0542 LossAtt 0.5478 TrainAcc 0.9900 TestAcc 0.9129 0.9500
epoch 1600 LossPred 0.0609 LossAtt 0.5351 TrainAcc 0.9800 TestAcc 0.9107 0.9500
epoch 1700 LossPred 0.0621 LossAtt 0.5234 TrainAcc 0.9800 TestAcc 0.9044 0.9400
epoch 1800 LossPred 0.0600 LossAtt 0.5180 TrainAcc 0.9800 TestAcc 0.9177 0.9650
epoch 1900 LossPred 0.0518 LossAtt 0.4975 TrainAcc 0.9900 TestAcc 0.9197 0.9600
epoch 2000 LossPred 0.0600 LossAtt 0.5106 TrainAcc 0.9800 TestAcc 0.9192 0.9650
epoch 2100 LossPred 0.0555 LossAtt 0.5016 TrainAcc 0.9800 TestAcc 0.9274 0.9700
epoch 2200 LossPred 0.0542 LossAtt 0.4906 TrainAcc 0.9900 TestAcc 0.9299 0.9700
epoch 2300 LossPred 0.1147 LossAtt 0.5047 TrainAcc 0.9500 TestAcc 0.9069 0.9250
epoch 2400 LossPred 0.0504 LossAtt 0.4881 TrainAcc 0.9800 TestAcc 0.9244 0.9650
epoch 2500 LossPred 0.0677 LossAtt 0.4961 TrainAcc 0.9800 TestAcc 0.9169 0.9550
Optimization Finished!
********** replication  97  **********
epoch   0 LossPred 1.0108 LossAtt 1.0069 TrainAcc 0.6000 TestAcc 0.5423 0.6000
epoch 100 LossPred 0.9193 LossAtt 0.4428 TrainAcc 0.6500 TestAcc 0.6016 0.6500
epoch 200 LossPred 0.8934 LossAtt 0.4034 TrainAcc 0.6500 TestAcc 0.6016 0.6500
epoch 300 LossPred 0.8639 LossAtt 0.5279 TrainAcc 0.6800 TestAcc 0.5641 0.6700
epoch 400 LossPred 0.8115 LossAtt 0.5061 TrainAcc 0.7000 TestAcc 0.5646 0.6750
epoch 500 LossPred 0.7501 LossAtt 0.5417 TrainAcc 0.7200 TestAcc 0.6294 0.7150
epoch 600 LossPred 0.6081 LossAtt 0.6493 TrainAcc 0.7500 TestAcc 0.6949 0.7650
epoch 700 LossPred 0.3391 LossAtt 0.6435 TrainAcc 0.8900 TestAcc 0.8516 0.8600
epoch 800 LossPred 0.2658 LossAtt 0.6470 TrainAcc 0.9100 TestAcc 0.8453 0.8600
epoch 900 LossPred 0.2862 LossAtt 0.6504 TrainAcc 0.9000 TestAcc 0.8416 0.8700
epoch 1000 LossPred 0.2300 LossAtt 0.6508 TrainAcc 0.9400 TestAcc 0.8406 0.8850
epoch 1100 LossPred 0.2233 LossAtt 0.6105 TrainAcc 0.9300 TestAcc 0.8431 0.8800
epoch 1200 LossPred 0.2076 LossAtt 0.6575 TrainAcc 0.9300 TestAcc 0.8461 0.8850
epoch 1300 LossPred 0.2061 LossAtt 0.6375 TrainAcc 0.9300 TestAcc 0.8431 0.8900
epoch 1400 LossPred 0.1930 LossAtt 0.6352 TrainAcc 0.9500 TestAcc 0.8493 0.9050
epoch 1500 LossPred 0.1876 LossAtt 0.6179 TrainAcc 0.9500 TestAcc 0.8519 0.9050
epoch 1600 LossPred 0.1808 LossAtt 0.6384 TrainAcc 0.9500 TestAcc 0.8539 0.9050
epoch 1700 LossPred 0.1767 LossAtt 0.6148 TrainAcc 0.9500 TestAcc 0.8591 0.9000
epoch 1800 LossPred 0.1745 LossAtt 0.6195 TrainAcc 0.9500 TestAcc 0.8604 0.9000
epoch 1900 LossPred 0.1895 LossAtt 0.6239 TrainAcc 0.9400 TestAcc 0.8511 0.9100
epoch 2000 LossPred 0.1914 LossAtt 0.5950 TrainAcc 0.9300 TestAcc 0.8461 0.9000
epoch 2100 LossPred 0.1463 LossAtt 0.6195 TrainAcc 0.9700 TestAcc 0.8466 0.9300
epoch 2200 LossPred 0.1421 LossAtt 0.6441 TrainAcc 0.9700 TestAcc 0.8531 0.9250
epoch 2300 LossPred 0.1252 LossAtt 0.6229 TrainAcc 0.9700 TestAcc 0.8594 0.9150
epoch 2400 LossPred 0.1159 LossAtt 0.6248 TrainAcc 0.9700 TestAcc 0.8686 0.9150
epoch 2500 LossPred 0.1068 LossAtt 0.6580 TrainAcc 0.9700 TestAcc 0.8689 0.9150
Optimization Finished!
********** replication  98  **********
epoch   0 LossPred 1.0658 LossAtt 1.0246 TrainAcc 0.5500 TestAcc 0.4995 0.5550
epoch 100 LossPred 0.9180 LossAtt 0.5347 TrainAcc 0.6200 TestAcc 0.6039 0.6300
epoch 200 LossPred 0.8341 LossAtt 0.5691 TrainAcc 0.6900 TestAcc 0.6276 0.6800
epoch 300 LossPred 0.2609 LossAtt 0.6851 TrainAcc 0.9300 TestAcc 0.8886 0.9300
epoch 400 LossPred 0.1696 LossAtt 0.6405 TrainAcc 0.9400 TestAcc 0.8931 0.9300
epoch 500 LossPred 0.1002 LossAtt 0.5860 TrainAcc 0.9800 TestAcc 0.9464 0.9550
epoch 600 LossPred 0.1127 LossAtt 0.5377 TrainAcc 0.9600 TestAcc 0.9407 0.9550
epoch 700 LossPred 0.0932 LossAtt 0.5198 TrainAcc 0.9700 TestAcc 0.9342 0.9600
epoch 800 LossPred 0.0973 LossAtt 0.5356 TrainAcc 0.9800 TestAcc 0.9317 0.9550
epoch 900 LossPred 0.1226 LossAtt 0.5493 TrainAcc 0.9600 TestAcc 0.9254 0.9500
epoch 1000 LossPred 0.0769 LossAtt 0.5121 TrainAcc 0.9700 TestAcc 0.9294 0.9600
epoch 1100 LossPred 0.0726 LossAtt 0.5297 TrainAcc 0.9900 TestAcc 0.9299 0.9650
epoch 1200 LossPred 0.0708 LossAtt 0.5436 TrainAcc 0.9900 TestAcc 0.9312 0.9700
epoch 1300 LossPred 0.1072 LossAtt 0.5025 TrainAcc 0.9800 TestAcc 0.9324 0.9550
epoch 1400 LossPred 0.0707 LossAtt 0.5381 TrainAcc 0.9800 TestAcc 0.9264 0.9700
epoch 1500 LossPred 0.0687 LossAtt 0.5203 TrainAcc 0.9900 TestAcc 0.9254 0.9700
epoch 1600 LossPred 0.0681 LossAtt 0.5371 TrainAcc 0.9900 TestAcc 0.9237 0.9800
epoch 1700 LossPred 0.0649 LossAtt 0.5499 TrainAcc 0.9900 TestAcc 0.9274 0.9800
epoch 1800 LossPred 0.0625 LossAtt 0.5193 TrainAcc 0.9900 TestAcc 0.9244 0.9800
epoch 1900 LossPred 0.0700 LossAtt 0.5079 TrainAcc 0.9900 TestAcc 0.9304 0.9600
epoch 2000 LossPred 0.0724 LossAtt 0.5495 TrainAcc 0.9800 TestAcc 0.9204 0.9800
epoch 2100 LossPred 0.0642 LossAtt 0.5368 TrainAcc 0.9900 TestAcc 0.9219 0.9700
epoch 2200 LossPred 0.0590 LossAtt 0.5301 TrainAcc 0.9900 TestAcc 0.9199 0.9800
epoch 2300 LossPred 0.0630 LossAtt 0.5159 TrainAcc 0.9800 TestAcc 0.9207 0.9750
epoch 2400 LossPred 0.0754 LossAtt 0.4964 TrainAcc 0.9800 TestAcc 0.9154 0.9750
epoch 2500 LossPred 0.0753 LossAtt 0.5194 TrainAcc 0.9800 TestAcc 0.9164 0.9800
Optimization Finished!
********** replication  99  **********
epoch   0 LossPred 1.1134 LossAtt 1.0227 TrainAcc 0.4100 TestAcc 0.4965 0.4050
epoch 100 LossPred 0.9476 LossAtt 0.4419 TrainAcc 0.6200 TestAcc 0.6339 0.6250
epoch 200 LossPred 0.7303 LossAtt 0.5386 TrainAcc 0.7800 TestAcc 0.7082 0.7800
epoch 300 LossPred 0.8498 LossAtt 0.4929 TrainAcc 0.6900 TestAcc 0.6632 0.7150
epoch 400 LossPred 0.5059 LossAtt 0.4786 TrainAcc 0.8400 TestAcc 0.7915 0.8350
epoch 500 LossPred 0.4389 LossAtt 0.4835 TrainAcc 0.8600 TestAcc 0.8263 0.8350
epoch 600 LossPred 0.4718 LossAtt 0.4608 TrainAcc 0.8700 TestAcc 0.8123 0.8400
epoch 700 LossPred 0.6475 LossAtt 0.4859 TrainAcc 0.7600 TestAcc 0.7085 0.7500
epoch 800 LossPred 0.5027 LossAtt 0.4552 TrainAcc 0.8600 TestAcc 0.7915 0.8350
epoch 900 LossPred 0.3754 LossAtt 0.4088 TrainAcc 0.8700 TestAcc 0.8599 0.8950
epoch 1000 LossPred 0.5112 LossAtt 0.4160 TrainAcc 0.8300 TestAcc 0.7743 0.7700
epoch 1100 LossPred 0.5378 LossAtt 0.4082 TrainAcc 0.8400 TestAcc 0.7748 0.7750
epoch 1200 LossPred 0.5537 LossAtt 0.3829 TrainAcc 0.8200 TestAcc 0.7730 0.7750
epoch 1300 LossPred 0.4559 LossAtt 0.4050 TrainAcc 0.8300 TestAcc 0.7995 0.8050
epoch 1400 LossPred 0.3538 LossAtt 0.3896 TrainAcc 0.8900 TestAcc 0.8346 0.8450
epoch 1500 LossPred 0.3023 LossAtt 0.3739 TrainAcc 0.9200 TestAcc 0.8596 0.8700
epoch 1600 LossPred 0.3090 LossAtt 0.3960 TrainAcc 0.9000 TestAcc 0.8871 0.8950
epoch 1700 LossPred 0.2566 LossAtt 0.3957 TrainAcc 0.9300 TestAcc 0.8981 0.9100
epoch 1800 LossPred 0.2404 LossAtt 0.4040 TrainAcc 0.9300 TestAcc 0.8994 0.9100
epoch 1900 LossPred 0.2196 LossAtt 0.4014 TrainAcc 0.9300 TestAcc 0.9029 0.9050
epoch 2000 LossPred 0.2008 LossAtt 0.4155 TrainAcc 0.9500 TestAcc 0.9044 0.9000
epoch 2100 LossPred 0.1696 LossAtt 0.4040 TrainAcc 0.9700 TestAcc 0.9112 0.9100
epoch 2200 LossPred 0.1435 LossAtt 0.3910 TrainAcc 0.9600 TestAcc 0.9267 0.9100
epoch 2300 LossPred 0.1350 LossAtt 0.4103 TrainAcc 0.9600 TestAcc 0.9284 0.9150
epoch 2400 LossPred 0.1353 LossAtt 0.4041 TrainAcc 0.9500 TestAcc 0.9279 0.9150
epoch 2500 LossPred 0.1205 LossAtt 0.4357 TrainAcc 0.9700 TestAcc 0.9272 0.9200
Optimization Finished!
********************************************************************
Namespace(arch='tanh', batch_size=256, display_epoch=100, input_noise_level=0.15, latent_attractor_space=True, loss_switch_frequency=0, lrate_attractor=0.002, lrate_prediction=0.002, lrate_wt_penalty=0.0, n_attractor_hidden=10, n_attractor_steps=5, n_hidden=5, n_replications=100, noise_level=0.25, report_best_train_performance=True, seq_len=15, task='majority', train_attr_weights_on_prediction=False, training_epochs=2500)
********************************************************************
mean train accuracy 0.95399994
indiv runs  [0.91, 0.94, 0.92, 0.95, 0.93, 1.0, 1.0, 0.99, 0.99, 0.96, 1.0, 1.0, 0.78, 0.95, 0.98, 0.99, 0.98, 1.0, 1.0, 0.98, 0.93, 0.99, 0.99, 0.88, 0.97, 0.98, 0.82, 0.99, 0.94, 0.99, 0.98, 0.99, 0.93, 0.99, 0.99, 0.71, 0.77, 0.98, 0.97, 0.97, 0.99, 0.97, 0.99, 0.99, 0.83, 1.0, 0.92, 0.99, 0.99, 0.93, 0.95, 0.82, 0.81, 0.8, 0.96, 0.98, 0.96, 0.98, 0.99, 0.98, 0.92, 0.97, 1.0, 0.99, 1.0, 1.0, 0.95, 0.95, 0.86, 1.0, 0.94, 1.0, 0.99, 0.92, 1.0, 0.97, 1.0, 1.0, 1.0, 0.98, 0.99, 0.96, 0.99, 0.98, 0.79, 0.95, 0.99, 0.93, 1.0, 0.99, 0.98, 0.95, 0.98, 0.77, 0.99, 0.96, 0.99, 0.97, 0.99, 0.97]
mean epoch 1630.41176471
indiv epochs  [1801, 2301, 1101, 601, 2201, 2501, 1701, 1301, 1601, 801, 2001, 1101, 1701, 1701, 1301, 1601, 2401]
test1 accuracy mean  0.86824334  median  0.9097848
test2 accuracy mean  0.91225  median  0.93
test1 indiv runs  [0.8603604, 0.8511011, 0.8055556, 0.8546046, 0.8511011, 0.8958959, 0.8788789, 0.9099099, 0.8813814, 0.8703704, 0.9537037, 0.9164164, 0.6063564, 0.8788789, 0.9221722, 0.9356857, 0.9344344, 0.9279279, 0.9614615, 0.9429429, 0.9031532, 0.8661161, 0.9634635, 0.6001001, 0.9451952, 0.7747748, 0.5945946, 0.8330831, 0.9096597, 0.9522022, 0.8731231, 0.8981481, 0.6356356, 0.9249249, 0.9496997, 0.5580581, 0.6761762, 0.9321822, 0.9131632, 0.8956456, 0.9602102, 0.9547047, 0.9406907, 0.9494494, 0.5898398, 0.970971, 0.8693694, 0.9481982, 0.9084084, 0.8848849, 0.8706206, 0.5885886, 0.5187688, 0.5858358, 0.8898899, 0.9319319, 0.9004004, 0.9774775, 0.9341842, 0.8748749, 0.9166667, 0.9717217, 0.9344344, 0.9004004, 0.9637137, 0.9476977, 0.8963964, 0.8628629, 0.5275275, 0.9134134, 0.8078078, 0.9206707, 0.9484484, 0.8448448, 0.9276777, 0.8941441, 0.8883884, 0.9349349, 0.963964, 0.9456957, 0.9366867, 0.9229229, 0.9564565, 0.9642142, 0.6111111, 0.8556056, 0.8493493, 0.8300801, 0.9564565, 0.9176677, 0.9439439, 0.9029029, 0.9201702, 0.5497998, 0.9702202, 0.9351852, 0.9149149, 0.8465966, 0.9299299, 0.9111612]
test2 indiv runs  [0.885, 0.89, 0.87, 0.93, 0.9, 0.945, 0.91, 0.92, 0.945, 0.925, 0.98, 0.93, 0.73, 0.925, 0.96, 0.95, 0.91, 0.975, 0.98, 0.965, 0.88, 0.965, 0.985, 0.805, 0.945, 0.925, 0.775, 0.965, 0.93, 0.98, 0.965, 0.905, 0.855, 0.92, 0.96, 0.67, 0.745, 0.945, 0.915, 0.925, 0.96, 0.95, 0.975, 0.94, 0.805, 0.985, 0.845, 0.97, 0.955, 0.915, 0.9, 0.725, 0.735, 0.745, 0.9, 0.96, 0.885, 0.93, 0.935, 0.95, 0.9, 0.89, 0.95, 0.915, 0.96, 0.96, 0.91, 0.9, 0.75, 0.965, 0.89, 0.96, 0.97, 0.87, 0.99, 0.94, 0.965, 0.925, 0.99, 0.935, 0.955, 0.965, 0.985, 0.96, 0.77, 0.91, 0.92, 0.87, 0.965, 0.965, 0.865, 0.91, 0.895, 0.725, 0.98, 0.945, 0.95, 0.93, 0.965, 0.91]
