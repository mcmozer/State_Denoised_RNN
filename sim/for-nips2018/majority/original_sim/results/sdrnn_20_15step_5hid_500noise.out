Namespace(arch='tanh', batch_size=256, display_epoch=100, input_noise_level=0.15, latent_attractor_space=True, loss_switch_frequency=0, lrate_attractor=0.002, lrate_prediction=0.002, lrate_wt_penalty=0.0, n_attractor_hidden=10, n_attractor_steps=15, n_hidden=5, n_replications=100, noise_level=0.5, report_best_train_performance=True, seq_len=20, task='majority', train_attr_weights_on_prediction=False, training_epochs=2500)
TRAINING ON 100 EXAMPLES, TESTING ON 3996
********** replication  0  **********
epoch   0 LossPred 1.0475 LossAtt 1.0361 TrainAcc 0.5300 TestAcc 0.4820 0.5050
epoch 100 LossPred 0.8923 LossAtt 0.4361 TrainAcc 0.6500 TestAcc 0.5916 0.6500
epoch 200 LossPred 0.8466 LossAtt 0.3866 TrainAcc 0.6500 TestAcc 0.5916 0.6500
epoch 300 LossPred 0.6431 LossAtt 0.4846 TrainAcc 0.7400 TestAcc 0.7170 0.7100
epoch 400 LossPred 0.4804 LossAtt 0.3917 TrainAcc 0.8500 TestAcc 0.8586 0.8100
epoch 500 LossPred 0.4387 LossAtt 0.3652 TrainAcc 0.8600 TestAcc 0.8609 0.8050
epoch 600 LossPred 0.4312 LossAtt 0.3505 TrainAcc 0.8600 TestAcc 0.8649 0.8000
epoch 700 LossPred 0.4131 LossAtt 0.3416 TrainAcc 0.8700 TestAcc 0.8574 0.8250
epoch 800 LossPred 0.4395 LossAtt 0.3316 TrainAcc 0.8700 TestAcc 0.8631 0.8100
epoch 900 LossPred 0.3953 LossAtt 0.3112 TrainAcc 0.8800 TestAcc 0.8634 0.8050
epoch 1000 LossPred 0.4076 LossAtt 0.3076 TrainAcc 0.8800 TestAcc 0.8671 0.8200
epoch 1100 LossPred 0.4056 LossAtt 0.2952 TrainAcc 0.8700 TestAcc 0.8666 0.8200
epoch 1200 LossPred 0.4340 LossAtt 0.2974 TrainAcc 0.8600 TestAcc 0.8576 0.8000
epoch 1300 LossPred 0.4545 LossAtt 0.3047 TrainAcc 0.8600 TestAcc 0.8604 0.8300
epoch 1400 LossPred 0.3727 LossAtt 0.2940 TrainAcc 0.8900 TestAcc 0.8624 0.8450
epoch 1500 LossPred 0.3833 LossAtt 0.2912 TrainAcc 0.8900 TestAcc 0.8579 0.8450
epoch 1600 LossPred 0.4544 LossAtt 0.3013 TrainAcc 0.8600 TestAcc 0.8471 0.8150
epoch 1700 LossPred 0.3822 LossAtt 0.3100 TrainAcc 0.8800 TestAcc 0.8744 0.8350
epoch 1800 LossPred 0.3817 LossAtt 0.3164 TrainAcc 0.9000 TestAcc 0.8581 0.8300
epoch 1900 LossPred 0.4893 LossAtt 0.3014 TrainAcc 0.8400 TestAcc 0.8421 0.8200
epoch 2000 LossPred 0.3273 LossAtt 0.3197 TrainAcc 0.9000 TestAcc 0.8759 0.8550
epoch 2100 LossPred 0.3472 LossAtt 0.3157 TrainAcc 0.8900 TestAcc 0.8811 0.8300
epoch 2200 LossPred 0.3689 LossAtt 0.3246 TrainAcc 0.8800 TestAcc 0.8624 0.8450
epoch 2300 LossPred 0.3212 LossAtt 0.3318 TrainAcc 0.9000 TestAcc 0.8779 0.8650
epoch 2400 LossPred 0.3110 LossAtt 0.3237 TrainAcc 0.9100 TestAcc 0.8991 0.8650
epoch 2500 LossPred 0.4486 LossAtt 0.3357 TrainAcc 0.8300 TestAcc 0.8341 0.8150
Optimization Finished!
********** replication  1  **********
epoch   0 LossPred 1.5202 LossAtt 0.9994 TrainAcc 0.3400 TestAcc 0.4782 0.3450
epoch 100 LossPred 1.0460 LossAtt 0.2719 TrainAcc 0.5400 TestAcc 0.5838 0.5350
epoch 200 LossPred 0.8554 LossAtt 0.2255 TrainAcc 0.7200 TestAcc 0.5906 0.7200
epoch 300 LossPred 0.7924 LossAtt 0.1945 TrainAcc 0.7200 TestAcc 0.5906 0.7200
epoch 400 LossPred 0.4679 LossAtt 0.4179 TrainAcc 0.8700 TestAcc 0.8021 0.8750
epoch 500 LossPred 0.3957 LossAtt 0.4027 TrainAcc 0.8900 TestAcc 0.7995 0.8800
epoch 600 LossPred 0.3778 LossAtt 0.3824 TrainAcc 0.8900 TestAcc 0.8008 0.8850
epoch 700 LossPred 0.4012 LossAtt 0.3765 TrainAcc 0.8700 TestAcc 0.8008 0.8750
epoch 800 LossPred 0.3630 LossAtt 0.3386 TrainAcc 0.9000 TestAcc 0.8163 0.8750
epoch 900 LossPred 0.4179 LossAtt 0.3384 TrainAcc 0.8400 TestAcc 0.8021 0.8350
epoch 1000 LossPred 0.3584 LossAtt 0.3349 TrainAcc 0.8800 TestAcc 0.8211 0.8550
epoch 1100 LossPred 0.3878 LossAtt 0.3235 TrainAcc 0.8800 TestAcc 0.8108 0.8750
epoch 1200 LossPred 0.3626 LossAtt 0.2954 TrainAcc 0.8700 TestAcc 0.8316 0.8550
epoch 1300 LossPred 0.3589 LossAtt 0.2919 TrainAcc 0.9000 TestAcc 0.8211 0.8700
epoch 1400 LossPred 0.3566 LossAtt 0.2816 TrainAcc 0.9000 TestAcc 0.8383 0.8650
epoch 1500 LossPred 0.3345 LossAtt 0.2694 TrainAcc 0.9000 TestAcc 0.8333 0.8950
epoch 1600 LossPred 0.3399 LossAtt 0.2712 TrainAcc 0.9000 TestAcc 0.8343 0.8850
epoch 1700 LossPred 0.3219 LossAtt 0.2480 TrainAcc 0.9100 TestAcc 0.8373 0.9000
epoch 1800 LossPred 0.3151 LossAtt 0.2461 TrainAcc 0.9100 TestAcc 0.8483 0.8950
epoch 1900 LossPred 0.3093 LossAtt 0.2338 TrainAcc 0.9100 TestAcc 0.8536 0.9000
epoch 2000 LossPred 0.3477 LossAtt 0.2409 TrainAcc 0.8800 TestAcc 0.8509 0.8700
epoch 2100 LossPred 0.3060 LossAtt 0.2227 TrainAcc 0.9100 TestAcc 0.8461 0.9050
epoch 2200 LossPred 0.3112 LossAtt 0.2278 TrainAcc 0.9000 TestAcc 0.8421 0.8700
epoch 2300 LossPred 0.3226 LossAtt 0.2386 TrainAcc 0.8900 TestAcc 0.8571 0.8850
epoch 2400 LossPred 0.3103 LossAtt 0.2258 TrainAcc 0.9000 TestAcc 0.8561 0.8850
epoch 2500 LossPred 0.3018 LossAtt 0.2233 TrainAcc 0.8900 TestAcc 0.8701 0.8750
Optimization Finished!
********** replication  2  **********
epoch   0 LossPred 0.9776 LossAtt 1.0303 TrainAcc 0.5500 TestAcc 0.4494 0.5700
epoch 100 LossPred 0.8922 LossAtt 0.3273 TrainAcc 0.6600 TestAcc 0.5716 0.6600
epoch 200 LossPred 0.8834 LossAtt 0.1783 TrainAcc 0.6600 TestAcc 0.5716 0.6600
epoch 300 LossPred 0.8826 LossAtt 0.1365 TrainAcc 0.6600 TestAcc 0.5716 0.6600
epoch 400 LossPred 0.8815 LossAtt 0.1593 TrainAcc 0.6600 TestAcc 0.5716 0.6600
epoch 500 LossPred 0.8732 LossAtt 0.3144 TrainAcc 0.6600 TestAcc 0.5716 0.6600
epoch 600 LossPred 0.4993 LossAtt 0.3916 TrainAcc 0.8500 TestAcc 0.8431 0.8350
epoch 700 LossPred 0.8298 LossAtt 0.3758 TrainAcc 0.6800 TestAcc 0.7422 0.7000
epoch 800 LossPred 0.4939 LossAtt 0.3363 TrainAcc 0.8500 TestAcc 0.7988 0.8050
epoch 900 LossPred 0.3264 LossAtt 0.3316 TrainAcc 0.8900 TestAcc 0.8776 0.8750
epoch 1000 LossPred 0.5493 LossAtt 0.3643 TrainAcc 0.7900 TestAcc 0.8001 0.8000
epoch 1100 LossPred 0.3204 LossAtt 0.3388 TrainAcc 0.9300 TestAcc 0.8811 0.8850
epoch 1200 LossPred 0.4366 LossAtt 0.3494 TrainAcc 0.8700 TestAcc 0.8273 0.8450
epoch 1300 LossPred 0.4560 LossAtt 0.3156 TrainAcc 0.8500 TestAcc 0.8136 0.8300
epoch 1400 LossPred 0.3085 LossAtt 0.3266 TrainAcc 0.9100 TestAcc 0.8614 0.8600
epoch 1500 LossPred 0.2704 LossAtt 0.3099 TrainAcc 0.9300 TestAcc 0.8784 0.8850
epoch 1600 LossPred 0.3241 LossAtt 0.3299 TrainAcc 0.8900 TestAcc 0.8714 0.8850
epoch 1700 LossPred 0.3111 LossAtt 0.3066 TrainAcc 0.9100 TestAcc 0.8734 0.8750
epoch 1800 LossPred 0.5029 LossAtt 0.3108 TrainAcc 0.8500 TestAcc 0.8246 0.8300
epoch 1900 LossPred 0.6781 LossAtt 0.3080 TrainAcc 0.7900 TestAcc 0.7788 0.7650
epoch 2000 LossPred 1.0895 LossAtt 0.2897 TrainAcc 0.6800 TestAcc 0.5943 0.6800
epoch 2100 LossPred 0.6330 LossAtt 0.2855 TrainAcc 0.7900 TestAcc 0.7515 0.7950
epoch 2200 LossPred 0.3640 LossAtt 0.3124 TrainAcc 0.8900 TestAcc 0.8551 0.8650
epoch 2300 LossPred 0.5513 LossAtt 0.2950 TrainAcc 0.8100 TestAcc 0.7813 0.8150
epoch 2400 LossPred 0.4981 LossAtt 0.2941 TrainAcc 0.8500 TestAcc 0.8266 0.8100
epoch 2500 LossPred 1.0251 LossAtt 0.3012 TrainAcc 0.6400 TestAcc 0.7090 0.6500
Optimization Finished!
********** replication  3  **********
epoch   0 LossPred 1.1637 LossAtt 1.0165 TrainAcc 0.4000 TestAcc 0.4635 0.4550
epoch 100 LossPred 0.9634 LossAtt 0.2380 TrainAcc 0.5400 TestAcc 0.5843 0.5850
epoch 200 LossPred 0.9293 LossAtt 0.1345 TrainAcc 0.6400 TestAcc 0.5841 0.6400
epoch 300 LossPred 0.9339 LossAtt 0.0864 TrainAcc 0.6400 TestAcc 0.5841 0.6400
epoch 400 LossPred 0.9535 LossAtt 0.1450 TrainAcc 0.6400 TestAcc 0.5841 0.6250
epoch 500 LossPred 0.9522 LossAtt 0.1550 TrainAcc 0.6400 TestAcc 0.6314 0.6350
epoch 600 LossPred 0.8919 LossAtt 0.2383 TrainAcc 0.6400 TestAcc 0.5841 0.6400
epoch 700 LossPred 0.8756 LossAtt 0.3386 TrainAcc 0.6400 TestAcc 0.5841 0.6400
epoch 800 LossPred 1.0601 LossAtt 0.3511 TrainAcc 0.6300 TestAcc 0.6391 0.6450
epoch 900 LossPred 0.4089 LossAtt 0.3075 TrainAcc 0.8800 TestAcc 0.8316 0.8500
epoch 1000 LossPred 0.5439 LossAtt 0.3026 TrainAcc 0.8300 TestAcc 0.7833 0.7900
epoch 1100 LossPred 0.3959 LossAtt 0.2979 TrainAcc 0.8700 TestAcc 0.8373 0.8350
epoch 1200 LossPred 0.4515 LossAtt 0.3270 TrainAcc 0.8600 TestAcc 0.7995 0.8200
epoch 1300 LossPred 0.3737 LossAtt 0.3493 TrainAcc 0.8600 TestAcc 0.8243 0.8450
epoch 1400 LossPred 0.3675 LossAtt 0.3106 TrainAcc 0.8700 TestAcc 0.8346 0.8400
epoch 1500 LossPred 0.3458 LossAtt 0.3176 TrainAcc 0.9000 TestAcc 0.8438 0.8550
epoch 1600 LossPred 0.4013 LossAtt 0.3037 TrainAcc 0.8500 TestAcc 0.8423 0.8400
epoch 1700 LossPred 0.3552 LossAtt 0.3314 TrainAcc 0.8900 TestAcc 0.8453 0.8650
epoch 1800 LossPred 0.3760 LossAtt 0.3173 TrainAcc 0.8800 TestAcc 0.8328 0.8350
epoch 1900 LossPred 0.3116 LossAtt 0.3309 TrainAcc 0.9000 TestAcc 0.8466 0.8850
epoch 2000 LossPred 0.3487 LossAtt 0.3383 TrainAcc 0.8600 TestAcc 0.8363 0.8550
epoch 2100 LossPred 0.3015 LossAtt 0.3378 TrainAcc 0.8900 TestAcc 0.8491 0.8650
epoch 2200 LossPred 0.5875 LossAtt 0.3426 TrainAcc 0.8100 TestAcc 0.7858 0.7900
epoch 2300 LossPred 0.2725 LossAtt 0.3295 TrainAcc 0.9100 TestAcc 0.8704 0.9050
epoch 2400 LossPred 0.2823 LossAtt 0.3409 TrainAcc 0.8900 TestAcc 0.8654 0.8850
epoch 2500 LossPred 0.2768 LossAtt 0.3567 TrainAcc 0.9100 TestAcc 0.8761 0.8800
Optimization Finished!
********** replication  4  **********
epoch   0 LossPred 1.2503 LossAtt 1.0067 TrainAcc 0.5000 TestAcc 0.4857 0.4750
epoch 100 LossPred 1.0017 LossAtt 0.3777 TrainAcc 0.5900 TestAcc 0.6054 0.5350
epoch 200 LossPred 0.9963 LossAtt 0.4051 TrainAcc 0.5900 TestAcc 0.6054 0.5800
epoch 300 LossPred 0.9193 LossAtt 0.2964 TrainAcc 0.5900 TestAcc 0.6054 0.5850
epoch 400 LossPred 0.8810 LossAtt 0.2439 TrainAcc 0.6700 TestAcc 0.5891 0.6700
epoch 500 LossPred 0.8670 LossAtt 0.2690 TrainAcc 0.6700 TestAcc 0.5891 0.6700
epoch 600 LossPred 0.8522 LossAtt 0.3626 TrainAcc 0.6900 TestAcc 0.6316 0.6850
epoch 700 LossPred 0.8394 LossAtt 0.3624 TrainAcc 0.6900 TestAcc 0.6339 0.6900
epoch 800 LossPred 0.8194 LossAtt 0.3943 TrainAcc 0.6900 TestAcc 0.6639 0.6950
epoch 900 LossPred 0.7920 LossAtt 0.3862 TrainAcc 0.7100 TestAcc 0.6737 0.7050
epoch 1000 LossPred 0.5656 LossAtt 0.3289 TrainAcc 0.7900 TestAcc 0.8386 0.7850
epoch 1100 LossPred 0.4648 LossAtt 0.3209 TrainAcc 0.8400 TestAcc 0.8769 0.8250
epoch 1200 LossPred 0.4022 LossAtt 0.3217 TrainAcc 0.8800 TestAcc 0.8791 0.8350
epoch 1300 LossPred 0.3779 LossAtt 0.2981 TrainAcc 0.8800 TestAcc 0.8946 0.8700
epoch 1400 LossPred 0.3590 LossAtt 0.2925 TrainAcc 0.8600 TestAcc 0.9044 0.8600
epoch 1500 LossPred 0.3481 LossAtt 0.3029 TrainAcc 0.9100 TestAcc 0.8914 0.8700
epoch 1600 LossPred 0.3142 LossAtt 0.2942 TrainAcc 0.9000 TestAcc 0.9099 0.8650
epoch 1700 LossPred 0.3355 LossAtt 0.2795 TrainAcc 0.8900 TestAcc 0.9014 0.8550
epoch 1800 LossPred 0.6480 LossAtt 0.3181 TrainAcc 0.7800 TestAcc 0.8218 0.8050
epoch 1900 LossPred 0.3435 LossAtt 0.2874 TrainAcc 0.8500 TestAcc 0.9129 0.8550
epoch 2000 LossPred 0.3306 LossAtt 0.3033 TrainAcc 0.9100 TestAcc 0.8841 0.8800
epoch 2100 LossPred 0.2628 LossAtt 0.2898 TrainAcc 0.9300 TestAcc 0.9139 0.8850
epoch 2200 LossPred 0.2865 LossAtt 0.2747 TrainAcc 0.9300 TestAcc 0.9164 0.8750
epoch 2300 LossPred 0.3664 LossAtt 0.2841 TrainAcc 0.8900 TestAcc 0.8784 0.8650
epoch 2400 LossPred 0.2585 LossAtt 0.2706 TrainAcc 0.9300 TestAcc 0.9097 0.8800
epoch 2500 LossPred 0.2640 LossAtt 0.2740 TrainAcc 0.9200 TestAcc 0.9102 0.8650
Optimization Finished!
********** replication  5  **********
epoch   0 LossPred 1.1651 LossAtt 1.0033 TrainAcc 0.4400 TestAcc 0.4902 0.4500
epoch 100 LossPred 0.9313 LossAtt 0.4416 TrainAcc 0.6200 TestAcc 0.5430 0.6000
epoch 200 LossPred 0.9124 LossAtt 0.3833 TrainAcc 0.6200 TestAcc 0.5430 0.6050
epoch 300 LossPred 0.8840 LossAtt 0.3065 TrainAcc 0.6600 TestAcc 0.5938 0.6600
epoch 400 LossPred 0.8641 LossAtt 0.2668 TrainAcc 0.6600 TestAcc 0.5938 0.6600
epoch 500 LossPred 0.8618 LossAtt 0.2092 TrainAcc 0.6600 TestAcc 0.5938 0.6600
epoch 600 LossPred 0.8618 LossAtt 0.1957 TrainAcc 0.6600 TestAcc 0.5938 0.6600
epoch 700 LossPred 0.8604 LossAtt 0.2203 TrainAcc 0.6600 TestAcc 0.5938 0.6600
epoch 800 LossPred 0.8583 LossAtt 0.2127 TrainAcc 0.6600 TestAcc 0.5938 0.6600
epoch 900 LossPred 0.8564 LossAtt 0.2454 TrainAcc 0.6600 TestAcc 0.5938 0.6600
epoch 1000 LossPred 0.8557 LossAtt 0.2076 TrainAcc 0.6600 TestAcc 0.5938 0.6600
epoch 1100 LossPred 0.8534 LossAtt 0.2207 TrainAcc 0.6600 TestAcc 0.5938 0.6600
epoch 1200 LossPred 0.8181 LossAtt 0.3887 TrainAcc 0.6600 TestAcc 0.5938 0.6600
epoch 1300 LossPred 0.6038 LossAtt 0.4879 TrainAcc 0.7700 TestAcc 0.7588 0.7700
epoch 1400 LossPred 0.7808 LossAtt 0.4465 TrainAcc 0.7100 TestAcc 0.6499 0.7150
epoch 1500 LossPred 0.6995 LossAtt 0.4128 TrainAcc 0.7500 TestAcc 0.7012 0.7600
epoch 1600 LossPred 0.5949 LossAtt 0.3998 TrainAcc 0.8000 TestAcc 0.7555 0.7850
epoch 1700 LossPred 0.5406 LossAtt 0.4354 TrainAcc 0.7800 TestAcc 0.8063 0.7900
epoch 1800 LossPred 0.3699 LossAtt 0.4047 TrainAcc 0.8700 TestAcc 0.8639 0.8550
epoch 1900 LossPred 0.3725 LossAtt 0.3955 TrainAcc 0.8600 TestAcc 0.8644 0.8450
epoch 2000 LossPred 0.3097 LossAtt 0.3770 TrainAcc 0.9100 TestAcc 0.8819 0.8600
epoch 2100 LossPred 0.2872 LossAtt 0.3582 TrainAcc 0.9100 TestAcc 0.8804 0.8550
epoch 2200 LossPred 0.4184 LossAtt 0.3702 TrainAcc 0.8700 TestAcc 0.8541 0.8500
epoch 2300 LossPred 0.6420 LossAtt 0.3421 TrainAcc 0.8000 TestAcc 0.7665 0.7900
epoch 2400 LossPred 0.4719 LossAtt 0.3799 TrainAcc 0.8200 TestAcc 0.8258 0.8300
epoch 2500 LossPred 0.3843 LossAtt 0.3783 TrainAcc 0.8900 TestAcc 0.8754 0.8450
Optimization Finished!
********** replication  6  **********
epoch   0 LossPred 1.0520 LossAtt 1.0101 TrainAcc 0.4600 TestAcc 0.4937 0.4800
epoch 100 LossPred 0.9224 LossAtt 0.5017 TrainAcc 0.6500 TestAcc 0.6054 0.6750
epoch 200 LossPred 0.8373 LossAtt 0.4830 TrainAcc 0.7000 TestAcc 0.6341 0.7000
epoch 300 LossPred 0.6799 LossAtt 0.5185 TrainAcc 0.7900 TestAcc 0.7110 0.7800
epoch 400 LossPred 0.4502 LossAtt 0.4960 TrainAcc 0.8200 TestAcc 0.8366 0.8250
epoch 500 LossPred 0.2108 LossAtt 0.4841 TrainAcc 0.9300 TestAcc 0.8966 0.8750
epoch 600 LossPred 0.4174 LossAtt 0.5045 TrainAcc 0.8300 TestAcc 0.8398 0.8400
epoch 700 LossPred 0.1418 LossAtt 0.4961 TrainAcc 0.9700 TestAcc 0.8974 0.9350
epoch 800 LossPred 0.5958 LossAtt 0.4885 TrainAcc 0.7800 TestAcc 0.8071 0.7900
epoch 900 LossPred 0.1629 LossAtt 0.4685 TrainAcc 0.9700 TestAcc 0.8769 0.9450
epoch 1000 LossPred 0.2696 LossAtt 0.4512 TrainAcc 0.9300 TestAcc 0.8281 0.9000
epoch 1100 LossPred 0.2157 LossAtt 0.4285 TrainAcc 0.9400 TestAcc 0.8368 0.9100
epoch 1200 LossPred 0.1916 LossAtt 0.4108 TrainAcc 0.9500 TestAcc 0.8594 0.9200
epoch 1300 LossPred 0.1803 LossAtt 0.4167 TrainAcc 0.9400 TestAcc 0.8659 0.9200
epoch 1400 LossPred 0.1611 LossAtt 0.4088 TrainAcc 0.9600 TestAcc 0.8458 0.9200
epoch 1500 LossPred 0.2676 LossAtt 0.3987 TrainAcc 0.9000 TestAcc 0.8589 0.9500
epoch 1600 LossPred 0.1518 LossAtt 0.4026 TrainAcc 0.9700 TestAcc 0.8531 0.9550
epoch 1700 LossPred 0.1778 LossAtt 0.3914 TrainAcc 0.9400 TestAcc 0.8463 0.9250
epoch 1800 LossPred 0.1775 LossAtt 0.3919 TrainAcc 0.9300 TestAcc 0.8451 0.9500
epoch 1900 LossPred 0.1722 LossAtt 0.3810 TrainAcc 0.9300 TestAcc 0.8408 0.9450
epoch 2000 LossPred 0.1483 LossAtt 0.3816 TrainAcc 0.9600 TestAcc 0.8456 0.9450
epoch 2100 LossPred 0.1929 LossAtt 0.3829 TrainAcc 0.9200 TestAcc 0.8363 0.9300
epoch 2200 LossPred 0.4061 LossAtt 0.3926 TrainAcc 0.8700 TestAcc 0.8321 0.8600
epoch 2300 LossPred 0.1365 LossAtt 0.3830 TrainAcc 0.9700 TestAcc 0.8504 0.9500
epoch 2400 LossPred 0.1644 LossAtt 0.3928 TrainAcc 0.9500 TestAcc 0.8326 0.9150
epoch 2500 LossPred 0.1420 LossAtt 0.3744 TrainAcc 0.9700 TestAcc 0.8351 0.9350
Optimization Finished!
********** replication  7  **********
epoch   0 LossPred 0.9748 LossAtt 1.0055 TrainAcc 0.5900 TestAcc 0.5183 0.5600
epoch 100 LossPred 0.8714 LossAtt 0.5082 TrainAcc 0.6700 TestAcc 0.5783 0.6750
epoch 200 LossPred 0.8503 LossAtt 0.4812 TrainAcc 0.7100 TestAcc 0.5966 0.6800
epoch 300 LossPred 0.8320 LossAtt 0.4849 TrainAcc 0.7000 TestAcc 0.5686 0.6650
epoch 400 LossPred 0.7620 LossAtt 0.6053 TrainAcc 0.7100 TestAcc 0.5348 0.6850
epoch 500 LossPred 0.6757 LossAtt 0.6171 TrainAcc 0.7700 TestAcc 0.5761 0.7700
epoch 600 LossPred 0.5943 LossAtt 0.6122 TrainAcc 0.8300 TestAcc 0.5921 0.7950
epoch 700 LossPred 0.5228 LossAtt 0.5756 TrainAcc 0.8300 TestAcc 0.6271 0.8300
epoch 800 LossPred 0.6122 LossAtt 0.6082 TrainAcc 0.7900 TestAcc 0.6001 0.7500
epoch 900 LossPred 0.4946 LossAtt 0.5973 TrainAcc 0.8300 TestAcc 0.6394 0.8300
epoch 1000 LossPred 0.4729 LossAtt 0.5991 TrainAcc 0.8400 TestAcc 0.6484 0.8200
epoch 1100 LossPred 0.4368 LossAtt 0.5978 TrainAcc 0.8600 TestAcc 0.6326 0.8300
epoch 1200 LossPred 0.4244 LossAtt 0.6157 TrainAcc 0.8500 TestAcc 0.6269 0.8300
epoch 1300 LossPred 0.4288 LossAtt 0.6015 TrainAcc 0.8400 TestAcc 0.6164 0.8400
epoch 1400 LossPred 0.4618 LossAtt 0.6084 TrainAcc 0.8500 TestAcc 0.6401 0.8300
epoch 1500 LossPred 0.4014 LossAtt 0.6213 TrainAcc 0.8600 TestAcc 0.6124 0.8450
epoch 1600 LossPred 0.4132 LossAtt 0.6073 TrainAcc 0.8700 TestAcc 0.6029 0.8350
epoch 1700 LossPred 0.4181 LossAtt 0.6093 TrainAcc 0.8800 TestAcc 0.5798 0.8200
epoch 1800 LossPred 0.4172 LossAtt 0.6079 TrainAcc 0.8800 TestAcc 0.5911 0.8350
epoch 1900 LossPred 0.4614 LossAtt 0.5916 TrainAcc 0.8800 TestAcc 0.5883 0.8000
epoch 2000 LossPred 0.4221 LossAtt 0.5848 TrainAcc 0.8500 TestAcc 0.5848 0.8100
epoch 2100 LossPred 0.4029 LossAtt 0.5866 TrainAcc 0.8700 TestAcc 0.5821 0.8050
epoch 2200 LossPred 0.4092 LossAtt 0.5990 TrainAcc 0.8800 TestAcc 0.5766 0.8100
epoch 2300 LossPred 0.3961 LossAtt 0.5777 TrainAcc 0.8900 TestAcc 0.5716 0.8050
epoch 2400 LossPred 0.3834 LossAtt 0.5766 TrainAcc 0.8800 TestAcc 0.5801 0.8200
epoch 2500 LossPred 0.5419 LossAtt 0.6083 TrainAcc 0.8300 TestAcc 0.5951 0.8150
Optimization Finished!
********** replication  8  **********
epoch   0 LossPred 1.3164 LossAtt 1.0261 TrainAcc 0.3800 TestAcc 0.4114 0.3800
epoch 100 LossPred 0.9750 LossAtt 0.3254 TrainAcc 0.6200 TestAcc 0.5886 0.6100
epoch 200 LossPred 0.9364 LossAtt 0.2598 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 300 LossPred 0.9241 LossAtt 0.1538 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 400 LossPred 0.9209 LossAtt 0.1194 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 500 LossPred 0.9199 LossAtt 0.0906 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 600 LossPred 0.9195 LossAtt 0.0784 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 700 LossPred 0.9192 LossAtt 0.0762 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 800 LossPred 0.9189 LossAtt 0.0869 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 900 LossPred 0.9184 LossAtt 0.0995 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 1000 LossPred 0.9166 LossAtt 0.1645 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 1100 LossPred 0.8930 LossAtt 0.2721 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 1200 LossPred 0.8912 LossAtt 0.2146 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 1300 LossPred 0.8916 LossAtt 0.2049 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 1400 LossPred 0.8918 LossAtt 0.1936 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 1500 LossPred 0.8916 LossAtt 0.1680 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 1600 LossPred 0.8912 LossAtt 0.1539 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 1700 LossPred 0.8910 LossAtt 0.1678 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 1800 LossPred 0.8910 LossAtt 0.1825 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 1900 LossPred 0.8909 LossAtt 0.1477 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 2000 LossPred 0.8909 LossAtt 0.1309 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 2100 LossPred 0.8908 LossAtt 0.1289 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 2200 LossPred 0.8908 LossAtt 0.1500 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 2300 LossPred 0.8908 LossAtt 0.1340 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 2400 LossPred 0.8907 LossAtt 0.1234 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 2500 LossPred 0.8906 LossAtt 0.1561 TrainAcc 0.6200 TestAcc 0.5886 0.6200
Optimization Finished!
********** replication  9  **********
epoch   0 LossPred 0.9428 LossAtt 1.0031 TrainAcc 0.6200 TestAcc 0.4965 0.6150
epoch 100 LossPred 0.8582 LossAtt 0.3607 TrainAcc 0.6700 TestAcc 0.5871 0.6700
epoch 200 LossPred 0.8229 LossAtt 0.2974 TrainAcc 0.6700 TestAcc 0.5871 0.6900
epoch 300 LossPred 0.3746 LossAtt 0.4053 TrainAcc 0.8600 TestAcc 0.8148 0.8700
epoch 400 LossPred 0.3339 LossAtt 0.3881 TrainAcc 0.8800 TestAcc 0.8106 0.8900
epoch 500 LossPred 0.3378 LossAtt 0.4060 TrainAcc 0.8800 TestAcc 0.8236 0.8800
epoch 600 LossPred 0.3238 LossAtt 0.3826 TrainAcc 0.8700 TestAcc 0.8191 0.8800
epoch 700 LossPred 0.3641 LossAtt 0.3716 TrainAcc 0.8700 TestAcc 0.8203 0.8950
epoch 800 LossPred 0.4474 LossAtt 0.3820 TrainAcc 0.8300 TestAcc 0.7720 0.8900
epoch 900 LossPred 0.3282 LossAtt 0.3700 TrainAcc 0.8800 TestAcc 0.8191 0.8850
epoch 1000 LossPred 0.3185 LossAtt 0.3489 TrainAcc 0.8900 TestAcc 0.8091 0.9000
epoch 1100 LossPred 0.3151 LossAtt 0.3092 TrainAcc 0.9000 TestAcc 0.8101 0.8850
epoch 1200 LossPred 0.4683 LossAtt 0.2920 TrainAcc 0.8400 TestAcc 0.8281 0.8400
epoch 1300 LossPred 0.3144 LossAtt 0.3006 TrainAcc 0.8900 TestAcc 0.8176 0.8850
epoch 1400 LossPred 0.3110 LossAtt 0.3226 TrainAcc 0.9000 TestAcc 0.8246 0.9050
epoch 1500 LossPred 0.3221 LossAtt 0.3072 TrainAcc 0.8900 TestAcc 0.8168 0.8950
epoch 1600 LossPred 0.2828 LossAtt 0.3208 TrainAcc 0.9100 TestAcc 0.8253 0.9050
epoch 1700 LossPred 0.2797 LossAtt 0.3308 TrainAcc 0.9200 TestAcc 0.8413 0.9150
epoch 1800 LossPred 0.4907 LossAtt 0.3617 TrainAcc 0.8400 TestAcc 0.7240 0.8350
epoch 1900 LossPred 0.2755 LossAtt 0.3400 TrainAcc 0.9200 TestAcc 0.8519 0.9350
epoch 2000 LossPred 0.3452 LossAtt 0.3867 TrainAcc 0.8500 TestAcc 0.7860 0.9000
epoch 2100 LossPred 0.1741 LossAtt 0.3825 TrainAcc 0.9600 TestAcc 0.8581 0.9600
epoch 2200 LossPred 0.1461 LossAtt 0.3983 TrainAcc 0.9700 TestAcc 0.8621 0.9600
epoch 2300 LossPred 0.1312 LossAtt 0.4236 TrainAcc 0.9800 TestAcc 0.8846 0.9700
epoch 2400 LossPred 0.1437 LossAtt 0.4167 TrainAcc 0.9500 TestAcc 0.8834 0.9600
epoch 2500 LossPred 0.1081 LossAtt 0.4082 TrainAcc 0.9700 TestAcc 0.8756 0.9650
Optimization Finished!
********** replication  10  **********
epoch   0 LossPred 0.9682 LossAtt 1.0357 TrainAcc 0.6200 TestAcc 0.5856 0.6150
epoch 100 LossPred 0.8649 LossAtt 0.5309 TrainAcc 0.6900 TestAcc 0.6301 0.6800
epoch 200 LossPred 0.6521 LossAtt 0.5866 TrainAcc 0.7600 TestAcc 0.8053 0.7550
epoch 300 LossPred 0.5246 LossAtt 0.5573 TrainAcc 0.8300 TestAcc 0.7930 0.8700
epoch 400 LossPred 0.5171 LossAtt 0.5448 TrainAcc 0.8300 TestAcc 0.7893 0.8450
epoch 500 LossPred 0.4978 LossAtt 0.5013 TrainAcc 0.8400 TestAcc 0.8028 0.8400
epoch 600 LossPred 0.4626 LossAtt 0.4423 TrainAcc 0.8500 TestAcc 0.7935 0.8350
epoch 700 LossPred 0.5243 LossAtt 0.4764 TrainAcc 0.8300 TestAcc 0.7880 0.8200
epoch 800 LossPred 0.5633 LossAtt 0.4441 TrainAcc 0.8200 TestAcc 0.7748 0.8050
epoch 900 LossPred 0.4910 LossAtt 0.4585 TrainAcc 0.8500 TestAcc 0.7805 0.8400
epoch 1000 LossPred 0.5090 LossAtt 0.4409 TrainAcc 0.8400 TestAcc 0.7705 0.8300
epoch 1100 LossPred 0.7468 LossAtt 0.4448 TrainAcc 0.7200 TestAcc 0.7342 0.7850
epoch 1200 LossPred 0.6239 LossAtt 0.4541 TrainAcc 0.8000 TestAcc 0.7135 0.7550
epoch 1300 LossPred 0.5170 LossAtt 0.4205 TrainAcc 0.8300 TestAcc 0.7725 0.8300
epoch 1400 LossPred 0.4854 LossAtt 0.4169 TrainAcc 0.8500 TestAcc 0.7800 0.8250
epoch 1500 LossPred 0.9693 LossAtt 0.4848 TrainAcc 0.6600 TestAcc 0.6532 0.6450
epoch 1600 LossPred 0.6269 LossAtt 0.4159 TrainAcc 0.7800 TestAcc 0.7505 0.7850
epoch 1700 LossPred 0.8921 LossAtt 0.4067 TrainAcc 0.6100 TestAcc 0.6384 0.6300
epoch 1800 LossPred 0.5356 LossAtt 0.3573 TrainAcc 0.8000 TestAcc 0.7588 0.7850
epoch 1900 LossPred 0.5195 LossAtt 0.3406 TrainAcc 0.8000 TestAcc 0.7605 0.7800
epoch 2000 LossPred 0.4989 LossAtt 0.3289 TrainAcc 0.8400 TestAcc 0.7823 0.8250
epoch 2100 LossPred 0.4846 LossAtt 0.3221 TrainAcc 0.8500 TestAcc 0.7795 0.8250
epoch 2200 LossPred 0.5302 LossAtt 0.3467 TrainAcc 0.8400 TestAcc 0.7578 0.8300
epoch 2300 LossPred 0.5807 LossAtt 0.2968 TrainAcc 0.8200 TestAcc 0.7513 0.8250
epoch 2400 LossPred 0.4868 LossAtt 0.2967 TrainAcc 0.8500 TestAcc 0.7705 0.8100
epoch 2500 LossPred 0.4252 LossAtt 0.3165 TrainAcc 0.8700 TestAcc 0.7943 0.8150
Optimization Finished!
********** replication  11  **********
epoch   0 LossPred 1.1871 LossAtt 1.0086 TrainAcc 0.5700 TestAcc 0.5898 0.5400
epoch 100 LossPred 0.9815 LossAtt 0.4626 TrainAcc 0.5700 TestAcc 0.5898 0.5700
epoch 200 LossPred 0.9405 LossAtt 0.3786 TrainAcc 0.6100 TestAcc 0.6029 0.6100
epoch 300 LossPred 0.9241 LossAtt 0.3964 TrainAcc 0.6400 TestAcc 0.6001 0.6400
epoch 400 LossPred 0.9113 LossAtt 0.4513 TrainAcc 0.6500 TestAcc 0.5966 0.6350
epoch 500 LossPred 0.8960 LossAtt 0.4223 TrainAcc 0.6500 TestAcc 0.5953 0.6400
epoch 600 LossPred 0.8884 LossAtt 0.4332 TrainAcc 0.6400 TestAcc 0.5913 0.6550
epoch 700 LossPred 0.8835 LossAtt 0.4149 TrainAcc 0.6500 TestAcc 0.5873 0.6550
epoch 800 LossPred 0.8880 LossAtt 0.3835 TrainAcc 0.6500 TestAcc 0.5871 0.6450
epoch 900 LossPred 0.8755 LossAtt 0.4113 TrainAcc 0.6500 TestAcc 0.5863 0.6550
epoch 1000 LossPred 0.8733 LossAtt 0.3993 TrainAcc 0.6500 TestAcc 0.5873 0.6700
epoch 1100 LossPred 0.8735 LossAtt 0.3998 TrainAcc 0.6500 TestAcc 0.5863 0.6650
epoch 1200 LossPred 0.8731 LossAtt 0.3650 TrainAcc 0.6500 TestAcc 0.5918 0.6450
epoch 1300 LossPred 0.8787 LossAtt 0.3754 TrainAcc 0.6500 TestAcc 0.5921 0.6350
epoch 1400 LossPred 0.8767 LossAtt 0.3840 TrainAcc 0.6500 TestAcc 0.5953 0.6350
epoch 1500 LossPred 0.8748 LossAtt 0.3684 TrainAcc 0.6500 TestAcc 0.5956 0.6400
epoch 1600 LossPred 0.9015 LossAtt 0.3654 TrainAcc 0.6300 TestAcc 0.5673 0.6350
epoch 1700 LossPred 0.8996 LossAtt 0.4020 TrainAcc 0.6300 TestAcc 0.5688 0.6300
epoch 1800 LossPred 0.8951 LossAtt 0.4118 TrainAcc 0.6200 TestAcc 0.5726 0.6250
epoch 1900 LossPred 0.9024 LossAtt 0.3401 TrainAcc 0.6300 TestAcc 0.5781 0.6450
epoch 2000 LossPred 0.9091 LossAtt 0.2920 TrainAcc 0.6400 TestAcc 0.6001 0.6350
epoch 2100 LossPred 0.9176 LossAtt 0.2676 TrainAcc 0.6400 TestAcc 0.6001 0.6350
epoch 2200 LossPred 0.9176 LossAtt 0.2391 TrainAcc 0.6400 TestAcc 0.6001 0.6350
epoch 2300 LossPred 0.9087 LossAtt 0.2330 TrainAcc 0.6400 TestAcc 0.6001 0.6400
epoch 2400 LossPred 0.8981 LossAtt 0.2288 TrainAcc 0.6400 TestAcc 0.6001 0.6350
epoch 2500 LossPred 0.9046 LossAtt 0.2559 TrainAcc 0.6000 TestAcc 0.6224 0.6000
Optimization Finished!
********** replication  12  **********
epoch   0 LossPred 1.3986 LossAtt 1.0082 TrainAcc 0.4900 TestAcc 0.5100 0.4500
epoch 100 LossPred 1.0658 LossAtt 0.5229 TrainAcc 0.5300 TestAcc 0.5175 0.5350
epoch 200 LossPred 0.9571 LossAtt 0.5486 TrainAcc 0.5300 TestAcc 0.5260 0.5300
epoch 300 LossPred 0.9266 LossAtt 0.5692 TrainAcc 0.6100 TestAcc 0.5473 0.5900
epoch 400 LossPred 0.8868 LossAtt 0.6071 TrainAcc 0.6500 TestAcc 0.5270 0.6550
epoch 500 LossPred 0.8265 LossAtt 0.6145 TrainAcc 0.6600 TestAcc 0.5468 0.6950
epoch 600 LossPred 0.4470 LossAtt 0.6096 TrainAcc 0.8700 TestAcc 0.8176 0.8450
epoch 700 LossPred 0.3701 LossAtt 0.5005 TrainAcc 0.8800 TestAcc 0.8001 0.8650
epoch 800 LossPred 0.2783 LossAtt 0.5358 TrainAcc 0.9100 TestAcc 0.8411 0.8900
epoch 900 LossPred 0.3071 LossAtt 0.5320 TrainAcc 0.8900 TestAcc 0.8506 0.8700
epoch 1000 LossPred 0.3222 LossAtt 0.5143 TrainAcc 0.9000 TestAcc 0.8323 0.8650
epoch 1100 LossPred 0.3047 LossAtt 0.4997 TrainAcc 0.9000 TestAcc 0.8363 0.8650
epoch 1200 LossPred 0.2493 LossAtt 0.5283 TrainAcc 0.9300 TestAcc 0.8621 0.9050
epoch 1300 LossPred 0.3824 LossAtt 0.5069 TrainAcc 0.8600 TestAcc 0.8141 0.8750
epoch 1400 LossPred 0.2681 LossAtt 0.5271 TrainAcc 0.9200 TestAcc 0.8478 0.8900
epoch 1500 LossPred 0.3532 LossAtt 0.4633 TrainAcc 0.8900 TestAcc 0.8026 0.8900
epoch 1600 LossPred 0.2775 LossAtt 0.5140 TrainAcc 0.9300 TestAcc 0.8276 0.8850
epoch 1700 LossPred 0.2148 LossAtt 0.4732 TrainAcc 0.9400 TestAcc 0.8298 0.8850
epoch 1800 LossPred 0.2856 LossAtt 0.4802 TrainAcc 0.9100 TestAcc 0.8281 0.8950
epoch 1900 LossPred 0.2012 LossAtt 0.4877 TrainAcc 0.9400 TestAcc 0.8371 0.8850
epoch 2000 LossPred 0.3254 LossAtt 0.4507 TrainAcc 0.9000 TestAcc 0.8193 0.8900
epoch 2100 LossPred 0.3143 LossAtt 0.5044 TrainAcc 0.9000 TestAcc 0.8326 0.8700
epoch 2200 LossPred 0.1916 LossAtt 0.4628 TrainAcc 0.9600 TestAcc 0.8406 0.8950
epoch 2300 LossPred 0.2817 LossAtt 0.5134 TrainAcc 0.9000 TestAcc 0.8388 0.8950
epoch 2400 LossPred 0.2777 LossAtt 0.5231 TrainAcc 0.9200 TestAcc 0.8231 0.8900
epoch 2500 LossPred 0.3112 LossAtt 0.4284 TrainAcc 0.9000 TestAcc 0.8236 0.8900
Optimization Finished!
********** replication  13  **********
epoch   0 LossPred 1.0882 LossAtt 1.0270 TrainAcc 0.4700 TestAcc 0.4797 0.4650
epoch 100 LossPred 0.8994 LossAtt 0.4202 TrainAcc 0.6100 TestAcc 0.5821 0.6100
epoch 200 LossPred 0.8781 LossAtt 0.3993 TrainAcc 0.6100 TestAcc 0.5821 0.6200
epoch 300 LossPred 0.8603 LossAtt 0.4123 TrainAcc 0.6400 TestAcc 0.6344 0.6400
epoch 400 LossPred 0.4061 LossAtt 0.4473 TrainAcc 0.8900 TestAcc 0.8161 0.8700
epoch 500 LossPred 0.5036 LossAtt 0.4088 TrainAcc 0.8400 TestAcc 0.7993 0.8500
epoch 600 LossPred 0.3518 LossAtt 0.4242 TrainAcc 0.9000 TestAcc 0.8201 0.8900
epoch 700 LossPred 0.3456 LossAtt 0.3974 TrainAcc 0.8900 TestAcc 0.8258 0.8700
epoch 800 LossPred 0.3460 LossAtt 0.3760 TrainAcc 0.8900 TestAcc 0.8273 0.8750
epoch 900 LossPred 0.3407 LossAtt 0.3858 TrainAcc 0.8900 TestAcc 0.8271 0.8700
epoch 1000 LossPred 0.3451 LossAtt 0.3941 TrainAcc 0.8800 TestAcc 0.8256 0.8800
epoch 1100 LossPred 0.4257 LossAtt 0.3471 TrainAcc 0.8900 TestAcc 0.8113 0.8700
epoch 1200 LossPred 0.6216 LossAtt 0.3461 TrainAcc 0.7900 TestAcc 0.7858 0.7550
epoch 1300 LossPred 0.5280 LossAtt 0.3453 TrainAcc 0.8300 TestAcc 0.8111 0.7800
epoch 1400 LossPred 0.4879 LossAtt 0.3510 TrainAcc 0.8600 TestAcc 0.8101 0.7950
epoch 1500 LossPred 0.4486 LossAtt 0.3567 TrainAcc 0.8400 TestAcc 0.7965 0.8700
epoch 1600 LossPred 0.7352 LossAtt 0.3447 TrainAcc 0.7500 TestAcc 0.7412 0.7900
epoch 1700 LossPred 0.7290 LossAtt 0.3247 TrainAcc 0.7400 TestAcc 0.7487 0.7550
epoch 1800 LossPred 0.4039 LossAtt 0.3239 TrainAcc 0.8800 TestAcc 0.8363 0.8850
epoch 1900 LossPred 0.3926 LossAtt 0.3256 TrainAcc 0.8800 TestAcc 0.8116 0.8800
epoch 2000 LossPred 0.7295 LossAtt 0.3381 TrainAcc 0.7700 TestAcc 0.7392 0.7900
epoch 2100 LossPred 0.6304 LossAtt 0.3112 TrainAcc 0.7800 TestAcc 0.7680 0.8150
epoch 2200 LossPred 0.8221 LossAtt 0.3141 TrainAcc 0.7400 TestAcc 0.6977 0.7400
epoch 2300 LossPred 0.8485 LossAtt 0.2530 TrainAcc 0.6700 TestAcc 0.6734 0.6450
epoch 2400 LossPred 0.8709 LossAtt 0.2548 TrainAcc 0.6500 TestAcc 0.6259 0.6500
epoch 2500 LossPred 0.8783 LossAtt 0.2181 TrainAcc 0.6900 TestAcc 0.6351 0.6500
Optimization Finished!
********** replication  14  **********
epoch   0 LossPred 1.0948 LossAtt 1.0205 TrainAcc 0.4900 TestAcc 0.4354 0.4850
epoch 100 LossPred 0.9925 LossAtt 0.3793 TrainAcc 0.5900 TestAcc 0.6286 0.5850
epoch 200 LossPred 0.9734 LossAtt 0.3730 TrainAcc 0.5900 TestAcc 0.5883 0.6000
epoch 300 LossPred 0.9465 LossAtt 0.3824 TrainAcc 0.6100 TestAcc 0.5538 0.6400
epoch 400 LossPred 0.9380 LossAtt 0.3774 TrainAcc 0.5800 TestAcc 0.5683 0.6300
epoch 500 LossPred 0.9192 LossAtt 0.4033 TrainAcc 0.6200 TestAcc 0.5516 0.6400
epoch 600 LossPred 0.9037 LossAtt 0.3762 TrainAcc 0.6400 TestAcc 0.5253 0.6500
epoch 700 LossPred 0.8943 LossAtt 0.3869 TrainAcc 0.6400 TestAcc 0.5233 0.6400
epoch 800 LossPred 0.8907 LossAtt 0.3439 TrainAcc 0.6400 TestAcc 0.5218 0.6400
epoch 900 LossPred 0.8915 LossAtt 0.4089 TrainAcc 0.6400 TestAcc 0.5358 0.6350
epoch 1000 LossPred 0.9030 LossAtt 0.4297 TrainAcc 0.6200 TestAcc 0.5546 0.6400
epoch 1100 LossPred 0.8890 LossAtt 0.4312 TrainAcc 0.6600 TestAcc 0.5566 0.6400
epoch 1200 LossPred 0.8839 LossAtt 0.3875 TrainAcc 0.6500 TestAcc 0.5551 0.6650
epoch 1300 LossPred 0.8851 LossAtt 0.3743 TrainAcc 0.6500 TestAcc 0.5323 0.6500
epoch 1400 LossPred 0.8806 LossAtt 0.3603 TrainAcc 0.6800 TestAcc 0.5398 0.6650
epoch 1500 LossPred 0.8678 LossAtt 0.3587 TrainAcc 0.6300 TestAcc 0.5616 0.6350
epoch 1600 LossPred 0.8646 LossAtt 0.3611 TrainAcc 0.6700 TestAcc 0.5621 0.6400
epoch 1700 LossPred 0.8718 LossAtt 0.3936 TrainAcc 0.6600 TestAcc 0.5633 0.6450
epoch 1800 LossPred 0.8673 LossAtt 0.3668 TrainAcc 0.6700 TestAcc 0.5628 0.6550
epoch 1900 LossPred 0.8656 LossAtt 0.3619 TrainAcc 0.6600 TestAcc 0.5621 0.6600
epoch 2000 LossPred 0.8663 LossAtt 0.3712 TrainAcc 0.6600 TestAcc 0.5518 0.6400
epoch 2100 LossPred 0.8770 LossAtt 0.3575 TrainAcc 0.6500 TestAcc 0.5523 0.6200
epoch 2200 LossPred 0.8687 LossAtt 0.4150 TrainAcc 0.6800 TestAcc 0.5485 0.6100
epoch 2300 LossPred 0.8432 LossAtt 0.4194 TrainAcc 0.6800 TestAcc 0.5350 0.6400
epoch 2400 LossPred 0.8265 LossAtt 0.4394 TrainAcc 0.6900 TestAcc 0.5453 0.6600
epoch 2500 LossPred 0.8293 LossAtt 0.4069 TrainAcc 0.6800 TestAcc 0.5450 0.6700
Optimization Finished!
********** replication  15  **********
epoch   0 LossPred 1.0389 LossAtt 1.0443 TrainAcc 0.4800 TestAcc 0.4905 0.4900
epoch 100 LossPred 0.9086 LossAtt 0.4362 TrainAcc 0.6000 TestAcc 0.5963 0.6000
epoch 200 LossPred 0.8867 LossAtt 0.3949 TrainAcc 0.6600 TestAcc 0.6339 0.6550
epoch 300 LossPred 0.8762 LossAtt 0.3570 TrainAcc 0.6600 TestAcc 0.6339 0.6600
epoch 400 LossPred 0.8733 LossAtt 0.3412 TrainAcc 0.6600 TestAcc 0.6339 0.6600
epoch 500 LossPred 0.8692 LossAtt 0.3281 TrainAcc 0.6600 TestAcc 0.5948 0.6700
epoch 600 LossPred 0.8602 LossAtt 0.3676 TrainAcc 0.6700 TestAcc 0.5803 0.6700
epoch 700 LossPred 0.8534 LossAtt 0.3707 TrainAcc 0.6600 TestAcc 0.5793 0.6650
epoch 800 LossPred 0.8427 LossAtt 0.4545 TrainAcc 0.6800 TestAcc 0.5978 0.6700
epoch 900 LossPred 0.8345 LossAtt 0.4380 TrainAcc 0.6400 TestAcc 0.5398 0.6500
epoch 1000 LossPred 0.7961 LossAtt 0.5207 TrainAcc 0.6900 TestAcc 0.6101 0.7000
epoch 1100 LossPred 0.6562 LossAtt 0.4630 TrainAcc 0.7900 TestAcc 0.7540 0.7900
epoch 1200 LossPred 0.3731 LossAtt 0.4411 TrainAcc 0.8800 TestAcc 0.8886 0.8600
epoch 1300 LossPred 0.3260 LossAtt 0.4892 TrainAcc 0.9000 TestAcc 0.8919 0.9000
epoch 1400 LossPred 0.4490 LossAtt 0.4263 TrainAcc 0.8400 TestAcc 0.8283 0.8350
epoch 1500 LossPred 0.3955 LossAtt 0.4064 TrainAcc 0.8600 TestAcc 0.8774 0.8550
epoch 1600 LossPred 0.6680 LossAtt 0.3921 TrainAcc 0.7700 TestAcc 0.8111 0.7750
epoch 1700 LossPred 0.4014 LossAtt 0.4101 TrainAcc 0.8600 TestAcc 0.8619 0.8700
epoch 1800 LossPred 0.2728 LossAtt 0.3859 TrainAcc 0.9400 TestAcc 0.8956 0.9250
epoch 1900 LossPred 0.4759 LossAtt 0.3698 TrainAcc 0.8500 TestAcc 0.8386 0.8350
epoch 2000 LossPred 0.4315 LossAtt 0.3535 TrainAcc 0.8600 TestAcc 0.8594 0.8400
epoch 2100 LossPred 0.3963 LossAtt 0.3740 TrainAcc 0.8500 TestAcc 0.8691 0.8400
epoch 2200 LossPred 0.4752 LossAtt 0.3807 TrainAcc 0.8300 TestAcc 0.8458 0.8350
epoch 2300 LossPred 0.3399 LossAtt 0.3779 TrainAcc 0.8900 TestAcc 0.8869 0.9000
epoch 2400 LossPred 0.3503 LossAtt 0.3876 TrainAcc 0.8900 TestAcc 0.8866 0.9050
epoch 2500 LossPred 0.3856 LossAtt 0.3415 TrainAcc 0.8700 TestAcc 0.8801 0.8700
Optimization Finished!
********** replication  16  **********
epoch   0 LossPred 1.0090 LossAtt 1.0037 TrainAcc 0.5500 TestAcc 0.4832 0.5550
epoch 100 LossPred 0.8956 LossAtt 0.4888 TrainAcc 0.6400 TestAcc 0.5503 0.6500
epoch 200 LossPred 0.8724 LossAtt 0.4217 TrainAcc 0.6400 TestAcc 0.5480 0.6400
epoch 300 LossPred 0.8702 LossAtt 0.4125 TrainAcc 0.6400 TestAcc 0.5480 0.6400
epoch 400 LossPred 0.8639 LossAtt 0.4122 TrainAcc 0.6500 TestAcc 0.5198 0.6500
epoch 500 LossPred 0.8604 LossAtt 0.4090 TrainAcc 0.6500 TestAcc 0.5198 0.6500
epoch 600 LossPred 0.8498 LossAtt 0.4685 TrainAcc 0.6500 TestAcc 0.5198 0.6500
epoch 700 LossPred 0.8178 LossAtt 0.5164 TrainAcc 0.6800 TestAcc 0.5270 0.7000
epoch 800 LossPred 0.7768 LossAtt 0.5472 TrainAcc 0.7100 TestAcc 0.5340 0.7200
epoch 900 LossPred 0.7312 LossAtt 0.5776 TrainAcc 0.7200 TestAcc 0.5313 0.7250
epoch 1000 LossPred 0.7113 LossAtt 0.5165 TrainAcc 0.7500 TestAcc 0.5425 0.7350
epoch 1100 LossPred 0.6928 LossAtt 0.5433 TrainAcc 0.7400 TestAcc 0.5418 0.7600
epoch 1200 LossPred 0.6792 LossAtt 0.5250 TrainAcc 0.7600 TestAcc 0.5340 0.7450
epoch 1300 LossPred 0.6827 LossAtt 0.5070 TrainAcc 0.7400 TestAcc 0.5255 0.7200
epoch 1400 LossPred 0.6645 LossAtt 0.5104 TrainAcc 0.7500 TestAcc 0.5243 0.7200
epoch 1500 LossPred 0.6411 LossAtt 0.4835 TrainAcc 0.7900 TestAcc 0.5280 0.7350
epoch 1600 LossPred 0.6497 LossAtt 0.4709 TrainAcc 0.7800 TestAcc 0.5325 0.7350
epoch 1700 LossPred 0.6177 LossAtt 0.4702 TrainAcc 0.8000 TestAcc 0.5358 0.7100
epoch 1800 LossPred 0.6378 LossAtt 0.4668 TrainAcc 0.7800 TestAcc 0.5273 0.7200
epoch 1900 LossPred 0.6057 LossAtt 0.4792 TrainAcc 0.8100 TestAcc 0.5238 0.7150
epoch 2000 LossPred 0.6062 LossAtt 0.4233 TrainAcc 0.8200 TestAcc 0.5100 0.7200
epoch 2100 LossPred 0.6117 LossAtt 0.4096 TrainAcc 0.7900 TestAcc 0.5278 0.7250
epoch 2200 LossPred 0.6080 LossAtt 0.3927 TrainAcc 0.7900 TestAcc 0.5280 0.7300
epoch 2300 LossPred 0.6071 LossAtt 0.4003 TrainAcc 0.8000 TestAcc 0.5178 0.7200
epoch 2400 LossPred 0.6120 LossAtt 0.4130 TrainAcc 0.7900 TestAcc 0.5215 0.7350
epoch 2500 LossPred 0.6399 LossAtt 0.4323 TrainAcc 0.7700 TestAcc 0.5203 0.7350
Optimization Finished!
********** replication  17  **********
epoch   0 LossPred 1.1888 LossAtt 1.0179 TrainAcc 0.5500 TestAcc 0.5453 0.5550
epoch 100 LossPred 0.9052 LossAtt 0.4143 TrainAcc 0.6600 TestAcc 0.5848 0.6600
epoch 200 LossPred 0.8522 LossAtt 0.3782 TrainAcc 0.6600 TestAcc 0.5848 0.6600
epoch 300 LossPred 0.8154 LossAtt 0.3481 TrainAcc 0.7200 TestAcc 0.6356 0.7200
epoch 400 LossPred 0.7973 LossAtt 0.3604 TrainAcc 0.7200 TestAcc 0.6356 0.7250
epoch 500 LossPred 0.7985 LossAtt 0.2588 TrainAcc 0.7000 TestAcc 0.6396 0.7050
epoch 600 LossPred 0.7925 LossAtt 0.2657 TrainAcc 0.7000 TestAcc 0.6396 0.7000
epoch 700 LossPred 0.7858 LossAtt 0.2676 TrainAcc 0.7000 TestAcc 0.6396 0.7000
epoch 800 LossPred 0.7666 LossAtt 0.3214 TrainAcc 0.7300 TestAcc 0.6476 0.7250
epoch 900 LossPred 0.4902 LossAtt 0.2795 TrainAcc 0.8400 TestAcc 0.8286 0.8550
epoch 1000 LossPred 1.6467 LossAtt 0.3005 TrainAcc 0.3800 TestAcc 0.4117 0.3800
epoch 1100 LossPred 0.7392 LossAtt 0.2971 TrainAcc 0.7300 TestAcc 0.6764 0.7150
epoch 1200 LossPred 0.5544 LossAtt 0.2707 TrainAcc 0.7700 TestAcc 0.7815 0.7750
epoch 1300 LossPred 0.5156 LossAtt 0.2858 TrainAcc 0.8300 TestAcc 0.8136 0.8150
epoch 1400 LossPred 0.4727 LossAtt 0.2826 TrainAcc 0.8200 TestAcc 0.8243 0.7950
epoch 1500 LossPred 0.4216 LossAtt 0.2809 TrainAcc 0.8300 TestAcc 0.8406 0.8200
epoch 1600 LossPred 0.3905 LossAtt 0.3117 TrainAcc 0.8600 TestAcc 0.8669 0.8600
epoch 1700 LossPred 0.3510 LossAtt 0.3421 TrainAcc 0.8800 TestAcc 0.8769 0.8800
epoch 1800 LossPred 0.3170 LossAtt 0.3479 TrainAcc 0.8800 TestAcc 0.8909 0.9000
epoch 1900 LossPred 0.3862 LossAtt 0.3604 TrainAcc 0.8500 TestAcc 0.8529 0.8650
epoch 2000 LossPred 0.4980 LossAtt 0.3951 TrainAcc 0.8200 TestAcc 0.8701 0.8350
epoch 2100 LossPred 0.3879 LossAtt 0.3028 TrainAcc 0.8500 TestAcc 0.8674 0.8200
epoch 2200 LossPred 1.0890 LossAtt 0.4376 TrainAcc 0.6200 TestAcc 0.5913 0.6200
epoch 2300 LossPred 0.7968 LossAtt 0.3243 TrainAcc 0.7300 TestAcc 0.6371 0.7250
epoch 2400 LossPred 0.2898 LossAtt 0.4044 TrainAcc 0.9100 TestAcc 0.8836 0.9200
epoch 2500 LossPred 0.2294 LossAtt 0.3679 TrainAcc 0.9500 TestAcc 0.9117 0.9400
Optimization Finished!
********** replication  18  **********
epoch   0 LossPred 1.1189 LossAtt 1.0146 TrainAcc 0.5500 TestAcc 0.4907 0.5050
epoch 100 LossPred 0.8844 LossAtt 0.4757 TrainAcc 0.6700 TestAcc 0.5513 0.6900
epoch 200 LossPred 0.8389 LossAtt 0.3467 TrainAcc 0.6600 TestAcc 0.5410 0.6600
epoch 300 LossPred 0.8272 LossAtt 0.3068 TrainAcc 0.6600 TestAcc 0.5410 0.6700
epoch 400 LossPred 0.8188 LossAtt 0.2551 TrainAcc 0.6600 TestAcc 0.5410 0.6700
epoch 500 LossPred 0.8163 LossAtt 0.2174 TrainAcc 0.7100 TestAcc 0.5843 0.6750
epoch 600 LossPred 0.8249 LossAtt 0.1990 TrainAcc 0.6600 TestAcc 0.5851 0.6800
epoch 700 LossPred 0.8393 LossAtt 0.2155 TrainAcc 0.6600 TestAcc 0.5851 0.6550
epoch 800 LossPred 0.8384 LossAtt 0.1973 TrainAcc 0.6600 TestAcc 0.5851 0.6600
epoch 900 LossPred 0.8356 LossAtt 0.1485 TrainAcc 0.6600 TestAcc 0.5851 0.6600
epoch 1000 LossPred 0.8328 LossAtt 0.1289 TrainAcc 0.6600 TestAcc 0.5851 0.6600
epoch 1100 LossPred 0.8318 LossAtt 0.1222 TrainAcc 0.6600 TestAcc 0.5851 0.6600
epoch 1200 LossPred 0.8282 LossAtt 0.1467 TrainAcc 0.6600 TestAcc 0.5851 0.6600
epoch 1300 LossPred 0.8242 LossAtt 0.2378 TrainAcc 0.6600 TestAcc 0.5851 0.6600
epoch 1400 LossPred 0.8159 LossAtt 0.2389 TrainAcc 0.6600 TestAcc 0.5851 0.6600
epoch 1500 LossPred 0.8063 LossAtt 0.1856 TrainAcc 0.6600 TestAcc 0.5851 0.6750
epoch 1600 LossPred 0.8035 LossAtt 0.1332 TrainAcc 0.6600 TestAcc 0.5410 0.6600
epoch 1700 LossPred 0.7974 LossAtt 0.1526 TrainAcc 0.6600 TestAcc 0.5410 0.6650
epoch 1800 LossPred 0.7902 LossAtt 0.2194 TrainAcc 0.6600 TestAcc 0.5410 0.6700
epoch 1900 LossPred 0.7892 LossAtt 0.1999 TrainAcc 0.6600 TestAcc 0.5410 0.6800
epoch 2000 LossPred 0.7892 LossAtt 0.2085 TrainAcc 0.6800 TestAcc 0.5495 0.6850
epoch 2100 LossPred 0.7858 LossAtt 0.2247 TrainAcc 0.6800 TestAcc 0.5526 0.6950
epoch 2200 LossPred 0.7734 LossAtt 0.2320 TrainAcc 0.6900 TestAcc 0.5616 0.6900
epoch 2300 LossPred 0.7744 LossAtt 0.2198 TrainAcc 0.6900 TestAcc 0.5641 0.7000
epoch 2400 LossPred 0.7702 LossAtt 0.2477 TrainAcc 0.6700 TestAcc 0.5803 0.7050
epoch 2500 LossPred 0.7600 LossAtt 0.2343 TrainAcc 0.7100 TestAcc 0.5921 0.6850
Optimization Finished!
********** replication  19  **********
epoch   0 LossPred 1.0418 LossAtt 0.9985 TrainAcc 0.4500 TestAcc 0.4797 0.4600
epoch 100 LossPred 0.8723 LossAtt 0.4464 TrainAcc 0.6200 TestAcc 0.5293 0.6200
epoch 200 LossPred 0.5888 LossAtt 0.5613 TrainAcc 0.8400 TestAcc 0.7272 0.8350
epoch 300 LossPred 0.4051 LossAtt 0.5839 TrainAcc 0.8600 TestAcc 0.8463 0.8650
epoch 400 LossPred 0.3816 LossAtt 0.5720 TrainAcc 0.8700 TestAcc 0.8028 0.8700
epoch 500 LossPred 0.2687 LossAtt 0.5723 TrainAcc 0.9200 TestAcc 0.8313 0.9350
epoch 600 LossPred 0.1932 LossAtt 0.5032 TrainAcc 0.9400 TestAcc 0.8741 0.9550
epoch 700 LossPred 0.2109 LossAtt 0.4699 TrainAcc 0.9300 TestAcc 0.8413 0.9350
epoch 800 LossPred 0.6982 LossAtt 0.4585 TrainAcc 0.7700 TestAcc 0.7733 0.7550
epoch 900 LossPred 0.2208 LossAtt 0.4543 TrainAcc 0.9300 TestAcc 0.8576 0.9350
epoch 1000 LossPred 0.3168 LossAtt 0.4404 TrainAcc 0.9100 TestAcc 0.8081 0.9000
epoch 1100 LossPred 0.2478 LossAtt 0.4489 TrainAcc 0.9400 TestAcc 0.8331 0.9400
epoch 1200 LossPred 0.1752 LossAtt 0.4147 TrainAcc 0.9600 TestAcc 0.8393 0.9550
epoch 1300 LossPred 0.2290 LossAtt 0.4187 TrainAcc 0.9500 TestAcc 0.8303 0.9450
epoch 1400 LossPred 0.1991 LossAtt 0.4202 TrainAcc 0.9500 TestAcc 0.8256 0.9650
epoch 1500 LossPred 0.2806 LossAtt 0.4020 TrainAcc 0.9200 TestAcc 0.8023 0.9300
epoch 1600 LossPred 0.1589 LossAtt 0.3963 TrainAcc 0.9700 TestAcc 0.8393 0.9700
epoch 1700 LossPred 0.2668 LossAtt 0.3814 TrainAcc 0.9400 TestAcc 0.8328 0.9150
epoch 1800 LossPred 0.1619 LossAtt 0.3905 TrainAcc 0.9500 TestAcc 0.8328 0.9550
epoch 1900 LossPred 0.2163 LossAtt 0.3659 TrainAcc 0.9400 TestAcc 0.8238 0.9450
epoch 2000 LossPred 0.1410 LossAtt 0.3588 TrainAcc 0.9700 TestAcc 0.8514 0.9700
epoch 2100 LossPred 0.1374 LossAtt 0.3734 TrainAcc 0.9700 TestAcc 0.8471 0.9600
epoch 2200 LossPred 0.1440 LossAtt 0.3732 TrainAcc 0.9700 TestAcc 0.8511 0.9700
epoch 2300 LossPred 0.1279 LossAtt 0.3594 TrainAcc 0.9700 TestAcc 0.8521 0.9700
epoch 2400 LossPred 0.1202 LossAtt 0.3541 TrainAcc 0.9700 TestAcc 0.8629 0.9650
epoch 2500 LossPred 0.2233 LossAtt 0.3761 TrainAcc 0.9300 TestAcc 0.8193 0.9450
Optimization Finished!
********** replication  20  **********
epoch   0 LossPred 1.1643 LossAtt 1.0082 TrainAcc 0.5000 TestAcc 0.5008 0.5100
epoch 100 LossPred 0.9520 LossAtt 0.4867 TrainAcc 0.6300 TestAcc 0.6461 0.6350
epoch 200 LossPred 0.8291 LossAtt 0.4153 TrainAcc 0.6800 TestAcc 0.6684 0.6750
epoch 300 LossPred 0.5732 LossAtt 0.3674 TrainAcc 0.8100 TestAcc 0.7843 0.7900
epoch 400 LossPred 0.6356 LossAtt 0.3503 TrainAcc 0.7400 TestAcc 0.7733 0.7700
epoch 500 LossPred 0.5558 LossAtt 0.3417 TrainAcc 0.8200 TestAcc 0.7415 0.8400
epoch 600 LossPred 0.6550 LossAtt 0.3518 TrainAcc 0.7400 TestAcc 0.7710 0.7500
epoch 700 LossPred 0.8459 LossAtt 0.3543 TrainAcc 0.6700 TestAcc 0.7265 0.6850
epoch 800 LossPred 0.6362 LossAtt 0.3272 TrainAcc 0.7500 TestAcc 0.7748 0.7700
epoch 900 LossPred 0.4858 LossAtt 0.3135 TrainAcc 0.8300 TestAcc 0.8141 0.8650
epoch 1000 LossPred 0.5351 LossAtt 0.2814 TrainAcc 0.8300 TestAcc 0.7337 0.8300
epoch 1100 LossPred 0.4138 LossAtt 0.3038 TrainAcc 0.8900 TestAcc 0.8313 0.8850
epoch 1200 LossPred 0.4009 LossAtt 0.2967 TrainAcc 0.8900 TestAcc 0.8343 0.8900
epoch 1300 LossPred 0.3971 LossAtt 0.2880 TrainAcc 0.8700 TestAcc 0.8011 0.8900
epoch 1400 LossPred 0.3983 LossAtt 0.2888 TrainAcc 0.8900 TestAcc 0.8311 0.8850
epoch 1500 LossPred 0.3970 LossAtt 0.2669 TrainAcc 0.8600 TestAcc 0.7933 0.8750
epoch 1600 LossPred 0.3990 LossAtt 0.2846 TrainAcc 0.8700 TestAcc 0.8038 0.8900
epoch 1700 LossPred 0.3924 LossAtt 0.2839 TrainAcc 0.8700 TestAcc 0.8056 0.8650
epoch 1800 LossPred 0.3797 LossAtt 0.2792 TrainAcc 0.8800 TestAcc 0.7905 0.8750
epoch 1900 LossPred 0.3780 LossAtt 0.2723 TrainAcc 0.8700 TestAcc 0.7953 0.8850
epoch 2000 LossPred 0.3920 LossAtt 0.2875 TrainAcc 0.8900 TestAcc 0.8171 0.9000
epoch 2100 LossPred 0.3906 LossAtt 0.2683 TrainAcc 0.8600 TestAcc 0.7965 0.8750
epoch 2200 LossPred 0.3872 LossAtt 0.2755 TrainAcc 0.8900 TestAcc 0.8083 0.9000
epoch 2300 LossPred 0.3880 LossAtt 0.2533 TrainAcc 0.8600 TestAcc 0.7983 0.8750
epoch 2400 LossPred 0.3891 LossAtt 0.2649 TrainAcc 0.8700 TestAcc 0.8066 0.8800
epoch 2500 LossPred 0.3759 LossAtt 0.2667 TrainAcc 0.8900 TestAcc 0.7885 0.8550
Optimization Finished!
********** replication  21  **********
epoch   0 LossPred 0.9566 LossAtt 0.9911 TrainAcc 0.6000 TestAcc 0.4580 0.6050
epoch 100 LossPred 0.8938 LossAtt 0.4775 TrainAcc 0.6200 TestAcc 0.5876 0.6250
epoch 200 LossPred 0.8612 LossAtt 0.4428 TrainAcc 0.6600 TestAcc 0.5350 0.6600
epoch 300 LossPred 0.8354 LossAtt 0.4249 TrainAcc 0.6600 TestAcc 0.5563 0.6450
epoch 400 LossPred 0.4538 LossAtt 0.4175 TrainAcc 0.8600 TestAcc 0.8373 0.8500
epoch 500 LossPred 0.3557 LossAtt 0.3467 TrainAcc 0.8700 TestAcc 0.8051 0.8850
epoch 600 LossPred 0.3359 LossAtt 0.3636 TrainAcc 0.8900 TestAcc 0.8318 0.8800
epoch 700 LossPred 0.2911 LossAtt 0.3634 TrainAcc 0.9100 TestAcc 0.8266 0.8850
epoch 800 LossPred 0.3359 LossAtt 0.3465 TrainAcc 0.8800 TestAcc 0.8283 0.8700
epoch 900 LossPred 0.3002 LossAtt 0.3485 TrainAcc 0.9000 TestAcc 0.8313 0.8800
epoch 1000 LossPred 0.2882 LossAtt 0.3666 TrainAcc 0.9000 TestAcc 0.8163 0.8850
epoch 1100 LossPred 0.4449 LossAtt 0.3547 TrainAcc 0.8500 TestAcc 0.7678 0.8300
epoch 1200 LossPred 0.3687 LossAtt 0.3574 TrainAcc 0.8800 TestAcc 0.8213 0.8700
epoch 1300 LossPred 0.3603 LossAtt 0.3572 TrainAcc 0.8800 TestAcc 0.8589 0.8600
epoch 1400 LossPred 0.3825 LossAtt 0.3487 TrainAcc 0.8800 TestAcc 0.8403 0.8650
epoch 1500 LossPred 0.3820 LossAtt 0.3461 TrainAcc 0.8700 TestAcc 0.8296 0.8700
epoch 1600 LossPred 0.3592 LossAtt 0.3363 TrainAcc 0.8800 TestAcc 0.8353 0.8700
epoch 1700 LossPred 0.3527 LossAtt 0.3547 TrainAcc 0.8800 TestAcc 0.8276 0.8700
epoch 1800 LossPred 0.3801 LossAtt 0.3225 TrainAcc 0.8600 TestAcc 0.8023 0.8500
epoch 1900 LossPred 0.3424 LossAtt 0.3390 TrainAcc 0.8800 TestAcc 0.7995 0.8500
epoch 2000 LossPred 0.3713 LossAtt 0.3333 TrainAcc 0.8700 TestAcc 0.8046 0.8400
epoch 2100 LossPred 0.3671 LossAtt 0.3264 TrainAcc 0.8700 TestAcc 0.8001 0.8500
epoch 2200 LossPred 0.3392 LossAtt 0.3148 TrainAcc 0.8900 TestAcc 0.8106 0.8550
epoch 2300 LossPred 0.4056 LossAtt 0.3374 TrainAcc 0.8500 TestAcc 0.8171 0.8550
epoch 2400 LossPred 0.3323 LossAtt 0.3115 TrainAcc 0.8900 TestAcc 0.8023 0.8350
epoch 2500 LossPred 0.3278 LossAtt 0.3281 TrainAcc 0.8900 TestAcc 0.8041 0.8500
Optimization Finished!
********** replication  22  **********
epoch   0 LossPred 1.4281 LossAtt 1.0225 TrainAcc 0.4200 TestAcc 0.4124 0.4200
epoch 100 LossPred 0.9873 LossAtt 0.3595 TrainAcc 0.5600 TestAcc 0.5956 0.5600
epoch 200 LossPred 0.9584 LossAtt 0.2347 TrainAcc 0.5800 TestAcc 0.5886 0.5800
epoch 300 LossPred 0.9574 LossAtt 0.1899 TrainAcc 0.5800 TestAcc 0.5886 0.5800
epoch 400 LossPred 0.9552 LossAtt 0.1832 TrainAcc 0.5800 TestAcc 0.5886 0.5800
epoch 500 LossPred 0.9528 LossAtt 0.1930 TrainAcc 0.5800 TestAcc 0.5886 0.5800
epoch 600 LossPred 0.9494 LossAtt 0.2094 TrainAcc 0.5800 TestAcc 0.5886 0.5800
epoch 700 LossPred 0.9433 LossAtt 0.2326 TrainAcc 0.5800 TestAcc 0.6304 0.5800
epoch 800 LossPred 1.0030 LossAtt 0.3168 TrainAcc 0.5200 TestAcc 0.5488 0.5150
epoch 900 LossPred 0.8698 LossAtt 0.3493 TrainAcc 0.6500 TestAcc 0.6997 0.6500
epoch 1000 LossPred 0.4750 LossAtt 0.3105 TrainAcc 0.8900 TestAcc 0.8596 0.8300
epoch 1100 LossPred 0.7059 LossAtt 0.3014 TrainAcc 0.7000 TestAcc 0.7540 0.7000
epoch 1200 LossPred 0.3353 LossAtt 0.2872 TrainAcc 0.9000 TestAcc 0.8651 0.8600
epoch 1300 LossPred 0.3137 LossAtt 0.2709 TrainAcc 0.9100 TestAcc 0.8764 0.8550
epoch 1400 LossPred 0.3000 LossAtt 0.2808 TrainAcc 0.9200 TestAcc 0.8809 0.8650
epoch 1500 LossPred 0.3619 LossAtt 0.2762 TrainAcc 0.8800 TestAcc 0.8526 0.8250
epoch 1600 LossPred 0.2922 LossAtt 0.2818 TrainAcc 0.9200 TestAcc 0.8844 0.8600
epoch 1700 LossPred 0.2883 LossAtt 0.2713 TrainAcc 0.9200 TestAcc 0.8844 0.8550
epoch 1800 LossPred 0.2813 LossAtt 0.2716 TrainAcc 0.9300 TestAcc 0.8879 0.8650
epoch 1900 LossPred 0.3024 LossAtt 0.2842 TrainAcc 0.9000 TestAcc 0.8871 0.8500
epoch 2000 LossPred 0.3154 LossAtt 0.2901 TrainAcc 0.8900 TestAcc 0.8641 0.8800
epoch 2100 LossPred 0.5043 LossAtt 0.3054 TrainAcc 0.8200 TestAcc 0.8416 0.8000
epoch 2200 LossPred 0.4167 LossAtt 0.2845 TrainAcc 0.8800 TestAcc 0.8258 0.8200
epoch 2300 LossPred 0.2738 LossAtt 0.2706 TrainAcc 0.9200 TestAcc 0.8936 0.8800
epoch 2400 LossPred 0.2895 LossAtt 0.2869 TrainAcc 0.9100 TestAcc 0.8999 0.8500
epoch 2500 LossPred 0.2639 LossAtt 0.2788 TrainAcc 0.9300 TestAcc 0.9049 0.8750
Optimization Finished!
********** replication  23  **********
epoch   0 LossPred 1.2871 LossAtt 1.0009 TrainAcc 0.4000 TestAcc 0.4264 0.4350
epoch 100 LossPred 1.0009 LossAtt 0.4567 TrainAcc 0.4200 TestAcc 0.4792 0.4300
epoch 200 LossPred 0.9333 LossAtt 0.3708 TrainAcc 0.6300 TestAcc 0.6221 0.6300
epoch 300 LossPred 0.8920 LossAtt 0.3622 TrainAcc 0.6400 TestAcc 0.6296 0.6400
epoch 400 LossPred 0.8527 LossAtt 0.4039 TrainAcc 0.6500 TestAcc 0.6081 0.6500
epoch 500 LossPred 0.8330 LossAtt 0.3912 TrainAcc 0.6500 TestAcc 0.6081 0.6500
epoch 600 LossPred 0.8330 LossAtt 0.3649 TrainAcc 0.6400 TestAcc 0.6296 0.6550
epoch 700 LossPred 0.8081 LossAtt 0.3612 TrainAcc 0.6400 TestAcc 0.6296 0.6650
epoch 800 LossPred 0.7863 LossAtt 0.4472 TrainAcc 0.6800 TestAcc 0.6559 0.6700
epoch 900 LossPred 0.5834 LossAtt 0.5604 TrainAcc 0.7600 TestAcc 0.7810 0.7800
epoch 1000 LossPred 0.6563 LossAtt 0.4914 TrainAcc 0.7500 TestAcc 0.7390 0.7500
epoch 1100 LossPred 0.4515 LossAtt 0.4486 TrainAcc 0.8700 TestAcc 0.8138 0.8600
epoch 1200 LossPred 0.4988 LossAtt 0.4758 TrainAcc 0.8700 TestAcc 0.7903 0.8750
epoch 1300 LossPred 0.4548 LossAtt 0.4438 TrainAcc 0.8600 TestAcc 0.8143 0.8650
epoch 1400 LossPred 0.4014 LossAtt 0.4379 TrainAcc 0.8900 TestAcc 0.8078 0.8700
epoch 1500 LossPred 0.3845 LossAtt 0.4240 TrainAcc 0.9000 TestAcc 0.8243 0.8950
epoch 1600 LossPred 0.4223 LossAtt 0.4079 TrainAcc 0.8500 TestAcc 0.8186 0.8400
epoch 1700 LossPred 0.3727 LossAtt 0.4338 TrainAcc 0.8900 TestAcc 0.8403 0.8900
epoch 1800 LossPred 0.3555 LossAtt 0.4085 TrainAcc 0.9000 TestAcc 0.8306 0.9100
epoch 1900 LossPred 0.3080 LossAtt 0.3991 TrainAcc 0.9200 TestAcc 0.8301 0.8950
epoch 2000 LossPred 0.3162 LossAtt 0.4088 TrainAcc 0.8700 TestAcc 0.8358 0.8800
epoch 2100 LossPred 0.2790 LossAtt 0.3997 TrainAcc 0.9300 TestAcc 0.8333 0.9000
epoch 2200 LossPred 1.1103 LossAtt 0.3258 TrainAcc 0.6000 TestAcc 0.5821 0.6000
epoch 2300 LossPred 0.9184 LossAtt 0.3395 TrainAcc 0.6600 TestAcc 0.6662 0.6600
epoch 2400 LossPred 0.7256 LossAtt 0.4092 TrainAcc 0.7200 TestAcc 0.7120 0.7250
epoch 2500 LossPred 0.3770 LossAtt 0.4051 TrainAcc 0.9200 TestAcc 0.8021 0.8950
Optimization Finished!
********** replication  24  **********
epoch   0 LossPred 0.8830 LossAtt 1.0212 TrainAcc 0.6900 TestAcc 0.5786 0.6700
epoch 100 LossPred 0.8248 LossAtt 0.2557 TrainAcc 0.7100 TestAcc 0.5893 0.7100
epoch 200 LossPred 0.8185 LossAtt 0.2236 TrainAcc 0.7100 TestAcc 0.5893 0.7100
epoch 300 LossPred 0.6618 LossAtt 0.4764 TrainAcc 0.7200 TestAcc 0.6039 0.7200
epoch 400 LossPred 0.4555 LossAtt 0.5113 TrainAcc 0.8800 TestAcc 0.8058 0.8700
epoch 500 LossPred 0.4110 LossAtt 0.4968 TrainAcc 0.8700 TestAcc 0.8411 0.8600
epoch 600 LossPred 0.2901 LossAtt 0.4792 TrainAcc 0.9200 TestAcc 0.8521 0.9250
epoch 700 LossPred 0.2786 LossAtt 0.4417 TrainAcc 0.9200 TestAcc 0.8521 0.9200
epoch 800 LossPred 0.2776 LossAtt 0.4140 TrainAcc 0.9200 TestAcc 0.8519 0.9150
epoch 900 LossPred 0.2641 LossAtt 0.4164 TrainAcc 0.9100 TestAcc 0.8524 0.9200
epoch 1000 LossPred 0.3682 LossAtt 0.4334 TrainAcc 0.8800 TestAcc 0.8296 0.8800
epoch 1100 LossPred 0.2939 LossAtt 0.4118 TrainAcc 0.9000 TestAcc 0.8448 0.9050
epoch 1200 LossPred 0.3106 LossAtt 0.4279 TrainAcc 0.8900 TestAcc 0.8539 0.9000
epoch 1300 LossPred 0.2861 LossAtt 0.4129 TrainAcc 0.9000 TestAcc 0.8498 0.9050
epoch 1400 LossPred 0.2940 LossAtt 0.4077 TrainAcc 0.9100 TestAcc 0.8451 0.9150
epoch 1500 LossPred 0.2794 LossAtt 0.4149 TrainAcc 0.8900 TestAcc 0.8541 0.9000
epoch 1600 LossPred 0.3212 LossAtt 0.3984 TrainAcc 0.9000 TestAcc 0.8336 0.9050
epoch 1700 LossPred 0.2609 LossAtt 0.4147 TrainAcc 0.9300 TestAcc 0.8591 0.9050
epoch 1800 LossPred 0.3268 LossAtt 0.3934 TrainAcc 0.9000 TestAcc 0.8361 0.9000
epoch 1900 LossPred 0.3218 LossAtt 0.3824 TrainAcc 0.9100 TestAcc 0.8423 0.9000
epoch 2000 LossPred 0.3406 LossAtt 0.3775 TrainAcc 0.9000 TestAcc 0.8283 0.9050
epoch 2100 LossPred 0.3083 LossAtt 0.3807 TrainAcc 0.9300 TestAcc 0.8316 0.9150
epoch 2200 LossPred 0.3362 LossAtt 0.3784 TrainAcc 0.9100 TestAcc 0.8303 0.9100
epoch 2300 LossPred 0.3154 LossAtt 0.3602 TrainAcc 0.9000 TestAcc 0.8426 0.9050
epoch 2400 LossPred 0.3233 LossAtt 0.3618 TrainAcc 0.9000 TestAcc 0.8451 0.9000
epoch 2500 LossPred 0.3948 LossAtt 0.3649 TrainAcc 0.8600 TestAcc 0.8458 0.8700
Optimization Finished!
********** replication  25  **********
epoch   0 LossPred 1.2006 LossAtt 1.0288 TrainAcc 0.4600 TestAcc 0.4665 0.4500
epoch 100 LossPred 0.9690 LossAtt 0.3938 TrainAcc 0.5800 TestAcc 0.5228 0.5900
epoch 200 LossPred 0.8906 LossAtt 0.4529 TrainAcc 0.6400 TestAcc 0.5776 0.6800
epoch 300 LossPred 0.8633 LossAtt 0.3929 TrainAcc 0.6700 TestAcc 0.6271 0.6550
epoch 400 LossPred 0.7708 LossAtt 0.4962 TrainAcc 0.6900 TestAcc 0.6782 0.6900
epoch 500 LossPred 0.4917 LossAtt 0.4380 TrainAcc 0.8500 TestAcc 0.8313 0.8350
epoch 600 LossPred 0.4346 LossAtt 0.4300 TrainAcc 0.8900 TestAcc 0.8336 0.8500
epoch 700 LossPred 0.4510 LossAtt 0.4483 TrainAcc 0.8400 TestAcc 0.8436 0.8450
epoch 800 LossPred 0.4231 LossAtt 0.4597 TrainAcc 0.8700 TestAcc 0.8411 0.8600
epoch 900 LossPred 0.5767 LossAtt 0.4210 TrainAcc 0.8000 TestAcc 0.8181 0.7900
epoch 1000 LossPred 0.4736 LossAtt 0.4425 TrainAcc 0.8400 TestAcc 0.8378 0.8100
epoch 1100 LossPred 0.4758 LossAtt 0.3868 TrainAcc 0.8300 TestAcc 0.8111 0.8100
epoch 1200 LossPred 0.4270 LossAtt 0.3478 TrainAcc 0.8500 TestAcc 0.8233 0.8250
epoch 1300 LossPred 0.4097 LossAtt 0.3223 TrainAcc 0.8800 TestAcc 0.8216 0.8250
epoch 1400 LossPred 0.5274 LossAtt 0.3208 TrainAcc 0.8100 TestAcc 0.8021 0.8300
epoch 1500 LossPred 0.4517 LossAtt 0.3023 TrainAcc 0.8800 TestAcc 0.8348 0.8350
epoch 1600 LossPred 0.4365 LossAtt 0.2946 TrainAcc 0.8500 TestAcc 0.8346 0.8050
epoch 1700 LossPred 0.5296 LossAtt 0.2918 TrainAcc 0.8000 TestAcc 0.8063 0.8200
epoch 1800 LossPred 0.4546 LossAtt 0.3045 TrainAcc 0.8600 TestAcc 0.8341 0.8250
epoch 1900 LossPred 0.4431 LossAtt 0.2955 TrainAcc 0.8500 TestAcc 0.8273 0.8350
epoch 2000 LossPred 0.4309 LossAtt 0.2771 TrainAcc 0.8600 TestAcc 0.8278 0.8350
epoch 2100 LossPred 0.4331 LossAtt 0.2625 TrainAcc 0.8800 TestAcc 0.8421 0.8250
epoch 2200 LossPred 0.4131 LossAtt 0.2774 TrainAcc 0.8700 TestAcc 0.8373 0.8300
epoch 2300 LossPred 0.3711 LossAtt 0.2582 TrainAcc 0.8700 TestAcc 0.8348 0.8250
epoch 2400 LossPred 0.4848 LossAtt 0.2536 TrainAcc 0.8500 TestAcc 0.8283 0.8350
epoch 2500 LossPred 0.4234 LossAtt 0.2683 TrainAcc 0.8700 TestAcc 0.8411 0.8400
Optimization Finished!
********** replication  26  **********
epoch   0 LossPred 1.0036 LossAtt 0.9877 TrainAcc 0.5300 TestAcc 0.5288 0.4900
epoch 100 LossPred 0.9626 LossAtt 0.3004 TrainAcc 0.5800 TestAcc 0.6004 0.5800
epoch 200 LossPred 0.9611 LossAtt 0.2454 TrainAcc 0.5800 TestAcc 0.6004 0.5800
epoch 300 LossPred 0.9604 LossAtt 0.1972 TrainAcc 0.5800 TestAcc 0.6004 0.5800
epoch 400 LossPred 0.9599 LossAtt 0.1861 TrainAcc 0.5800 TestAcc 0.6004 0.5800
epoch 500 LossPred 0.9480 LossAtt 0.3459 TrainAcc 0.6400 TestAcc 0.6311 0.6300
epoch 600 LossPred 0.3762 LossAtt 0.4194 TrainAcc 0.9000 TestAcc 0.8253 0.8700
epoch 700 LossPred 0.2357 LossAtt 0.3981 TrainAcc 0.9300 TestAcc 0.8979 0.9100
epoch 800 LossPred 0.2389 LossAtt 0.3697 TrainAcc 0.9300 TestAcc 0.8941 0.8900
epoch 900 LossPred 0.2503 LossAtt 0.3854 TrainAcc 0.9200 TestAcc 0.8921 0.9050
epoch 1000 LossPred 0.2308 LossAtt 0.3767 TrainAcc 0.9400 TestAcc 0.8976 0.9150
epoch 1100 LossPred 0.1980 LossAtt 0.3767 TrainAcc 0.9300 TestAcc 0.8971 0.9050
epoch 1200 LossPred 0.2953 LossAtt 0.3919 TrainAcc 0.9000 TestAcc 0.8949 0.8850
epoch 1300 LossPred 0.2027 LossAtt 0.3837 TrainAcc 0.9200 TestAcc 0.8979 0.9150
epoch 1400 LossPred 0.2023 LossAtt 0.3869 TrainAcc 0.9200 TestAcc 0.9017 0.9050
epoch 1500 LossPred 0.1900 LossAtt 0.3788 TrainAcc 0.9500 TestAcc 0.9184 0.9150
epoch 1600 LossPred 0.2148 LossAtt 0.3617 TrainAcc 0.9400 TestAcc 0.9084 0.9250
epoch 1700 LossPred 0.2038 LossAtt 0.3880 TrainAcc 0.9400 TestAcc 0.9272 0.8950
epoch 1800 LossPred 0.2308 LossAtt 0.3804 TrainAcc 0.9200 TestAcc 0.8911 0.9050
epoch 1900 LossPred 0.3153 LossAtt 0.3686 TrainAcc 0.8900 TestAcc 0.9092 0.8800
epoch 2000 LossPred 0.2237 LossAtt 0.3858 TrainAcc 0.9200 TestAcc 0.9279 0.8950
epoch 2100 LossPred 0.3156 LossAtt 0.3783 TrainAcc 0.8900 TestAcc 0.8216 0.8850
epoch 2200 LossPred 0.1619 LossAtt 0.3870 TrainAcc 0.9300 TestAcc 0.9124 0.9350
epoch 2300 LossPred 0.2765 LossAtt 0.3634 TrainAcc 0.9100 TestAcc 0.9087 0.9000
epoch 2400 LossPred 0.1631 LossAtt 0.3811 TrainAcc 0.9300 TestAcc 0.8976 0.9050
epoch 2500 LossPred 0.1295 LossAtt 0.3743 TrainAcc 0.9500 TestAcc 0.9052 0.9350
Optimization Finished!
********** replication  27  **********
epoch   0 LossPred 0.9974 LossAtt 1.0554 TrainAcc 0.5900 TestAcc 0.5976 0.6050
epoch 100 LossPred 0.9489 LossAtt 0.4657 TrainAcc 0.6000 TestAcc 0.5928 0.5900
epoch 200 LossPred 0.9348 LossAtt 0.4645 TrainAcc 0.6000 TestAcc 0.6216 0.6250
epoch 300 LossPred 0.9205 LossAtt 0.4563 TrainAcc 0.6400 TestAcc 0.6319 0.6150
epoch 400 LossPred 0.8856 LossAtt 0.4111 TrainAcc 0.6200 TestAcc 0.6296 0.6350
epoch 500 LossPred 0.8340 LossAtt 0.4940 TrainAcc 0.6700 TestAcc 0.6692 0.6350
epoch 600 LossPred 0.7803 LossAtt 0.4595 TrainAcc 0.7100 TestAcc 0.7132 0.7050
epoch 700 LossPred 0.4372 LossAtt 0.3714 TrainAcc 0.8900 TestAcc 0.8616 0.8500
epoch 800 LossPred 0.4605 LossAtt 0.3670 TrainAcc 0.8500 TestAcc 0.8326 0.8350
epoch 900 LossPred 0.6079 LossAtt 0.3505 TrainAcc 0.8100 TestAcc 0.8203 0.8000
epoch 1000 LossPred 0.5955 LossAtt 0.3598 TrainAcc 0.8000 TestAcc 0.8253 0.8000
epoch 1100 LossPred 0.5380 LossAtt 0.3551 TrainAcc 0.8100 TestAcc 0.7943 0.8150
epoch 1200 LossPred 0.4649 LossAtt 0.3486 TrainAcc 0.8500 TestAcc 0.8061 0.8400
epoch 1300 LossPred 0.3642 LossAtt 0.3208 TrainAcc 0.8900 TestAcc 0.8581 0.9000
epoch 1400 LossPred 0.4958 LossAtt 0.3042 TrainAcc 0.8100 TestAcc 0.8426 0.8250
epoch 1500 LossPred 0.3962 LossAtt 0.3128 TrainAcc 0.8700 TestAcc 0.8373 0.8550
epoch 1600 LossPred 0.3842 LossAtt 0.2934 TrainAcc 0.8800 TestAcc 0.8521 0.8750
epoch 1700 LossPred 0.3332 LossAtt 0.2961 TrainAcc 0.8900 TestAcc 0.8569 0.8800
epoch 1800 LossPred 0.5385 LossAtt 0.2892 TrainAcc 0.8100 TestAcc 0.8296 0.8150
epoch 1900 LossPred 0.6248 LossAtt 0.2804 TrainAcc 0.7600 TestAcc 0.8061 0.7750
epoch 2000 LossPred 0.3577 LossAtt 0.2867 TrainAcc 0.8800 TestAcc 0.8696 0.8950
epoch 2100 LossPred 0.4048 LossAtt 0.2743 TrainAcc 0.8900 TestAcc 0.8048 0.8450
epoch 2200 LossPred 0.2992 LossAtt 0.2875 TrainAcc 0.9200 TestAcc 0.8689 0.8900
epoch 2300 LossPred 0.3397 LossAtt 0.2876 TrainAcc 0.9000 TestAcc 0.8413 0.8950
epoch 2400 LossPred 0.3052 LossAtt 0.2835 TrainAcc 0.9000 TestAcc 0.8579 0.8950
epoch 2500 LossPred 0.2932 LossAtt 0.2838 TrainAcc 0.9000 TestAcc 0.8646 0.9000
Optimization Finished!
********** replication  28  **********
epoch   0 LossPred 1.2666 LossAtt 0.9948 TrainAcc 0.5500 TestAcc 0.5513 0.5550
epoch 100 LossPred 0.9925 LossAtt 0.5443 TrainAcc 0.5700 TestAcc 0.5976 0.5700
epoch 200 LossPred 0.9000 LossAtt 0.5009 TrainAcc 0.6700 TestAcc 0.5901 0.6700
epoch 300 LossPred 0.8803 LossAtt 0.5083 TrainAcc 0.6700 TestAcc 0.5901 0.6700
epoch 400 LossPred 0.8748 LossAtt 0.4223 TrainAcc 0.6700 TestAcc 0.5901 0.6700
epoch 500 LossPred 0.8724 LossAtt 0.4080 TrainAcc 0.6700 TestAcc 0.5901 0.6700
epoch 600 LossPred 0.8677 LossAtt 0.3247 TrainAcc 0.6700 TestAcc 0.5786 0.6700
epoch 700 LossPred 0.8566 LossAtt 0.3002 TrainAcc 0.6600 TestAcc 0.6419 0.6600
epoch 800 LossPred 0.8327 LossAtt 0.4307 TrainAcc 0.6900 TestAcc 0.6607 0.6750
epoch 900 LossPred 0.7855 LossAtt 0.4817 TrainAcc 0.7000 TestAcc 0.6839 0.7000
epoch 1000 LossPred 0.6837 LossAtt 0.4743 TrainAcc 0.7300 TestAcc 0.7568 0.7200
epoch 1100 LossPred 0.4494 LossAtt 0.4749 TrainAcc 0.8900 TestAcc 0.8679 0.8650
epoch 1200 LossPred 0.7713 LossAtt 0.4052 TrainAcc 0.7200 TestAcc 0.6999 0.6850
epoch 1300 LossPred 0.7875 LossAtt 0.3726 TrainAcc 0.7000 TestAcc 0.7222 0.7150
epoch 1400 LossPred 0.7250 LossAtt 0.3527 TrainAcc 0.7400 TestAcc 0.7492 0.7450
epoch 1500 LossPred 0.7238 LossAtt 0.3228 TrainAcc 0.7600 TestAcc 0.7417 0.7300
epoch 1600 LossPred 0.5401 LossAtt 0.3335 TrainAcc 0.8200 TestAcc 0.8053 0.8050
epoch 1700 LossPred 0.3821 LossAtt 0.3069 TrainAcc 0.8600 TestAcc 0.8736 0.8500
epoch 1800 LossPred 0.6597 LossAtt 0.3166 TrainAcc 0.7800 TestAcc 0.7693 0.7400
epoch 1900 LossPred 0.3777 LossAtt 0.2811 TrainAcc 0.8800 TestAcc 0.8766 0.8600
epoch 2000 LossPred 0.4490 LossAtt 0.2891 TrainAcc 0.8400 TestAcc 0.8544 0.8200
epoch 2100 LossPred 0.4126 LossAtt 0.2749 TrainAcc 0.8500 TestAcc 0.8591 0.8450
epoch 2200 LossPred 0.4902 LossAtt 0.2704 TrainAcc 0.8300 TestAcc 0.8428 0.8150
epoch 2300 LossPred 0.6561 LossAtt 0.2683 TrainAcc 0.7500 TestAcc 0.7638 0.7500
epoch 2400 LossPred 0.4487 LossAtt 0.2912 TrainAcc 0.8400 TestAcc 0.8471 0.8500
epoch 2500 LossPred 0.4054 LossAtt 0.2497 TrainAcc 0.8700 TestAcc 0.8636 0.8700
Optimization Finished!
********** replication  29  **********
epoch   0 LossPred 1.1874 LossAtt 1.0181 TrainAcc 0.5300 TestAcc 0.4562 0.5300
epoch 100 LossPred 0.9944 LossAtt 0.4093 TrainAcc 0.5300 TestAcc 0.5856 0.5300
epoch 200 LossPred 0.9892 LossAtt 0.3436 TrainAcc 0.5300 TestAcc 0.5856 0.5300
epoch 300 LossPred 0.9769 LossAtt 0.3379 TrainAcc 0.4900 TestAcc 0.6331 0.4950
epoch 400 LossPred 0.9556 LossAtt 0.3123 TrainAcc 0.5800 TestAcc 0.6269 0.5450
epoch 500 LossPred 0.7233 LossAtt 0.3983 TrainAcc 0.7600 TestAcc 0.7965 0.7400
epoch 600 LossPred 0.6117 LossAtt 0.3955 TrainAcc 0.8400 TestAcc 0.7375 0.8200
epoch 700 LossPred 0.5224 LossAtt 0.4070 TrainAcc 0.8600 TestAcc 0.8146 0.8600
epoch 800 LossPred 0.4469 LossAtt 0.3816 TrainAcc 0.8800 TestAcc 0.8288 0.8550
epoch 900 LossPred 0.4532 LossAtt 0.3879 TrainAcc 0.8600 TestAcc 0.8186 0.8550
epoch 1000 LossPred 0.4439 LossAtt 0.3798 TrainAcc 0.8900 TestAcc 0.8323 0.8600
epoch 1100 LossPred 0.4636 LossAtt 0.3947 TrainAcc 0.8700 TestAcc 0.8243 0.8700
epoch 1200 LossPred 0.4190 LossAtt 0.3920 TrainAcc 0.8800 TestAcc 0.8534 0.8750
epoch 1300 LossPred 0.4116 LossAtt 0.3935 TrainAcc 0.8600 TestAcc 0.8446 0.8700
epoch 1400 LossPred 0.3387 LossAtt 0.4040 TrainAcc 0.8900 TestAcc 0.8504 0.8700
epoch 1500 LossPred 0.3797 LossAtt 0.4124 TrainAcc 0.8700 TestAcc 0.7943 0.8500
epoch 1600 LossPred 0.3425 LossAtt 0.3858 TrainAcc 0.8800 TestAcc 0.8451 0.8500
epoch 1700 LossPred 0.3775 LossAtt 0.4035 TrainAcc 0.8600 TestAcc 0.7920 0.8650
epoch 1800 LossPred 0.3435 LossAtt 0.3997 TrainAcc 0.9100 TestAcc 0.8276 0.8650
epoch 1900 LossPred 0.3246 LossAtt 0.3773 TrainAcc 0.9000 TestAcc 0.8248 0.8700
epoch 2000 LossPred 0.3742 LossAtt 0.3656 TrainAcc 0.9000 TestAcc 0.7978 0.8350
epoch 2100 LossPred 0.3419 LossAtt 0.3702 TrainAcc 0.8800 TestAcc 0.8283 0.8450
epoch 2200 LossPred 0.3208 LossAtt 0.3807 TrainAcc 0.8900 TestAcc 0.8186 0.8550
epoch 2300 LossPred 0.3334 LossAtt 0.3908 TrainAcc 0.8700 TestAcc 0.8261 0.8350
epoch 2400 LossPred 0.4610 LossAtt 0.4000 TrainAcc 0.8300 TestAcc 0.7628 0.8350
epoch 2500 LossPred 0.3145 LossAtt 0.3620 TrainAcc 0.9100 TestAcc 0.8208 0.8500
Optimization Finished!
********** replication  30  **********
epoch   0 LossPred 1.5003 LossAtt 1.0146 TrainAcc 0.4200 TestAcc 0.4422 0.4100
epoch 100 LossPred 1.0772 LossAtt 0.5114 TrainAcc 0.5400 TestAcc 0.5333 0.5050
epoch 200 LossPred 0.9408 LossAtt 0.4584 TrainAcc 0.6000 TestAcc 0.5360 0.5900
epoch 300 LossPred 0.9072 LossAtt 0.4142 TrainAcc 0.5900 TestAcc 0.5118 0.5900
epoch 400 LossPred 0.8964 LossAtt 0.3884 TrainAcc 0.5900 TestAcc 0.5118 0.5850
epoch 500 LossPred 0.8873 LossAtt 0.3660 TrainAcc 0.6000 TestAcc 0.5340 0.5800
epoch 600 LossPred 0.8818 LossAtt 0.3214 TrainAcc 0.6400 TestAcc 0.5963 0.6400
epoch 700 LossPred 0.8773 LossAtt 0.3043 TrainAcc 0.6400 TestAcc 0.5963 0.6400
epoch 800 LossPred 0.8738 LossAtt 0.3277 TrainAcc 0.6400 TestAcc 0.5963 0.6400
epoch 900 LossPred 0.8665 LossAtt 0.3625 TrainAcc 0.6400 TestAcc 0.5963 0.6400
epoch 1000 LossPred 0.8461 LossAtt 0.4569 TrainAcc 0.6500 TestAcc 0.6324 0.6600
epoch 1100 LossPred 0.6232 LossAtt 0.5707 TrainAcc 0.7400 TestAcc 0.7915 0.7700
epoch 1200 LossPred 0.5698 LossAtt 0.5402 TrainAcc 0.8100 TestAcc 0.7800 0.7950
epoch 1300 LossPred 0.5150 LossAtt 0.4926 TrainAcc 0.8200 TestAcc 0.7655 0.8200
epoch 1400 LossPred 0.5051 LossAtt 0.4617 TrainAcc 0.8200 TestAcc 0.7663 0.8200
epoch 1500 LossPred 0.5417 LossAtt 0.4387 TrainAcc 0.7900 TestAcc 0.8001 0.7900
epoch 1600 LossPred 0.4966 LossAtt 0.4594 TrainAcc 0.8200 TestAcc 0.7815 0.8250
epoch 1700 LossPred 0.4772 LossAtt 0.4368 TrainAcc 0.8300 TestAcc 0.7838 0.8250
epoch 1800 LossPred 0.5273 LossAtt 0.4234 TrainAcc 0.7900 TestAcc 0.8276 0.7950
epoch 1900 LossPred 0.5187 LossAtt 0.4458 TrainAcc 0.8100 TestAcc 0.7515 0.8050
epoch 2000 LossPred 0.4789 LossAtt 0.4107 TrainAcc 0.8100 TestAcc 0.8171 0.8200
epoch 2100 LossPred 0.4891 LossAtt 0.4211 TrainAcc 0.8200 TestAcc 0.8156 0.8150
epoch 2200 LossPred 0.4595 LossAtt 0.4033 TrainAcc 0.8300 TestAcc 0.8028 0.8250
epoch 2300 LossPred 0.5041 LossAtt 0.4095 TrainAcc 0.8100 TestAcc 0.7715 0.8100
epoch 2400 LossPred 0.4737 LossAtt 0.3990 TrainAcc 0.8300 TestAcc 0.8096 0.8200
epoch 2500 LossPred 0.4411 LossAtt 0.4304 TrainAcc 0.8300 TestAcc 0.8108 0.8350
Optimization Finished!
********** replication  31  **********
epoch   0 LossPred 1.2701 LossAtt 1.0090 TrainAcc 0.4800 TestAcc 0.5165 0.4400
epoch 100 LossPred 0.9734 LossAtt 0.4284 TrainAcc 0.5000 TestAcc 0.5438 0.5100
epoch 200 LossPred 0.9225 LossAtt 0.3665 TrainAcc 0.6300 TestAcc 0.5861 0.6300
epoch 300 LossPred 0.8559 LossAtt 0.3934 TrainAcc 0.6300 TestAcc 0.5936 0.6100
epoch 400 LossPred 0.6549 LossAtt 0.4154 TrainAcc 0.7900 TestAcc 0.8013 0.7900
epoch 500 LossPred 0.5927 LossAtt 0.3994 TrainAcc 0.8200 TestAcc 0.8256 0.7650
epoch 600 LossPred 0.4852 LossAtt 0.3557 TrainAcc 0.8700 TestAcc 0.8599 0.8150
epoch 700 LossPred 0.4272 LossAtt 0.3582 TrainAcc 0.8900 TestAcc 0.8791 0.8650
epoch 800 LossPred 0.3788 LossAtt 0.3468 TrainAcc 0.9000 TestAcc 0.8846 0.8550
epoch 900 LossPred 1.2882 LossAtt 0.3085 TrainAcc 0.6300 TestAcc 0.5871 0.6300
epoch 1000 LossPred 0.6530 LossAtt 0.3228 TrainAcc 0.8000 TestAcc 0.8148 0.7700
epoch 1100 LossPred 0.4816 LossAtt 0.3692 TrainAcc 0.9100 TestAcc 0.8706 0.8900
epoch 1200 LossPred 0.9002 LossAtt 0.3668 TrainAcc 0.6600 TestAcc 0.6114 0.6550
epoch 1300 LossPred 1.0021 LossAtt 0.3364 TrainAcc 0.5000 TestAcc 0.5350 0.5050
epoch 1400 LossPred 0.6615 LossAtt 0.3647 TrainAcc 0.7500 TestAcc 0.7720 0.7500
epoch 1500 LossPred 0.4608 LossAtt 0.3528 TrainAcc 0.8800 TestAcc 0.8734 0.8500
epoch 1600 LossPred 0.4827 LossAtt 0.3758 TrainAcc 0.8600 TestAcc 0.8501 0.8600
epoch 1700 LossPred 0.4340 LossAtt 0.3636 TrainAcc 0.8600 TestAcc 0.8691 0.8400
epoch 1800 LossPred 0.4361 LossAtt 0.3601 TrainAcc 0.8400 TestAcc 0.8724 0.8400
epoch 1900 LossPred 0.3960 LossAtt 0.3460 TrainAcc 0.8800 TestAcc 0.8914 0.8950
epoch 2000 LossPred 0.4154 LossAtt 0.3642 TrainAcc 0.8400 TestAcc 0.8819 0.8450
epoch 2100 LossPred 0.3817 LossAtt 0.3586 TrainAcc 0.8900 TestAcc 0.8914 0.8800
epoch 2200 LossPred 0.3679 LossAtt 0.3459 TrainAcc 0.9000 TestAcc 0.8919 0.8750
epoch 2300 LossPred 0.3844 LossAtt 0.3414 TrainAcc 0.8700 TestAcc 0.8941 0.8750
epoch 2400 LossPred 0.3972 LossAtt 0.3375 TrainAcc 0.8900 TestAcc 0.8811 0.8750
epoch 2500 LossPred 0.3281 LossAtt 0.3381 TrainAcc 0.9100 TestAcc 0.9057 0.9050
Optimization Finished!
********** replication  32  **********
epoch   0 LossPred 1.2266 LossAtt 1.0219 TrainAcc 0.4900 TestAcc 0.4429 0.4800
epoch 100 LossPred 1.0004 LossAtt 0.4351 TrainAcc 0.5700 TestAcc 0.5523 0.5750
epoch 200 LossPred 0.9618 LossAtt 0.4314 TrainAcc 0.5700 TestAcc 0.5618 0.5850
epoch 300 LossPred 0.9467 LossAtt 0.4519 TrainAcc 0.6100 TestAcc 0.6161 0.6150
epoch 400 LossPred 0.7665 LossAtt 0.4810 TrainAcc 0.7500 TestAcc 0.6967 0.7300
epoch 500 LossPred 0.3230 LossAtt 0.3447 TrainAcc 0.9000 TestAcc 0.8591 0.8450
epoch 600 LossPred 0.2909 LossAtt 0.3257 TrainAcc 0.9100 TestAcc 0.8676 0.8500
epoch 700 LossPred 0.2817 LossAtt 0.3394 TrainAcc 0.8900 TestAcc 0.8616 0.8350
epoch 800 LossPred 0.2846 LossAtt 0.3207 TrainAcc 0.8900 TestAcc 0.8566 0.8550
epoch 900 LossPred 0.2756 LossAtt 0.3219 TrainAcc 0.9000 TestAcc 0.8569 0.8450
epoch 1000 LossPred 0.2855 LossAtt 0.3229 TrainAcc 0.9000 TestAcc 0.8559 0.8300
epoch 1100 LossPred 0.2786 LossAtt 0.3001 TrainAcc 0.9100 TestAcc 0.8616 0.8400
epoch 1200 LossPred 0.2861 LossAtt 0.2964 TrainAcc 0.9100 TestAcc 0.8601 0.8600
epoch 1300 LossPred 0.2726 LossAtt 0.2870 TrainAcc 0.9000 TestAcc 0.8669 0.8400
epoch 1400 LossPred 0.2951 LossAtt 0.2802 TrainAcc 0.8900 TestAcc 0.8556 0.8250
epoch 1500 LossPred 0.3111 LossAtt 0.2755 TrainAcc 0.9000 TestAcc 0.8421 0.8650
epoch 1600 LossPred 0.2730 LossAtt 0.2608 TrainAcc 0.8900 TestAcc 0.8644 0.8350
epoch 1700 LossPred 0.2723 LossAtt 0.2552 TrainAcc 0.8900 TestAcc 0.8684 0.8450
epoch 1800 LossPred 0.2955 LossAtt 0.2435 TrainAcc 0.9000 TestAcc 0.8636 0.8500
epoch 1900 LossPred 0.2781 LossAtt 0.2415 TrainAcc 0.9000 TestAcc 0.8689 0.8500
epoch 2000 LossPred 0.2839 LossAtt 0.2440 TrainAcc 0.9000 TestAcc 0.8671 0.8750
epoch 2100 LossPred 0.2714 LossAtt 0.2382 TrainAcc 0.8900 TestAcc 0.8651 0.8300
epoch 2200 LossPred 0.2694 LossAtt 0.2350 TrainAcc 0.8900 TestAcc 0.8666 0.8350
epoch 2300 LossPred 0.2785 LossAtt 0.2242 TrainAcc 0.9000 TestAcc 0.8684 0.8450
epoch 2400 LossPred 0.2676 LossAtt 0.2337 TrainAcc 0.8900 TestAcc 0.8759 0.8450
epoch 2500 LossPred 0.2672 LossAtt 0.2416 TrainAcc 0.8900 TestAcc 0.8701 0.8400
Optimization Finished!
********** replication  33  **********
epoch   0 LossPred 1.2227 LossAtt 1.0094 TrainAcc 0.5200 TestAcc 0.5591 0.5350
epoch 100 LossPred 0.9965 LossAtt 0.4774 TrainAcc 0.5700 TestAcc 0.5853 0.5700
epoch 200 LossPred 0.9591 LossAtt 0.5165 TrainAcc 0.5800 TestAcc 0.5526 0.5850
epoch 300 LossPred 0.9408 LossAtt 0.5471 TrainAcc 0.6000 TestAcc 0.5666 0.5950
epoch 400 LossPred 0.8574 LossAtt 0.6247 TrainAcc 0.7200 TestAcc 0.6156 0.7000
epoch 500 LossPred 0.3403 LossAtt 0.6159 TrainAcc 0.9100 TestAcc 0.8591 0.9050
epoch 600 LossPred 0.2690 LossAtt 0.5710 TrainAcc 0.9300 TestAcc 0.8574 0.9000
epoch 700 LossPred 0.2365 LossAtt 0.5770 TrainAcc 0.9200 TestAcc 0.8411 0.9000
epoch 800 LossPred 0.2201 LossAtt 0.5015 TrainAcc 0.9300 TestAcc 0.8559 0.9150
epoch 900 LossPred 0.2383 LossAtt 0.4815 TrainAcc 0.9300 TestAcc 0.8631 0.9150
epoch 1000 LossPred 0.2252 LossAtt 0.4818 TrainAcc 0.9300 TestAcc 0.8609 0.9250
epoch 1100 LossPred 0.2387 LossAtt 0.4669 TrainAcc 0.9300 TestAcc 0.8631 0.9200
epoch 1200 LossPred 0.3076 LossAtt 0.4563 TrainAcc 0.9000 TestAcc 0.8171 0.8800
epoch 1300 LossPred 0.2686 LossAtt 0.3949 TrainAcc 0.9100 TestAcc 0.8694 0.9000
epoch 1400 LossPred 0.2132 LossAtt 0.3816 TrainAcc 0.9400 TestAcc 0.8621 0.9150
epoch 1500 LossPred 0.2077 LossAtt 0.3845 TrainAcc 0.9400 TestAcc 0.8739 0.9300
epoch 1600 LossPred 0.2182 LossAtt 0.3682 TrainAcc 0.9400 TestAcc 0.8586 0.9100
epoch 1700 LossPred 0.2343 LossAtt 0.3772 TrainAcc 0.9300 TestAcc 0.8749 0.9200
epoch 1800 LossPred 0.2375 LossAtt 0.3847 TrainAcc 0.9300 TestAcc 0.8363 0.9000
epoch 1900 LossPred 0.1829 LossAtt 0.3782 TrainAcc 0.9600 TestAcc 0.8561 0.9250
epoch 2000 LossPred 0.2025 LossAtt 0.3689 TrainAcc 0.9500 TestAcc 0.8744 0.9250
epoch 2100 LossPred 0.1911 LossAtt 0.3743 TrainAcc 0.9600 TestAcc 0.8491 0.9150
epoch 2200 LossPred 0.1880 LossAtt 0.3829 TrainAcc 0.9600 TestAcc 0.8656 0.9350
epoch 2300 LossPred 0.1946 LossAtt 0.3758 TrainAcc 0.9500 TestAcc 0.8784 0.9350
epoch 2400 LossPred 0.1810 LossAtt 0.3635 TrainAcc 0.9500 TestAcc 0.8586 0.9350
epoch 2500 LossPred 0.2430 LossAtt 0.3931 TrainAcc 0.9300 TestAcc 0.8666 0.9050
Optimization Finished!
********** replication  34  **********
epoch   0 LossPred 0.9172 LossAtt 1.0063 TrainAcc 0.6200 TestAcc 0.5928 0.6200
epoch 100 LossPred 0.8456 LossAtt 0.3809 TrainAcc 0.6600 TestAcc 0.6416 0.6800
epoch 200 LossPred 1.1075 LossAtt 0.6184 TrainAcc 0.5400 TestAcc 0.6141 0.5100
epoch 300 LossPred 0.5940 LossAtt 0.4734 TrainAcc 0.8600 TestAcc 0.7945 0.8250
epoch 400 LossPred 0.9924 LossAtt 0.4452 TrainAcc 0.6200 TestAcc 0.5931 0.6200
epoch 500 LossPred 0.4338 LossAtt 0.4536 TrainAcc 0.9100 TestAcc 0.8844 0.8550
epoch 600 LossPred 0.7484 LossAtt 0.4741 TrainAcc 0.7000 TestAcc 0.6647 0.7200
epoch 700 LossPred 0.4261 LossAtt 0.4662 TrainAcc 0.8500 TestAcc 0.8531 0.8150
epoch 800 LossPred 0.3772 LossAtt 0.4844 TrainAcc 0.8900 TestAcc 0.8709 0.8450
epoch 900 LossPred 0.6008 LossAtt 0.4742 TrainAcc 0.7600 TestAcc 0.7685 0.7900
epoch 1000 LossPred 0.4002 LossAtt 0.4774 TrainAcc 0.8400 TestAcc 0.8401 0.8150
epoch 1100 LossPred 0.4104 LossAtt 0.4650 TrainAcc 0.8700 TestAcc 0.8391 0.8300
epoch 1200 LossPred 0.3443 LossAtt 0.4592 TrainAcc 0.8600 TestAcc 0.8536 0.8500
epoch 1300 LossPred 0.4301 LossAtt 0.4285 TrainAcc 0.8400 TestAcc 0.8231 0.8300
epoch 1400 LossPred 0.3312 LossAtt 0.4305 TrainAcc 0.8900 TestAcc 0.8626 0.8450
epoch 1500 LossPred 0.4664 LossAtt 0.4218 TrainAcc 0.8300 TestAcc 0.8111 0.8050
epoch 1600 LossPred 0.2826 LossAtt 0.4267 TrainAcc 0.8900 TestAcc 0.8736 0.8600
epoch 1700 LossPred 0.4401 LossAtt 0.4138 TrainAcc 0.8400 TestAcc 0.8191 0.8250
epoch 1800 LossPred 0.4000 LossAtt 0.4275 TrainAcc 0.8800 TestAcc 0.8363 0.8300
epoch 1900 LossPred 0.3120 LossAtt 0.4273 TrainAcc 0.9200 TestAcc 0.8586 0.8450
epoch 2000 LossPred 0.4103 LossAtt 0.4235 TrainAcc 0.8700 TestAcc 0.8331 0.8250
epoch 2100 LossPred 0.2482 LossAtt 0.4348 TrainAcc 0.9100 TestAcc 0.8774 0.8700
epoch 2200 LossPred 0.2596 LossAtt 0.4242 TrainAcc 0.9300 TestAcc 0.8811 0.8900
epoch 2300 LossPred 0.2462 LossAtt 0.4373 TrainAcc 0.9300 TestAcc 0.8766 0.8850
epoch 2400 LossPred 0.2211 LossAtt 0.4625 TrainAcc 0.9300 TestAcc 0.8769 0.8800
epoch 2500 LossPred 0.3180 LossAtt 0.4313 TrainAcc 0.8700 TestAcc 0.8458 0.8700
Optimization Finished!
********** replication  35  **********
epoch   0 LossPred 1.4251 LossAtt 1.0319 TrainAcc 0.4900 TestAcc 0.5025 0.4500
epoch 100 LossPred 1.0440 LossAtt 0.3899 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 200 LossPred 0.9768 LossAtt 0.3200 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 300 LossPred 1.0030 LossAtt 0.1619 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 400 LossPred 1.0096 LossAtt 0.1309 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 500 LossPred 0.9922 LossAtt 0.0987 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 600 LossPred 0.9844 LossAtt 0.1030 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 700 LossPred 0.9813 LossAtt 0.1069 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 800 LossPred 0.9801 LossAtt 0.0984 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 900 LossPred 0.9781 LossAtt 0.0871 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 1000 LossPred 0.9773 LossAtt 0.0660 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 1100 LossPred 0.9767 LossAtt 0.0575 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 1200 LossPred 0.9763 LossAtt 0.0526 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 1300 LossPred 0.9761 LossAtt 0.0797 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 1400 LossPred 0.9760 LossAtt 0.0648 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 1500 LossPred 0.9757 LossAtt 0.0538 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 1600 LossPred 0.9757 LossAtt 0.0445 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 1700 LossPred 0.9753 LossAtt 0.0618 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 1800 LossPred 0.9754 LossAtt 0.0432 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 1900 LossPred 0.9753 LossAtt 0.0793 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 2000 LossPred 0.9752 LossAtt 0.0414 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 2100 LossPred 0.9752 LossAtt 0.0352 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 2200 LossPred 0.9751 LossAtt 0.0328 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 2300 LossPred 0.9750 LossAtt 0.0446 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 2400 LossPred 0.9750 LossAtt 0.0396 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 2500 LossPred 0.9749 LossAtt 0.0343 TrainAcc 0.5800 TestAcc 0.5773 0.5800
Optimization Finished!
********** replication  36  **********
epoch   0 LossPred 1.1542 LossAtt 1.0214 TrainAcc 0.5100 TestAcc 0.5065 0.5150
epoch 100 LossPred 0.8757 LossAtt 0.3559 TrainAcc 0.6900 TestAcc 0.6009 0.6700
epoch 200 LossPred 0.8137 LossAtt 0.3542 TrainAcc 0.6900 TestAcc 0.6009 0.6900
epoch 300 LossPred 0.5100 LossAtt 0.3091 TrainAcc 0.8700 TestAcc 0.7503 0.8300
epoch 400 LossPred 0.7883 LossAtt 0.3089 TrainAcc 0.6900 TestAcc 0.6829 0.7050
epoch 500 LossPred 0.3692 LossAtt 0.2833 TrainAcc 0.8700 TestAcc 0.8153 0.8750
epoch 600 LossPred 0.3628 LossAtt 0.3140 TrainAcc 0.8700 TestAcc 0.8033 0.8750
epoch 700 LossPred 0.4708 LossAtt 0.2924 TrainAcc 0.8300 TestAcc 0.7873 0.8250
epoch 800 LossPred 0.3767 LossAtt 0.2777 TrainAcc 0.8800 TestAcc 0.8161 0.8700
epoch 900 LossPred 0.3625 LossAtt 0.2859 TrainAcc 0.8500 TestAcc 0.7983 0.8450
epoch 1000 LossPred 0.3693 LossAtt 0.2739 TrainAcc 0.8600 TestAcc 0.8048 0.8750
epoch 1100 LossPred 0.3415 LossAtt 0.2920 TrainAcc 0.8700 TestAcc 0.7963 0.8350
epoch 1200 LossPred 0.3323 LossAtt 0.2980 TrainAcc 0.8600 TestAcc 0.8048 0.8500
epoch 1300 LossPred 0.3331 LossAtt 0.2967 TrainAcc 0.8700 TestAcc 0.7973 0.8500
epoch 1400 LossPred 0.3030 LossAtt 0.3075 TrainAcc 0.8900 TestAcc 0.8293 0.8750
epoch 1500 LossPred 0.2768 LossAtt 0.3210 TrainAcc 0.9000 TestAcc 0.8416 0.8900
epoch 1600 LossPred 0.2565 LossAtt 0.3195 TrainAcc 0.9100 TestAcc 0.8363 0.8700
epoch 1700 LossPred 0.2478 LossAtt 0.3215 TrainAcc 0.9200 TestAcc 0.8463 0.8750
epoch 1800 LossPred 0.2458 LossAtt 0.3099 TrainAcc 0.9300 TestAcc 0.8466 0.8850
epoch 1900 LossPred 0.2315 LossAtt 0.3276 TrainAcc 0.9400 TestAcc 0.8451 0.8800
epoch 2000 LossPred 0.2235 LossAtt 0.3084 TrainAcc 0.9500 TestAcc 0.8524 0.8800
epoch 2100 LossPred 0.2387 LossAtt 0.3279 TrainAcc 0.9400 TestAcc 0.8431 0.8750
epoch 2200 LossPred 0.2192 LossAtt 0.3238 TrainAcc 0.9400 TestAcc 0.8629 0.8900
epoch 2300 LossPred 0.2282 LossAtt 0.3083 TrainAcc 0.9200 TestAcc 0.8461 0.8900
epoch 2400 LossPred 0.2363 LossAtt 0.3245 TrainAcc 0.9300 TestAcc 0.8511 0.8750
epoch 2500 LossPred 0.2131 LossAtt 0.3254 TrainAcc 0.9400 TestAcc 0.8493 0.8850
Optimization Finished!
********** replication  37  **********
epoch   0 LossPred 1.1767 LossAtt 1.0041 TrainAcc 0.4400 TestAcc 0.3991 0.4400
epoch 100 LossPred 0.9536 LossAtt 0.4346 TrainAcc 0.5600 TestAcc 0.5158 0.5750
epoch 200 LossPred 0.9404 LossAtt 0.3714 TrainAcc 0.5700 TestAcc 0.4930 0.5700
epoch 300 LossPred 0.9295 LossAtt 0.3571 TrainAcc 0.5700 TestAcc 0.4960 0.5700
epoch 400 LossPred 0.5898 LossAtt 0.4348 TrainAcc 0.8300 TestAcc 0.8561 0.8500
epoch 500 LossPred 0.4364 LossAtt 0.3928 TrainAcc 0.8600 TestAcc 0.8834 0.8550
epoch 600 LossPred 0.3627 LossAtt 0.3541 TrainAcc 0.8600 TestAcc 0.8901 0.8750
epoch 700 LossPred 0.3216 LossAtt 0.3275 TrainAcc 0.8800 TestAcc 0.8919 0.8700
epoch 800 LossPred 0.3210 LossAtt 0.2951 TrainAcc 0.8900 TestAcc 0.8934 0.8650
epoch 900 LossPred 0.3086 LossAtt 0.2772 TrainAcc 0.8900 TestAcc 0.8939 0.8700
epoch 1000 LossPred 0.3854 LossAtt 0.2769 TrainAcc 0.8800 TestAcc 0.8834 0.8500
epoch 1100 LossPred 0.4000 LossAtt 0.2936 TrainAcc 0.8400 TestAcc 0.8726 0.8500
epoch 1200 LossPred 0.3637 LossAtt 0.2693 TrainAcc 0.8700 TestAcc 0.8789 0.8550
epoch 1300 LossPred 0.3015 LossAtt 0.2678 TrainAcc 0.9000 TestAcc 0.8936 0.8650
epoch 1400 LossPred 0.2965 LossAtt 0.2537 TrainAcc 0.8900 TestAcc 0.8889 0.8600
epoch 1500 LossPred 0.4214 LossAtt 0.2466 TrainAcc 0.8500 TestAcc 0.8791 0.8400
epoch 1600 LossPred 0.2969 LossAtt 0.2454 TrainAcc 0.9100 TestAcc 0.8964 0.8650
epoch 1700 LossPred 0.4929 LossAtt 0.2345 TrainAcc 0.8300 TestAcc 0.8581 0.8450
epoch 1800 LossPred 0.3259 LossAtt 0.2324 TrainAcc 0.8800 TestAcc 0.8981 0.8750
epoch 1900 LossPred 0.2802 LossAtt 0.2348 TrainAcc 0.9200 TestAcc 0.8949 0.8750
epoch 2000 LossPred 0.3494 LossAtt 0.2424 TrainAcc 0.8700 TestAcc 0.8739 0.8600
epoch 2100 LossPred 0.5082 LossAtt 0.2316 TrainAcc 0.8200 TestAcc 0.8514 0.8400
epoch 2200 LossPred 0.5032 LossAtt 0.2332 TrainAcc 0.8200 TestAcc 0.8486 0.8400
epoch 2300 LossPred 0.5602 LossAtt 0.2312 TrainAcc 0.7900 TestAcc 0.8121 0.7900
epoch 2400 LossPred 0.5025 LossAtt 0.2185 TrainAcc 0.8200 TestAcc 0.8471 0.8300
epoch 2500 LossPred 0.3117 LossAtt 0.2137 TrainAcc 0.8800 TestAcc 0.8921 0.8650
Optimization Finished!
********** replication  38  **********
epoch   0 LossPred 1.1513 LossAtt 1.0109 TrainAcc 0.5300 TestAcc 0.4552 0.5200
epoch 100 LossPred 0.9945 LossAtt 0.3431 TrainAcc 0.5500 TestAcc 0.5455 0.5350
epoch 200 LossPred 0.9930 LossAtt 0.3012 TrainAcc 0.5200 TestAcc 0.5963 0.5200
epoch 300 LossPred 0.9926 LossAtt 0.2556 TrainAcc 0.5200 TestAcc 0.5963 0.5200
epoch 400 LossPred 0.9824 LossAtt 0.2870 TrainAcc 0.5500 TestAcc 0.5455 0.5600
epoch 500 LossPred 0.9786 LossAtt 0.2639 TrainAcc 0.5600 TestAcc 0.4910 0.5600
epoch 600 LossPred 0.9773 LossAtt 0.2544 TrainAcc 0.5600 TestAcc 0.4910 0.5600
epoch 700 LossPred 0.9776 LossAtt 0.2198 TrainAcc 0.5600 TestAcc 0.4910 0.5600
epoch 800 LossPred 0.9875 LossAtt 0.1614 TrainAcc 0.5500 TestAcc 0.5455 0.5500
epoch 900 LossPred 0.9951 LossAtt 0.0950 TrainAcc 0.5500 TestAcc 0.5455 0.5200
epoch 1000 LossPred 0.9969 LossAtt 0.0912 TrainAcc 0.5500 TestAcc 0.5455 0.5300
epoch 1100 LossPred 0.9982 LossAtt 0.0693 TrainAcc 0.5500 TestAcc 0.5455 0.5450
epoch 1200 LossPred 0.9984 LossAtt 0.0682 TrainAcc 0.5100 TestAcc 0.4167 0.5150
epoch 1300 LossPred 0.9984 LossAtt 0.0646 TrainAcc 0.5100 TestAcc 0.4167 0.5200
epoch 1400 LossPred 0.9985 LossAtt 0.0646 TrainAcc 0.5100 TestAcc 0.4167 0.5300
epoch 1500 LossPred 0.9985 LossAtt 0.0441 TrainAcc 0.5100 TestAcc 0.4167 0.5100
epoch 1600 LossPred 0.9985 LossAtt 0.0624 TrainAcc 0.5100 TestAcc 0.4167 0.5100
epoch 1700 LossPred 0.9986 LossAtt 0.0707 TrainAcc 0.5100 TestAcc 0.4167 0.5100
epoch 1800 LossPred 0.9986 LossAtt 0.0790 TrainAcc 0.5100 TestAcc 0.4167 0.5100
epoch 1900 LossPred 0.9986 LossAtt 0.0645 TrainAcc 0.5100 TestAcc 0.4167 0.5100
epoch 2000 LossPred 0.9987 LossAtt 0.0668 TrainAcc 0.5100 TestAcc 0.4167 0.5100
epoch 2100 LossPred 0.9987 LossAtt 0.0697 TrainAcc 0.5100 TestAcc 0.4167 0.5100
epoch 2200 LossPred 0.9987 LossAtt 0.0664 TrainAcc 0.5100 TestAcc 0.4167 0.5100
epoch 2300 LossPred 0.9987 LossAtt 0.0723 TrainAcc 0.5100 TestAcc 0.4167 0.5100
epoch 2400 LossPred 0.9986 LossAtt 0.0643 TrainAcc 0.5100 TestAcc 0.4167 0.5100
epoch 2500 LossPred 0.9986 LossAtt 0.0802 TrainAcc 0.5100 TestAcc 0.4167 0.5100
Optimization Finished!
********** replication  39  **********
epoch   0 LossPred 1.1421 LossAtt 0.9945 TrainAcc 0.4900 TestAcc 0.5125 0.5150
epoch 100 LossPred 0.9392 LossAtt 0.3714 TrainAcc 0.5900 TestAcc 0.5736 0.5900
epoch 200 LossPred 0.9246 LossAtt 0.3118 TrainAcc 0.6500 TestAcc 0.5833 0.6250
epoch 300 LossPred 0.6976 LossAtt 0.4365 TrainAcc 0.8100 TestAcc 0.7828 0.7850
epoch 400 LossPred 1.0878 LossAtt 0.4434 TrainAcc 0.5900 TestAcc 0.5736 0.5900
epoch 500 LossPred 0.9326 LossAtt 0.3932 TrainAcc 0.6500 TestAcc 0.5751 0.6100
epoch 600 LossPred 0.8644 LossAtt 0.4142 TrainAcc 0.6800 TestAcc 0.6189 0.6550
epoch 700 LossPred 0.6834 LossAtt 0.4126 TrainAcc 0.7500 TestAcc 0.7235 0.7600
epoch 800 LossPred 0.6980 LossAtt 0.3787 TrainAcc 0.8000 TestAcc 0.7027 0.7850
epoch 900 LossPred 0.6164 LossAtt 0.3833 TrainAcc 0.8100 TestAcc 0.7410 0.7900
epoch 1000 LossPred 0.3582 LossAtt 0.3646 TrainAcc 0.9100 TestAcc 0.8711 0.8900
epoch 1100 LossPred 0.3148 LossAtt 0.3617 TrainAcc 0.9000 TestAcc 0.8679 0.8950
epoch 1200 LossPred 0.3766 LossAtt 0.3575 TrainAcc 0.8800 TestAcc 0.8436 0.8750
epoch 1300 LossPred 0.3345 LossAtt 0.3593 TrainAcc 0.9100 TestAcc 0.8651 0.8900
epoch 1400 LossPred 0.3390 LossAtt 0.3732 TrainAcc 0.9000 TestAcc 0.8493 0.8900
epoch 1500 LossPred 0.9526 LossAtt 0.3210 TrainAcc 0.7100 TestAcc 0.6814 0.7050
epoch 1600 LossPred 0.4178 LossAtt 0.3467 TrainAcc 0.8600 TestAcc 0.8238 0.8800
epoch 1700 LossPred 0.3215 LossAtt 0.3615 TrainAcc 0.8900 TestAcc 0.8646 0.8800
epoch 1800 LossPred 0.3552 LossAtt 0.3633 TrainAcc 0.8900 TestAcc 0.8188 0.8900
epoch 1900 LossPred 0.2949 LossAtt 0.3423 TrainAcc 0.8900 TestAcc 0.8524 0.9000
epoch 2000 LossPred 0.2780 LossAtt 0.3549 TrainAcc 0.9200 TestAcc 0.8679 0.9000
epoch 2100 LossPred 0.2434 LossAtt 0.3372 TrainAcc 0.9200 TestAcc 0.8736 0.9250
epoch 2200 LossPred 0.2345 LossAtt 0.3455 TrainAcc 0.9200 TestAcc 0.8556 0.9200
epoch 2300 LossPred 0.2419 LossAtt 0.3641 TrainAcc 0.9300 TestAcc 0.8711 0.9300
epoch 2400 LossPred 0.2242 LossAtt 0.3381 TrainAcc 0.9300 TestAcc 0.8711 0.9200
epoch 2500 LossPred 0.2372 LossAtt 0.3503 TrainAcc 0.9300 TestAcc 0.8686 0.9200
Optimization Finished!
********** replication  40  **********
epoch   0 LossPred 1.1558 LossAtt 1.0193 TrainAcc 0.5900 TestAcc 0.5848 0.5850
epoch 100 LossPred 0.9049 LossAtt 0.4079 TrainAcc 0.5900 TestAcc 0.5898 0.6100
epoch 200 LossPred 0.8860 LossAtt 0.4100 TrainAcc 0.6500 TestAcc 0.6364 0.6400
epoch 300 LossPred 0.8530 LossAtt 0.4317 TrainAcc 0.6300 TestAcc 0.6794 0.6500
epoch 400 LossPred 0.5695 LossAtt 0.4556 TrainAcc 0.8100 TestAcc 0.8003 0.8100
epoch 500 LossPred 0.4216 LossAtt 0.4615 TrainAcc 0.8800 TestAcc 0.8123 0.8500
epoch 600 LossPred 0.3812 LossAtt 0.4322 TrainAcc 0.8800 TestAcc 0.8218 0.8600
epoch 700 LossPred 0.4598 LossAtt 0.4057 TrainAcc 0.8600 TestAcc 0.8071 0.7950
epoch 800 LossPred 0.3249 LossAtt 0.4122 TrainAcc 0.8900 TestAcc 0.8161 0.8700
epoch 900 LossPred 0.3361 LossAtt 0.3983 TrainAcc 0.9000 TestAcc 0.8148 0.8650
epoch 1000 LossPred 0.3360 LossAtt 0.3898 TrainAcc 0.8900 TestAcc 0.8223 0.8550
epoch 1100 LossPred 0.3379 LossAtt 0.3355 TrainAcc 0.8900 TestAcc 0.8181 0.8600
epoch 1200 LossPred 0.2978 LossAtt 0.3548 TrainAcc 0.8900 TestAcc 0.8233 0.8650
epoch 1300 LossPred 0.3075 LossAtt 0.3551 TrainAcc 0.8900 TestAcc 0.8271 0.8550
epoch 1400 LossPred 0.3927 LossAtt 0.3311 TrainAcc 0.8700 TestAcc 0.8061 0.8300
epoch 1500 LossPred 0.3159 LossAtt 0.3175 TrainAcc 0.9100 TestAcc 0.8276 0.8650
epoch 1600 LossPred 0.2534 LossAtt 0.3193 TrainAcc 0.9400 TestAcc 0.8308 0.8650
epoch 1700 LossPred 0.3233 LossAtt 0.3115 TrainAcc 0.9000 TestAcc 0.8276 0.8550
epoch 1800 LossPred 0.2566 LossAtt 0.3143 TrainAcc 0.9300 TestAcc 0.8288 0.8650
epoch 1900 LossPred 0.2626 LossAtt 0.3386 TrainAcc 0.9300 TestAcc 0.8286 0.8700
epoch 2000 LossPred 0.3190 LossAtt 0.3262 TrainAcc 0.9100 TestAcc 0.8273 0.8550
epoch 2100 LossPred 0.3315 LossAtt 0.3202 TrainAcc 0.8800 TestAcc 0.8226 0.8650
epoch 2200 LossPred 0.5611 LossAtt 0.3313 TrainAcc 0.8200 TestAcc 0.7858 0.8300
epoch 2300 LossPred 0.9050 LossAtt 0.2603 TrainAcc 0.7000 TestAcc 0.6664 0.7150
epoch 2400 LossPred 0.4793 LossAtt 0.3275 TrainAcc 0.8400 TestAcc 0.8063 0.8300
epoch 2500 LossPred 0.4329 LossAtt 0.2989 TrainAcc 0.8500 TestAcc 0.8191 0.8400
Optimization Finished!
********** replication  41  **********
epoch   0 LossPred 1.2876 LossAtt 1.0006 TrainAcc 0.4600 TestAcc 0.4237 0.4550
epoch 100 LossPred 1.0003 LossAtt 0.4514 TrainAcc 0.5500 TestAcc 0.5928 0.5500
epoch 200 LossPred 0.9647 LossAtt 0.3976 TrainAcc 0.5500 TestAcc 0.6264 0.5500
epoch 300 LossPred 0.9143 LossAtt 0.4437 TrainAcc 0.6000 TestAcc 0.6852 0.6100
epoch 400 LossPred 0.4608 LossAtt 0.4021 TrainAcc 0.8600 TestAcc 0.8316 0.8550
epoch 500 LossPred 0.3784 LossAtt 0.4043 TrainAcc 0.8600 TestAcc 0.8526 0.8550
epoch 600 LossPred 0.3274 LossAtt 0.4164 TrainAcc 0.8800 TestAcc 0.8786 0.8750
epoch 700 LossPred 0.3321 LossAtt 0.3905 TrainAcc 0.8900 TestAcc 0.8641 0.8750
epoch 800 LossPred 0.3423 LossAtt 0.3957 TrainAcc 0.8600 TestAcc 0.8824 0.8650
epoch 900 LossPred 0.2606 LossAtt 0.4295 TrainAcc 0.9200 TestAcc 0.8846 0.9050
epoch 1000 LossPred 0.2359 LossAtt 0.4058 TrainAcc 0.9000 TestAcc 0.8916 0.8850
epoch 1100 LossPred 0.2495 LossAtt 0.4135 TrainAcc 0.9000 TestAcc 0.8814 0.8950
epoch 1200 LossPred 0.3556 LossAtt 0.3741 TrainAcc 0.9000 TestAcc 0.8303 0.8600
epoch 1300 LossPred 0.2630 LossAtt 0.3930 TrainAcc 0.9100 TestAcc 0.8706 0.8900
epoch 1400 LossPred 0.2530 LossAtt 0.3857 TrainAcc 0.9100 TestAcc 0.8686 0.8950
epoch 1500 LossPred 0.3213 LossAtt 0.3937 TrainAcc 0.9000 TestAcc 0.8751 0.8750
epoch 1600 LossPred 0.2663 LossAtt 0.3762 TrainAcc 0.9100 TestAcc 0.8691 0.8950
epoch 1700 LossPred 0.2887 LossAtt 0.3828 TrainAcc 0.9100 TestAcc 0.8654 0.8750
epoch 1800 LossPred 0.3494 LossAtt 0.4010 TrainAcc 0.8900 TestAcc 0.8626 0.8750
epoch 1900 LossPred 0.4126 LossAtt 0.3986 TrainAcc 0.8600 TestAcc 0.8203 0.8300
epoch 2000 LossPred 0.2608 LossAtt 0.4200 TrainAcc 0.9000 TestAcc 0.8766 0.8800
epoch 2100 LossPred 0.2390 LossAtt 0.4026 TrainAcc 0.9400 TestAcc 0.8794 0.8750
epoch 2200 LossPred 0.3537 LossAtt 0.4122 TrainAcc 0.8800 TestAcc 0.8514 0.8500
epoch 2300 LossPred 0.2661 LossAtt 0.3901 TrainAcc 0.9100 TestAcc 0.8646 0.8700
epoch 2400 LossPred 0.3072 LossAtt 0.3671 TrainAcc 0.9000 TestAcc 0.8811 0.8500
epoch 2500 LossPred 0.2488 LossAtt 0.3689 TrainAcc 0.9500 TestAcc 0.8854 0.8800
Optimization Finished!
********** replication  42  **********
epoch   0 LossPred 1.0244 LossAtt 0.9695 TrainAcc 0.5000 TestAcc 0.4484 0.5000
epoch 100 LossPred 0.8561 LossAtt 0.4220 TrainAcc 0.6600 TestAcc 0.5888 0.6600
epoch 200 LossPred 0.8390 LossAtt 0.3692 TrainAcc 0.6600 TestAcc 0.5888 0.6600
epoch 300 LossPred 0.8282 LossAtt 0.3259 TrainAcc 0.6600 TestAcc 0.5888 0.6600
epoch 400 LossPred 0.7917 LossAtt 0.4538 TrainAcc 0.7000 TestAcc 0.6567 0.7200
epoch 500 LossPred 0.7653 LossAtt 0.4220 TrainAcc 0.7200 TestAcc 0.7082 0.7100
epoch 600 LossPred 0.5425 LossAtt 0.4240 TrainAcc 0.8500 TestAcc 0.8101 0.8550
epoch 700 LossPred 0.5063 LossAtt 0.4432 TrainAcc 0.8600 TestAcc 0.7798 0.8750
epoch 800 LossPred 0.5859 LossAtt 0.4513 TrainAcc 0.8200 TestAcc 0.7487 0.8200
epoch 900 LossPred 0.4312 LossAtt 0.4289 TrainAcc 0.8800 TestAcc 0.7885 0.8750
epoch 1000 LossPred 0.5148 LossAtt 0.4372 TrainAcc 0.8300 TestAcc 0.8043 0.8100
epoch 1100 LossPred 0.4154 LossAtt 0.4552 TrainAcc 0.8700 TestAcc 0.8101 0.8450
epoch 1200 LossPred 0.3906 LossAtt 0.4262 TrainAcc 0.9000 TestAcc 0.7925 0.8500
epoch 1300 LossPred 0.3630 LossAtt 0.3878 TrainAcc 0.8800 TestAcc 0.8181 0.8350
epoch 1400 LossPred 0.3512 LossAtt 0.4086 TrainAcc 0.8900 TestAcc 0.8111 0.8700
epoch 1500 LossPred 0.3068 LossAtt 0.3841 TrainAcc 0.9000 TestAcc 0.7940 0.8700
epoch 1600 LossPred 0.3397 LossAtt 0.4034 TrainAcc 0.9000 TestAcc 0.7978 0.8650
epoch 1700 LossPred 0.9452 LossAtt 0.3819 TrainAcc 0.6700 TestAcc 0.6619 0.7000
epoch 1800 LossPred 0.5829 LossAtt 0.3791 TrainAcc 0.8400 TestAcc 0.7475 0.8050
epoch 1900 LossPred 0.4835 LossAtt 0.3765 TrainAcc 0.8500 TestAcc 0.7745 0.8550
epoch 2000 LossPred 0.3145 LossAtt 0.3934 TrainAcc 0.9000 TestAcc 0.7903 0.8400
epoch 2100 LossPred 0.5122 LossAtt 0.3709 TrainAcc 0.8300 TestAcc 0.7945 0.8200
epoch 2200 LossPred 0.3091 LossAtt 0.3867 TrainAcc 0.9000 TestAcc 0.7890 0.8500
epoch 2300 LossPred 0.5116 LossAtt 0.3702 TrainAcc 0.8600 TestAcc 0.7580 0.8500
epoch 2400 LossPred 0.3213 LossAtt 0.3451 TrainAcc 0.9000 TestAcc 0.7865 0.8650
epoch 2500 LossPred 0.5471 LossAtt 0.3351 TrainAcc 0.8400 TestAcc 0.7508 0.8100
Optimization Finished!
********** replication  43  **********
epoch   0 LossPred 0.9598 LossAtt 1.0311 TrainAcc 0.5900 TestAcc 0.5030 0.5900
epoch 100 LossPred 0.8815 LossAtt 0.5347 TrainAcc 0.6400 TestAcc 0.5901 0.6250
epoch 200 LossPred 0.8270 LossAtt 0.4634 TrainAcc 0.6500 TestAcc 0.6479 0.6400
epoch 300 LossPred 0.3414 LossAtt 0.4718 TrainAcc 0.8900 TestAcc 0.8781 0.8400
epoch 400 LossPred 0.2500 LossAtt 0.4662 TrainAcc 0.9000 TestAcc 0.8944 0.8700
epoch 500 LossPred 0.3510 LossAtt 0.4781 TrainAcc 0.8800 TestAcc 0.8686 0.8850
epoch 600 LossPred 0.2438 LossAtt 0.4530 TrainAcc 0.9400 TestAcc 0.8959 0.8800
epoch 700 LossPred 0.4185 LossAtt 0.4023 TrainAcc 0.8400 TestAcc 0.8576 0.8150
epoch 800 LossPred 0.4766 LossAtt 0.4235 TrainAcc 0.8400 TestAcc 0.8018 0.8300
epoch 900 LossPred 0.4532 LossAtt 0.3994 TrainAcc 0.8300 TestAcc 0.8143 0.8500
epoch 1000 LossPred 0.5239 LossAtt 0.3630 TrainAcc 0.7800 TestAcc 0.8266 0.7900
epoch 1100 LossPred 0.3724 LossAtt 0.3774 TrainAcc 0.8800 TestAcc 0.8323 0.8800
epoch 1200 LossPred 0.6201 LossAtt 0.3527 TrainAcc 0.7500 TestAcc 0.8051 0.7550
epoch 1300 LossPred 0.3377 LossAtt 0.3845 TrainAcc 0.9000 TestAcc 0.8659 0.8900
epoch 1400 LossPred 0.3630 LossAtt 0.3572 TrainAcc 0.8700 TestAcc 0.8614 0.8750
epoch 1500 LossPred 0.4097 LossAtt 0.3563 TrainAcc 0.8600 TestAcc 0.8589 0.8350
epoch 1600 LossPred 0.3168 LossAtt 0.3671 TrainAcc 0.8900 TestAcc 0.8824 0.9050
epoch 1700 LossPred 0.4227 LossAtt 0.3522 TrainAcc 0.8500 TestAcc 0.8554 0.8200
epoch 1800 LossPred 0.3654 LossAtt 0.3767 TrainAcc 0.8600 TestAcc 0.8636 0.8800
epoch 1900 LossPred 0.5218 LossAtt 0.3416 TrainAcc 0.7800 TestAcc 0.8246 0.7950
epoch 2000 LossPred 0.3223 LossAtt 0.3648 TrainAcc 0.9000 TestAcc 0.8824 0.8850
epoch 2100 LossPred 0.3467 LossAtt 0.3454 TrainAcc 0.8600 TestAcc 0.8821 0.8450
epoch 2200 LossPred 0.4007 LossAtt 0.3768 TrainAcc 0.8800 TestAcc 0.8531 0.8800
epoch 2300 LossPred 0.2867 LossAtt 0.3764 TrainAcc 0.9200 TestAcc 0.8879 0.9050
epoch 2400 LossPred 0.5096 LossAtt 0.3612 TrainAcc 0.8000 TestAcc 0.8308 0.8050
epoch 2500 LossPred 0.3297 LossAtt 0.3801 TrainAcc 0.9200 TestAcc 0.8756 0.8800
Optimization Finished!
********** replication  44  **********
epoch   0 LossPred 1.1788 LossAtt 1.0189 TrainAcc 0.5500 TestAcc 0.4882 0.5400
epoch 100 LossPred 0.9777 LossAtt 0.4272 TrainAcc 0.5800 TestAcc 0.5040 0.5900
epoch 200 LossPred 0.9500 LossAtt 0.3790 TrainAcc 0.5900 TestAcc 0.5240 0.5700
epoch 300 LossPred 0.9021 LossAtt 0.3890 TrainAcc 0.6400 TestAcc 0.5480 0.6300
epoch 400 LossPred 0.8606 LossAtt 0.3728 TrainAcc 0.6800 TestAcc 0.5971 0.6600
epoch 500 LossPred 0.8468 LossAtt 0.3865 TrainAcc 0.6700 TestAcc 0.5948 0.6650
epoch 600 LossPred 0.8403 LossAtt 0.3741 TrainAcc 0.6600 TestAcc 0.5983 0.6750
epoch 700 LossPred 0.8335 LossAtt 0.3764 TrainAcc 0.6600 TestAcc 0.5908 0.6700
epoch 800 LossPred 0.8307 LossAtt 0.3783 TrainAcc 0.6600 TestAcc 0.5978 0.6750
epoch 900 LossPred 0.8302 LossAtt 0.3821 TrainAcc 0.6600 TestAcc 0.5911 0.6700
epoch 1000 LossPred 0.8273 LossAtt 0.3773 TrainAcc 0.6600 TestAcc 0.5941 0.6700
epoch 1100 LossPred 0.8256 LossAtt 0.3797 TrainAcc 0.6600 TestAcc 0.5943 0.6700
epoch 1200 LossPred 0.8264 LossAtt 0.3886 TrainAcc 0.6600 TestAcc 0.5913 0.6700
epoch 1300 LossPred 0.8278 LossAtt 0.4060 TrainAcc 0.6800 TestAcc 0.5941 0.6700
epoch 1400 LossPred 0.8241 LossAtt 0.3976 TrainAcc 0.6700 TestAcc 0.5946 0.6700
epoch 1500 LossPred 0.8170 LossAtt 0.3872 TrainAcc 0.6800 TestAcc 0.5928 0.6700
epoch 1600 LossPred 0.8241 LossAtt 0.4033 TrainAcc 0.6700 TestAcc 0.5951 0.6650
epoch 1700 LossPred 0.8116 LossAtt 0.4301 TrainAcc 0.6800 TestAcc 0.5956 0.6750
epoch 1800 LossPred 0.8015 LossAtt 0.3901 TrainAcc 0.6800 TestAcc 0.5801 0.6600
epoch 1900 LossPred 0.8143 LossAtt 0.4016 TrainAcc 0.7000 TestAcc 0.5836 0.6700
epoch 2000 LossPred 0.8073 LossAtt 0.4266 TrainAcc 0.6900 TestAcc 0.5858 0.6750
epoch 2100 LossPred 0.7897 LossAtt 0.4220 TrainAcc 0.7100 TestAcc 0.5858 0.6650
epoch 2200 LossPred 0.7917 LossAtt 0.4180 TrainAcc 0.6800 TestAcc 0.5843 0.6800
epoch 2300 LossPred 0.8300 LossAtt 0.4400 TrainAcc 0.6700 TestAcc 0.5883 0.6650
epoch 2400 LossPred 0.7835 LossAtt 0.4349 TrainAcc 0.7000 TestAcc 0.5863 0.6850
epoch 2500 LossPred 0.7782 LossAtt 0.4316 TrainAcc 0.7200 TestAcc 0.5908 0.6900
Optimization Finished!
********** replication  45  **********
epoch   0 LossPred 1.2944 LossAtt 0.9960 TrainAcc 0.5100 TestAcc 0.4865 0.5050
epoch 100 LossPred 0.9472 LossAtt 0.3844 TrainAcc 0.5800 TestAcc 0.5833 0.5800
epoch 200 LossPred 0.8832 LossAtt 0.2706 TrainAcc 0.6500 TestAcc 0.5996 0.6500
epoch 300 LossPred 0.8748 LossAtt 0.1186 TrainAcc 0.6500 TestAcc 0.5996 0.6500
epoch 400 LossPred 0.8731 LossAtt 0.1197 TrainAcc 0.6500 TestAcc 0.5996 0.6500
epoch 500 LossPred 0.8725 LossAtt 0.1448 TrainAcc 0.6500 TestAcc 0.5996 0.6500
epoch 600 LossPred 0.8722 LossAtt 0.1775 TrainAcc 0.6500 TestAcc 0.5996 0.6500
epoch 700 LossPred 0.8704 LossAtt 0.2155 TrainAcc 0.6500 TestAcc 0.5996 0.6500
epoch 800 LossPred 0.8669 LossAtt 0.2756 TrainAcc 0.6500 TestAcc 0.5996 0.6500
epoch 900 LossPred 0.8385 LossAtt 0.3828 TrainAcc 0.7100 TestAcc 0.6441 0.7000
epoch 1000 LossPred 0.6194 LossAtt 0.3573 TrainAcc 0.7800 TestAcc 0.7570 0.7900
epoch 1100 LossPred 0.4922 LossAtt 0.2766 TrainAcc 0.8300 TestAcc 0.8113 0.8300
epoch 1200 LossPred 0.5659 LossAtt 0.2855 TrainAcc 0.7800 TestAcc 0.7820 0.7850
epoch 1300 LossPred 0.3112 LossAtt 0.2976 TrainAcc 0.9000 TestAcc 0.8388 0.8750
epoch 1400 LossPred 0.3123 LossAtt 0.3183 TrainAcc 0.8900 TestAcc 0.8551 0.8850
epoch 1500 LossPred 0.3134 LossAtt 0.3214 TrainAcc 0.8900 TestAcc 0.8661 0.9100
epoch 1600 LossPred 0.3120 LossAtt 0.3205 TrainAcc 0.8900 TestAcc 0.8408 0.8650
epoch 1700 LossPred 0.2880 LossAtt 0.3421 TrainAcc 0.8800 TestAcc 0.8431 0.8500
epoch 1800 LossPred 0.2558 LossAtt 0.3284 TrainAcc 0.9100 TestAcc 0.8514 0.8850
epoch 1900 LossPred 0.3025 LossAtt 0.3473 TrainAcc 0.9100 TestAcc 0.8619 0.8850
epoch 2000 LossPred 0.2944 LossAtt 0.3586 TrainAcc 0.9100 TestAcc 0.8721 0.9000
epoch 2100 LossPred 0.4037 LossAtt 0.3579 TrainAcc 0.8500 TestAcc 0.8358 0.8600
epoch 2200 LossPred 0.4266 LossAtt 0.3404 TrainAcc 0.8500 TestAcc 0.8426 0.8700
epoch 2300 LossPred 0.3006 LossAtt 0.3573 TrainAcc 0.8800 TestAcc 0.8829 0.9000
epoch 2400 LossPred 0.2160 LossAtt 0.3531 TrainAcc 0.9300 TestAcc 0.8701 0.9050
epoch 2500 LossPred 0.2817 LossAtt 0.3523 TrainAcc 0.9100 TestAcc 0.8631 0.8950
Optimization Finished!
********** replication  46  **********
epoch   0 LossPred 1.0257 LossAtt 1.0315 TrainAcc 0.5500 TestAcc 0.5906 0.5350
epoch 100 LossPred 0.9890 LossAtt 0.2571 TrainAcc 0.5500 TestAcc 0.5916 0.5500
epoch 200 LossPred 0.9888 LossAtt 0.1397 TrainAcc 0.5500 TestAcc 0.5916 0.5500
epoch 300 LossPred 0.9884 LossAtt 0.1029 TrainAcc 0.5500 TestAcc 0.5916 0.5500
epoch 400 LossPred 0.9881 LossAtt 0.1642 TrainAcc 0.5500 TestAcc 0.5916 0.5500
epoch 500 LossPred 0.9732 LossAtt 0.2240 TrainAcc 0.6100 TestAcc 0.6391 0.5900
epoch 600 LossPred 0.9822 LossAtt 0.3201 TrainAcc 0.5600 TestAcc 0.6179 0.5600
epoch 700 LossPred 0.7929 LossAtt 0.2970 TrainAcc 0.7100 TestAcc 0.6652 0.7300
epoch 800 LossPred 0.3870 LossAtt 0.2899 TrainAcc 0.9000 TestAcc 0.8016 0.8900
epoch 900 LossPred 0.3610 LossAtt 0.2854 TrainAcc 0.9100 TestAcc 0.8263 0.8950
epoch 1000 LossPred 0.4749 LossAtt 0.2785 TrainAcc 0.8300 TestAcc 0.7828 0.8050
epoch 1100 LossPred 0.3221 LossAtt 0.2731 TrainAcc 0.9100 TestAcc 0.8273 0.9050
epoch 1200 LossPred 0.3220 LossAtt 0.2636 TrainAcc 0.9000 TestAcc 0.8281 0.8950
epoch 1300 LossPred 0.8569 LossAtt 0.2511 TrainAcc 0.7200 TestAcc 0.7450 0.7550
epoch 1400 LossPred 0.3317 LossAtt 0.2637 TrainAcc 0.8900 TestAcc 0.8441 0.8950
epoch 1500 LossPred 0.6143 LossAtt 0.2539 TrainAcc 0.7800 TestAcc 0.7838 0.8000
epoch 1600 LossPred 0.6986 LossAtt 0.2720 TrainAcc 0.7400 TestAcc 0.7040 0.7450
epoch 1700 LossPred 0.3395 LossAtt 0.2593 TrainAcc 0.9000 TestAcc 0.8233 0.8750
epoch 1800 LossPred 0.7312 LossAtt 0.2604 TrainAcc 0.7000 TestAcc 0.7072 0.7450
epoch 1900 LossPred 0.9074 LossAtt 0.2731 TrainAcc 0.6800 TestAcc 0.5891 0.6600
epoch 2000 LossPred 0.5134 LossAtt 0.2714 TrainAcc 0.8200 TestAcc 0.8036 0.8050
epoch 2100 LossPred 0.3959 LossAtt 0.2529 TrainAcc 0.8800 TestAcc 0.7995 0.8550
epoch 2200 LossPred 0.4884 LossAtt 0.2623 TrainAcc 0.8500 TestAcc 0.8103 0.8050
epoch 2300 LossPred 0.6400 LossAtt 0.2663 TrainAcc 0.7800 TestAcc 0.7050 0.7800
epoch 2400 LossPred 0.4716 LossAtt 0.2600 TrainAcc 0.8400 TestAcc 0.8078 0.8150
epoch 2500 LossPred 0.4209 LossAtt 0.2694 TrainAcc 0.8700 TestAcc 0.8306 0.8350
Optimization Finished!
********** replication  47  **********
epoch   0 LossPred 1.0032 LossAtt 1.0102 TrainAcc 0.6100 TestAcc 0.5125 0.5500
epoch 100 LossPred 0.9509 LossAtt 0.4016 TrainAcc 0.6200 TestAcc 0.5448 0.5900
epoch 200 LossPred 0.9418 LossAtt 0.3408 TrainAcc 0.6200 TestAcc 0.5443 0.6200
epoch 300 LossPred 0.9384 LossAtt 0.3124 TrainAcc 0.6200 TestAcc 0.5443 0.6200
epoch 400 LossPred 0.9368 LossAtt 0.2908 TrainAcc 0.6200 TestAcc 0.5443 0.6200
epoch 500 LossPred 0.9365 LossAtt 0.2555 TrainAcc 0.6200 TestAcc 0.5443 0.6200
epoch 600 LossPred 0.9368 LossAtt 0.2348 TrainAcc 0.6200 TestAcc 0.5443 0.6150
epoch 700 LossPred 0.9374 LossAtt 0.1946 TrainAcc 0.6200 TestAcc 0.5443 0.6200
epoch 800 LossPred 0.9385 LossAtt 0.2116 TrainAcc 0.6200 TestAcc 0.5538 0.6150
epoch 900 LossPred 0.9392 LossAtt 0.1887 TrainAcc 0.6200 TestAcc 0.5538 0.6150
epoch 1000 LossPred 0.9395 LossAtt 0.1777 TrainAcc 0.6200 TestAcc 0.5533 0.6150
epoch 1100 LossPred 0.9469 LossAtt 0.0908 TrainAcc 0.6100 TestAcc 0.5816 0.6100
epoch 1200 LossPred 0.9471 LossAtt 0.0724 TrainAcc 0.6100 TestAcc 0.5816 0.6100
epoch 1300 LossPred 0.9480 LossAtt 0.0713 TrainAcc 0.6100 TestAcc 0.5816 0.6100
epoch 1400 LossPred 0.9482 LossAtt 0.0690 TrainAcc 0.6100 TestAcc 0.5816 0.6100
epoch 1500 LossPred 0.9484 LossAtt 0.0557 TrainAcc 0.6100 TestAcc 0.5816 0.6100
epoch 1600 LossPred 0.9489 LossAtt 0.0421 TrainAcc 0.6100 TestAcc 0.5816 0.6100
epoch 1700 LossPred 0.9486 LossAtt 0.0775 TrainAcc 0.6100 TestAcc 0.5816 0.6100
epoch 1800 LossPred 0.9494 LossAtt 0.0448 TrainAcc 0.6100 TestAcc 0.5816 0.6100
epoch 1900 LossPred 0.9500 LossAtt 0.0332 TrainAcc 0.6100 TestAcc 0.5816 0.6100
epoch 2000 LossPred 0.9504 LossAtt 0.0297 TrainAcc 0.6100 TestAcc 0.5816 0.6100
epoch 2100 LossPred 0.9508 LossAtt 0.0255 TrainAcc 0.6100 TestAcc 0.5816 0.6100
epoch 2200 LossPred 0.9508 LossAtt 0.0216 TrainAcc 0.6100 TestAcc 0.5816 0.6100
epoch 2300 LossPred 0.9507 LossAtt 0.0201 TrainAcc 0.6100 TestAcc 0.5816 0.6100
epoch 2400 LossPred 0.9506 LossAtt 0.0192 TrainAcc 0.6100 TestAcc 0.5816 0.6100
epoch 2500 LossPred 0.9503 LossAtt 0.0194 TrainAcc 0.6100 TestAcc 0.5816 0.6100
Optimization Finished!
********** replication  48  **********
epoch   0 LossPred 1.2605 LossAtt 1.0012 TrainAcc 0.4100 TestAcc 0.4622 0.4350
epoch 100 LossPred 0.9021 LossAtt 0.5119 TrainAcc 0.6300 TestAcc 0.5966 0.6400
epoch 200 LossPred 0.8541 LossAtt 0.4060 TrainAcc 0.6500 TestAcc 0.6019 0.6500
epoch 300 LossPred 0.8396 LossAtt 0.3572 TrainAcc 0.6500 TestAcc 0.6019 0.6500
epoch 400 LossPred 0.8248 LossAtt 0.2433 TrainAcc 0.6500 TestAcc 0.6019 0.6500
epoch 500 LossPred 0.8125 LossAtt 0.1956 TrainAcc 0.6500 TestAcc 0.6019 0.6500
epoch 600 LossPred 0.7838 LossAtt 0.2112 TrainAcc 0.7400 TestAcc 0.6481 0.7400
epoch 700 LossPred 0.5202 LossAtt 0.3844 TrainAcc 0.8500 TestAcc 0.7673 0.8500
epoch 800 LossPred 0.4171 LossAtt 0.3403 TrainAcc 0.8700 TestAcc 0.8031 0.8600
epoch 900 LossPred 0.3761 LossAtt 0.3682 TrainAcc 0.8800 TestAcc 0.8421 0.8600
epoch 1000 LossPred 0.3965 LossAtt 0.3596 TrainAcc 0.8700 TestAcc 0.7958 0.8650
epoch 1100 LossPred 0.3513 LossAtt 0.3358 TrainAcc 0.8800 TestAcc 0.8381 0.8650
epoch 1200 LossPred 0.3962 LossAtt 0.3316 TrainAcc 0.8500 TestAcc 0.8136 0.8500
epoch 1300 LossPred 0.3540 LossAtt 0.3425 TrainAcc 0.8800 TestAcc 0.8146 0.8650
epoch 1400 LossPred 0.2932 LossAtt 0.3529 TrainAcc 0.9200 TestAcc 0.8216 0.9150
epoch 1500 LossPred 0.2968 LossAtt 0.3393 TrainAcc 0.8800 TestAcc 0.8213 0.8850
epoch 1600 LossPred 0.3199 LossAtt 0.3221 TrainAcc 0.8900 TestAcc 0.8461 0.8900
epoch 1700 LossPred 0.2777 LossAtt 0.3583 TrainAcc 0.8900 TestAcc 0.8346 0.8850
epoch 1800 LossPred 0.4114 LossAtt 0.3268 TrainAcc 0.8600 TestAcc 0.7793 0.8600
epoch 1900 LossPred 0.2859 LossAtt 0.3252 TrainAcc 0.9100 TestAcc 0.8338 0.9100
epoch 2000 LossPred 0.3017 LossAtt 0.3302 TrainAcc 0.8800 TestAcc 0.8554 0.8850
epoch 2100 LossPred 0.3421 LossAtt 0.3279 TrainAcc 0.8800 TestAcc 0.8213 0.8800
epoch 2200 LossPred 0.2968 LossAtt 0.3299 TrainAcc 0.9000 TestAcc 0.8656 0.9000
epoch 2300 LossPred 0.2873 LossAtt 0.3174 TrainAcc 0.8800 TestAcc 0.8649 0.9000
epoch 2400 LossPred 0.2574 LossAtt 0.3214 TrainAcc 0.9200 TestAcc 0.8784 0.9250
epoch 2500 LossPred 0.2501 LossAtt 0.3368 TrainAcc 0.9200 TestAcc 0.8794 0.9150
Optimization Finished!
********** replication  49  **********
epoch   0 LossPred 1.1494 LossAtt 1.0136 TrainAcc 0.4200 TestAcc 0.5003 0.4050
epoch 100 LossPred 0.8581 LossAtt 0.4312 TrainAcc 0.6800 TestAcc 0.5878 0.6800
epoch 200 LossPred 0.8359 LossAtt 0.3525 TrainAcc 0.6800 TestAcc 0.5878 0.6800
epoch 300 LossPred 0.8176 LossAtt 0.2714 TrainAcc 0.6800 TestAcc 0.5878 0.6950
epoch 400 LossPred 0.7403 LossAtt 0.3498 TrainAcc 0.7100 TestAcc 0.6827 0.7050
epoch 500 LossPred 0.4655 LossAtt 0.3633 TrainAcc 0.8300 TestAcc 0.8126 0.8350
epoch 600 LossPred 0.4217 LossAtt 0.3556 TrainAcc 0.8800 TestAcc 0.8158 0.8750
epoch 700 LossPred 0.3818 LossAtt 0.3075 TrainAcc 0.8700 TestAcc 0.8491 0.8850
epoch 800 LossPred 0.4120 LossAtt 0.3280 TrainAcc 0.8700 TestAcc 0.8298 0.8550
epoch 900 LossPred 0.4301 LossAtt 0.3712 TrainAcc 0.8600 TestAcc 0.8036 0.8450
epoch 1000 LossPred 0.3213 LossAtt 0.3131 TrainAcc 0.9100 TestAcc 0.8413 0.8700
epoch 1100 LossPred 0.3296 LossAtt 0.3088 TrainAcc 0.8900 TestAcc 0.8486 0.9000
epoch 1200 LossPred 0.4007 LossAtt 0.3170 TrainAcc 0.8700 TestAcc 0.8253 0.8550
epoch 1300 LossPred 0.3597 LossAtt 0.2915 TrainAcc 0.8700 TestAcc 0.8368 0.8700
epoch 1400 LossPred 0.2889 LossAtt 0.3002 TrainAcc 0.9100 TestAcc 0.8599 0.8950
epoch 1500 LossPred 0.3528 LossAtt 0.2754 TrainAcc 0.8900 TestAcc 0.8311 0.8800
epoch 1600 LossPred 0.5048 LossAtt 0.3013 TrainAcc 0.8200 TestAcc 0.7865 0.8100
epoch 1700 LossPred 0.3109 LossAtt 0.2925 TrainAcc 0.9000 TestAcc 0.8441 0.8950
epoch 1800 LossPred 0.2384 LossAtt 0.2851 TrainAcc 0.9400 TestAcc 0.8601 0.9150
epoch 1900 LossPred 0.2575 LossAtt 0.2872 TrainAcc 0.9200 TestAcc 0.8649 0.9100
epoch 2000 LossPred 0.5403 LossAtt 0.2834 TrainAcc 0.8300 TestAcc 0.7598 0.8200
epoch 2100 LossPred 0.8376 LossAtt 0.2735 TrainAcc 0.7000 TestAcc 0.6924 0.6900
epoch 2200 LossPred 0.3098 LossAtt 0.3096 TrainAcc 0.9100 TestAcc 0.8461 0.9000
epoch 2300 LossPred 0.3283 LossAtt 0.3110 TrainAcc 0.9000 TestAcc 0.8233 0.8850
epoch 2400 LossPred 0.3021 LossAtt 0.3076 TrainAcc 0.9100 TestAcc 0.8433 0.9000
epoch 2500 LossPred 0.2677 LossAtt 0.3247 TrainAcc 0.9100 TestAcc 0.8621 0.9050
Optimization Finished!
********** replication  50  **********
epoch   0 LossPred 0.9885 LossAtt 1.0018 TrainAcc 0.5300 TestAcc 0.4900 0.5300
epoch 100 LossPred 0.9465 LossAtt 0.3947 TrainAcc 0.5800 TestAcc 0.5000 0.5700
epoch 200 LossPred 0.9413 LossAtt 0.3112 TrainAcc 0.5700 TestAcc 0.5030 0.5700
epoch 300 LossPred 0.9530 LossAtt 0.2665 TrainAcc 0.5700 TestAcc 0.5781 0.5700
epoch 400 LossPred 0.8142 LossAtt 0.3993 TrainAcc 0.6900 TestAcc 0.6436 0.7100
epoch 500 LossPred 0.1654 LossAtt 0.3371 TrainAcc 0.9400 TestAcc 0.8671 0.9050
epoch 600 LossPred 0.1521 LossAtt 0.3311 TrainAcc 0.9500 TestAcc 0.8689 0.9100
epoch 700 LossPred 0.1550 LossAtt 0.3201 TrainAcc 0.9500 TestAcc 0.8691 0.9250
epoch 800 LossPred 0.1475 LossAtt 0.3221 TrainAcc 0.9700 TestAcc 0.8674 0.9050
epoch 900 LossPred 0.1418 LossAtt 0.3147 TrainAcc 0.9600 TestAcc 0.8744 0.9200
epoch 1000 LossPred 0.1326 LossAtt 0.3219 TrainAcc 0.9600 TestAcc 0.8734 0.9200
epoch 1100 LossPred 0.1321 LossAtt 0.3068 TrainAcc 0.9600 TestAcc 0.8736 0.9250
epoch 1200 LossPred 0.1242 LossAtt 0.2961 TrainAcc 0.9600 TestAcc 0.8751 0.9250
epoch 1300 LossPred 0.1450 LossAtt 0.3025 TrainAcc 0.9500 TestAcc 0.8766 0.9300
epoch 1400 LossPred 0.1301 LossAtt 0.2864 TrainAcc 0.9600 TestAcc 0.8849 0.9250
epoch 1500 LossPred 0.1238 LossAtt 0.2867 TrainAcc 0.9600 TestAcc 0.8836 0.9450
epoch 1600 LossPred 0.1322 LossAtt 0.2757 TrainAcc 0.9700 TestAcc 0.8811 0.9200
epoch 1700 LossPred 0.1364 LossAtt 0.2722 TrainAcc 0.9600 TestAcc 0.8816 0.9250
epoch 1800 LossPred 0.1299 LossAtt 0.2684 TrainAcc 0.9500 TestAcc 0.8846 0.9350
epoch 1900 LossPred 0.1366 LossAtt 0.2657 TrainAcc 0.9600 TestAcc 0.8814 0.9300
epoch 2000 LossPred 0.1139 LossAtt 0.2512 TrainAcc 0.9600 TestAcc 0.8856 0.9300
epoch 2100 LossPred 0.1260 LossAtt 0.2560 TrainAcc 0.9600 TestAcc 0.8909 0.9350
epoch 2200 LossPred 0.1129 LossAtt 0.2645 TrainAcc 0.9600 TestAcc 0.8874 0.9400
epoch 2300 LossPred 0.1288 LossAtt 0.2458 TrainAcc 0.9500 TestAcc 0.8781 0.9200
epoch 2400 LossPred 0.1386 LossAtt 0.2441 TrainAcc 0.9500 TestAcc 0.8801 0.9200
epoch 2500 LossPred 0.1135 LossAtt 0.2454 TrainAcc 0.9600 TestAcc 0.8861 0.9300
Optimization Finished!
********** replication  51  **********
epoch   0 LossPred 1.2608 LossAtt 1.0121 TrainAcc 0.4400 TestAcc 0.4642 0.4350
epoch 100 LossPred 0.9380 LossAtt 0.5422 TrainAcc 0.5800 TestAcc 0.5020 0.5850
epoch 200 LossPred 0.8619 LossAtt 0.5497 TrainAcc 0.6700 TestAcc 0.5343 0.6700
epoch 300 LossPred 0.8252 LossAtt 0.5340 TrainAcc 0.6900 TestAcc 0.5538 0.6800
epoch 400 LossPred 0.8104 LossAtt 0.5070 TrainAcc 0.6900 TestAcc 0.5455 0.6800
epoch 500 LossPred 0.7989 LossAtt 0.4513 TrainAcc 0.6900 TestAcc 0.5433 0.6850
epoch 600 LossPred 0.7905 LossAtt 0.3972 TrainAcc 0.6900 TestAcc 0.5433 0.6900
epoch 700 LossPred 0.7881 LossAtt 0.3555 TrainAcc 0.6900 TestAcc 0.5433 0.6900
epoch 800 LossPred 0.7843 LossAtt 0.2943 TrainAcc 0.6900 TestAcc 0.5433 0.6900
epoch 900 LossPred 0.7809 LossAtt 0.2556 TrainAcc 0.6900 TestAcc 0.5433 0.6900
epoch 1000 LossPred 0.7808 LossAtt 0.2118 TrainAcc 0.6900 TestAcc 0.5433 0.6900
epoch 1100 LossPred 0.7686 LossAtt 0.2647 TrainAcc 0.7100 TestAcc 0.5583 0.7050
epoch 1200 LossPred 0.7586 LossAtt 0.3148 TrainAcc 0.7600 TestAcc 0.6024 0.7400
epoch 1300 LossPred 0.7038 LossAtt 0.3338 TrainAcc 0.7700 TestAcc 0.6281 0.7600
epoch 1400 LossPred 0.6803 LossAtt 0.3607 TrainAcc 0.7700 TestAcc 0.6269 0.7450
epoch 1500 LossPred 0.6570 LossAtt 0.4001 TrainAcc 0.7700 TestAcc 0.6391 0.7500
epoch 1600 LossPred 0.6337 LossAtt 0.3792 TrainAcc 0.7600 TestAcc 0.6524 0.7350
epoch 1700 LossPred 0.6163 LossAtt 0.4315 TrainAcc 0.8100 TestAcc 0.6627 0.7600
epoch 1800 LossPred 0.6242 LossAtt 0.4559 TrainAcc 0.7900 TestAcc 0.6537 0.7600
epoch 1900 LossPred 0.6136 LossAtt 0.4241 TrainAcc 0.7900 TestAcc 0.6549 0.7450
epoch 2000 LossPred 0.6119 LossAtt 0.4340 TrainAcc 0.7800 TestAcc 0.6612 0.7650
epoch 2100 LossPred 0.6379 LossAtt 0.4445 TrainAcc 0.7600 TestAcc 0.6537 0.7600
epoch 2200 LossPred 0.5970 LossAtt 0.4439 TrainAcc 0.8100 TestAcc 0.6476 0.7800
epoch 2300 LossPred 0.5958 LossAtt 0.4660 TrainAcc 0.8100 TestAcc 0.6451 0.7800
epoch 2400 LossPred 0.5894 LossAtt 0.4681 TrainAcc 0.7900 TestAcc 0.6449 0.7700
epoch 2500 LossPred 0.5733 LossAtt 0.4649 TrainAcc 0.8000 TestAcc 0.6512 0.7850
Optimization Finished!
********** replication  52  **********
epoch   0 LossPred 0.9693 LossAtt 1.0206 TrainAcc 0.6200 TestAcc 0.5008 0.5700
epoch 100 LossPred 0.8348 LossAtt 0.4146 TrainAcc 0.6700 TestAcc 0.5876 0.6800
epoch 200 LossPred 0.7816 LossAtt 0.3779 TrainAcc 0.7200 TestAcc 0.5886 0.7200
epoch 300 LossPred 0.5860 LossAtt 0.3685 TrainAcc 0.7900 TestAcc 0.7563 0.8000
epoch 400 LossPred 0.4304 LossAtt 0.3302 TrainAcc 0.8600 TestAcc 0.8268 0.8600
epoch 500 LossPred 0.3918 LossAtt 0.3035 TrainAcc 0.8700 TestAcc 0.8318 0.8800
epoch 600 LossPred 0.3914 LossAtt 0.2838 TrainAcc 0.8700 TestAcc 0.8328 0.8750
epoch 700 LossPred 0.3420 LossAtt 0.2679 TrainAcc 0.9000 TestAcc 0.8551 0.9050
epoch 800 LossPred 0.3927 LossAtt 0.2619 TrainAcc 0.8700 TestAcc 0.8176 0.8650
epoch 900 LossPred 0.5820 LossAtt 0.2512 TrainAcc 0.8200 TestAcc 0.8241 0.8250
epoch 1000 LossPred 0.3953 LossAtt 0.2521 TrainAcc 0.8800 TestAcc 0.8178 0.8700
epoch 1100 LossPred 0.3843 LossAtt 0.2622 TrainAcc 0.8800 TestAcc 0.8333 0.8850
epoch 1200 LossPred 0.5179 LossAtt 0.2338 TrainAcc 0.7900 TestAcc 0.8003 0.8050
epoch 1300 LossPred 0.3779 LossAtt 0.2487 TrainAcc 0.8700 TestAcc 0.8478 0.8900
epoch 1400 LossPred 0.3694 LossAtt 0.2559 TrainAcc 0.8900 TestAcc 0.8393 0.8850
epoch 1500 LossPred 0.3773 LossAtt 0.2451 TrainAcc 0.8900 TestAcc 0.8343 0.8850
epoch 1600 LossPred 0.5004 LossAtt 0.2380 TrainAcc 0.8400 TestAcc 0.8371 0.8450
epoch 1700 LossPred 0.4716 LossAtt 0.2260 TrainAcc 0.8200 TestAcc 0.7808 0.8150
epoch 1800 LossPred 0.5199 LossAtt 0.2488 TrainAcc 0.8300 TestAcc 0.8273 0.8400
epoch 1900 LossPred 0.7862 LossAtt 0.2242 TrainAcc 0.7000 TestAcc 0.6769 0.6900
epoch 2000 LossPred 0.5781 LossAtt 0.2416 TrainAcc 0.8100 TestAcc 0.8161 0.8300
epoch 2100 LossPred 0.4411 LossAtt 0.2692 TrainAcc 0.8300 TestAcc 0.7778 0.8300
epoch 2200 LossPred 0.7667 LossAtt 0.2733 TrainAcc 0.7100 TestAcc 0.6744 0.7000
epoch 2300 LossPred 0.3992 LossAtt 0.2537 TrainAcc 0.8600 TestAcc 0.8043 0.8350
epoch 2400 LossPred 0.4337 LossAtt 0.2982 TrainAcc 0.8600 TestAcc 0.8276 0.8600
epoch 2500 LossPred 0.5457 LossAtt 0.3060 TrainAcc 0.8300 TestAcc 0.8221 0.8250
Optimization Finished!
********** replication  53  **********
epoch   0 LossPred 1.1526 LossAtt 1.0011 TrainAcc 0.4100 TestAcc 0.4617 0.4300
epoch 100 LossPred 0.9264 LossAtt 0.4449 TrainAcc 0.6200 TestAcc 0.5891 0.6200
epoch 200 LossPred 0.9097 LossAtt 0.3968 TrainAcc 0.6200 TestAcc 0.5891 0.6200
epoch 300 LossPred 0.9046 LossAtt 0.3605 TrainAcc 0.6200 TestAcc 0.5891 0.6200
epoch 400 LossPred 0.9016 LossAtt 0.3355 TrainAcc 0.6200 TestAcc 0.5908 0.6450
epoch 500 LossPred 0.8991 LossAtt 0.2972 TrainAcc 0.6500 TestAcc 0.6211 0.6400
epoch 600 LossPred 0.8989 LossAtt 0.3002 TrainAcc 0.6500 TestAcc 0.6271 0.6400
epoch 700 LossPred 0.8987 LossAtt 0.2713 TrainAcc 0.6500 TestAcc 0.6324 0.6500
epoch 800 LossPred 0.8970 LossAtt 0.2291 TrainAcc 0.6500 TestAcc 0.6211 0.6500
epoch 900 LossPred 0.8974 LossAtt 0.1962 TrainAcc 0.6500 TestAcc 0.6211 0.6450
epoch 1000 LossPred 0.8978 LossAtt 0.1610 TrainAcc 0.6200 TestAcc 0.6049 0.6350
epoch 1100 LossPred 0.8989 LossAtt 0.1628 TrainAcc 0.6400 TestAcc 0.6309 0.6350
epoch 1200 LossPred 0.8989 LossAtt 0.1978 TrainAcc 0.6500 TestAcc 0.6271 0.6450
epoch 1300 LossPred 0.8947 LossAtt 0.1958 TrainAcc 0.6500 TestAcc 0.6271 0.6500
epoch 1400 LossPred 0.8964 LossAtt 0.2278 TrainAcc 0.6500 TestAcc 0.6271 0.6650
epoch 1500 LossPred 0.8935 LossAtt 0.1584 TrainAcc 0.6500 TestAcc 0.6271 0.6550
epoch 1600 LossPred 0.8949 LossAtt 0.1546 TrainAcc 0.6500 TestAcc 0.6271 0.6650
epoch 1700 LossPred 0.8935 LossAtt 0.1716 TrainAcc 0.6500 TestAcc 0.6271 0.6500
epoch 1800 LossPred 0.8898 LossAtt 0.2534 TrainAcc 0.6500 TestAcc 0.6271 0.6500
epoch 1900 LossPred 0.8848 LossAtt 0.4334 TrainAcc 0.6500 TestAcc 0.6271 0.6600
epoch 2000 LossPred 0.8882 LossAtt 0.3098 TrainAcc 0.6200 TestAcc 0.6049 0.6350
epoch 2100 LossPred 0.8793 LossAtt 0.2926 TrainAcc 0.6200 TestAcc 0.6186 0.6200
epoch 2200 LossPred 0.8697 LossAtt 0.2867 TrainAcc 0.6600 TestAcc 0.6264 0.6400
epoch 2300 LossPred 0.7478 LossAtt 0.4445 TrainAcc 0.7000 TestAcc 0.6394 0.6900
epoch 2400 LossPred 0.4937 LossAtt 0.4257 TrainAcc 0.8300 TestAcc 0.8176 0.8300
epoch 2500 LossPred 0.3126 LossAtt 0.3819 TrainAcc 0.9000 TestAcc 0.8498 0.8650
Optimization Finished!
********** replication  54  **********
epoch   0 LossPred 1.0363 LossAtt 0.9955 TrainAcc 0.3900 TestAcc 0.4690 0.4000
epoch 100 LossPred 0.8854 LossAtt 0.2363 TrainAcc 0.6500 TestAcc 0.5846 0.6500
epoch 200 LossPred 0.8662 LossAtt 0.1198 TrainAcc 0.6500 TestAcc 0.5846 0.6500
epoch 300 LossPred 0.8499 LossAtt 0.0910 TrainAcc 0.6500 TestAcc 0.5846 0.6500
epoch 400 LossPred 0.8531 LossAtt 0.0804 TrainAcc 0.6500 TestAcc 0.5846 0.6500
epoch 500 LossPred 0.8680 LossAtt 0.0804 TrainAcc 0.6500 TestAcc 0.5846 0.6500
epoch 600 LossPred 0.8742 LossAtt 0.0968 TrainAcc 0.6500 TestAcc 0.5846 0.6500
epoch 700 LossPred 0.8806 LossAtt 0.1143 TrainAcc 0.6500 TestAcc 0.5846 0.6500
epoch 800 LossPred 0.8869 LossAtt 0.1314 TrainAcc 0.6500 TestAcc 0.5846 0.6500
epoch 900 LossPred 0.8909 LossAtt 0.1134 TrainAcc 0.6500 TestAcc 0.5846 0.6500
epoch 1000 LossPred 0.8891 LossAtt 0.0960 TrainAcc 0.6500 TestAcc 0.5846 0.6500
epoch 1100 LossPred 0.8918 LossAtt 0.1416 TrainAcc 0.6500 TestAcc 0.5846 0.6500
epoch 1200 LossPred 0.9019 LossAtt 0.1252 TrainAcc 0.6500 TestAcc 0.5846 0.6500
epoch 1300 LossPred 0.9008 LossAtt 0.1005 TrainAcc 0.6500 TestAcc 0.5846 0.6500
epoch 1400 LossPred 0.8982 LossAtt 0.0806 TrainAcc 0.6500 TestAcc 0.5846 0.6500
epoch 1500 LossPred 0.9017 LossAtt 0.0787 TrainAcc 0.6500 TestAcc 0.5846 0.6500
epoch 1600 LossPred 0.9081 LossAtt 0.1081 TrainAcc 0.6500 TestAcc 0.5846 0.6500
epoch 1700 LossPred 0.9105 LossAtt 0.0856 TrainAcc 0.6500 TestAcc 0.5846 0.6500
epoch 1800 LossPred 0.9110 LossAtt 0.0742 TrainAcc 0.6500 TestAcc 0.5846 0.6500
epoch 1900 LossPred 0.9109 LossAtt 0.0764 TrainAcc 0.6500 TestAcc 0.5846 0.6500
epoch 2000 LossPred 0.9106 LossAtt 0.0902 TrainAcc 0.6500 TestAcc 0.5846 0.6500
epoch 2100 LossPred 0.9104 LossAtt 0.0713 TrainAcc 0.6500 TestAcc 0.5846 0.6500
epoch 2200 LossPred 0.9103 LossAtt 0.0801 TrainAcc 0.6500 TestAcc 0.5846 0.6500
epoch 2300 LossPred 0.9102 LossAtt 0.0715 TrainAcc 0.6500 TestAcc 0.5846 0.6500
epoch 2400 LossPred 0.9101 LossAtt 0.0510 TrainAcc 0.6500 TestAcc 0.5846 0.6500
epoch 2500 LossPred 0.9101 LossAtt 0.0433 TrainAcc 0.6500 TestAcc 0.5846 0.6500
Optimization Finished!
********** replication  55  **********
epoch   0 LossPred 1.0468 LossAtt 0.9991 TrainAcc 0.5100 TestAcc 0.4117 0.5100
epoch 100 LossPred 0.8693 LossAtt 0.3265 TrainAcc 0.6700 TestAcc 0.5663 0.6700
epoch 200 LossPred 0.9147 LossAtt 0.1708 TrainAcc 0.6300 TestAcc 0.6119 0.6300
epoch 300 LossPred 0.8411 LossAtt 0.2106 TrainAcc 0.6800 TestAcc 0.5490 0.6800
epoch 400 LossPred 0.8098 LossAtt 0.2024 TrainAcc 0.6800 TestAcc 0.5490 0.6800
epoch 500 LossPred 0.7927 LossAtt 0.2048 TrainAcc 0.6800 TestAcc 0.5490 0.6800
epoch 600 LossPred 0.7582 LossAtt 0.3643 TrainAcc 0.7400 TestAcc 0.6569 0.7350
epoch 700 LossPred 0.4524 LossAtt 0.4612 TrainAcc 0.8500 TestAcc 0.8539 0.8700
epoch 800 LossPred 0.3140 LossAtt 0.4716 TrainAcc 0.9100 TestAcc 0.8751 0.9100
epoch 900 LossPred 0.3193 LossAtt 0.5158 TrainAcc 0.8900 TestAcc 0.8476 0.8750
epoch 1000 LossPred 0.2487 LossAtt 0.4740 TrainAcc 0.9100 TestAcc 0.8706 0.9250
epoch 1100 LossPred 0.2930 LossAtt 0.4733 TrainAcc 0.9200 TestAcc 0.8891 0.9150
epoch 1200 LossPred 0.2973 LossAtt 0.4727 TrainAcc 0.9300 TestAcc 0.8906 0.9100
epoch 1300 LossPred 0.2379 LossAtt 0.4827 TrainAcc 0.9400 TestAcc 0.8806 0.9150
epoch 1400 LossPred 0.2480 LossAtt 0.5002 TrainAcc 0.9200 TestAcc 0.8586 0.9100
epoch 1500 LossPred 0.3543 LossAtt 0.4962 TrainAcc 0.8700 TestAcc 0.8754 0.8900
epoch 1600 LossPred 0.3530 LossAtt 0.4823 TrainAcc 0.8900 TestAcc 0.8749 0.9050
epoch 1700 LossPred 0.2417 LossAtt 0.4699 TrainAcc 0.9400 TestAcc 0.8749 0.9150
epoch 1800 LossPred 0.2505 LossAtt 0.4952 TrainAcc 0.9100 TestAcc 0.8824 0.9250
epoch 1900 LossPred 0.2421 LossAtt 0.4841 TrainAcc 0.9400 TestAcc 0.8771 0.9100
epoch 2000 LossPred 0.3234 LossAtt 0.5016 TrainAcc 0.8600 TestAcc 0.8801 0.8750
epoch 2100 LossPred 0.2635 LossAtt 0.4913 TrainAcc 0.9000 TestAcc 0.8814 0.9300
epoch 2200 LossPred 0.2606 LossAtt 0.4848 TrainAcc 0.9100 TestAcc 0.8834 0.9300
epoch 2300 LossPred 0.2553 LossAtt 0.4778 TrainAcc 0.9100 TestAcc 0.8626 0.9050
epoch 2400 LossPred 0.2475 LossAtt 0.4613 TrainAcc 0.9300 TestAcc 0.8761 0.9200
epoch 2500 LossPred 0.3129 LossAtt 0.5046 TrainAcc 0.9100 TestAcc 0.8699 0.8900
Optimization Finished!
********** replication  56  **********
epoch   0 LossPred 1.0591 LossAtt 1.0107 TrainAcc 0.5800 TestAcc 0.5340 0.5400
epoch 100 LossPred 0.9447 LossAtt 0.3140 TrainAcc 0.6200 TestAcc 0.5938 0.6200
epoch 200 LossPred 0.9431 LossAtt 0.2347 TrainAcc 0.6200 TestAcc 0.5938 0.6200
epoch 300 LossPred 0.9413 LossAtt 0.1943 TrainAcc 0.6200 TestAcc 0.5938 0.6200
epoch 400 LossPred 0.9346 LossAtt 0.2048 TrainAcc 0.6200 TestAcc 0.5938 0.6200
epoch 500 LossPred 0.9290 LossAtt 0.1961 TrainAcc 0.6200 TestAcc 0.5938 0.6200
epoch 600 LossPred 0.9225 LossAtt 0.1949 TrainAcc 0.6200 TestAcc 0.5938 0.6200
epoch 700 LossPred 0.9146 LossAtt 0.1644 TrainAcc 0.6200 TestAcc 0.5938 0.6200
epoch 800 LossPred 0.9389 LossAtt 0.2446 TrainAcc 0.6200 TestAcc 0.5938 0.6200
epoch 900 LossPred 0.9360 LossAtt 0.3525 TrainAcc 0.6200 TestAcc 0.5938 0.6200
epoch 1000 LossPred 0.9375 LossAtt 0.1977 TrainAcc 0.6200 TestAcc 0.5938 0.6200
epoch 1100 LossPred 0.9373 LossAtt 0.1862 TrainAcc 0.6200 TestAcc 0.5938 0.6200
epoch 1200 LossPred 0.9403 LossAtt 0.1960 TrainAcc 0.6200 TestAcc 0.5938 0.6200
epoch 1300 LossPred 0.9280 LossAtt 0.2761 TrainAcc 0.6200 TestAcc 0.5938 0.6200
epoch 1400 LossPred 0.8729 LossAtt 0.3480 TrainAcc 0.5900 TestAcc 0.5891 0.6250
epoch 1500 LossPred 0.7453 LossAtt 0.5121 TrainAcc 0.7500 TestAcc 0.6894 0.7300
epoch 1600 LossPred 0.3734 LossAtt 0.4790 TrainAcc 0.8700 TestAcc 0.8261 0.8650
epoch 1700 LossPred 0.3257 LossAtt 0.4740 TrainAcc 0.8700 TestAcc 0.8448 0.8900
epoch 1800 LossPred 0.2896 LossAtt 0.4577 TrainAcc 0.9100 TestAcc 0.8446 0.9000
epoch 1900 LossPred 0.2718 LossAtt 0.4821 TrainAcc 0.9100 TestAcc 0.8496 0.9100
epoch 2000 LossPred 0.3015 LossAtt 0.5158 TrainAcc 0.9100 TestAcc 0.8376 0.9250
epoch 2100 LossPred 0.2845 LossAtt 0.5129 TrainAcc 0.9200 TestAcc 0.8446 0.9200
epoch 2200 LossPred 0.2347 LossAtt 0.5103 TrainAcc 0.9300 TestAcc 0.8626 0.9150
epoch 2300 LossPred 0.2224 LossAtt 0.5275 TrainAcc 0.9300 TestAcc 0.8676 0.9150
epoch 2400 LossPred 0.3607 LossAtt 0.5358 TrainAcc 0.9000 TestAcc 0.8073 0.9050
epoch 2500 LossPred 0.2363 LossAtt 0.5241 TrainAcc 0.9300 TestAcc 0.8716 0.9100
Optimization Finished!
********** replication  57  **********
epoch   0 LossPred 1.0368 LossAtt 1.0194 TrainAcc 0.5100 TestAcc 0.5551 0.5100
epoch 100 LossPred 0.9494 LossAtt 0.3327 TrainAcc 0.5800 TestAcc 0.5868 0.5800
epoch 200 LossPred 0.9348 LossAtt 0.3339 TrainAcc 0.5800 TestAcc 0.5868 0.5750
epoch 300 LossPred 0.7849 LossAtt 0.3740 TrainAcc 0.8100 TestAcc 0.6992 0.7650
epoch 400 LossPred 0.6754 LossAtt 0.4342 TrainAcc 0.7700 TestAcc 0.7277 0.7550
epoch 500 LossPred 0.3394 LossAtt 0.4351 TrainAcc 0.9100 TestAcc 0.8233 0.8850
epoch 600 LossPred 0.3370 LossAtt 0.3985 TrainAcc 0.8700 TestAcc 0.8386 0.8900
epoch 700 LossPred 0.2349 LossAtt 0.3935 TrainAcc 0.9100 TestAcc 0.8596 0.9150
epoch 800 LossPred 0.2237 LossAtt 0.3898 TrainAcc 0.9300 TestAcc 0.8771 0.8950
epoch 900 LossPred 0.1462 LossAtt 0.3661 TrainAcc 0.9700 TestAcc 0.8919 0.9150
epoch 1000 LossPred 0.1286 LossAtt 0.3520 TrainAcc 0.9900 TestAcc 0.9102 0.9400
epoch 1100 LossPred 0.1506 LossAtt 0.3255 TrainAcc 0.9700 TestAcc 0.8791 0.9650
epoch 1200 LossPred 0.2386 LossAtt 0.3261 TrainAcc 0.9300 TestAcc 0.8849 0.9200
epoch 1300 LossPred 0.3952 LossAtt 0.3200 TrainAcc 0.8700 TestAcc 0.8103 0.8550
epoch 1400 LossPred 0.1321 LossAtt 0.2853 TrainAcc 0.9800 TestAcc 0.9252 0.9700
epoch 1500 LossPred 0.3634 LossAtt 0.2733 TrainAcc 0.8800 TestAcc 0.8981 0.9000
epoch 1600 LossPred 0.2284 LossAtt 0.2780 TrainAcc 0.9200 TestAcc 0.9007 0.9500
epoch 1700 LossPred 0.3537 LossAtt 0.2913 TrainAcc 0.8900 TestAcc 0.8206 0.8850
epoch 1800 LossPred 0.3917 LossAtt 0.2887 TrainAcc 0.8800 TestAcc 0.8181 0.8650
epoch 1900 LossPred 0.1662 LossAtt 0.2726 TrainAcc 0.9500 TestAcc 0.8931 0.9350
epoch 2000 LossPred 0.4104 LossAtt 0.2707 TrainAcc 0.8700 TestAcc 0.8498 0.8850
epoch 2100 LossPred 0.3858 LossAtt 0.2728 TrainAcc 0.8800 TestAcc 0.8176 0.8750
epoch 2200 LossPred 0.3567 LossAtt 0.2750 TrainAcc 0.8600 TestAcc 0.8233 0.8750
epoch 2300 LossPred 0.3762 LossAtt 0.2515 TrainAcc 0.8700 TestAcc 0.8641 0.8900
epoch 2400 LossPred 0.2245 LossAtt 0.2722 TrainAcc 0.9300 TestAcc 0.8596 0.9200
epoch 2500 LossPred 0.4577 LossAtt 0.2749 TrainAcc 0.8300 TestAcc 0.8043 0.8350
Optimization Finished!
********** replication  58  **********
epoch   0 LossPred 1.0551 LossAtt 0.9955 TrainAcc 0.5400 TestAcc 0.5428 0.5500
epoch 100 LossPred 0.8662 LossAtt 0.4269 TrainAcc 0.6500 TestAcc 0.5856 0.6300
epoch 200 LossPred 0.8315 LossAtt 0.4326 TrainAcc 0.6500 TestAcc 0.5856 0.6500
epoch 300 LossPred 0.4661 LossAtt 0.5008 TrainAcc 0.8800 TestAcc 0.8498 0.9350
epoch 400 LossPred 0.8148 LossAtt 0.4157 TrainAcc 0.7000 TestAcc 0.6802 0.7150
epoch 500 LossPred 0.9627 LossAtt 0.3636 TrainAcc 0.5000 TestAcc 0.5671 0.5050
epoch 600 LossPred 0.9972 LossAtt 0.2676 TrainAcc 0.4400 TestAcc 0.4520 0.4700
epoch 700 LossPred 0.9232 LossAtt 0.2403 TrainAcc 0.6500 TestAcc 0.5856 0.6500
epoch 800 LossPred 0.9024 LossAtt 0.2244 TrainAcc 0.6500 TestAcc 0.5856 0.6500
epoch 900 LossPred 0.8931 LossAtt 0.2120 TrainAcc 0.6500 TestAcc 0.5856 0.6500
epoch 1000 LossPred 0.8881 LossAtt 0.2076 TrainAcc 0.6500 TestAcc 0.5856 0.6500
epoch 1100 LossPred 0.8864 LossAtt 0.2257 TrainAcc 0.6500 TestAcc 0.5856 0.6500
epoch 1200 LossPred 0.8808 LossAtt 0.1939 TrainAcc 0.6500 TestAcc 0.5856 0.6500
epoch 1300 LossPred 0.8805 LossAtt 0.1976 TrainAcc 0.6500 TestAcc 0.5856 0.6500
epoch 1400 LossPred 0.8747 LossAtt 0.1788 TrainAcc 0.6500 TestAcc 0.5856 0.6500
epoch 1500 LossPred 0.8729 LossAtt 0.1829 TrainAcc 0.6500 TestAcc 0.5856 0.6500
epoch 1600 LossPred 0.8682 LossAtt 0.1857 TrainAcc 0.6500 TestAcc 0.5856 0.6500
epoch 1700 LossPred 0.8628 LossAtt 0.1979 TrainAcc 0.6500 TestAcc 0.5856 0.6500
epoch 1800 LossPred 0.8704 LossAtt 0.2054 TrainAcc 0.6500 TestAcc 0.5856 0.6500
epoch 1900 LossPred 0.8652 LossAtt 0.2134 TrainAcc 0.6500 TestAcc 0.5856 0.6500
epoch 2000 LossPred 0.8418 LossAtt 0.2396 TrainAcc 0.6500 TestAcc 0.5856 0.6500
epoch 2100 LossPred 0.8322 LossAtt 0.2346 TrainAcc 0.6500 TestAcc 0.5856 0.6500
epoch 2200 LossPred 0.8425 LossAtt 0.2158 TrainAcc 0.6500 TestAcc 0.5856 0.6500
epoch 2300 LossPred 0.8493 LossAtt 0.2056 TrainAcc 0.6500 TestAcc 0.5856 0.6500
epoch 2400 LossPred 0.8456 LossAtt 0.2167 TrainAcc 0.6500 TestAcc 0.5856 0.6500
epoch 2500 LossPred 0.8412 LossAtt 0.2343 TrainAcc 0.6500 TestAcc 0.5856 0.6500
Optimization Finished!
********** replication  59  **********
epoch   0 LossPred 1.0340 LossAtt 1.0035 TrainAcc 0.5900 TestAcc 0.5193 0.5700
epoch 100 LossPred 0.9023 LossAtt 0.3626 TrainAcc 0.6200 TestAcc 0.5813 0.6200
epoch 200 LossPred 0.8958 LossAtt 0.3014 TrainAcc 0.6200 TestAcc 0.5813 0.6200
epoch 300 LossPred 0.8935 LossAtt 0.2678 TrainAcc 0.6200 TestAcc 0.5813 0.6200
epoch 400 LossPred 0.8906 LossAtt 0.2471 TrainAcc 0.6200 TestAcc 0.5813 0.6200
epoch 500 LossPred 0.8873 LossAtt 0.2536 TrainAcc 0.6200 TestAcc 0.5813 0.6200
epoch 600 LossPred 0.8921 LossAtt 0.1948 TrainAcc 0.6200 TestAcc 0.5813 0.6200
epoch 700 LossPred 0.8887 LossAtt 0.2062 TrainAcc 0.6200 TestAcc 0.5813 0.6200
epoch 800 LossPred 0.4627 LossAtt 0.4252 TrainAcc 0.8600 TestAcc 0.8654 0.8700
epoch 900 LossPred 0.7299 LossAtt 0.4042 TrainAcc 0.7600 TestAcc 0.6847 0.7550
epoch 1000 LossPred 0.8860 LossAtt 0.3418 TrainAcc 0.6700 TestAcc 0.6547 0.6600
epoch 1100 LossPred 0.4447 LossAtt 0.3361 TrainAcc 0.8600 TestAcc 0.8306 0.8400
epoch 1200 LossPred 0.3616 LossAtt 0.3190 TrainAcc 0.8800 TestAcc 0.8581 0.8400
epoch 1300 LossPred 0.3383 LossAtt 0.3078 TrainAcc 0.9000 TestAcc 0.8438 0.8550
epoch 1400 LossPred 0.4518 LossAtt 0.3044 TrainAcc 0.8600 TestAcc 0.8218 0.8350
epoch 1500 LossPred 0.4024 LossAtt 0.2979 TrainAcc 0.8600 TestAcc 0.8413 0.8450
epoch 1600 LossPred 0.4648 LossAtt 0.2804 TrainAcc 0.8300 TestAcc 0.8118 0.8150
epoch 1700 LossPred 0.4463 LossAtt 0.2804 TrainAcc 0.8500 TestAcc 0.8271 0.8500
epoch 1800 LossPred 0.4247 LossAtt 0.2882 TrainAcc 0.8400 TestAcc 0.8263 0.8450
epoch 1900 LossPred 0.7139 LossAtt 0.2802 TrainAcc 0.7700 TestAcc 0.7858 0.7450
epoch 2000 LossPred 0.4596 LossAtt 0.2705 TrainAcc 0.8500 TestAcc 0.8188 0.8350
epoch 2100 LossPred 0.3516 LossAtt 0.2736 TrainAcc 0.8800 TestAcc 0.8581 0.8450
epoch 2200 LossPred 0.3336 LossAtt 0.2649 TrainAcc 0.8900 TestAcc 0.8736 0.8400
epoch 2300 LossPred 0.4548 LossAtt 0.2549 TrainAcc 0.8500 TestAcc 0.8228 0.8350
epoch 2400 LossPred 0.3356 LossAtt 0.2468 TrainAcc 0.8900 TestAcc 0.8681 0.8350
epoch 2500 LossPred 0.4976 LossAtt 0.2540 TrainAcc 0.8200 TestAcc 0.8058 0.8050
Optimization Finished!
********** replication  60  **********
epoch   0 LossPred 1.0058 LossAtt 0.9821 TrainAcc 0.4800 TestAcc 0.5776 0.4650
epoch 100 LossPred 0.8718 LossAtt 0.4664 TrainAcc 0.6600 TestAcc 0.5873 0.6600
epoch 200 LossPred 0.8178 LossAtt 0.4996 TrainAcc 0.6900 TestAcc 0.6071 0.6750
epoch 300 LossPred 0.4680 LossAtt 0.4858 TrainAcc 0.8600 TestAcc 0.8666 0.8500
epoch 400 LossPred 0.3354 LossAtt 0.4633 TrainAcc 0.8900 TestAcc 0.8554 0.8650
epoch 500 LossPred 0.2843 LossAtt 0.4649 TrainAcc 0.9200 TestAcc 0.8601 0.8500
epoch 600 LossPred 0.2464 LossAtt 0.4734 TrainAcc 0.9200 TestAcc 0.8506 0.8700
epoch 700 LossPred 0.2925 LossAtt 0.4463 TrainAcc 0.9000 TestAcc 0.8426 0.8550
epoch 800 LossPred 0.2205 LossAtt 0.4694 TrainAcc 0.9500 TestAcc 0.8448 0.8850
epoch 900 LossPred 0.2149 LossAtt 0.4591 TrainAcc 0.9400 TestAcc 0.8381 0.8800
epoch 1000 LossPred 0.2005 LossAtt 0.4522 TrainAcc 0.9500 TestAcc 0.8356 0.9000
epoch 1100 LossPred 0.1944 LossAtt 0.4598 TrainAcc 0.9400 TestAcc 0.8293 0.8800
epoch 1200 LossPred 0.1741 LossAtt 0.4566 TrainAcc 0.9400 TestAcc 0.8481 0.8900
epoch 1300 LossPred 0.2040 LossAtt 0.4571 TrainAcc 0.9400 TestAcc 0.8323 0.8750
epoch 1400 LossPred 0.1951 LossAtt 0.4545 TrainAcc 0.9500 TestAcc 0.8466 0.9050
epoch 1500 LossPred 0.1635 LossAtt 0.4547 TrainAcc 0.9400 TestAcc 0.8376 0.8850
epoch 1600 LossPred 0.1684 LossAtt 0.4445 TrainAcc 0.9400 TestAcc 0.8443 0.8950
epoch 1700 LossPred 0.1677 LossAtt 0.4385 TrainAcc 0.9500 TestAcc 0.8431 0.8900
epoch 1800 LossPred 0.1658 LossAtt 0.4534 TrainAcc 0.9500 TestAcc 0.8356 0.8900
epoch 1900 LossPred 0.1784 LossAtt 0.4191 TrainAcc 0.9400 TestAcc 0.8341 0.8800
epoch 2000 LossPred 0.1713 LossAtt 0.4291 TrainAcc 0.9600 TestAcc 0.8246 0.8850
epoch 2100 LossPred 0.2588 LossAtt 0.4382 TrainAcc 0.8900 TestAcc 0.8401 0.8600
epoch 2200 LossPred 0.1717 LossAtt 0.4385 TrainAcc 0.9500 TestAcc 0.8261 0.8900
epoch 2300 LossPred 0.3962 LossAtt 0.4118 TrainAcc 0.8800 TestAcc 0.7868 0.8600
epoch 2400 LossPred 0.1753 LossAtt 0.4360 TrainAcc 0.9500 TestAcc 0.8361 0.9100
epoch 2500 LossPred 0.1662 LossAtt 0.4365 TrainAcc 0.9400 TestAcc 0.8278 0.8800
Optimization Finished!
********** replication  61  **********
epoch   0 LossPred 1.1016 LossAtt 1.0148 TrainAcc 0.4700 TestAcc 0.4882 0.4550
epoch 100 LossPred 0.9580 LossAtt 0.4272 TrainAcc 0.6000 TestAcc 0.5220 0.6000
epoch 200 LossPred 0.9538 LossAtt 0.3679 TrainAcc 0.6000 TestAcc 0.5180 0.6000
epoch 300 LossPred 0.9652 LossAtt 0.2698 TrainAcc 0.6000 TestAcc 0.5383 0.6100
epoch 400 LossPred 0.9655 LossAtt 0.2420 TrainAcc 0.5900 TestAcc 0.5916 0.5900
epoch 500 LossPred 0.9651 LossAtt 0.2314 TrainAcc 0.5900 TestAcc 0.5566 0.5950
epoch 600 LossPred 0.9636 LossAtt 0.2349 TrainAcc 0.5900 TestAcc 0.5916 0.5800
epoch 700 LossPred 0.9601 LossAtt 0.2439 TrainAcc 0.5900 TestAcc 0.5916 0.5700
epoch 800 LossPred 0.9552 LossAtt 0.3159 TrainAcc 0.6000 TestAcc 0.5383 0.6000
epoch 900 LossPred 0.9315 LossAtt 0.4778 TrainAcc 0.6000 TestAcc 0.5240 0.5900
epoch 1000 LossPred 0.8270 LossAtt 0.5485 TrainAcc 0.6800 TestAcc 0.5083 0.6650
epoch 1100 LossPred 0.8268 LossAtt 0.5352 TrainAcc 0.6900 TestAcc 0.4912 0.6650
epoch 1200 LossPred 0.8040 LossAtt 0.4938 TrainAcc 0.6900 TestAcc 0.5090 0.6650
epoch 1300 LossPred 0.8117 LossAtt 0.5220 TrainAcc 0.6800 TestAcc 0.5018 0.6700
epoch 1400 LossPred 0.7812 LossAtt 0.5124 TrainAcc 0.7100 TestAcc 0.5035 0.6800
epoch 1500 LossPred 0.7996 LossAtt 0.5145 TrainAcc 0.7100 TestAcc 0.5000 0.7100
epoch 1600 LossPred 0.8249 LossAtt 0.5210 TrainAcc 0.7000 TestAcc 0.4992 0.6800
epoch 1700 LossPred 0.7885 LossAtt 0.5147 TrainAcc 0.7000 TestAcc 0.5025 0.6750
epoch 1800 LossPred 0.7974 LossAtt 0.4905 TrainAcc 0.6900 TestAcc 0.5010 0.6700
epoch 1900 LossPred 0.7854 LossAtt 0.5166 TrainAcc 0.7200 TestAcc 0.5045 0.6900
epoch 2000 LossPred 0.8010 LossAtt 0.5046 TrainAcc 0.6800 TestAcc 0.5058 0.6700
epoch 2100 LossPred 0.7753 LossAtt 0.4994 TrainAcc 0.7200 TestAcc 0.5068 0.6850
epoch 2200 LossPred 0.7866 LossAtt 0.4988 TrainAcc 0.7200 TestAcc 0.5048 0.6900
epoch 2300 LossPred 0.8080 LossAtt 0.4970 TrainAcc 0.6900 TestAcc 0.4995 0.6700
epoch 2400 LossPred 0.7885 LossAtt 0.5039 TrainAcc 0.7000 TestAcc 0.4987 0.6600
epoch 2500 LossPred 0.8072 LossAtt 0.4940 TrainAcc 0.7000 TestAcc 0.4990 0.6700
Optimization Finished!
********** replication  62  **********
epoch   0 LossPred 1.1509 LossAtt 1.0370 TrainAcc 0.4300 TestAcc 0.4545 0.4450
epoch 100 LossPred 0.8904 LossAtt 0.4188 TrainAcc 0.6500 TestAcc 0.5971 0.6500
epoch 200 LossPred 0.8933 LossAtt 0.3022 TrainAcc 0.6500 TestAcc 0.5971 0.6500
epoch 300 LossPred 0.8997 LossAtt 0.2696 TrainAcc 0.6500 TestAcc 0.5971 0.6500
epoch 400 LossPred 0.8958 LossAtt 0.2598 TrainAcc 0.6500 TestAcc 0.5971 0.6500
epoch 500 LossPred 0.8909 LossAtt 0.2431 TrainAcc 0.6500 TestAcc 0.5971 0.6500
epoch 600 LossPred 0.8732 LossAtt 0.2398 TrainAcc 0.6500 TestAcc 0.5971 0.6500
epoch 700 LossPred 0.8519 LossAtt 0.3734 TrainAcc 0.6500 TestAcc 0.5971 0.6500
epoch 800 LossPred 0.7739 LossAtt 0.4796 TrainAcc 0.7400 TestAcc 0.6331 0.7400
epoch 900 LossPred 0.3273 LossAtt 0.6236 TrainAcc 0.9100 TestAcc 0.8153 0.9000
epoch 1000 LossPred 0.2718 LossAtt 0.5459 TrainAcc 0.9000 TestAcc 0.8556 0.8850
epoch 1100 LossPred 0.4109 LossAtt 0.5505 TrainAcc 0.8400 TestAcc 0.7708 0.8400
epoch 1200 LossPred 0.2425 LossAtt 0.5806 TrainAcc 0.9100 TestAcc 0.8736 0.8800
epoch 1300 LossPred 0.2106 LossAtt 0.5865 TrainAcc 0.9100 TestAcc 0.8819 0.9100
epoch 1400 LossPred 0.2718 LossAtt 0.5504 TrainAcc 0.9100 TestAcc 0.8428 0.8750
epoch 1500 LossPred 0.2942 LossAtt 0.5626 TrainAcc 0.9100 TestAcc 0.8036 0.8950
epoch 1600 LossPred 0.2339 LossAtt 0.5583 TrainAcc 0.9200 TestAcc 0.8316 0.9150
epoch 1700 LossPred 0.1592 LossAtt 0.5513 TrainAcc 0.9400 TestAcc 0.8759 0.9200
epoch 1800 LossPred 0.1466 LossAtt 0.5113 TrainAcc 0.9600 TestAcc 0.8949 0.9300
epoch 1900 LossPred 0.1353 LossAtt 0.5268 TrainAcc 0.9600 TestAcc 0.9017 0.9300
epoch 2000 LossPred 0.1246 LossAtt 0.5223 TrainAcc 0.9800 TestAcc 0.9042 0.9200
epoch 2100 LossPred 0.1292 LossAtt 0.5051 TrainAcc 0.9600 TestAcc 0.9114 0.9250
epoch 2200 LossPred 0.1756 LossAtt 0.4983 TrainAcc 0.9400 TestAcc 0.8921 0.9500
epoch 2300 LossPred 0.1488 LossAtt 0.4902 TrainAcc 0.9400 TestAcc 0.8954 0.9300
epoch 2400 LossPred 0.1751 LossAtt 0.4869 TrainAcc 0.9300 TestAcc 0.8819 0.9200
epoch 2500 LossPred 0.1724 LossAtt 0.4949 TrainAcc 0.9500 TestAcc 0.8801 0.9450
Optimization Finished!
********** replication  63  **********
epoch   0 LossPred 0.9880 LossAtt 1.0096 TrainAcc 0.5100 TestAcc 0.5300 0.5250
epoch 100 LossPred 0.9181 LossAtt 0.4221 TrainAcc 0.6500 TestAcc 0.5133 0.6500
epoch 200 LossPred 0.8934 LossAtt 0.3873 TrainAcc 0.6500 TestAcc 0.5120 0.6650
epoch 300 LossPred 0.8903 LossAtt 0.3584 TrainAcc 0.6500 TestAcc 0.5120 0.6550
epoch 400 LossPred 0.8827 LossAtt 0.3821 TrainAcc 0.6500 TestAcc 0.5355 0.6400
epoch 500 LossPred 0.8771 LossAtt 0.3926 TrainAcc 0.6500 TestAcc 0.5355 0.6400
epoch 600 LossPred 0.8689 LossAtt 0.4193 TrainAcc 0.6500 TestAcc 0.5355 0.6400
epoch 700 LossPred 1.0030 LossAtt 0.4752 TrainAcc 0.6200 TestAcc 0.5553 0.6150
epoch 800 LossPred 0.8840 LossAtt 0.4209 TrainAcc 0.6500 TestAcc 0.5325 0.6300
epoch 900 LossPred 0.9399 LossAtt 0.4110 TrainAcc 0.6200 TestAcc 0.5485 0.6150
epoch 1000 LossPred 0.8805 LossAtt 0.3780 TrainAcc 0.6500 TestAcc 0.5355 0.6400
epoch 1100 LossPred 0.8816 LossAtt 0.3534 TrainAcc 0.6500 TestAcc 0.5355 0.6400
epoch 1200 LossPred 0.8823 LossAtt 0.3264 TrainAcc 0.6500 TestAcc 0.5355 0.6500
epoch 1300 LossPred 0.8795 LossAtt 0.2975 TrainAcc 0.6500 TestAcc 0.5355 0.6500
epoch 1400 LossPred 0.8775 LossAtt 0.3000 TrainAcc 0.6500 TestAcc 0.5355 0.6500
epoch 1500 LossPred 0.8776 LossAtt 0.3035 TrainAcc 0.6500 TestAcc 0.5355 0.6450
epoch 1600 LossPred 0.8771 LossAtt 0.3329 TrainAcc 0.6500 TestAcc 0.5355 0.6500
epoch 1700 LossPred 0.8803 LossAtt 0.3688 TrainAcc 0.6500 TestAcc 0.5355 0.6400
epoch 1800 LossPred 0.9223 LossAtt 0.4954 TrainAcc 0.6400 TestAcc 0.5893 0.6100
epoch 1900 LossPred 0.9368 LossAtt 0.5309 TrainAcc 0.5900 TestAcc 0.5791 0.5850
epoch 2000 LossPred 0.9180 LossAtt 0.5266 TrainAcc 0.5900 TestAcc 0.5768 0.5950
epoch 2100 LossPred 0.9176 LossAtt 0.5842 TrainAcc 0.5900 TestAcc 0.5698 0.5900
epoch 2200 LossPred 0.9159 LossAtt 0.5587 TrainAcc 0.6100 TestAcc 0.5245 0.6100
epoch 2300 LossPred 0.9225 LossAtt 0.5534 TrainAcc 0.6000 TestAcc 0.5586 0.5750
epoch 2400 LossPred 0.9393 LossAtt 0.5685 TrainAcc 0.6100 TestAcc 0.5573 0.5750
epoch 2500 LossPred 0.9434 LossAtt 0.5663 TrainAcc 0.5700 TestAcc 0.5348 0.5850
Optimization Finished!
********** replication  64  **********
epoch   0 LossPred 1.0636 LossAtt 0.9963 TrainAcc 0.5800 TestAcc 0.5213 0.5800
epoch 100 LossPred 0.9296 LossAtt 0.4552 TrainAcc 0.6000 TestAcc 0.5843 0.6000
epoch 200 LossPred 0.9229 LossAtt 0.3499 TrainAcc 0.6000 TestAcc 0.5843 0.6000
epoch 300 LossPred 0.9145 LossAtt 0.3445 TrainAcc 0.6000 TestAcc 0.5843 0.6000
epoch 400 LossPred 0.9091 LossAtt 0.3277 TrainAcc 0.6000 TestAcc 0.5843 0.5800
epoch 500 LossPred 0.9046 LossAtt 0.2709 TrainAcc 0.6500 TestAcc 0.6484 0.5900
epoch 600 LossPred 0.8931 LossAtt 0.3174 TrainAcc 0.6500 TestAcc 0.6484 0.6450
epoch 700 LossPred 0.5807 LossAtt 0.3971 TrainAcc 0.8100 TestAcc 0.8063 0.8250
epoch 800 LossPred 0.3252 LossAtt 0.3912 TrainAcc 0.9000 TestAcc 0.8891 0.9100
epoch 900 LossPred 0.2739 LossAtt 0.3745 TrainAcc 0.9000 TestAcc 0.8886 0.8850
epoch 1000 LossPred 0.2294 LossAtt 0.3955 TrainAcc 0.9200 TestAcc 0.9064 0.9050
epoch 1100 LossPred 0.2142 LossAtt 0.3953 TrainAcc 0.9300 TestAcc 0.9127 0.9150
epoch 1200 LossPred 0.2027 LossAtt 0.3920 TrainAcc 0.9300 TestAcc 0.9069 0.9300
epoch 1300 LossPred 0.1964 LossAtt 0.3991 TrainAcc 0.9300 TestAcc 0.9009 0.9050
epoch 1400 LossPred 0.2559 LossAtt 0.3983 TrainAcc 0.9200 TestAcc 0.8794 0.9200
epoch 1500 LossPred 0.2137 LossAtt 0.3874 TrainAcc 0.9000 TestAcc 0.8976 0.9200
epoch 1600 LossPred 0.1945 LossAtt 0.3638 TrainAcc 0.9300 TestAcc 0.9037 0.9150
epoch 1700 LossPred 0.1976 LossAtt 0.3575 TrainAcc 0.9300 TestAcc 0.9037 0.9150
epoch 1800 LossPred 0.1864 LossAtt 0.3655 TrainAcc 0.9300 TestAcc 0.9062 0.9100
epoch 1900 LossPred 0.1888 LossAtt 0.3588 TrainAcc 0.9300 TestAcc 0.9039 0.9100
epoch 2000 LossPred 0.2009 LossAtt 0.3763 TrainAcc 0.9300 TestAcc 0.9104 0.9200
epoch 2100 LossPred 0.2061 LossAtt 0.3591 TrainAcc 0.9000 TestAcc 0.9024 0.9150
epoch 2200 LossPred 0.2396 LossAtt 0.3346 TrainAcc 0.9100 TestAcc 0.8844 0.9100
epoch 2300 LossPred 0.1866 LossAtt 0.3326 TrainAcc 0.9400 TestAcc 0.9004 0.9100
epoch 2400 LossPred 0.2528 LossAtt 0.3464 TrainAcc 0.9100 TestAcc 0.8699 0.9150
epoch 2500 LossPred 0.1895 LossAtt 0.3043 TrainAcc 0.9100 TestAcc 0.8941 0.9150
Optimization Finished!
********** replication  65  **********
epoch   0 LossPred 1.2819 LossAtt 1.0071 TrainAcc 0.3700 TestAcc 0.4855 0.3900
epoch 100 LossPred 0.8944 LossAtt 0.4506 TrainAcc 0.6500 TestAcc 0.5648 0.6450
epoch 200 LossPred 0.8346 LossAtt 0.3973 TrainAcc 0.6600 TestAcc 0.5320 0.6700
epoch 300 LossPred 0.8156 LossAtt 0.3886 TrainAcc 0.6600 TestAcc 0.5320 0.6850
epoch 400 LossPred 0.7986 LossAtt 0.4284 TrainAcc 0.6800 TestAcc 0.5748 0.6950
epoch 500 LossPred 0.7824 LossAtt 0.4605 TrainAcc 0.6800 TestAcc 0.5816 0.6750
epoch 600 LossPred 0.7716 LossAtt 0.4291 TrainAcc 0.6900 TestAcc 0.5813 0.7050
epoch 700 LossPred 0.7683 LossAtt 0.4034 TrainAcc 0.6900 TestAcc 0.5986 0.7100
epoch 800 LossPred 0.7633 LossAtt 0.3591 TrainAcc 0.7100 TestAcc 0.6146 0.7100
epoch 900 LossPred 0.7611 LossAtt 0.3725 TrainAcc 0.7300 TestAcc 0.6039 0.7200
epoch 1000 LossPred 0.7569 LossAtt 0.3393 TrainAcc 0.7100 TestAcc 0.6114 0.7200
epoch 1100 LossPred 0.7473 LossAtt 0.3626 TrainAcc 0.7300 TestAcc 0.6114 0.7250
epoch 1200 LossPred 0.7465 LossAtt 0.3726 TrainAcc 0.7300 TestAcc 0.6131 0.7350
epoch 1300 LossPred 0.7413 LossAtt 0.3734 TrainAcc 0.7300 TestAcc 0.6114 0.7200
epoch 1400 LossPred 0.7446 LossAtt 0.3510 TrainAcc 0.7300 TestAcc 0.6086 0.7200
epoch 1500 LossPred 0.7410 LossAtt 0.3497 TrainAcc 0.7400 TestAcc 0.6279 0.7450
epoch 1600 LossPred 0.7423 LossAtt 0.3257 TrainAcc 0.7200 TestAcc 0.6236 0.7300
epoch 1700 LossPred 0.7481 LossAtt 0.2736 TrainAcc 0.7300 TestAcc 0.6361 0.7300
epoch 1800 LossPred 0.7532 LossAtt 0.2722 TrainAcc 0.7000 TestAcc 0.6274 0.7250
epoch 1900 LossPred 0.7342 LossAtt 0.2920 TrainAcc 0.7700 TestAcc 0.6291 0.7500
epoch 2000 LossPred 0.7382 LossAtt 0.2701 TrainAcc 0.7300 TestAcc 0.6266 0.7300
epoch 2100 LossPred 0.7340 LossAtt 0.2485 TrainAcc 0.7400 TestAcc 0.6154 0.7400
epoch 2200 LossPred 0.7183 LossAtt 0.2692 TrainAcc 0.7500 TestAcc 0.6199 0.7500
epoch 2300 LossPred 0.7436 LossAtt 0.2875 TrainAcc 0.7400 TestAcc 0.6411 0.7400
epoch 2400 LossPred 0.7297 LossAtt 0.2725 TrainAcc 0.7400 TestAcc 0.6356 0.7400
epoch 2500 LossPred 0.7461 LossAtt 0.2814 TrainAcc 0.7600 TestAcc 0.6421 0.7400
Optimization Finished!
********** replication  66  **********
epoch   0 LossPred 1.1368 LossAtt 1.0088 TrainAcc 0.4600 TestAcc 0.4094 0.4550
epoch 100 LossPred 0.9742 LossAtt 0.3265 TrainAcc 0.5500 TestAcc 0.5851 0.5500
epoch 200 LossPred 0.9225 LossAtt 0.2772 TrainAcc 0.5800 TestAcc 0.6336 0.5800
epoch 300 LossPred 0.5073 LossAtt 0.3578 TrainAcc 0.8600 TestAcc 0.8126 0.8300
epoch 400 LossPred 0.5026 LossAtt 0.3591 TrainAcc 0.8500 TestAcc 0.8046 0.8350
epoch 500 LossPred 0.3778 LossAtt 0.3693 TrainAcc 0.8800 TestAcc 0.8521 0.8500
epoch 600 LossPred 0.3805 LossAtt 0.3745 TrainAcc 0.8400 TestAcc 0.8516 0.8450
epoch 700 LossPred 0.4534 LossAtt 0.3827 TrainAcc 0.8400 TestAcc 0.8448 0.8250
epoch 800 LossPred 0.5602 LossAtt 0.3627 TrainAcc 0.8100 TestAcc 0.7985 0.8100
epoch 900 LossPred 0.3439 LossAtt 0.3783 TrainAcc 0.8800 TestAcc 0.8476 0.8500
epoch 1000 LossPred 0.7890 LossAtt 0.4345 TrainAcc 0.7000 TestAcc 0.7422 0.7250
epoch 1100 LossPred 0.5694 LossAtt 0.3968 TrainAcc 0.8200 TestAcc 0.8101 0.8150
epoch 1200 LossPred 0.6908 LossAtt 0.4161 TrainAcc 0.7700 TestAcc 0.7803 0.7750
epoch 1300 LossPred 0.4279 LossAtt 0.4036 TrainAcc 0.8500 TestAcc 0.8298 0.8300
epoch 1400 LossPred 0.3970 LossAtt 0.3702 TrainAcc 0.8400 TestAcc 0.8376 0.8450
epoch 1500 LossPred 0.3290 LossAtt 0.3569 TrainAcc 0.8800 TestAcc 0.8406 0.8550
epoch 1600 LossPred 0.4519 LossAtt 0.3240 TrainAcc 0.8600 TestAcc 0.8236 0.8550
epoch 1700 LossPred 0.3736 LossAtt 0.3740 TrainAcc 0.8600 TestAcc 0.8416 0.8500
epoch 1800 LossPred 0.3132 LossAtt 0.3548 TrainAcc 0.9100 TestAcc 0.8473 0.8650
epoch 1900 LossPred 0.3445 LossAtt 0.3757 TrainAcc 0.8600 TestAcc 0.8498 0.8700
epoch 2000 LossPred 0.3698 LossAtt 0.3411 TrainAcc 0.8500 TestAcc 0.8448 0.8600
epoch 2100 LossPred 0.3356 LossAtt 0.3655 TrainAcc 0.8700 TestAcc 0.8639 0.8600
epoch 2200 LossPred 0.2883 LossAtt 0.3529 TrainAcc 0.9100 TestAcc 0.8551 0.8850
epoch 2300 LossPred 0.4202 LossAtt 0.3180 TrainAcc 0.8600 TestAcc 0.8368 0.8650
epoch 2400 LossPred 0.3101 LossAtt 0.3478 TrainAcc 0.8900 TestAcc 0.8706 0.8700
epoch 2500 LossPred 0.3083 LossAtt 0.3396 TrainAcc 0.9000 TestAcc 0.8704 0.8800
Optimization Finished!
********** replication  67  **********
epoch   0 LossPred 0.9633 LossAtt 1.0092 TrainAcc 0.5400 TestAcc 0.5380 0.5450
epoch 100 LossPred 0.8841 LossAtt 0.3347 TrainAcc 0.6200 TestAcc 0.5833 0.6200
epoch 200 LossPred 0.8814 LossAtt 0.3537 TrainAcc 0.5800 TestAcc 0.5861 0.6150
epoch 300 LossPred 0.8643 LossAtt 0.3230 TrainAcc 0.6900 TestAcc 0.6299 0.6900
epoch 400 LossPred 0.8422 LossAtt 0.3126 TrainAcc 0.6900 TestAcc 0.6299 0.6900
epoch 500 LossPred 0.8322 LossAtt 0.2698 TrainAcc 0.6900 TestAcc 0.6299 0.6950
epoch 600 LossPred 0.8772 LossAtt 0.2508 TrainAcc 0.6900 TestAcc 0.6299 0.6900
epoch 700 LossPred 0.8834 LossAtt 0.1464 TrainAcc 0.6200 TestAcc 0.5833 0.6200
epoch 800 LossPred 0.8813 LossAtt 0.1197 TrainAcc 0.6200 TestAcc 0.5833 0.6200
epoch 900 LossPred 0.8842 LossAtt 0.1242 TrainAcc 0.5200 TestAcc 0.5385 0.5500
epoch 1000 LossPred 0.8848 LossAtt 0.1118 TrainAcc 0.6200 TestAcc 0.5833 0.5900
epoch 1100 LossPred 0.8826 LossAtt 0.0900 TrainAcc 0.6200 TestAcc 0.5833 0.6200
epoch 1200 LossPred 0.8819 LossAtt 0.0883 TrainAcc 0.6200 TestAcc 0.5833 0.6200
epoch 1300 LossPred 0.8825 LossAtt 0.0722 TrainAcc 0.6200 TestAcc 0.5833 0.6200
epoch 1400 LossPred 0.8823 LossAtt 0.0934 TrainAcc 0.6200 TestAcc 0.5833 0.6200
epoch 1500 LossPred 0.8824 LossAtt 0.0851 TrainAcc 0.6200 TestAcc 0.5833 0.6200
epoch 1600 LossPred 0.8841 LossAtt 0.0739 TrainAcc 0.6200 TestAcc 0.5833 0.6200
epoch 1700 LossPred 0.8928 LossAtt 0.1149 TrainAcc 0.6200 TestAcc 0.5833 0.6200
epoch 1800 LossPred 0.8835 LossAtt 0.0892 TrainAcc 0.6200 TestAcc 0.5833 0.6200
epoch 1900 LossPred 0.8827 LossAtt 0.0627 TrainAcc 0.6200 TestAcc 0.5833 0.6200
epoch 2000 LossPred 0.8840 LossAtt 0.0582 TrainAcc 0.6200 TestAcc 0.5833 0.6200
epoch 2100 LossPred 0.9182 LossAtt 0.1048 TrainAcc 0.6200 TestAcc 0.5833 0.6200
epoch 2200 LossPred 0.9344 LossAtt 0.0936 TrainAcc 0.6200 TestAcc 0.5833 0.6200
epoch 2300 LossPred 0.9374 LossAtt 0.1133 TrainAcc 0.6200 TestAcc 0.5833 0.6200
epoch 2400 LossPred 0.9341 LossAtt 0.0885 TrainAcc 0.6200 TestAcc 0.5833 0.6200
epoch 2500 LossPred 0.9352 LossAtt 0.0791 TrainAcc 0.6200 TestAcc 0.5833 0.6200
Optimization Finished!
********** replication  68  **********
epoch   0 LossPred 1.0188 LossAtt 0.9966 TrainAcc 0.5800 TestAcc 0.5771 0.5750
epoch 100 LossPred 0.8852 LossAtt 0.4679 TrainAcc 0.7200 TestAcc 0.6386 0.7200
epoch 200 LossPred 0.8230 LossAtt 0.4680 TrainAcc 0.7400 TestAcc 0.6529 0.7250
epoch 300 LossPred 0.7558 LossAtt 0.4218 TrainAcc 0.7300 TestAcc 0.6539 0.7050
epoch 400 LossPred 0.6962 LossAtt 0.4131 TrainAcc 0.7200 TestAcc 0.6817 0.7300
epoch 500 LossPred 0.5666 LossAtt 0.3484 TrainAcc 0.8100 TestAcc 0.7963 0.8100
epoch 600 LossPred 0.5172 LossAtt 0.2873 TrainAcc 0.8300 TestAcc 0.8126 0.8450
epoch 700 LossPred 0.4498 LossAtt 0.2963 TrainAcc 0.8600 TestAcc 0.8311 0.8450
epoch 800 LossPred 0.4422 LossAtt 0.2980 TrainAcc 0.8700 TestAcc 0.8371 0.8700
epoch 900 LossPred 0.4413 LossAtt 0.2965 TrainAcc 0.8800 TestAcc 0.8283 0.8750
epoch 1000 LossPred 0.4569 LossAtt 0.2713 TrainAcc 0.8300 TestAcc 0.8111 0.8500
epoch 1100 LossPred 0.4909 LossAtt 0.2771 TrainAcc 0.8300 TestAcc 0.8266 0.8500
epoch 1200 LossPred 0.4064 LossAtt 0.2520 TrainAcc 0.8700 TestAcc 0.8298 0.8750
epoch 1300 LossPred 0.4144 LossAtt 0.2407 TrainAcc 0.8500 TestAcc 0.8073 0.8450
epoch 1400 LossPred 0.4824 LossAtt 0.2401 TrainAcc 0.8300 TestAcc 0.7653 0.8150
epoch 1500 LossPred 0.5206 LossAtt 0.2199 TrainAcc 0.8100 TestAcc 0.7620 0.7950
epoch 1600 LossPred 0.4379 LossAtt 0.2184 TrainAcc 0.8300 TestAcc 0.7980 0.8400
epoch 1700 LossPred 0.4160 LossAtt 0.2492 TrainAcc 0.8600 TestAcc 0.8246 0.8450
epoch 1800 LossPred 0.4069 LossAtt 0.2343 TrainAcc 0.8500 TestAcc 0.8113 0.8350
epoch 1900 LossPred 0.4279 LossAtt 0.2285 TrainAcc 0.8400 TestAcc 0.8193 0.8450
epoch 2000 LossPred 0.3910 LossAtt 0.2184 TrainAcc 0.8700 TestAcc 0.8226 0.8550
epoch 2100 LossPred 0.3805 LossAtt 0.2346 TrainAcc 0.8700 TestAcc 0.8328 0.8700
epoch 2200 LossPred 0.4000 LossAtt 0.2319 TrainAcc 0.8500 TestAcc 0.8171 0.8400
epoch 2300 LossPred 0.3776 LossAtt 0.2484 TrainAcc 0.8700 TestAcc 0.8331 0.8700
epoch 2400 LossPred 0.3725 LossAtt 0.2156 TrainAcc 0.8700 TestAcc 0.8231 0.8550
epoch 2500 LossPred 0.3742 LossAtt 0.2453 TrainAcc 0.8800 TestAcc 0.8273 0.8500
Optimization Finished!
********** replication  69  **********
epoch   0 LossPred 1.2024 LossAtt 1.0336 TrainAcc 0.5400 TestAcc 0.4932 0.5300
epoch 100 LossPred 1.0100 LossAtt 0.5315 TrainAcc 0.5700 TestAcc 0.4875 0.5500
epoch 200 LossPred 0.9575 LossAtt 0.4763 TrainAcc 0.5600 TestAcc 0.4997 0.5450
epoch 300 LossPred 0.9454 LossAtt 0.3809 TrainAcc 0.5500 TestAcc 0.5551 0.5300
epoch 400 LossPred 0.9685 LossAtt 0.3940 TrainAcc 0.5500 TestAcc 0.5633 0.5250
epoch 500 LossPred 0.9683 LossAtt 0.3360 TrainAcc 0.5300 TestAcc 0.5591 0.5400
epoch 600 LossPred 0.9686 LossAtt 0.3172 TrainAcc 0.5300 TestAcc 0.5596 0.5300
epoch 700 LossPred 0.9520 LossAtt 0.3570 TrainAcc 0.5500 TestAcc 0.5791 0.5650
epoch 800 LossPred 0.9317 LossAtt 0.3912 TrainAcc 0.5700 TestAcc 0.5200 0.5900
epoch 900 LossPred 0.9159 LossAtt 0.3983 TrainAcc 0.6200 TestAcc 0.5205 0.6050
epoch 1000 LossPred 0.9082 LossAtt 0.3187 TrainAcc 0.6000 TestAcc 0.5160 0.6000
epoch 1100 LossPred 0.9052 LossAtt 0.3004 TrainAcc 0.6000 TestAcc 0.5160 0.5950
epoch 1200 LossPred 0.9035 LossAtt 0.2711 TrainAcc 0.6000 TestAcc 0.5160 0.5950
epoch 1300 LossPred 0.9025 LossAtt 0.2915 TrainAcc 0.6000 TestAcc 0.5058 0.6000
epoch 1400 LossPred 0.9011 LossAtt 0.2690 TrainAcc 0.6000 TestAcc 0.5058 0.5900
epoch 1500 LossPred 0.8994 LossAtt 0.3000 TrainAcc 0.6100 TestAcc 0.5188 0.5850
epoch 1600 LossPred 0.8981 LossAtt 0.3258 TrainAcc 0.6100 TestAcc 0.5188 0.6150
epoch 1700 LossPred 0.8698 LossAtt 0.5124 TrainAcc 0.6200 TestAcc 0.5213 0.6100
epoch 1800 LossPred 0.8368 LossAtt 0.4757 TrainAcc 0.6700 TestAcc 0.5485 0.6550
epoch 1900 LossPred 0.8240 LossAtt 0.4577 TrainAcc 0.6600 TestAcc 0.5298 0.6550
epoch 2000 LossPred 0.8241 LossAtt 0.3943 TrainAcc 0.6200 TestAcc 0.5400 0.6250
epoch 2100 LossPred 0.8059 LossAtt 0.3546 TrainAcc 0.6100 TestAcc 0.5513 0.6050
epoch 2200 LossPred 0.7922 LossAtt 0.3596 TrainAcc 0.6500 TestAcc 0.5666 0.6350
epoch 2300 LossPred 0.7954 LossAtt 0.3609 TrainAcc 0.6400 TestAcc 0.5606 0.6350
epoch 2400 LossPred 0.7842 LossAtt 0.3361 TrainAcc 0.6600 TestAcc 0.5443 0.6350
epoch 2500 LossPred 0.8251 LossAtt 0.3358 TrainAcc 0.6500 TestAcc 0.5563 0.6700
Optimization Finished!
********** replication  70  **********
epoch   0 LossPred 1.2076 LossAtt 1.0179 TrainAcc 0.5200 TestAcc 0.5020 0.5000
epoch 100 LossPred 0.9480 LossAtt 0.5546 TrainAcc 0.5600 TestAcc 0.5193 0.5650
epoch 200 LossPred 0.8951 LossAtt 0.5529 TrainAcc 0.5900 TestAcc 0.5310 0.5900
epoch 300 LossPred 0.8407 LossAtt 0.5755 TrainAcc 0.6500 TestAcc 0.5478 0.6400
epoch 400 LossPred 0.8225 LossAtt 0.5891 TrainAcc 0.6600 TestAcc 0.5495 0.6550
epoch 500 LossPred 0.7983 LossAtt 0.5994 TrainAcc 0.7000 TestAcc 0.5533 0.6450
epoch 600 LossPred 0.7839 LossAtt 0.5816 TrainAcc 0.7200 TestAcc 0.5558 0.6500
epoch 700 LossPred 0.7731 LossAtt 0.5317 TrainAcc 0.7300 TestAcc 0.5558 0.6800
epoch 800 LossPred 0.7971 LossAtt 0.4858 TrainAcc 0.7000 TestAcc 0.5526 0.6700
epoch 900 LossPred 0.7684 LossAtt 0.4634 TrainAcc 0.7300 TestAcc 0.5508 0.7100
epoch 1000 LossPred 0.8185 LossAtt 0.4677 TrainAcc 0.7200 TestAcc 0.5603 0.7100
epoch 1100 LossPred 0.7713 LossAtt 0.4749 TrainAcc 0.7300 TestAcc 0.5693 0.7100
epoch 1200 LossPred 0.7808 LossAtt 0.4703 TrainAcc 0.7300 TestAcc 0.5678 0.7150
epoch 1300 LossPred 0.8141 LossAtt 0.4367 TrainAcc 0.7200 TestAcc 0.5636 0.7050
epoch 1400 LossPred 0.7986 LossAtt 0.4638 TrainAcc 0.7200 TestAcc 0.5648 0.7000
epoch 1500 LossPred 0.7781 LossAtt 0.4553 TrainAcc 0.7300 TestAcc 0.5623 0.7200
epoch 1600 LossPred 0.7753 LossAtt 0.4481 TrainAcc 0.7200 TestAcc 0.5643 0.7100
epoch 1700 LossPred 0.7794 LossAtt 0.4440 TrainAcc 0.7300 TestAcc 0.5628 0.7100
epoch 1800 LossPred 0.7756 LossAtt 0.4575 TrainAcc 0.7200 TestAcc 0.5656 0.7050
epoch 1900 LossPred 0.7768 LossAtt 0.4482 TrainAcc 0.7300 TestAcc 0.5666 0.7150
epoch 2000 LossPred 0.7763 LossAtt 0.4494 TrainAcc 0.7200 TestAcc 0.5683 0.7100
epoch 2100 LossPred 0.7736 LossAtt 0.4691 TrainAcc 0.7100 TestAcc 0.5678 0.7050
epoch 2200 LossPred 0.7657 LossAtt 0.4272 TrainAcc 0.7100 TestAcc 0.5701 0.7050
epoch 2300 LossPred 0.7680 LossAtt 0.4176 TrainAcc 0.7200 TestAcc 0.5638 0.7050
epoch 2400 LossPred 0.7648 LossAtt 0.4073 TrainAcc 0.7100 TestAcc 0.5713 0.7000
epoch 2500 LossPred 0.7886 LossAtt 0.4297 TrainAcc 0.7200 TestAcc 0.5638 0.7150
Optimization Finished!
********** replication  71  **********
epoch   0 LossPred 0.9364 LossAtt 0.9994 TrainAcc 0.6100 TestAcc 0.5183 0.6150
epoch 100 LossPred 0.8440 LossAtt 0.4603 TrainAcc 0.6900 TestAcc 0.5883 0.6900
epoch 200 LossPred 0.8284 LossAtt 0.4514 TrainAcc 0.6900 TestAcc 0.5883 0.6900
epoch 300 LossPred 0.8111 LossAtt 0.4805 TrainAcc 0.6900 TestAcc 0.5883 0.6900
epoch 400 LossPred 0.7978 LossAtt 0.4736 TrainAcc 0.6900 TestAcc 0.5883 0.6900
epoch 500 LossPred 0.7727 LossAtt 0.4888 TrainAcc 0.7000 TestAcc 0.6001 0.6900
epoch 600 LossPred 0.4666 LossAtt 0.5481 TrainAcc 0.8500 TestAcc 0.8363 0.8150
epoch 700 LossPred 1.0454 LossAtt 0.5483 TrainAcc 0.5800 TestAcc 0.6732 0.5900
epoch 800 LossPred 0.4588 LossAtt 0.4711 TrainAcc 0.8500 TestAcc 0.7918 0.8300
epoch 900 LossPred 0.5801 LossAtt 0.4597 TrainAcc 0.7800 TestAcc 0.8126 0.7800
epoch 1000 LossPred 0.5096 LossAtt 0.4082 TrainAcc 0.8200 TestAcc 0.8286 0.8200
epoch 1100 LossPred 0.4863 LossAtt 0.3936 TrainAcc 0.8300 TestAcc 0.8318 0.8250
epoch 1200 LossPred 0.3924 LossAtt 0.3773 TrainAcc 0.8600 TestAcc 0.8068 0.8600
epoch 1300 LossPred 0.3719 LossAtt 0.3547 TrainAcc 0.8700 TestAcc 0.8341 0.8800
epoch 1400 LossPred 0.3373 LossAtt 0.3785 TrainAcc 0.8700 TestAcc 0.8519 0.8600
epoch 1500 LossPred 0.3749 LossAtt 0.3646 TrainAcc 0.8600 TestAcc 0.8298 0.8650
epoch 1600 LossPred 0.3321 LossAtt 0.3682 TrainAcc 0.8600 TestAcc 0.8569 0.8600
epoch 1700 LossPred 0.5758 LossAtt 0.3686 TrainAcc 0.8000 TestAcc 0.7608 0.8100
epoch 1800 LossPred 0.3366 LossAtt 0.3881 TrainAcc 0.9100 TestAcc 0.8441 0.9050
epoch 1900 LossPred 0.3242 LossAtt 0.3807 TrainAcc 0.8800 TestAcc 0.8554 0.8800
epoch 2000 LossPred 0.3520 LossAtt 0.3938 TrainAcc 0.8800 TestAcc 0.8504 0.8750
epoch 2100 LossPred 0.5796 LossAtt 0.3996 TrainAcc 0.8000 TestAcc 0.7528 0.8150
epoch 2200 LossPred 0.3481 LossAtt 0.3950 TrainAcc 0.8800 TestAcc 0.8493 0.8900
epoch 2300 LossPred 0.3339 LossAtt 0.4093 TrainAcc 0.8800 TestAcc 0.8576 0.8500
epoch 2400 LossPred 0.3708 LossAtt 0.4151 TrainAcc 0.8800 TestAcc 0.8433 0.8750
epoch 2500 LossPred 0.3148 LossAtt 0.3910 TrainAcc 0.9000 TestAcc 0.8406 0.9050
Optimization Finished!
********** replication  72  **********
epoch   0 LossPred 1.0517 LossAtt 0.9802 TrainAcc 0.5400 TestAcc 0.5098 0.5300
epoch 100 LossPred 0.9277 LossAtt 0.3787 TrainAcc 0.6000 TestAcc 0.5893 0.6000
epoch 200 LossPred 0.9133 LossAtt 0.3051 TrainAcc 0.6000 TestAcc 0.5893 0.5900
epoch 300 LossPred 0.9056 LossAtt 0.3266 TrainAcc 0.6000 TestAcc 0.5893 0.6050
epoch 400 LossPred 0.8954 LossAtt 0.3416 TrainAcc 0.6000 TestAcc 0.6014 0.6050
epoch 500 LossPred 0.8544 LossAtt 0.4337 TrainAcc 0.6600 TestAcc 0.6194 0.6500
epoch 600 LossPred 0.8383 LossAtt 0.3610 TrainAcc 0.6600 TestAcc 0.6306 0.6650
epoch 700 LossPred 0.8248 LossAtt 0.2981 TrainAcc 0.6600 TestAcc 0.6306 0.6650
epoch 800 LossPred 0.8238 LossAtt 0.2563 TrainAcc 0.6600 TestAcc 0.6274 0.6650
epoch 900 LossPred 0.8298 LossAtt 0.2871 TrainAcc 0.6600 TestAcc 0.6261 0.6500
epoch 1000 LossPred 0.8392 LossAtt 0.2654 TrainAcc 0.6200 TestAcc 0.6331 0.6250
epoch 1100 LossPred 0.7458 LossAtt 0.3243 TrainAcc 0.7200 TestAcc 0.7117 0.7050
epoch 1200 LossPred 0.5376 LossAtt 0.3561 TrainAcc 0.8200 TestAcc 0.8178 0.8050
epoch 1300 LossPred 0.5074 LossAtt 0.3239 TrainAcc 0.8200 TestAcc 0.8431 0.8250
epoch 1400 LossPred 0.4626 LossAtt 0.3325 TrainAcc 0.8600 TestAcc 0.8451 0.8600
epoch 1500 LossPred 0.4305 LossAtt 0.2951 TrainAcc 0.8400 TestAcc 0.8418 0.8400
epoch 1600 LossPred 0.4538 LossAtt 0.3225 TrainAcc 0.8400 TestAcc 0.8343 0.8500
epoch 1700 LossPred 0.6215 LossAtt 0.2787 TrainAcc 0.8000 TestAcc 0.7958 0.8050
epoch 1800 LossPred 0.4731 LossAtt 0.2767 TrainAcc 0.8500 TestAcc 0.8388 0.8450
epoch 1900 LossPred 0.5147 LossAtt 0.3127 TrainAcc 0.8300 TestAcc 0.8361 0.8450
epoch 2000 LossPred 0.4669 LossAtt 0.2825 TrainAcc 0.8300 TestAcc 0.8418 0.8300
epoch 2100 LossPred 0.4349 LossAtt 0.2994 TrainAcc 0.8300 TestAcc 0.8436 0.8350
epoch 2200 LossPred 0.4271 LossAtt 0.2948 TrainAcc 0.8400 TestAcc 0.8446 0.8450
epoch 2300 LossPred 0.4168 LossAtt 0.3028 TrainAcc 0.8500 TestAcc 0.8403 0.8650
epoch 2400 LossPred 0.4044 LossAtt 0.3277 TrainAcc 0.8600 TestAcc 0.8328 0.8500
epoch 2500 LossPred 0.4227 LossAtt 0.3049 TrainAcc 0.8500 TestAcc 0.8351 0.8650
Optimization Finished!
********** replication  73  **********
epoch   0 LossPred 1.0844 LossAtt 1.0067 TrainAcc 0.5200 TestAcc 0.5325 0.5400
epoch 100 LossPred 0.9886 LossAtt 0.2743 TrainAcc 0.5600 TestAcc 0.5843 0.5600
epoch 200 LossPred 0.9851 LossAtt 0.1788 TrainAcc 0.5600 TestAcc 0.5843 0.5600
epoch 300 LossPred 0.9637 LossAtt 0.3100 TrainAcc 0.5900 TestAcc 0.5688 0.5600
epoch 400 LossPred 0.9442 LossAtt 0.4776 TrainAcc 0.6000 TestAcc 0.5618 0.5950
epoch 500 LossPred 0.8235 LossAtt 0.4932 TrainAcc 0.7200 TestAcc 0.6869 0.7250
epoch 600 LossPred 0.3006 LossAtt 0.5068 TrainAcc 0.9500 TestAcc 0.8859 0.8950
epoch 700 LossPred 0.2324 LossAtt 0.4753 TrainAcc 0.9500 TestAcc 0.8974 0.8850
epoch 800 LossPred 0.4443 LossAtt 0.4690 TrainAcc 0.8300 TestAcc 0.8261 0.8300
epoch 900 LossPred 0.2313 LossAtt 0.4935 TrainAcc 0.9400 TestAcc 0.8901 0.9000
epoch 1000 LossPred 0.2276 LossAtt 0.4716 TrainAcc 0.9300 TestAcc 0.8834 0.8950
epoch 1100 LossPred 0.2558 LossAtt 0.4457 TrainAcc 0.9200 TestAcc 0.8709 0.9050
epoch 1200 LossPred 0.2348 LossAtt 0.4394 TrainAcc 0.9300 TestAcc 0.8734 0.9150
epoch 1300 LossPred 0.2065 LossAtt 0.4381 TrainAcc 0.9500 TestAcc 0.8749 0.9200
epoch 1400 LossPred 0.3381 LossAtt 0.4203 TrainAcc 0.8600 TestAcc 0.8473 0.8900
epoch 1500 LossPred 0.3549 LossAtt 0.4119 TrainAcc 0.8600 TestAcc 0.8556 0.8450
epoch 1600 LossPred 0.3386 LossAtt 0.4031 TrainAcc 0.8800 TestAcc 0.8681 0.8850
epoch 1700 LossPred 0.3382 LossAtt 0.3995 TrainAcc 0.8800 TestAcc 0.8654 0.8600
epoch 1800 LossPred 0.3137 LossAtt 0.3674 TrainAcc 0.9000 TestAcc 0.8511 0.8900
epoch 1900 LossPred 0.3199 LossAtt 0.3751 TrainAcc 0.8900 TestAcc 0.8491 0.8800
epoch 2000 LossPred 0.3665 LossAtt 0.3521 TrainAcc 0.8800 TestAcc 0.8273 0.8500
epoch 2100 LossPred 0.3604 LossAtt 0.3678 TrainAcc 0.8800 TestAcc 0.8621 0.8400
epoch 2200 LossPred 0.3497 LossAtt 0.3767 TrainAcc 0.8800 TestAcc 0.8589 0.8450
epoch 2300 LossPred 0.3964 LossAtt 0.3571 TrainAcc 0.8600 TestAcc 0.8136 0.8550
epoch 2400 LossPred 0.4417 LossAtt 0.3611 TrainAcc 0.8600 TestAcc 0.8306 0.8200
epoch 2500 LossPred 0.4509 LossAtt 0.3574 TrainAcc 0.8400 TestAcc 0.7855 0.8400
Optimization Finished!
********** replication  74  **********
epoch   0 LossPred 1.1023 LossAtt 0.9886 TrainAcc 0.4200 TestAcc 0.4757 0.4500
epoch 100 LossPred 0.8989 LossAtt 0.3985 TrainAcc 0.6300 TestAcc 0.5883 0.6300
epoch 200 LossPred 0.8838 LossAtt 0.3613 TrainAcc 0.6600 TestAcc 0.5475 0.6400
epoch 300 LossPred 0.8832 LossAtt 0.2972 TrainAcc 0.6600 TestAcc 0.5475 0.6600
epoch 400 LossPred 0.8820 LossAtt 0.3287 TrainAcc 0.6600 TestAcc 0.5475 0.6600
epoch 500 LossPred 0.8834 LossAtt 0.2927 TrainAcc 0.6500 TestAcc 0.5538 0.6450
epoch 600 LossPred 0.8874 LossAtt 0.3237 TrainAcc 0.6600 TestAcc 0.5551 0.6250
epoch 700 LossPred 0.8891 LossAtt 0.3801 TrainAcc 0.6600 TestAcc 0.5578 0.6500
epoch 800 LossPred 0.8852 LossAtt 0.3493 TrainAcc 0.6600 TestAcc 0.5591 0.6350
epoch 900 LossPred 0.8655 LossAtt 0.3881 TrainAcc 0.6400 TestAcc 0.5383 0.6300
epoch 1000 LossPred 0.8546 LossAtt 0.4085 TrainAcc 0.6500 TestAcc 0.5521 0.6500
epoch 1100 LossPred 0.8396 LossAtt 0.4222 TrainAcc 0.6500 TestAcc 0.5483 0.6400
epoch 1200 LossPred 0.8183 LossAtt 0.3668 TrainAcc 0.6700 TestAcc 0.5573 0.6500
epoch 1300 LossPred 0.8059 LossAtt 0.3649 TrainAcc 0.6700 TestAcc 0.5608 0.6600
epoch 1400 LossPred 0.8013 LossAtt 0.3706 TrainAcc 0.6900 TestAcc 0.5733 0.6750
epoch 1500 LossPred 0.7970 LossAtt 0.3753 TrainAcc 0.7000 TestAcc 0.5748 0.6750
epoch 1600 LossPred 0.7870 LossAtt 0.3618 TrainAcc 0.7000 TestAcc 0.5681 0.6700
epoch 1700 LossPred 0.7784 LossAtt 0.3525 TrainAcc 0.7200 TestAcc 0.5836 0.6950
epoch 1800 LossPred 0.7586 LossAtt 0.3772 TrainAcc 0.7000 TestAcc 0.5678 0.6800
epoch 1900 LossPred 0.7518 LossAtt 0.3579 TrainAcc 0.7000 TestAcc 0.5688 0.6800
epoch 2000 LossPred 0.7446 LossAtt 0.3533 TrainAcc 0.7300 TestAcc 0.5848 0.7000
epoch 2100 LossPred 0.7365 LossAtt 0.3633 TrainAcc 0.7400 TestAcc 0.5868 0.6950
epoch 2200 LossPred 0.7493 LossAtt 0.3688 TrainAcc 0.7300 TestAcc 0.5826 0.7100
epoch 2300 LossPred 0.7301 LossAtt 0.3735 TrainAcc 0.7400 TestAcc 0.5841 0.7050
epoch 2400 LossPred 0.7272 LossAtt 0.3398 TrainAcc 0.7400 TestAcc 0.5876 0.7050
epoch 2500 LossPred 0.7226 LossAtt 0.3663 TrainAcc 0.7400 TestAcc 0.5871 0.7100
Optimization Finished!
********** replication  75  **********
epoch   0 LossPred 1.2288 LossAtt 1.0108 TrainAcc 0.5800 TestAcc 0.5706 0.5450
epoch 100 LossPred 0.9911 LossAtt 0.4187 TrainAcc 0.6100 TestAcc 0.5325 0.6050
epoch 200 LossPred 0.9471 LossAtt 0.3808 TrainAcc 0.6400 TestAcc 0.5428 0.6050
epoch 300 LossPred 0.9175 LossAtt 0.3628 TrainAcc 0.6100 TestAcc 0.5325 0.6150
epoch 400 LossPred 0.8952 LossAtt 0.3601 TrainAcc 0.6300 TestAcc 0.5345 0.6300
epoch 500 LossPred 0.8742 LossAtt 0.3423 TrainAcc 0.6500 TestAcc 0.6059 0.6600
epoch 600 LossPred 0.8620 LossAtt 0.3268 TrainAcc 0.6800 TestAcc 0.5981 0.6800
epoch 700 LossPred 0.8539 LossAtt 0.3536 TrainAcc 0.6800 TestAcc 0.5981 0.6800
epoch 800 LossPred 0.8344 LossAtt 0.3651 TrainAcc 0.6800 TestAcc 0.6114 0.6800
epoch 900 LossPred 0.8069 LossAtt 0.3717 TrainAcc 0.7100 TestAcc 0.6419 0.7100
epoch 1000 LossPred 0.7009 LossAtt 0.3356 TrainAcc 0.7700 TestAcc 0.7503 0.7650
epoch 1100 LossPred 0.8833 LossAtt 0.3956 TrainAcc 0.7300 TestAcc 0.7235 0.7200
epoch 1200 LossPred 0.5096 LossAtt 0.2695 TrainAcc 0.8300 TestAcc 0.8151 0.8150
epoch 1300 LossPred 0.4871 LossAtt 0.2606 TrainAcc 0.8400 TestAcc 0.8466 0.8300
epoch 1400 LossPred 0.5713 LossAtt 0.2327 TrainAcc 0.8000 TestAcc 0.8168 0.8000
epoch 1500 LossPred 0.5909 LossAtt 0.2360 TrainAcc 0.7800 TestAcc 0.8086 0.7850
epoch 1600 LossPred 0.3699 LossAtt 0.2061 TrainAcc 0.8900 TestAcc 0.8749 0.8800
epoch 1700 LossPred 0.3484 LossAtt 0.1853 TrainAcc 0.9000 TestAcc 0.8681 0.8900
epoch 1800 LossPred 0.5707 LossAtt 0.2119 TrainAcc 0.7900 TestAcc 0.7700 0.8000
epoch 1900 LossPred 0.3768 LossAtt 0.2180 TrainAcc 0.8900 TestAcc 0.8619 0.8650
epoch 2000 LossPred 0.3779 LossAtt 0.2035 TrainAcc 0.8700 TestAcc 0.8659 0.8450
epoch 2100 LossPred 0.3279 LossAtt 0.2094 TrainAcc 0.8700 TestAcc 0.8626 0.8750
epoch 2200 LossPred 0.8058 LossAtt 0.2504 TrainAcc 0.7000 TestAcc 0.7200 0.7200
epoch 2300 LossPred 0.3370 LossAtt 0.2574 TrainAcc 0.8800 TestAcc 0.8401 0.8650
epoch 2400 LossPred 0.3112 LossAtt 0.2534 TrainAcc 0.8800 TestAcc 0.8674 0.8600
epoch 2500 LossPred 0.3072 LossAtt 0.2666 TrainAcc 0.9000 TestAcc 0.8604 0.8700
Optimization Finished!
********** replication  76  **********
epoch   0 LossPred 1.2238 LossAtt 0.9701 TrainAcc 0.5200 TestAcc 0.4880 0.5150
epoch 100 LossPred 0.9823 LossAtt 0.4983 TrainAcc 0.5700 TestAcc 0.6216 0.5700
epoch 200 LossPred 0.9521 LossAtt 0.4012 TrainAcc 0.5800 TestAcc 0.5881 0.5550
epoch 300 LossPred 0.9206 LossAtt 0.4675 TrainAcc 0.6000 TestAcc 0.5811 0.5950
epoch 400 LossPred 0.8316 LossAtt 0.5097 TrainAcc 0.6900 TestAcc 0.5546 0.6700
epoch 500 LossPred 0.7861 LossAtt 0.5827 TrainAcc 0.7100 TestAcc 0.5573 0.6950
epoch 600 LossPred 0.7481 LossAtt 0.5400 TrainAcc 0.7200 TestAcc 0.5448 0.6950
epoch 700 LossPred 0.7357 LossAtt 0.5375 TrainAcc 0.7200 TestAcc 0.5453 0.7200
epoch 800 LossPred 0.7151 LossAtt 0.5216 TrainAcc 0.7400 TestAcc 0.5468 0.7000
epoch 900 LossPred 0.7096 LossAtt 0.4917 TrainAcc 0.7300 TestAcc 0.5536 0.7100
epoch 1000 LossPred 0.7003 LossAtt 0.4869 TrainAcc 0.7300 TestAcc 0.5475 0.6950
epoch 1100 LossPred 0.6853 LossAtt 0.4429 TrainAcc 0.7300 TestAcc 0.5523 0.7050
epoch 1200 LossPred 0.6829 LossAtt 0.4493 TrainAcc 0.7400 TestAcc 0.5480 0.7050
epoch 1300 LossPred 0.6885 LossAtt 0.4473 TrainAcc 0.7100 TestAcc 0.5363 0.6950
epoch 1400 LossPred 0.6839 LossAtt 0.4140 TrainAcc 0.7200 TestAcc 0.5440 0.6700
epoch 1500 LossPred 0.7465 LossAtt 0.4122 TrainAcc 0.7100 TestAcc 0.5485 0.6950
epoch 1600 LossPred 0.7154 LossAtt 0.4368 TrainAcc 0.7000 TestAcc 0.5423 0.7000
epoch 1700 LossPred 0.7218 LossAtt 0.4066 TrainAcc 0.7000 TestAcc 0.5475 0.7100
epoch 1800 LossPred 0.7421 LossAtt 0.4201 TrainAcc 0.7100 TestAcc 0.5490 0.6900
epoch 1900 LossPred 0.7423 LossAtt 0.4366 TrainAcc 0.7300 TestAcc 0.5428 0.7100
epoch 2000 LossPred 0.7175 LossAtt 0.4237 TrainAcc 0.7400 TestAcc 0.5400 0.7000
epoch 2100 LossPred 0.7226 LossAtt 0.4269 TrainAcc 0.7100 TestAcc 0.5368 0.6900
epoch 2200 LossPred 0.7189 LossAtt 0.4255 TrainAcc 0.6800 TestAcc 0.5408 0.7000
epoch 2300 LossPred 0.7268 LossAtt 0.4202 TrainAcc 0.7200 TestAcc 0.5410 0.6950
epoch 2400 LossPred 0.7041 LossAtt 0.4239 TrainAcc 0.7000 TestAcc 0.5405 0.7100
epoch 2500 LossPred 0.6871 LossAtt 0.4295 TrainAcc 0.7300 TestAcc 0.5470 0.6900
Optimization Finished!
********** replication  77  **********
epoch   0 LossPred 1.0454 LossAtt 0.9991 TrainAcc 0.5100 TestAcc 0.5055 0.5250
epoch 100 LossPred 0.8849 LossAtt 0.4354 TrainAcc 0.6200 TestAcc 0.5863 0.6650
epoch 200 LossPred 0.8760 LossAtt 0.4120 TrainAcc 0.6900 TestAcc 0.6346 0.6900
epoch 300 LossPred 0.8642 LossAtt 0.4783 TrainAcc 0.6900 TestAcc 0.6346 0.6900
epoch 400 LossPred 0.8306 LossAtt 0.4911 TrainAcc 0.6900 TestAcc 0.6346 0.6900
epoch 500 LossPred 0.4129 LossAtt 0.5125 TrainAcc 0.8700 TestAcc 0.8554 0.8600
epoch 600 LossPred 0.3165 LossAtt 0.4645 TrainAcc 0.8800 TestAcc 0.8746 0.8650
epoch 700 LossPred 0.2837 LossAtt 0.4448 TrainAcc 0.8900 TestAcc 0.8864 0.8900
epoch 800 LossPred 0.2296 LossAtt 0.4398 TrainAcc 0.9200 TestAcc 0.8924 0.9150
epoch 900 LossPred 0.2249 LossAtt 0.4308 TrainAcc 0.9000 TestAcc 0.9097 0.9100
epoch 1000 LossPred 0.2045 LossAtt 0.4428 TrainAcc 0.9000 TestAcc 0.9207 0.8950
epoch 1100 LossPred 0.1971 LossAtt 0.4079 TrainAcc 0.9200 TestAcc 0.9189 0.9100
epoch 1200 LossPred 0.4393 LossAtt 0.4205 TrainAcc 0.8500 TestAcc 0.8081 0.8450
epoch 1300 LossPred 0.2134 LossAtt 0.4250 TrainAcc 0.9000 TestAcc 0.9067 0.9050
epoch 1400 LossPred 0.2076 LossAtt 0.4030 TrainAcc 0.9200 TestAcc 0.9087 0.9000
epoch 1500 LossPred 0.1898 LossAtt 0.4267 TrainAcc 0.9400 TestAcc 0.9162 0.9350
epoch 1600 LossPred 0.1862 LossAtt 0.3973 TrainAcc 0.9400 TestAcc 0.9124 0.9350
epoch 1700 LossPred 0.1853 LossAtt 0.4193 TrainAcc 0.9400 TestAcc 0.9117 0.9350
epoch 1800 LossPred 0.2325 LossAtt 0.4094 TrainAcc 0.9200 TestAcc 0.8836 0.9150
epoch 1900 LossPred 0.1970 LossAtt 0.4486 TrainAcc 0.9200 TestAcc 0.9032 0.9000
epoch 2000 LossPred 0.1768 LossAtt 0.4175 TrainAcc 0.9300 TestAcc 0.9117 0.9150
epoch 2100 LossPred 0.2400 LossAtt 0.4262 TrainAcc 0.9200 TestAcc 0.8826 0.9250
epoch 2200 LossPred 0.3146 LossAtt 0.4186 TrainAcc 0.8700 TestAcc 0.8524 0.8850
epoch 2300 LossPred 0.2127 LossAtt 0.4104 TrainAcc 0.9300 TestAcc 0.8959 0.9300
epoch 2400 LossPred 0.2043 LossAtt 0.3969 TrainAcc 0.9200 TestAcc 0.9027 0.9200
epoch 2500 LossPred 0.1749 LossAtt 0.4147 TrainAcc 0.9200 TestAcc 0.9119 0.9200
Optimization Finished!
********** replication  78  **********
epoch   0 LossPred 1.1875 LossAtt 0.9808 TrainAcc 0.4100 TestAcc 0.4815 0.4050
epoch 100 LossPred 0.9503 LossAtt 0.4052 TrainAcc 0.5600 TestAcc 0.5636 0.5550
epoch 200 LossPred 0.9260 LossAtt 0.3680 TrainAcc 0.6200 TestAcc 0.5911 0.6200
epoch 300 LossPred 0.9061 LossAtt 0.3640 TrainAcc 0.6200 TestAcc 0.5911 0.6200
epoch 400 LossPred 0.6019 LossAtt 0.3309 TrainAcc 0.7800 TestAcc 0.8078 0.8000
epoch 500 LossPred 0.5852 LossAtt 0.3371 TrainAcc 0.8000 TestAcc 0.7905 0.7950
epoch 600 LossPred 0.5456 LossAtt 0.3045 TrainAcc 0.8000 TestAcc 0.8003 0.7950
epoch 700 LossPred 0.5452 LossAtt 0.2902 TrainAcc 0.7900 TestAcc 0.7988 0.7950
epoch 800 LossPred 0.5859 LossAtt 0.3091 TrainAcc 0.8000 TestAcc 0.7745 0.7900
epoch 900 LossPred 0.5707 LossAtt 0.2953 TrainAcc 0.7900 TestAcc 0.7915 0.7800
epoch 1000 LossPred 0.6052 LossAtt 0.3019 TrainAcc 0.7800 TestAcc 0.8293 0.7900
epoch 1100 LossPred 0.5692 LossAtt 0.3034 TrainAcc 0.8000 TestAcc 0.8161 0.8050
epoch 1200 LossPred 0.5887 LossAtt 0.2960 TrainAcc 0.7900 TestAcc 0.8096 0.7950
epoch 1300 LossPred 0.5991 LossAtt 0.2989 TrainAcc 0.7700 TestAcc 0.7890 0.7650
epoch 1400 LossPred 0.5328 LossAtt 0.2989 TrainAcc 0.8000 TestAcc 0.7953 0.8050
epoch 1500 LossPred 0.5162 LossAtt 0.2890 TrainAcc 0.8300 TestAcc 0.7973 0.8100
epoch 1600 LossPred 0.5488 LossAtt 0.2913 TrainAcc 0.8000 TestAcc 0.7908 0.8050
epoch 1700 LossPred 0.5275 LossAtt 0.3008 TrainAcc 0.8300 TestAcc 0.7855 0.7800
epoch 1800 LossPred 0.7297 LossAtt 0.2828 TrainAcc 0.7500 TestAcc 0.7553 0.7350
epoch 1900 LossPred 0.6482 LossAtt 0.3018 TrainAcc 0.7800 TestAcc 0.7983 0.7900
epoch 2000 LossPred 0.5457 LossAtt 0.2907 TrainAcc 0.8200 TestAcc 0.8078 0.8100
epoch 2100 LossPred 0.9714 LossAtt 0.2723 TrainAcc 0.6500 TestAcc 0.6451 0.6500
epoch 2200 LossPred 0.8768 LossAtt 0.2381 TrainAcc 0.6600 TestAcc 0.6507 0.6500
epoch 2300 LossPred 0.8034 LossAtt 0.2463 TrainAcc 0.7000 TestAcc 0.6922 0.7000
epoch 2400 LossPred 0.6571 LossAtt 0.2745 TrainAcc 0.8000 TestAcc 0.7765 0.7650
epoch 2500 LossPred 0.5845 LossAtt 0.3043 TrainAcc 0.8100 TestAcc 0.8073 0.8000
Optimization Finished!
********** replication  79  **********
epoch   0 LossPred 1.1673 LossAtt 1.0303 TrainAcc 0.4200 TestAcc 0.4482 0.4500
epoch 100 LossPred 0.9481 LossAtt 0.3479 TrainAcc 0.5900 TestAcc 0.5816 0.6000
epoch 200 LossPred 0.9360 LossAtt 0.3486 TrainAcc 0.6000 TestAcc 0.6089 0.5900
epoch 300 LossPred 0.9163 LossAtt 0.3380 TrainAcc 0.6000 TestAcc 0.6159 0.6150
epoch 400 LossPred 0.9050 LossAtt 0.3617 TrainAcc 0.6100 TestAcc 0.6011 0.5950
epoch 500 LossPred 0.8835 LossAtt 0.3771 TrainAcc 0.6400 TestAcc 0.6031 0.6650
epoch 600 LossPred 0.8581 LossAtt 0.3831 TrainAcc 0.6800 TestAcc 0.6121 0.6650
epoch 700 LossPred 0.8473 LossAtt 0.3804 TrainAcc 0.6500 TestAcc 0.6139 0.6550
epoch 800 LossPred 0.8330 LossAtt 0.3635 TrainAcc 0.6500 TestAcc 0.6191 0.6550
epoch 900 LossPred 0.8170 LossAtt 0.3914 TrainAcc 0.6600 TestAcc 0.6161 0.6550
epoch 1000 LossPred 0.8037 LossAtt 0.3863 TrainAcc 0.6700 TestAcc 0.5906 0.6350
epoch 1100 LossPred 0.8031 LossAtt 0.3844 TrainAcc 0.6700 TestAcc 0.6056 0.6550
epoch 1200 LossPred 0.7968 LossAtt 0.3778 TrainAcc 0.6800 TestAcc 0.5903 0.6400
epoch 1300 LossPred 0.7957 LossAtt 0.3510 TrainAcc 0.6700 TestAcc 0.5938 0.6500
epoch 1400 LossPred 0.7903 LossAtt 0.3802 TrainAcc 0.6700 TestAcc 0.5853 0.6600
epoch 1500 LossPred 0.7850 LossAtt 0.3634 TrainAcc 0.6800 TestAcc 0.5928 0.6400
epoch 1600 LossPred 0.7899 LossAtt 0.3400 TrainAcc 0.6900 TestAcc 0.5931 0.6650
epoch 1700 LossPred 0.7906 LossAtt 0.3262 TrainAcc 0.6700 TestAcc 0.5931 0.6600
epoch 1800 LossPred 0.7836 LossAtt 0.3274 TrainAcc 0.6700 TestAcc 0.5858 0.6650
epoch 1900 LossPred 0.7874 LossAtt 0.2957 TrainAcc 0.6800 TestAcc 0.5863 0.6600
epoch 2000 LossPred 0.7859 LossAtt 0.2884 TrainAcc 0.6800 TestAcc 0.5893 0.6650
epoch 2100 LossPred 0.7856 LossAtt 0.3086 TrainAcc 0.6900 TestAcc 0.5921 0.6500
epoch 2200 LossPred 0.7878 LossAtt 0.2953 TrainAcc 0.6900 TestAcc 0.5918 0.6450
epoch 2300 LossPred 0.7924 LossAtt 0.3000 TrainAcc 0.6900 TestAcc 0.5926 0.6300
epoch 2400 LossPred 0.7919 LossAtt 0.2849 TrainAcc 0.6700 TestAcc 0.5906 0.6550
epoch 2500 LossPred 0.7985 LossAtt 0.3069 TrainAcc 0.6800 TestAcc 0.5881 0.6350
Optimization Finished!
********** replication  80  **********
epoch   0 LossPred 1.1056 LossAtt 1.0137 TrainAcc 0.4700 TestAcc 0.5053 0.4850
epoch 100 LossPred 0.9242 LossAtt 0.5065 TrainAcc 0.5900 TestAcc 0.5996 0.5900
epoch 200 LossPred 0.8922 LossAtt 0.4519 TrainAcc 0.6200 TestAcc 0.5801 0.6150
epoch 300 LossPred 0.8827 LossAtt 0.3466 TrainAcc 0.6200 TestAcc 0.5758 0.6200
epoch 400 LossPred 0.8797 LossAtt 0.2760 TrainAcc 0.6200 TestAcc 0.5758 0.6200
epoch 500 LossPred 0.8777 LossAtt 0.2324 TrainAcc 0.6200 TestAcc 0.5758 0.6200
epoch 600 LossPred 0.8790 LossAtt 0.2180 TrainAcc 0.6200 TestAcc 0.5758 0.6200
epoch 700 LossPred 0.8805 LossAtt 0.1985 TrainAcc 0.6200 TestAcc 0.5758 0.6200
epoch 800 LossPred 0.8755 LossAtt 0.1726 TrainAcc 0.6200 TestAcc 0.5758 0.6200
epoch 900 LossPred 0.8733 LossAtt 0.1642 TrainAcc 0.6200 TestAcc 0.5758 0.6200
epoch 1000 LossPred 0.8719 LossAtt 0.1569 TrainAcc 0.6200 TestAcc 0.5758 0.6200
epoch 1100 LossPred 0.8686 LossAtt 0.1440 TrainAcc 0.6200 TestAcc 0.5758 0.6350
epoch 1200 LossPred 0.8045 LossAtt 0.4805 TrainAcc 0.7000 TestAcc 0.6356 0.6900
epoch 1300 LossPred 0.6045 LossAtt 0.4762 TrainAcc 0.8200 TestAcc 0.7407 0.7750
epoch 1400 LossPred 0.4524 LossAtt 0.4122 TrainAcc 0.8700 TestAcc 0.7833 0.8600
epoch 1500 LossPred 0.4243 LossAtt 0.3690 TrainAcc 0.8700 TestAcc 0.8083 0.8850
epoch 1600 LossPred 0.3759 LossAtt 0.3765 TrainAcc 0.9000 TestAcc 0.8183 0.8900
epoch 1700 LossPred 0.4727 LossAtt 0.3693 TrainAcc 0.8500 TestAcc 0.8038 0.8400
epoch 1800 LossPred 0.3279 LossAtt 0.3663 TrainAcc 0.9000 TestAcc 0.8401 0.8900
epoch 1900 LossPred 0.4143 LossAtt 0.3530 TrainAcc 0.8900 TestAcc 0.8241 0.8700
epoch 2000 LossPred 0.3140 LossAtt 0.3527 TrainAcc 0.9100 TestAcc 0.8446 0.8950
epoch 2100 LossPred 0.4176 LossAtt 0.3599 TrainAcc 0.8600 TestAcc 0.8103 0.8450
epoch 2200 LossPred 0.3075 LossAtt 0.3761 TrainAcc 0.9000 TestAcc 0.8323 0.8600
epoch 2300 LossPred 0.3159 LossAtt 0.3447 TrainAcc 0.9100 TestAcc 0.8408 0.9000
epoch 2400 LossPred 0.4258 LossAtt 0.3344 TrainAcc 0.8600 TestAcc 0.8086 0.8550
epoch 2500 LossPred 0.3718 LossAtt 0.3457 TrainAcc 0.8600 TestAcc 0.8156 0.8700
Optimization Finished!
********** replication  81  **********
epoch   0 LossPred 0.9698 LossAtt 1.0040 TrainAcc 0.6600 TestAcc 0.5561 0.5900
epoch 100 LossPred 0.8394 LossAtt 0.3946 TrainAcc 0.6700 TestAcc 0.5908 0.6700
epoch 200 LossPred 0.8237 LossAtt 0.3019 TrainAcc 0.6700 TestAcc 0.5908 0.6700
epoch 300 LossPred 0.8150 LossAtt 0.2520 TrainAcc 0.6700 TestAcc 0.5908 0.6700
epoch 400 LossPred 0.8104 LossAtt 0.2180 TrainAcc 0.6700 TestAcc 0.5908 0.6700
epoch 500 LossPred 0.7982 LossAtt 0.2426 TrainAcc 0.6700 TestAcc 0.5908 0.6700
epoch 600 LossPred 0.7908 LossAtt 0.2489 TrainAcc 0.6700 TestAcc 0.5908 0.6700
epoch 700 LossPred 0.7083 LossAtt 0.4125 TrainAcc 0.7500 TestAcc 0.7147 0.7450
epoch 800 LossPred 0.3939 LossAtt 0.3574 TrainAcc 0.9000 TestAcc 0.7835 0.8750
epoch 900 LossPred 0.6195 LossAtt 0.3762 TrainAcc 0.7500 TestAcc 0.6802 0.7400
epoch 1000 LossPred 0.4978 LossAtt 0.2986 TrainAcc 0.8500 TestAcc 0.7417 0.8350
epoch 1100 LossPred 0.8055 LossAtt 0.2829 TrainAcc 0.7300 TestAcc 0.6827 0.7900
epoch 1200 LossPred 1.5510 LossAtt 0.2674 TrainAcc 0.3300 TestAcc 0.4092 0.3300
epoch 1300 LossPred 0.9255 LossAtt 0.1257 TrainAcc 0.6700 TestAcc 0.5908 0.6700
epoch 1400 LossPred 0.8802 LossAtt 0.1008 TrainAcc 0.6700 TestAcc 0.5908 0.6700
epoch 1500 LossPred 0.8632 LossAtt 0.0973 TrainAcc 0.6700 TestAcc 0.5908 0.6700
epoch 1600 LossPred 0.8321 LossAtt 0.1773 TrainAcc 0.6700 TestAcc 0.5908 0.6700
epoch 1700 LossPred 0.8188 LossAtt 0.1895 TrainAcc 0.6700 TestAcc 0.5908 0.6700
epoch 1800 LossPred 0.6739 LossAtt 0.2309 TrainAcc 0.7400 TestAcc 0.6962 0.7150
epoch 1900 LossPred 0.4518 LossAtt 0.2466 TrainAcc 0.8200 TestAcc 0.7190 0.8250
epoch 2000 LossPred 0.5357 LossAtt 0.2256 TrainAcc 0.8400 TestAcc 0.7775 0.8500
epoch 2100 LossPred 0.5957 LossAtt 0.2145 TrainAcc 0.7900 TestAcc 0.7332 0.8050
epoch 2200 LossPred 0.4904 LossAtt 0.2331 TrainAcc 0.8700 TestAcc 0.7935 0.8250
epoch 2300 LossPred 0.4251 LossAtt 0.2309 TrainAcc 0.8700 TestAcc 0.7655 0.8500
epoch 2400 LossPred 0.4209 LossAtt 0.2380 TrainAcc 0.8900 TestAcc 0.7885 0.8300
epoch 2500 LossPred 0.4257 LossAtt 0.2173 TrainAcc 0.8700 TestAcc 0.7628 0.8600
Optimization Finished!
********** replication  82  **********
epoch   0 LossPred 1.2137 LossAtt 0.9956 TrainAcc 0.4600 TestAcc 0.4094 0.4600
epoch 100 LossPred 0.9661 LossAtt 0.2605 TrainAcc 0.6300 TestAcc 0.6161 0.5550
epoch 200 LossPred 0.9595 LossAtt 0.1958 TrainAcc 0.5800 TestAcc 0.5881 0.5800
epoch 300 LossPred 0.9334 LossAtt 0.2350 TrainAcc 0.6300 TestAcc 0.6286 0.6450
epoch 400 LossPred 0.8493 LossAtt 0.2906 TrainAcc 0.6800 TestAcc 0.6184 0.6700
epoch 500 LossPred 0.8954 LossAtt 0.3154 TrainAcc 0.6600 TestAcc 0.6989 0.6650
epoch 600 LossPred 0.6183 LossAtt 0.2865 TrainAcc 0.7500 TestAcc 0.7825 0.7650
epoch 700 LossPred 0.3522 LossAtt 0.3056 TrainAcc 0.9000 TestAcc 0.8809 0.8850
epoch 800 LossPred 0.3886 LossAtt 0.3090 TrainAcc 0.9000 TestAcc 0.8629 0.8850
epoch 900 LossPred 0.3002 LossAtt 0.3184 TrainAcc 0.9200 TestAcc 0.8994 0.9050
epoch 1000 LossPred 0.2828 LossAtt 0.3030 TrainAcc 0.9300 TestAcc 0.8986 0.8950
epoch 1100 LossPred 0.2774 LossAtt 0.2973 TrainAcc 0.9200 TestAcc 0.8966 0.8950
epoch 1200 LossPred 0.4313 LossAtt 0.2655 TrainAcc 0.8300 TestAcc 0.8416 0.8600
epoch 1300 LossPred 0.5599 LossAtt 0.2944 TrainAcc 0.7900 TestAcc 0.7297 0.7850
epoch 1400 LossPred 0.7253 LossAtt 0.2752 TrainAcc 0.7000 TestAcc 0.7212 0.7000
epoch 1500 LossPred 0.7759 LossAtt 0.2748 TrainAcc 0.7100 TestAcc 0.7205 0.7100
epoch 1600 LossPred 0.8636 LossAtt 0.3039 TrainAcc 0.6800 TestAcc 0.7237 0.6750
epoch 1700 LossPred 0.4809 LossAtt 0.3018 TrainAcc 0.8200 TestAcc 0.8266 0.8200
epoch 1800 LossPred 0.5628 LossAtt 0.3168 TrainAcc 0.8000 TestAcc 0.8078 0.8000
epoch 1900 LossPred 0.4852 LossAtt 0.3252 TrainAcc 0.8200 TestAcc 0.8253 0.8200
epoch 2000 LossPred 0.6024 LossAtt 0.3416 TrainAcc 0.8100 TestAcc 0.7733 0.8150
epoch 2100 LossPred 0.3709 LossAtt 0.3412 TrainAcc 0.8800 TestAcc 0.8759 0.8800
epoch 2200 LossPred 0.3345 LossAtt 0.3378 TrainAcc 0.9000 TestAcc 0.8549 0.9000
epoch 2300 LossPred 0.3822 LossAtt 0.3467 TrainAcc 0.8800 TestAcc 0.8203 0.8800
epoch 2400 LossPred 0.3214 LossAtt 0.3499 TrainAcc 0.9100 TestAcc 0.8566 0.9050
epoch 2500 LossPred 0.3230 LossAtt 0.3678 TrainAcc 0.9100 TestAcc 0.8504 0.9050
Optimization Finished!
********** replication  83  **********
epoch   0 LossPred 1.0365 LossAtt 1.0018 TrainAcc 0.6100 TestAcc 0.5568 0.5800
epoch 100 LossPred 0.8421 LossAtt 0.4292 TrainAcc 0.7100 TestAcc 0.5991 0.7100
epoch 200 LossPred 0.8162 LossAtt 0.4302 TrainAcc 0.6900 TestAcc 0.5868 0.6950
epoch 300 LossPred 0.7668 LossAtt 0.4055 TrainAcc 0.7500 TestAcc 0.5976 0.7500
epoch 400 LossPred 0.7208 LossAtt 0.3792 TrainAcc 0.7500 TestAcc 0.6171 0.7500
epoch 500 LossPred 0.6254 LossAtt 0.5480 TrainAcc 0.8000 TestAcc 0.6461 0.7750
epoch 600 LossPred 0.4152 LossAtt 0.5624 TrainAcc 0.8300 TestAcc 0.8076 0.8300
epoch 700 LossPred 0.3241 LossAtt 0.5255 TrainAcc 0.8900 TestAcc 0.8308 0.8750
epoch 800 LossPred 0.2105 LossAtt 0.5294 TrainAcc 0.9300 TestAcc 0.8666 0.9000
epoch 900 LossPred 0.1902 LossAtt 0.4976 TrainAcc 0.9400 TestAcc 0.8704 0.9150
epoch 1000 LossPred 0.2495 LossAtt 0.5049 TrainAcc 0.9100 TestAcc 0.8634 0.8950
epoch 1100 LossPred 0.2175 LossAtt 0.4569 TrainAcc 0.9300 TestAcc 0.8591 0.9100
epoch 1200 LossPred 0.4979 LossAtt 0.4610 TrainAcc 0.8200 TestAcc 0.7923 0.8300
epoch 1300 LossPred 0.3459 LossAtt 0.4305 TrainAcc 0.8700 TestAcc 0.8291 0.8750
epoch 1400 LossPred 0.1581 LossAtt 0.4399 TrainAcc 0.9400 TestAcc 0.8581 0.9450
epoch 1500 LossPred 0.1617 LossAtt 0.4225 TrainAcc 0.9400 TestAcc 0.8509 0.9300
epoch 1600 LossPred 0.1536 LossAtt 0.4122 TrainAcc 0.9400 TestAcc 0.8559 0.9350
epoch 1700 LossPred 0.1521 LossAtt 0.4199 TrainAcc 0.9600 TestAcc 0.8609 0.9550
epoch 1800 LossPred 0.2372 LossAtt 0.4155 TrainAcc 0.9200 TestAcc 0.8443 0.9200
epoch 1900 LossPred 0.1898 LossAtt 0.4172 TrainAcc 0.9400 TestAcc 0.8549 0.9150
epoch 2000 LossPred 0.1624 LossAtt 0.4275 TrainAcc 0.9400 TestAcc 0.8596 0.9350
epoch 2100 LossPred 0.1603 LossAtt 0.4192 TrainAcc 0.9400 TestAcc 0.8546 0.9250
epoch 2200 LossPred 0.1518 LossAtt 0.4186 TrainAcc 0.9500 TestAcc 0.8624 0.9500
epoch 2300 LossPred 0.1474 LossAtt 0.3925 TrainAcc 0.9400 TestAcc 0.8649 0.9300
epoch 2400 LossPred 0.1866 LossAtt 0.4007 TrainAcc 0.9400 TestAcc 0.8619 0.9400
epoch 2500 LossPred 0.1524 LossAtt 0.3918 TrainAcc 0.9400 TestAcc 0.8629 0.9250
Optimization Finished!
********** replication  84  **********
epoch   0 LossPred 1.0737 LossAtt 1.0239 TrainAcc 0.5000 TestAcc 0.4797 0.4950
epoch 100 LossPred 0.9541 LossAtt 0.3756 TrainAcc 0.5500 TestAcc 0.5493 0.5500
epoch 200 LossPred 0.9299 LossAtt 0.3231 TrainAcc 0.6500 TestAcc 0.6164 0.6150
epoch 300 LossPred 0.5097 LossAtt 0.4038 TrainAcc 0.8400 TestAcc 0.8436 0.8150
epoch 400 LossPred 0.4395 LossAtt 0.4027 TrainAcc 0.8600 TestAcc 0.8556 0.8350
epoch 500 LossPred 0.4305 LossAtt 0.3870 TrainAcc 0.8700 TestAcc 0.8561 0.8400
epoch 600 LossPred 0.4060 LossAtt 0.3979 TrainAcc 0.8800 TestAcc 0.8674 0.8550
epoch 700 LossPred 0.4053 LossAtt 0.3969 TrainAcc 0.8700 TestAcc 0.8584 0.8450
epoch 800 LossPred 0.3964 LossAtt 0.3945 TrainAcc 0.8700 TestAcc 0.8609 0.8300
epoch 900 LossPred 0.4047 LossAtt 0.3960 TrainAcc 0.8900 TestAcc 0.8716 0.8650
epoch 1000 LossPred 0.3958 LossAtt 0.3897 TrainAcc 0.8800 TestAcc 0.8739 0.8750
epoch 1100 LossPred 0.3794 LossAtt 0.4011 TrainAcc 0.8700 TestAcc 0.8781 0.8650
epoch 1200 LossPred 0.4075 LossAtt 0.3868 TrainAcc 0.8900 TestAcc 0.8721 0.8750
epoch 1300 LossPred 0.4594 LossAtt 0.3848 TrainAcc 0.8400 TestAcc 0.8691 0.8400
epoch 1400 LossPred 0.3845 LossAtt 0.3867 TrainAcc 0.8800 TestAcc 0.8836 0.8750
epoch 1500 LossPred 0.4980 LossAtt 0.3855 TrainAcc 0.8300 TestAcc 0.8356 0.8500
epoch 1600 LossPred 0.4131 LossAtt 0.3507 TrainAcc 0.8500 TestAcc 0.8834 0.8850
epoch 1700 LossPred 0.4135 LossAtt 0.3368 TrainAcc 0.8700 TestAcc 0.8626 0.8700
epoch 1800 LossPred 0.5297 LossAtt 0.3439 TrainAcc 0.8100 TestAcc 0.8368 0.7850
epoch 1900 LossPred 0.4814 LossAtt 0.3284 TrainAcc 0.8500 TestAcc 0.8406 0.8600
epoch 2000 LossPred 0.3195 LossAtt 0.3337 TrainAcc 0.8900 TestAcc 0.9089 0.8900
epoch 2100 LossPred 0.3177 LossAtt 0.3285 TrainAcc 0.8800 TestAcc 0.9029 0.8550
epoch 2200 LossPred 0.4502 LossAtt 0.3035 TrainAcc 0.8400 TestAcc 0.8639 0.8650
epoch 2300 LossPred 0.3965 LossAtt 0.3036 TrainAcc 0.8600 TestAcc 0.8771 0.8400
epoch 2400 LossPred 0.2608 LossAtt 0.3041 TrainAcc 0.9200 TestAcc 0.9207 0.8900
epoch 2500 LossPred 0.3441 LossAtt 0.2971 TrainAcc 0.8700 TestAcc 0.8804 0.8750
Optimization Finished!
********** replication  85  **********
epoch   0 LossPred 1.1005 LossAtt 1.0602 TrainAcc 0.5100 TestAcc 0.5093 0.4850
epoch 100 LossPred 0.9857 LossAtt 0.3436 TrainAcc 0.5600 TestAcc 0.5876 0.5600
epoch 200 LossPred 0.9845 LossAtt 0.2132 TrainAcc 0.5600 TestAcc 0.5876 0.5600
epoch 300 LossPred 0.9856 LossAtt 0.2564 TrainAcc 0.5600 TestAcc 0.5876 0.5600
epoch 400 LossPred 0.9801 LossAtt 0.2677 TrainAcc 0.5600 TestAcc 0.5876 0.5600
epoch 500 LossPred 0.9774 LossAtt 0.2714 TrainAcc 0.5600 TestAcc 0.5876 0.5600
epoch 600 LossPred 0.9722 LossAtt 0.2992 TrainAcc 0.5600 TestAcc 0.5876 0.5600
epoch 700 LossPred 0.9565 LossAtt 0.3413 TrainAcc 0.6100 TestAcc 0.6281 0.6100
epoch 800 LossPred 0.9056 LossAtt 0.3516 TrainAcc 0.6300 TestAcc 0.6341 0.6150
epoch 900 LossPred 0.7195 LossAtt 0.3382 TrainAcc 0.7200 TestAcc 0.7633 0.7200
epoch 1000 LossPred 0.4229 LossAtt 0.2661 TrainAcc 0.8800 TestAcc 0.8011 0.8600
epoch 1100 LossPred 0.3454 LossAtt 0.2676 TrainAcc 0.8900 TestAcc 0.8273 0.8700
epoch 1200 LossPred 0.7155 LossAtt 0.2730 TrainAcc 0.7500 TestAcc 0.7275 0.7550
epoch 1300 LossPred 0.3545 LossAtt 0.2427 TrainAcc 0.9000 TestAcc 0.8376 0.8900
epoch 1400 LossPred 0.3165 LossAtt 0.2369 TrainAcc 0.9100 TestAcc 0.8789 0.8950
epoch 1500 LossPred 0.2112 LossAtt 0.2498 TrainAcc 0.9500 TestAcc 0.8826 0.9300
epoch 1600 LossPred 0.5082 LossAtt 0.2528 TrainAcc 0.8200 TestAcc 0.8008 0.8000
epoch 1700 LossPred 0.3463 LossAtt 0.2437 TrainAcc 0.9100 TestAcc 0.8641 0.8950
epoch 1800 LossPred 0.3054 LossAtt 0.2535 TrainAcc 0.9100 TestAcc 0.8549 0.9050
epoch 1900 LossPred 0.2885 LossAtt 0.2286 TrainAcc 0.9100 TestAcc 0.8836 0.9050
epoch 2000 LossPred 0.2654 LossAtt 0.2383 TrainAcc 0.9100 TestAcc 0.8699 0.9050
epoch 2100 LossPred 0.1975 LossAtt 0.2528 TrainAcc 0.9700 TestAcc 0.8949 0.9400
epoch 2200 LossPred 0.2905 LossAtt 0.2396 TrainAcc 0.9200 TestAcc 0.8759 0.9150
epoch 2300 LossPred 0.2498 LossAtt 0.2333 TrainAcc 0.9100 TestAcc 0.8969 0.9150
epoch 2400 LossPred 0.3147 LossAtt 0.2413 TrainAcc 0.9100 TestAcc 0.8649 0.9000
epoch 2500 LossPred 0.2673 LossAtt 0.2784 TrainAcc 0.9100 TestAcc 0.8854 0.9050
Optimization Finished!
********** replication  86  **********
epoch   0 LossPred 1.1015 LossAtt 1.0183 TrainAcc 0.3900 TestAcc 0.4164 0.4000
epoch 100 LossPred 0.9330 LossAtt 0.4424 TrainAcc 0.6300 TestAcc 0.6346 0.6300
epoch 200 LossPred 0.8591 LossAtt 0.4577 TrainAcc 0.6300 TestAcc 0.6687 0.6250
epoch 300 LossPred 0.5189 LossAtt 0.4575 TrainAcc 0.8300 TestAcc 0.8168 0.8050
epoch 400 LossPred 0.3273 LossAtt 0.3886 TrainAcc 0.9200 TestAcc 0.8764 0.9150
epoch 500 LossPred 0.2765 LossAtt 0.3630 TrainAcc 0.9500 TestAcc 0.8839 0.9250
epoch 600 LossPred 0.2730 LossAtt 0.3615 TrainAcc 0.9200 TestAcc 0.8846 0.9200
epoch 700 LossPred 0.2975 LossAtt 0.3813 TrainAcc 0.8800 TestAcc 0.8731 0.8900
epoch 800 LossPred 0.2843 LossAtt 0.3945 TrainAcc 0.9100 TestAcc 0.8849 0.9050
epoch 900 LossPred 0.2603 LossAtt 0.3765 TrainAcc 0.9300 TestAcc 0.8891 0.9050
epoch 1000 LossPred 0.3584 LossAtt 0.3785 TrainAcc 0.8700 TestAcc 0.8559 0.8700
epoch 1100 LossPred 0.2447 LossAtt 0.3799 TrainAcc 0.9300 TestAcc 0.8869 0.9350
epoch 1200 LossPred 0.6759 LossAtt 0.4027 TrainAcc 0.7500 TestAcc 0.7397 0.7650
epoch 1300 LossPred 0.3916 LossAtt 0.4562 TrainAcc 0.8600 TestAcc 0.8589 0.8450
epoch 1400 LossPred 0.5602 LossAtt 0.4272 TrainAcc 0.8100 TestAcc 0.7833 0.7750
epoch 1500 LossPred 0.3156 LossAtt 0.4119 TrainAcc 0.9000 TestAcc 0.8669 0.8800
epoch 1600 LossPred 0.2331 LossAtt 0.4266 TrainAcc 0.9200 TestAcc 0.8841 0.9100
epoch 1700 LossPred 0.2122 LossAtt 0.4061 TrainAcc 0.9400 TestAcc 0.8921 0.9150
epoch 1800 LossPred 0.2639 LossAtt 0.4115 TrainAcc 0.9200 TestAcc 0.8736 0.9050
epoch 1900 LossPred 0.2076 LossAtt 0.3808 TrainAcc 0.9400 TestAcc 0.8884 0.9250
epoch 2000 LossPred 0.4739 LossAtt 0.4059 TrainAcc 0.8200 TestAcc 0.7868 0.8100
epoch 2100 LossPred 0.3369 LossAtt 0.4021 TrainAcc 0.8800 TestAcc 0.8456 0.8700
epoch 2200 LossPred 0.2032 LossAtt 0.3631 TrainAcc 0.9400 TestAcc 0.8966 0.9200
epoch 2300 LossPred 0.1980 LossAtt 0.3723 TrainAcc 0.9400 TestAcc 0.8931 0.9250
epoch 2400 LossPred 0.2325 LossAtt 0.3591 TrainAcc 0.9200 TestAcc 0.8904 0.9200
epoch 2500 LossPred 0.2023 LossAtt 0.3528 TrainAcc 0.9400 TestAcc 0.8921 0.9300
Optimization Finished!
********** replication  87  **********
epoch   0 LossPred 0.9844 LossAtt 1.0261 TrainAcc 0.6200 TestAcc 0.5183 0.6100
epoch 100 LossPred 0.8930 LossAtt 0.4077 TrainAcc 0.6400 TestAcc 0.5583 0.6150
epoch 200 LossPred 0.8657 LossAtt 0.3891 TrainAcc 0.6300 TestAcc 0.5390 0.6150
epoch 300 LossPred 0.8600 LossAtt 0.3974 TrainAcc 0.6600 TestAcc 0.5546 0.6600
epoch 400 LossPred 0.8525 LossAtt 0.4241 TrainAcc 0.6800 TestAcc 0.5588 0.6700
epoch 500 LossPred 0.8157 LossAtt 0.3424 TrainAcc 0.7100 TestAcc 0.5183 0.7100
epoch 600 LossPred 0.7946 LossAtt 0.3361 TrainAcc 0.7100 TestAcc 0.5275 0.7150
epoch 700 LossPred 0.7792 LossAtt 0.3739 TrainAcc 0.7200 TestAcc 0.5343 0.6850
epoch 800 LossPred 0.7559 LossAtt 0.4205 TrainAcc 0.7100 TestAcc 0.5250 0.7000
epoch 900 LossPred 0.7320 LossAtt 0.4169 TrainAcc 0.7100 TestAcc 0.5208 0.7100
epoch 1000 LossPred 0.6854 LossAtt 0.4986 TrainAcc 0.7600 TestAcc 0.5593 0.7450
epoch 1100 LossPred 0.6827 LossAtt 0.5198 TrainAcc 0.7500 TestAcc 0.5646 0.7300
epoch 1200 LossPred 0.6994 LossAtt 0.5175 TrainAcc 0.7400 TestAcc 0.5528 0.7450
epoch 1300 LossPred 0.6720 LossAtt 0.5294 TrainAcc 0.7600 TestAcc 0.5546 0.7400
epoch 1400 LossPred 0.6590 LossAtt 0.5299 TrainAcc 0.7700 TestAcc 0.5636 0.7550
epoch 1500 LossPred 0.6340 LossAtt 0.5105 TrainAcc 0.8000 TestAcc 0.5723 0.7700
epoch 1600 LossPred 0.6214 LossAtt 0.5724 TrainAcc 0.7600 TestAcc 0.5808 0.7250
epoch 1700 LossPred 0.7031 LossAtt 0.5759 TrainAcc 0.7200 TestAcc 0.5846 0.7200
epoch 1800 LossPred 0.5711 LossAtt 0.5620 TrainAcc 0.7900 TestAcc 0.5918 0.7400
epoch 1900 LossPred 0.5469 LossAtt 0.5284 TrainAcc 0.8000 TestAcc 0.5906 0.7450
epoch 2000 LossPred 0.5484 LossAtt 0.5521 TrainAcc 0.8200 TestAcc 0.5856 0.7500
epoch 2100 LossPred 0.5686 LossAtt 0.5074 TrainAcc 0.7900 TestAcc 0.5901 0.7500
epoch 2200 LossPred 0.5507 LossAtt 0.5405 TrainAcc 0.8100 TestAcc 0.5946 0.7650
epoch 2300 LossPred 0.6162 LossAtt 0.4735 TrainAcc 0.8000 TestAcc 0.6011 0.7300
epoch 2400 LossPred 0.5661 LossAtt 0.4897 TrainAcc 0.8100 TestAcc 0.5973 0.7600
epoch 2500 LossPred 0.5856 LossAtt 0.5173 TrainAcc 0.8100 TestAcc 0.5998 0.7500
Optimization Finished!
********** replication  88  **********
epoch   0 LossPred 1.1446 LossAtt 1.0119 TrainAcc 0.5100 TestAcc 0.4272 0.4900
epoch 100 LossPred 0.9536 LossAtt 0.4689 TrainAcc 0.5700 TestAcc 0.4910 0.5600
epoch 200 LossPred 0.9252 LossAtt 0.4561 TrainAcc 0.5700 TestAcc 0.4910 0.5750
epoch 300 LossPred 0.9018 LossAtt 0.4373 TrainAcc 0.5900 TestAcc 0.5103 0.5800
epoch 400 LossPred 0.5273 LossAtt 0.3548 TrainAcc 0.8600 TestAcc 0.8098 0.8350
epoch 500 LossPred 0.4621 LossAtt 0.3287 TrainAcc 0.8500 TestAcc 0.7745 0.8200
epoch 600 LossPred 0.4060 LossAtt 0.3109 TrainAcc 0.8800 TestAcc 0.7538 0.8650
epoch 700 LossPred 0.4038 LossAtt 0.3112 TrainAcc 0.8700 TestAcc 0.7728 0.8350
epoch 800 LossPred 0.3863 LossAtt 0.3170 TrainAcc 0.8900 TestAcc 0.7808 0.8500
epoch 900 LossPred 0.3850 LossAtt 0.3199 TrainAcc 0.8800 TestAcc 0.7670 0.8750
epoch 1000 LossPred 0.3812 LossAtt 0.3147 TrainAcc 0.8800 TestAcc 0.8008 0.8500
epoch 1100 LossPred 0.3872 LossAtt 0.3164 TrainAcc 0.8900 TestAcc 0.8298 0.8900
epoch 1200 LossPred 0.3704 LossAtt 0.3214 TrainAcc 0.8800 TestAcc 0.8216 0.8700
epoch 1300 LossPred 0.4227 LossAtt 0.3089 TrainAcc 0.8600 TestAcc 0.7923 0.8500
epoch 1400 LossPred 0.3643 LossAtt 0.3251 TrainAcc 0.8900 TestAcc 0.8461 0.8850
epoch 1500 LossPred 0.3304 LossAtt 0.3247 TrainAcc 0.9000 TestAcc 0.8151 0.8700
epoch 1600 LossPred 0.3030 LossAtt 0.3433 TrainAcc 0.9200 TestAcc 0.8116 0.8800
epoch 1700 LossPred 0.3557 LossAtt 0.3421 TrainAcc 0.8900 TestAcc 0.8148 0.8650
epoch 1800 LossPred 0.3181 LossAtt 0.3451 TrainAcc 0.9100 TestAcc 0.8048 0.8700
epoch 1900 LossPred 0.4123 LossAtt 0.3370 TrainAcc 0.8700 TestAcc 0.8511 0.8750
epoch 2000 LossPred 0.3713 LossAtt 0.3485 TrainAcc 0.9000 TestAcc 0.8011 0.8550
epoch 2100 LossPred 0.3204 LossAtt 0.3483 TrainAcc 0.9000 TestAcc 0.8333 0.8750
epoch 2200 LossPred 0.3398 LossAtt 0.3495 TrainAcc 0.9000 TestAcc 0.8078 0.8600
epoch 2300 LossPred 0.3870 LossAtt 0.3521 TrainAcc 0.8800 TestAcc 0.8496 0.8600
epoch 2400 LossPred 0.3495 LossAtt 0.3677 TrainAcc 0.8900 TestAcc 0.8386 0.8600
epoch 2500 LossPred 0.3159 LossAtt 0.3479 TrainAcc 0.9000 TestAcc 0.8278 0.8600
Optimization Finished!
********** replication  89  **********
epoch   0 LossPred 0.9658 LossAtt 0.9952 TrainAcc 0.5700 TestAcc 0.5741 0.5650
epoch 100 LossPred 0.8030 LossAtt 0.5074 TrainAcc 0.7200 TestAcc 0.6329 0.7150
epoch 200 LossPred 0.6599 LossAtt 0.5316 TrainAcc 0.7400 TestAcc 0.6862 0.7400
epoch 300 LossPred 0.5153 LossAtt 0.4824 TrainAcc 0.8200 TestAcc 0.8091 0.8400
epoch 400 LossPred 0.4386 LossAtt 0.4876 TrainAcc 0.8400 TestAcc 0.8408 0.8500
epoch 500 LossPred 0.3652 LossAtt 0.4318 TrainAcc 0.8700 TestAcc 0.8591 0.8800
epoch 600 LossPred 0.4596 LossAtt 0.4329 TrainAcc 0.8300 TestAcc 0.7958 0.8450
epoch 700 LossPred 0.4429 LossAtt 0.4333 TrainAcc 0.8500 TestAcc 0.8026 0.8650
epoch 800 LossPred 0.8427 LossAtt 0.3959 TrainAcc 0.6700 TestAcc 0.6852 0.6800
epoch 900 LossPred 0.5497 LossAtt 0.3922 TrainAcc 0.8100 TestAcc 0.7798 0.8100
epoch 1000 LossPred 0.6788 LossAtt 0.3781 TrainAcc 0.7100 TestAcc 0.6694 0.7000
epoch 1100 LossPred 0.5577 LossAtt 0.3829 TrainAcc 0.7900 TestAcc 0.7640 0.7800
epoch 1200 LossPred 0.6397 LossAtt 0.3577 TrainAcc 0.7400 TestAcc 0.7162 0.7450
epoch 1300 LossPred 0.6608 LossAtt 0.3343 TrainAcc 0.7500 TestAcc 0.6757 0.7400
epoch 1400 LossPred 0.5816 LossAtt 0.3630 TrainAcc 0.7600 TestAcc 0.7640 0.7750
epoch 1500 LossPred 0.5068 LossAtt 0.3354 TrainAcc 0.8300 TestAcc 0.7645 0.8050
epoch 1600 LossPred 0.4657 LossAtt 0.3462 TrainAcc 0.8500 TestAcc 0.8066 0.8500
epoch 1700 LossPred 0.5787 LossAtt 0.3158 TrainAcc 0.8000 TestAcc 0.7813 0.7900
epoch 1800 LossPred 0.6320 LossAtt 0.3166 TrainAcc 0.7900 TestAcc 0.7710 0.7800
epoch 1900 LossPred 0.5018 LossAtt 0.3146 TrainAcc 0.8000 TestAcc 0.8183 0.8000
epoch 2000 LossPred 0.3761 LossAtt 0.3131 TrainAcc 0.8700 TestAcc 0.8576 0.8500
epoch 2100 LossPred 0.7380 LossAtt 0.2895 TrainAcc 0.6900 TestAcc 0.6984 0.6900
epoch 2200 LossPred 0.6139 LossAtt 0.2872 TrainAcc 0.7700 TestAcc 0.7362 0.7500
epoch 2300 LossPred 0.5609 LossAtt 0.3230 TrainAcc 0.8000 TestAcc 0.8016 0.7950
epoch 2400 LossPred 0.7067 LossAtt 0.2993 TrainAcc 0.7400 TestAcc 0.7728 0.7550
epoch 2500 LossPred 0.6242 LossAtt 0.2707 TrainAcc 0.7700 TestAcc 0.7875 0.7750
Optimization Finished!
********** replication  90  **********
epoch   0 LossPred 1.2728 LossAtt 1.0053 TrainAcc 0.4500 TestAcc 0.4892 0.4550
epoch 100 LossPred 0.9756 LossAtt 0.2452 TrainAcc 0.6100 TestAcc 0.5751 0.6100
epoch 200 LossPred 0.8743 LossAtt 0.3584 TrainAcc 0.6100 TestAcc 0.5751 0.6100
epoch 300 LossPred 0.7920 LossAtt 0.4091 TrainAcc 0.7400 TestAcc 0.6396 0.7150
epoch 400 LossPred 0.5560 LossAtt 0.3772 TrainAcc 0.8100 TestAcc 0.7958 0.8000
epoch 500 LossPred 0.4927 LossAtt 0.3624 TrainAcc 0.8400 TestAcc 0.8396 0.8400
epoch 600 LossPred 0.4804 LossAtt 0.3497 TrainAcc 0.8300 TestAcc 0.8301 0.8500
epoch 700 LossPred 0.4207 LossAtt 0.3414 TrainAcc 0.8700 TestAcc 0.8328 0.8350
epoch 800 LossPred 0.4544 LossAtt 0.3214 TrainAcc 0.8300 TestAcc 0.8273 0.8400
epoch 900 LossPred 0.4259 LossAtt 0.3308 TrainAcc 0.8700 TestAcc 0.8236 0.8250
epoch 1000 LossPred 0.4568 LossAtt 0.3031 TrainAcc 0.8500 TestAcc 0.8121 0.8150
epoch 1100 LossPred 0.4678 LossAtt 0.3206 TrainAcc 0.8400 TestAcc 0.7928 0.8350
epoch 1200 LossPred 0.4796 LossAtt 0.3344 TrainAcc 0.8000 TestAcc 0.8011 0.8150
epoch 1300 LossPred 0.4657 LossAtt 0.3481 TrainAcc 0.8100 TestAcc 0.8041 0.8050
epoch 1400 LossPred 0.5033 LossAtt 0.3389 TrainAcc 0.8200 TestAcc 0.7800 0.8100
epoch 1500 LossPred 0.3871 LossAtt 0.3667 TrainAcc 0.8700 TestAcc 0.8646 0.8200
epoch 1600 LossPred 0.3094 LossAtt 0.3676 TrainAcc 0.9100 TestAcc 0.8814 0.8550
epoch 1700 LossPred 0.2946 LossAtt 0.3615 TrainAcc 0.8900 TestAcc 0.9009 0.8900
epoch 1800 LossPred 0.1900 LossAtt 0.3526 TrainAcc 0.9700 TestAcc 0.8874 0.9500
epoch 1900 LossPred 0.1528 LossAtt 0.3574 TrainAcc 0.9700 TestAcc 0.9157 0.9300
epoch 2000 LossPred 0.1492 LossAtt 0.3452 TrainAcc 0.9700 TestAcc 0.9099 0.9350
epoch 2100 LossPred 0.1576 LossAtt 0.3467 TrainAcc 0.9600 TestAcc 0.9124 0.9200
epoch 2200 LossPred 0.2417 LossAtt 0.3549 TrainAcc 0.9100 TestAcc 0.8641 0.8900
epoch 2300 LossPred 0.2087 LossAtt 0.3664 TrainAcc 0.9400 TestAcc 0.8699 0.8800
epoch 2400 LossPred 0.2726 LossAtt 0.3468 TrainAcc 0.9000 TestAcc 0.8368 0.8700
epoch 2500 LossPred 0.1869 LossAtt 0.3191 TrainAcc 0.9400 TestAcc 0.8789 0.9400
Optimization Finished!
********** replication  91  **********
epoch   0 LossPred 0.9453 LossAtt 0.9912 TrainAcc 0.5300 TestAcc 0.5638 0.5400
epoch 100 LossPred 0.8565 LossAtt 0.4167 TrainAcc 0.6700 TestAcc 0.6286 0.6550
epoch 200 LossPred 0.8538 LossAtt 0.3043 TrainAcc 0.6700 TestAcc 0.6286 0.6600
epoch 300 LossPred 0.8463 LossAtt 0.3165 TrainAcc 0.6700 TestAcc 0.6421 0.6650
epoch 400 LossPred 0.4468 LossAtt 0.3737 TrainAcc 0.8600 TestAcc 0.8446 0.8450
epoch 500 LossPred 0.3717 LossAtt 0.3529 TrainAcc 0.8600 TestAcc 0.8559 0.8750
epoch 600 LossPred 0.4171 LossAtt 0.3698 TrainAcc 0.8800 TestAcc 0.8546 0.8400
epoch 700 LossPred 0.3405 LossAtt 0.3632 TrainAcc 0.8800 TestAcc 0.8669 0.8550
epoch 800 LossPred 0.3785 LossAtt 0.3662 TrainAcc 0.8700 TestAcc 0.8596 0.8400
epoch 900 LossPred 0.3419 LossAtt 0.3559 TrainAcc 0.8700 TestAcc 0.8534 0.8750
epoch 1000 LossPred 0.3363 LossAtt 0.3744 TrainAcc 0.9000 TestAcc 0.8664 0.8450
epoch 1100 LossPred 0.3208 LossAtt 0.3612 TrainAcc 0.8800 TestAcc 0.8586 0.8800
epoch 1200 LossPred 0.3664 LossAtt 0.3434 TrainAcc 0.8400 TestAcc 0.8521 0.8500
epoch 1300 LossPred 0.3122 LossAtt 0.3445 TrainAcc 0.8800 TestAcc 0.8616 0.8800
epoch 1400 LossPred 0.3373 LossAtt 0.3504 TrainAcc 0.8700 TestAcc 0.8604 0.8650
epoch 1500 LossPred 0.2912 LossAtt 0.3781 TrainAcc 0.9100 TestAcc 0.8751 0.8750
epoch 1600 LossPred 0.3691 LossAtt 0.3495 TrainAcc 0.8800 TestAcc 0.8566 0.8400
epoch 1700 LossPred 0.2877 LossAtt 0.3579 TrainAcc 0.9000 TestAcc 0.8704 0.8800
epoch 1800 LossPred 0.6499 LossAtt 0.3549 TrainAcc 0.7800 TestAcc 0.7958 0.7650
epoch 1900 LossPred 0.3112 LossAtt 0.3488 TrainAcc 0.9000 TestAcc 0.8651 0.8650
epoch 2000 LossPred 0.3307 LossAtt 0.3267 TrainAcc 0.8600 TestAcc 0.8606 0.8750
epoch 2100 LossPred 0.2999 LossAtt 0.3546 TrainAcc 0.9000 TestAcc 0.8754 0.8750
epoch 2200 LossPred 0.5010 LossAtt 0.3841 TrainAcc 0.8300 TestAcc 0.8306 0.7950
epoch 2300 LossPred 0.3128 LossAtt 0.3503 TrainAcc 0.8900 TestAcc 0.8629 0.8750
epoch 2400 LossPred 0.2707 LossAtt 0.3645 TrainAcc 0.8900 TestAcc 0.8784 0.8800
epoch 2500 LossPred 0.5833 LossAtt 0.3428 TrainAcc 0.8000 TestAcc 0.8211 0.8250
Optimization Finished!
********** replication  92  **********
epoch   0 LossPred 1.3237 LossAtt 0.9988 TrainAcc 0.4500 TestAcc 0.4645 0.4400
epoch 100 LossPred 1.0207 LossAtt 0.4469 TrainAcc 0.5300 TestAcc 0.5398 0.5400
epoch 200 LossPred 0.9469 LossAtt 0.3551 TrainAcc 0.6800 TestAcc 0.6266 0.6300
epoch 300 LossPred 0.8823 LossAtt 0.4036 TrainAcc 0.7300 TestAcc 0.6839 0.7200
epoch 400 LossPred 0.5447 LossAtt 0.4854 TrainAcc 0.8300 TestAcc 0.7825 0.8150
epoch 500 LossPred 0.4153 LossAtt 0.4671 TrainAcc 0.8900 TestAcc 0.8421 0.8700
epoch 600 LossPred 0.3066 LossAtt 0.4659 TrainAcc 0.9500 TestAcc 0.8273 0.9150
epoch 700 LossPred 0.2965 LossAtt 0.4543 TrainAcc 0.9300 TestAcc 0.8336 0.9050
epoch 800 LossPred 0.2709 LossAtt 0.4484 TrainAcc 0.9300 TestAcc 0.8381 0.9150
epoch 900 LossPred 0.2462 LossAtt 0.4224 TrainAcc 0.9400 TestAcc 0.8301 0.9100
epoch 1000 LossPred 0.2400 LossAtt 0.4276 TrainAcc 0.9300 TestAcc 0.8393 0.9100
epoch 1100 LossPred 0.2426 LossAtt 0.4310 TrainAcc 0.9300 TestAcc 0.8133 0.9100
epoch 1200 LossPred 0.2138 LossAtt 0.4418 TrainAcc 0.9500 TestAcc 0.8406 0.9200
epoch 1300 LossPred 0.2139 LossAtt 0.4376 TrainAcc 0.9500 TestAcc 0.8373 0.9100
epoch 1400 LossPred 0.2001 LossAtt 0.4355 TrainAcc 0.9500 TestAcc 0.8396 0.9200
epoch 1500 LossPred 0.1705 LossAtt 0.4367 TrainAcc 0.9600 TestAcc 0.8393 0.9350
epoch 1600 LossPred 0.1684 LossAtt 0.4317 TrainAcc 0.9600 TestAcc 0.8428 0.9400
epoch 1700 LossPred 0.2005 LossAtt 0.4322 TrainAcc 0.9300 TestAcc 0.8301 0.9250
epoch 1800 LossPred 0.1834 LossAtt 0.4324 TrainAcc 0.9500 TestAcc 0.8343 0.9300
epoch 1900 LossPred 0.1985 LossAtt 0.4265 TrainAcc 0.9400 TestAcc 0.8326 0.9150
epoch 2000 LossPred 0.1625 LossAtt 0.4223 TrainAcc 0.9500 TestAcc 0.8506 0.9250
epoch 2100 LossPred 0.1403 LossAtt 0.4031 TrainAcc 0.9700 TestAcc 0.8696 0.9350
epoch 2200 LossPred 0.2288 LossAtt 0.4066 TrainAcc 0.9200 TestAcc 0.8704 0.9050
epoch 2300 LossPred 0.1389 LossAtt 0.4236 TrainAcc 0.9500 TestAcc 0.8846 0.9400
epoch 2400 LossPred 0.1259 LossAtt 0.4065 TrainAcc 0.9600 TestAcc 0.8844 0.9550
epoch 2500 LossPred 0.1429 LossAtt 0.4267 TrainAcc 0.9600 TestAcc 0.8726 0.9400
Optimization Finished!
********** replication  93  **********
epoch   0 LossPred 1.0672 LossAtt 1.0302 TrainAcc 0.5700 TestAcc 0.5078 0.5800
epoch 100 LossPred 0.8116 LossAtt 0.3129 TrainAcc 0.6800 TestAcc 0.5946 0.6600
epoch 200 LossPred 0.7842 LossAtt 0.2048 TrainAcc 0.6800 TestAcc 0.5946 0.6850
epoch 300 LossPred 0.7482 LossAtt 0.2899 TrainAcc 0.7400 TestAcc 0.6269 0.7550
epoch 400 LossPred 0.4995 LossAtt 0.3755 TrainAcc 0.8400 TestAcc 0.7948 0.8300
epoch 500 LossPred 0.3748 LossAtt 0.3384 TrainAcc 0.8800 TestAcc 0.8298 0.8400
epoch 600 LossPred 0.3698 LossAtt 0.3466 TrainAcc 0.8700 TestAcc 0.8403 0.8700
epoch 700 LossPred 0.3804 LossAtt 0.3488 TrainAcc 0.8300 TestAcc 0.8684 0.8700
epoch 800 LossPred 0.4177 LossAtt 0.3296 TrainAcc 0.8300 TestAcc 0.8341 0.8350
epoch 900 LossPred 0.3856 LossAtt 0.3404 TrainAcc 0.8700 TestAcc 0.8448 0.8750
epoch 1000 LossPred 0.3292 LossAtt 0.3498 TrainAcc 0.8800 TestAcc 0.8634 0.8700
epoch 1100 LossPred 0.3503 LossAtt 0.3401 TrainAcc 0.8700 TestAcc 0.8446 0.8700
epoch 1200 LossPred 0.3082 LossAtt 0.3292 TrainAcc 0.8600 TestAcc 0.8626 0.8700
epoch 1300 LossPred 0.3371 LossAtt 0.3161 TrainAcc 0.8500 TestAcc 0.8564 0.8700
epoch 1400 LossPred 0.3070 LossAtt 0.3145 TrainAcc 0.9100 TestAcc 0.8509 0.8800
epoch 1500 LossPred 0.3588 LossAtt 0.3145 TrainAcc 0.8800 TestAcc 0.8641 0.8750
epoch 1600 LossPred 0.3623 LossAtt 0.3022 TrainAcc 0.8400 TestAcc 0.8443 0.8650
epoch 1700 LossPred 0.3702 LossAtt 0.3192 TrainAcc 0.8400 TestAcc 0.8436 0.8600
epoch 1800 LossPred 0.3805 LossAtt 0.3308 TrainAcc 0.8800 TestAcc 0.8636 0.8700
epoch 1900 LossPred 0.3047 LossAtt 0.3227 TrainAcc 0.8900 TestAcc 0.8784 0.8750
epoch 2000 LossPred 0.2802 LossAtt 0.3052 TrainAcc 0.8900 TestAcc 0.8779 0.8750
epoch 2100 LossPred 0.3250 LossAtt 0.3050 TrainAcc 0.8800 TestAcc 0.8549 0.8750
epoch 2200 LossPred 0.2949 LossAtt 0.3132 TrainAcc 0.8800 TestAcc 0.8836 0.8750
epoch 2300 LossPred 0.3006 LossAtt 0.3113 TrainAcc 0.9000 TestAcc 0.8781 0.8750
epoch 2400 LossPred 0.3288 LossAtt 0.2956 TrainAcc 0.8800 TestAcc 0.8794 0.8700
epoch 2500 LossPred 0.2694 LossAtt 0.2968 TrainAcc 0.9000 TestAcc 0.8784 0.8800
Optimization Finished!
********** replication  94  **********
epoch   0 LossPred 1.1338 LossAtt 0.9815 TrainAcc 0.3500 TestAcc 0.4049 0.3600
epoch 100 LossPred 0.9393 LossAtt 0.3986 TrainAcc 0.6500 TestAcc 0.5838 0.6500
epoch 200 LossPred 0.8723 LossAtt 0.4066 TrainAcc 0.6500 TestAcc 0.5838 0.6500
epoch 300 LossPred 0.8253 LossAtt 0.3506 TrainAcc 0.7000 TestAcc 0.6496 0.6900
epoch 400 LossPred 0.7934 LossAtt 0.3499 TrainAcc 0.6800 TestAcc 0.6414 0.6800
epoch 500 LossPred 0.4318 LossAtt 0.3987 TrainAcc 0.8600 TestAcc 0.8413 0.8700
epoch 600 LossPred 0.3481 LossAtt 0.4204 TrainAcc 0.9100 TestAcc 0.8746 0.8650
epoch 700 LossPred 0.3594 LossAtt 0.4144 TrainAcc 0.8700 TestAcc 0.8058 0.8650
epoch 800 LossPred 0.3601 LossAtt 0.4318 TrainAcc 0.8900 TestAcc 0.7940 0.8650
epoch 900 LossPred 0.3852 LossAtt 0.4397 TrainAcc 0.8700 TestAcc 0.8744 0.8700
epoch 1000 LossPred 0.3068 LossAtt 0.4386 TrainAcc 0.8800 TestAcc 0.8781 0.9000
epoch 1100 LossPred 0.2983 LossAtt 0.4561 TrainAcc 0.9400 TestAcc 0.9104 0.9200
epoch 1200 LossPred 0.2603 LossAtt 0.4441 TrainAcc 0.9400 TestAcc 0.9052 0.9200
epoch 1300 LossPred 0.1998 LossAtt 0.4319 TrainAcc 0.9300 TestAcc 0.9017 0.9200
epoch 1400 LossPred 0.1951 LossAtt 0.4190 TrainAcc 0.9500 TestAcc 0.8811 0.9200
epoch 1500 LossPred 0.1834 LossAtt 0.4340 TrainAcc 0.9400 TestAcc 0.8746 0.9100
epoch 1600 LossPred 0.1776 LossAtt 0.4317 TrainAcc 0.9500 TestAcc 0.8839 0.9200
epoch 1700 LossPred 0.2361 LossAtt 0.4338 TrainAcc 0.9400 TestAcc 0.9042 0.9200
epoch 1800 LossPred 0.1939 LossAtt 0.4534 TrainAcc 0.9400 TestAcc 0.9129 0.9250
epoch 1900 LossPred 0.2574 LossAtt 0.4197 TrainAcc 0.9200 TestAcc 0.8889 0.9200
epoch 2000 LossPred 0.3871 LossAtt 0.4446 TrainAcc 0.8600 TestAcc 0.8423 0.8700
epoch 2100 LossPred 0.1876 LossAtt 0.4290 TrainAcc 0.9300 TestAcc 0.8864 0.9200
epoch 2200 LossPred 0.3094 LossAtt 0.4522 TrainAcc 0.9000 TestAcc 0.8911 0.9100
epoch 2300 LossPred 0.1986 LossAtt 0.4525 TrainAcc 0.9400 TestAcc 0.9122 0.9250
epoch 2400 LossPred 0.2478 LossAtt 0.4504 TrainAcc 0.9400 TestAcc 0.8751 0.9050
epoch 2500 LossPred 0.2978 LossAtt 0.4365 TrainAcc 0.9000 TestAcc 0.8796 0.8900
Optimization Finished!
********** replication  95  **********
epoch   0 LossPred 1.1572 LossAtt 0.9944 TrainAcc 0.4800 TestAcc 0.4755 0.4700
epoch 100 LossPred 0.9080 LossAtt 0.3465 TrainAcc 0.6200 TestAcc 0.5896 0.6200
epoch 200 LossPred 0.8784 LossAtt 0.2393 TrainAcc 0.6200 TestAcc 0.5896 0.6200
epoch 300 LossPred 0.4701 LossAtt 0.4282 TrainAcc 0.8900 TestAcc 0.8714 0.8650
epoch 400 LossPred 0.4067 LossAtt 0.3999 TrainAcc 0.8600 TestAcc 0.7908 0.8550
epoch 500 LossPred 0.4102 LossAtt 0.3802 TrainAcc 0.8600 TestAcc 0.8841 0.8450
epoch 600 LossPred 0.4064 LossAtt 0.3772 TrainAcc 0.8600 TestAcc 0.8839 0.8550
epoch 700 LossPred 0.3081 LossAtt 0.3908 TrainAcc 0.9100 TestAcc 0.8961 0.8800
epoch 800 LossPred 0.4175 LossAtt 0.3612 TrainAcc 0.8800 TestAcc 0.7825 0.8700
epoch 900 LossPred 0.2962 LossAtt 0.3789 TrainAcc 0.9100 TestAcc 0.8524 0.8950
epoch 1000 LossPred 0.2685 LossAtt 0.3619 TrainAcc 0.9100 TestAcc 0.8846 0.8750
epoch 1100 LossPred 0.3530 LossAtt 0.3470 TrainAcc 0.8800 TestAcc 0.8138 0.9100
epoch 1200 LossPred 0.2852 LossAtt 0.3366 TrainAcc 0.9200 TestAcc 0.8458 0.9000
epoch 1300 LossPred 0.3108 LossAtt 0.3545 TrainAcc 0.8800 TestAcc 0.8884 0.8750
epoch 1400 LossPred 0.3894 LossAtt 0.3396 TrainAcc 0.8700 TestAcc 0.7788 0.8500
epoch 1500 LossPred 0.5917 LossAtt 0.3751 TrainAcc 0.7600 TestAcc 0.8061 0.7800
epoch 1600 LossPred 0.5446 LossAtt 0.3649 TrainAcc 0.7800 TestAcc 0.8351 0.8050
epoch 1700 LossPred 0.3717 LossAtt 0.3717 TrainAcc 0.8800 TestAcc 0.8799 0.8800
epoch 1800 LossPred 0.2594 LossAtt 0.3838 TrainAcc 0.9200 TestAcc 0.8864 0.9100
epoch 1900 LossPred 0.3043 LossAtt 0.3790 TrainAcc 0.9000 TestAcc 0.8346 0.9050
epoch 2000 LossPred 0.3079 LossAtt 0.3827 TrainAcc 0.9000 TestAcc 0.8243 0.9100
epoch 2100 LossPred 0.5630 LossAtt 0.3787 TrainAcc 0.8200 TestAcc 0.7217 0.8050
epoch 2200 LossPred 0.5490 LossAtt 0.3593 TrainAcc 0.8200 TestAcc 0.7252 0.8100
epoch 2300 LossPred 0.3556 LossAtt 0.3849 TrainAcc 0.8900 TestAcc 0.7998 0.8900
epoch 2400 LossPred 0.3579 LossAtt 0.3785 TrainAcc 0.8900 TestAcc 0.7985 0.8950
epoch 2500 LossPred 0.2656 LossAtt 0.4132 TrainAcc 0.9000 TestAcc 0.8539 0.9100
Optimization Finished!
********** replication  96  **********
epoch   0 LossPred 1.0978 LossAtt 1.0005 TrainAcc 0.4800 TestAcc 0.4182 0.4800
epoch 100 LossPred 0.9228 LossAtt 0.5188 TrainAcc 0.6500 TestAcc 0.5425 0.6500
epoch 200 LossPred 0.8716 LossAtt 0.5290 TrainAcc 0.6500 TestAcc 0.5425 0.6650
epoch 300 LossPred 0.8327 LossAtt 0.5903 TrainAcc 0.6800 TestAcc 0.5523 0.6600
epoch 400 LossPred 0.8074 LossAtt 0.5567 TrainAcc 0.6800 TestAcc 0.5633 0.6850
epoch 500 LossPred 0.4944 LossAtt 0.4965 TrainAcc 0.8500 TestAcc 0.7753 0.8250
epoch 600 LossPred 0.5461 LossAtt 0.4828 TrainAcc 0.8300 TestAcc 0.7688 0.8150
epoch 700 LossPred 0.5062 LossAtt 0.4670 TrainAcc 0.8500 TestAcc 0.7440 0.8300
epoch 800 LossPred 0.3444 LossAtt 0.5175 TrainAcc 0.9000 TestAcc 0.8028 0.8850
epoch 900 LossPred 0.2990 LossAtt 0.5537 TrainAcc 0.9000 TestAcc 0.8301 0.8900
epoch 1000 LossPred 0.2321 LossAtt 0.5474 TrainAcc 0.9300 TestAcc 0.8308 0.9300
epoch 1100 LossPred 0.2544 LossAtt 0.4624 TrainAcc 0.9300 TestAcc 0.7745 0.9200
epoch 1200 LossPred 0.2524 LossAtt 0.4567 TrainAcc 0.9300 TestAcc 0.7828 0.9150
epoch 1300 LossPred 0.1687 LossAtt 0.5547 TrainAcc 0.9500 TestAcc 0.8258 0.9400
epoch 1400 LossPred 0.1861 LossAtt 0.5318 TrainAcc 0.9400 TestAcc 0.8303 0.9300
epoch 1500 LossPred 0.1870 LossAtt 0.5451 TrainAcc 0.9400 TestAcc 0.8331 0.9150
epoch 1600 LossPred 0.1230 LossAtt 0.5119 TrainAcc 0.9500 TestAcc 0.8326 0.9450
epoch 1700 LossPred 0.2364 LossAtt 0.5072 TrainAcc 0.9300 TestAcc 0.8091 0.9200
epoch 1800 LossPred 0.1351 LossAtt 0.5072 TrainAcc 0.9600 TestAcc 0.8428 0.9600
epoch 1900 LossPred 0.0971 LossAtt 0.4953 TrainAcc 0.9800 TestAcc 0.8428 0.9650
epoch 2000 LossPred 0.1046 LossAtt 0.5244 TrainAcc 0.9700 TestAcc 0.8554 0.9500
epoch 2100 LossPred 0.1850 LossAtt 0.5054 TrainAcc 0.9400 TestAcc 0.8416 0.9350
epoch 2200 LossPred 0.1197 LossAtt 0.5350 TrainAcc 0.9700 TestAcc 0.8203 0.9350
epoch 2300 LossPred 0.3734 LossAtt 0.5392 TrainAcc 0.8700 TestAcc 0.8293 0.8650
epoch 2400 LossPred 0.1034 LossAtt 0.5627 TrainAcc 0.9800 TestAcc 0.8609 0.9600
epoch 2500 LossPred 0.3814 LossAtt 0.5224 TrainAcc 0.8900 TestAcc 0.8316 0.8850
Optimization Finished!
********** replication  97  **********
epoch   0 LossPred 1.0273 LossAtt 0.9978 TrainAcc 0.5300 TestAcc 0.5065 0.5350
epoch 100 LossPred 0.9619 LossAtt 0.3735 TrainAcc 0.5900 TestAcc 0.5898 0.5900
epoch 200 LossPred 0.9545 LossAtt 0.3511 TrainAcc 0.5900 TestAcc 0.5898 0.5850
epoch 300 LossPred 0.9460 LossAtt 0.3482 TrainAcc 0.6100 TestAcc 0.5711 0.6050
epoch 400 LossPred 0.9401 LossAtt 0.3254 TrainAcc 0.6100 TestAcc 0.5711 0.6050
epoch 500 LossPred 0.9208 LossAtt 0.3247 TrainAcc 0.6100 TestAcc 0.5711 0.6100
epoch 600 LossPred 0.8982 LossAtt 0.4413 TrainAcc 0.6500 TestAcc 0.5450 0.6500
epoch 700 LossPred 0.8546 LossAtt 0.3921 TrainAcc 0.6600 TestAcc 0.5290 0.6600
epoch 800 LossPred 0.8205 LossAtt 0.3618 TrainAcc 0.6700 TestAcc 0.5123 0.6550
epoch 900 LossPred 0.8025 LossAtt 0.3787 TrainAcc 0.6900 TestAcc 0.5215 0.6550
epoch 1000 LossPred 0.8279 LossAtt 0.4672 TrainAcc 0.6300 TestAcc 0.5390 0.6450
epoch 1100 LossPred 0.8418 LossAtt 0.4690 TrainAcc 0.6500 TestAcc 0.5430 0.6500
epoch 1200 LossPred 0.8108 LossAtt 0.4924 TrainAcc 0.6700 TestAcc 0.5340 0.6550
epoch 1300 LossPred 0.7250 LossAtt 0.6545 TrainAcc 0.7400 TestAcc 0.6216 0.7050
epoch 1400 LossPred 0.1774 LossAtt 0.5049 TrainAcc 0.9500 TestAcc 0.8649 0.9300
epoch 1500 LossPred 0.1592 LossAtt 0.4714 TrainAcc 0.9600 TestAcc 0.8471 0.9350
epoch 1600 LossPred 0.1385 LossAtt 0.4733 TrainAcc 0.9500 TestAcc 0.8706 0.9550
epoch 1700 LossPred 0.1164 LossAtt 0.4675 TrainAcc 0.9700 TestAcc 0.8676 0.9450
epoch 1800 LossPred 0.1126 LossAtt 0.4833 TrainAcc 0.9500 TestAcc 0.8724 0.9550
epoch 1900 LossPred 0.0911 LossAtt 0.4794 TrainAcc 0.9800 TestAcc 0.8606 0.9150
epoch 2000 LossPred 0.0839 LossAtt 0.5018 TrainAcc 0.9700 TestAcc 0.8664 0.9600
epoch 2100 LossPred 0.0846 LossAtt 0.4982 TrainAcc 0.9800 TestAcc 0.8551 0.9350
epoch 2200 LossPred 0.0719 LossAtt 0.5021 TrainAcc 0.9700 TestAcc 0.8706 0.9650
epoch 2300 LossPred 0.0741 LossAtt 0.5433 TrainAcc 0.9800 TestAcc 0.8759 0.9600
epoch 2400 LossPred 0.0653 LossAtt 0.5445 TrainAcc 0.9700 TestAcc 0.8559 0.9550
epoch 2500 LossPred 0.0844 LossAtt 0.5347 TrainAcc 0.9800 TestAcc 0.8691 0.9550
Optimization Finished!
********** replication  98  **********
epoch   0 LossPred 1.2570 LossAtt 1.0041 TrainAcc 0.3700 TestAcc 0.4505 0.4000
epoch 100 LossPred 0.9306 LossAtt 0.4175 TrainAcc 0.6600 TestAcc 0.5948 0.6600
epoch 200 LossPred 0.8942 LossAtt 0.3877 TrainAcc 0.6600 TestAcc 0.5948 0.6600
epoch 300 LossPred 0.8813 LossAtt 0.3441 TrainAcc 0.6600 TestAcc 0.5948 0.6600
epoch 400 LossPred 0.8733 LossAtt 0.3052 TrainAcc 0.6600 TestAcc 0.5948 0.6600
epoch 500 LossPred 0.8633 LossAtt 0.3109 TrainAcc 0.6600 TestAcc 0.5948 0.6600
epoch 600 LossPred 0.7737 LossAtt 0.3416 TrainAcc 0.7100 TestAcc 0.6702 0.7000
epoch 700 LossPred 0.5324 LossAtt 0.3336 TrainAcc 0.8100 TestAcc 0.8709 0.7850
epoch 800 LossPred 0.4652 LossAtt 0.3552 TrainAcc 0.8400 TestAcc 0.8649 0.7950
epoch 900 LossPred 0.4959 LossAtt 0.3780 TrainAcc 0.8200 TestAcc 0.8453 0.8150
epoch 1000 LossPred 0.4991 LossAtt 0.3467 TrainAcc 0.8600 TestAcc 0.8671 0.8700
epoch 1100 LossPred 0.3253 LossAtt 0.3789 TrainAcc 0.8900 TestAcc 0.8891 0.8600
epoch 1200 LossPred 0.3427 LossAtt 0.3543 TrainAcc 0.9000 TestAcc 0.8836 0.8650
epoch 1300 LossPred 0.3019 LossAtt 0.3557 TrainAcc 0.9100 TestAcc 0.8996 0.8700
epoch 1400 LossPred 0.2770 LossAtt 0.3575 TrainAcc 0.8900 TestAcc 0.9072 0.8650
epoch 1500 LossPred 0.2912 LossAtt 0.3817 TrainAcc 0.9100 TestAcc 0.9064 0.8700
epoch 1600 LossPred 0.2981 LossAtt 0.3811 TrainAcc 0.9000 TestAcc 0.9124 0.8850
epoch 1700 LossPred 0.2859 LossAtt 0.3831 TrainAcc 0.9100 TestAcc 0.9092 0.8700
epoch 1800 LossPred 0.2406 LossAtt 0.3701 TrainAcc 0.9200 TestAcc 0.9024 0.8650
epoch 1900 LossPred 0.2645 LossAtt 0.3784 TrainAcc 0.8900 TestAcc 0.9062 0.8500
epoch 2000 LossPred 0.2977 LossAtt 0.3879 TrainAcc 0.8600 TestAcc 0.9154 0.9000
epoch 2100 LossPred 0.2826 LossAtt 0.3831 TrainAcc 0.9100 TestAcc 0.9002 0.8650
epoch 2200 LossPred 0.2356 LossAtt 0.3780 TrainAcc 0.9200 TestAcc 0.9247 0.8750
epoch 2300 LossPred 0.2221 LossAtt 0.3912 TrainAcc 0.9300 TestAcc 0.9182 0.8800
epoch 2400 LossPred 0.2665 LossAtt 0.3566 TrainAcc 0.9000 TestAcc 0.9114 0.8800
epoch 2500 LossPred 0.2172 LossAtt 0.3493 TrainAcc 0.9100 TestAcc 0.9189 0.8800
Optimization Finished!
********** replication  99  **********
epoch   0 LossPred 1.0829 LossAtt 1.0147 TrainAcc 0.4800 TestAcc 0.4667 0.5050
epoch 100 LossPred 0.9109 LossAtt 0.3009 TrainAcc 0.6600 TestAcc 0.6524 0.6400
epoch 200 LossPred 0.8323 LossAtt 0.3533 TrainAcc 0.7000 TestAcc 0.6829 0.6850
epoch 300 LossPred 0.9774 LossAtt 0.2484 TrainAcc 0.6000 TestAcc 0.6001 0.6000
epoch 400 LossPred 0.9332 LossAtt 0.1809 TrainAcc 0.6000 TestAcc 0.6001 0.6050
epoch 500 LossPred 0.9302 LossAtt 0.1576 TrainAcc 0.6000 TestAcc 0.6001 0.6100
epoch 600 LossPred 0.9298 LossAtt 0.1456 TrainAcc 0.6000 TestAcc 0.6001 0.6100
epoch 700 LossPred 0.9297 LossAtt 0.1533 TrainAcc 0.6000 TestAcc 0.6001 0.6000
epoch 800 LossPred 0.9301 LossAtt 0.1441 TrainAcc 0.6000 TestAcc 0.6001 0.6000
epoch 900 LossPred 0.9298 LossAtt 0.1412 TrainAcc 0.6000 TestAcc 0.6001 0.6000
epoch 1000 LossPred 0.9302 LossAtt 0.1329 TrainAcc 0.6000 TestAcc 0.6001 0.6000
epoch 1100 LossPred 0.9300 LossAtt 0.1444 TrainAcc 0.6000 TestAcc 0.6001 0.6000
epoch 1200 LossPred 0.9298 LossAtt 0.1330 TrainAcc 0.6000 TestAcc 0.6001 0.6000
epoch 1300 LossPred 0.9290 LossAtt 0.1207 TrainAcc 0.6000 TestAcc 0.6001 0.6000
epoch 1400 LossPred 0.9285 LossAtt 0.1191 TrainAcc 0.6000 TestAcc 0.6001 0.6000
epoch 1500 LossPred 0.9281 LossAtt 0.1163 TrainAcc 0.6000 TestAcc 0.6001 0.6000
epoch 1600 LossPred 0.9276 LossAtt 0.1219 TrainAcc 0.6000 TestAcc 0.6001 0.6000
epoch 1700 LossPred 0.9273 LossAtt 0.1206 TrainAcc 0.6000 TestAcc 0.6001 0.6000
epoch 1800 LossPred 0.9266 LossAtt 0.1282 TrainAcc 0.6000 TestAcc 0.6001 0.6000
epoch 1900 LossPred 0.9257 LossAtt 0.1332 TrainAcc 0.6000 TestAcc 0.6001 0.6000
epoch 2000 LossPred 0.9243 LossAtt 0.1687 TrainAcc 0.6000 TestAcc 0.6001 0.6000
epoch 2100 LossPred 0.9222 LossAtt 0.1844 TrainAcc 0.6000 TestAcc 0.6001 0.6050
epoch 2200 LossPred 0.9242 LossAtt 0.5164 TrainAcc 0.6000 TestAcc 0.6001 0.6150
epoch 2300 LossPred 0.9000 LossAtt 0.2772 TrainAcc 0.6500 TestAcc 0.6306 0.6350
epoch 2400 LossPred 0.8607 LossAtt 0.2913 TrainAcc 0.6500 TestAcc 0.6479 0.6400
epoch 2500 LossPred 1.4550 LossAtt 0.6531 TrainAcc 0.4200 TestAcc 0.4154 0.4350
Optimization Finished!
********************************************************************
Namespace(arch='tanh', batch_size=256, display_epoch=100, input_noise_level=0.15, latent_attractor_space=True, loss_switch_frequency=0, lrate_attractor=0.002, lrate_prediction=0.002, lrate_wt_penalty=0.0, n_attractor_hidden=10, n_attractor_steps=15, n_hidden=5, n_replications=100, noise_level=0.5, report_best_train_performance=True, seq_len=20, task='majority', train_attr_weights_on_prediction=False, training_epochs=2500)
********************************************************************
mean train accuracy 0.87520003
indiv runs  [0.91, 0.91, 0.93, 0.91, 0.93, 0.91, 0.97, 0.89, 0.62, 0.98, 0.87, 0.65, 0.96, 0.9, 0.69, 0.94, 0.82, 0.95, 0.71, 0.97, 0.89, 0.91, 0.93, 0.93, 0.93, 0.89, 0.95, 0.92, 0.89, 0.91, 0.83, 0.91, 0.91, 0.96, 0.93, 0.58, 0.95, 0.92, 0.56, 0.93, 0.94, 0.95, 0.9, 0.94, 0.72, 0.93, 0.91, 0.62, 0.92, 0.94, 0.97, 0.81, 0.9, 0.9, 0.65, 0.94, 0.93, 0.99, 0.88, 0.9, 0.96, 0.72, 0.98, 0.65, 0.94, 0.77, 0.91, 0.69, 0.88, 0.67, 0.73, 0.91, 0.86, 0.95, 0.74, 0.9, 0.74, 0.94, 0.83, 0.69, 0.91, 0.9, 0.93, 0.96, 0.92, 0.97, 0.95, 0.82, 0.92, 0.87, 0.97, 0.91, 0.97, 0.91, 0.95, 0.92, 0.98, 0.98, 0.93, 0.7]
mean epoch nan
indiv epochs  []
test1 accuracy mean  0.7957657  median  0.8485986
test2 accuracy mean  0.8451999  median  0.8825
test1 indiv runs  [0.8991491, 0.8373373, 0.8811311, 0.8703704, 0.9139139, 0.8818819, 0.8973974, 0.5715716, 0.5885886, 0.8846346, 0.7942943, 0.5965966, 0.8405906, 0.8200701, 0.5452953, 0.8956456, 0.51001, 0.9116617, 0.5843343, 0.8393393, 0.8313313, 0.8265766, 0.8878879, 0.8333333, 0.8591091, 0.8335836, 0.9184184, 0.8688689, 0.8678679, 0.8275776, 0.7837838, 0.8706206, 0.8676176, 0.8561061, 0.8811311, 0.5773273, 0.8523524, 0.8948949, 0.490991, 0.8711211, 0.8308308, 0.8853854, 0.7925425, 0.8958959, 0.5908408, 0.8701201, 0.8263263, 0.5447948, 0.8215716, 0.8601101, 0.8673674, 0.6626627, 0.8551051, 0.8498498, 0.5845846, 0.8806306, 0.8626126, 0.9101602, 0.8498498, 0.8438438, 0.8245746, 0.5045045, 0.9041542, 0.5132633, 0.9004004, 0.6291291, 0.8473473, 0.6298799, 0.8283283, 0.5485485, 0.5558058, 0.8440941, 0.8450951, 0.8858859, 0.5868368, 0.8681181, 0.5467968, 0.9161662, 0.7972973, 0.5930931, 0.8445946, 0.7835335, 0.8986486, 0.8608609, 0.9206707, 0.8948949, 0.8838839, 0.5855856, 0.8115616, 0.8591091, 0.8873874, 0.8751251, 0.8696196, 0.8508509, 0.8811311, 0.8458458, 0.8428428, 0.8606106, 0.9181682, 0.6829329]
test2 indiv runs  [0.865, 0.9, 0.885, 0.905, 0.885, 0.86, 0.935, 0.805, 0.61, 0.97, 0.815, 0.635, 0.895, 0.89, 0.66, 0.925, 0.72, 0.94, 0.675, 0.97, 0.885, 0.885, 0.865, 0.9, 0.905, 0.85, 0.915, 0.89, 0.865, 0.865, 0.825, 0.89, 0.85, 0.925, 0.89, 0.58, 0.88, 0.875, 0.56, 0.93, 0.865, 0.88, 0.85, 0.88, 0.69, 0.905, 0.895, 0.59, 0.915, 0.915, 0.905, 0.76, 0.905, 0.865, 0.65, 0.915, 0.915, 0.94, 0.935, 0.855, 0.885, 0.69, 0.92, 0.65, 0.91, 0.75, 0.865, 0.69, 0.875, 0.655, 0.68, 0.905, 0.86, 0.895, 0.695, 0.89, 0.7, 0.935, 0.81, 0.665, 0.895, 0.875, 0.895, 0.955, 0.89, 0.94, 0.925, 0.75, 0.88, 0.88, 0.95, 0.875, 0.935, 0.88, 0.92, 0.9, 0.965, 0.915, 0.88, 0.685]
