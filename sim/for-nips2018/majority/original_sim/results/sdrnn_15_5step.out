Namespace(arch='tanh', batch_size=256, display_epoch=100, input_noise_level=0.15, latent_attractor_space=True, loss_switch_frequency=0, lrate_attractor=0.002, lrate_prediction=0.002, lrate_wt_penalty=0.0, n_attractor_hidden=10, n_attractor_steps=5, n_hidden=5, n_replications=100, noise_level=0.5, report_best_train_performance=True, seq_len=15, task='majority', train_attr_weights_on_prediction=False, training_epochs=2500)
TRAINING ON 100 EXAMPLES, TESTING ON 3996
********** replication  0  **********
epoch   0 LossPred 1.0637 LossAtt 1.0346 TrainAcc 0.5100 TestAcc 0.5305 0.5000
epoch 100 LossPred 0.9536 LossAtt 0.4393 TrainAcc 0.6100 TestAcc 0.5403 0.6050
epoch 200 LossPred 0.9395 LossAtt 0.3346 TrainAcc 0.6100 TestAcc 0.5403 0.6200
epoch 300 LossPred 0.9338 LossAtt 0.2862 TrainAcc 0.6200 TestAcc 0.5501 0.6200
epoch 400 LossPred 0.9083 LossAtt 0.3437 TrainAcc 0.6200 TestAcc 0.5851 0.6250
epoch 500 LossPred 0.4973 LossAtt 0.4373 TrainAcc 0.8300 TestAcc 0.8521 0.8500
epoch 600 LossPred 0.4395 LossAtt 0.3410 TrainAcc 0.8200 TestAcc 0.8511 0.8600
epoch 700 LossPred 0.3487 LossAtt 0.3811 TrainAcc 0.8700 TestAcc 0.8746 0.8700
epoch 800 LossPred 0.2862 LossAtt 0.3799 TrainAcc 0.8800 TestAcc 0.9007 0.8600
epoch 900 LossPred 0.2183 LossAtt 0.3482 TrainAcc 0.9200 TestAcc 0.9269 0.8900
epoch 1000 LossPred 0.1555 LossAtt 0.3609 TrainAcc 0.9700 TestAcc 0.9565 0.9200
epoch 1100 LossPred 0.1769 LossAtt 0.3643 TrainAcc 0.9500 TestAcc 0.9379 0.9300
epoch 1200 LossPred 0.3678 LossAtt 0.3427 TrainAcc 0.8700 TestAcc 0.8509 0.8650
epoch 1300 LossPred 0.1965 LossAtt 0.3715 TrainAcc 0.9300 TestAcc 0.9384 0.9050
epoch 1400 LossPred 0.2438 LossAtt 0.3676 TrainAcc 0.9100 TestAcc 0.9192 0.9000
epoch 1500 LossPred 0.2870 LossAtt 0.3450 TrainAcc 0.8800 TestAcc 0.8719 0.8800
epoch 1600 LossPred 0.1865 LossAtt 0.3431 TrainAcc 0.9200 TestAcc 0.9332 0.9200
epoch 1700 LossPred 0.1226 LossAtt 0.3584 TrainAcc 0.9900 TestAcc 0.9727 0.9150
epoch 1800 LossPred 0.1159 LossAtt 0.3446 TrainAcc 0.9900 TestAcc 0.9740 0.9200
epoch 1900 LossPred 0.2696 LossAtt 0.3164 TrainAcc 0.9000 TestAcc 0.8824 0.8800
epoch 2000 LossPred 0.0978 LossAtt 0.3563 TrainAcc 0.9900 TestAcc 0.9740 0.9250
epoch 2100 LossPred 0.1109 LossAtt 0.3285 TrainAcc 0.9800 TestAcc 0.9635 0.9400
epoch 2200 LossPred 0.1851 LossAtt 0.3350 TrainAcc 0.9300 TestAcc 0.9224 0.9200
epoch 2300 LossPred 0.4162 LossAtt 0.3334 TrainAcc 0.8400 TestAcc 0.8306 0.8500
epoch 2400 LossPred 0.0871 LossAtt 0.3436 TrainAcc 0.9800 TestAcc 0.9670 0.9550
epoch 2500 LossPred 0.1055 LossAtt 0.3406 TrainAcc 0.9900 TestAcc 0.9750 0.9200
Optimization Finished!
********** replication  1  **********
epoch   0 LossPred 1.4913 LossAtt 1.0107 TrainAcc 0.3800 TestAcc 0.4474 0.3800
epoch 100 LossPred 1.0779 LossAtt 0.2868 TrainAcc 0.4300 TestAcc 0.4907 0.4250
epoch 200 LossPred 0.8836 LossAtt 0.2242 TrainAcc 0.7100 TestAcc 0.6074 0.7100
epoch 300 LossPred 0.8403 LossAtt 0.1805 TrainAcc 0.7100 TestAcc 0.6074 0.7100
epoch 400 LossPred 0.8538 LossAtt 0.1511 TrainAcc 0.7100 TestAcc 0.6074 0.7100
epoch 500 LossPred 0.8272 LossAtt 0.1671 TrainAcc 0.7100 TestAcc 0.6074 0.7100
epoch 600 LossPred 0.8167 LossAtt 0.1622 TrainAcc 0.7100 TestAcc 0.6074 0.7100
epoch 700 LossPred 0.8298 LossAtt 0.1898 TrainAcc 0.7100 TestAcc 0.6074 0.7100
epoch 800 LossPred 0.8218 LossAtt 0.0658 TrainAcc 0.7100 TestAcc 0.6074 0.7100
epoch 900 LossPred 0.8217 LossAtt 0.0693 TrainAcc 0.7100 TestAcc 0.6074 0.7100
epoch 1000 LossPred 0.8213 LossAtt 0.0715 TrainAcc 0.7100 TestAcc 0.6074 0.7100
epoch 1100 LossPred 0.8209 LossAtt 0.0761 TrainAcc 0.7100 TestAcc 0.6074 0.7100
epoch 1200 LossPred 0.8208 LossAtt 0.0723 TrainAcc 0.7100 TestAcc 0.6074 0.7100
epoch 1300 LossPred 0.8206 LossAtt 0.0622 TrainAcc 0.7100 TestAcc 0.6074 0.7100
epoch 1400 LossPred 0.8207 LossAtt 0.0575 TrainAcc 0.7100 TestAcc 0.6074 0.7100
epoch 1500 LossPred 0.8206 LossAtt 0.0549 TrainAcc 0.7100 TestAcc 0.6074 0.7100
epoch 1600 LossPred 0.8207 LossAtt 0.0503 TrainAcc 0.7100 TestAcc 0.6074 0.7100
epoch 1700 LossPred 0.8208 LossAtt 0.0456 TrainAcc 0.7100 TestAcc 0.6074 0.7100
epoch 1800 LossPred 0.8208 LossAtt 0.0390 TrainAcc 0.7100 TestAcc 0.6074 0.7100
epoch 1900 LossPred 0.8208 LossAtt 0.0397 TrainAcc 0.7100 TestAcc 0.6074 0.7100
epoch 2000 LossPred 0.8207 LossAtt 0.0366 TrainAcc 0.7100 TestAcc 0.6074 0.7100
epoch 2100 LossPred 0.8207 LossAtt 0.0404 TrainAcc 0.7100 TestAcc 0.6074 0.7100
epoch 2200 LossPred 0.8207 LossAtt 0.0532 TrainAcc 0.7100 TestAcc 0.6074 0.7100
epoch 2300 LossPred 0.8207 LossAtt 0.0646 TrainAcc 0.7100 TestAcc 0.6074 0.7100
epoch 2400 LossPred 0.8205 LossAtt 0.0828 TrainAcc 0.7100 TestAcc 0.6074 0.7100
epoch 2500 LossPred 0.8181 LossAtt 0.1144 TrainAcc 0.7100 TestAcc 0.6074 0.7100
Optimization Finished!
********** replication  2  **********
epoch   0 LossPred 1.1972 LossAtt 1.0299 TrainAcc 0.4000 TestAcc 0.3951 0.4100
epoch 100 LossPred 0.9909 LossAtt 0.3243 TrainAcc 0.5500 TestAcc 0.4957 0.5500
epoch 200 LossPred 0.9672 LossAtt 0.2209 TrainAcc 0.5400 TestAcc 0.5458 0.5850
epoch 300 LossPred 0.9623 LossAtt 0.2243 TrainAcc 0.6000 TestAcc 0.6049 0.6000
epoch 400 LossPred 0.9590 LossAtt 0.2857 TrainAcc 0.6000 TestAcc 0.6049 0.6000
epoch 500 LossPred 0.9568 LossAtt 0.3342 TrainAcc 0.6100 TestAcc 0.5881 0.6050
epoch 600 LossPred 0.9578 LossAtt 0.3081 TrainAcc 0.6000 TestAcc 0.5786 0.5950
epoch 700 LossPred 0.9709 LossAtt 0.3691 TrainAcc 0.5800 TestAcc 0.6016 0.5800
epoch 800 LossPred 0.9765 LossAtt 0.2980 TrainAcc 0.5700 TestAcc 0.5746 0.5700
epoch 900 LossPred 0.9752 LossAtt 0.2687 TrainAcc 0.5700 TestAcc 0.5330 0.5350
epoch 1000 LossPred 0.9683 LossAtt 0.1883 TrainAcc 0.5800 TestAcc 0.6016 0.5800
epoch 1100 LossPred 0.9676 LossAtt 0.1818 TrainAcc 0.5800 TestAcc 0.6016 0.5800
epoch 1200 LossPred 0.9671 LossAtt 0.1643 TrainAcc 0.5800 TestAcc 0.6016 0.5600
epoch 1300 LossPred 0.9667 LossAtt 0.1752 TrainAcc 0.5800 TestAcc 0.6016 0.5700
epoch 1400 LossPred 0.9647 LossAtt 0.2167 TrainAcc 0.5800 TestAcc 0.6016 0.5750
epoch 1500 LossPred 0.9659 LossAtt 0.3195 TrainAcc 0.5600 TestAcc 0.5228 0.5450
epoch 1600 LossPred 0.4691 LossAtt 0.4338 TrainAcc 0.8800 TestAcc 0.8143 0.8850
epoch 1700 LossPred 0.4246 LossAtt 0.4313 TrainAcc 0.8600 TestAcc 0.8724 0.8600
epoch 1800 LossPred 0.3061 LossAtt 0.4265 TrainAcc 0.9000 TestAcc 0.8661 0.8950
epoch 1900 LossPred 0.2785 LossAtt 0.4145 TrainAcc 0.9000 TestAcc 0.8974 0.8900
epoch 2000 LossPred 0.2287 LossAtt 0.3538 TrainAcc 0.9300 TestAcc 0.9014 0.9300
epoch 2100 LossPred 0.2230 LossAtt 0.3342 TrainAcc 0.9300 TestAcc 0.9084 0.9300
epoch 2200 LossPred 0.2002 LossAtt 0.3576 TrainAcc 0.9300 TestAcc 0.9159 0.9300
epoch 2300 LossPred 0.2011 LossAtt 0.3454 TrainAcc 0.9300 TestAcc 0.9039 0.9300
epoch 2400 LossPred 0.1754 LossAtt 0.3297 TrainAcc 0.9500 TestAcc 0.9282 0.9550
epoch 2500 LossPred 0.4234 LossAtt 0.3447 TrainAcc 0.8200 TestAcc 0.8361 0.8200
Optimization Finished!
********** replication  3  **********
epoch   0 LossPred 1.1285 LossAtt 1.0111 TrainAcc 0.3800 TestAcc 0.3999 0.4250
epoch 100 LossPred 0.9797 LossAtt 0.1991 TrainAcc 0.6100 TestAcc 0.6036 0.6100
epoch 200 LossPred 0.9336 LossAtt 0.1967 TrainAcc 0.6100 TestAcc 0.6036 0.6200
epoch 300 LossPred 0.8132 LossAtt 0.3134 TrainAcc 0.7600 TestAcc 0.6544 0.7400
epoch 400 LossPred 0.3389 LossAtt 0.3197 TrainAcc 0.9200 TestAcc 0.8734 0.9050
epoch 500 LossPred 0.2317 LossAtt 0.2938 TrainAcc 0.9200 TestAcc 0.8861 0.9050
epoch 600 LossPred 0.2039 LossAtt 0.2814 TrainAcc 0.9300 TestAcc 0.9022 0.9300
epoch 700 LossPred 0.2442 LossAtt 0.3021 TrainAcc 0.9300 TestAcc 0.8871 0.8900
epoch 800 LossPred 0.4556 LossAtt 0.3125 TrainAcc 0.8500 TestAcc 0.8278 0.8400
epoch 900 LossPred 0.1642 LossAtt 0.2945 TrainAcc 0.9500 TestAcc 0.9132 0.9250
epoch 1000 LossPred 0.2296 LossAtt 0.2941 TrainAcc 0.9100 TestAcc 0.8849 0.8800
epoch 1100 LossPred 0.1861 LossAtt 0.2910 TrainAcc 0.9300 TestAcc 0.8964 0.9200
epoch 1200 LossPred 0.1942 LossAtt 0.2853 TrainAcc 0.9400 TestAcc 0.9054 0.9200
epoch 1300 LossPred 0.2039 LossAtt 0.3027 TrainAcc 0.9300 TestAcc 0.8879 0.9100
epoch 1400 LossPred 0.2863 LossAtt 0.3086 TrainAcc 0.9000 TestAcc 0.8541 0.8750
epoch 1500 LossPred 0.1403 LossAtt 0.3012 TrainAcc 0.9500 TestAcc 0.9202 0.9450
epoch 1600 LossPred 0.1081 LossAtt 0.3089 TrainAcc 0.9700 TestAcc 0.9349 0.9400
epoch 1700 LossPred 0.1889 LossAtt 0.3176 TrainAcc 0.9100 TestAcc 0.9064 0.9400
epoch 1800 LossPred 0.1758 LossAtt 0.3254 TrainAcc 0.9300 TestAcc 0.9077 0.9100
epoch 1900 LossPred 0.1578 LossAtt 0.3052 TrainAcc 0.9400 TestAcc 0.9274 0.9550
epoch 2000 LossPred 0.1393 LossAtt 0.3235 TrainAcc 0.9700 TestAcc 0.9229 0.9300
epoch 2100 LossPred 0.1283 LossAtt 0.3239 TrainAcc 0.9500 TestAcc 0.9344 0.9300
epoch 2200 LossPred 0.1439 LossAtt 0.3508 TrainAcc 0.9400 TestAcc 0.9409 0.9600
epoch 2300 LossPred 0.0767 LossAtt 0.3401 TrainAcc 0.9800 TestAcc 0.9377 0.9550
epoch 2400 LossPred 0.0795 LossAtt 0.3957 TrainAcc 0.9900 TestAcc 0.9392 0.9650
epoch 2500 LossPred 0.1041 LossAtt 0.3489 TrainAcc 0.9700 TestAcc 0.9262 0.9550
Optimization Finished!
********** replication  4  **********
epoch   0 LossPred 1.1347 LossAtt 1.0086 TrainAcc 0.5600 TestAcc 0.4274 0.5550
epoch 100 LossPred 0.9817 LossAtt 0.4376 TrainAcc 0.5900 TestAcc 0.5175 0.5900
epoch 200 LossPred 0.9901 LossAtt 0.3429 TrainAcc 0.5900 TestAcc 0.5175 0.5850
epoch 300 LossPred 0.9640 LossAtt 0.3081 TrainAcc 0.5900 TestAcc 0.5175 0.5900
epoch 400 LossPred 0.9543 LossAtt 0.1647 TrainAcc 0.5900 TestAcc 0.5175 0.5900
epoch 500 LossPred 0.9469 LossAtt 0.3738 TrainAcc 0.5900 TestAcc 0.5175 0.5900
epoch 600 LossPred 0.9160 LossAtt 0.3411 TrainAcc 0.6200 TestAcc 0.6079 0.6450
epoch 700 LossPred 0.7752 LossAtt 0.4029 TrainAcc 0.7400 TestAcc 0.6967 0.7100
epoch 800 LossPred 0.4451 LossAtt 0.4069 TrainAcc 0.8800 TestAcc 0.8804 0.8800
epoch 900 LossPred 0.4779 LossAtt 0.3773 TrainAcc 0.8400 TestAcc 0.8033 0.8350
epoch 1000 LossPred 0.3296 LossAtt 0.3746 TrainAcc 0.9000 TestAcc 0.8781 0.8750
epoch 1100 LossPred 0.3004 LossAtt 0.3893 TrainAcc 0.9000 TestAcc 0.8741 0.8700
epoch 1200 LossPred 0.2892 LossAtt 0.4101 TrainAcc 0.9100 TestAcc 0.8759 0.8850
epoch 1300 LossPred 0.2865 LossAtt 0.4154 TrainAcc 0.9100 TestAcc 0.8876 0.8800
epoch 1400 LossPred 0.2746 LossAtt 0.3788 TrainAcc 0.9100 TestAcc 0.8791 0.8850
epoch 1500 LossPred 0.3305 LossAtt 0.4051 TrainAcc 0.8600 TestAcc 0.8428 0.8650
epoch 1600 LossPred 0.2461 LossAtt 0.3528 TrainAcc 0.9200 TestAcc 0.8961 0.8900
epoch 1700 LossPred 0.2365 LossAtt 0.3735 TrainAcc 0.9200 TestAcc 0.8861 0.8850
epoch 1800 LossPred 0.2795 LossAtt 0.4011 TrainAcc 0.9000 TestAcc 0.8916 0.8650
epoch 1900 LossPred 0.2783 LossAtt 0.3625 TrainAcc 0.9100 TestAcc 0.8869 0.8700
epoch 2000 LossPred 0.2550 LossAtt 0.3562 TrainAcc 0.9200 TestAcc 0.8669 0.9000
epoch 2100 LossPred 0.2388 LossAtt 0.3497 TrainAcc 0.9300 TestAcc 0.8766 0.8850
epoch 2200 LossPred 0.2305 LossAtt 0.3517 TrainAcc 0.9200 TestAcc 0.8899 0.8750
epoch 2300 LossPred 0.3698 LossAtt 0.3578 TrainAcc 0.8800 TestAcc 0.8781 0.8550
epoch 2400 LossPred 0.2186 LossAtt 0.3711 TrainAcc 0.9200 TestAcc 0.8796 0.8900
epoch 2500 LossPred 0.2534 LossAtt 0.3411 TrainAcc 0.9300 TestAcc 0.8951 0.8800
Optimization Finished!
********** replication  5  **********
epoch   0 LossPred 1.1030 LossAtt 1.0032 TrainAcc 0.5300 TestAcc 0.5661 0.5400
epoch 100 LossPred 0.9551 LossAtt 0.3998 TrainAcc 0.5700 TestAcc 0.6094 0.5700
epoch 200 LossPred 0.8991 LossAtt 0.4281 TrainAcc 0.6400 TestAcc 0.6301 0.6500
epoch 300 LossPred 0.3287 LossAtt 0.4564 TrainAcc 0.9200 TestAcc 0.8816 0.8950
epoch 400 LossPred 0.2232 LossAtt 0.4322 TrainAcc 0.9500 TestAcc 0.9024 0.9150
epoch 500 LossPred 0.1717 LossAtt 0.4613 TrainAcc 0.9600 TestAcc 0.9159 0.9150
epoch 600 LossPred 0.1236 LossAtt 0.4697 TrainAcc 0.9800 TestAcc 0.9222 0.9600
epoch 700 LossPred 0.1080 LossAtt 0.4834 TrainAcc 0.9800 TestAcc 0.9159 0.9500
epoch 800 LossPred 0.0914 LossAtt 0.4740 TrainAcc 0.9800 TestAcc 0.9092 0.9700
epoch 900 LossPred 0.0850 LossAtt 0.4215 TrainAcc 0.9800 TestAcc 0.9157 0.9550
epoch 1000 LossPred 0.1147 LossAtt 0.3913 TrainAcc 0.9700 TestAcc 0.8979 0.9750
epoch 1100 LossPred 0.0957 LossAtt 0.4165 TrainAcc 0.9800 TestAcc 0.9027 0.9550
epoch 1200 LossPred 0.0899 LossAtt 0.4045 TrainAcc 0.9800 TestAcc 0.9119 0.9600
epoch 1300 LossPred 0.1062 LossAtt 0.3916 TrainAcc 0.9700 TestAcc 0.9144 0.9500
epoch 1400 LossPred 0.0918 LossAtt 0.3838 TrainAcc 0.9800 TestAcc 0.9014 0.9650
epoch 1500 LossPred 0.0822 LossAtt 0.4068 TrainAcc 0.9800 TestAcc 0.9127 0.9700
epoch 1600 LossPred 0.0813 LossAtt 0.3774 TrainAcc 0.9800 TestAcc 0.9177 0.9650
epoch 1700 LossPred 0.0641 LossAtt 0.3770 TrainAcc 0.9900 TestAcc 0.9317 0.9700
epoch 1800 LossPred 0.0867 LossAtt 0.3944 TrainAcc 0.9700 TestAcc 0.9212 0.9550
epoch 1900 LossPred 0.0713 LossAtt 0.4059 TrainAcc 0.9800 TestAcc 0.9284 0.9600
epoch 2000 LossPred 0.0823 LossAtt 0.3871 TrainAcc 0.9700 TestAcc 0.9302 0.9550
epoch 2100 LossPred 0.0492 LossAtt 0.3952 TrainAcc 0.9800 TestAcc 0.9432 0.9700
epoch 2200 LossPred 0.0889 LossAtt 0.3827 TrainAcc 0.9800 TestAcc 0.9292 0.9550
epoch 2300 LossPred 0.0428 LossAtt 0.3880 TrainAcc 0.9800 TestAcc 0.9487 0.9750
epoch 2400 LossPred 0.0502 LossAtt 0.4017 TrainAcc 0.9800 TestAcc 0.9414 0.9600
epoch 2500 LossPred 0.0596 LossAtt 0.4095 TrainAcc 0.9800 TestAcc 0.9302 0.9500
Optimization Finished!
********** replication  6  **********
epoch   0 LossPred 0.9754 LossAtt 1.0122 TrainAcc 0.5300 TestAcc 0.4657 0.5300
epoch 100 LossPred 0.9047 LossAtt 0.4561 TrainAcc 0.6300 TestAcc 0.5796 0.6050
epoch 200 LossPred 0.8035 LossAtt 0.4508 TrainAcc 0.7100 TestAcc 0.6429 0.6950
epoch 300 LossPred 0.3168 LossAtt 0.4584 TrainAcc 0.9000 TestAcc 0.9064 0.8500
epoch 400 LossPred 0.3833 LossAtt 0.4738 TrainAcc 0.8800 TestAcc 0.9064 0.8550
epoch 500 LossPred 0.2721 LossAtt 0.5034 TrainAcc 0.9300 TestAcc 0.9269 0.8600
epoch 600 LossPred 0.2696 LossAtt 0.4780 TrainAcc 0.9200 TestAcc 0.9272 0.8350
epoch 700 LossPred 0.3253 LossAtt 0.4885 TrainAcc 0.9000 TestAcc 0.9204 0.8750
epoch 800 LossPred 0.2430 LossAtt 0.4796 TrainAcc 0.9300 TestAcc 0.8936 0.8900
epoch 900 LossPred 0.2184 LossAtt 0.5212 TrainAcc 0.9400 TestAcc 0.9152 0.9000
epoch 1000 LossPred 0.6439 LossAtt 0.4911 TrainAcc 0.7500 TestAcc 0.7518 0.7900
epoch 1100 LossPred 0.2400 LossAtt 0.4562 TrainAcc 0.9400 TestAcc 0.9107 0.8700
epoch 1200 LossPred 0.3990 LossAtt 0.4280 TrainAcc 0.8500 TestAcc 0.8686 0.8350
epoch 1300 LossPred 0.2504 LossAtt 0.4353 TrainAcc 0.9200 TestAcc 0.9017 0.8800
epoch 1400 LossPred 0.2358 LossAtt 0.4639 TrainAcc 0.9200 TestAcc 0.8916 0.8900
epoch 1500 LossPred 0.2062 LossAtt 0.4345 TrainAcc 0.9500 TestAcc 0.9194 0.9200
epoch 1600 LossPred 0.1997 LossAtt 0.4506 TrainAcc 0.9400 TestAcc 0.9174 0.9150
epoch 1700 LossPred 0.3588 LossAtt 0.4335 TrainAcc 0.8800 TestAcc 0.8836 0.8750
epoch 1800 LossPred 0.3851 LossAtt 0.4521 TrainAcc 0.8800 TestAcc 0.8413 0.8550
epoch 1900 LossPred 0.2252 LossAtt 0.4456 TrainAcc 0.9300 TestAcc 0.9042 0.9000
epoch 2000 LossPred 0.2420 LossAtt 0.4483 TrainAcc 0.9200 TestAcc 0.8909 0.9050
epoch 2100 LossPred 0.2395 LossAtt 0.4318 TrainAcc 0.9200 TestAcc 0.8879 0.9000
epoch 2200 LossPred 0.2251 LossAtt 0.4374 TrainAcc 0.9400 TestAcc 0.8924 0.9100
epoch 2300 LossPred 0.2134 LossAtt 0.4608 TrainAcc 0.9500 TestAcc 0.8986 0.9000
epoch 2400 LossPred 0.2455 LossAtt 0.4401 TrainAcc 0.9300 TestAcc 0.8956 0.8850
epoch 2500 LossPred 0.2333 LossAtt 0.4580 TrainAcc 0.9300 TestAcc 0.8831 0.9150
Optimization Finished!
********** replication  7  **********
epoch   0 LossPred 0.9747 LossAtt 1.0048 TrainAcc 0.6300 TestAcc 0.5831 0.5850
epoch 100 LossPred 0.8442 LossAtt 0.4567 TrainAcc 0.6700 TestAcc 0.6114 0.6650
epoch 200 LossPred 0.6151 LossAtt 0.3988 TrainAcc 0.7900 TestAcc 0.6834 0.7800
epoch 300 LossPred 0.3255 LossAtt 0.4309 TrainAcc 0.9000 TestAcc 0.8231 0.9150
epoch 400 LossPred 0.3258 LossAtt 0.3683 TrainAcc 0.9000 TestAcc 0.8183 0.8750
epoch 500 LossPred 0.2990 LossAtt 0.3369 TrainAcc 0.9000 TestAcc 0.8203 0.9150
epoch 600 LossPred 0.2851 LossAtt 0.4067 TrainAcc 0.9100 TestAcc 0.8291 0.9250
epoch 700 LossPred 0.2615 LossAtt 0.4092 TrainAcc 0.9300 TestAcc 0.8486 0.9150
epoch 800 LossPred 0.2448 LossAtt 0.3814 TrainAcc 0.9300 TestAcc 0.8401 0.9250
epoch 900 LossPred 0.2426 LossAtt 0.3790 TrainAcc 0.9300 TestAcc 0.8473 0.9250
epoch 1000 LossPred 0.2293 LossAtt 0.3842 TrainAcc 0.9400 TestAcc 0.8539 0.9200
epoch 1100 LossPred 0.2138 LossAtt 0.3677 TrainAcc 0.9500 TestAcc 0.8554 0.9200
epoch 1200 LossPred 0.1947 LossAtt 0.4034 TrainAcc 0.9500 TestAcc 0.8781 0.9200
epoch 1300 LossPred 0.2106 LossAtt 0.3880 TrainAcc 0.9400 TestAcc 0.8689 0.9250
epoch 1400 LossPred 0.2510 LossAtt 0.4015 TrainAcc 0.9300 TestAcc 0.8321 0.9250
epoch 1500 LossPred 0.2238 LossAtt 0.4065 TrainAcc 0.9400 TestAcc 0.8766 0.9250
epoch 1600 LossPred 0.2002 LossAtt 0.3974 TrainAcc 0.9500 TestAcc 0.8779 0.9300
epoch 1700 LossPred 0.2290 LossAtt 0.4113 TrainAcc 0.9200 TestAcc 0.8566 0.9200
epoch 1800 LossPred 0.2222 LossAtt 0.3827 TrainAcc 0.9300 TestAcc 0.8589 0.9150
epoch 1900 LossPred 0.1752 LossAtt 0.3769 TrainAcc 0.9600 TestAcc 0.8744 0.9350
epoch 2000 LossPred 0.2669 LossAtt 0.3833 TrainAcc 0.9200 TestAcc 0.8721 0.9250
epoch 2100 LossPred 0.1737 LossAtt 0.3773 TrainAcc 0.9600 TestAcc 0.8789 0.9400
epoch 2200 LossPred 0.2074 LossAtt 0.3572 TrainAcc 0.9400 TestAcc 0.8544 0.9400
epoch 2300 LossPred 0.2169 LossAtt 0.3572 TrainAcc 0.9400 TestAcc 0.8631 0.9150
epoch 2400 LossPred 0.1779 LossAtt 0.3717 TrainAcc 0.9600 TestAcc 0.8799 0.9450
epoch 2500 LossPred 0.2055 LossAtt 0.3448 TrainAcc 0.9400 TestAcc 0.8894 0.9300
Optimization Finished!
********** replication  8  **********
epoch   0 LossPred 1.0838 LossAtt 1.0222 TrainAcc 0.5700 TestAcc 0.5048 0.5700
epoch 100 LossPred 0.9487 LossAtt 0.4229 TrainAcc 0.5700 TestAcc 0.5048 0.5750
epoch 200 LossPred 0.9059 LossAtt 0.3851 TrainAcc 0.6400 TestAcc 0.6026 0.6400
epoch 300 LossPred 0.8065 LossAtt 0.4225 TrainAcc 0.7200 TestAcc 0.6564 0.7150
epoch 400 LossPred 0.4221 LossAtt 0.4386 TrainAcc 0.8600 TestAcc 0.8734 0.8400
epoch 500 LossPred 0.3482 LossAtt 0.4035 TrainAcc 0.8900 TestAcc 0.8976 0.8750
epoch 600 LossPred 0.2687 LossAtt 0.3745 TrainAcc 0.9100 TestAcc 0.9209 0.9000
epoch 700 LossPred 0.2808 LossAtt 0.3756 TrainAcc 0.9000 TestAcc 0.9132 0.9000
epoch 800 LossPred 0.2590 LossAtt 0.3578 TrainAcc 0.9300 TestAcc 0.9242 0.9100
epoch 900 LossPred 0.2480 LossAtt 0.3789 TrainAcc 0.9400 TestAcc 0.9217 0.9200
epoch 1000 LossPred 0.4061 LossAtt 0.3296 TrainAcc 0.8400 TestAcc 0.8709 0.8400
epoch 1100 LossPred 0.2150 LossAtt 0.3350 TrainAcc 0.9300 TestAcc 0.9292 0.9350
epoch 1200 LossPred 0.3437 LossAtt 0.3591 TrainAcc 0.8400 TestAcc 0.8651 0.8150
epoch 1300 LossPred 0.2320 LossAtt 0.3604 TrainAcc 0.9100 TestAcc 0.9304 0.9200
epoch 1400 LossPred 0.1918 LossAtt 0.3418 TrainAcc 0.9500 TestAcc 0.9264 0.9350
epoch 1500 LossPred 0.2318 LossAtt 0.3526 TrainAcc 0.9000 TestAcc 0.9304 0.9100
epoch 1600 LossPred 0.2208 LossAtt 0.3569 TrainAcc 0.9000 TestAcc 0.9289 0.9100
epoch 1700 LossPred 0.1781 LossAtt 0.3810 TrainAcc 0.9200 TestAcc 0.9339 0.9200
epoch 1800 LossPred 0.2383 LossAtt 0.3571 TrainAcc 0.9100 TestAcc 0.9239 0.9150
epoch 1900 LossPred 0.1779 LossAtt 0.3771 TrainAcc 0.9200 TestAcc 0.9347 0.9200
epoch 2000 LossPred 0.2313 LossAtt 0.3765 TrainAcc 0.9000 TestAcc 0.9214 0.9050
epoch 2100 LossPred 0.1609 LossAtt 0.3632 TrainAcc 0.9300 TestAcc 0.9387 0.9300
epoch 2200 LossPred 0.1536 LossAtt 0.3619 TrainAcc 0.9600 TestAcc 0.9444 0.9600
epoch 2300 LossPred 0.1306 LossAtt 0.3675 TrainAcc 0.9800 TestAcc 0.9492 0.9700
epoch 2400 LossPred 0.1784 LossAtt 0.3801 TrainAcc 0.9200 TestAcc 0.9244 0.9150
epoch 2500 LossPred 0.1540 LossAtt 0.3902 TrainAcc 0.9400 TestAcc 0.9379 0.9400
Optimization Finished!
********** replication  9  **********
epoch   0 LossPred 1.0379 LossAtt 1.0029 TrainAcc 0.5100 TestAcc 0.5556 0.5000
epoch 100 LossPred 0.9642 LossAtt 0.3216 TrainAcc 0.5900 TestAcc 0.5938 0.5900
epoch 200 LossPred 0.9620 LossAtt 0.2840 TrainAcc 0.5900 TestAcc 0.5938 0.5900
epoch 300 LossPred 0.9589 LossAtt 0.2308 TrainAcc 0.5900 TestAcc 0.5938 0.5900
epoch 400 LossPred 0.8806 LossAtt 0.4584 TrainAcc 0.6700 TestAcc 0.6737 0.6450
epoch 500 LossPred 0.4491 LossAtt 0.4625 TrainAcc 0.8600 TestAcc 0.8821 0.8650
epoch 600 LossPred 0.4694 LossAtt 0.4657 TrainAcc 0.8300 TestAcc 0.8774 0.8300
epoch 700 LossPred 0.3876 LossAtt 0.4940 TrainAcc 0.8800 TestAcc 0.8509 0.8600
epoch 800 LossPred 0.5452 LossAtt 0.4848 TrainAcc 0.8000 TestAcc 0.8358 0.8000
epoch 900 LossPred 0.4355 LossAtt 0.4853 TrainAcc 0.8600 TestAcc 0.8846 0.8450
epoch 1000 LossPred 0.3439 LossAtt 0.4550 TrainAcc 0.8800 TestAcc 0.8373 0.8700
epoch 1100 LossPred 0.2554 LossAtt 0.4556 TrainAcc 0.9300 TestAcc 0.8706 0.9150
epoch 1200 LossPred 0.3220 LossAtt 0.4490 TrainAcc 0.9100 TestAcc 0.8398 0.9050
epoch 1300 LossPred 0.5591 LossAtt 0.4428 TrainAcc 0.7900 TestAcc 0.7748 0.7950
epoch 1400 LossPred 0.4118 LossAtt 0.4364 TrainAcc 0.8600 TestAcc 0.8151 0.8700
epoch 1500 LossPred 0.5128 LossAtt 0.4341 TrainAcc 0.8100 TestAcc 0.8038 0.8200
epoch 1600 LossPred 0.7574 LossAtt 0.4121 TrainAcc 0.7400 TestAcc 0.7215 0.7300
epoch 1700 LossPred 0.4769 LossAtt 0.4177 TrainAcc 0.8400 TestAcc 0.8043 0.8450
epoch 1800 LossPred 0.3652 LossAtt 0.4011 TrainAcc 0.9000 TestAcc 0.8629 0.9050
epoch 1900 LossPred 0.3347 LossAtt 0.4196 TrainAcc 0.9100 TestAcc 0.8871 0.9050
epoch 2000 LossPred 0.3842 LossAtt 0.4024 TrainAcc 0.8700 TestAcc 0.8669 0.8650
epoch 2100 LossPred 0.4522 LossAtt 0.3868 TrainAcc 0.8400 TestAcc 0.8368 0.8600
epoch 2200 LossPred 0.1930 LossAtt 0.4025 TrainAcc 0.9500 TestAcc 0.8604 0.9450
epoch 2300 LossPred 0.2692 LossAtt 0.4339 TrainAcc 0.9200 TestAcc 0.8669 0.9200
epoch 2400 LossPred 0.2350 LossAtt 0.3954 TrainAcc 0.9400 TestAcc 0.8721 0.9300
epoch 2500 LossPred 0.1789 LossAtt 0.3881 TrainAcc 0.9300 TestAcc 0.8591 0.9450
Optimization Finished!
********** replication  10  **********
epoch   0 LossPred 0.8321 LossAtt 1.0324 TrainAcc 0.7000 TestAcc 0.6069 0.6950
epoch 100 LossPred 0.7333 LossAtt 0.4830 TrainAcc 0.7200 TestAcc 0.6241 0.7300
epoch 200 LossPred 0.4446 LossAtt 0.6162 TrainAcc 0.8500 TestAcc 0.7585 0.8500
epoch 300 LossPred 0.3233 LossAtt 0.5569 TrainAcc 0.9400 TestAcc 0.8426 0.9050
epoch 400 LossPred 0.4056 LossAtt 0.5254 TrainAcc 0.8900 TestAcc 0.7738 0.8750
epoch 500 LossPred 0.2330 LossAtt 0.5294 TrainAcc 0.9400 TestAcc 0.8929 0.9300
epoch 600 LossPred 0.2813 LossAtt 0.5247 TrainAcc 0.9100 TestAcc 0.8879 0.9200
epoch 700 LossPred 0.1997 LossAtt 0.5209 TrainAcc 0.9600 TestAcc 0.9202 0.9250
epoch 800 LossPred 0.1577 LossAtt 0.4860 TrainAcc 0.9600 TestAcc 0.8829 0.9250
epoch 900 LossPred 0.1632 LossAtt 0.4708 TrainAcc 0.9500 TestAcc 0.8851 0.9300
epoch 1000 LossPred 0.1432 LossAtt 0.4823 TrainAcc 0.9500 TestAcc 0.9027 0.9500
epoch 1100 LossPred 0.1401 LossAtt 0.4807 TrainAcc 0.9600 TestAcc 0.9062 0.9550
epoch 1200 LossPred 0.1370 LossAtt 0.4662 TrainAcc 0.9500 TestAcc 0.9017 0.9400
epoch 1300 LossPred 0.1560 LossAtt 0.4634 TrainAcc 0.9700 TestAcc 0.9142 0.9550
epoch 1400 LossPred 0.1308 LossAtt 0.4649 TrainAcc 0.9500 TestAcc 0.9074 0.9550
epoch 1500 LossPred 0.2652 LossAtt 0.4674 TrainAcc 0.9300 TestAcc 0.8373 0.8950
epoch 1600 LossPred 0.2100 LossAtt 0.4697 TrainAcc 0.9300 TestAcc 0.8689 0.9250
epoch 1700 LossPred 0.2496 LossAtt 0.4651 TrainAcc 0.9200 TestAcc 0.8966 0.8950
epoch 1800 LossPred 0.1441 LossAtt 0.4529 TrainAcc 0.9600 TestAcc 0.9024 0.9500
epoch 1900 LossPred 0.1393 LossAtt 0.4599 TrainAcc 0.9600 TestAcc 0.8989 0.9600
epoch 2000 LossPred 0.1416 LossAtt 0.4471 TrainAcc 0.9600 TestAcc 0.8884 0.9400
epoch 2100 LossPred 0.1355 LossAtt 0.4430 TrainAcc 0.9600 TestAcc 0.9054 0.9650
epoch 2200 LossPred 0.1312 LossAtt 0.4555 TrainAcc 0.9600 TestAcc 0.9092 0.9650
epoch 2300 LossPred 0.1381 LossAtt 0.4467 TrainAcc 0.9600 TestAcc 0.9087 0.9600
epoch 2400 LossPred 0.1248 LossAtt 0.4599 TrainAcc 0.9600 TestAcc 0.9154 0.9700
epoch 2500 LossPred 0.1470 LossAtt 0.4311 TrainAcc 0.9600 TestAcc 0.8949 0.9450
Optimization Finished!
********** replication  11  **********
epoch   0 LossPred 1.4150 LossAtt 1.0041 TrainAcc 0.4400 TestAcc 0.5073 0.4500
epoch 100 LossPred 0.9081 LossAtt 0.4870 TrainAcc 0.5600 TestAcc 0.5130 0.6200
epoch 200 LossPred 0.7430 LossAtt 0.4001 TrainAcc 0.7600 TestAcc 0.6081 0.7600
epoch 300 LossPred 0.7139 LossAtt 0.3703 TrainAcc 0.7600 TestAcc 0.6081 0.7600
epoch 400 LossPred 0.7036 LossAtt 0.3633 TrainAcc 0.7600 TestAcc 0.6081 0.7600
epoch 500 LossPred 0.7010 LossAtt 0.3843 TrainAcc 0.7600 TestAcc 0.6081 0.7600
epoch 600 LossPred 0.6853 LossAtt 0.4120 TrainAcc 0.7600 TestAcc 0.6081 0.7600
epoch 700 LossPred 0.6641 LossAtt 0.4219 TrainAcc 0.7700 TestAcc 0.6229 0.7600
epoch 800 LossPred 0.2386 LossAtt 0.4562 TrainAcc 0.9700 TestAcc 0.8649 0.9250
epoch 900 LossPred 0.2586 LossAtt 0.4264 TrainAcc 0.9200 TestAcc 0.8626 0.9150
epoch 1000 LossPred 0.2081 LossAtt 0.4284 TrainAcc 0.9400 TestAcc 0.8378 0.8950
epoch 1100 LossPred 0.1956 LossAtt 0.4184 TrainAcc 0.9500 TestAcc 0.8641 0.9150
epoch 1200 LossPred 0.1854 LossAtt 0.4144 TrainAcc 0.9600 TestAcc 0.8604 0.9150
epoch 1300 LossPred 0.1837 LossAtt 0.4013 TrainAcc 0.9600 TestAcc 0.8749 0.8950
epoch 1400 LossPred 0.1823 LossAtt 0.3979 TrainAcc 0.9400 TestAcc 0.8501 0.9150
epoch 1500 LossPred 0.1673 LossAtt 0.3970 TrainAcc 0.9700 TestAcc 0.8744 0.9150
epoch 1600 LossPred 0.1518 LossAtt 0.3870 TrainAcc 0.9600 TestAcc 0.8659 0.9150
epoch 1700 LossPred 0.1937 LossAtt 0.4011 TrainAcc 0.9400 TestAcc 0.8303 0.9000
epoch 1800 LossPred 0.1708 LossAtt 0.3722 TrainAcc 0.9400 TestAcc 0.8611 0.9250
epoch 1900 LossPred 0.1525 LossAtt 0.3967 TrainAcc 0.9600 TestAcc 0.8771 0.9300
epoch 2000 LossPred 0.1515 LossAtt 0.4061 TrainAcc 0.9500 TestAcc 0.8731 0.9300
epoch 2100 LossPred 0.1576 LossAtt 0.3686 TrainAcc 0.9500 TestAcc 0.8514 0.9100
epoch 2200 LossPred 0.1414 LossAtt 0.3885 TrainAcc 0.9600 TestAcc 0.8786 0.9400
epoch 2300 LossPred 0.1412 LossAtt 0.3969 TrainAcc 0.9600 TestAcc 0.8791 0.9500
epoch 2400 LossPred 0.1243 LossAtt 0.4036 TrainAcc 0.9700 TestAcc 0.8759 0.9350
epoch 2500 LossPred 0.1074 LossAtt 0.3895 TrainAcc 0.9800 TestAcc 0.8796 0.9400
Optimization Finished!
********** replication  12  **********
epoch   0 LossPred 1.0763 LossAtt 1.0106 TrainAcc 0.6400 TestAcc 0.5495 0.6150
epoch 100 LossPred 0.9210 LossAtt 0.5467 TrainAcc 0.6500 TestAcc 0.5533 0.6350
epoch 200 LossPred 0.9025 LossAtt 0.5857 TrainAcc 0.6500 TestAcc 0.5651 0.6350
epoch 300 LossPred 0.8863 LossAtt 0.5751 TrainAcc 0.6300 TestAcc 0.5613 0.6200
epoch 400 LossPred 0.8659 LossAtt 0.5767 TrainAcc 0.6500 TestAcc 0.5641 0.6200
epoch 500 LossPred 0.8535 LossAtt 0.5544 TrainAcc 0.6800 TestAcc 0.5626 0.6400
epoch 600 LossPred 0.8359 LossAtt 0.5372 TrainAcc 0.7000 TestAcc 0.5561 0.6450
epoch 700 LossPred 0.7967 LossAtt 0.5741 TrainAcc 0.6800 TestAcc 0.5586 0.6600
epoch 800 LossPred 0.6619 LossAtt 0.5892 TrainAcc 0.7500 TestAcc 0.5838 0.6700
epoch 900 LossPred 0.6252 LossAtt 0.5877 TrainAcc 0.7900 TestAcc 0.6161 0.7200
epoch 1000 LossPred 0.6088 LossAtt 0.6045 TrainAcc 0.7700 TestAcc 0.6309 0.7100
epoch 1100 LossPred 0.5501 LossAtt 0.5632 TrainAcc 0.8000 TestAcc 0.6264 0.7150
epoch 1200 LossPred 0.5637 LossAtt 0.5513 TrainAcc 0.7900 TestAcc 0.6331 0.7300
epoch 1300 LossPred 0.5668 LossAtt 0.5501 TrainAcc 0.7900 TestAcc 0.6344 0.7350
epoch 1400 LossPred 0.5318 LossAtt 0.5297 TrainAcc 0.8100 TestAcc 0.6296 0.7400
epoch 1500 LossPred 0.5304 LossAtt 0.5232 TrainAcc 0.8000 TestAcc 0.6246 0.7400
epoch 1600 LossPred 0.5318 LossAtt 0.5045 TrainAcc 0.8100 TestAcc 0.6209 0.7500
epoch 1700 LossPred 0.5419 LossAtt 0.5161 TrainAcc 0.8100 TestAcc 0.6249 0.7400
epoch 1800 LossPred 0.6315 LossAtt 0.5585 TrainAcc 0.7800 TestAcc 0.6404 0.7200
epoch 1900 LossPred 0.6223 LossAtt 0.5838 TrainAcc 0.8000 TestAcc 0.6584 0.7550
epoch 2000 LossPred 0.5848 LossAtt 0.5889 TrainAcc 0.8100 TestAcc 0.6749 0.7700
epoch 2100 LossPred 0.5056 LossAtt 0.5581 TrainAcc 0.8400 TestAcc 0.6679 0.7950
epoch 2200 LossPred 0.4902 LossAtt 0.5510 TrainAcc 0.8400 TestAcc 0.6707 0.7850
epoch 2300 LossPred 0.4660 LossAtt 0.5463 TrainAcc 0.8500 TestAcc 0.6824 0.7950
epoch 2400 LossPred 0.5168 LossAtt 0.5265 TrainAcc 0.8600 TestAcc 0.6799 0.7950
epoch 2500 LossPred 0.4448 LossAtt 0.5358 TrainAcc 0.8800 TestAcc 0.7012 0.8350
Optimization Finished!
********** replication  13  **********
epoch   0 LossPred 1.0544 LossAtt 1.0291 TrainAcc 0.5100 TestAcc 0.5621 0.5050
epoch 100 LossPred 0.9133 LossAtt 0.3912 TrainAcc 0.5600 TestAcc 0.5993 0.5600
epoch 200 LossPred 0.9066 LossAtt 0.3734 TrainAcc 0.6000 TestAcc 0.5758 0.5850
epoch 300 LossPred 0.9017 LossAtt 0.3977 TrainAcc 0.6100 TestAcc 0.5395 0.5950
epoch 400 LossPred 0.8897 LossAtt 0.4240 TrainAcc 0.6000 TestAcc 0.5215 0.5900
epoch 500 LossPred 0.6853 LossAtt 0.4529 TrainAcc 0.7800 TestAcc 0.7703 0.7600
epoch 600 LossPred 0.5783 LossAtt 0.4103 TrainAcc 0.8200 TestAcc 0.7292 0.8250
epoch 700 LossPred 0.4290 LossAtt 0.3965 TrainAcc 0.8600 TestAcc 0.7550 0.8350
epoch 800 LossPred 0.3865 LossAtt 0.3626 TrainAcc 0.9000 TestAcc 0.7780 0.8750
epoch 900 LossPred 0.3996 LossAtt 0.3740 TrainAcc 0.8900 TestAcc 0.7780 0.8700
epoch 1000 LossPred 0.2808 LossAtt 0.3628 TrainAcc 0.9000 TestAcc 0.8276 0.9050
epoch 1100 LossPred 0.2614 LossAtt 0.3660 TrainAcc 0.9000 TestAcc 0.8303 0.9050
epoch 1200 LossPred 0.3076 LossAtt 0.3851 TrainAcc 0.9000 TestAcc 0.8228 0.9000
epoch 1300 LossPred 0.2491 LossAtt 0.3936 TrainAcc 0.9200 TestAcc 0.8381 0.8950
epoch 1400 LossPred 0.2412 LossAtt 0.3910 TrainAcc 0.9300 TestAcc 0.8471 0.9000
epoch 1500 LossPred 0.2267 LossAtt 0.3991 TrainAcc 0.9400 TestAcc 0.8488 0.9150
epoch 1600 LossPred 0.2994 LossAtt 0.3882 TrainAcc 0.9000 TestAcc 0.8386 0.9100
epoch 1700 LossPred 0.2248 LossAtt 0.3694 TrainAcc 0.9300 TestAcc 0.8441 0.9150
epoch 1800 LossPred 0.2281 LossAtt 0.3433 TrainAcc 0.9200 TestAcc 0.8213 0.9050
epoch 1900 LossPred 0.2375 LossAtt 0.3489 TrainAcc 0.9200 TestAcc 0.8203 0.9200
epoch 2000 LossPred 0.2518 LossAtt 0.3730 TrainAcc 0.9300 TestAcc 0.8141 0.9050
epoch 2100 LossPred 0.2227 LossAtt 0.3454 TrainAcc 0.9300 TestAcc 0.8298 0.9150
epoch 2200 LossPred 0.2967 LossAtt 0.3852 TrainAcc 0.9200 TestAcc 0.8456 0.9050
epoch 2300 LossPred 0.2258 LossAtt 0.3827 TrainAcc 0.9400 TestAcc 0.8511 0.9200
epoch 2400 LossPred 0.2017 LossAtt 0.4015 TrainAcc 0.9300 TestAcc 0.8258 0.9100
epoch 2500 LossPred 0.4966 LossAtt 0.4086 TrainAcc 0.8600 TestAcc 0.8006 0.8450
Optimization Finished!
********** replication  14  **********
epoch   0 LossPred 1.0782 LossAtt 1.0263 TrainAcc 0.5500 TestAcc 0.5193 0.5400
epoch 100 LossPred 0.9210 LossAtt 0.4101 TrainAcc 0.6300 TestAcc 0.5991 0.6200
epoch 200 LossPred 0.9125 LossAtt 0.3068 TrainAcc 0.6300 TestAcc 0.5991 0.6250
epoch 300 LossPred 0.9094 LossAtt 0.3076 TrainAcc 0.6300 TestAcc 0.5991 0.6300
epoch 400 LossPred 0.9023 LossAtt 0.3369 TrainAcc 0.6300 TestAcc 0.5991 0.6300
epoch 500 LossPred 0.8682 LossAtt 0.3720 TrainAcc 0.6500 TestAcc 0.6642 0.6450
epoch 600 LossPred 0.5967 LossAtt 0.4640 TrainAcc 0.7700 TestAcc 0.7798 0.7650
epoch 700 LossPred 0.4175 LossAtt 0.4974 TrainAcc 0.8600 TestAcc 0.8351 0.8300
epoch 800 LossPred 0.1859 LossAtt 0.4757 TrainAcc 0.9800 TestAcc 0.9424 0.9100
epoch 900 LossPred 0.3124 LossAtt 0.4296 TrainAcc 0.9000 TestAcc 0.9032 0.8900
epoch 1000 LossPred 0.1626 LossAtt 0.4086 TrainAcc 0.9800 TestAcc 0.9532 0.9100
epoch 1100 LossPred 0.1400 LossAtt 0.3828 TrainAcc 0.9700 TestAcc 0.9347 0.9250
epoch 1200 LossPred 0.1527 LossAtt 0.4014 TrainAcc 0.9500 TestAcc 0.9134 0.9350
epoch 1300 LossPred 0.1495 LossAtt 0.3815 TrainAcc 0.9700 TestAcc 0.9254 0.9350
epoch 1400 LossPred 0.1394 LossAtt 0.3655 TrainAcc 0.9700 TestAcc 0.9382 0.9350
epoch 1500 LossPred 0.1467 LossAtt 0.3691 TrainAcc 0.9500 TestAcc 0.9184 0.9450
epoch 1600 LossPred 0.2046 LossAtt 0.3959 TrainAcc 0.9300 TestAcc 0.8806 0.9000
epoch 1700 LossPred 0.1214 LossAtt 0.3585 TrainAcc 0.9700 TestAcc 0.9359 0.9550
epoch 1800 LossPred 0.1155 LossAtt 0.3611 TrainAcc 0.9600 TestAcc 0.9447 0.9550
epoch 1900 LossPred 0.1272 LossAtt 0.3515 TrainAcc 0.9600 TestAcc 0.9489 0.9500
epoch 2000 LossPred 0.1133 LossAtt 0.3495 TrainAcc 0.9700 TestAcc 0.9359 0.9600
epoch 2100 LossPred 0.1376 LossAtt 0.3535 TrainAcc 0.9400 TestAcc 0.9127 0.9400
epoch 2200 LossPred 0.1071 LossAtt 0.3458 TrainAcc 0.9800 TestAcc 0.9494 0.9600
epoch 2300 LossPred 0.1129 LossAtt 0.3726 TrainAcc 0.9700 TestAcc 0.9322 0.9600
epoch 2400 LossPred 0.0987 LossAtt 0.3462 TrainAcc 0.9800 TestAcc 0.9537 0.9600
epoch 2500 LossPred 0.1301 LossAtt 0.3610 TrainAcc 0.9800 TestAcc 0.9560 0.9450
Optimization Finished!
********** replication  15  **********
epoch   0 LossPred 0.9870 LossAtt 1.0463 TrainAcc 0.5400 TestAcc 0.5738 0.5650
epoch 100 LossPred 0.9075 LossAtt 0.4218 TrainAcc 0.6100 TestAcc 0.6049 0.6100
epoch 200 LossPred 0.7392 LossAtt 0.4392 TrainAcc 0.7700 TestAcc 0.6709 0.7550
epoch 300 LossPred 0.4095 LossAtt 0.4279 TrainAcc 0.8700 TestAcc 0.8836 0.8550
epoch 400 LossPred 0.2318 LossAtt 0.4261 TrainAcc 0.9400 TestAcc 0.8924 0.9050
epoch 500 LossPred 0.2736 LossAtt 0.4229 TrainAcc 0.8800 TestAcc 0.8739 0.8900
epoch 600 LossPred 0.1434 LossAtt 0.4160 TrainAcc 0.9600 TestAcc 0.9429 0.9400
epoch 700 LossPred 0.1335 LossAtt 0.4174 TrainAcc 0.9700 TestAcc 0.9535 0.9200
epoch 800 LossPred 0.1239 LossAtt 0.4258 TrainAcc 0.9700 TestAcc 0.9542 0.9350
epoch 900 LossPred 0.1508 LossAtt 0.4244 TrainAcc 0.9500 TestAcc 0.9359 0.9350
epoch 1000 LossPred 0.1289 LossAtt 0.4300 TrainAcc 0.9700 TestAcc 0.9562 0.9200
epoch 1100 LossPred 0.1380 LossAtt 0.4004 TrainAcc 0.9500 TestAcc 0.9439 0.9400
epoch 1200 LossPred 0.1136 LossAtt 0.3859 TrainAcc 0.9700 TestAcc 0.9647 0.9250
epoch 1300 LossPred 0.0912 LossAtt 0.4015 TrainAcc 0.9800 TestAcc 0.9575 0.9550
epoch 1400 LossPred 0.0997 LossAtt 0.4204 TrainAcc 0.9800 TestAcc 0.9635 0.9300
epoch 1500 LossPred 0.1513 LossAtt 0.3925 TrainAcc 0.9600 TestAcc 0.9247 0.9350
epoch 1600 LossPred 0.0910 LossAtt 0.4151 TrainAcc 0.9800 TestAcc 0.9600 0.9350
epoch 1700 LossPred 0.0935 LossAtt 0.4147 TrainAcc 0.9800 TestAcc 0.9580 0.9550
epoch 1800 LossPred 0.0896 LossAtt 0.4089 TrainAcc 0.9800 TestAcc 0.9540 0.9300
epoch 1900 LossPred 0.0732 LossAtt 0.4025 TrainAcc 0.9800 TestAcc 0.9610 0.9550
epoch 2000 LossPred 0.0889 LossAtt 0.4048 TrainAcc 0.9800 TestAcc 0.9444 0.9550
epoch 2100 LossPred 0.0757 LossAtt 0.3930 TrainAcc 0.9800 TestAcc 0.9685 0.9500
epoch 2200 LossPred 0.0745 LossAtt 0.3902 TrainAcc 0.9900 TestAcc 0.9630 0.9350
epoch 2300 LossPred 0.1244 LossAtt 0.3876 TrainAcc 0.9600 TestAcc 0.9329 0.9450
epoch 2400 LossPred 0.0714 LossAtt 0.3995 TrainAcc 0.9800 TestAcc 0.9542 0.9550
epoch 2500 LossPred 0.0730 LossAtt 0.3860 TrainAcc 0.9800 TestAcc 0.9520 0.9550
Optimization Finished!
********** replication  16  **********
epoch   0 LossPred 1.0214 LossAtt 1.0047 TrainAcc 0.5700 TestAcc 0.5400 0.5650
epoch 100 LossPred 0.9209 LossAtt 0.4485 TrainAcc 0.5800 TestAcc 0.5736 0.5800
epoch 200 LossPred 0.9181 LossAtt 0.3816 TrainAcc 0.6000 TestAcc 0.6036 0.5750
epoch 300 LossPred 0.9080 LossAtt 0.3380 TrainAcc 0.5700 TestAcc 0.6021 0.5700
epoch 400 LossPred 0.8831 LossAtt 0.3668 TrainAcc 0.6400 TestAcc 0.5751 0.6300
epoch 500 LossPred 0.8672 LossAtt 0.3880 TrainAcc 0.6800 TestAcc 0.5886 0.6750
epoch 600 LossPred 0.8343 LossAtt 0.4135 TrainAcc 0.6800 TestAcc 0.5693 0.6700
epoch 700 LossPred 0.8327 LossAtt 0.3510 TrainAcc 0.6800 TestAcc 0.5628 0.6700
epoch 800 LossPred 0.7930 LossAtt 0.4262 TrainAcc 0.7000 TestAcc 0.5571 0.6800
epoch 900 LossPred 0.7609 LossAtt 0.4161 TrainAcc 0.6900 TestAcc 0.5623 0.6650
epoch 1000 LossPred 0.7501 LossAtt 0.3732 TrainAcc 0.7000 TestAcc 0.5648 0.6850
epoch 1100 LossPred 0.7378 LossAtt 0.3693 TrainAcc 0.7000 TestAcc 0.5658 0.6900
epoch 1200 LossPred 0.7383 LossAtt 0.3379 TrainAcc 0.7200 TestAcc 0.5711 0.6800
epoch 1300 LossPred 0.7317 LossAtt 0.3274 TrainAcc 0.6800 TestAcc 0.5621 0.6800
epoch 1400 LossPred 0.7326 LossAtt 0.3151 TrainAcc 0.7100 TestAcc 0.5858 0.6700
epoch 1500 LossPred 0.7076 LossAtt 0.2994 TrainAcc 0.7200 TestAcc 0.6006 0.6650
epoch 1600 LossPred 0.7151 LossAtt 0.2938 TrainAcc 0.7100 TestAcc 0.5673 0.6750
epoch 1700 LossPred 0.7261 LossAtt 0.3105 TrainAcc 0.7000 TestAcc 0.5858 0.6750
epoch 1800 LossPred 0.6827 LossAtt 0.2927 TrainAcc 0.7000 TestAcc 0.6129 0.7000
epoch 1900 LossPred 0.6873 LossAtt 0.2973 TrainAcc 0.7200 TestAcc 0.6361 0.7050
epoch 2000 LossPred 0.6713 LossAtt 0.3036 TrainAcc 0.7100 TestAcc 0.6246 0.6800
epoch 2100 LossPred 0.6797 LossAtt 0.3068 TrainAcc 0.7100 TestAcc 0.6261 0.7100
epoch 2200 LossPred 0.6875 LossAtt 0.3116 TrainAcc 0.7100 TestAcc 0.6346 0.6900
epoch 2300 LossPred 0.7334 LossAtt 0.3228 TrainAcc 0.6700 TestAcc 0.6401 0.7100
epoch 2400 LossPred 0.7102 LossAtt 0.3319 TrainAcc 0.7000 TestAcc 0.6419 0.7000
epoch 2500 LossPred 0.6878 LossAtt 0.3104 TrainAcc 0.7200 TestAcc 0.6431 0.6900
Optimization Finished!
********** replication  17  **********
epoch   0 LossPred 1.1877 LossAtt 1.0174 TrainAcc 0.5600 TestAcc 0.5786 0.5250
epoch 100 LossPred 0.9804 LossAtt 0.4476 TrainAcc 0.5800 TestAcc 0.6049 0.5800
epoch 200 LossPred 0.9363 LossAtt 0.5313 TrainAcc 0.6200 TestAcc 0.6049 0.6100
epoch 300 LossPred 0.9177 LossAtt 0.5148 TrainAcc 0.6400 TestAcc 0.6066 0.6350
epoch 400 LossPred 0.8976 LossAtt 0.5359 TrainAcc 0.6500 TestAcc 0.6081 0.6350
epoch 500 LossPred 0.8783 LossAtt 0.5397 TrainAcc 0.6400 TestAcc 0.6084 0.6450
epoch 600 LossPred 0.8623 LossAtt 0.4957 TrainAcc 0.6600 TestAcc 0.6049 0.6500
epoch 700 LossPred 0.8475 LossAtt 0.4422 TrainAcc 0.6700 TestAcc 0.5966 0.6650
epoch 800 LossPred 0.8398 LossAtt 0.4828 TrainAcc 0.6700 TestAcc 0.5881 0.6450
epoch 900 LossPred 0.8151 LossAtt 0.5028 TrainAcc 0.6700 TestAcc 0.5733 0.6450
epoch 1000 LossPred 0.8226 LossAtt 0.5247 TrainAcc 0.6600 TestAcc 0.5771 0.6350
epoch 1100 LossPred 0.8179 LossAtt 0.5145 TrainAcc 0.6400 TestAcc 0.5766 0.6350
epoch 1200 LossPred 0.8000 LossAtt 0.4973 TrainAcc 0.6700 TestAcc 0.5728 0.6500
epoch 1300 LossPred 0.7926 LossAtt 0.5218 TrainAcc 0.6800 TestAcc 0.5801 0.6250
epoch 1400 LossPred 0.7795 LossAtt 0.5009 TrainAcc 0.7100 TestAcc 0.5771 0.6400
epoch 1500 LossPred 0.7725 LossAtt 0.4572 TrainAcc 0.6900 TestAcc 0.5858 0.6600
epoch 1600 LossPred 0.7639 LossAtt 0.4471 TrainAcc 0.7000 TestAcc 0.5783 0.6400
epoch 1700 LossPred 0.7026 LossAtt 0.4900 TrainAcc 0.7400 TestAcc 0.5876 0.6600
epoch 1800 LossPred 0.6740 LossAtt 0.4780 TrainAcc 0.7600 TestAcc 0.5981 0.6750
epoch 1900 LossPred 0.7386 LossAtt 0.5614 TrainAcc 0.7100 TestAcc 0.6189 0.6650
epoch 2000 LossPred 0.6985 LossAtt 0.5254 TrainAcc 0.7500 TestAcc 0.6101 0.7050
epoch 2100 LossPred 0.7074 LossAtt 0.5250 TrainAcc 0.7700 TestAcc 0.6166 0.6850
epoch 2200 LossPred 0.6828 LossAtt 0.5000 TrainAcc 0.7500 TestAcc 0.6174 0.6900
epoch 2300 LossPred 0.6820 LossAtt 0.5230 TrainAcc 0.7600 TestAcc 0.6109 0.7150
epoch 2400 LossPred 0.6800 LossAtt 0.4782 TrainAcc 0.7500 TestAcc 0.6171 0.6900
epoch 2500 LossPred 0.7123 LossAtt 0.5186 TrainAcc 0.7300 TestAcc 0.6266 0.6950
Optimization Finished!
********** replication  18  **********
epoch   0 LossPred 1.2176 LossAtt 1.0240 TrainAcc 0.5000 TestAcc 0.5465 0.5050
epoch 100 LossPred 0.9549 LossAtt 0.4827 TrainAcc 0.6000 TestAcc 0.6139 0.6000
epoch 200 LossPred 0.9235 LossAtt 0.4116 TrainAcc 0.6300 TestAcc 0.6051 0.6100
epoch 300 LossPred 0.9074 LossAtt 0.3980 TrainAcc 0.6300 TestAcc 0.6051 0.6300
epoch 400 LossPred 0.8949 LossAtt 0.2866 TrainAcc 0.6300 TestAcc 0.6051 0.6300
epoch 500 LossPred 0.8830 LossAtt 0.3192 TrainAcc 0.6600 TestAcc 0.6329 0.6600
epoch 600 LossPred 0.8573 LossAtt 0.3226 TrainAcc 0.6700 TestAcc 0.6542 0.6650
epoch 700 LossPred 0.2876 LossAtt 0.4186 TrainAcc 0.9500 TestAcc 0.9092 0.9500
epoch 800 LossPred 0.2225 LossAtt 0.3813 TrainAcc 0.9400 TestAcc 0.8911 0.9400
epoch 900 LossPred 0.1654 LossAtt 0.3962 TrainAcc 0.9400 TestAcc 0.9179 0.9500
epoch 1000 LossPred 0.1743 LossAtt 0.3918 TrainAcc 0.9600 TestAcc 0.9169 0.9500
epoch 1100 LossPred 0.0958 LossAtt 0.3964 TrainAcc 0.9900 TestAcc 0.9464 0.9850
epoch 1200 LossPred 0.1559 LossAtt 0.4260 TrainAcc 0.9500 TestAcc 0.9184 0.9550
epoch 1300 LossPred 0.0631 LossAtt 0.4257 TrainAcc 0.9900 TestAcc 0.9592 0.9850
epoch 1400 LossPred 0.0637 LossAtt 0.4290 TrainAcc 0.9900 TestAcc 0.9552 0.9950
epoch 1500 LossPred 0.0796 LossAtt 0.4661 TrainAcc 0.9800 TestAcc 0.9462 0.9800
epoch 1600 LossPred 0.0615 LossAtt 0.4544 TrainAcc 0.9900 TestAcc 0.9522 0.9850
epoch 1700 LossPred 0.0705 LossAtt 0.4321 TrainAcc 1.0000 TestAcc 0.9464 0.9850
Optimization Finished!
********** replication  19  **********
epoch   0 LossPred 0.9473 LossAtt 0.9971 TrainAcc 0.6000 TestAcc 0.5561 0.6050
epoch 100 LossPred 0.8000 LossAtt 0.5028 TrainAcc 0.6800 TestAcc 0.6589 0.6900
epoch 200 LossPred 0.4901 LossAtt 0.5154 TrainAcc 0.8300 TestAcc 0.8639 0.8350
epoch 300 LossPred 0.2963 LossAtt 0.5368 TrainAcc 0.9500 TestAcc 0.8934 0.8900
epoch 400 LossPred 0.2878 LossAtt 0.5361 TrainAcc 0.9100 TestAcc 0.8191 0.8950
epoch 500 LossPred 0.2470 LossAtt 0.5238 TrainAcc 0.9100 TestAcc 0.8571 0.9100
epoch 600 LossPred 0.2686 LossAtt 0.5158 TrainAcc 0.9400 TestAcc 0.9132 0.9000
epoch 700 LossPred 0.2204 LossAtt 0.4668 TrainAcc 0.9400 TestAcc 0.9219 0.9200
epoch 800 LossPred 0.1673 LossAtt 0.4356 TrainAcc 0.9700 TestAcc 0.9037 0.9550
epoch 900 LossPred 0.2452 LossAtt 0.4189 TrainAcc 0.9100 TestAcc 0.8559 0.9100
epoch 1000 LossPred 0.2213 LossAtt 0.4061 TrainAcc 0.9200 TestAcc 0.8659 0.9200
epoch 1100 LossPred 0.3585 LossAtt 0.3994 TrainAcc 0.9000 TestAcc 0.8851 0.8700
epoch 1200 LossPred 0.1726 LossAtt 0.4081 TrainAcc 0.9600 TestAcc 0.9234 0.9500
epoch 1300 LossPred 0.1781 LossAtt 0.3596 TrainAcc 0.9600 TestAcc 0.9257 0.9550
epoch 1400 LossPred 0.2491 LossAtt 0.3688 TrainAcc 0.9400 TestAcc 0.9169 0.9150
epoch 1500 LossPred 0.1943 LossAtt 0.3797 TrainAcc 0.9600 TestAcc 0.9309 0.9350
epoch 1600 LossPred 0.1635 LossAtt 0.3602 TrainAcc 0.9700 TestAcc 0.9224 0.9700
epoch 1700 LossPred 0.1541 LossAtt 0.3566 TrainAcc 0.9700 TestAcc 0.9217 0.9700
epoch 1800 LossPred 0.1977 LossAtt 0.3387 TrainAcc 0.9600 TestAcc 0.9292 0.9200
epoch 1900 LossPred 0.1852 LossAtt 0.3198 TrainAcc 0.9400 TestAcc 0.9302 0.9500
epoch 2000 LossPred 0.1989 LossAtt 0.3223 TrainAcc 0.9600 TestAcc 0.9189 0.9350
epoch 2100 LossPred 0.1598 LossAtt 0.2991 TrainAcc 0.9500 TestAcc 0.9059 0.9500
epoch 2200 LossPred 0.1503 LossAtt 0.2782 TrainAcc 0.9700 TestAcc 0.9217 0.9700
epoch 2300 LossPred 0.1551 LossAtt 0.2559 TrainAcc 0.9700 TestAcc 0.9034 0.9600
epoch 2400 LossPred 0.1965 LossAtt 0.2586 TrainAcc 0.9500 TestAcc 0.8826 0.9550
epoch 2500 LossPred 0.1672 LossAtt 0.2530 TrainAcc 0.9500 TestAcc 0.8934 0.9450
Optimization Finished!
********** replication  20  **********
epoch   0 LossPred 1.0272 LossAtt 1.0079 TrainAcc 0.5500 TestAcc 0.5518 0.5500
epoch 100 LossPred 0.8555 LossAtt 0.4853 TrainAcc 0.6800 TestAcc 0.6682 0.6700
epoch 200 LossPred 0.4444 LossAtt 0.4575 TrainAcc 0.8500 TestAcc 0.7990 0.8050
epoch 300 LossPred 1.1472 LossAtt 0.3414 TrainAcc 0.5300 TestAcc 0.4927 0.5300
epoch 400 LossPred 0.8748 LossAtt 0.3618 TrainAcc 0.6400 TestAcc 0.6436 0.6450
epoch 500 LossPred 0.4683 LossAtt 0.4197 TrainAcc 0.8300 TestAcc 0.7780 0.8150
epoch 600 LossPred 0.6401 LossAtt 0.4003 TrainAcc 0.7500 TestAcc 0.7220 0.7250
epoch 700 LossPred 0.5691 LossAtt 0.4036 TrainAcc 0.8300 TestAcc 0.8198 0.8050
epoch 800 LossPred 0.4490 LossAtt 0.3965 TrainAcc 0.8500 TestAcc 0.8456 0.8450
epoch 900 LossPred 0.3598 LossAtt 0.3949 TrainAcc 0.8800 TestAcc 0.8776 0.8700
epoch 1000 LossPred 0.4899 LossAtt 0.3960 TrainAcc 0.8200 TestAcc 0.8133 0.8100
epoch 1100 LossPred 0.4383 LossAtt 0.4095 TrainAcc 0.8100 TestAcc 0.8451 0.8450
epoch 1200 LossPred 0.2671 LossAtt 0.4199 TrainAcc 0.9400 TestAcc 0.8859 0.8950
epoch 1300 LossPred 0.3391 LossAtt 0.4420 TrainAcc 0.8800 TestAcc 0.8944 0.8700
epoch 1400 LossPred 0.2228 LossAtt 0.4521 TrainAcc 0.9500 TestAcc 0.9119 0.9150
epoch 1500 LossPred 0.2131 LossAtt 0.4433 TrainAcc 0.9500 TestAcc 0.9039 0.9150
epoch 1600 LossPred 0.2236 LossAtt 0.4468 TrainAcc 0.9500 TestAcc 0.8876 0.9150
epoch 1700 LossPred 0.2240 LossAtt 0.4319 TrainAcc 0.9400 TestAcc 0.8846 0.9100
epoch 1800 LossPred 0.1968 LossAtt 0.4446 TrainAcc 0.9400 TestAcc 0.9004 0.9200
epoch 1900 LossPred 0.2041 LossAtt 0.4460 TrainAcc 0.9500 TestAcc 0.8966 0.9100
epoch 2000 LossPred 0.1912 LossAtt 0.4321 TrainAcc 0.9500 TestAcc 0.9094 0.9150
epoch 2100 LossPred 0.2129 LossAtt 0.4141 TrainAcc 0.9400 TestAcc 0.9124 0.9000
epoch 2200 LossPred 0.2000 LossAtt 0.4173 TrainAcc 0.9400 TestAcc 0.9124 0.8950
epoch 2300 LossPred 0.1905 LossAtt 0.4227 TrainAcc 0.9400 TestAcc 0.9122 0.9200
epoch 2400 LossPred 0.1739 LossAtt 0.4003 TrainAcc 0.9500 TestAcc 0.9037 0.9150
epoch 2500 LossPred 0.2404 LossAtt 0.3963 TrainAcc 0.9000 TestAcc 0.8811 0.8900
Optimization Finished!
********** replication  21  **********
epoch   0 LossPred 0.9868 LossAtt 0.9932 TrainAcc 0.4800 TestAcc 0.5195 0.5000
epoch 100 LossPred 0.8380 LossAtt 0.4024 TrainAcc 0.6800 TestAcc 0.6061 0.6850
epoch 200 LossPred 0.8057 LossAtt 0.3894 TrainAcc 0.7000 TestAcc 0.6344 0.6950
epoch 300 LossPred 0.5075 LossAtt 0.4954 TrainAcc 0.8500 TestAcc 0.8809 0.8250
epoch 400 LossPred 0.5367 LossAtt 0.4231 TrainAcc 0.8400 TestAcc 0.7915 0.7900
epoch 500 LossPred 0.3190 LossAtt 0.4633 TrainAcc 0.9000 TestAcc 0.8846 0.8500
epoch 600 LossPred 0.3331 LossAtt 0.4405 TrainAcc 0.8800 TestAcc 0.8969 0.8500
epoch 700 LossPred 0.4404 LossAtt 0.4545 TrainAcc 0.8400 TestAcc 0.8764 0.8300
epoch 800 LossPred 0.2726 LossAtt 0.4453 TrainAcc 0.9200 TestAcc 0.8891 0.8450
epoch 900 LossPred 0.2585 LossAtt 0.4423 TrainAcc 0.9300 TestAcc 0.9162 0.8950
epoch 1000 LossPred 0.3592 LossAtt 0.4553 TrainAcc 0.8600 TestAcc 0.9042 0.8500
epoch 1100 LossPred 0.1987 LossAtt 0.4551 TrainAcc 0.9400 TestAcc 0.9344 0.8950
epoch 1200 LossPred 0.2037 LossAtt 0.4359 TrainAcc 0.9700 TestAcc 0.9429 0.8900
epoch 1300 LossPred 0.3805 LossAtt 0.4364 TrainAcc 0.8200 TestAcc 0.8451 0.8400
epoch 1400 LossPred 0.4521 LossAtt 0.4436 TrainAcc 0.8200 TestAcc 0.8774 0.8250
epoch 1500 LossPred 0.1914 LossAtt 0.4381 TrainAcc 0.9600 TestAcc 0.9510 0.9200
epoch 1600 LossPred 0.1926 LossAtt 0.4367 TrainAcc 0.9600 TestAcc 0.9392 0.9100
epoch 1700 LossPred 0.1754 LossAtt 0.4231 TrainAcc 0.9700 TestAcc 0.9657 0.9100
epoch 1800 LossPred 0.2560 LossAtt 0.4090 TrainAcc 0.9200 TestAcc 0.9277 0.8850
epoch 1900 LossPred 0.2294 LossAtt 0.4192 TrainAcc 0.9400 TestAcc 0.9462 0.8900
epoch 2000 LossPred 0.1620 LossAtt 0.4018 TrainAcc 0.9600 TestAcc 0.9359 0.9100
epoch 2100 LossPred 0.1705 LossAtt 0.3815 TrainAcc 0.9400 TestAcc 0.9104 0.9250
epoch 2200 LossPred 0.3836 LossAtt 0.3822 TrainAcc 0.8500 TestAcc 0.8584 0.8600
epoch 2300 LossPred 0.1863 LossAtt 0.3835 TrainAcc 0.9400 TestAcc 0.9152 0.9250
epoch 2400 LossPred 0.1808 LossAtt 0.3710 TrainAcc 0.9600 TestAcc 0.9219 0.9500
epoch 2500 LossPred 0.2038 LossAtt 0.3838 TrainAcc 0.9200 TestAcc 0.9314 0.9050
Optimization Finished!
********** replication  22  **********
epoch   0 LossPred 1.2165 LossAtt 1.0164 TrainAcc 0.5100 TestAcc 0.4985 0.5200
epoch 100 LossPred 0.9324 LossAtt 0.4035 TrainAcc 0.6100 TestAcc 0.6021 0.6200
epoch 200 LossPred 0.9095 LossAtt 0.3783 TrainAcc 0.6400 TestAcc 0.6026 0.6500
epoch 300 LossPred 0.7734 LossAtt 0.3182 TrainAcc 0.7200 TestAcc 0.7110 0.7150
epoch 400 LossPred 0.3862 LossAtt 0.2636 TrainAcc 0.8500 TestAcc 0.9117 0.8450
epoch 500 LossPred 0.3080 LossAtt 0.2630 TrainAcc 0.9000 TestAcc 0.9217 0.8750
epoch 600 LossPred 0.1565 LossAtt 0.2918 TrainAcc 0.9600 TestAcc 0.9552 0.9150
epoch 700 LossPred 0.1118 LossAtt 0.2886 TrainAcc 0.9800 TestAcc 0.9484 0.9350
epoch 800 LossPred 0.3684 LossAtt 0.2682 TrainAcc 0.8800 TestAcc 0.8669 0.8800
epoch 900 LossPred 0.2596 LossAtt 0.2656 TrainAcc 0.9200 TestAcc 0.9004 0.9050
epoch 1000 LossPred 0.2526 LossAtt 0.2449 TrainAcc 0.9200 TestAcc 0.9054 0.9100
epoch 1100 LossPred 0.2154 LossAtt 0.2671 TrainAcc 0.9400 TestAcc 0.9197 0.9150
epoch 1200 LossPred 0.1324 LossAtt 0.2752 TrainAcc 0.9700 TestAcc 0.9612 0.9200
epoch 1300 LossPred 0.2154 LossAtt 0.2379 TrainAcc 0.9300 TestAcc 0.9302 0.9150
epoch 1400 LossPred 0.3193 LossAtt 0.2653 TrainAcc 0.9000 TestAcc 0.8744 0.8850
epoch 1500 LossPred 0.4295 LossAtt 0.2291 TrainAcc 0.8700 TestAcc 0.8316 0.8650
epoch 1600 LossPred 0.1104 LossAtt 0.2494 TrainAcc 0.9700 TestAcc 0.9655 0.9300
epoch 1700 LossPred 0.1662 LossAtt 0.2448 TrainAcc 0.9500 TestAcc 0.9402 0.9350
epoch 1800 LossPred 0.0884 LossAtt 0.2756 TrainAcc 0.9800 TestAcc 0.9319 0.9700
epoch 1900 LossPred 0.0654 LossAtt 0.2642 TrainAcc 0.9900 TestAcc 0.9482 0.9550
epoch 2000 LossPred 0.0520 LossAtt 0.2678 TrainAcc 0.9900 TestAcc 0.9665 0.9500
epoch 2100 LossPred 0.2770 LossAtt 0.2571 TrainAcc 0.9100 TestAcc 0.9107 0.9100
epoch 2200 LossPred 0.0651 LossAtt 0.2527 TrainAcc 0.9800 TestAcc 0.9610 0.9450
epoch 2300 LossPred 0.1615 LossAtt 0.2717 TrainAcc 0.9500 TestAcc 0.8961 0.9350
epoch 2400 LossPred 0.0611 LossAtt 0.2685 TrainAcc 0.9900 TestAcc 0.9547 0.9550
epoch 2500 LossPred 0.0832 LossAtt 0.2476 TrainAcc 0.9800 TestAcc 0.9607 0.9600
Optimization Finished!
********** replication  23  **********
epoch   0 LossPred 1.1836 LossAtt 1.0027 TrainAcc 0.4600 TestAcc 0.4132 0.5050
epoch 100 LossPred 0.9654 LossAtt 0.5132 TrainAcc 0.5900 TestAcc 0.5460 0.6000
epoch 200 LossPred 0.9140 LossAtt 0.5094 TrainAcc 0.6200 TestAcc 0.5636 0.6100
epoch 300 LossPred 0.8891 LossAtt 0.4507 TrainAcc 0.6200 TestAcc 0.5636 0.6400
epoch 400 LossPred 0.8580 LossAtt 0.3964 TrainAcc 0.6500 TestAcc 0.5868 0.6450
epoch 500 LossPred 0.8005 LossAtt 0.4573 TrainAcc 0.7000 TestAcc 0.6609 0.6800
epoch 600 LossPred 0.3320 LossAtt 0.5057 TrainAcc 0.8800 TestAcc 0.8706 0.8800
epoch 700 LossPred 0.2970 LossAtt 0.4631 TrainAcc 0.9200 TestAcc 0.8759 0.9100
epoch 800 LossPred 0.2964 LossAtt 0.4385 TrainAcc 0.9000 TestAcc 0.8806 0.8950
epoch 900 LossPred 0.2340 LossAtt 0.4230 TrainAcc 0.9300 TestAcc 0.8701 0.9150
epoch 1000 LossPred 0.2456 LossAtt 0.3988 TrainAcc 0.9100 TestAcc 0.8651 0.9150
epoch 1100 LossPred 0.2322 LossAtt 0.4118 TrainAcc 0.9200 TestAcc 0.8614 0.9200
epoch 1200 LossPred 0.2194 LossAtt 0.4143 TrainAcc 0.9100 TestAcc 0.8646 0.9200
epoch 1300 LossPred 0.2329 LossAtt 0.4104 TrainAcc 0.9100 TestAcc 0.8636 0.9150
epoch 1400 LossPred 0.4222 LossAtt 0.4179 TrainAcc 0.8300 TestAcc 0.8398 0.8400
epoch 1500 LossPred 0.2449 LossAtt 0.3805 TrainAcc 0.9300 TestAcc 0.8524 0.9300
epoch 1600 LossPred 0.2762 LossAtt 0.3932 TrainAcc 0.9100 TestAcc 0.8478 0.9050
epoch 1700 LossPred 0.2309 LossAtt 0.4009 TrainAcc 0.9400 TestAcc 0.8571 0.9400
epoch 1800 LossPred 0.2034 LossAtt 0.3972 TrainAcc 0.9400 TestAcc 0.8674 0.9450
epoch 1900 LossPred 0.2037 LossAtt 0.4013 TrainAcc 0.9500 TestAcc 0.8679 0.9450
epoch 2000 LossPred 0.2997 LossAtt 0.3995 TrainAcc 0.8800 TestAcc 0.8701 0.8900
epoch 2100 LossPred 0.3412 LossAtt 0.3857 TrainAcc 0.8700 TestAcc 0.8636 0.8700
epoch 2200 LossPred 0.2405 LossAtt 0.3906 TrainAcc 0.9200 TestAcc 0.8566 0.9200
epoch 2300 LossPred 0.2069 LossAtt 0.3853 TrainAcc 0.9400 TestAcc 0.8649 0.9300
epoch 2400 LossPred 0.2834 LossAtt 0.3892 TrainAcc 0.9000 TestAcc 0.8456 0.9150
epoch 2500 LossPred 0.1864 LossAtt 0.3880 TrainAcc 0.9500 TestAcc 0.8669 0.9650
Optimization Finished!
********** replication  24  **********
epoch   0 LossPred 1.2828 LossAtt 1.0182 TrainAcc 0.5000 TestAcc 0.4807 0.4800
epoch 100 LossPred 0.9890 LossAtt 0.3777 TrainAcc 0.5100 TestAcc 0.4920 0.5100
epoch 200 LossPred 0.8576 LossAtt 0.3573 TrainAcc 0.7200 TestAcc 0.6922 0.7400
epoch 300 LossPred 0.7281 LossAtt 0.4180 TrainAcc 0.7600 TestAcc 0.7668 0.7650
epoch 400 LossPred 0.5887 LossAtt 0.4016 TrainAcc 0.8400 TestAcc 0.8408 0.8300
epoch 500 LossPred 0.5603 LossAtt 0.3706 TrainAcc 0.8300 TestAcc 0.8363 0.8200
epoch 600 LossPred 0.7208 LossAtt 0.3977 TrainAcc 0.7800 TestAcc 0.7380 0.7450
epoch 700 LossPred 0.5044 LossAtt 0.3474 TrainAcc 0.8400 TestAcc 0.8348 0.8200
epoch 800 LossPred 0.5227 LossAtt 0.3340 TrainAcc 0.8200 TestAcc 0.8176 0.8100
epoch 900 LossPred 0.5612 LossAtt 0.3506 TrainAcc 0.8100 TestAcc 0.8346 0.7950
epoch 1000 LossPred 0.4919 LossAtt 0.3321 TrainAcc 0.8500 TestAcc 0.8331 0.8150
epoch 1100 LossPred 0.4844 LossAtt 0.3278 TrainAcc 0.8400 TestAcc 0.8331 0.8250
epoch 1200 LossPred 0.5121 LossAtt 0.3036 TrainAcc 0.8100 TestAcc 0.8181 0.8250
epoch 1300 LossPred 0.5173 LossAtt 0.3049 TrainAcc 0.8200 TestAcc 0.8268 0.8150
epoch 1400 LossPred 0.5145 LossAtt 0.2900 TrainAcc 0.8200 TestAcc 0.8213 0.8250
epoch 1500 LossPred 0.5078 LossAtt 0.2864 TrainAcc 0.8200 TestAcc 0.8353 0.8300
epoch 1600 LossPred 0.5405 LossAtt 0.2920 TrainAcc 0.8300 TestAcc 0.8238 0.8100
epoch 1700 LossPred 0.4934 LossAtt 0.2489 TrainAcc 0.8200 TestAcc 0.8178 0.8400
epoch 1800 LossPred 0.4989 LossAtt 0.2580 TrainAcc 0.8300 TestAcc 0.8181 0.8350
epoch 1900 LossPred 0.4980 LossAtt 0.2588 TrainAcc 0.8100 TestAcc 0.8361 0.8200
epoch 2000 LossPred 0.5054 LossAtt 0.2244 TrainAcc 0.8200 TestAcc 0.8358 0.8300
epoch 2100 LossPred 0.5077 LossAtt 0.2462 TrainAcc 0.8200 TestAcc 0.8251 0.8350
epoch 2200 LossPred 0.5109 LossAtt 0.2483 TrainAcc 0.8200 TestAcc 0.8298 0.8250
epoch 2300 LossPred 0.5156 LossAtt 0.2137 TrainAcc 0.8000 TestAcc 0.7988 0.8000
epoch 2400 LossPred 0.5691 LossAtt 0.2392 TrainAcc 0.8100 TestAcc 0.8183 0.8150
epoch 2500 LossPred 0.4693 LossAtt 0.2563 TrainAcc 0.8400 TestAcc 0.8306 0.8450
Optimization Finished!
********** replication  25  **********
epoch   0 LossPred 1.1269 LossAtt 1.0232 TrainAcc 0.4900 TestAcc 0.4317 0.4850
epoch 100 LossPred 0.9165 LossAtt 0.5007 TrainAcc 0.6500 TestAcc 0.5378 0.6600
epoch 200 LossPred 0.8211 LossAtt 0.5641 TrainAcc 0.6800 TestAcc 0.5596 0.6750
epoch 300 LossPred 0.4026 LossAtt 0.5807 TrainAcc 0.9000 TestAcc 0.8604 0.8950
epoch 400 LossPred 0.2358 LossAtt 0.5477 TrainAcc 0.9300 TestAcc 0.8766 0.9300
epoch 500 LossPred 0.1927 LossAtt 0.5330 TrainAcc 0.9300 TestAcc 0.8899 0.9450
epoch 600 LossPred 0.1517 LossAtt 0.5277 TrainAcc 0.9600 TestAcc 0.9029 0.9700
epoch 700 LossPred 0.1716 LossAtt 0.5072 TrainAcc 0.9500 TestAcc 0.9032 0.9400
epoch 800 LossPred 0.1457 LossAtt 0.4986 TrainAcc 0.9600 TestAcc 0.9107 0.9650
epoch 900 LossPred 0.1589 LossAtt 0.4831 TrainAcc 0.9500 TestAcc 0.9002 0.9550
epoch 1000 LossPred 0.1455 LossAtt 0.5221 TrainAcc 0.9500 TestAcc 0.8934 0.9600
epoch 1100 LossPred 0.1394 LossAtt 0.5096 TrainAcc 0.9700 TestAcc 0.8989 0.9600
epoch 1200 LossPred 0.1680 LossAtt 0.4953 TrainAcc 0.9400 TestAcc 0.9002 0.9300
epoch 1300 LossPred 0.1324 LossAtt 0.4916 TrainAcc 0.9700 TestAcc 0.8981 0.9600
epoch 1400 LossPred 0.1245 LossAtt 0.5160 TrainAcc 0.9600 TestAcc 0.8949 0.9500
epoch 1500 LossPred 0.1290 LossAtt 0.4985 TrainAcc 0.9500 TestAcc 0.8989 0.9450
epoch 1600 LossPred 0.1110 LossAtt 0.4919 TrainAcc 0.9600 TestAcc 0.8946 0.9550
epoch 1700 LossPred 0.0964 LossAtt 0.4815 TrainAcc 0.9600 TestAcc 0.8981 0.9600
epoch 1800 LossPred 0.1120 LossAtt 0.4859 TrainAcc 0.9600 TestAcc 0.9059 0.9600
epoch 1900 LossPred 0.0651 LossAtt 0.4693 TrainAcc 0.9800 TestAcc 0.8891 0.9800
epoch 2000 LossPred 0.0546 LossAtt 0.4429 TrainAcc 0.9900 TestAcc 0.8941 0.9850
epoch 2100 LossPred 0.0492 LossAtt 0.4284 TrainAcc 0.9900 TestAcc 0.9022 0.9850
epoch 2200 LossPred 0.0501 LossAtt 0.4590 TrainAcc 0.9800 TestAcc 0.9164 0.9850
epoch 2300 LossPred 0.0419 LossAtt 0.4406 TrainAcc 1.0000 TestAcc 0.9027 0.9950
Optimization Finished!
********** replication  26  **********
epoch   0 LossPred 1.0828 LossAtt 0.9869 TrainAcc 0.4600 TestAcc 0.4560 0.4550
epoch 100 LossPred 0.9684 LossAtt 0.3465 TrainAcc 0.5900 TestAcc 0.6154 0.5900
epoch 200 LossPred 0.9600 LossAtt 0.2922 TrainAcc 0.5900 TestAcc 0.6154 0.6000
epoch 300 LossPred 0.9549 LossAtt 0.2253 TrainAcc 0.5900 TestAcc 0.6154 0.5900
epoch 400 LossPred 0.7800 LossAtt 0.3161 TrainAcc 0.7600 TestAcc 0.7535 0.7350
epoch 500 LossPred 0.3523 LossAtt 0.3848 TrainAcc 0.9000 TestAcc 0.8761 0.8800
epoch 600 LossPred 0.3711 LossAtt 0.3711 TrainAcc 0.8600 TestAcc 0.8686 0.8800
epoch 700 LossPred 0.3319 LossAtt 0.3610 TrainAcc 0.9100 TestAcc 0.9014 0.9100
epoch 800 LossPred 0.3100 LossAtt 0.3616 TrainAcc 0.8700 TestAcc 0.8789 0.8950
epoch 900 LossPred 0.2451 LossAtt 0.3504 TrainAcc 0.9200 TestAcc 0.9092 0.9300
epoch 1000 LossPred 0.2255 LossAtt 0.3361 TrainAcc 0.9300 TestAcc 0.9229 0.9350
epoch 1100 LossPred 0.2192 LossAtt 0.3661 TrainAcc 0.9300 TestAcc 0.9257 0.9300
epoch 1200 LossPred 0.2990 LossAtt 0.3363 TrainAcc 0.9000 TestAcc 0.9174 0.9100
epoch 1300 LossPred 0.2102 LossAtt 0.3382 TrainAcc 0.9300 TestAcc 0.9297 0.9350
epoch 1400 LossPred 0.2227 LossAtt 0.3411 TrainAcc 0.9100 TestAcc 0.9067 0.9100
epoch 1500 LossPred 0.2680 LossAtt 0.3285 TrainAcc 0.8900 TestAcc 0.9329 0.9150
epoch 1600 LossPred 0.1801 LossAtt 0.3321 TrainAcc 0.9500 TestAcc 0.9459 0.9300
epoch 1700 LossPred 0.1744 LossAtt 0.3238 TrainAcc 0.9500 TestAcc 0.9517 0.9350
epoch 1800 LossPred 0.2205 LossAtt 0.3281 TrainAcc 0.9400 TestAcc 0.9342 0.9000
epoch 1900 LossPred 0.1685 LossAtt 0.3193 TrainAcc 0.9500 TestAcc 0.9267 0.9200
epoch 2000 LossPred 0.1991 LossAtt 0.3210 TrainAcc 0.9400 TestAcc 0.9449 0.9200
epoch 2100 LossPred 0.1337 LossAtt 0.3175 TrainAcc 0.9700 TestAcc 0.9572 0.9500
epoch 2200 LossPred 0.1536 LossAtt 0.3315 TrainAcc 0.9600 TestAcc 0.9287 0.9250
epoch 2300 LossPred 0.2890 LossAtt 0.3389 TrainAcc 0.8900 TestAcc 0.8596 0.8800
epoch 2400 LossPred 0.1171 LossAtt 0.3237 TrainAcc 0.9600 TestAcc 0.9610 0.9350
epoch 2500 LossPred 0.1092 LossAtt 0.3181 TrainAcc 0.9700 TestAcc 0.9572 0.9500
Optimization Finished!
********** replication  27  **********
epoch   0 LossPred 0.9209 LossAtt 1.0346 TrainAcc 0.6900 TestAcc 0.6096 0.6200
epoch 100 LossPred 0.8458 LossAtt 0.4450 TrainAcc 0.6900 TestAcc 0.6096 0.6900
epoch 200 LossPred 0.8053 LossAtt 0.3912 TrainAcc 0.6900 TestAcc 0.6096 0.6900
epoch 300 LossPred 0.7134 LossAtt 0.4301 TrainAcc 0.7900 TestAcc 0.6692 0.7850
epoch 400 LossPred 0.3068 LossAtt 0.5671 TrainAcc 0.9200 TestAcc 0.9184 0.8950
epoch 500 LossPred 0.1553 LossAtt 0.5170 TrainAcc 0.9900 TestAcc 0.9374 0.9500
epoch 600 LossPred 0.1479 LossAtt 0.5099 TrainAcc 0.9700 TestAcc 0.9257 0.9250
epoch 700 LossPred 0.0895 LossAtt 0.5194 TrainAcc 1.0000 TestAcc 0.9399 0.9650
Optimization Finished!
********** replication  28  **********
epoch   0 LossPred 1.4151 LossAtt 1.0015 TrainAcc 0.4800 TestAcc 0.4642 0.4750
epoch 100 LossPred 1.0568 LossAtt 0.4593 TrainAcc 0.5200 TestAcc 0.5018 0.5200
epoch 200 LossPred 0.9651 LossAtt 0.3270 TrainAcc 0.6000 TestAcc 0.6189 0.6000
epoch 300 LossPred 0.9341 LossAtt 0.3048 TrainAcc 0.5700 TestAcc 0.5791 0.6150
epoch 400 LossPred 0.9096 LossAtt 0.2447 TrainAcc 0.6100 TestAcc 0.6084 0.6150
epoch 500 LossPred 0.7462 LossAtt 0.4647 TrainAcc 0.7600 TestAcc 0.7120 0.7650
epoch 600 LossPred 0.3348 LossAtt 0.4621 TrainAcc 0.9200 TestAcc 0.8961 0.8800
epoch 700 LossPred 0.2684 LossAtt 0.4352 TrainAcc 0.9400 TestAcc 0.9087 0.8950
epoch 800 LossPred 0.2463 LossAtt 0.4297 TrainAcc 0.9400 TestAcc 0.9054 0.8850
epoch 900 LossPred 0.8036 LossAtt 0.4067 TrainAcc 0.7100 TestAcc 0.7360 0.7350
epoch 1000 LossPred 0.3783 LossAtt 0.3938 TrainAcc 0.8800 TestAcc 0.8749 0.8400
epoch 1100 LossPred 0.4300 LossAtt 0.3943 TrainAcc 0.8500 TestAcc 0.8396 0.8300
epoch 1200 LossPred 0.4743 LossAtt 0.4176 TrainAcc 0.8200 TestAcc 0.8471 0.8400
epoch 1300 LossPred 0.3257 LossAtt 0.4454 TrainAcc 0.9000 TestAcc 0.8804 0.8550
epoch 1400 LossPred 0.4335 LossAtt 0.4087 TrainAcc 0.8600 TestAcc 0.8656 0.8350
epoch 1500 LossPred 0.2558 LossAtt 0.4326 TrainAcc 0.9700 TestAcc 0.9094 0.9000
epoch 1600 LossPred 0.3247 LossAtt 0.4287 TrainAcc 0.8800 TestAcc 0.8774 0.8800
epoch 1700 LossPred 0.3922 LossAtt 0.4284 TrainAcc 0.8400 TestAcc 0.8871 0.8650
epoch 1800 LossPred 0.3352 LossAtt 0.4427 TrainAcc 0.8800 TestAcc 0.8744 0.8650
epoch 1900 LossPred 0.4047 LossAtt 0.4411 TrainAcc 0.8600 TestAcc 0.8498 0.8300
epoch 2000 LossPred 0.3371 LossAtt 0.4496 TrainAcc 0.8800 TestAcc 0.8901 0.8700
epoch 2100 LossPred 0.4688 LossAtt 0.4224 TrainAcc 0.8400 TestAcc 0.8251 0.8150
epoch 2200 LossPred 0.5075 LossAtt 0.4353 TrainAcc 0.8300 TestAcc 0.8038 0.8000
epoch 2300 LossPred 0.5410 LossAtt 0.4385 TrainAcc 0.8300 TestAcc 0.8026 0.7900
epoch 2400 LossPred 0.4429 LossAtt 0.4650 TrainAcc 0.8600 TestAcc 0.8411 0.8150
epoch 2500 LossPred 0.4211 LossAtt 0.4643 TrainAcc 0.8500 TestAcc 0.8473 0.8350
Optimization Finished!
********** replication  29  **********
epoch   0 LossPred 1.2082 LossAtt 1.0197 TrainAcc 0.4900 TestAcc 0.5305 0.4700
epoch 100 LossPred 0.9590 LossAtt 0.4700 TrainAcc 0.5700 TestAcc 0.6104 0.5700
epoch 200 LossPred 0.9158 LossAtt 0.4850 TrainAcc 0.6400 TestAcc 0.6009 0.6400
epoch 300 LossPred 0.4971 LossAtt 0.5057 TrainAcc 0.9100 TestAcc 0.8168 0.8700
epoch 400 LossPred 0.2983 LossAtt 0.4786 TrainAcc 0.9300 TestAcc 0.8609 0.9100
epoch 500 LossPred 0.2409 LossAtt 0.4316 TrainAcc 0.9300 TestAcc 0.8881 0.9450
epoch 600 LossPred 0.1999 LossAtt 0.3994 TrainAcc 0.9500 TestAcc 0.8814 0.9450
epoch 700 LossPred 0.1745 LossAtt 0.4072 TrainAcc 0.9600 TestAcc 0.8684 0.9650
epoch 800 LossPred 0.1484 LossAtt 0.4123 TrainAcc 0.9700 TestAcc 0.8711 0.9550
epoch 900 LossPred 0.1390 LossAtt 0.4191 TrainAcc 0.9800 TestAcc 0.8666 0.9650
epoch 1000 LossPred 0.1476 LossAtt 0.4218 TrainAcc 0.9600 TestAcc 0.8579 0.9500
epoch 1100 LossPred 0.1138 LossAtt 0.4036 TrainAcc 0.9800 TestAcc 0.8616 0.9700
epoch 1200 LossPred 0.1190 LossAtt 0.4266 TrainAcc 0.9700 TestAcc 0.8641 0.9600
epoch 1300 LossPred 0.0994 LossAtt 0.4321 TrainAcc 0.9800 TestAcc 0.8759 0.9650
epoch 1400 LossPred 0.0988 LossAtt 0.4324 TrainAcc 0.9700 TestAcc 0.8719 0.9750
epoch 1500 LossPred 0.0896 LossAtt 0.4513 TrainAcc 0.9800 TestAcc 0.8774 0.9750
epoch 1600 LossPred 0.0953 LossAtt 0.4412 TrainAcc 0.9800 TestAcc 0.8826 0.9700
epoch 1700 LossPred 0.1092 LossAtt 0.4427 TrainAcc 0.9800 TestAcc 0.8861 0.9550
epoch 1800 LossPred 0.0963 LossAtt 0.4781 TrainAcc 0.9800 TestAcc 0.8836 0.9750
epoch 1900 LossPred 0.1199 LossAtt 0.4764 TrainAcc 0.9800 TestAcc 0.8511 0.9500
epoch 2000 LossPred 0.1010 LossAtt 0.4311 TrainAcc 0.9600 TestAcc 0.8824 0.9650
epoch 2100 LossPred 0.0989 LossAtt 0.4995 TrainAcc 0.9800 TestAcc 0.8741 0.9700
epoch 2200 LossPred 0.0961 LossAtt 0.4703 TrainAcc 0.9800 TestAcc 0.8861 0.9750
epoch 2300 LossPred 0.1007 LossAtt 0.4623 TrainAcc 0.9800 TestAcc 0.8814 0.9650
epoch 2400 LossPred 0.0714 LossAtt 0.4911 TrainAcc 0.9900 TestAcc 0.8849 0.9750
epoch 2500 LossPred 0.0860 LossAtt 0.5005 TrainAcc 0.9800 TestAcc 0.8829 0.9800
Optimization Finished!
********** replication  30  **********
epoch   0 LossPred 1.3265 LossAtt 1.0161 TrainAcc 0.4400 TestAcc 0.5228 0.4400
epoch 100 LossPred 0.9874 LossAtt 0.5208 TrainAcc 0.6400 TestAcc 0.6074 0.6250
epoch 200 LossPred 0.9232 LossAtt 0.4958 TrainAcc 0.6300 TestAcc 0.5883 0.6250
epoch 300 LossPred 0.8876 LossAtt 0.4688 TrainAcc 0.6700 TestAcc 0.5883 0.6650
epoch 400 LossPred 0.8699 LossAtt 0.4184 TrainAcc 0.6700 TestAcc 0.5916 0.6500
epoch 500 LossPred 0.8583 LossAtt 0.4009 TrainAcc 0.6700 TestAcc 0.6079 0.6650
epoch 600 LossPred 0.8514 LossAtt 0.3557 TrainAcc 0.6800 TestAcc 0.6154 0.6750
epoch 700 LossPred 0.8516 LossAtt 0.4100 TrainAcc 0.6800 TestAcc 0.6219 0.6750
epoch 800 LossPred 0.5238 LossAtt 0.5007 TrainAcc 0.8400 TestAcc 0.8076 0.8000
epoch 900 LossPred 0.3230 LossAtt 0.3982 TrainAcc 0.9000 TestAcc 0.8684 0.8600
epoch 1000 LossPred 0.2895 LossAtt 0.3677 TrainAcc 0.9000 TestAcc 0.8721 0.8600
epoch 1100 LossPred 0.2714 LossAtt 0.3732 TrainAcc 0.9000 TestAcc 0.8804 0.8850
epoch 1200 LossPred 0.2508 LossAtt 0.3781 TrainAcc 0.9100 TestAcc 0.8899 0.8800
epoch 1300 LossPred 0.2342 LossAtt 0.3595 TrainAcc 0.9300 TestAcc 0.8954 0.8800
epoch 1400 LossPred 0.2869 LossAtt 0.3307 TrainAcc 0.8800 TestAcc 0.8849 0.8550
epoch 1500 LossPred 0.2155 LossAtt 0.3625 TrainAcc 0.9300 TestAcc 0.9189 0.8950
epoch 1600 LossPred 0.2024 LossAtt 0.3476 TrainAcc 0.9300 TestAcc 0.9264 0.9050
epoch 1700 LossPred 0.1898 LossAtt 0.3671 TrainAcc 0.9300 TestAcc 0.9137 0.9200
epoch 1800 LossPred 0.1308 LossAtt 0.3787 TrainAcc 0.9500 TestAcc 0.9570 0.9350
epoch 1900 LossPred 0.1236 LossAtt 0.3675 TrainAcc 0.9800 TestAcc 0.9580 0.9400
epoch 2000 LossPred 0.1160 LossAtt 0.3795 TrainAcc 0.9600 TestAcc 0.9525 0.9300
epoch 2100 LossPred 0.1235 LossAtt 0.3943 TrainAcc 0.9600 TestAcc 0.9232 0.9200
epoch 2200 LossPred 0.0584 LossAtt 0.3778 TrainAcc 0.9900 TestAcc 0.9817 0.9600
epoch 2300 LossPred 0.0440 LossAtt 0.3582 TrainAcc 0.9900 TestAcc 0.9840 0.9600
epoch 2400 LossPred 0.0452 LossAtt 0.3553 TrainAcc 0.9900 TestAcc 0.9810 0.9550
epoch 2500 LossPred 0.0610 LossAtt 0.3603 TrainAcc 0.9900 TestAcc 0.9687 0.9500
Optimization Finished!
********** replication  31  **********
epoch   0 LossPred 1.0492 LossAtt 1.0087 TrainAcc 0.6200 TestAcc 0.5813 0.5850
epoch 100 LossPred 0.8769 LossAtt 0.3743 TrainAcc 0.6400 TestAcc 0.6094 0.6400
epoch 200 LossPred 0.6562 LossAtt 0.4691 TrainAcc 0.8200 TestAcc 0.7372 0.8000
epoch 300 LossPred 0.3861 LossAtt 0.5098 TrainAcc 0.9200 TestAcc 0.8343 0.8600
epoch 400 LossPred 0.2766 LossAtt 0.4863 TrainAcc 0.9400 TestAcc 0.9292 0.9000
epoch 500 LossPred 0.2248 LossAtt 0.4969 TrainAcc 0.9600 TestAcc 0.9282 0.9000
epoch 600 LossPred 0.3183 LossAtt 0.4942 TrainAcc 0.8700 TestAcc 0.8441 0.8650
epoch 700 LossPred 0.3727 LossAtt 0.4744 TrainAcc 0.8500 TestAcc 0.8646 0.8500
epoch 800 LossPred 0.2242 LossAtt 0.4761 TrainAcc 0.9500 TestAcc 0.9217 0.9150
epoch 900 LossPred 0.2085 LossAtt 0.3809 TrainAcc 0.9100 TestAcc 0.9257 0.9200
epoch 1000 LossPred 0.1958 LossAtt 0.3927 TrainAcc 0.9500 TestAcc 0.9414 0.9200
epoch 1100 LossPred 0.1874 LossAtt 0.3644 TrainAcc 0.9600 TestAcc 0.9442 0.9350
epoch 1200 LossPred 0.1985 LossAtt 0.3493 TrainAcc 0.9400 TestAcc 0.9412 0.9300
epoch 1300 LossPred 0.3028 LossAtt 0.3544 TrainAcc 0.9000 TestAcc 0.8906 0.9000
epoch 1400 LossPred 0.1789 LossAtt 0.3513 TrainAcc 0.9600 TestAcc 0.9449 0.9600
epoch 1500 LossPred 0.1810 LossAtt 0.3663 TrainAcc 0.9400 TestAcc 0.9232 0.9250
epoch 1600 LossPred 0.1717 LossAtt 0.3548 TrainAcc 0.9600 TestAcc 0.9284 0.9550
epoch 1700 LossPred 0.1697 LossAtt 0.3536 TrainAcc 0.9700 TestAcc 0.9324 0.9550
epoch 1800 LossPred 0.1963 LossAtt 0.3585 TrainAcc 0.9500 TestAcc 0.9272 0.9500
epoch 1900 LossPred 0.2454 LossAtt 0.3389 TrainAcc 0.9200 TestAcc 0.9149 0.9150
epoch 2000 LossPred 0.2679 LossAtt 0.3113 TrainAcc 0.9100 TestAcc 0.8831 0.9100
epoch 2100 LossPred 0.2112 LossAtt 0.3351 TrainAcc 0.9400 TestAcc 0.9239 0.9250
epoch 2200 LossPred 0.2343 LossAtt 0.3351 TrainAcc 0.9300 TestAcc 0.9182 0.9300
epoch 2300 LossPred 0.1910 LossAtt 0.3879 TrainAcc 0.9300 TestAcc 0.8771 0.9150
epoch 2400 LossPred 0.2964 LossAtt 0.3393 TrainAcc 0.9100 TestAcc 0.8383 0.9100
epoch 2500 LossPred 0.3498 LossAtt 0.3439 TrainAcc 0.8700 TestAcc 0.8594 0.8700
Optimization Finished!
********** replication  32  **********
epoch   0 LossPred 1.1414 LossAtt 1.0221 TrainAcc 0.5300 TestAcc 0.5400 0.5600
epoch 100 LossPred 0.9447 LossAtt 0.3851 TrainAcc 0.6300 TestAcc 0.6084 0.6350
epoch 200 LossPred 0.9013 LossAtt 0.4011 TrainAcc 0.6300 TestAcc 0.6084 0.6350
epoch 300 LossPred 0.4360 LossAtt 0.4236 TrainAcc 0.9000 TestAcc 0.8416 0.8700
epoch 400 LossPred 0.3291 LossAtt 0.3818 TrainAcc 0.9000 TestAcc 0.8473 0.8500
epoch 500 LossPred 0.2948 LossAtt 0.3662 TrainAcc 0.9100 TestAcc 0.8609 0.8650
epoch 600 LossPred 0.2783 LossAtt 0.3641 TrainAcc 0.9200 TestAcc 0.8674 0.8750
epoch 700 LossPred 0.2763 LossAtt 0.3368 TrainAcc 0.9200 TestAcc 0.8754 0.8850
epoch 800 LossPred 0.2775 LossAtt 0.2972 TrainAcc 0.9200 TestAcc 0.8684 0.8750
epoch 900 LossPred 0.2843 LossAtt 0.3112 TrainAcc 0.9200 TestAcc 0.8701 0.8700
epoch 1000 LossPred 0.2623 LossAtt 0.3105 TrainAcc 0.9100 TestAcc 0.8709 0.8950
epoch 1100 LossPred 0.2600 LossAtt 0.2961 TrainAcc 0.9200 TestAcc 0.8709 0.8750
epoch 1200 LossPred 0.2730 LossAtt 0.2926 TrainAcc 0.9000 TestAcc 0.8769 0.8700
epoch 1300 LossPred 0.2529 LossAtt 0.2818 TrainAcc 0.9200 TestAcc 0.8749 0.8950
epoch 1400 LossPred 0.2474 LossAtt 0.2810 TrainAcc 0.9200 TestAcc 0.8804 0.8800
epoch 1500 LossPred 0.2342 LossAtt 0.2770 TrainAcc 0.9400 TestAcc 0.8899 0.8850
epoch 1600 LossPred 0.2298 LossAtt 0.2586 TrainAcc 0.9300 TestAcc 0.8919 0.8800
epoch 1700 LossPred 0.2115 LossAtt 0.2492 TrainAcc 0.9600 TestAcc 0.9027 0.8900
epoch 1800 LossPred 0.2086 LossAtt 0.2347 TrainAcc 0.9200 TestAcc 0.8999 0.8950
epoch 1900 LossPred 0.2126 LossAtt 0.2321 TrainAcc 0.9200 TestAcc 0.9022 0.8800
epoch 2000 LossPred 0.2089 LossAtt 0.2251 TrainAcc 0.9300 TestAcc 0.9079 0.9000
epoch 2100 LossPred 0.1925 LossAtt 0.2344 TrainAcc 0.9500 TestAcc 0.9099 0.9050
epoch 2200 LossPred 0.2248 LossAtt 0.2246 TrainAcc 0.9100 TestAcc 0.8971 0.8800
epoch 2300 LossPred 0.1849 LossAtt 0.2103 TrainAcc 0.9600 TestAcc 0.9194 0.9000
epoch 2400 LossPred 0.2108 LossAtt 0.2230 TrainAcc 0.9400 TestAcc 0.9074 0.9000
epoch 2500 LossPred 0.1596 LossAtt 0.2160 TrainAcc 0.9600 TestAcc 0.9169 0.9150
Optimization Finished!
********** replication  33  **********
epoch   0 LossPred 0.9709 LossAtt 1.0147 TrainAcc 0.6000 TestAcc 0.5688 0.5900
epoch 100 LossPred 0.8400 LossAtt 0.4625 TrainAcc 0.7000 TestAcc 0.5926 0.7150
epoch 200 LossPred 0.7816 LossAtt 0.4574 TrainAcc 0.7000 TestAcc 0.5926 0.7050
epoch 300 LossPred 0.3600 LossAtt 0.4481 TrainAcc 0.8700 TestAcc 0.8626 0.8850
epoch 400 LossPred 0.3145 LossAtt 0.4241 TrainAcc 0.9000 TestAcc 0.8791 0.8900
epoch 500 LossPred 0.2875 LossAtt 0.4227 TrainAcc 0.8900 TestAcc 0.8909 0.8900
epoch 600 LossPred 0.2608 LossAtt 0.4357 TrainAcc 0.9200 TestAcc 0.8934 0.9250
epoch 700 LossPred 0.2147 LossAtt 0.4153 TrainAcc 0.9400 TestAcc 0.9102 0.9200
epoch 800 LossPred 0.2123 LossAtt 0.3970 TrainAcc 0.9400 TestAcc 0.9182 0.9150
epoch 900 LossPred 0.2370 LossAtt 0.3842 TrainAcc 0.9200 TestAcc 0.9457 0.8950
epoch 1000 LossPred 0.1906 LossAtt 0.3728 TrainAcc 0.9200 TestAcc 0.9259 0.9100
epoch 1100 LossPred 0.2672 LossAtt 0.3554 TrainAcc 0.9000 TestAcc 0.9364 0.8900
epoch 1200 LossPred 0.1767 LossAtt 0.3568 TrainAcc 0.9400 TestAcc 0.9587 0.9100
epoch 1300 LossPred 0.1595 LossAtt 0.3449 TrainAcc 0.9400 TestAcc 0.9572 0.9050
epoch 1400 LossPred 0.1472 LossAtt 0.3483 TrainAcc 0.9400 TestAcc 0.9252 0.9350
epoch 1500 LossPred 0.1461 LossAtt 0.3520 TrainAcc 0.9500 TestAcc 0.9655 0.9450
epoch 1600 LossPred 0.2165 LossAtt 0.3400 TrainAcc 0.9500 TestAcc 0.8814 0.9150
epoch 1700 LossPred 0.1418 LossAtt 0.3343 TrainAcc 0.9500 TestAcc 0.9635 0.9300
epoch 1800 LossPred 0.0914 LossAtt 0.3484 TrainAcc 0.9600 TestAcc 0.9757 0.9550
epoch 1900 LossPred 0.0961 LossAtt 0.3453 TrainAcc 0.9700 TestAcc 0.9647 0.9450
epoch 2000 LossPred 0.0793 LossAtt 0.3464 TrainAcc 0.9700 TestAcc 0.9795 0.9500
epoch 2100 LossPred 0.0847 LossAtt 0.3351 TrainAcc 0.9700 TestAcc 0.9772 0.9500
epoch 2200 LossPred 0.1214 LossAtt 0.3288 TrainAcc 0.9600 TestAcc 0.9507 0.9450
epoch 2300 LossPred 0.1659 LossAtt 0.3233 TrainAcc 0.9400 TestAcc 0.9612 0.9150
epoch 2400 LossPred 0.1026 LossAtt 0.3089 TrainAcc 0.9600 TestAcc 0.9625 0.9400
epoch 2500 LossPred 0.1257 LossAtt 0.3040 TrainAcc 0.9600 TestAcc 0.9672 0.9400
Optimization Finished!
********** replication  34  **********
epoch   0 LossPred 1.0628 LossAtt 1.0051 TrainAcc 0.5000 TestAcc 0.5013 0.5000
epoch 100 LossPred 0.9092 LossAtt 0.3991 TrainAcc 0.6300 TestAcc 0.6091 0.6300
epoch 200 LossPred 0.8830 LossAtt 0.3110 TrainAcc 0.6800 TestAcc 0.6344 0.6550
epoch 300 LossPred 0.8416 LossAtt 0.3317 TrainAcc 0.6900 TestAcc 0.6279 0.7000
epoch 400 LossPred 0.4023 LossAtt 0.5179 TrainAcc 0.8900 TestAcc 0.8696 0.8900
epoch 500 LossPred 0.3153 LossAtt 0.4957 TrainAcc 0.9000 TestAcc 0.8754 0.8850
epoch 600 LossPred 0.2938 LossAtt 0.5174 TrainAcc 0.9100 TestAcc 0.8904 0.9000
epoch 700 LossPred 0.2565 LossAtt 0.5318 TrainAcc 0.9000 TestAcc 0.8891 0.8950
epoch 800 LossPred 0.1584 LossAtt 0.4994 TrainAcc 0.9800 TestAcc 0.9324 0.9150
epoch 900 LossPred 0.1581 LossAtt 0.5098 TrainAcc 0.9300 TestAcc 0.9237 0.9350
epoch 1000 LossPred 0.1922 LossAtt 0.5183 TrainAcc 0.9200 TestAcc 0.8739 0.9150
epoch 1100 LossPred 0.1048 LossAtt 0.4879 TrainAcc 0.9800 TestAcc 0.9357 0.9550
epoch 1200 LossPred 0.2494 LossAtt 0.4776 TrainAcc 0.9200 TestAcc 0.8834 0.9250
epoch 1300 LossPred 0.2834 LossAtt 0.5140 TrainAcc 0.8900 TestAcc 0.8316 0.8800
epoch 1400 LossPred 0.3636 LossAtt 0.5320 TrainAcc 0.8800 TestAcc 0.8524 0.8800
epoch 1500 LossPred 0.2990 LossAtt 0.4764 TrainAcc 0.8800 TestAcc 0.8661 0.8900
epoch 1600 LossPred 0.1503 LossAtt 0.4966 TrainAcc 0.9500 TestAcc 0.8964 0.9500
epoch 1700 LossPred 0.2007 LossAtt 0.5215 TrainAcc 0.9300 TestAcc 0.8729 0.9350
epoch 1800 LossPred 0.1304 LossAtt 0.5144 TrainAcc 0.9500 TestAcc 0.9002 0.9500
epoch 1900 LossPred 0.0764 LossAtt 0.5032 TrainAcc 0.9900 TestAcc 0.9272 0.9850
epoch 2000 LossPred 0.1005 LossAtt 0.5005 TrainAcc 0.9700 TestAcc 0.9117 0.9750
epoch 2100 LossPred 0.1119 LossAtt 0.5233 TrainAcc 0.9700 TestAcc 0.9012 0.9550
epoch 2200 LossPred 0.1362 LossAtt 0.4903 TrainAcc 0.9700 TestAcc 0.8836 0.9450
epoch 2300 LossPred 0.0897 LossAtt 0.4985 TrainAcc 0.9700 TestAcc 0.9137 0.9750
epoch 2400 LossPred 0.0851 LossAtt 0.5041 TrainAcc 0.9800 TestAcc 0.9227 0.9800
epoch 2500 LossPred 0.1017 LossAtt 0.4872 TrainAcc 0.9800 TestAcc 0.9149 0.9750
Optimization Finished!
********** replication  35  **********
epoch   0 LossPred 1.3570 LossAtt 1.0297 TrainAcc 0.4800 TestAcc 0.4302 0.4650
epoch 100 LossPred 1.0937 LossAtt 0.4469 TrainAcc 0.5100 TestAcc 0.4775 0.4900
epoch 200 LossPred 1.0220 LossAtt 0.3361 TrainAcc 0.4700 TestAcc 0.4177 0.4550
epoch 300 LossPred 0.9891 LossAtt 0.2253 TrainAcc 0.5800 TestAcc 0.6114 0.5800
epoch 400 LossPred 0.9737 LossAtt 0.1885 TrainAcc 0.5800 TestAcc 0.6114 0.5800
epoch 500 LossPred 0.9591 LossAtt 0.2092 TrainAcc 0.5800 TestAcc 0.6114 0.5950
epoch 600 LossPred 0.9161 LossAtt 0.3576 TrainAcc 0.6400 TestAcc 0.6942 0.6300
epoch 700 LossPred 0.5070 LossAtt 0.3159 TrainAcc 0.8300 TestAcc 0.8561 0.8150
epoch 800 LossPred 0.3671 LossAtt 0.2815 TrainAcc 0.8900 TestAcc 0.8781 0.8700
epoch 900 LossPred 0.3409 LossAtt 0.3006 TrainAcc 0.8900 TestAcc 0.8769 0.8800
epoch 1000 LossPred 0.3396 LossAtt 0.3005 TrainAcc 0.9000 TestAcc 0.8721 0.8750
epoch 1100 LossPred 0.3239 LossAtt 0.2977 TrainAcc 0.9000 TestAcc 0.8731 0.8800
epoch 1200 LossPred 0.3093 LossAtt 0.2812 TrainAcc 0.9100 TestAcc 0.8674 0.8850
epoch 1300 LossPred 0.3274 LossAtt 0.2978 TrainAcc 0.9100 TestAcc 0.8839 0.8850
epoch 1400 LossPred 0.3642 LossAtt 0.3084 TrainAcc 0.8900 TestAcc 0.8549 0.8600
epoch 1500 LossPred 0.3222 LossAtt 0.2793 TrainAcc 0.9100 TestAcc 0.8666 0.8700
epoch 1600 LossPred 0.3261 LossAtt 0.2627 TrainAcc 0.9200 TestAcc 0.8649 0.8700
epoch 1700 LossPred 0.2889 LossAtt 0.2912 TrainAcc 0.9100 TestAcc 0.8811 0.8950
epoch 1800 LossPred 0.3918 LossAtt 0.2696 TrainAcc 0.8800 TestAcc 0.8644 0.8800
epoch 1900 LossPred 0.3052 LossAtt 0.2980 TrainAcc 0.9100 TestAcc 0.8889 0.8850
epoch 2000 LossPred 0.2854 LossAtt 0.2831 TrainAcc 0.9100 TestAcc 0.8789 0.8800
epoch 2100 LossPred 0.3078 LossAtt 0.2887 TrainAcc 0.9000 TestAcc 0.8914 0.9050
epoch 2200 LossPred 0.3353 LossAtt 0.2863 TrainAcc 0.9000 TestAcc 0.8811 0.8700
epoch 2300 LossPred 0.4810 LossAtt 0.2814 TrainAcc 0.7900 TestAcc 0.8338 0.8350
epoch 2400 LossPred 0.3049 LossAtt 0.3169 TrainAcc 0.9200 TestAcc 0.8681 0.8850
epoch 2500 LossPred 0.2805 LossAtt 0.2993 TrainAcc 0.9000 TestAcc 0.8889 0.8850
Optimization Finished!
********** replication  36  **********
epoch   0 LossPred 1.1811 LossAtt 1.0190 TrainAcc 0.5100 TestAcc 0.5553 0.5250
epoch 100 LossPred 0.9264 LossAtt 0.4205 TrainAcc 0.6100 TestAcc 0.6006 0.6050
epoch 200 LossPred 0.8725 LossAtt 0.4488 TrainAcc 0.5800 TestAcc 0.5543 0.6250
epoch 300 LossPred 0.8252 LossAtt 0.4354 TrainAcc 0.6600 TestAcc 0.5390 0.6600
epoch 400 LossPred 0.7918 LossAtt 0.4269 TrainAcc 0.6900 TestAcc 0.5483 0.6850
epoch 500 LossPred 0.7711 LossAtt 0.4482 TrainAcc 0.7100 TestAcc 0.5360 0.6900
epoch 600 LossPred 0.7584 LossAtt 0.4545 TrainAcc 0.7100 TestAcc 0.5335 0.6800
epoch 700 LossPred 0.7282 LossAtt 0.4389 TrainAcc 0.7300 TestAcc 0.5313 0.7000
epoch 800 LossPred 0.7244 LossAtt 0.4171 TrainAcc 0.7000 TestAcc 0.5293 0.6950
epoch 900 LossPred 0.7106 LossAtt 0.4167 TrainAcc 0.7200 TestAcc 0.5328 0.7100
epoch 1000 LossPred 0.7072 LossAtt 0.3769 TrainAcc 0.7200 TestAcc 0.5335 0.7100
epoch 1100 LossPred 0.7207 LossAtt 0.4227 TrainAcc 0.7300 TestAcc 0.5355 0.7250
epoch 1200 LossPred 0.7343 LossAtt 0.3939 TrainAcc 0.7300 TestAcc 0.5323 0.7100
epoch 1300 LossPred 0.7045 LossAtt 0.4026 TrainAcc 0.7300 TestAcc 0.5285 0.7200
epoch 1400 LossPred 0.7060 LossAtt 0.4148 TrainAcc 0.7300 TestAcc 0.5355 0.7250
epoch 1500 LossPred 0.7195 LossAtt 0.4423 TrainAcc 0.7300 TestAcc 0.5395 0.7000
epoch 1600 LossPred 0.7109 LossAtt 0.4530 TrainAcc 0.7300 TestAcc 0.5385 0.7050
epoch 1700 LossPred 0.7379 LossAtt 0.4424 TrainAcc 0.7100 TestAcc 0.5385 0.7050
epoch 1800 LossPred 0.7100 LossAtt 0.4884 TrainAcc 0.7300 TestAcc 0.5378 0.7100
epoch 1900 LossPred 0.7026 LossAtt 0.4665 TrainAcc 0.7300 TestAcc 0.5360 0.6950
epoch 2000 LossPred 0.7047 LossAtt 0.4366 TrainAcc 0.7400 TestAcc 0.5400 0.7050
epoch 2100 LossPred 0.7269 LossAtt 0.4331 TrainAcc 0.7200 TestAcc 0.5388 0.7100
epoch 2200 LossPred 0.6966 LossAtt 0.4299 TrainAcc 0.7400 TestAcc 0.5410 0.7100
epoch 2300 LossPred 0.6937 LossAtt 0.4525 TrainAcc 0.7300 TestAcc 0.5370 0.6950
epoch 2400 LossPred 0.6913 LossAtt 0.4389 TrainAcc 0.7300 TestAcc 0.5368 0.7100
epoch 2500 LossPred 0.6885 LossAtt 0.4755 TrainAcc 0.7400 TestAcc 0.5343 0.7300
Optimization Finished!
********** replication  37  **********
epoch   0 LossPred 1.0875 LossAtt 1.0006 TrainAcc 0.5100 TestAcc 0.4972 0.5100
epoch 100 LossPred 0.9600 LossAtt 0.3599 TrainAcc 0.6000 TestAcc 0.6106 0.6000
epoch 200 LossPred 0.9214 LossAtt 0.3845 TrainAcc 0.6300 TestAcc 0.6141 0.6150
epoch 300 LossPred 0.5021 LossAtt 0.3824 TrainAcc 0.8600 TestAcc 0.8201 0.8350
epoch 400 LossPred 0.4672 LossAtt 0.3555 TrainAcc 0.8600 TestAcc 0.8261 0.8400
epoch 500 LossPred 0.4588 LossAtt 0.3521 TrainAcc 0.8600 TestAcc 0.8246 0.8450
epoch 600 LossPred 0.4554 LossAtt 0.3345 TrainAcc 0.8600 TestAcc 0.8356 0.8550
epoch 700 LossPred 0.4043 LossAtt 0.3345 TrainAcc 0.8700 TestAcc 0.8684 0.8600
epoch 800 LossPred 0.3910 LossAtt 0.3330 TrainAcc 0.8800 TestAcc 0.8791 0.8650
epoch 900 LossPred 0.3946 LossAtt 0.3417 TrainAcc 0.8600 TestAcc 0.8931 0.8500
epoch 1000 LossPred 0.3409 LossAtt 0.3476 TrainAcc 0.8800 TestAcc 0.8991 0.8750
epoch 1100 LossPred 0.2789 LossAtt 0.3449 TrainAcc 0.9200 TestAcc 0.9179 0.8850
epoch 1200 LossPred 0.2258 LossAtt 0.3275 TrainAcc 0.9300 TestAcc 0.9209 0.9050
epoch 1300 LossPred 0.2018 LossAtt 0.3351 TrainAcc 0.9500 TestAcc 0.9452 0.9150
epoch 1400 LossPred 0.1302 LossAtt 0.3151 TrainAcc 0.9600 TestAcc 0.9369 0.9150
epoch 1500 LossPred 0.1189 LossAtt 0.2972 TrainAcc 0.9600 TestAcc 0.9469 0.9150
epoch 1600 LossPred 0.1338 LossAtt 0.3157 TrainAcc 0.9600 TestAcc 0.9522 0.9350
epoch 1700 LossPred 0.1056 LossAtt 0.3091 TrainAcc 0.9800 TestAcc 0.9439 0.9450
epoch 1800 LossPred 0.1009 LossAtt 0.3013 TrainAcc 0.9800 TestAcc 0.9334 0.9350
epoch 1900 LossPred 0.0704 LossAtt 0.3069 TrainAcc 0.9900 TestAcc 0.9510 0.9450
epoch 2000 LossPred 0.0668 LossAtt 0.3012 TrainAcc 0.9800 TestAcc 0.9587 0.9450
epoch 2100 LossPred 0.0778 LossAtt 0.2900 TrainAcc 0.9700 TestAcc 0.9372 0.9350
epoch 2200 LossPred 0.0895 LossAtt 0.2992 TrainAcc 0.9800 TestAcc 0.9600 0.9550
epoch 2300 LossPred 0.0796 LossAtt 0.2934 TrainAcc 0.9700 TestAcc 0.9374 0.9400
epoch 2400 LossPred 0.1396 LossAtt 0.2832 TrainAcc 0.9500 TestAcc 0.9102 0.9500
epoch 2500 LossPred 0.1468 LossAtt 0.2749 TrainAcc 0.9500 TestAcc 0.9089 0.9300
Optimization Finished!
********** replication  38  **********
epoch   0 LossPred 1.1321 LossAtt 1.0085 TrainAcc 0.5100 TestAcc 0.5516 0.5150
epoch 100 LossPred 0.9030 LossAtt 0.3933 TrainAcc 0.6200 TestAcc 0.6151 0.6200
epoch 200 LossPred 0.8248 LossAtt 0.4441 TrainAcc 0.7000 TestAcc 0.6196 0.6750
epoch 300 LossPred 0.5710 LossAtt 0.4639 TrainAcc 0.8100 TestAcc 0.7190 0.8150
epoch 400 LossPred 0.3141 LossAtt 0.3910 TrainAcc 0.9200 TestAcc 0.8646 0.8700
epoch 500 LossPred 0.2834 LossAtt 0.3757 TrainAcc 0.9200 TestAcc 0.8689 0.8700
epoch 600 LossPred 0.2705 LossAtt 0.3356 TrainAcc 0.9200 TestAcc 0.8701 0.8700
epoch 700 LossPred 0.2632 LossAtt 0.3254 TrainAcc 0.9200 TestAcc 0.8816 0.8900
epoch 800 LossPred 0.2808 LossAtt 0.3050 TrainAcc 0.9000 TestAcc 0.8834 0.8900
epoch 900 LossPred 0.2826 LossAtt 0.2791 TrainAcc 0.9200 TestAcc 0.8646 0.8750
epoch 1000 LossPred 0.2554 LossAtt 0.2880 TrainAcc 0.9300 TestAcc 0.8689 0.8800
epoch 1100 LossPred 0.2413 LossAtt 0.2750 TrainAcc 0.9400 TestAcc 0.8849 0.9000
epoch 1200 LossPred 0.2368 LossAtt 0.2548 TrainAcc 0.9300 TestAcc 0.8889 0.8950
epoch 1300 LossPred 0.2487 LossAtt 0.2613 TrainAcc 0.9100 TestAcc 0.9019 0.8900
epoch 1400 LossPred 0.2369 LossAtt 0.2504 TrainAcc 0.9200 TestAcc 0.9064 0.8900
epoch 1500 LossPred 0.2473 LossAtt 0.2461 TrainAcc 0.9200 TestAcc 0.9074 0.8900
epoch 1600 LossPred 0.3205 LossAtt 0.2372 TrainAcc 0.8900 TestAcc 0.8509 0.8800
epoch 1700 LossPred 0.2018 LossAtt 0.2341 TrainAcc 0.9300 TestAcc 0.9184 0.9050
epoch 1800 LossPred 0.2208 LossAtt 0.2337 TrainAcc 0.9300 TestAcc 0.9219 0.9000
epoch 1900 LossPred 0.1991 LossAtt 0.2368 TrainAcc 0.9400 TestAcc 0.9214 0.9000
epoch 2000 LossPred 0.2271 LossAtt 0.2218 TrainAcc 0.9400 TestAcc 0.8976 0.8900
epoch 2100 LossPred 0.1937 LossAtt 0.2374 TrainAcc 0.9500 TestAcc 0.9159 0.9050
epoch 2200 LossPred 0.1803 LossAtt 0.2353 TrainAcc 0.9400 TestAcc 0.9334 0.9100
epoch 2300 LossPred 0.2492 LossAtt 0.2219 TrainAcc 0.9300 TestAcc 0.9104 0.8850
epoch 2400 LossPred 0.3468 LossAtt 0.2244 TrainAcc 0.8700 TestAcc 0.8413 0.8800
epoch 2500 LossPred 0.1588 LossAtt 0.2218 TrainAcc 0.9600 TestAcc 0.9427 0.9150
Optimization Finished!
********** replication  39  **********
epoch   0 LossPred 1.2893 LossAtt 0.9972 TrainAcc 0.4300 TestAcc 0.4337 0.4200
epoch 100 LossPred 0.9194 LossAtt 0.4461 TrainAcc 0.6800 TestAcc 0.6214 0.6700
epoch 200 LossPred 0.5246 LossAtt 0.4747 TrainAcc 0.9000 TestAcc 0.8909 0.8700
epoch 300 LossPred 0.3801 LossAtt 0.3986 TrainAcc 0.9000 TestAcc 0.8644 0.9000
epoch 400 LossPred 0.3180 LossAtt 0.4127 TrainAcc 0.8900 TestAcc 0.8659 0.9050
epoch 500 LossPred 0.2840 LossAtt 0.4496 TrainAcc 0.9200 TestAcc 0.8924 0.9100
epoch 600 LossPred 0.4112 LossAtt 0.4603 TrainAcc 0.8500 TestAcc 0.8861 0.8450
epoch 700 LossPred 0.2638 LossAtt 0.4473 TrainAcc 0.9100 TestAcc 0.9257 0.9050
epoch 800 LossPred 0.2548 LossAtt 0.4276 TrainAcc 0.9100 TestAcc 0.8999 0.9000
epoch 900 LossPred 0.2213 LossAtt 0.4233 TrainAcc 0.9400 TestAcc 0.8674 0.9300
epoch 1000 LossPred 0.2127 LossAtt 0.4180 TrainAcc 0.9400 TestAcc 0.8699 0.9350
epoch 1100 LossPred 0.3006 LossAtt 0.4026 TrainAcc 0.8800 TestAcc 0.8666 0.8900
epoch 1200 LossPred 0.2541 LossAtt 0.4124 TrainAcc 0.9100 TestAcc 0.8701 0.9100
epoch 1300 LossPred 0.2050 LossAtt 0.3708 TrainAcc 0.9400 TestAcc 0.8699 0.9500
epoch 1400 LossPred 0.2471 LossAtt 0.3851 TrainAcc 0.8900 TestAcc 0.8656 0.8950
epoch 1500 LossPred 0.1965 LossAtt 0.3831 TrainAcc 0.9500 TestAcc 0.8739 0.9500
epoch 1600 LossPred 0.1953 LossAtt 0.3801 TrainAcc 0.9500 TestAcc 0.8781 0.9500
epoch 1700 LossPred 0.2582 LossAtt 0.3806 TrainAcc 0.8700 TestAcc 0.8639 0.8800
epoch 1800 LossPred 0.2188 LossAtt 0.3891 TrainAcc 0.9100 TestAcc 0.8826 0.9000
epoch 1900 LossPred 0.2180 LossAtt 0.4070 TrainAcc 0.9100 TestAcc 0.8736 0.9100
epoch 2000 LossPred 0.2428 LossAtt 0.4021 TrainAcc 0.9100 TestAcc 0.8604 0.9100
epoch 2100 LossPred 0.1893 LossAtt 0.3918 TrainAcc 0.9500 TestAcc 0.8761 0.9350
epoch 2200 LossPred 0.1779 LossAtt 0.4086 TrainAcc 0.9400 TestAcc 0.8714 0.9300
epoch 2300 LossPred 0.1797 LossAtt 0.3980 TrainAcc 0.9400 TestAcc 0.8766 0.9400
epoch 2400 LossPred 0.2574 LossAtt 0.4188 TrainAcc 0.9100 TestAcc 0.8496 0.8950
epoch 2500 LossPred 0.1733 LossAtt 0.4359 TrainAcc 0.9400 TestAcc 0.8706 0.9450
Optimization Finished!
********** replication  40  **********
epoch   0 LossPred 0.9618 LossAtt 1.0233 TrainAcc 0.6400 TestAcc 0.5943 0.6350
epoch 100 LossPred 0.7936 LossAtt 0.3932 TrainAcc 0.7100 TestAcc 0.6226 0.7050
epoch 200 LossPred 0.5055 LossAtt 0.4064 TrainAcc 0.8100 TestAcc 0.8699 0.8250
epoch 300 LossPred 0.5297 LossAtt 0.3998 TrainAcc 0.7900 TestAcc 0.8148 0.8150
epoch 400 LossPred 0.4262 LossAtt 0.3743 TrainAcc 0.8800 TestAcc 0.8554 0.8350
epoch 500 LossPred 0.4129 LossAtt 0.3922 TrainAcc 0.8600 TestAcc 0.8481 0.8400
epoch 600 LossPred 0.7282 LossAtt 0.3850 TrainAcc 0.7200 TestAcc 0.7372 0.7300
epoch 700 LossPred 0.7547 LossAtt 0.3800 TrainAcc 0.7300 TestAcc 0.7282 0.7100
epoch 800 LossPred 0.4355 LossAtt 0.3487 TrainAcc 0.8900 TestAcc 0.8316 0.8450
epoch 900 LossPred 0.3959 LossAtt 0.3491 TrainAcc 0.8800 TestAcc 0.8609 0.8800
epoch 1000 LossPred 0.4927 LossAtt 0.3378 TrainAcc 0.8100 TestAcc 0.8096 0.8000
epoch 1100 LossPred 0.5329 LossAtt 0.3522 TrainAcc 0.8100 TestAcc 0.8038 0.7900
epoch 1200 LossPred 0.3502 LossAtt 0.3501 TrainAcc 0.8800 TestAcc 0.8941 0.8450
epoch 1300 LossPred 0.5325 LossAtt 0.3462 TrainAcc 0.8200 TestAcc 0.8043 0.7900
epoch 1400 LossPred 0.3652 LossAtt 0.3602 TrainAcc 0.8900 TestAcc 0.8659 0.8850
epoch 1500 LossPred 0.3661 LossAtt 0.3282 TrainAcc 0.8800 TestAcc 0.8751 0.8600
epoch 1600 LossPred 0.4896 LossAtt 0.3406 TrainAcc 0.8000 TestAcc 0.8128 0.8050
epoch 1700 LossPred 0.5103 LossAtt 0.3281 TrainAcc 0.8100 TestAcc 0.8131 0.8100
epoch 1800 LossPred 0.2932 LossAtt 0.3432 TrainAcc 0.8800 TestAcc 0.9004 0.8750
epoch 1900 LossPred 0.3994 LossAtt 0.3516 TrainAcc 0.8700 TestAcc 0.8488 0.8750
epoch 2000 LossPred 0.5963 LossAtt 0.3560 TrainAcc 0.7800 TestAcc 0.8013 0.7650
epoch 2100 LossPred 0.2996 LossAtt 0.3641 TrainAcc 0.9100 TestAcc 0.8866 0.8950
epoch 2200 LossPred 0.5096 LossAtt 0.3958 TrainAcc 0.8100 TestAcc 0.8046 0.8050
epoch 2300 LossPred 0.5414 LossAtt 0.3787 TrainAcc 0.8100 TestAcc 0.7880 0.7800
epoch 2400 LossPred 0.4026 LossAtt 0.3769 TrainAcc 0.8700 TestAcc 0.8701 0.8550
epoch 2500 LossPred 0.2855 LossAtt 0.3786 TrainAcc 0.9100 TestAcc 0.8846 0.8800
Optimization Finished!
********** replication  41  **********
epoch   0 LossPred 1.1595 LossAtt 1.0032 TrainAcc 0.4800 TestAcc 0.4927 0.4800
epoch 100 LossPred 0.8953 LossAtt 0.4412 TrainAcc 0.6500 TestAcc 0.6071 0.6550
epoch 200 LossPred 0.8642 LossAtt 0.3721 TrainAcc 0.6500 TestAcc 0.6071 0.6650
epoch 300 LossPred 0.8397 LossAtt 0.4264 TrainAcc 0.6600 TestAcc 0.6471 0.6800
epoch 400 LossPred 0.4203 LossAtt 0.3619 TrainAcc 0.8600 TestAcc 0.8393 0.8550
epoch 500 LossPred 0.3531 LossAtt 0.3885 TrainAcc 0.8600 TestAcc 0.8401 0.8650
epoch 600 LossPred 0.3134 LossAtt 0.3752 TrainAcc 0.8800 TestAcc 0.8398 0.8650
epoch 700 LossPred 0.2843 LossAtt 0.3862 TrainAcc 0.8800 TestAcc 0.8488 0.8800
epoch 800 LossPred 0.3133 LossAtt 0.3545 TrainAcc 0.8800 TestAcc 0.8316 0.8450
epoch 900 LossPred 0.2318 LossAtt 0.3766 TrainAcc 0.9200 TestAcc 0.9044 0.9150
epoch 1000 LossPred 0.2335 LossAtt 0.3676 TrainAcc 0.9100 TestAcc 0.8869 0.8800
epoch 1100 LossPred 0.2854 LossAtt 0.3615 TrainAcc 0.8900 TestAcc 0.8841 0.8800
epoch 1200 LossPred 0.2054 LossAtt 0.3595 TrainAcc 0.9300 TestAcc 0.9277 0.9250
epoch 1300 LossPred 0.2072 LossAtt 0.3519 TrainAcc 0.9200 TestAcc 0.9139 0.9100
epoch 1400 LossPred 0.2358 LossAtt 0.3539 TrainAcc 0.9200 TestAcc 0.8926 0.9100
epoch 1500 LossPred 0.2281 LossAtt 0.3511 TrainAcc 0.9000 TestAcc 0.9119 0.9000
epoch 1600 LossPred 0.1850 LossAtt 0.3458 TrainAcc 0.9300 TestAcc 0.9379 0.9150
epoch 1700 LossPred 0.1649 LossAtt 0.3423 TrainAcc 0.9700 TestAcc 0.9384 0.9250
epoch 1800 LossPred 0.1647 LossAtt 0.3513 TrainAcc 0.9500 TestAcc 0.9317 0.9300
epoch 1900 LossPred 0.1489 LossAtt 0.3379 TrainAcc 0.9500 TestAcc 0.9417 0.9250
epoch 2000 LossPred 0.1574 LossAtt 0.3257 TrainAcc 0.9600 TestAcc 0.9217 0.9300
epoch 2100 LossPred 0.2063 LossAtt 0.3296 TrainAcc 0.9400 TestAcc 0.8946 0.9200
epoch 2200 LossPred 0.1402 LossAtt 0.3201 TrainAcc 0.9500 TestAcc 0.9262 0.9500
epoch 2300 LossPred 0.1620 LossAtt 0.3312 TrainAcc 0.9400 TestAcc 0.9232 0.9150
epoch 2400 LossPred 0.1685 LossAtt 0.3337 TrainAcc 0.9400 TestAcc 0.9237 0.9250
epoch 2500 LossPred 0.1124 LossAtt 0.3359 TrainAcc 0.9700 TestAcc 0.9532 0.9400
Optimization Finished!
********** replication  42  **********
epoch   0 LossPred 1.0291 LossAtt 0.9662 TrainAcc 0.4200 TestAcc 0.3736 0.4300
epoch 100 LossPred 0.9562 LossAtt 0.4450 TrainAcc 0.6100 TestAcc 0.5040 0.6100
epoch 200 LossPred 0.8777 LossAtt 0.4389 TrainAcc 0.6500 TestAcc 0.6214 0.6500
epoch 300 LossPred 0.3369 LossAtt 0.5130 TrainAcc 0.9200 TestAcc 0.8739 0.8850
epoch 400 LossPred 0.2258 LossAtt 0.4614 TrainAcc 0.9400 TestAcc 0.9002 0.9150
epoch 500 LossPred 0.2096 LossAtt 0.4549 TrainAcc 0.9300 TestAcc 0.9127 0.9150
epoch 600 LossPred 0.1942 LossAtt 0.4399 TrainAcc 0.9400 TestAcc 0.9152 0.9400
epoch 700 LossPred 0.2091 LossAtt 0.4389 TrainAcc 0.9000 TestAcc 0.9087 0.8900
epoch 800 LossPred 0.1608 LossAtt 0.4788 TrainAcc 0.9700 TestAcc 0.9277 0.9400
epoch 900 LossPred 0.1514 LossAtt 0.4844 TrainAcc 0.9500 TestAcc 0.9319 0.9500
epoch 1000 LossPred 0.1806 LossAtt 0.5062 TrainAcc 0.9600 TestAcc 0.9319 0.9350
epoch 1100 LossPred 0.1866 LossAtt 0.4445 TrainAcc 0.9300 TestAcc 0.9117 0.9200
epoch 1200 LossPred 0.1848 LossAtt 0.5067 TrainAcc 0.9500 TestAcc 0.9214 0.9250
epoch 1300 LossPred 0.1555 LossAtt 0.4857 TrainAcc 0.9500 TestAcc 0.9384 0.9350
epoch 1400 LossPred 0.1132 LossAtt 0.4695 TrainAcc 0.9600 TestAcc 0.9472 0.9450
epoch 1500 LossPred 0.1813 LossAtt 0.4941 TrainAcc 0.9300 TestAcc 0.9227 0.9300
epoch 1600 LossPred 0.0868 LossAtt 0.4943 TrainAcc 0.9800 TestAcc 0.9560 0.9550
epoch 1700 LossPred 0.1221 LossAtt 0.4873 TrainAcc 0.9800 TestAcc 0.9402 0.9450
epoch 1800 LossPred 0.1489 LossAtt 0.4406 TrainAcc 0.9500 TestAcc 0.9442 0.9250
epoch 1900 LossPred 0.0915 LossAtt 0.4535 TrainAcc 0.9800 TestAcc 0.9675 0.9600
epoch 2000 LossPred 0.1457 LossAtt 0.4557 TrainAcc 0.9400 TestAcc 0.9422 0.9150
epoch 2100 LossPred 0.2881 LossAtt 0.4343 TrainAcc 0.8900 TestAcc 0.9077 0.9000
epoch 2200 LossPred 0.1526 LossAtt 0.4498 TrainAcc 0.9500 TestAcc 0.9412 0.9150
epoch 2300 LossPred 0.1772 LossAtt 0.4155 TrainAcc 0.9400 TestAcc 0.9417 0.9150
epoch 2400 LossPred 0.2112 LossAtt 0.4441 TrainAcc 0.9300 TestAcc 0.9092 0.9000
epoch 2500 LossPred 0.1238 LossAtt 0.4344 TrainAcc 0.9500 TestAcc 0.9550 0.9350
Optimization Finished!
********** replication  43  **********
epoch   0 LossPred 1.1602 LossAtt 1.0308 TrainAcc 0.3900 TestAcc 0.5536 0.4150
epoch 100 LossPred 0.8784 LossAtt 0.4860 TrainAcc 0.6700 TestAcc 0.6391 0.6300
epoch 200 LossPred 0.4923 LossAtt 0.4393 TrainAcc 0.8300 TestAcc 0.8514 0.8350
epoch 300 LossPred 0.3438 LossAtt 0.4307 TrainAcc 0.9100 TestAcc 0.8964 0.8900
epoch 400 LossPred 0.2545 LossAtt 0.4296 TrainAcc 0.9500 TestAcc 0.8901 0.9000
epoch 500 LossPred 0.2214 LossAtt 0.4299 TrainAcc 0.9600 TestAcc 0.9039 0.9100
epoch 600 LossPred 0.2331 LossAtt 0.4436 TrainAcc 0.9500 TestAcc 0.9372 0.9100
epoch 700 LossPred 0.2296 LossAtt 0.4102 TrainAcc 0.9400 TestAcc 0.8919 0.8900
epoch 800 LossPred 0.2243 LossAtt 0.3841 TrainAcc 0.9400 TestAcc 0.8931 0.9200
epoch 900 LossPred 0.2141 LossAtt 0.3398 TrainAcc 0.9400 TestAcc 0.8961 0.9350
epoch 1000 LossPred 0.2403 LossAtt 0.3208 TrainAcc 0.9400 TestAcc 0.8874 0.9250
epoch 1100 LossPred 0.3579 LossAtt 0.3319 TrainAcc 0.8600 TestAcc 0.8441 0.8850
epoch 1200 LossPred 0.3205 LossAtt 0.3376 TrainAcc 0.8800 TestAcc 0.8604 0.8950
epoch 1300 LossPred 0.2008 LossAtt 0.3068 TrainAcc 0.9500 TestAcc 0.9039 0.9400
epoch 1400 LossPred 0.2041 LossAtt 0.3103 TrainAcc 0.9500 TestAcc 0.8944 0.9400
epoch 1500 LossPred 0.2440 LossAtt 0.3035 TrainAcc 0.9300 TestAcc 0.9147 0.9150
epoch 1600 LossPred 0.2334 LossAtt 0.2896 TrainAcc 0.9400 TestAcc 0.9152 0.9300
epoch 1700 LossPred 0.2015 LossAtt 0.3035 TrainAcc 0.9400 TestAcc 0.9054 0.9450
epoch 1800 LossPred 0.2002 LossAtt 0.3099 TrainAcc 0.9500 TestAcc 0.9149 0.9450
epoch 1900 LossPred 0.1822 LossAtt 0.2957 TrainAcc 0.9600 TestAcc 0.9092 0.9450
epoch 2000 LossPred 0.1926 LossAtt 0.3165 TrainAcc 0.9500 TestAcc 0.9049 0.9350
epoch 2100 LossPred 0.1982 LossAtt 0.2963 TrainAcc 0.9500 TestAcc 0.9187 0.9400
epoch 2200 LossPred 0.1992 LossAtt 0.2929 TrainAcc 0.9400 TestAcc 0.8921 0.9350
epoch 2300 LossPred 0.2422 LossAtt 0.3001 TrainAcc 0.9200 TestAcc 0.8694 0.9100
epoch 2400 LossPred 0.1867 LossAtt 0.3087 TrainAcc 0.9400 TestAcc 0.8971 0.9350
epoch 2500 LossPred 0.2021 LossAtt 0.3173 TrainAcc 0.9400 TestAcc 0.8856 0.9300
Optimization Finished!
********** replication  44  **********
epoch   0 LossPred 1.0248 LossAtt 1.0226 TrainAcc 0.5900 TestAcc 0.5631 0.5900
epoch 100 LossPred 0.9272 LossAtt 0.4293 TrainAcc 0.6400 TestAcc 0.5523 0.6300
epoch 200 LossPred 0.9150 LossAtt 0.3766 TrainAcc 0.6400 TestAcc 0.5546 0.6450
epoch 300 LossPred 0.9095 LossAtt 0.3718 TrainAcc 0.6400 TestAcc 0.5588 0.6450
epoch 400 LossPred 0.9064 LossAtt 0.3603 TrainAcc 0.6500 TestAcc 0.5823 0.6500
epoch 500 LossPred 0.8277 LossAtt 0.3841 TrainAcc 0.7000 TestAcc 0.6794 0.7000
epoch 600 LossPred 0.3734 LossAtt 0.3612 TrainAcc 0.8800 TestAcc 0.8313 0.7650
epoch 700 LossPred 0.3329 LossAtt 0.3702 TrainAcc 0.8700 TestAcc 0.8388 0.7950
epoch 800 LossPred 0.3329 LossAtt 0.3458 TrainAcc 0.8700 TestAcc 0.8388 0.7950
epoch 900 LossPred 0.3159 LossAtt 0.3639 TrainAcc 0.8800 TestAcc 0.8426 0.8200
epoch 1000 LossPred 0.3268 LossAtt 0.3595 TrainAcc 0.8800 TestAcc 0.8421 0.7950
epoch 1100 LossPred 0.3261 LossAtt 0.3606 TrainAcc 0.8800 TestAcc 0.8408 0.7950
epoch 1200 LossPred 0.3100 LossAtt 0.3554 TrainAcc 0.8800 TestAcc 0.8428 0.8150
epoch 1300 LossPred 0.3162 LossAtt 0.3576 TrainAcc 0.8800 TestAcc 0.8371 0.8100
epoch 1400 LossPred 0.3183 LossAtt 0.3645 TrainAcc 0.8800 TestAcc 0.8441 0.8150
epoch 1500 LossPred 0.3088 LossAtt 0.3716 TrainAcc 0.8800 TestAcc 0.8416 0.8150
epoch 1600 LossPred 0.3061 LossAtt 0.3541 TrainAcc 0.8900 TestAcc 0.8426 0.8250
epoch 1700 LossPred 0.3225 LossAtt 0.3649 TrainAcc 0.8800 TestAcc 0.8463 0.8150
epoch 1800 LossPred 0.3277 LossAtt 0.3684 TrainAcc 0.8700 TestAcc 0.8423 0.8150
epoch 1900 LossPred 0.4048 LossAtt 0.3768 TrainAcc 0.8500 TestAcc 0.8426 0.8250
epoch 2000 LossPred 0.3112 LossAtt 0.3399 TrainAcc 0.8800 TestAcc 0.8486 0.8250
epoch 2100 LossPred 0.3135 LossAtt 0.3427 TrainAcc 0.8800 TestAcc 0.8468 0.8050
epoch 2200 LossPred 0.3097 LossAtt 0.3626 TrainAcc 0.8800 TestAcc 0.8473 0.8250
epoch 2300 LossPred 0.3066 LossAtt 0.3379 TrainAcc 0.8800 TestAcc 0.8466 0.8150
epoch 2400 LossPred 0.3491 LossAtt 0.3417 TrainAcc 0.8600 TestAcc 0.8383 0.8050
epoch 2500 LossPred 0.3041 LossAtt 0.3363 TrainAcc 0.8800 TestAcc 0.8458 0.8350
Optimization Finished!
********** replication  45  **********
epoch   0 LossPred 1.0821 LossAtt 0.9939 TrainAcc 0.5500 TestAcc 0.5275 0.5800
epoch 100 LossPred 0.9165 LossAtt 0.4280 TrainAcc 0.6300 TestAcc 0.6101 0.6300
epoch 200 LossPred 0.8485 LossAtt 0.4941 TrainAcc 0.6200 TestAcc 0.6464 0.6600
epoch 300 LossPred 0.3082 LossAtt 0.4974 TrainAcc 0.9500 TestAcc 0.9142 0.9250
epoch 400 LossPred 0.2633 LossAtt 0.4707 TrainAcc 0.9000 TestAcc 0.8931 0.9100
epoch 500 LossPred 0.4405 LossAtt 0.4056 TrainAcc 0.8600 TestAcc 0.8481 0.8350
epoch 600 LossPred 0.2722 LossAtt 0.3815 TrainAcc 0.9000 TestAcc 0.8881 0.9000
epoch 700 LossPred 0.2068 LossAtt 0.3928 TrainAcc 0.9500 TestAcc 0.9062 0.9500
epoch 800 LossPred 0.2169 LossAtt 0.3652 TrainAcc 0.9600 TestAcc 0.9084 0.9550
epoch 900 LossPred 0.2448 LossAtt 0.3577 TrainAcc 0.9300 TestAcc 0.9002 0.9350
epoch 1000 LossPred 0.3450 LossAtt 0.3769 TrainAcc 0.9000 TestAcc 0.8689 0.8950
epoch 1100 LossPred 0.2630 LossAtt 0.3700 TrainAcc 0.9300 TestAcc 0.8916 0.9150
epoch 1200 LossPred 0.4172 LossAtt 0.3645 TrainAcc 0.8500 TestAcc 0.8596 0.8550
epoch 1300 LossPred 0.4512 LossAtt 0.3645 TrainAcc 0.8300 TestAcc 0.8431 0.8450
epoch 1400 LossPred 0.2242 LossAtt 0.3821 TrainAcc 0.9300 TestAcc 0.8924 0.9200
epoch 1500 LossPred 0.1942 LossAtt 0.3986 TrainAcc 0.9300 TestAcc 0.8991 0.9500
epoch 1600 LossPred 0.1977 LossAtt 0.3909 TrainAcc 0.9600 TestAcc 0.9209 0.9550
epoch 1700 LossPred 0.1660 LossAtt 0.3816 TrainAcc 0.9500 TestAcc 0.9087 0.9500
epoch 1800 LossPred 0.2421 LossAtt 0.3711 TrainAcc 0.9300 TestAcc 0.8856 0.9050
epoch 1900 LossPred 0.4333 LossAtt 0.3711 TrainAcc 0.8600 TestAcc 0.8551 0.8400
epoch 2000 LossPred 0.4801 LossAtt 0.3941 TrainAcc 0.8400 TestAcc 0.8431 0.8200
epoch 2100 LossPred 0.2673 LossAtt 0.3703 TrainAcc 0.9000 TestAcc 0.8796 0.9250
epoch 2200 LossPred 0.2450 LossAtt 0.3718 TrainAcc 0.9200 TestAcc 0.8859 0.9050
epoch 2300 LossPred 0.1623 LossAtt 0.3654 TrainAcc 0.9500 TestAcc 0.9114 0.9400
epoch 2400 LossPred 0.1544 LossAtt 0.3736 TrainAcc 0.9500 TestAcc 0.9009 0.9400
epoch 2500 LossPred 0.1409 LossAtt 0.3670 TrainAcc 0.9500 TestAcc 0.9179 0.9500
Optimization Finished!
********** replication  46  **********
epoch   0 LossPred 1.1209 LossAtt 1.0353 TrainAcc 0.4100 TestAcc 0.5088 0.4050
epoch 100 LossPred 0.9164 LossAtt 0.4370 TrainAcc 0.6500 TestAcc 0.5340 0.6450
epoch 200 LossPred 0.9068 LossAtt 0.3488 TrainAcc 0.6500 TestAcc 0.5415 0.6500
epoch 300 LossPred 0.9025 LossAtt 0.2567 TrainAcc 0.6500 TestAcc 0.5415 0.6350
epoch 400 LossPred 0.9039 LossAtt 0.2455 TrainAcc 0.6500 TestAcc 0.5415 0.6350
epoch 500 LossPred 0.8992 LossAtt 0.2905 TrainAcc 0.6500 TestAcc 0.5485 0.6300
epoch 600 LossPred 0.4874 LossAtt 0.5080 TrainAcc 0.8500 TestAcc 0.8511 0.8550
epoch 700 LossPred 0.3019 LossAtt 0.4281 TrainAcc 0.9100 TestAcc 0.8869 0.8800
epoch 800 LossPred 0.2259 LossAtt 0.3760 TrainAcc 0.9400 TestAcc 0.8889 0.9100
epoch 900 LossPred 0.2044 LossAtt 0.4028 TrainAcc 0.9400 TestAcc 0.9027 0.9100
epoch 1000 LossPred 0.2058 LossAtt 0.3866 TrainAcc 0.9300 TestAcc 0.8676 0.8950
epoch 1100 LossPred 0.1693 LossAtt 0.3932 TrainAcc 0.9500 TestAcc 0.8726 0.9100
epoch 1200 LossPred 0.3433 LossAtt 0.4041 TrainAcc 0.9000 TestAcc 0.8561 0.8750
epoch 1300 LossPred 0.6012 LossAtt 0.3951 TrainAcc 0.8200 TestAcc 0.8271 0.8050
epoch 1400 LossPred 0.1985 LossAtt 0.4078 TrainAcc 0.9400 TestAcc 0.9137 0.9150
epoch 1500 LossPred 0.4586 LossAtt 0.3808 TrainAcc 0.8500 TestAcc 0.7653 0.8600
epoch 1600 LossPred 0.1755 LossAtt 0.3727 TrainAcc 0.9400 TestAcc 0.8711 0.9200
epoch 1700 LossPred 0.1279 LossAtt 0.3748 TrainAcc 0.9800 TestAcc 0.9044 0.9400
epoch 1800 LossPred 0.1295 LossAtt 0.3908 TrainAcc 0.9600 TestAcc 0.9167 0.9400
epoch 1900 LossPred 0.1135 LossAtt 0.3953 TrainAcc 0.9800 TestAcc 0.9112 0.9350
epoch 2000 LossPred 0.1041 LossAtt 0.3814 TrainAcc 0.9800 TestAcc 0.9124 0.9500
epoch 2100 LossPred 0.1548 LossAtt 0.3799 TrainAcc 0.9400 TestAcc 0.9174 0.9250
epoch 2200 LossPred 0.1005 LossAtt 0.3690 TrainAcc 0.9800 TestAcc 0.9127 0.9600
epoch 2300 LossPred 0.0997 LossAtt 0.3822 TrainAcc 0.9800 TestAcc 0.9174 0.9550
epoch 2400 LossPred 0.1223 LossAtt 0.3835 TrainAcc 0.9600 TestAcc 0.8736 0.9300
epoch 2500 LossPred 0.1216 LossAtt 0.3778 TrainAcc 0.9600 TestAcc 0.9334 0.9500
Optimization Finished!
********** replication  47  **********
epoch   0 LossPred 1.1152 LossAtt 1.0102 TrainAcc 0.4900 TestAcc 0.4487 0.4550
epoch 100 LossPred 0.9697 LossAtt 0.3222 TrainAcc 0.5800 TestAcc 0.6046 0.5800
epoch 200 LossPred 0.9497 LossAtt 0.3121 TrainAcc 0.5800 TestAcc 0.6046 0.5800
epoch 300 LossPred 0.8852 LossAtt 0.3765 TrainAcc 0.6800 TestAcc 0.6444 0.6750
epoch 400 LossPred 0.4006 LossAtt 0.4873 TrainAcc 0.8700 TestAcc 0.8388 0.8650
epoch 500 LossPred 0.3748 LossAtt 0.4349 TrainAcc 0.8500 TestAcc 0.8136 0.8550
epoch 600 LossPred 0.2788 LossAtt 0.3994 TrainAcc 0.8800 TestAcc 0.8684 0.8950
epoch 700 LossPred 0.2247 LossAtt 0.3841 TrainAcc 0.9200 TestAcc 0.8964 0.8900
epoch 800 LossPred 0.2007 LossAtt 0.3602 TrainAcc 0.9400 TestAcc 0.9107 0.9100
epoch 900 LossPred 0.2773 LossAtt 0.3752 TrainAcc 0.9000 TestAcc 0.8564 0.8950
epoch 1000 LossPred 0.3796 LossAtt 0.3752 TrainAcc 0.8700 TestAcc 0.8221 0.8450
epoch 1100 LossPred 0.2316 LossAtt 0.3617 TrainAcc 0.9200 TestAcc 0.8771 0.9100
epoch 1200 LossPred 0.1891 LossAtt 0.3707 TrainAcc 0.9400 TestAcc 0.9219 0.9050
epoch 1300 LossPred 0.2185 LossAtt 0.3635 TrainAcc 0.9300 TestAcc 0.8969 0.9050
epoch 1400 LossPred 0.1767 LossAtt 0.3278 TrainAcc 0.9200 TestAcc 0.9252 0.9050
epoch 1500 LossPred 0.1825 LossAtt 0.3272 TrainAcc 0.9300 TestAcc 0.8999 0.9000
epoch 1600 LossPred 0.1682 LossAtt 0.3035 TrainAcc 0.9300 TestAcc 0.9227 0.9000
epoch 1700 LossPred 0.1692 LossAtt 0.3135 TrainAcc 0.9600 TestAcc 0.9357 0.9200
epoch 1800 LossPred 0.1623 LossAtt 0.3152 TrainAcc 0.9400 TestAcc 0.9329 0.9150
epoch 1900 LossPred 0.1796 LossAtt 0.3109 TrainAcc 0.9500 TestAcc 0.9187 0.9150
epoch 2000 LossPred 0.1706 LossAtt 0.3144 TrainAcc 0.9200 TestAcc 0.9344 0.9150
epoch 2100 LossPred 0.1648 LossAtt 0.3020 TrainAcc 0.9500 TestAcc 0.9379 0.9050
epoch 2200 LossPred 0.1575 LossAtt 0.3016 TrainAcc 0.9200 TestAcc 0.9274 0.9050
epoch 2300 LossPred 0.3367 LossAtt 0.3077 TrainAcc 0.8900 TestAcc 0.8148 0.8950
epoch 2400 LossPred 0.1513 LossAtt 0.3179 TrainAcc 0.9500 TestAcc 0.9530 0.9250
epoch 2500 LossPred 0.2470 LossAtt 0.3330 TrainAcc 0.9000 TestAcc 0.8706 0.9050
Optimization Finished!
********** replication  48  **********
epoch   0 LossPred 1.0792 LossAtt 1.0053 TrainAcc 0.5300 TestAcc 0.5613 0.5200
epoch 100 LossPred 0.9260 LossAtt 0.4970 TrainAcc 0.5600 TestAcc 0.5756 0.5650
epoch 200 LossPred 0.8954 LossAtt 0.4242 TrainAcc 0.6200 TestAcc 0.6129 0.6050
epoch 300 LossPred 0.6124 LossAtt 0.5643 TrainAcc 0.7900 TestAcc 0.7580 0.7600
epoch 400 LossPred 0.4656 LossAtt 0.4002 TrainAcc 0.8400 TestAcc 0.8023 0.8200
epoch 500 LossPred 0.4511 LossAtt 0.4037 TrainAcc 0.8400 TestAcc 0.8026 0.8250
epoch 600 LossPred 0.4458 LossAtt 0.3887 TrainAcc 0.8300 TestAcc 0.8026 0.8350
epoch 700 LossPred 0.4422 LossAtt 0.3745 TrainAcc 0.8500 TestAcc 0.8203 0.8250
epoch 800 LossPred 0.4458 LossAtt 0.3648 TrainAcc 0.8100 TestAcc 0.8586 0.8550
epoch 900 LossPred 0.3930 LossAtt 0.3488 TrainAcc 0.8700 TestAcc 0.8661 0.8550
epoch 1000 LossPred 0.4061 LossAtt 0.3696 TrainAcc 0.9000 TestAcc 0.8601 0.8700
epoch 1100 LossPred 0.4041 LossAtt 0.3445 TrainAcc 0.8800 TestAcc 0.8604 0.8700
epoch 1200 LossPred 0.3566 LossAtt 0.3222 TrainAcc 0.8700 TestAcc 0.8646 0.8650
epoch 1300 LossPred 0.4934 LossAtt 0.3125 TrainAcc 0.8200 TestAcc 0.8388 0.8400
epoch 1400 LossPred 0.3549 LossAtt 0.3324 TrainAcc 0.9000 TestAcc 0.8776 0.8850
epoch 1500 LossPred 0.3934 LossAtt 0.3295 TrainAcc 0.8600 TestAcc 0.8676 0.8500
epoch 1600 LossPred 0.3423 LossAtt 0.3322 TrainAcc 0.9100 TestAcc 0.8896 0.8700
epoch 1700 LossPred 0.3497 LossAtt 0.3276 TrainAcc 0.8800 TestAcc 0.8736 0.8800
epoch 1800 LossPred 0.3741 LossAtt 0.3403 TrainAcc 0.8500 TestAcc 0.8779 0.8800
epoch 1900 LossPred 0.2214 LossAtt 0.3431 TrainAcc 0.9300 TestAcc 0.9309 0.9250
epoch 2000 LossPred 0.1639 LossAtt 0.3617 TrainAcc 0.9600 TestAcc 0.9505 0.9250
epoch 2100 LossPred 0.1699 LossAtt 0.3851 TrainAcc 0.9400 TestAcc 0.9294 0.9250
epoch 2200 LossPred 0.1277 LossAtt 0.3615 TrainAcc 0.9700 TestAcc 0.9582 0.9450
epoch 2300 LossPred 0.3284 LossAtt 0.3499 TrainAcc 0.8400 TestAcc 0.8516 0.8800
epoch 2400 LossPred 0.1748 LossAtt 0.3589 TrainAcc 0.9400 TestAcc 0.8994 0.9200
epoch 2500 LossPred 0.4034 LossAtt 0.3662 TrainAcc 0.8200 TestAcc 0.8153 0.8300
Optimization Finished!
********** replication  49  **********
epoch   0 LossPred 0.9827 LossAtt 1.0140 TrainAcc 0.5500 TestAcc 0.4507 0.5500
epoch 100 LossPred 0.8663 LossAtt 0.4749 TrainAcc 0.6800 TestAcc 0.5951 0.6850
epoch 200 LossPred 0.7404 LossAtt 0.5702 TrainAcc 0.7300 TestAcc 0.6577 0.7500
epoch 300 LossPred 0.2595 LossAtt 0.5954 TrainAcc 0.9300 TestAcc 0.9164 0.8800
epoch 400 LossPred 0.2555 LossAtt 0.6119 TrainAcc 0.9200 TestAcc 0.9057 0.9050
epoch 500 LossPred 0.1963 LossAtt 0.5945 TrainAcc 0.9500 TestAcc 0.9269 0.9150
epoch 600 LossPred 0.1807 LossAtt 0.5723 TrainAcc 0.9600 TestAcc 0.9329 0.9200
epoch 700 LossPred 0.1583 LossAtt 0.5857 TrainAcc 0.9600 TestAcc 0.9347 0.9150
epoch 800 LossPred 0.1538 LossAtt 0.5639 TrainAcc 0.9600 TestAcc 0.9342 0.9200
epoch 900 LossPred 0.1742 LossAtt 0.5808 TrainAcc 0.9400 TestAcc 0.9312 0.9150
epoch 1000 LossPred 0.1517 LossAtt 0.5577 TrainAcc 0.9700 TestAcc 0.9289 0.9300
epoch 1100 LossPred 0.2063 LossAtt 0.5337 TrainAcc 0.9300 TestAcc 0.9044 0.9100
epoch 1200 LossPred 0.3601 LossAtt 0.4326 TrainAcc 0.8800 TestAcc 0.8536 0.8800
epoch 1300 LossPred 0.2371 LossAtt 0.3929 TrainAcc 0.9500 TestAcc 0.8714 0.9250
epoch 1400 LossPred 0.1671 LossAtt 0.3872 TrainAcc 0.9500 TestAcc 0.9204 0.9550
epoch 1500 LossPred 0.1855 LossAtt 0.3985 TrainAcc 0.9500 TestAcc 0.9124 0.9450
epoch 1600 LossPred 0.1615 LossAtt 0.4225 TrainAcc 0.9600 TestAcc 0.8901 0.9450
epoch 1700 LossPred 0.3668 LossAtt 0.3486 TrainAcc 0.9100 TestAcc 0.8488 0.9050
epoch 1800 LossPred 0.3030 LossAtt 0.3571 TrainAcc 0.9200 TestAcc 0.8546 0.9200
epoch 1900 LossPred 0.3443 LossAtt 0.3545 TrainAcc 0.9100 TestAcc 0.8453 0.9050
epoch 2000 LossPred 0.3257 LossAtt 0.3465 TrainAcc 0.9100 TestAcc 0.8468 0.9100
epoch 2100 LossPred 0.3034 LossAtt 0.3393 TrainAcc 0.9100 TestAcc 0.8611 0.9200
epoch 2200 LossPred 0.2569 LossAtt 0.3301 TrainAcc 0.9200 TestAcc 0.8909 0.9300
epoch 2300 LossPred 0.1711 LossAtt 0.3343 TrainAcc 0.9500 TestAcc 0.9044 0.9500
epoch 2400 LossPred 0.2234 LossAtt 0.3692 TrainAcc 0.9300 TestAcc 0.8646 0.9350
epoch 2500 LossPred 0.1724 LossAtt 0.3606 TrainAcc 0.9500 TestAcc 0.9029 0.9500
Optimization Finished!
********** replication  50  **********
epoch   0 LossPred 0.9706 LossAtt 0.9987 TrainAcc 0.6300 TestAcc 0.5538 0.6300
epoch 100 LossPred 0.8836 LossAtt 0.3800 TrainAcc 0.6700 TestAcc 0.5981 0.6650
epoch 200 LossPred 0.8585 LossAtt 0.3570 TrainAcc 0.6700 TestAcc 0.5981 0.6700
epoch 300 LossPred 0.8394 LossAtt 0.4045 TrainAcc 0.6800 TestAcc 0.6046 0.6750
epoch 400 LossPred 0.8200 LossAtt 0.3633 TrainAcc 0.7000 TestAcc 0.6281 0.6700
epoch 500 LossPred 0.8178 LossAtt 0.3774 TrainAcc 0.7000 TestAcc 0.6276 0.6550
epoch 600 LossPred 0.8166 LossAtt 0.3630 TrainAcc 0.7000 TestAcc 0.6309 0.6750
epoch 700 LossPred 0.8149 LossAtt 0.3645 TrainAcc 0.7000 TestAcc 0.6331 0.6650
epoch 800 LossPred 0.8150 LossAtt 0.3742 TrainAcc 0.7000 TestAcc 0.6339 0.6650
epoch 900 LossPred 0.8166 LossAtt 0.3704 TrainAcc 0.6900 TestAcc 0.6326 0.6500
epoch 1000 LossPred 0.4746 LossAtt 0.4397 TrainAcc 0.8400 TestAcc 0.8298 0.8250
epoch 1100 LossPred 0.3175 LossAtt 0.4297 TrainAcc 0.9300 TestAcc 0.8579 0.8400
epoch 1200 LossPred 0.3273 LossAtt 0.4312 TrainAcc 0.9200 TestAcc 0.8744 0.8300
epoch 1300 LossPred 0.3014 LossAtt 0.4038 TrainAcc 0.9200 TestAcc 0.8806 0.8700
epoch 1400 LossPred 0.2903 LossAtt 0.3868 TrainAcc 0.9200 TestAcc 0.8571 0.8700
epoch 1500 LossPred 0.2923 LossAtt 0.4046 TrainAcc 0.9100 TestAcc 0.8714 0.8700
epoch 1600 LossPred 0.2777 LossAtt 0.4263 TrainAcc 0.9200 TestAcc 0.8756 0.8700
epoch 1700 LossPred 0.2707 LossAtt 0.4169 TrainAcc 0.9300 TestAcc 0.8866 0.8800
epoch 1800 LossPred 0.3468 LossAtt 0.4043 TrainAcc 0.8700 TestAcc 0.8609 0.8550
epoch 1900 LossPred 0.2670 LossAtt 0.3895 TrainAcc 0.9200 TestAcc 0.8766 0.8600
epoch 2000 LossPred 0.2448 LossAtt 0.4074 TrainAcc 0.9300 TestAcc 0.8856 0.8750
epoch 2100 LossPred 0.2676 LossAtt 0.4149 TrainAcc 0.9300 TestAcc 0.8906 0.8800
epoch 2200 LossPred 0.2765 LossAtt 0.4112 TrainAcc 0.9200 TestAcc 0.8881 0.8650
epoch 2300 LossPred 0.2306 LossAtt 0.4093 TrainAcc 0.9400 TestAcc 0.8939 0.9050
epoch 2400 LossPred 0.2296 LossAtt 0.4152 TrainAcc 0.9400 TestAcc 0.8951 0.8950
epoch 2500 LossPred 0.2206 LossAtt 0.4085 TrainAcc 0.9400 TestAcc 0.8851 0.9050
Optimization Finished!
********** replication  51  **********
epoch   0 LossPred 1.4034 LossAtt 1.0110 TrainAcc 0.3300 TestAcc 0.4437 0.2950
epoch 100 LossPred 0.9528 LossAtt 0.4959 TrainAcc 0.5900 TestAcc 0.5098 0.6000
epoch 200 LossPred 0.8547 LossAtt 0.5178 TrainAcc 0.6500 TestAcc 0.5428 0.6200
epoch 300 LossPred 0.8190 LossAtt 0.5042 TrainAcc 0.6800 TestAcc 0.5761 0.6950
epoch 400 LossPred 0.7914 LossAtt 0.4843 TrainAcc 0.7100 TestAcc 0.5836 0.7300
epoch 500 LossPred 0.7764 LossAtt 0.4587 TrainAcc 0.7300 TestAcc 0.5951 0.7300
epoch 600 LossPred 0.7656 LossAtt 0.4309 TrainAcc 0.7300 TestAcc 0.5878 0.7200
epoch 700 LossPred 0.7557 LossAtt 0.4147 TrainAcc 0.7300 TestAcc 0.6051 0.7300
epoch 800 LossPred 0.7480 LossAtt 0.3419 TrainAcc 0.7300 TestAcc 0.6051 0.7300
epoch 900 LossPred 0.7412 LossAtt 0.3281 TrainAcc 0.7300 TestAcc 0.6051 0.7300
epoch 1000 LossPred 0.7434 LossAtt 0.2891 TrainAcc 0.7300 TestAcc 0.6051 0.7300
epoch 1100 LossPred 0.7491 LossAtt 0.3122 TrainAcc 0.7300 TestAcc 0.6051 0.7300
epoch 1200 LossPred 0.7444 LossAtt 0.2863 TrainAcc 0.7300 TestAcc 0.6051 0.7300
epoch 1300 LossPred 0.7343 LossAtt 0.3173 TrainAcc 0.7300 TestAcc 0.6051 0.7300
epoch 1400 LossPred 0.7235 LossAtt 0.3403 TrainAcc 0.7300 TestAcc 0.6051 0.7300
epoch 1500 LossPred 0.7072 LossAtt 0.4165 TrainAcc 0.7400 TestAcc 0.6001 0.7350
epoch 1600 LossPred 0.6610 LossAtt 0.5384 TrainAcc 0.7700 TestAcc 0.5868 0.7350
epoch 1700 LossPred 0.6158 LossAtt 0.5300 TrainAcc 0.8100 TestAcc 0.5876 0.7550
epoch 1800 LossPred 0.6155 LossAtt 0.4880 TrainAcc 0.8100 TestAcc 0.5916 0.7600
epoch 1900 LossPred 0.6099 LossAtt 0.4893 TrainAcc 0.8200 TestAcc 0.5941 0.8000
epoch 2000 LossPred 0.5877 LossAtt 0.4811 TrainAcc 0.8100 TestAcc 0.5863 0.8000
epoch 2100 LossPred 0.6074 LossAtt 0.4829 TrainAcc 0.8200 TestAcc 0.5891 0.7950
epoch 2200 LossPred 0.6019 LossAtt 0.4871 TrainAcc 0.8100 TestAcc 0.5828 0.8000
epoch 2300 LossPred 0.6060 LossAtt 0.4882 TrainAcc 0.8000 TestAcc 0.5851 0.7850
epoch 2400 LossPred 0.5995 LossAtt 0.4466 TrainAcc 0.8100 TestAcc 0.5918 0.8050
epoch 2500 LossPred 0.5684 LossAtt 0.4858 TrainAcc 0.8200 TestAcc 0.5958 0.8100
Optimization Finished!
********** replication  52  **********
epoch   0 LossPred 0.9668 LossAtt 1.0152 TrainAcc 0.6100 TestAcc 0.5743 0.5800
epoch 100 LossPred 0.9055 LossAtt 0.4396 TrainAcc 0.6400 TestAcc 0.6111 0.6500
epoch 200 LossPred 0.8825 LossAtt 0.4164 TrainAcc 0.6400 TestAcc 0.6304 0.6600
epoch 300 LossPred 0.5964 LossAtt 0.4126 TrainAcc 0.8000 TestAcc 0.8181 0.8000
epoch 400 LossPred 0.2662 LossAtt 0.3882 TrainAcc 0.9500 TestAcc 0.8749 0.9250
epoch 500 LossPred 0.4104 LossAtt 0.3891 TrainAcc 0.8800 TestAcc 0.7980 0.8700
epoch 600 LossPred 0.1914 LossAtt 0.3860 TrainAcc 0.9500 TestAcc 0.8929 0.9350
epoch 700 LossPred 0.3091 LossAtt 0.3733 TrainAcc 0.9000 TestAcc 0.8611 0.9100
epoch 800 LossPred 0.1625 LossAtt 0.3736 TrainAcc 0.9600 TestAcc 0.8871 0.9400
epoch 900 LossPred 0.4693 LossAtt 0.3548 TrainAcc 0.8100 TestAcc 0.8428 0.8300
epoch 1000 LossPred 0.2014 LossAtt 0.3306 TrainAcc 0.9400 TestAcc 0.8809 0.9300
epoch 1100 LossPred 0.2291 LossAtt 0.3044 TrainAcc 0.9200 TestAcc 0.8621 0.9200
epoch 1200 LossPred 0.1462 LossAtt 0.2956 TrainAcc 0.9400 TestAcc 0.8859 0.9350
epoch 1300 LossPred 0.1780 LossAtt 0.2577 TrainAcc 0.9600 TestAcc 0.9199 0.9500
epoch 1400 LossPred 0.2727 LossAtt 0.2341 TrainAcc 0.9100 TestAcc 0.8886 0.9050
epoch 1500 LossPred 0.1149 LossAtt 0.2317 TrainAcc 0.9700 TestAcc 0.8961 0.9400
epoch 1600 LossPred 0.1806 LossAtt 0.2439 TrainAcc 0.9500 TestAcc 0.9099 0.9200
epoch 1700 LossPred 1.2391 LossAtt 0.1832 TrainAcc 0.6300 TestAcc 0.5568 0.6250
epoch 1800 LossPred 1.2499 LossAtt 0.2934 TrainAcc 0.6000 TestAcc 0.5260 0.6100
epoch 1900 LossPred 0.9660 LossAtt 0.2579 TrainAcc 0.6300 TestAcc 0.5893 0.6350
epoch 2000 LossPred 0.9071 LossAtt 0.2599 TrainAcc 0.6300 TestAcc 0.5893 0.6300
epoch 2100 LossPred 0.8958 LossAtt 0.2558 TrainAcc 0.6300 TestAcc 0.6131 0.6350
epoch 2200 LossPred 0.8911 LossAtt 0.2470 TrainAcc 0.6400 TestAcc 0.6111 0.6500
epoch 2300 LossPred 0.8872 LossAtt 0.2481 TrainAcc 0.6300 TestAcc 0.6131 0.6300
epoch 2400 LossPred 0.8879 LossAtt 0.2277 TrainAcc 0.6300 TestAcc 0.6131 0.6300
epoch 2500 LossPred 0.8865 LossAtt 0.2547 TrainAcc 0.6400 TestAcc 0.6076 0.6300
Optimization Finished!
********** replication  53  **********
epoch   0 LossPred 1.0135 LossAtt 1.0010 TrainAcc 0.5100 TestAcc 0.4384 0.4950
epoch 100 LossPred 0.9119 LossAtt 0.5231 TrainAcc 0.6400 TestAcc 0.6049 0.6600
epoch 200 LossPred 0.7347 LossAtt 0.5129 TrainAcc 0.7200 TestAcc 0.6959 0.7400
epoch 300 LossPred 0.2935 LossAtt 0.5177 TrainAcc 0.9100 TestAcc 0.8606 0.8950
epoch 400 LossPred 0.2829 LossAtt 0.4987 TrainAcc 0.9100 TestAcc 0.8674 0.8800
epoch 500 LossPred 0.2619 LossAtt 0.5090 TrainAcc 0.9300 TestAcc 0.8719 0.8950
epoch 600 LossPred 0.2651 LossAtt 0.5001 TrainAcc 0.9100 TestAcc 0.8891 0.8950
epoch 700 LossPred 0.2393 LossAtt 0.4895 TrainAcc 0.9300 TestAcc 0.8809 0.9000
epoch 800 LossPred 0.2431 LossAtt 0.4559 TrainAcc 0.9200 TestAcc 0.8781 0.9000
epoch 900 LossPred 0.2521 LossAtt 0.4165 TrainAcc 0.9200 TestAcc 0.8771 0.9100
epoch 1000 LossPred 0.2483 LossAtt 0.3954 TrainAcc 0.9200 TestAcc 0.8801 0.9150
epoch 1100 LossPred 0.2207 LossAtt 0.4285 TrainAcc 0.9300 TestAcc 0.8911 0.9150
epoch 1200 LossPred 0.2964 LossAtt 0.3737 TrainAcc 0.9000 TestAcc 0.8961 0.8900
epoch 1300 LossPred 0.2295 LossAtt 0.4011 TrainAcc 0.9200 TestAcc 0.8906 0.9200
epoch 1400 LossPred 0.2042 LossAtt 0.3906 TrainAcc 0.9400 TestAcc 0.9012 0.9250
epoch 1500 LossPred 0.2023 LossAtt 0.4069 TrainAcc 0.9400 TestAcc 0.8954 0.9150
epoch 1600 LossPred 0.2924 LossAtt 0.3838 TrainAcc 0.9200 TestAcc 0.8904 0.9000
epoch 1700 LossPred 0.2033 LossAtt 0.3887 TrainAcc 0.9400 TestAcc 0.8901 0.9200
epoch 1800 LossPred 0.3266 LossAtt 0.3669 TrainAcc 0.8900 TestAcc 0.8786 0.8700
epoch 1900 LossPred 0.2801 LossAtt 0.3857 TrainAcc 0.9100 TestAcc 0.8606 0.8950
epoch 2000 LossPred 0.3268 LossAtt 0.3794 TrainAcc 0.8900 TestAcc 0.8771 0.8800
epoch 2100 LossPred 0.2239 LossAtt 0.3776 TrainAcc 0.9300 TestAcc 0.8764 0.9200
epoch 2200 LossPred 0.2043 LossAtt 0.3862 TrainAcc 0.9400 TestAcc 0.8896 0.9250
epoch 2300 LossPred 0.1979 LossAtt 0.3637 TrainAcc 0.9400 TestAcc 0.9084 0.9400
epoch 2400 LossPred 0.1958 LossAtt 0.3609 TrainAcc 0.9500 TestAcc 0.9042 0.9400
epoch 2500 LossPred 0.1879 LossAtt 0.3641 TrainAcc 0.9500 TestAcc 0.9007 0.9250
Optimization Finished!
********** replication  54  **********
epoch   0 LossPred 1.0073 LossAtt 0.9939 TrainAcc 0.5300 TestAcc 0.5571 0.5350
epoch 100 LossPred 0.9402 LossAtt 0.3790 TrainAcc 0.5800 TestAcc 0.6006 0.6200
epoch 200 LossPred 0.9178 LossAtt 0.3130 TrainAcc 0.6200 TestAcc 0.5836 0.6000
epoch 300 LossPred 0.8604 LossAtt 0.4393 TrainAcc 0.6700 TestAcc 0.6046 0.6500
epoch 400 LossPred 0.3764 LossAtt 0.4029 TrainAcc 0.8700 TestAcc 0.7930 0.8600
epoch 500 LossPred 0.2595 LossAtt 0.3847 TrainAcc 0.9300 TestAcc 0.8436 0.8700
epoch 600 LossPred 0.2317 LossAtt 0.4287 TrainAcc 0.9400 TestAcc 0.8306 0.8800
epoch 700 LossPred 0.1717 LossAtt 0.4784 TrainAcc 0.9500 TestAcc 0.8271 0.9000
epoch 800 LossPred 0.1415 LossAtt 0.4585 TrainAcc 0.9600 TestAcc 0.8421 0.9050
epoch 900 LossPred 0.1516 LossAtt 0.4393 TrainAcc 0.9500 TestAcc 0.8371 0.9200
epoch 1000 LossPred 0.1405 LossAtt 0.4434 TrainAcc 0.9600 TestAcc 0.8478 0.9150
epoch 1100 LossPred 0.1245 LossAtt 0.4371 TrainAcc 0.9700 TestAcc 0.8491 0.9200
epoch 1200 LossPred 0.1403 LossAtt 0.4392 TrainAcc 0.9600 TestAcc 0.8604 0.9150
epoch 1300 LossPred 0.1449 LossAtt 0.4309 TrainAcc 0.9700 TestAcc 0.8493 0.9150
epoch 1400 LossPred 0.1322 LossAtt 0.4004 TrainAcc 0.9700 TestAcc 0.8511 0.9250
epoch 1500 LossPred 0.1534 LossAtt 0.4300 TrainAcc 0.9600 TestAcc 0.8636 0.9150
epoch 1600 LossPred 0.1627 LossAtt 0.4373 TrainAcc 0.9400 TestAcc 0.8396 0.9250
epoch 1700 LossPred 0.1366 LossAtt 0.4208 TrainAcc 0.9600 TestAcc 0.8689 0.9350
epoch 1800 LossPred 0.1219 LossAtt 0.4399 TrainAcc 0.9700 TestAcc 0.8746 0.9200
epoch 1900 LossPred 0.1482 LossAtt 0.4077 TrainAcc 0.9500 TestAcc 0.8846 0.9200
epoch 2000 LossPred 0.1071 LossAtt 0.4370 TrainAcc 0.9700 TestAcc 0.8611 0.9400
epoch 2100 LossPred 0.1141 LossAtt 0.4072 TrainAcc 0.9600 TestAcc 0.8739 0.9450
epoch 2200 LossPred 0.1052 LossAtt 0.4400 TrainAcc 0.9700 TestAcc 0.8766 0.9350
epoch 2300 LossPred 0.1390 LossAtt 0.3995 TrainAcc 0.9600 TestAcc 0.8486 0.9300
epoch 2400 LossPred 0.1270 LossAtt 0.4150 TrainAcc 0.9600 TestAcc 0.8934 0.9250
epoch 2500 LossPred 0.0880 LossAtt 0.4020 TrainAcc 0.9800 TestAcc 0.8919 0.9200
Optimization Finished!
********** replication  55  **********
epoch   0 LossPred 1.0486 LossAtt 0.9989 TrainAcc 0.4700 TestAcc 0.3959 0.4700
epoch 100 LossPred 0.9731 LossAtt 0.3388 TrainAcc 0.5800 TestAcc 0.6134 0.5800
epoch 200 LossPred 0.9542 LossAtt 0.3229 TrainAcc 0.6300 TestAcc 0.5933 0.6250
epoch 300 LossPred 0.9227 LossAtt 0.4330 TrainAcc 0.6200 TestAcc 0.5881 0.6400
epoch 400 LossPred 0.8705 LossAtt 0.4920 TrainAcc 0.6500 TestAcc 0.5478 0.6600
epoch 500 LossPred 0.8469 LossAtt 0.4601 TrainAcc 0.7000 TestAcc 0.5548 0.6950
epoch 600 LossPred 0.8233 LossAtt 0.4588 TrainAcc 0.7000 TestAcc 0.5671 0.7150
epoch 700 LossPred 0.8097 LossAtt 0.4457 TrainAcc 0.7000 TestAcc 0.5768 0.6950
epoch 800 LossPred 0.7419 LossAtt 0.4829 TrainAcc 0.7400 TestAcc 0.5591 0.7300
epoch 900 LossPred 0.6922 LossAtt 0.5340 TrainAcc 0.7500 TestAcc 0.5573 0.7450
epoch 1000 LossPred 0.6874 LossAtt 0.4863 TrainAcc 0.7600 TestAcc 0.5518 0.7600
epoch 1100 LossPred 0.6927 LossAtt 0.4821 TrainAcc 0.7500 TestAcc 0.5395 0.7500
epoch 1200 LossPred 0.7031 LossAtt 0.4357 TrainAcc 0.7300 TestAcc 0.5385 0.7200
epoch 1300 LossPred 0.6987 LossAtt 0.4197 TrainAcc 0.7600 TestAcc 0.5395 0.7250
epoch 1400 LossPred 0.6796 LossAtt 0.4010 TrainAcc 0.7600 TestAcc 0.5521 0.7350
epoch 1500 LossPred 0.6800 LossAtt 0.4124 TrainAcc 0.7600 TestAcc 0.5553 0.7200
epoch 1600 LossPred 0.6772 LossAtt 0.3954 TrainAcc 0.7500 TestAcc 0.5713 0.7250
epoch 1700 LossPred 0.6788 LossAtt 0.3995 TrainAcc 0.7600 TestAcc 0.5781 0.7400
epoch 1800 LossPred 0.6927 LossAtt 0.4249 TrainAcc 0.7500 TestAcc 0.5748 0.7250
epoch 1900 LossPred 0.6688 LossAtt 0.4634 TrainAcc 0.7600 TestAcc 0.5648 0.7450
epoch 2000 LossPred 0.6611 LossAtt 0.4510 TrainAcc 0.7700 TestAcc 0.5728 0.7600
epoch 2100 LossPred 0.6733 LossAtt 0.4939 TrainAcc 0.7600 TestAcc 0.5538 0.7650
epoch 2200 LossPred 0.6631 LossAtt 0.5166 TrainAcc 0.7600 TestAcc 0.5478 0.7650
epoch 2300 LossPred 0.6893 LossAtt 0.5933 TrainAcc 0.7500 TestAcc 0.5390 0.7100
epoch 2400 LossPred 0.7136 LossAtt 0.5687 TrainAcc 0.7500 TestAcc 0.5508 0.7350
epoch 2500 LossPred 0.6468 LossAtt 0.5339 TrainAcc 0.7800 TestAcc 0.5275 0.7350
Optimization Finished!
********** replication  56  **********
epoch   0 LossPred 1.2278 LossAtt 1.0113 TrainAcc 0.4700 TestAcc 0.4702 0.4300
epoch 100 LossPred 0.9491 LossAtt 0.2777 TrainAcc 0.6300 TestAcc 0.6104 0.6300
epoch 200 LossPred 0.9333 LossAtt 0.2270 TrainAcc 0.6300 TestAcc 0.6104 0.6250
epoch 300 LossPred 0.8841 LossAtt 0.2608 TrainAcc 0.6300 TestAcc 0.6104 0.6300
epoch 400 LossPred 0.8438 LossAtt 0.3025 TrainAcc 0.6800 TestAcc 0.6411 0.6800
epoch 500 LossPred 0.5221 LossAtt 0.3531 TrainAcc 0.8600 TestAcc 0.8596 0.8550
epoch 600 LossPred 0.3979 LossAtt 0.3273 TrainAcc 0.8800 TestAcc 0.8386 0.8950
epoch 700 LossPred 0.3689 LossAtt 0.3292 TrainAcc 0.8800 TestAcc 0.8611 0.8900
epoch 800 LossPred 0.4892 LossAtt 0.3320 TrainAcc 0.8600 TestAcc 0.8068 0.8300
epoch 900 LossPred 0.4891 LossAtt 0.3180 TrainAcc 0.8500 TestAcc 0.8566 0.8500
epoch 1000 LossPred 0.5762 LossAtt 0.3118 TrainAcc 0.8100 TestAcc 0.7195 0.8050
epoch 1100 LossPred 0.4403 LossAtt 0.3203 TrainAcc 0.8900 TestAcc 0.7825 0.8600
epoch 1200 LossPred 0.3683 LossAtt 0.3088 TrainAcc 0.8800 TestAcc 0.8776 0.8750
epoch 1300 LossPred 0.3111 LossAtt 0.3152 TrainAcc 0.9000 TestAcc 0.8591 0.8800
epoch 1400 LossPred 0.2990 LossAtt 0.3264 TrainAcc 0.8900 TestAcc 0.8614 0.8900
epoch 1500 LossPred 0.4575 LossAtt 0.2924 TrainAcc 0.8600 TestAcc 0.7750 0.8550
epoch 1600 LossPred 0.3037 LossAtt 0.3319 TrainAcc 0.9000 TestAcc 0.8564 0.8950
epoch 1700 LossPred 0.3163 LossAtt 0.3303 TrainAcc 0.8900 TestAcc 0.8534 0.9050
epoch 1800 LossPred 0.4291 LossAtt 0.3217 TrainAcc 0.8600 TestAcc 0.8781 0.8850
epoch 1900 LossPred 0.3118 LossAtt 0.3455 TrainAcc 0.9000 TestAcc 0.8566 0.9050
epoch 2000 LossPred 0.3293 LossAtt 0.3437 TrainAcc 0.9000 TestAcc 0.8899 0.9000
epoch 2100 LossPred 0.2802 LossAtt 0.3010 TrainAcc 0.9000 TestAcc 0.8539 0.9150
epoch 2200 LossPred 0.2718 LossAtt 0.3162 TrainAcc 0.9100 TestAcc 0.8749 0.9050
epoch 2300 LossPred 0.3323 LossAtt 0.3224 TrainAcc 0.9000 TestAcc 0.8268 0.8900
epoch 2400 LossPred 0.2817 LossAtt 0.3112 TrainAcc 0.9100 TestAcc 0.8871 0.8900
epoch 2500 LossPred 0.3846 LossAtt 0.3256 TrainAcc 0.8900 TestAcc 0.7975 0.8850
Optimization Finished!
********** replication  57  **********
epoch   0 LossPred 1.0046 LossAtt 1.0180 TrainAcc 0.5600 TestAcc 0.5813 0.5650
epoch 100 LossPred 0.9651 LossAtt 0.3735 TrainAcc 0.5600 TestAcc 0.6036 0.5650
epoch 200 LossPred 0.9570 LossAtt 0.3523 TrainAcc 0.5600 TestAcc 0.6036 0.5750
epoch 300 LossPred 0.3608 LossAtt 0.3922 TrainAcc 0.9000 TestAcc 0.9142 0.8900
epoch 400 LossPred 0.2310 LossAtt 0.3262 TrainAcc 0.9300 TestAcc 0.9499 0.9050
epoch 500 LossPred 0.2955 LossAtt 0.2986 TrainAcc 0.8800 TestAcc 0.8954 0.8850
epoch 600 LossPred 0.6971 LossAtt 0.2966 TrainAcc 0.7600 TestAcc 0.7798 0.7600
epoch 700 LossPred 0.7836 LossAtt 0.3190 TrainAcc 0.7400 TestAcc 0.7530 0.7350
epoch 800 LossPred 0.6736 LossAtt 0.3399 TrainAcc 0.7800 TestAcc 0.7793 0.7650
epoch 900 LossPred 0.5397 LossAtt 0.3740 TrainAcc 0.8100 TestAcc 0.8091 0.7950
epoch 1000 LossPred 0.4540 LossAtt 0.3794 TrainAcc 0.8200 TestAcc 0.8276 0.8350
epoch 1100 LossPred 0.1958 LossAtt 0.3908 TrainAcc 0.9600 TestAcc 0.9269 0.9450
epoch 1200 LossPred 0.1993 LossAtt 0.3904 TrainAcc 0.9500 TestAcc 0.9189 0.9250
epoch 1300 LossPred 0.1640 LossAtt 0.3885 TrainAcc 0.9500 TestAcc 0.9349 0.9300
epoch 1400 LossPred 0.1431 LossAtt 0.3988 TrainAcc 0.9700 TestAcc 0.9404 0.9450
epoch 1500 LossPred 0.1478 LossAtt 0.4126 TrainAcc 0.9600 TestAcc 0.9314 0.9350
epoch 1600 LossPred 0.1138 LossAtt 0.3823 TrainAcc 0.9900 TestAcc 0.9464 0.9650
epoch 1700 LossPred 0.1153 LossAtt 0.3833 TrainAcc 0.9700 TestAcc 0.9409 0.9650
epoch 1800 LossPred 0.0990 LossAtt 0.3968 TrainAcc 0.9800 TestAcc 0.9422 0.9650
epoch 1900 LossPred 0.0767 LossAtt 0.4087 TrainAcc 0.9800 TestAcc 0.9457 0.9700
epoch 2000 LossPred 0.0641 LossAtt 0.4180 TrainAcc 0.9800 TestAcc 0.9424 0.9850
epoch 2100 LossPred 0.0610 LossAtt 0.4160 TrainAcc 0.9800 TestAcc 0.9469 0.9750
epoch 2200 LossPred 0.0527 LossAtt 0.4095 TrainAcc 0.9900 TestAcc 0.9372 0.9850
epoch 2300 LossPred 0.0492 LossAtt 0.4336 TrainAcc 0.9900 TestAcc 0.9414 0.9850
epoch 2400 LossPred 0.0555 LossAtt 0.4222 TrainAcc 0.9900 TestAcc 0.9392 0.9850
epoch 2500 LossPred 0.0461 LossAtt 0.4303 TrainAcc 0.9900 TestAcc 0.9352 0.9850
Optimization Finished!
********** replication  58  **********
epoch   0 LossPred 1.1067 LossAtt 0.9924 TrainAcc 0.4800 TestAcc 0.5598 0.5250
epoch 100 LossPred 0.9606 LossAtt 0.3498 TrainAcc 0.5500 TestAcc 0.5813 0.5550
epoch 200 LossPred 0.9557 LossAtt 0.2933 TrainAcc 0.5800 TestAcc 0.4972 0.5800
epoch 300 LossPred 0.9493 LossAtt 0.2334 TrainAcc 0.5800 TestAcc 0.4972 0.5800
epoch 400 LossPred 0.9329 LossAtt 0.2640 TrainAcc 0.5800 TestAcc 0.4972 0.5800
epoch 500 LossPred 0.6373 LossAtt 0.3696 TrainAcc 0.7000 TestAcc 0.6667 0.7050
epoch 600 LossPred 0.3593 LossAtt 0.2785 TrainAcc 0.9100 TestAcc 0.8418 0.8800
epoch 700 LossPred 0.2494 LossAtt 0.2674 TrainAcc 0.9400 TestAcc 0.8851 0.9150
epoch 800 LossPred 0.3175 LossAtt 0.2582 TrainAcc 0.9000 TestAcc 0.8288 0.8900
epoch 900 LossPred 0.1954 LossAtt 0.2773 TrainAcc 0.9400 TestAcc 0.8921 0.9100
epoch 1000 LossPred 0.5319 LossAtt 0.2939 TrainAcc 0.8300 TestAcc 0.8761 0.8400
epoch 1100 LossPred 0.2398 LossAtt 0.2856 TrainAcc 0.9300 TestAcc 0.8576 0.9000
epoch 1200 LossPred 0.2392 LossAtt 0.3020 TrainAcc 0.9400 TestAcc 0.8969 0.9150
epoch 1300 LossPred 0.2532 LossAtt 0.3099 TrainAcc 0.9100 TestAcc 0.9122 0.8950
epoch 1400 LossPred 0.2928 LossAtt 0.3129 TrainAcc 0.9000 TestAcc 0.8323 0.8850
epoch 1500 LossPred 0.1299 LossAtt 0.2923 TrainAcc 0.9600 TestAcc 0.9029 0.9250
epoch 1600 LossPred 0.1428 LossAtt 0.3112 TrainAcc 0.9600 TestAcc 0.9204 0.9100
epoch 1700 LossPred 0.3273 LossAtt 0.3175 TrainAcc 0.8800 TestAcc 0.8496 0.8750
epoch 1800 LossPred 0.1480 LossAtt 0.3022 TrainAcc 0.9600 TestAcc 0.9244 0.9100
epoch 1900 LossPred 0.5547 LossAtt 0.3144 TrainAcc 0.8500 TestAcc 0.7645 0.7950
epoch 2000 LossPred 0.2254 LossAtt 0.3049 TrainAcc 0.9300 TestAcc 0.8634 0.9150
epoch 2100 LossPred 0.3238 LossAtt 0.3120 TrainAcc 0.8900 TestAcc 0.8213 0.8900
epoch 2200 LossPred 0.4461 LossAtt 0.3238 TrainAcc 0.8500 TestAcc 0.8759 0.8400
epoch 2300 LossPred 0.4649 LossAtt 0.3031 TrainAcc 0.8600 TestAcc 0.7815 0.8250
epoch 2400 LossPred 0.2329 LossAtt 0.3169 TrainAcc 0.9400 TestAcc 0.9242 0.9100
epoch 2500 LossPred 0.4386 LossAtt 0.2787 TrainAcc 0.8600 TestAcc 0.7838 0.8350
Optimization Finished!
********** replication  59  **********
epoch   0 LossPred 1.3195 LossAtt 1.0018 TrainAcc 0.4300 TestAcc 0.4464 0.4050
epoch 100 LossPred 0.9149 LossAtt 0.3729 TrainAcc 0.6900 TestAcc 0.6094 0.6900
epoch 200 LossPred 0.8193 LossAtt 0.3811 TrainAcc 0.6900 TestAcc 0.5598 0.6950
epoch 300 LossPred 0.8066 LossAtt 0.3176 TrainAcc 0.7100 TestAcc 0.5731 0.7250
epoch 400 LossPred 0.7896 LossAtt 0.3190 TrainAcc 0.7300 TestAcc 0.5711 0.7250
epoch 500 LossPred 0.7858 LossAtt 0.3195 TrainAcc 0.7200 TestAcc 0.5648 0.7250
epoch 600 LossPred 0.7803 LossAtt 0.2905 TrainAcc 0.7200 TestAcc 0.5608 0.7200
epoch 700 LossPred 0.7750 LossAtt 0.3155 TrainAcc 0.7000 TestAcc 0.5578 0.7200
epoch 800 LossPred 0.7686 LossAtt 0.3942 TrainAcc 0.7000 TestAcc 0.5638 0.7000
epoch 900 LossPred 0.7707 LossAtt 0.3942 TrainAcc 0.6900 TestAcc 0.5648 0.6950
epoch 1000 LossPred 0.7717 LossAtt 0.3957 TrainAcc 0.6900 TestAcc 0.5683 0.6950
epoch 1100 LossPred 0.7549 LossAtt 0.3858 TrainAcc 0.7000 TestAcc 0.5966 0.6950
epoch 1200 LossPred 0.4333 LossAtt 0.5673 TrainAcc 0.8600 TestAcc 0.8098 0.8750
epoch 1300 LossPred 0.2149 LossAtt 0.4762 TrainAcc 0.9400 TestAcc 0.9122 0.9450
epoch 1400 LossPred 0.1654 LossAtt 0.4188 TrainAcc 0.9500 TestAcc 0.9227 0.9650
epoch 1500 LossPred 0.1504 LossAtt 0.4166 TrainAcc 0.9500 TestAcc 0.9282 0.9550
epoch 1600 LossPred 0.2558 LossAtt 0.3886 TrainAcc 0.9200 TestAcc 0.8436 0.9100
epoch 1700 LossPred 0.1234 LossAtt 0.3703 TrainAcc 0.9600 TestAcc 0.9239 0.9700
epoch 1800 LossPred 0.1121 LossAtt 0.3505 TrainAcc 0.9700 TestAcc 0.9287 0.9700
epoch 1900 LossPred 0.1043 LossAtt 0.3467 TrainAcc 0.9600 TestAcc 0.9244 0.9650
epoch 2000 LossPred 0.1169 LossAtt 0.3176 TrainAcc 0.9700 TestAcc 0.9169 0.9650
epoch 2100 LossPred 0.1301 LossAtt 0.3070 TrainAcc 0.9500 TestAcc 0.9142 0.9700
epoch 2200 LossPred 0.1094 LossAtt 0.2960 TrainAcc 0.9700 TestAcc 0.9182 0.9600
epoch 2300 LossPred 0.0993 LossAtt 0.2849 TrainAcc 0.9700 TestAcc 0.9242 0.9650
epoch 2400 LossPred 0.1099 LossAtt 0.3008 TrainAcc 0.9800 TestAcc 0.9264 0.9800
epoch 2500 LossPred 0.1299 LossAtt 0.3081 TrainAcc 0.9600 TestAcc 0.9017 0.9650
Optimization Finished!
********** replication  60  **********
epoch   0 LossPred 0.9764 LossAtt 0.9914 TrainAcc 0.5300 TestAcc 0.5023 0.5250
epoch 100 LossPred 0.8576 LossAtt 0.4409 TrainAcc 0.6900 TestAcc 0.6111 0.6900
epoch 200 LossPred 0.7856 LossAtt 0.5034 TrainAcc 0.7100 TestAcc 0.6166 0.7000
epoch 300 LossPred 0.4059 LossAtt 0.4798 TrainAcc 0.8800 TestAcc 0.8463 0.8550
epoch 400 LossPred 0.3376 LossAtt 0.4260 TrainAcc 0.8900 TestAcc 0.8584 0.8650
epoch 500 LossPred 0.3322 LossAtt 0.4029 TrainAcc 0.8900 TestAcc 0.8641 0.8700
epoch 600 LossPred 0.3255 LossAtt 0.3868 TrainAcc 0.8800 TestAcc 0.8786 0.8650
epoch 700 LossPred 0.3114 LossAtt 0.3635 TrainAcc 0.9000 TestAcc 0.8746 0.8650
epoch 800 LossPred 0.3023 LossAtt 0.3280 TrainAcc 0.9000 TestAcc 0.8716 0.8650
epoch 900 LossPred 0.2932 LossAtt 0.3329 TrainAcc 0.9000 TestAcc 0.8726 0.8850
epoch 1000 LossPred 0.2626 LossAtt 0.3211 TrainAcc 0.9200 TestAcc 0.8996 0.9000
epoch 1100 LossPred 0.2426 LossAtt 0.3005 TrainAcc 0.9300 TestAcc 0.9017 0.9000
epoch 1200 LossPred 0.2342 LossAtt 0.2866 TrainAcc 0.9300 TestAcc 0.9079 0.9000
epoch 1300 LossPred 0.2097 LossAtt 0.2951 TrainAcc 0.9400 TestAcc 0.9229 0.9000
epoch 1400 LossPred 0.1954 LossAtt 0.2798 TrainAcc 0.9300 TestAcc 0.9349 0.9100
epoch 1500 LossPred 0.1937 LossAtt 0.2738 TrainAcc 0.9300 TestAcc 0.9314 0.9000
epoch 1600 LossPred 0.2111 LossAtt 0.2878 TrainAcc 0.9300 TestAcc 0.9132 0.8900
epoch 1700 LossPred 0.1649 LossAtt 0.2599 TrainAcc 0.9600 TestAcc 0.9472 0.9200
epoch 1800 LossPred 0.1550 LossAtt 0.2581 TrainAcc 0.9600 TestAcc 0.9630 0.9200
epoch 1900 LossPred 0.1450 LossAtt 0.2765 TrainAcc 0.9500 TestAcc 0.9660 0.9250
epoch 2000 LossPred 0.1514 LossAtt 0.2525 TrainAcc 0.9600 TestAcc 0.9520 0.9250
epoch 2100 LossPred 0.1436 LossAtt 0.2503 TrainAcc 0.9400 TestAcc 0.9499 0.9200
epoch 2200 LossPred 0.1261 LossAtt 0.2464 TrainAcc 0.9600 TestAcc 0.9482 0.9250
epoch 2300 LossPred 0.1384 LossAtt 0.2461 TrainAcc 0.9500 TestAcc 0.9620 0.9200
epoch 2400 LossPred 0.1107 LossAtt 0.2635 TrainAcc 0.9900 TestAcc 0.9860 0.9300
epoch 2500 LossPred 0.1547 LossAtt 0.2439 TrainAcc 0.9400 TestAcc 0.9394 0.9100
Optimization Finished!
********** replication  61  **********
epoch   0 LossPred 1.0551 LossAtt 1.0112 TrainAcc 0.5400 TestAcc 0.5190 0.5600
epoch 100 LossPred 0.9259 LossAtt 0.3579 TrainAcc 0.6300 TestAcc 0.6136 0.6100
epoch 200 LossPred 0.8951 LossAtt 0.3285 TrainAcc 0.6300 TestAcc 0.6136 0.6300
epoch 300 LossPred 0.8833 LossAtt 0.2475 TrainAcc 0.6600 TestAcc 0.6096 0.6500
epoch 400 LossPred 0.5161 LossAtt 0.3876 TrainAcc 0.8600 TestAcc 0.8238 0.8000
epoch 500 LossPred 0.2758 LossAtt 0.3424 TrainAcc 0.9200 TestAcc 0.8776 0.9000
epoch 600 LossPred 0.2924 LossAtt 0.3414 TrainAcc 0.9200 TestAcc 0.8691 0.8900
epoch 700 LossPred 0.2534 LossAtt 0.3288 TrainAcc 0.9200 TestAcc 0.8704 0.9000
epoch 800 LossPred 0.2455 LossAtt 0.3210 TrainAcc 0.9200 TestAcc 0.8799 0.9150
epoch 900 LossPred 0.2527 LossAtt 0.3157 TrainAcc 0.9200 TestAcc 0.8831 0.9100
epoch 1000 LossPred 0.2509 LossAtt 0.3130 TrainAcc 0.9100 TestAcc 0.8776 0.8850
epoch 1100 LossPred 0.2485 LossAtt 0.3137 TrainAcc 0.9200 TestAcc 0.8761 0.9100
epoch 1200 LossPred 0.2452 LossAtt 0.3056 TrainAcc 0.9300 TestAcc 0.8824 0.8900
epoch 1300 LossPred 0.2574 LossAtt 0.3014 TrainAcc 0.9300 TestAcc 0.8891 0.9100
epoch 1400 LossPred 0.2546 LossAtt 0.3015 TrainAcc 0.9200 TestAcc 0.8846 0.9150
epoch 1500 LossPred 0.2341 LossAtt 0.3156 TrainAcc 0.9300 TestAcc 0.8896 0.9050
epoch 1600 LossPred 0.2315 LossAtt 0.2989 TrainAcc 0.9300 TestAcc 0.8864 0.9200
epoch 1700 LossPred 0.2414 LossAtt 0.2900 TrainAcc 0.9200 TestAcc 0.8851 0.8950
epoch 1800 LossPred 0.2562 LossAtt 0.2966 TrainAcc 0.9200 TestAcc 0.8739 0.9150
epoch 1900 LossPred 0.2574 LossAtt 0.2913 TrainAcc 0.9100 TestAcc 0.8759 0.8950
epoch 2000 LossPred 0.2323 LossAtt 0.2856 TrainAcc 0.9300 TestAcc 0.8889 0.9050
epoch 2100 LossPred 0.2485 LossAtt 0.3126 TrainAcc 0.9200 TestAcc 0.8869 0.9000
epoch 2200 LossPred 0.2474 LossAtt 0.2803 TrainAcc 0.9200 TestAcc 0.8831 0.9200
epoch 2300 LossPred 0.2502 LossAtt 0.2945 TrainAcc 0.9300 TestAcc 0.8899 0.9200
epoch 2400 LossPred 0.2742 LossAtt 0.2933 TrainAcc 0.9200 TestAcc 0.8819 0.9050
epoch 2500 LossPred 0.2963 LossAtt 0.2801 TrainAcc 0.9000 TestAcc 0.8789 0.9050
Optimization Finished!
********** replication  62  **********
epoch   0 LossPred 1.1023 LossAtt 1.0388 TrainAcc 0.5200 TestAcc 0.4422 0.5500
epoch 100 LossPred 0.9293 LossAtt 0.4818 TrainAcc 0.5900 TestAcc 0.4860 0.6100
epoch 200 LossPred 0.8460 LossAtt 0.5287 TrainAcc 0.6600 TestAcc 0.5991 0.6600
epoch 300 LossPred 0.4091 LossAtt 0.6048 TrainAcc 0.8800 TestAcc 0.8796 0.8450
epoch 400 LossPred 0.2671 LossAtt 0.5349 TrainAcc 0.9200 TestAcc 0.8711 0.8750
epoch 500 LossPred 0.2383 LossAtt 0.5122 TrainAcc 0.9200 TestAcc 0.8731 0.8800
epoch 600 LossPred 0.1697 LossAtt 0.4855 TrainAcc 0.9600 TestAcc 0.8801 0.9250
epoch 700 LossPred 0.1546 LossAtt 0.4541 TrainAcc 0.9700 TestAcc 0.8946 0.9250
epoch 800 LossPred 0.1408 LossAtt 0.4548 TrainAcc 0.9600 TestAcc 0.9037 0.9350
epoch 900 LossPred 0.2635 LossAtt 0.4604 TrainAcc 0.9000 TestAcc 0.8716 0.8950
epoch 1000 LossPred 0.1850 LossAtt 0.4629 TrainAcc 0.9500 TestAcc 0.8921 0.9400
epoch 1100 LossPred 0.2725 LossAtt 0.4537 TrainAcc 0.8800 TestAcc 0.8696 0.8900
epoch 1200 LossPred 0.3161 LossAtt 0.4746 TrainAcc 0.8700 TestAcc 0.8829 0.8550
epoch 1300 LossPred 0.1222 LossAtt 0.4621 TrainAcc 0.9800 TestAcc 0.8951 0.9550
epoch 1400 LossPred 0.1479 LossAtt 0.4365 TrainAcc 0.9700 TestAcc 0.8984 0.9500
epoch 1500 LossPred 0.1243 LossAtt 0.4303 TrainAcc 0.9700 TestAcc 0.8954 0.9600
epoch 1600 LossPred 0.2004 LossAtt 0.4275 TrainAcc 0.9500 TestAcc 0.8789 0.9250
epoch 1700 LossPred 0.1324 LossAtt 0.4257 TrainAcc 0.9700 TestAcc 0.8981 0.9350
epoch 1800 LossPred 0.2795 LossAtt 0.4292 TrainAcc 0.9200 TestAcc 0.8716 0.9250
epoch 1900 LossPred 0.2974 LossAtt 0.4250 TrainAcc 0.8900 TestAcc 0.8729 0.8500
epoch 2000 LossPred 0.2230 LossAtt 0.4176 TrainAcc 0.9200 TestAcc 0.8574 0.9050
epoch 2100 LossPred 0.2825 LossAtt 0.4267 TrainAcc 0.9300 TestAcc 0.8554 0.9150
epoch 2200 LossPred 0.1356 LossAtt 0.4173 TrainAcc 0.9700 TestAcc 0.8944 0.9550
epoch 2300 LossPred 0.2215 LossAtt 0.4374 TrainAcc 0.9400 TestAcc 0.8694 0.9350
epoch 2400 LossPred 0.1271 LossAtt 0.4287 TrainAcc 0.9700 TestAcc 0.8941 0.9650
epoch 2500 LossPred 0.1274 LossAtt 0.4216 TrainAcc 0.9700 TestAcc 0.8834 0.9550
Optimization Finished!
********** replication  63  **********
epoch   0 LossPred 1.1095 LossAtt 1.0129 TrainAcc 0.4300 TestAcc 0.4600 0.4550
epoch 100 LossPred 0.9739 LossAtt 0.3772 TrainAcc 0.5700 TestAcc 0.5353 0.5750
epoch 200 LossPred 0.9666 LossAtt 0.3778 TrainAcc 0.5800 TestAcc 0.5696 0.5750
epoch 300 LossPred 0.9308 LossAtt 0.4083 TrainAcc 0.5800 TestAcc 0.6096 0.5750
epoch 400 LossPred 0.5371 LossAtt 0.4359 TrainAcc 0.8600 TestAcc 0.8271 0.8450
epoch 500 LossPred 0.1758 LossAtt 0.4064 TrainAcc 0.9700 TestAcc 0.8994 0.9250
epoch 600 LossPred 0.1439 LossAtt 0.2984 TrainAcc 0.9600 TestAcc 0.8876 0.9550
epoch 700 LossPred 0.1324 LossAtt 0.2787 TrainAcc 0.9700 TestAcc 0.9047 0.9700
epoch 800 LossPred 0.1192 LossAtt 0.2608 TrainAcc 0.9800 TestAcc 0.9009 0.9750
epoch 900 LossPred 0.1126 LossAtt 0.2715 TrainAcc 0.9800 TestAcc 0.8994 0.9700
epoch 1000 LossPred 0.1070 LossAtt 0.2758 TrainAcc 0.9700 TestAcc 0.8966 0.9700
epoch 1100 LossPred 0.0970 LossAtt 0.2763 TrainAcc 0.9800 TestAcc 0.9057 0.9750
epoch 1200 LossPred 0.0974 LossAtt 0.2646 TrainAcc 0.9800 TestAcc 0.9087 0.9700
epoch 1300 LossPred 0.0844 LossAtt 0.2722 TrainAcc 0.9900 TestAcc 0.9134 0.9700
epoch 1400 LossPred 0.0871 LossAtt 0.3056 TrainAcc 0.9800 TestAcc 0.9034 0.9800
epoch 1500 LossPred 0.1235 LossAtt 0.3051 TrainAcc 0.9700 TestAcc 0.8934 0.9600
epoch 1600 LossPred 0.0713 LossAtt 0.3111 TrainAcc 0.9900 TestAcc 0.9097 0.9800
epoch 1700 LossPred 0.0657 LossAtt 0.3060 TrainAcc 0.9900 TestAcc 0.9054 0.9850
epoch 1800 LossPred 0.0577 LossAtt 0.3099 TrainAcc 0.9900 TestAcc 0.9087 0.9850
epoch 1900 LossPred 0.1151 LossAtt 0.3093 TrainAcc 0.9600 TestAcc 0.8899 0.9500
epoch 2000 LossPred 0.0548 LossAtt 0.3069 TrainAcc 0.9900 TestAcc 0.9124 0.9900
epoch 2100 LossPred 0.0743 LossAtt 0.3058 TrainAcc 0.9900 TestAcc 0.9059 0.9800
epoch 2200 LossPred 0.0511 LossAtt 0.3119 TrainAcc 0.9900 TestAcc 0.9107 0.9850
epoch 2300 LossPred 0.0522 LossAtt 0.2868 TrainAcc 0.9900 TestAcc 0.9127 0.9900
epoch 2400 LossPred 0.0506 LossAtt 0.2876 TrainAcc 0.9900 TestAcc 0.9097 0.9850
epoch 2500 LossPred 0.0634 LossAtt 0.2971 TrainAcc 0.9900 TestAcc 0.9072 0.9800
Optimization Finished!
********** replication  64  **********
epoch   0 LossPred 1.0575 LossAtt 0.9948 TrainAcc 0.5700 TestAcc 0.4567 0.5800
epoch 100 LossPred 0.9549 LossAtt 0.4109 TrainAcc 0.5800 TestAcc 0.4710 0.5900
epoch 200 LossPred 0.9498 LossAtt 0.2921 TrainAcc 0.5900 TestAcc 0.5095 0.5900
epoch 300 LossPred 0.9507 LossAtt 0.2433 TrainAcc 0.5900 TestAcc 0.5095 0.5900
epoch 400 LossPred 0.9437 LossAtt 0.1721 TrainAcc 0.5900 TestAcc 0.5095 0.5900
epoch 500 LossPred 0.9415 LossAtt 0.1004 TrainAcc 0.5900 TestAcc 0.5095 0.5900
epoch 600 LossPred 0.9409 LossAtt 0.1058 TrainAcc 0.5900 TestAcc 0.5095 0.5900
epoch 700 LossPred 0.9406 LossAtt 0.1259 TrainAcc 0.5900 TestAcc 0.5095 0.5900
epoch 800 LossPred 0.9421 LossAtt 0.1280 TrainAcc 0.5900 TestAcc 0.5095 0.5900
epoch 900 LossPred 0.9407 LossAtt 0.0555 TrainAcc 0.5900 TestAcc 0.5095 0.5900
epoch 1000 LossPred 0.9346 LossAtt 0.2083 TrainAcc 0.5900 TestAcc 0.5095 0.5900
epoch 1100 LossPred 0.8391 LossAtt 0.4521 TrainAcc 0.6400 TestAcc 0.6164 0.6550
epoch 1200 LossPred 0.8013 LossAtt 0.4105 TrainAcc 0.7100 TestAcc 0.5898 0.6950
epoch 1300 LossPred 0.7442 LossAtt 0.3947 TrainAcc 0.7400 TestAcc 0.5896 0.7000
epoch 1400 LossPred 0.7239 LossAtt 0.4097 TrainAcc 0.6900 TestAcc 0.6086 0.7050
epoch 1500 LossPred 0.7710 LossAtt 0.4536 TrainAcc 0.7000 TestAcc 0.5941 0.7050
epoch 1600 LossPred 0.7094 LossAtt 0.4168 TrainAcc 0.7300 TestAcc 0.6434 0.7200
epoch 1700 LossPred 0.6964 LossAtt 0.3986 TrainAcc 0.7300 TestAcc 0.6389 0.7100
epoch 1800 LossPred 0.7146 LossAtt 0.3910 TrainAcc 0.7300 TestAcc 0.6466 0.7050
epoch 1900 LossPred 0.6899 LossAtt 0.3968 TrainAcc 0.7300 TestAcc 0.6211 0.7050
epoch 2000 LossPred 0.6922 LossAtt 0.3778 TrainAcc 0.7300 TestAcc 0.6399 0.7050
epoch 2100 LossPred 0.6824 LossAtt 0.4233 TrainAcc 0.7300 TestAcc 0.6244 0.7200
epoch 2200 LossPred 0.6817 LossAtt 0.3925 TrainAcc 0.7300 TestAcc 0.6411 0.7250
epoch 2300 LossPred 0.6820 LossAtt 0.4097 TrainAcc 0.7400 TestAcc 0.6116 0.7150
epoch 2400 LossPred 0.6762 LossAtt 0.3958 TrainAcc 0.7400 TestAcc 0.6154 0.7200
epoch 2500 LossPred 0.6753 LossAtt 0.3919 TrainAcc 0.7300 TestAcc 0.6299 0.6950
Optimization Finished!
********** replication  65  **********
epoch   0 LossPred 1.1982 LossAtt 1.0020 TrainAcc 0.4300 TestAcc 0.4697 0.4450
epoch 100 LossPred 0.8510 LossAtt 0.4358 TrainAcc 0.6700 TestAcc 0.6144 0.7050
epoch 200 LossPred 0.8098 LossAtt 0.3768 TrainAcc 0.7000 TestAcc 0.6759 0.7000
epoch 300 LossPred 0.7658 LossAtt 0.3881 TrainAcc 0.7300 TestAcc 0.6804 0.7200
epoch 400 LossPred 0.2794 LossAtt 0.4006 TrainAcc 0.9400 TestAcc 0.9289 0.9500
epoch 500 LossPred 0.3080 LossAtt 0.3385 TrainAcc 0.8900 TestAcc 0.9209 0.8850
epoch 600 LossPred 0.3463 LossAtt 0.3733 TrainAcc 0.8700 TestAcc 0.8601 0.8850
epoch 700 LossPred 0.5174 LossAtt 0.3737 TrainAcc 0.8400 TestAcc 0.8048 0.8150
epoch 800 LossPred 0.2264 LossAtt 0.3983 TrainAcc 0.9500 TestAcc 0.9254 0.9350
epoch 900 LossPred 0.2634 LossAtt 0.4050 TrainAcc 0.9000 TestAcc 0.9147 0.9000
epoch 1000 LossPred 0.4431 LossAtt 0.4179 TrainAcc 0.8400 TestAcc 0.8463 0.8100
epoch 1100 LossPred 0.4033 LossAtt 0.4230 TrainAcc 0.8800 TestAcc 0.8388 0.8800
epoch 1200 LossPred 0.5257 LossAtt 0.4106 TrainAcc 0.8400 TestAcc 0.7940 0.8500
epoch 1300 LossPred 0.4465 LossAtt 0.4055 TrainAcc 0.8700 TestAcc 0.8203 0.8600
epoch 1400 LossPred 0.3793 LossAtt 0.4073 TrainAcc 0.8700 TestAcc 0.8383 0.8800
epoch 1500 LossPred 0.2802 LossAtt 0.4152 TrainAcc 0.9200 TestAcc 0.8671 0.8800
epoch 1600 LossPred 0.3102 LossAtt 0.3950 TrainAcc 0.9100 TestAcc 0.8406 0.8800
epoch 1700 LossPred 0.2720 LossAtt 0.3889 TrainAcc 0.9200 TestAcc 0.8551 0.9400
epoch 1800 LossPred 0.2314 LossAtt 0.3876 TrainAcc 0.9300 TestAcc 0.8549 0.9350
epoch 1900 LossPred 0.2140 LossAtt 0.3609 TrainAcc 0.9300 TestAcc 0.8584 0.9450
epoch 2000 LossPred 0.1893 LossAtt 0.3625 TrainAcc 0.9500 TestAcc 0.8596 0.9500
epoch 2100 LossPred 0.1965 LossAtt 0.3808 TrainAcc 0.9300 TestAcc 0.8621 0.9400
epoch 2200 LossPred 0.2293 LossAtt 0.3847 TrainAcc 0.9300 TestAcc 0.8651 0.9350
epoch 2300 LossPred 0.1667 LossAtt 0.4082 TrainAcc 0.9500 TestAcc 0.8644 0.9350
epoch 2400 LossPred 0.1599 LossAtt 0.3893 TrainAcc 0.9400 TestAcc 0.8641 0.9400
epoch 2500 LossPred 0.1147 LossAtt 0.3980 TrainAcc 0.9700 TestAcc 0.8754 0.9700
Optimization Finished!
********** replication  66  **********
epoch   0 LossPred 1.1642 LossAtt 1.0040 TrainAcc 0.3600 TestAcc 0.3971 0.3550
epoch 100 LossPred 0.8662 LossAtt 0.3143 TrainAcc 0.6700 TestAcc 0.6144 0.6450
epoch 200 LossPred 0.6625 LossAtt 0.3362 TrainAcc 0.7600 TestAcc 0.7237 0.7500
epoch 300 LossPred 0.3231 LossAtt 0.3419 TrainAcc 0.9100 TestAcc 0.8433 0.8950
epoch 400 LossPred 0.2895 LossAtt 0.3526 TrainAcc 0.9300 TestAcc 0.8468 0.9050
epoch 500 LossPred 0.2688 LossAtt 0.3217 TrainAcc 0.9200 TestAcc 0.8423 0.8950
epoch 600 LossPred 0.2324 LossAtt 0.3407 TrainAcc 0.9300 TestAcc 0.8556 0.9150
epoch 700 LossPred 0.1936 LossAtt 0.3693 TrainAcc 0.9400 TestAcc 0.8824 0.9250
epoch 800 LossPred 0.1838 LossAtt 0.3847 TrainAcc 0.9400 TestAcc 0.8944 0.9350
epoch 900 LossPred 0.1660 LossAtt 0.3483 TrainAcc 0.9500 TestAcc 0.8531 0.9300
epoch 1000 LossPred 0.1514 LossAtt 0.3668 TrainAcc 0.9400 TestAcc 0.8794 0.9350
epoch 1100 LossPred 0.1520 LossAtt 0.3587 TrainAcc 0.9500 TestAcc 0.8471 0.9400
epoch 1200 LossPred 0.1521 LossAtt 0.3633 TrainAcc 0.9500 TestAcc 0.8994 0.9500
epoch 1300 LossPred 0.1348 LossAtt 0.3627 TrainAcc 0.9500 TestAcc 0.8736 0.9400
epoch 1400 LossPred 0.1952 LossAtt 0.3691 TrainAcc 0.9100 TestAcc 0.9002 0.9150
epoch 1500 LossPred 0.1394 LossAtt 0.3790 TrainAcc 0.9600 TestAcc 0.9029 0.9500
epoch 1600 LossPred 0.1187 LossAtt 0.3583 TrainAcc 0.9700 TestAcc 0.8659 0.9400
epoch 1700 LossPred 0.1113 LossAtt 0.3727 TrainAcc 0.9700 TestAcc 0.8684 0.9400
epoch 1800 LossPred 0.1207 LossAtt 0.3495 TrainAcc 0.9500 TestAcc 0.8856 0.9500
epoch 1900 LossPred 0.1484 LossAtt 0.3625 TrainAcc 0.9500 TestAcc 0.8413 0.9450
epoch 2000 LossPred 0.1120 LossAtt 0.3477 TrainAcc 0.9700 TestAcc 0.8731 0.9500
epoch 2100 LossPred 0.1314 LossAtt 0.3452 TrainAcc 0.9400 TestAcc 0.8826 0.9350
epoch 2200 LossPred 0.1194 LossAtt 0.3236 TrainAcc 0.9700 TestAcc 0.8531 0.9400
epoch 2300 LossPred 0.1346 LossAtt 0.3340 TrainAcc 0.9500 TestAcc 0.8996 0.9300
epoch 2400 LossPred 0.1453 LossAtt 0.3577 TrainAcc 0.9400 TestAcc 0.9082 0.9350
epoch 2500 LossPred 0.1063 LossAtt 0.3543 TrainAcc 0.9700 TestAcc 0.8834 0.9400
Optimization Finished!
********** replication  67  **********
epoch   0 LossPred 1.0071 LossAtt 1.0061 TrainAcc 0.5600 TestAcc 0.5531 0.5550
epoch 100 LossPred 0.8713 LossAtt 0.3234 TrainAcc 0.7000 TestAcc 0.5526 0.7050
epoch 200 LossPred 0.8712 LossAtt 0.2103 TrainAcc 0.7000 TestAcc 0.5526 0.6900
epoch 300 LossPred 0.8705 LossAtt 0.1606 TrainAcc 0.6600 TestAcc 0.5445 0.6600
epoch 400 LossPred 0.8692 LossAtt 0.1618 TrainAcc 0.6600 TestAcc 0.5445 0.6600
epoch 500 LossPred 0.8709 LossAtt 0.1482 TrainAcc 0.6500 TestAcc 0.5958 0.6500
epoch 600 LossPred 0.8709 LossAtt 0.1611 TrainAcc 0.6500 TestAcc 0.5958 0.6450
epoch 700 LossPred 0.8689 LossAtt 0.1682 TrainAcc 0.6600 TestAcc 0.5445 0.6400
epoch 800 LossPred 0.8871 LossAtt 0.1353 TrainAcc 0.6500 TestAcc 0.5958 0.6500
epoch 900 LossPred 0.8684 LossAtt 0.2379 TrainAcc 0.7200 TestAcc 0.5721 0.6700
epoch 1000 LossPred 0.8669 LossAtt 0.2108 TrainAcc 0.6600 TestAcc 0.5443 0.6450
epoch 1100 LossPred 0.8657 LossAtt 0.2381 TrainAcc 0.6600 TestAcc 0.5443 0.6650
epoch 1200 LossPred 0.8638 LossAtt 0.2409 TrainAcc 0.6600 TestAcc 0.5443 0.6650
epoch 1300 LossPred 0.8286 LossAtt 0.3342 TrainAcc 0.6800 TestAcc 0.5638 0.6750
epoch 1400 LossPred 0.7333 LossAtt 0.2458 TrainAcc 0.7200 TestAcc 0.5721 0.7200
epoch 1500 LossPred 0.7296 LossAtt 0.2314 TrainAcc 0.7200 TestAcc 0.5721 0.7200
epoch 1600 LossPred 0.7293 LossAtt 0.2308 TrainAcc 0.7200 TestAcc 0.5721 0.7200
epoch 1700 LossPred 0.7805 LossAtt 0.2265 TrainAcc 0.6900 TestAcc 0.5761 0.6600
epoch 1800 LossPred 0.7521 LossAtt 0.2280 TrainAcc 0.6900 TestAcc 0.5761 0.6900
epoch 1900 LossPred 0.7285 LossAtt 0.1774 TrainAcc 0.7200 TestAcc 0.5721 0.7200
epoch 2000 LossPred 0.7264 LossAtt 0.1829 TrainAcc 0.7200 TestAcc 0.5721 0.7200
epoch 2100 LossPred 0.7254 LossAtt 0.1708 TrainAcc 0.7200 TestAcc 0.5721 0.7100
epoch 2200 LossPred 0.7249 LossAtt 0.1891 TrainAcc 0.7200 TestAcc 0.5781 0.7200
epoch 2300 LossPred 0.7247 LossAtt 0.1961 TrainAcc 0.7200 TestAcc 0.5926 0.7200
epoch 2400 LossPred 0.7243 LossAtt 0.1607 TrainAcc 0.7200 TestAcc 0.5988 0.7200
epoch 2500 LossPred 0.7227 LossAtt 0.1861 TrainAcc 0.7200 TestAcc 0.5988 0.7200
Optimization Finished!
********** replication  68  **********
epoch   0 LossPred 1.0013 LossAtt 0.9910 TrainAcc 0.5900 TestAcc 0.5868 0.5800
epoch 100 LossPred 0.9349 LossAtt 0.5052 TrainAcc 0.5900 TestAcc 0.5973 0.5750
epoch 200 LossPred 0.8341 LossAtt 0.5717 TrainAcc 0.6800 TestAcc 0.6314 0.6650
epoch 300 LossPred 0.7437 LossAtt 0.5963 TrainAcc 0.7000 TestAcc 0.6016 0.6800
epoch 400 LossPred 0.7316 LossAtt 0.5564 TrainAcc 0.7200 TestAcc 0.5926 0.7000
epoch 500 LossPred 0.7228 LossAtt 0.5544 TrainAcc 0.7300 TestAcc 0.6126 0.7150
epoch 600 LossPred 0.7037 LossAtt 0.4675 TrainAcc 0.7400 TestAcc 0.6106 0.7300
epoch 700 LossPred 0.6957 LossAtt 0.4273 TrainAcc 0.7500 TestAcc 0.6049 0.7350
epoch 800 LossPred 0.6889 LossAtt 0.4227 TrainAcc 0.7600 TestAcc 0.5998 0.7300
epoch 900 LossPred 0.6936 LossAtt 0.4717 TrainAcc 0.7400 TestAcc 0.5823 0.7350
epoch 1000 LossPred 0.6818 LossAtt 0.4793 TrainAcc 0.7400 TestAcc 0.5846 0.7250
epoch 1100 LossPred 0.6998 LossAtt 0.4642 TrainAcc 0.7300 TestAcc 0.5791 0.7050
epoch 1200 LossPred 0.6556 LossAtt 0.4563 TrainAcc 0.7800 TestAcc 0.5851 0.7400
epoch 1300 LossPred 0.7167 LossAtt 0.4893 TrainAcc 0.7100 TestAcc 0.5863 0.7050
epoch 1400 LossPred 0.6304 LossAtt 0.4913 TrainAcc 0.7800 TestAcc 0.5791 0.7500
epoch 1500 LossPred 0.7028 LossAtt 0.4904 TrainAcc 0.7200 TestAcc 0.5701 0.7200
epoch 1600 LossPred 0.6387 LossAtt 0.5038 TrainAcc 0.7700 TestAcc 0.5801 0.7550
epoch 1700 LossPred 0.6259 LossAtt 0.4644 TrainAcc 0.7800 TestAcc 0.5591 0.7550
epoch 1800 LossPred 0.6172 LossAtt 0.4481 TrainAcc 0.7900 TestAcc 0.5676 0.7750
epoch 1900 LossPred 0.6100 LossAtt 0.4663 TrainAcc 0.8000 TestAcc 0.5706 0.7750
epoch 2000 LossPred 0.6610 LossAtt 0.4258 TrainAcc 0.7500 TestAcc 0.5563 0.7250
epoch 2100 LossPred 0.6108 LossAtt 0.4898 TrainAcc 0.7900 TestAcc 0.5831 0.7650
epoch 2200 LossPred 0.6294 LossAtt 0.4625 TrainAcc 0.7800 TestAcc 0.5653 0.7550
epoch 2300 LossPred 0.6092 LossAtt 0.4979 TrainAcc 0.8000 TestAcc 0.5798 0.7800
epoch 2400 LossPred 0.6493 LossAtt 0.4942 TrainAcc 0.7400 TestAcc 0.5743 0.7300
epoch 2500 LossPred 0.6117 LossAtt 0.5049 TrainAcc 0.8000 TestAcc 0.5786 0.7550
Optimization Finished!
********** replication  69  **********
epoch   0 LossPred 1.4124 LossAtt 1.0383 TrainAcc 0.4100 TestAcc 0.4507 0.4250
epoch 100 LossPred 1.0409 LossAtt 0.5576 TrainAcc 0.5500 TestAcc 0.4922 0.5300
epoch 200 LossPred 0.9444 LossAtt 0.5426 TrainAcc 0.6100 TestAcc 0.5320 0.6150
epoch 300 LossPred 0.8654 LossAtt 0.5698 TrainAcc 0.6800 TestAcc 0.6281 0.6450
epoch 400 LossPred 0.5278 LossAtt 0.5561 TrainAcc 0.8300 TestAcc 0.8448 0.8400
epoch 500 LossPred 0.4330 LossAtt 0.5603 TrainAcc 0.9000 TestAcc 0.8814 0.8550
epoch 600 LossPred 0.3869 LossAtt 0.4843 TrainAcc 0.9200 TestAcc 0.8846 0.8850
epoch 700 LossPred 0.3813 LossAtt 0.4039 TrainAcc 0.8800 TestAcc 0.8619 0.8800
epoch 800 LossPred 0.3650 LossAtt 0.4078 TrainAcc 0.9000 TestAcc 0.8654 0.8950
epoch 900 LossPred 0.3493 LossAtt 0.4150 TrainAcc 0.9100 TestAcc 0.8776 0.9000
epoch 1000 LossPred 0.3723 LossAtt 0.3970 TrainAcc 0.8900 TestAcc 0.8566 0.8950
epoch 1100 LossPred 0.3362 LossAtt 0.3956 TrainAcc 0.9100 TestAcc 0.8819 0.9150
epoch 1200 LossPred 0.3256 LossAtt 0.4329 TrainAcc 0.9100 TestAcc 0.8896 0.9150
epoch 1300 LossPred 0.2926 LossAtt 0.4979 TrainAcc 0.9300 TestAcc 0.9099 0.9300
epoch 1400 LossPred 0.3434 LossAtt 0.4857 TrainAcc 0.8900 TestAcc 0.9057 0.8850
epoch 1500 LossPred 0.2422 LossAtt 0.4675 TrainAcc 0.9500 TestAcc 0.9247 0.9500
epoch 1600 LossPred 0.2612 LossAtt 0.4558 TrainAcc 0.9300 TestAcc 0.8876 0.9350
epoch 1700 LossPred 0.2163 LossAtt 0.4763 TrainAcc 0.9700 TestAcc 0.9314 0.9650
epoch 1800 LossPred 0.1771 LossAtt 0.4363 TrainAcc 0.9700 TestAcc 0.9279 0.9700
epoch 1900 LossPred 0.2548 LossAtt 0.4429 TrainAcc 0.9500 TestAcc 0.9164 0.9500
epoch 2000 LossPred 0.1589 LossAtt 0.4453 TrainAcc 0.9700 TestAcc 0.9372 0.9700
epoch 2100 LossPred 0.1468 LossAtt 0.4413 TrainAcc 0.9700 TestAcc 0.9289 0.9800
epoch 2200 LossPred 0.1612 LossAtt 0.4539 TrainAcc 0.9700 TestAcc 0.9159 0.9650
epoch 2300 LossPred 0.1614 LossAtt 0.4216 TrainAcc 0.9700 TestAcc 0.9249 0.9700
epoch 2400 LossPred 0.1501 LossAtt 0.4060 TrainAcc 0.9700 TestAcc 0.9392 0.9750
epoch 2500 LossPred 0.1903 LossAtt 0.4010 TrainAcc 0.9600 TestAcc 0.8954 0.9400
Optimization Finished!
********** replication  70  **********
epoch   0 LossPred 1.0879 LossAtt 1.0173 TrainAcc 0.5700 TestAcc 0.5696 0.5600
epoch 100 LossPred 0.9454 LossAtt 0.4075 TrainAcc 0.6000 TestAcc 0.6056 0.5800
epoch 200 LossPred 0.9190 LossAtt 0.4087 TrainAcc 0.6300 TestAcc 0.5683 0.6300
epoch 300 LossPred 0.5702 LossAtt 0.3592 TrainAcc 0.8400 TestAcc 0.7898 0.8100
epoch 400 LossPred 0.4993 LossAtt 0.2862 TrainAcc 0.8200 TestAcc 0.7928 0.8000
epoch 500 LossPred 0.4575 LossAtt 0.2154 TrainAcc 0.8400 TestAcc 0.8201 0.8200
epoch 600 LossPred 0.4335 LossAtt 0.1990 TrainAcc 0.8300 TestAcc 0.8181 0.8350
epoch 700 LossPred 0.4266 LossAtt 0.2360 TrainAcc 0.8400 TestAcc 0.8549 0.8450
epoch 800 LossPred 0.4555 LossAtt 0.2189 TrainAcc 0.8400 TestAcc 0.8686 0.8300
epoch 900 LossPred 0.4509 LossAtt 0.2150 TrainAcc 0.8700 TestAcc 0.8684 0.8500
epoch 1000 LossPred 0.4529 LossAtt 0.2134 TrainAcc 0.8600 TestAcc 0.8008 0.8300
epoch 1100 LossPred 0.4032 LossAtt 0.2153 TrainAcc 0.8600 TestAcc 0.8789 0.8600
epoch 1200 LossPred 0.3907 LossAtt 0.2258 TrainAcc 0.8700 TestAcc 0.8428 0.8750
epoch 1300 LossPred 0.4305 LossAtt 0.2217 TrainAcc 0.8600 TestAcc 0.7968 0.8600
epoch 1400 LossPred 0.3956 LossAtt 0.2084 TrainAcc 0.8700 TestAcc 0.8511 0.8700
epoch 1500 LossPred 0.4307 LossAtt 0.1915 TrainAcc 0.8600 TestAcc 0.8456 0.8600
epoch 1600 LossPred 0.4634 LossAtt 0.1951 TrainAcc 0.8600 TestAcc 0.7698 0.8600
epoch 1700 LossPred 0.2988 LossAtt 0.2171 TrainAcc 0.8900 TestAcc 0.8751 0.8900
epoch 1800 LossPred 0.3790 LossAtt 0.2019 TrainAcc 0.8700 TestAcc 0.8363 0.8700
epoch 1900 LossPred 0.3524 LossAtt 0.2284 TrainAcc 0.8700 TestAcc 0.8651 0.8700
epoch 2000 LossPred 0.3927 LossAtt 0.2270 TrainAcc 0.8700 TestAcc 0.8559 0.8700
epoch 2100 LossPred 0.3230 LossAtt 0.2132 TrainAcc 0.8800 TestAcc 0.8251 0.8800
epoch 2200 LossPred 1.1906 LossAtt 0.2104 TrainAcc 0.6300 TestAcc 0.5450 0.6300
epoch 2300 LossPred 0.3823 LossAtt 0.2027 TrainAcc 0.8700 TestAcc 0.8711 0.8650
epoch 2400 LossPred 0.3861 LossAtt 0.2043 TrainAcc 0.8600 TestAcc 0.8208 0.8600
epoch 2500 LossPred 0.4078 LossAtt 0.2276 TrainAcc 0.8900 TestAcc 0.9042 0.8850
Optimization Finished!
********** replication  71  **********
epoch   0 LossPred 0.9323 LossAtt 0.9979 TrainAcc 0.5700 TestAcc 0.5335 0.6100
epoch 100 LossPred 0.7870 LossAtt 0.4201 TrainAcc 0.7300 TestAcc 0.6084 0.7300
epoch 200 LossPred 0.7546 LossAtt 0.3802 TrainAcc 0.7300 TestAcc 0.6084 0.7300
epoch 300 LossPred 0.7079 LossAtt 0.3842 TrainAcc 0.7300 TestAcc 0.6084 0.7300
epoch 400 LossPred 0.4865 LossAtt 0.4928 TrainAcc 0.8300 TestAcc 0.8163 0.8400
epoch 500 LossPred 0.4431 LossAtt 0.4958 TrainAcc 0.8200 TestAcc 0.8221 0.8150
epoch 600 LossPred 0.3770 LossAtt 0.4842 TrainAcc 0.8600 TestAcc 0.8819 0.8500
epoch 700 LossPred 0.3680 LossAtt 0.4760 TrainAcc 0.8900 TestAcc 0.8416 0.8900
epoch 800 LossPred 0.3559 LossAtt 0.4658 TrainAcc 0.8400 TestAcc 0.8516 0.8200
epoch 900 LossPred 0.3811 LossAtt 0.4395 TrainAcc 0.8400 TestAcc 0.8561 0.8200
epoch 1000 LossPred 0.2715 LossAtt 0.4805 TrainAcc 0.9300 TestAcc 0.8821 0.9150
epoch 1100 LossPred 0.2808 LossAtt 0.4636 TrainAcc 0.9200 TestAcc 0.8741 0.9250
epoch 1200 LossPred 0.2819 LossAtt 0.4947 TrainAcc 0.9200 TestAcc 0.8766 0.9100
epoch 1300 LossPred 0.4465 LossAtt 0.4859 TrainAcc 0.8600 TestAcc 0.7985 0.8550
epoch 1400 LossPred 0.2396 LossAtt 0.4474 TrainAcc 0.9200 TestAcc 0.8934 0.9200
epoch 1500 LossPred 0.3569 LossAtt 0.4325 TrainAcc 0.8700 TestAcc 0.8714 0.8400
epoch 1600 LossPred 0.5850 LossAtt 0.4648 TrainAcc 0.8100 TestAcc 0.7850 0.8300
epoch 1700 LossPred 0.3606 LossAtt 0.4788 TrainAcc 0.8900 TestAcc 0.8481 0.8850
epoch 1800 LossPred 0.2694 LossAtt 0.4805 TrainAcc 0.9200 TestAcc 0.8851 0.9200
epoch 1900 LossPred 0.2142 LossAtt 0.4559 TrainAcc 0.9200 TestAcc 0.9054 0.9350
epoch 2000 LossPred 0.3336 LossAtt 0.4710 TrainAcc 0.8500 TestAcc 0.8646 0.8600
epoch 2100 LossPred 0.2976 LossAtt 0.4588 TrainAcc 0.9100 TestAcc 0.8824 0.8850
epoch 2200 LossPred 0.2459 LossAtt 0.4606 TrainAcc 0.9000 TestAcc 0.9014 0.8850
epoch 2300 LossPred 0.2219 LossAtt 0.4792 TrainAcc 0.9500 TestAcc 0.8974 0.9250
epoch 2400 LossPred 0.2155 LossAtt 0.4875 TrainAcc 0.9500 TestAcc 0.8974 0.9300
epoch 2500 LossPred 0.2421 LossAtt 0.4637 TrainAcc 0.9000 TestAcc 0.9017 0.8900
Optimization Finished!
********** replication  72  **********
epoch   0 LossPred 0.9799 LossAtt 0.9847 TrainAcc 0.6000 TestAcc 0.5648 0.5950
epoch 100 LossPred 0.8853 LossAtt 0.4986 TrainAcc 0.6500 TestAcc 0.6031 0.6500
epoch 200 LossPred 0.8696 LossAtt 0.4560 TrainAcc 0.6600 TestAcc 0.5783 0.6600
epoch 300 LossPred 0.8556 LossAtt 0.4622 TrainAcc 0.6800 TestAcc 0.6036 0.6800
epoch 400 LossPred 0.8229 LossAtt 0.5043 TrainAcc 0.6700 TestAcc 0.6039 0.6700
epoch 500 LossPred 0.3777 LossAtt 0.5386 TrainAcc 0.8600 TestAcc 0.8636 0.8700
epoch 600 LossPred 0.1826 LossAtt 0.5554 TrainAcc 0.9200 TestAcc 0.9157 0.9200
epoch 700 LossPred 0.1187 LossAtt 0.5657 TrainAcc 0.9800 TestAcc 0.9282 0.9450
epoch 800 LossPred 0.2113 LossAtt 0.5525 TrainAcc 0.9400 TestAcc 0.8534 0.9250
epoch 900 LossPred 0.1021 LossAtt 0.5396 TrainAcc 0.9600 TestAcc 0.9274 0.9650
epoch 1000 LossPred 0.1142 LossAtt 0.5445 TrainAcc 0.9700 TestAcc 0.9297 0.9400
epoch 1100 LossPred 0.2633 LossAtt 0.5467 TrainAcc 0.9300 TestAcc 0.8401 0.8850
epoch 1200 LossPred 0.0845 LossAtt 0.5289 TrainAcc 0.9700 TestAcc 0.9287 0.9650
epoch 1300 LossPred 0.0813 LossAtt 0.5381 TrainAcc 0.9800 TestAcc 0.9369 0.9450
epoch 1400 LossPred 0.0704 LossAtt 0.5462 TrainAcc 0.9800 TestAcc 0.9347 0.9400
epoch 1500 LossPred 0.1105 LossAtt 0.5351 TrainAcc 0.9500 TestAcc 0.9079 0.9450
epoch 1600 LossPred 0.0726 LossAtt 0.5330 TrainAcc 0.9700 TestAcc 0.9269 0.9350
epoch 1700 LossPred 0.0550 LossAtt 0.5224 TrainAcc 0.9900 TestAcc 0.9297 0.9550
epoch 1800 LossPred 0.0658 LossAtt 0.5486 TrainAcc 0.9800 TestAcc 0.9354 0.9450
epoch 1900 LossPred 0.1181 LossAtt 0.5338 TrainAcc 0.9700 TestAcc 0.9234 0.9250
epoch 2000 LossPred 0.0472 LossAtt 0.5480 TrainAcc 0.9900 TestAcc 0.9279 0.9450
epoch 2100 LossPred 0.0297 LossAtt 0.5550 TrainAcc 1.0000 TestAcc 0.9164 0.9650
Optimization Finished!
********** replication  73  **********
epoch   0 LossPred 1.0076 LossAtt 1.0072 TrainAcc 0.5800 TestAcc 0.5678 0.5550
epoch 100 LossPred 0.9385 LossAtt 0.3481 TrainAcc 0.6200 TestAcc 0.5978 0.6200
epoch 200 LossPred 0.9343 LossAtt 0.2001 TrainAcc 0.6200 TestAcc 0.5978 0.6300
epoch 300 LossPred 0.9117 LossAtt 0.2128 TrainAcc 0.6200 TestAcc 0.5978 0.6350
epoch 400 LossPred 0.3074 LossAtt 0.2675 TrainAcc 0.9000 TestAcc 0.8761 0.8900
epoch 500 LossPred 0.2624 LossAtt 0.2615 TrainAcc 0.8900 TestAcc 0.8781 0.9050
epoch 600 LossPred 0.2446 LossAtt 0.2490 TrainAcc 0.9100 TestAcc 0.8911 0.9000
epoch 700 LossPred 0.2343 LossAtt 0.2670 TrainAcc 0.9000 TestAcc 0.8929 0.9000
epoch 800 LossPred 0.1990 LossAtt 0.2454 TrainAcc 0.9300 TestAcc 0.9147 0.9300
epoch 900 LossPred 0.2177 LossAtt 0.2431 TrainAcc 0.9200 TestAcc 0.8969 0.9250
epoch 1000 LossPred 0.3383 LossAtt 0.2538 TrainAcc 0.8800 TestAcc 0.8428 0.8900
epoch 1100 LossPred 0.2221 LossAtt 0.2316 TrainAcc 0.9400 TestAcc 0.8989 0.8850
epoch 1200 LossPred 0.1973 LossAtt 0.2220 TrainAcc 0.9500 TestAcc 0.9122 0.8850
epoch 1300 LossPred 0.1677 LossAtt 0.2254 TrainAcc 0.9700 TestAcc 0.9297 0.9100
epoch 1400 LossPred 0.1590 LossAtt 0.2285 TrainAcc 0.9400 TestAcc 0.9399 0.9200
epoch 1500 LossPred 0.1448 LossAtt 0.2117 TrainAcc 0.9500 TestAcc 0.9322 0.9250
epoch 1600 LossPred 0.1631 LossAtt 0.2181 TrainAcc 0.9300 TestAcc 0.9114 0.9200
epoch 1700 LossPred 0.2297 LossAtt 0.2113 TrainAcc 0.9200 TestAcc 0.8844 0.9100
epoch 1800 LossPred 0.2003 LossAtt 0.2156 TrainAcc 0.9300 TestAcc 0.9249 0.8900
epoch 1900 LossPred 0.3860 LossAtt 0.2280 TrainAcc 0.8600 TestAcc 0.8141 0.8600
epoch 2000 LossPred 0.3658 LossAtt 0.2131 TrainAcc 0.8500 TestAcc 0.8036 0.8650
epoch 2100 LossPred 0.2201 LossAtt 0.2033 TrainAcc 0.9600 TestAcc 0.9167 0.8950
epoch 2200 LossPred 0.2347 LossAtt 0.2059 TrainAcc 0.9500 TestAcc 0.9087 0.8800
epoch 2300 LossPred 0.3022 LossAtt 0.2117 TrainAcc 0.8900 TestAcc 0.8556 0.8950
epoch 2400 LossPred 0.4424 LossAtt 0.2142 TrainAcc 0.8500 TestAcc 0.7948 0.8450
epoch 2500 LossPred 0.3475 LossAtt 0.2067 TrainAcc 0.8600 TestAcc 0.8083 0.8700
Optimization Finished!
********** replication  74  **********
epoch   0 LossPred 1.0423 LossAtt 0.9907 TrainAcc 0.4900 TestAcc 0.4702 0.4950
epoch 100 LossPred 0.9335 LossAtt 0.4605 TrainAcc 0.5800 TestAcc 0.5068 0.5800
epoch 200 LossPred 0.9149 LossAtt 0.4217 TrainAcc 0.6200 TestAcc 0.6071 0.6200
epoch 300 LossPred 0.9037 LossAtt 0.3950 TrainAcc 0.6200 TestAcc 0.6071 0.6200
epoch 400 LossPred 0.8470 LossAtt 0.4261 TrainAcc 0.6600 TestAcc 0.5726 0.6850
epoch 500 LossPred 0.7054 LossAtt 0.4526 TrainAcc 0.7800 TestAcc 0.6749 0.7900
epoch 600 LossPred 0.2860 LossAtt 0.4635 TrainAcc 0.9300 TestAcc 0.8869 0.9050
epoch 700 LossPred 0.2611 LossAtt 0.4486 TrainAcc 0.9300 TestAcc 0.9014 0.9150
epoch 800 LossPred 0.2043 LossAtt 0.4556 TrainAcc 0.9700 TestAcc 0.9322 0.9450
epoch 900 LossPred 0.3216 LossAtt 0.4634 TrainAcc 0.8800 TestAcc 0.8091 0.8500
epoch 1000 LossPred 0.2235 LossAtt 0.4243 TrainAcc 0.9100 TestAcc 0.8311 0.9050
epoch 1100 LossPred 0.1427 LossAtt 0.4016 TrainAcc 0.9600 TestAcc 0.8881 0.9400
epoch 1200 LossPred 0.1587 LossAtt 0.4031 TrainAcc 0.9400 TestAcc 0.8974 0.9350
epoch 1300 LossPred 0.1323 LossAtt 0.3595 TrainAcc 0.9600 TestAcc 0.8691 0.9450
epoch 1400 LossPred 0.1434 LossAtt 0.3320 TrainAcc 0.9500 TestAcc 0.8776 0.9300
epoch 1500 LossPred 0.1317 LossAtt 0.3395 TrainAcc 0.9600 TestAcc 0.8704 0.9450
epoch 1600 LossPred 0.1279 LossAtt 0.3289 TrainAcc 0.9600 TestAcc 0.8841 0.9500
epoch 1700 LossPred 0.1843 LossAtt 0.3315 TrainAcc 0.9300 TestAcc 0.8386 0.9150
epoch 1800 LossPred 0.1176 LossAtt 0.3385 TrainAcc 0.9600 TestAcc 0.8921 0.9450
epoch 1900 LossPred 0.1169 LossAtt 0.3227 TrainAcc 0.9600 TestAcc 0.8934 0.9500
epoch 2000 LossPred 0.0877 LossAtt 0.3237 TrainAcc 0.9600 TestAcc 0.8759 0.9400
epoch 2100 LossPred 0.1425 LossAtt 0.3110 TrainAcc 0.9600 TestAcc 0.8539 0.9400
epoch 2200 LossPred 0.1436 LossAtt 0.3146 TrainAcc 0.9300 TestAcc 0.8814 0.9300
epoch 2300 LossPred 0.1985 LossAtt 0.3317 TrainAcc 0.9300 TestAcc 0.8323 0.9200
epoch 2400 LossPred 0.0840 LossAtt 0.3136 TrainAcc 0.9800 TestAcc 0.8994 0.9600
epoch 2500 LossPred 0.0901 LossAtt 0.3105 TrainAcc 0.9800 TestAcc 0.9117 0.9500
Optimization Finished!
********** replication  75  **********
epoch   0 LossPred 1.4574 LossAtt 1.0121 TrainAcc 0.5100 TestAcc 0.4985 0.4900
epoch 100 LossPred 1.0905 LossAtt 0.4361 TrainAcc 0.5100 TestAcc 0.4985 0.5100
epoch 200 LossPred 0.9582 LossAtt 0.4887 TrainAcc 0.5700 TestAcc 0.5365 0.5950
epoch 300 LossPred 0.8277 LossAtt 0.5419 TrainAcc 0.7500 TestAcc 0.6939 0.7500
epoch 400 LossPred 0.5742 LossAtt 0.5459 TrainAcc 0.8000 TestAcc 0.8458 0.8100
epoch 500 LossPred 0.5573 LossAtt 0.5137 TrainAcc 0.7900 TestAcc 0.8546 0.7950
epoch 600 LossPred 0.7054 LossAtt 0.4696 TrainAcc 0.7600 TestAcc 0.6992 0.7550
epoch 700 LossPred 0.5319 LossAtt 0.4403 TrainAcc 0.8200 TestAcc 0.8363 0.8100
epoch 800 LossPred 0.3304 LossAtt 0.4227 TrainAcc 0.9400 TestAcc 0.9217 0.9100
epoch 900 LossPred 0.6211 LossAtt 0.4191 TrainAcc 0.8000 TestAcc 0.8251 0.8150
epoch 1000 LossPred 0.6271 LossAtt 0.4336 TrainAcc 0.8100 TestAcc 0.7763 0.7850
epoch 1100 LossPred 0.4103 LossAtt 0.4192 TrainAcc 0.8200 TestAcc 0.8891 0.8350
epoch 1200 LossPred 0.4372 LossAtt 0.4083 TrainAcc 0.8300 TestAcc 0.8669 0.8300
epoch 1300 LossPred 0.3898 LossAtt 0.4020 TrainAcc 0.8600 TestAcc 0.8946 0.8700
epoch 1400 LossPred 0.3044 LossAtt 0.3990 TrainAcc 0.9100 TestAcc 0.9352 0.9100
epoch 1500 LossPred 0.2991 LossAtt 0.3768 TrainAcc 0.9200 TestAcc 0.9339 0.9250
epoch 1600 LossPred 0.4500 LossAtt 0.4083 TrainAcc 0.8200 TestAcc 0.8188 0.8150
epoch 1700 LossPred 0.3782 LossAtt 0.4050 TrainAcc 0.8500 TestAcc 0.8721 0.8500
epoch 1800 LossPred 0.4751 LossAtt 0.4227 TrainAcc 0.8200 TestAcc 0.8121 0.8100
epoch 1900 LossPred 0.4535 LossAtt 0.4210 TrainAcc 0.7900 TestAcc 0.8096 0.7950
epoch 2000 LossPred 0.3978 LossAtt 0.4036 TrainAcc 0.8500 TestAcc 0.8338 0.8400
epoch 2100 LossPred 0.3868 LossAtt 0.3985 TrainAcc 0.8300 TestAcc 0.8646 0.8300
epoch 2200 LossPred 0.2490 LossAtt 0.3966 TrainAcc 0.9400 TestAcc 0.9232 0.9650
epoch 2300 LossPred 0.3409 LossAtt 0.3839 TrainAcc 0.9300 TestAcc 0.8896 0.9000
epoch 2400 LossPred 0.2864 LossAtt 0.3868 TrainAcc 0.9200 TestAcc 0.8996 0.9300
epoch 2500 LossPred 0.2894 LossAtt 0.3862 TrainAcc 0.9100 TestAcc 0.8994 0.9250
Optimization Finished!
********** replication  76  **********
epoch   0 LossPred 1.0024 LossAtt 0.9665 TrainAcc 0.5300 TestAcc 0.5548 0.5750
epoch 100 LossPred 0.8707 LossAtt 0.5372 TrainAcc 0.6900 TestAcc 0.6029 0.6850
epoch 200 LossPred 0.8355 LossAtt 0.4680 TrainAcc 0.7000 TestAcc 0.6001 0.6900
epoch 300 LossPred 0.8143 LossAtt 0.4625 TrainAcc 0.7000 TestAcc 0.5993 0.6900
epoch 400 LossPred 0.7943 LossAtt 0.4595 TrainAcc 0.7000 TestAcc 0.6011 0.6950
epoch 500 LossPred 0.7698 LossAtt 0.4473 TrainAcc 0.7000 TestAcc 0.6021 0.6800
epoch 600 LossPred 0.7610 LossAtt 0.4201 TrainAcc 0.7000 TestAcc 0.5918 0.6650
epoch 700 LossPred 0.6948 LossAtt 0.4840 TrainAcc 0.7500 TestAcc 0.6299 0.7250
epoch 800 LossPred 0.6754 LossAtt 0.5072 TrainAcc 0.7400 TestAcc 0.6451 0.7300
epoch 900 LossPred 0.2894 LossAtt 0.4169 TrainAcc 0.9400 TestAcc 0.8336 0.9100
epoch 1000 LossPred 0.1621 LossAtt 0.3639 TrainAcc 0.9700 TestAcc 0.8431 0.9300
epoch 1100 LossPred 0.1759 LossAtt 0.3380 TrainAcc 0.9600 TestAcc 0.8501 0.9250
epoch 1200 LossPred 0.2100 LossAtt 0.3626 TrainAcc 0.9400 TestAcc 0.8263 0.9250
epoch 1300 LossPred 0.1466 LossAtt 0.3244 TrainAcc 0.9600 TestAcc 0.8443 0.9200
epoch 1400 LossPred 0.1532 LossAtt 0.3054 TrainAcc 0.9600 TestAcc 0.8398 0.9150
epoch 1500 LossPred 0.1424 LossAtt 0.3300 TrainAcc 0.9600 TestAcc 0.8433 0.9150
epoch 1600 LossPred 0.1427 LossAtt 0.3288 TrainAcc 0.9600 TestAcc 0.8403 0.9350
epoch 1700 LossPred 0.1724 LossAtt 0.3479 TrainAcc 0.9500 TestAcc 0.8431 0.9200
epoch 1800 LossPred 0.1401 LossAtt 0.3182 TrainAcc 0.9700 TestAcc 0.8524 0.9250
epoch 1900 LossPred 0.1925 LossAtt 0.3607 TrainAcc 0.9400 TestAcc 0.8331 0.9250
epoch 2000 LossPred 0.1372 LossAtt 0.3213 TrainAcc 0.9600 TestAcc 0.8509 0.9200
epoch 2100 LossPred 0.1701 LossAtt 0.3624 TrainAcc 0.9600 TestAcc 0.8438 0.9150
epoch 2200 LossPred 0.1374 LossAtt 0.3418 TrainAcc 0.9700 TestAcc 0.8441 0.9400
epoch 2300 LossPred 0.1660 LossAtt 0.3748 TrainAcc 0.9600 TestAcc 0.8436 0.9250
epoch 2400 LossPred 0.1811 LossAtt 0.3782 TrainAcc 0.9500 TestAcc 0.8436 0.9350
epoch 2500 LossPred 0.1687 LossAtt 0.3584 TrainAcc 0.9400 TestAcc 0.8333 0.9150
Optimization Finished!
********** replication  77  **********
epoch   0 LossPred 0.8808 LossAtt 0.9993 TrainAcc 0.6700 TestAcc 0.5893 0.6600
epoch 100 LossPred 0.8205 LossAtt 0.4795 TrainAcc 0.6500 TestAcc 0.5846 0.6850
epoch 200 LossPred 0.8164 LossAtt 0.4660 TrainAcc 0.6500 TestAcc 0.5608 0.6850
epoch 300 LossPred 0.8014 LossAtt 0.5120 TrainAcc 0.7200 TestAcc 0.6294 0.6950
epoch 400 LossPred 0.7828 LossAtt 0.5172 TrainAcc 0.7400 TestAcc 0.6216 0.7300
epoch 500 LossPred 0.7512 LossAtt 0.5183 TrainAcc 0.7400 TestAcc 0.6316 0.7400
epoch 600 LossPred 0.3848 LossAtt 0.5685 TrainAcc 0.8900 TestAcc 0.8371 0.8850
epoch 700 LossPred 0.3650 LossAtt 0.5886 TrainAcc 0.8800 TestAcc 0.8101 0.8850
epoch 800 LossPred 0.2978 LossAtt 0.5818 TrainAcc 0.9000 TestAcc 0.8423 0.9000
epoch 900 LossPred 0.3015 LossAtt 0.5628 TrainAcc 0.9100 TestAcc 0.8046 0.8900
epoch 1000 LossPred 0.4045 LossAtt 0.5533 TrainAcc 0.8300 TestAcc 0.8361 0.8400
epoch 1100 LossPred 0.3033 LossAtt 0.5395 TrainAcc 0.8900 TestAcc 0.8098 0.8900
epoch 1200 LossPred 0.2726 LossAtt 0.5270 TrainAcc 0.9200 TestAcc 0.8473 0.9000
epoch 1300 LossPred 0.2589 LossAtt 0.5405 TrainAcc 0.9300 TestAcc 0.8561 0.9100
epoch 1400 LossPred 0.2387 LossAtt 0.5399 TrainAcc 0.9200 TestAcc 0.8596 0.9250
epoch 1500 LossPred 0.2921 LossAtt 0.5472 TrainAcc 0.9000 TestAcc 0.8151 0.8750
epoch 1600 LossPred 0.3149 LossAtt 0.5142 TrainAcc 0.9000 TestAcc 0.7958 0.8600
epoch 1700 LossPred 0.2195 LossAtt 0.5029 TrainAcc 0.9200 TestAcc 0.8576 0.9250
epoch 1800 LossPred 0.2134 LossAtt 0.5033 TrainAcc 0.9300 TestAcc 0.8614 0.9300
epoch 1900 LossPred 0.2309 LossAtt 0.4967 TrainAcc 0.9200 TestAcc 0.8468 0.8950
epoch 2000 LossPred 0.2552 LossAtt 0.4914 TrainAcc 0.9100 TestAcc 0.8403 0.8900
epoch 2100 LossPred 0.2296 LossAtt 0.4897 TrainAcc 0.9300 TestAcc 0.8461 0.9100
epoch 2200 LossPred 0.2257 LossAtt 0.4893 TrainAcc 0.9300 TestAcc 0.8328 0.9000
epoch 2300 LossPred 0.2444 LossAtt 0.4789 TrainAcc 0.9100 TestAcc 0.8411 0.9000
epoch 2400 LossPred 0.1999 LossAtt 0.5134 TrainAcc 0.9600 TestAcc 0.8589 0.9200
epoch 2500 LossPred 0.2709 LossAtt 0.4785 TrainAcc 0.9000 TestAcc 0.8351 0.8800
Optimization Finished!
********** replication  78  **********
epoch   0 LossPred 1.0402 LossAtt 0.9809 TrainAcc 0.5400 TestAcc 0.5901 0.5400
epoch 100 LossPred 0.9380 LossAtt 0.3682 TrainAcc 0.6200 TestAcc 0.6374 0.6200
epoch 200 LossPred 0.4920 LossAtt 0.3911 TrainAcc 0.8600 TestAcc 0.8201 0.8200
epoch 300 LossPred 0.4495 LossAtt 0.3711 TrainAcc 0.8800 TestAcc 0.8466 0.8300
epoch 400 LossPred 0.4909 LossAtt 0.3747 TrainAcc 0.8300 TestAcc 0.8576 0.8100
epoch 500 LossPred 0.4350 LossAtt 0.3512 TrainAcc 0.8900 TestAcc 0.8654 0.8350
epoch 600 LossPred 0.4327 LossAtt 0.3739 TrainAcc 0.8800 TestAcc 0.8569 0.8300
epoch 700 LossPred 0.4275 LossAtt 0.3485 TrainAcc 0.8800 TestAcc 0.8366 0.8550
epoch 800 LossPred 0.4290 LossAtt 0.3503 TrainAcc 0.8800 TestAcc 0.8604 0.8500
epoch 900 LossPred 0.4083 LossAtt 0.3413 TrainAcc 0.8800 TestAcc 0.8446 0.8550
epoch 1000 LossPred 0.3807 LossAtt 0.3213 TrainAcc 0.8800 TestAcc 0.8451 0.8550
epoch 1100 LossPred 0.3319 LossAtt 0.3418 TrainAcc 0.9000 TestAcc 0.8321 0.8800
epoch 1200 LossPred 0.3948 LossAtt 0.3469 TrainAcc 0.8700 TestAcc 0.8273 0.8700
epoch 1300 LossPred 0.2859 LossAtt 0.3607 TrainAcc 0.9200 TestAcc 0.8238 0.8800
epoch 1400 LossPred 0.2990 LossAtt 0.3251 TrainAcc 0.9200 TestAcc 0.8263 0.8850
epoch 1500 LossPred 0.3074 LossAtt 0.3365 TrainAcc 0.9200 TestAcc 0.8208 0.8900
epoch 1600 LossPred 0.3146 LossAtt 0.3175 TrainAcc 0.9000 TestAcc 0.8316 0.9050
epoch 1700 LossPred 0.2988 LossAtt 0.3038 TrainAcc 0.9100 TestAcc 0.8148 0.8950
epoch 1800 LossPred 0.4206 LossAtt 0.2874 TrainAcc 0.8800 TestAcc 0.7710 0.8550
epoch 1900 LossPred 0.3202 LossAtt 0.2724 TrainAcc 0.9100 TestAcc 0.7900 0.8750
epoch 2000 LossPred 0.4000 LossAtt 0.2652 TrainAcc 0.8900 TestAcc 0.7738 0.8600
epoch 2100 LossPred 0.3008 LossAtt 0.2622 TrainAcc 0.9100 TestAcc 0.8006 0.8850
epoch 2200 LossPred 0.3278 LossAtt 0.2751 TrainAcc 0.9000 TestAcc 0.7900 0.8800
epoch 2300 LossPred 0.3507 LossAtt 0.2732 TrainAcc 0.9000 TestAcc 0.7858 0.8700
epoch 2400 LossPred 0.2928 LossAtt 0.2667 TrainAcc 0.9100 TestAcc 0.7965 0.8800
epoch 2500 LossPred 0.2859 LossAtt 0.2737 TrainAcc 0.9100 TestAcc 0.7975 0.8850
Optimization Finished!
********** replication  79  **********
epoch   0 LossPred 1.0574 LossAtt 1.0314 TrainAcc 0.4900 TestAcc 0.4822 0.5300
epoch 100 LossPred 0.9616 LossAtt 0.4100 TrainAcc 0.5900 TestAcc 0.6009 0.5650
epoch 200 LossPred 0.8821 LossAtt 0.4617 TrainAcc 0.6400 TestAcc 0.6837 0.6400
epoch 300 LossPred 0.2997 LossAtt 0.4952 TrainAcc 0.9200 TestAcc 0.8851 0.8750
epoch 400 LossPred 0.2722 LossAtt 0.4548 TrainAcc 0.9300 TestAcc 0.8961 0.8850
epoch 500 LossPred 0.2463 LossAtt 0.4611 TrainAcc 0.9200 TestAcc 0.9077 0.8850
epoch 600 LossPred 0.2924 LossAtt 0.3749 TrainAcc 0.9100 TestAcc 0.8791 0.8850
epoch 700 LossPred 0.2621 LossAtt 0.3889 TrainAcc 0.9200 TestAcc 0.9084 0.9000
epoch 800 LossPred 0.2354 LossAtt 0.3662 TrainAcc 0.9000 TestAcc 0.9167 0.9000
epoch 900 LossPred 0.3334 LossAtt 0.3778 TrainAcc 0.8800 TestAcc 0.8619 0.8750
epoch 1000 LossPred 0.2489 LossAtt 0.3687 TrainAcc 0.9000 TestAcc 0.9102 0.9000
epoch 1100 LossPred 0.2317 LossAtt 0.3761 TrainAcc 0.9300 TestAcc 0.9192 0.9250
epoch 1200 LossPred 0.2326 LossAtt 0.3688 TrainAcc 0.9400 TestAcc 0.9189 0.9250
epoch 1300 LossPred 0.2347 LossAtt 0.3653 TrainAcc 0.9300 TestAcc 0.9179 0.9050
epoch 1400 LossPred 0.2434 LossAtt 0.3581 TrainAcc 0.9300 TestAcc 0.8999 0.8950
epoch 1500 LossPred 0.2269 LossAtt 0.3743 TrainAcc 0.9400 TestAcc 0.9214 0.9000
epoch 1600 LossPred 0.2662 LossAtt 0.3536 TrainAcc 0.9200 TestAcc 0.8799 0.8850
epoch 1700 LossPred 0.2823 LossAtt 0.3442 TrainAcc 0.9200 TestAcc 0.8709 0.8750
epoch 1800 LossPred 0.1974 LossAtt 0.3523 TrainAcc 0.9200 TestAcc 0.9294 0.9250
epoch 1900 LossPred 0.2599 LossAtt 0.3613 TrainAcc 0.9200 TestAcc 0.9162 0.9050
epoch 2000 LossPred 0.3037 LossAtt 0.3382 TrainAcc 0.8900 TestAcc 0.9017 0.8850
epoch 2100 LossPred 0.2485 LossAtt 0.3607 TrainAcc 0.9100 TestAcc 0.9157 0.9150
epoch 2200 LossPred 0.2103 LossAtt 0.3518 TrainAcc 0.9400 TestAcc 0.9144 0.9350
epoch 2300 LossPred 0.1956 LossAtt 0.3557 TrainAcc 0.9300 TestAcc 0.9219 0.9300
epoch 2400 LossPred 0.1900 LossAtt 0.3498 TrainAcc 0.9500 TestAcc 0.9264 0.9400
epoch 2500 LossPred 0.4043 LossAtt 0.3491 TrainAcc 0.8700 TestAcc 0.8261 0.8400
Optimization Finished!
********** replication  80  **********
epoch   0 LossPred 1.2809 LossAtt 1.0135 TrainAcc 0.3200 TestAcc 0.4349 0.3350
epoch 100 LossPred 0.9149 LossAtt 0.4708 TrainAcc 0.6800 TestAcc 0.5348 0.6800
epoch 200 LossPred 0.8309 LossAtt 0.4089 TrainAcc 0.6800 TestAcc 0.5348 0.6700
epoch 300 LossPred 0.7679 LossAtt 0.3814 TrainAcc 0.7400 TestAcc 0.6089 0.7350
epoch 400 LossPred 0.7557 LossAtt 0.2923 TrainAcc 0.7400 TestAcc 0.6089 0.7400
epoch 500 LossPred 0.7523 LossAtt 0.2832 TrainAcc 0.7400 TestAcc 0.6089 0.7400
epoch 600 LossPred 0.7510 LossAtt 0.2491 TrainAcc 0.7400 TestAcc 0.6089 0.7400
epoch 700 LossPred 0.7419 LossAtt 0.2587 TrainAcc 0.7400 TestAcc 0.6089 0.7350
epoch 800 LossPred 0.6034 LossAtt 0.3609 TrainAcc 0.7900 TestAcc 0.7763 0.7550
epoch 900 LossPred 0.4367 LossAtt 0.3041 TrainAcc 0.8600 TestAcc 0.7955 0.8400
epoch 1000 LossPred 0.4520 LossAtt 0.3023 TrainAcc 0.8500 TestAcc 0.8526 0.8500
epoch 1100 LossPred 0.3785 LossAtt 0.3025 TrainAcc 0.8700 TestAcc 0.8296 0.8600
epoch 1200 LossPred 0.4264 LossAtt 0.2993 TrainAcc 0.8400 TestAcc 0.8136 0.8400
epoch 1300 LossPred 0.4593 LossAtt 0.3199 TrainAcc 0.8500 TestAcc 0.8539 0.8350
epoch 1400 LossPred 0.3607 LossAtt 0.2850 TrainAcc 0.8600 TestAcc 0.8378 0.8550
epoch 1500 LossPred 0.3919 LossAtt 0.3126 TrainAcc 0.8500 TestAcc 0.8148 0.8500
epoch 1600 LossPred 0.3850 LossAtt 0.2862 TrainAcc 0.8700 TestAcc 0.8343 0.8450
epoch 1700 LossPred 0.4282 LossAtt 0.2763 TrainAcc 0.8400 TestAcc 0.8168 0.8450
epoch 1800 LossPred 0.4456 LossAtt 0.2650 TrainAcc 0.8600 TestAcc 0.7968 0.8300
epoch 1900 LossPred 0.4164 LossAtt 0.3084 TrainAcc 0.8500 TestAcc 0.8536 0.8250
epoch 2000 LossPred 0.3967 LossAtt 0.2898 TrainAcc 0.8600 TestAcc 0.8231 0.8500
epoch 2100 LossPred 0.4389 LossAtt 0.2995 TrainAcc 0.8600 TestAcc 0.8514 0.8450
epoch 2200 LossPred 0.4351 LossAtt 0.2806 TrainAcc 0.8500 TestAcc 0.8303 0.8500
epoch 2300 LossPred 0.4685 LossAtt 0.2652 TrainAcc 0.8400 TestAcc 0.7788 0.8250
epoch 2400 LossPred 0.3643 LossAtt 0.2848 TrainAcc 0.8600 TestAcc 0.8436 0.8500
epoch 2500 LossPred 0.3779 LossAtt 0.2872 TrainAcc 0.8700 TestAcc 0.8436 0.8600
Optimization Finished!
********** replication  81  **********
epoch   0 LossPred 1.1750 LossAtt 1.0060 TrainAcc 0.4300 TestAcc 0.4660 0.4350
epoch 100 LossPred 0.9420 LossAtt 0.3948 TrainAcc 0.6200 TestAcc 0.5988 0.6200
epoch 200 LossPred 0.9338 LossAtt 0.3090 TrainAcc 0.6200 TestAcc 0.5988 0.6200
epoch 300 LossPred 0.9260 LossAtt 0.2334 TrainAcc 0.6200 TestAcc 0.5988 0.6200
epoch 400 LossPred 0.8678 LossAtt 0.2800 TrainAcc 0.6700 TestAcc 0.6361 0.6800
epoch 500 LossPred 1.1660 LossAtt 0.3851 TrainAcc 0.4700 TestAcc 0.5108 0.4600
epoch 600 LossPred 0.9120 LossAtt 0.3896 TrainAcc 0.6700 TestAcc 0.5691 0.6500
epoch 700 LossPred 0.8672 LossAtt 0.4281 TrainAcc 0.7000 TestAcc 0.6274 0.6750
epoch 800 LossPred 0.8935 LossAtt 0.4326 TrainAcc 0.6400 TestAcc 0.6021 0.6200
epoch 900 LossPred 0.9027 LossAtt 0.4269 TrainAcc 0.6400 TestAcc 0.5618 0.6050
epoch 1000 LossPred 0.8305 LossAtt 0.4578 TrainAcc 0.6800 TestAcc 0.6316 0.6850
epoch 1100 LossPred 0.3896 LossAtt 0.5772 TrainAcc 0.9000 TestAcc 0.8796 0.8800
epoch 1200 LossPred 0.2159 LossAtt 0.5405 TrainAcc 0.9800 TestAcc 0.9314 0.9400
epoch 1300 LossPred 0.1837 LossAtt 0.5037 TrainAcc 0.9700 TestAcc 0.9252 0.9400
epoch 1400 LossPred 0.1893 LossAtt 0.4906 TrainAcc 0.9400 TestAcc 0.8891 0.9300
epoch 1500 LossPred 0.1296 LossAtt 0.4624 TrainAcc 0.9600 TestAcc 0.9154 0.9300
epoch 1600 LossPred 0.1616 LossAtt 0.4798 TrainAcc 0.9500 TestAcc 0.8964 0.9400
epoch 1700 LossPred 0.1411 LossAtt 0.4670 TrainAcc 0.9600 TestAcc 0.9197 0.9200
epoch 1800 LossPred 0.0910 LossAtt 0.4865 TrainAcc 0.9800 TestAcc 0.9367 0.9500
epoch 1900 LossPred 0.0875 LossAtt 0.4817 TrainAcc 0.9800 TestAcc 0.9322 0.9600
epoch 2000 LossPred 0.1774 LossAtt 0.4801 TrainAcc 0.9400 TestAcc 0.8894 0.9500
epoch 2100 LossPred 0.1155 LossAtt 0.4738 TrainAcc 0.9700 TestAcc 0.9249 0.9400
epoch 2200 LossPred 0.0544 LossAtt 0.4811 TrainAcc 0.9900 TestAcc 0.9312 0.9450
epoch 2300 LossPred 0.1931 LossAtt 0.5100 TrainAcc 0.9400 TestAcc 0.8759 0.9450
epoch 2400 LossPred 0.0749 LossAtt 0.4799 TrainAcc 0.9700 TestAcc 0.9369 0.9700
epoch 2500 LossPred 0.1970 LossAtt 0.4896 TrainAcc 0.9400 TestAcc 0.8841 0.9350
Optimization Finished!
********** replication  82  **********
epoch   0 LossPred 1.2349 LossAtt 0.9971 TrainAcc 0.4300 TestAcc 0.4985 0.4400
epoch 100 LossPred 0.8817 LossAtt 0.2754 TrainAcc 0.6600 TestAcc 0.6549 0.6500
epoch 200 LossPred 0.8690 LossAtt 0.2366 TrainAcc 0.6800 TestAcc 0.6419 0.6700
epoch 300 LossPred 0.8329 LossAtt 0.2781 TrainAcc 0.6900 TestAcc 0.6154 0.6650
epoch 400 LossPred 0.6345 LossAtt 0.3125 TrainAcc 0.7900 TestAcc 0.7352 0.7600
epoch 500 LossPred 0.2707 LossAtt 0.3163 TrainAcc 0.9200 TestAcc 0.9139 0.9050
epoch 600 LossPred 0.2194 LossAtt 0.2866 TrainAcc 0.9400 TestAcc 0.9297 0.9100
epoch 700 LossPred 1.0556 LossAtt 0.3176 TrainAcc 0.6700 TestAcc 0.7125 0.6700
epoch 800 LossPred 0.4220 LossAtt 0.2740 TrainAcc 0.9100 TestAcc 0.8366 0.8900
epoch 900 LossPred 0.7357 LossAtt 0.2729 TrainAcc 0.7200 TestAcc 0.6759 0.7150
epoch 1000 LossPred 0.6807 LossAtt 0.2540 TrainAcc 0.7400 TestAcc 0.6849 0.7350
epoch 1100 LossPred 0.6772 LossAtt 0.2451 TrainAcc 0.7300 TestAcc 0.6922 0.7350
epoch 1200 LossPred 0.5949 LossAtt 0.2688 TrainAcc 0.7900 TestAcc 0.7422 0.7800
epoch 1300 LossPred 0.4036 LossAtt 0.2461 TrainAcc 0.8700 TestAcc 0.8181 0.8500
epoch 1400 LossPred 0.2583 LossAtt 0.2472 TrainAcc 0.9100 TestAcc 0.8954 0.9150
epoch 1500 LossPred 0.2612 LossAtt 0.2456 TrainAcc 0.9100 TestAcc 0.8909 0.9150
epoch 1600 LossPred 0.2722 LossAtt 0.2378 TrainAcc 0.8900 TestAcc 0.8831 0.9000
epoch 1700 LossPred 0.4130 LossAtt 0.2313 TrainAcc 0.8600 TestAcc 0.8063 0.8450
epoch 1800 LossPred 0.4187 LossAtt 0.2391 TrainAcc 0.8500 TestAcc 0.8333 0.8400
epoch 1900 LossPred 0.3637 LossAtt 0.2385 TrainAcc 0.8800 TestAcc 0.8173 0.8600
epoch 2000 LossPred 0.3396 LossAtt 0.2351 TrainAcc 0.8900 TestAcc 0.8311 0.9000
epoch 2100 LossPred 0.3035 LossAtt 0.2783 TrainAcc 0.8800 TestAcc 0.8801 0.8850
epoch 2200 LossPred 0.2877 LossAtt 0.2466 TrainAcc 0.9000 TestAcc 0.8771 0.9050
epoch 2300 LossPred 0.2952 LossAtt 0.2465 TrainAcc 0.9000 TestAcc 0.8799 0.9050
epoch 2400 LossPred 0.2941 LossAtt 0.2406 TrainAcc 0.8800 TestAcc 0.8729 0.8950
epoch 2500 LossPred 0.2826 LossAtt 0.2500 TrainAcc 0.8800 TestAcc 0.8789 0.8900
Optimization Finished!
********** replication  83  **********
epoch   0 LossPred 0.9351 LossAtt 0.9990 TrainAcc 0.6200 TestAcc 0.5833 0.6450
epoch 100 LossPred 0.8709 LossAtt 0.4304 TrainAcc 0.6600 TestAcc 0.6054 0.6600
epoch 200 LossPred 0.8504 LossAtt 0.4904 TrainAcc 0.6600 TestAcc 0.6054 0.6350
epoch 300 LossPred 0.4526 LossAtt 0.4048 TrainAcc 0.8500 TestAcc 0.8216 0.8150
epoch 400 LossPred 0.2736 LossAtt 0.4233 TrainAcc 0.9200 TestAcc 0.8974 0.8950
epoch 500 LossPred 0.3852 LossAtt 0.4371 TrainAcc 0.8300 TestAcc 0.8726 0.8300
epoch 600 LossPred 0.5851 LossAtt 0.3930 TrainAcc 0.8100 TestAcc 0.7740 0.8250
epoch 700 LossPred 0.3215 LossAtt 0.4214 TrainAcc 0.8700 TestAcc 0.9244 0.8600
epoch 800 LossPred 0.4810 LossAtt 0.3827 TrainAcc 0.8200 TestAcc 0.8326 0.8250
epoch 900 LossPred 0.3436 LossAtt 0.3803 TrainAcc 0.8600 TestAcc 0.8794 0.8800
epoch 1000 LossPred 0.4890 LossAtt 0.3649 TrainAcc 0.8500 TestAcc 0.8096 0.8450
epoch 1100 LossPred 0.3044 LossAtt 0.3775 TrainAcc 0.9100 TestAcc 0.9372 0.8600
epoch 1200 LossPred 0.4574 LossAtt 0.3684 TrainAcc 0.8400 TestAcc 0.8511 0.8250
epoch 1300 LossPred 0.4212 LossAtt 0.3634 TrainAcc 0.8300 TestAcc 0.8163 0.8550
epoch 1400 LossPred 0.3381 LossAtt 0.3751 TrainAcc 0.8700 TestAcc 0.8569 0.8650
epoch 1500 LossPred 0.3546 LossAtt 0.3753 TrainAcc 0.8900 TestAcc 0.9054 0.8800
epoch 1600 LossPred 0.3366 LossAtt 0.3805 TrainAcc 0.8600 TestAcc 0.8524 0.8700
epoch 1700 LossPred 0.5586 LossAtt 0.3835 TrainAcc 0.8300 TestAcc 0.7730 0.8200
epoch 1800 LossPred 0.2753 LossAtt 0.4011 TrainAcc 0.9000 TestAcc 0.8591 0.9000
epoch 1900 LossPred 0.4165 LossAtt 0.3891 TrainAcc 0.8400 TestAcc 0.8148 0.8400
epoch 2000 LossPred 0.2127 LossAtt 0.4097 TrainAcc 0.9400 TestAcc 0.9184 0.9050
epoch 2100 LossPred 0.2660 LossAtt 0.4168 TrainAcc 0.9100 TestAcc 0.8786 0.9100
epoch 2200 LossPred 0.3544 LossAtt 0.4057 TrainAcc 0.8500 TestAcc 0.8276 0.8700
epoch 2300 LossPred 0.4608 LossAtt 0.4466 TrainAcc 0.8600 TestAcc 0.8006 0.8450
epoch 2400 LossPred 0.3843 LossAtt 0.4234 TrainAcc 0.8700 TestAcc 0.8143 0.8750
epoch 2500 LossPred 0.3098 LossAtt 0.4346 TrainAcc 0.8900 TestAcc 0.8328 0.8800
Optimization Finished!
********** replication  84  **********
epoch   0 LossPred 1.1418 LossAtt 1.0186 TrainAcc 0.4700 TestAcc 0.4647 0.4600
epoch 100 LossPred 0.9189 LossAtt 0.3903 TrainAcc 0.6500 TestAcc 0.6066 0.6500
epoch 200 LossPred 0.8708 LossAtt 0.3183 TrainAcc 0.6500 TestAcc 0.6066 0.6650
epoch 300 LossPred 0.4119 LossAtt 0.3377 TrainAcc 0.8900 TestAcc 0.8574 0.8450
epoch 400 LossPred 0.3271 LossAtt 0.3359 TrainAcc 0.9000 TestAcc 0.8729 0.8650
epoch 500 LossPred 0.3342 LossAtt 0.3133 TrainAcc 0.8800 TestAcc 0.8766 0.8650
epoch 600 LossPred 0.3082 LossAtt 0.3169 TrainAcc 0.9000 TestAcc 0.8716 0.8700
epoch 700 LossPred 0.2951 LossAtt 0.3009 TrainAcc 0.9000 TestAcc 0.8704 0.8750
epoch 800 LossPred 0.2871 LossAtt 0.2882 TrainAcc 0.9000 TestAcc 0.8691 0.8800
epoch 900 LossPred 0.2891 LossAtt 0.2669 TrainAcc 0.9200 TestAcc 0.8854 0.8700
epoch 1000 LossPred 0.2773 LossAtt 0.2720 TrainAcc 0.9100 TestAcc 0.8771 0.8850
epoch 1100 LossPred 0.2586 LossAtt 0.2792 TrainAcc 0.9000 TestAcc 0.8916 0.8950
epoch 1200 LossPred 0.2660 LossAtt 0.2623 TrainAcc 0.9000 TestAcc 0.8736 0.8800
epoch 1300 LossPred 0.2552 LossAtt 0.2681 TrainAcc 0.9300 TestAcc 0.8979 0.8700
epoch 1400 LossPred 0.3123 LossAtt 0.2600 TrainAcc 0.9000 TestAcc 0.8724 0.8500
epoch 1500 LossPred 0.2376 LossAtt 0.2733 TrainAcc 0.9100 TestAcc 0.8989 0.9000
epoch 1600 LossPred 0.2308 LossAtt 0.2573 TrainAcc 0.9000 TestAcc 0.9017 0.9250
epoch 1700 LossPred 0.2368 LossAtt 0.2839 TrainAcc 0.9200 TestAcc 0.9044 0.8800
epoch 1800 LossPred 0.2315 LossAtt 0.2723 TrainAcc 0.9100 TestAcc 0.9032 0.9000
epoch 1900 LossPred 0.2180 LossAtt 0.2808 TrainAcc 0.9400 TestAcc 0.9114 0.8850
epoch 2000 LossPred 0.2191 LossAtt 0.2690 TrainAcc 0.9100 TestAcc 0.9057 0.9100
epoch 2100 LossPred 0.2044 LossAtt 0.2967 TrainAcc 0.9200 TestAcc 0.9167 0.9250
epoch 2200 LossPred 0.2151 LossAtt 0.2923 TrainAcc 0.9300 TestAcc 0.9052 0.9150
epoch 2300 LossPred 0.2546 LossAtt 0.2965 TrainAcc 0.9100 TestAcc 0.8931 0.8700
epoch 2400 LossPred 0.2200 LossAtt 0.2886 TrainAcc 0.9300 TestAcc 0.9064 0.9000
epoch 2500 LossPred 0.1862 LossAtt 0.2848 TrainAcc 0.9300 TestAcc 0.9297 0.9350
Optimization Finished!
********** replication  85  **********
epoch   0 LossPred 1.1454 LossAtt 1.0610 TrainAcc 0.4400 TestAcc 0.4632 0.4250
epoch 100 LossPred 0.9459 LossAtt 0.3217 TrainAcc 0.5500 TestAcc 0.4960 0.5450
epoch 200 LossPred 0.9363 LossAtt 0.2217 TrainAcc 0.6100 TestAcc 0.6091 0.5800
epoch 300 LossPred 0.9258 LossAtt 0.2786 TrainAcc 0.6000 TestAcc 0.6349 0.5850
epoch 400 LossPred 0.8938 LossAtt 0.3682 TrainAcc 0.6300 TestAcc 0.6484 0.6200
epoch 500 LossPred 0.5689 LossAtt 0.4256 TrainAcc 0.8100 TestAcc 0.7558 0.8250
epoch 600 LossPred 0.3769 LossAtt 0.4658 TrainAcc 0.9100 TestAcc 0.8398 0.8900
epoch 700 LossPred 0.2957 LossAtt 0.4670 TrainAcc 0.9200 TestAcc 0.8641 0.8900
epoch 800 LossPred 0.2580 LossAtt 0.4378 TrainAcc 0.9100 TestAcc 0.8621 0.9050
epoch 900 LossPred 0.3223 LossAtt 0.4381 TrainAcc 0.8600 TestAcc 0.8866 0.8450
epoch 1000 LossPred 0.5618 LossAtt 0.4563 TrainAcc 0.8300 TestAcc 0.7853 0.8350
epoch 1100 LossPred 0.3237 LossAtt 0.4690 TrainAcc 0.8900 TestAcc 0.8801 0.8700
epoch 1200 LossPred 0.2155 LossAtt 0.4512 TrainAcc 0.9600 TestAcc 0.9152 0.8900
epoch 1300 LossPred 0.2513 LossAtt 0.4479 TrainAcc 0.9200 TestAcc 0.8661 0.8950
epoch 1400 LossPred 0.1869 LossAtt 0.4429 TrainAcc 0.9300 TestAcc 0.8909 0.8950
epoch 1500 LossPred 0.2205 LossAtt 0.4710 TrainAcc 0.9100 TestAcc 0.8809 0.8850
epoch 1600 LossPred 0.2077 LossAtt 0.4245 TrainAcc 0.9200 TestAcc 0.8881 0.9150
epoch 1700 LossPred 0.1789 LossAtt 0.4239 TrainAcc 0.9300 TestAcc 0.8981 0.9000
epoch 1800 LossPred 0.1202 LossAtt 0.4302 TrainAcc 0.9600 TestAcc 0.9032 0.9350
epoch 1900 LossPred 0.1871 LossAtt 0.4298 TrainAcc 0.9300 TestAcc 0.8984 0.9250
epoch 2000 LossPred 0.1887 LossAtt 0.4192 TrainAcc 0.9500 TestAcc 0.9014 0.9200
epoch 2100 LossPred 0.1057 LossAtt 0.4392 TrainAcc 0.9600 TestAcc 0.9077 0.9250
epoch 2200 LossPred 0.1139 LossAtt 0.4847 TrainAcc 0.9700 TestAcc 0.8966 0.9400
epoch 2300 LossPred 0.2725 LossAtt 0.5069 TrainAcc 0.9100 TestAcc 0.8819 0.8950
epoch 2400 LossPred 0.4183 LossAtt 0.4233 TrainAcc 0.8900 TestAcc 0.8243 0.8650
epoch 2500 LossPred 0.2418 LossAtt 0.4503 TrainAcc 0.9200 TestAcc 0.8954 0.9050
Optimization Finished!
********** replication  86  **********
epoch   0 LossPred 1.1250 LossAtt 1.0201 TrainAcc 0.4300 TestAcc 0.3991 0.4450
epoch 100 LossPred 0.9594 LossAtt 0.4277 TrainAcc 0.6000 TestAcc 0.5891 0.6000
epoch 200 LossPred 0.9264 LossAtt 0.4514 TrainAcc 0.6000 TestAcc 0.6104 0.5950
epoch 300 LossPred 0.4876 LossAtt 0.4875 TrainAcc 0.8600 TestAcc 0.8241 0.8700
epoch 400 LossPred 0.2919 LossAtt 0.4728 TrainAcc 0.9200 TestAcc 0.9194 0.9300
epoch 500 LossPred 0.3000 LossAtt 0.4608 TrainAcc 0.8900 TestAcc 0.8634 0.8900
epoch 600 LossPred 0.2746 LossAtt 0.4386 TrainAcc 0.9000 TestAcc 0.8779 0.9150
epoch 700 LossPred 0.3393 LossAtt 0.4232 TrainAcc 0.8900 TestAcc 0.8351 0.8800
epoch 800 LossPred 0.2199 LossAtt 0.4548 TrainAcc 0.9700 TestAcc 0.9582 0.9500
epoch 900 LossPred 0.2023 LossAtt 0.4857 TrainAcc 0.9500 TestAcc 0.9414 0.9350
epoch 1000 LossPred 0.2265 LossAtt 0.4558 TrainAcc 0.9300 TestAcc 0.8654 0.9250
epoch 1100 LossPred 0.1674 LossAtt 0.4729 TrainAcc 0.9600 TestAcc 0.9357 0.9400
epoch 1200 LossPred 0.1284 LossAtt 0.4921 TrainAcc 0.9700 TestAcc 0.9254 0.9500
epoch 1300 LossPred 0.1417 LossAtt 0.4713 TrainAcc 0.9800 TestAcc 0.8926 0.9550
epoch 1400 LossPred 0.1357 LossAtt 0.4966 TrainAcc 0.9400 TestAcc 0.9077 0.9300
epoch 1500 LossPred 0.1255 LossAtt 0.4931 TrainAcc 0.9700 TestAcc 0.9229 0.9500
epoch 1600 LossPred 0.1071 LossAtt 0.4743 TrainAcc 0.9800 TestAcc 0.9044 0.9500
epoch 1700 LossPred 0.1112 LossAtt 0.4596 TrainAcc 0.9700 TestAcc 0.9112 0.9500
epoch 1800 LossPred 0.0909 LossAtt 0.4639 TrainAcc 0.9800 TestAcc 0.9139 0.9600
epoch 1900 LossPred 0.1209 LossAtt 0.4661 TrainAcc 0.9600 TestAcc 0.9194 0.9400
epoch 2000 LossPred 0.0885 LossAtt 0.4607 TrainAcc 0.9700 TestAcc 0.9124 0.9650
epoch 2100 LossPred 0.0782 LossAtt 0.4765 TrainAcc 0.9800 TestAcc 0.9094 0.9650
epoch 2200 LossPred 0.0791 LossAtt 0.4580 TrainAcc 0.9800 TestAcc 0.9149 0.9650
epoch 2300 LossPred 0.0861 LossAtt 0.4519 TrainAcc 0.9700 TestAcc 0.9047 0.9650
epoch 2400 LossPred 0.0933 LossAtt 0.4738 TrainAcc 0.9800 TestAcc 0.9147 0.9650
epoch 2500 LossPred 0.0796 LossAtt 0.4653 TrainAcc 0.9700 TestAcc 0.9112 0.9550
Optimization Finished!
********** replication  87  **********
epoch   0 LossPred 1.0520 LossAtt 1.0277 TrainAcc 0.5600 TestAcc 0.5526 0.5850
epoch 100 LossPred 0.8937 LossAtt 0.4338 TrainAcc 0.6500 TestAcc 0.5976 0.6650
epoch 200 LossPred 0.8522 LossAtt 0.4248 TrainAcc 0.6700 TestAcc 0.6386 0.6750
epoch 300 LossPred 0.5208 LossAtt 0.4568 TrainAcc 0.8100 TestAcc 0.8438 0.8150
epoch 400 LossPred 0.4403 LossAtt 0.4404 TrainAcc 0.8300 TestAcc 0.8599 0.8200
epoch 500 LossPred 0.3987 LossAtt 0.4165 TrainAcc 0.8700 TestAcc 0.8931 0.8150
epoch 600 LossPred 0.3616 LossAtt 0.4098 TrainAcc 0.9100 TestAcc 0.9247 0.8450
epoch 700 LossPred 0.3098 LossAtt 0.4307 TrainAcc 0.9200 TestAcc 0.9264 0.8300
epoch 800 LossPred 0.3901 LossAtt 0.4039 TrainAcc 0.8800 TestAcc 0.8671 0.8550
epoch 900 LossPred 0.3422 LossAtt 0.4038 TrainAcc 0.8900 TestAcc 0.8961 0.8400
epoch 1000 LossPred 0.3182 LossAtt 0.4143 TrainAcc 0.9200 TestAcc 0.9249 0.8350
epoch 1100 LossPred 0.3053 LossAtt 0.4116 TrainAcc 0.9200 TestAcc 0.9377 0.8400
epoch 1200 LossPred 0.2833 LossAtt 0.3926 TrainAcc 0.9300 TestAcc 0.9347 0.8450
epoch 1300 LossPred 0.2838 LossAtt 0.4010 TrainAcc 0.9000 TestAcc 0.9267 0.8500
epoch 1400 LossPred 0.2779 LossAtt 0.3911 TrainAcc 0.9300 TestAcc 0.9462 0.8400
epoch 1500 LossPred 0.2635 LossAtt 0.3898 TrainAcc 0.9100 TestAcc 0.9467 0.8550
epoch 1600 LossPred 0.3077 LossAtt 0.4096 TrainAcc 0.8800 TestAcc 0.9182 0.8550
epoch 1700 LossPred 0.3087 LossAtt 0.4054 TrainAcc 0.9000 TestAcc 0.9154 0.8500
epoch 1800 LossPred 0.3259 LossAtt 0.3939 TrainAcc 0.8900 TestAcc 0.9267 0.8600
epoch 1900 LossPred 0.2465 LossAtt 0.4074 TrainAcc 0.9100 TestAcc 0.9512 0.8700
epoch 2000 LossPred 0.3931 LossAtt 0.3886 TrainAcc 0.8400 TestAcc 0.8986 0.8250
epoch 2100 LossPred 0.4790 LossAtt 0.3919 TrainAcc 0.8300 TestAcc 0.8551 0.8300
epoch 2200 LossPred 0.3326 LossAtt 0.4149 TrainAcc 0.8800 TestAcc 0.9277 0.8300
epoch 2300 LossPred 0.2917 LossAtt 0.4206 TrainAcc 0.8900 TestAcc 0.9377 0.8350
epoch 2400 LossPred 0.2215 LossAtt 0.3827 TrainAcc 0.9400 TestAcc 0.9615 0.8550
epoch 2500 LossPred 0.2056 LossAtt 0.4259 TrainAcc 0.9500 TestAcc 0.9640 0.8600
Optimization Finished!
********** replication  88  **********
epoch   0 LossPred 1.2744 LossAtt 1.0081 TrainAcc 0.5000 TestAcc 0.4277 0.4650
epoch 100 LossPred 0.9923 LossAtt 0.4431 TrainAcc 0.6100 TestAcc 0.5355 0.5700
epoch 200 LossPred 0.9475 LossAtt 0.4455 TrainAcc 0.6000 TestAcc 0.5663 0.6150
epoch 300 LossPred 0.9217 LossAtt 0.4743 TrainAcc 0.6100 TestAcc 0.5741 0.6150
epoch 400 LossPred 0.5970 LossAtt 0.5432 TrainAcc 0.8500 TestAcc 0.7993 0.8350
epoch 500 LossPred 0.3319 LossAtt 0.5531 TrainAcc 0.9500 TestAcc 0.8616 0.9100
epoch 600 LossPred 0.2457 LossAtt 0.5457 TrainAcc 0.9400 TestAcc 0.8478 0.9450
epoch 700 LossPred 0.2598 LossAtt 0.5123 TrainAcc 0.9200 TestAcc 0.8483 0.9250
epoch 800 LossPred 0.2234 LossAtt 0.4920 TrainAcc 0.9200 TestAcc 0.8569 0.9150
epoch 900 LossPred 0.2123 LossAtt 0.4920 TrainAcc 0.9300 TestAcc 0.8466 0.9250
epoch 1000 LossPred 0.1779 LossAtt 0.4915 TrainAcc 0.9500 TestAcc 0.8564 0.9450
epoch 1100 LossPred 0.1844 LossAtt 0.4872 TrainAcc 0.9500 TestAcc 0.8579 0.9300
epoch 1200 LossPred 0.1793 LossAtt 0.5282 TrainAcc 0.9400 TestAcc 0.8551 0.9400
epoch 1300 LossPred 0.1550 LossAtt 0.5148 TrainAcc 0.9700 TestAcc 0.8721 0.9600
epoch 1400 LossPred 0.1841 LossAtt 0.4918 TrainAcc 0.9600 TestAcc 0.8759 0.9450
epoch 1500 LossPred 0.1714 LossAtt 0.4811 TrainAcc 0.9600 TestAcc 0.8811 0.9550
epoch 1600 LossPred 0.2073 LossAtt 0.4899 TrainAcc 0.9300 TestAcc 0.8801 0.9300
epoch 1700 LossPred 0.1753 LossAtt 0.4995 TrainAcc 0.9500 TestAcc 0.8636 0.9350
epoch 1800 LossPred 0.1692 LossAtt 0.4966 TrainAcc 0.9400 TestAcc 0.8676 0.9450
epoch 1900 LossPred 0.2598 LossAtt 0.4850 TrainAcc 0.9200 TestAcc 0.8764 0.8950
epoch 2000 LossPred 0.3041 LossAtt 0.5132 TrainAcc 0.8800 TestAcc 0.8716 0.8700
epoch 2100 LossPred 0.1673 LossAtt 0.4962 TrainAcc 0.9400 TestAcc 0.8669 0.9400
epoch 2200 LossPred 0.1947 LossAtt 0.4970 TrainAcc 0.9200 TestAcc 0.8866 0.9200
epoch 2300 LossPred 0.1264 LossAtt 0.4647 TrainAcc 0.9600 TestAcc 0.8749 0.9550
epoch 2400 LossPred 0.1466 LossAtt 0.4844 TrainAcc 0.9600 TestAcc 0.8734 0.9500
epoch 2500 LossPred 0.1275 LossAtt 0.4785 TrainAcc 0.9500 TestAcc 0.8924 0.9300
Optimization Finished!
********** replication  89  **********
epoch   0 LossPred 0.9847 LossAtt 0.9937 TrainAcc 0.5600 TestAcc 0.5323 0.5450
epoch 100 LossPred 0.9382 LossAtt 0.4842 TrainAcc 0.5900 TestAcc 0.6146 0.5950
epoch 200 LossPred 0.8047 LossAtt 0.5316 TrainAcc 0.7300 TestAcc 0.6984 0.7100
epoch 300 LossPred 0.6403 LossAtt 0.4738 TrainAcc 0.7800 TestAcc 0.7430 0.7800
epoch 400 LossPred 0.3605 LossAtt 0.4828 TrainAcc 0.9100 TestAcc 0.9037 0.8950
epoch 500 LossPred 0.3816 LossAtt 0.4590 TrainAcc 0.8700 TestAcc 0.8468 0.8600
epoch 600 LossPred 0.3525 LossAtt 0.4414 TrainAcc 0.8800 TestAcc 0.8461 0.8650
epoch 700 LossPred 0.2732 LossAtt 0.3865 TrainAcc 0.9200 TestAcc 0.9177 0.9150
epoch 800 LossPred 0.2982 LossAtt 0.3674 TrainAcc 0.8800 TestAcc 0.9207 0.8850
epoch 900 LossPred 0.2514 LossAtt 0.3751 TrainAcc 0.9200 TestAcc 0.9284 0.9100
epoch 1000 LossPred 0.2007 LossAtt 0.3652 TrainAcc 0.9600 TestAcc 0.9212 0.9650
epoch 1100 LossPred 0.1873 LossAtt 0.3450 TrainAcc 0.9600 TestAcc 0.9244 0.9700
epoch 1200 LossPred 0.1960 LossAtt 0.3557 TrainAcc 0.9500 TestAcc 0.8931 0.9350
epoch 1300 LossPred 0.1796 LossAtt 0.3427 TrainAcc 0.9600 TestAcc 0.9002 0.9450
epoch 1400 LossPred 0.2582 LossAtt 0.3522 TrainAcc 0.9000 TestAcc 0.8601 0.8850
epoch 1500 LossPred 0.1589 LossAtt 0.3480 TrainAcc 0.9600 TestAcc 0.9057 0.9500
epoch 1600 LossPred 0.1515 LossAtt 0.3270 TrainAcc 0.9700 TestAcc 0.9139 0.9550
epoch 1700 LossPred 0.1933 LossAtt 0.3461 TrainAcc 0.9500 TestAcc 0.8966 0.9300
epoch 1800 LossPred 0.1907 LossAtt 0.3302 TrainAcc 0.9400 TestAcc 0.9347 0.9100
epoch 1900 LossPred 0.1302 LossAtt 0.3433 TrainAcc 0.9900 TestAcc 0.9502 0.9600
epoch 2000 LossPred 0.3610 LossAtt 0.3396 TrainAcc 0.8600 TestAcc 0.8493 0.8800
epoch 2100 LossPred 0.1183 LossAtt 0.3406 TrainAcc 0.9900 TestAcc 0.9394 0.9600
epoch 2200 LossPred 0.1396 LossAtt 0.3412 TrainAcc 0.9600 TestAcc 0.9372 0.9500
epoch 2300 LossPred 0.1089 LossAtt 0.3262 TrainAcc 0.9900 TestAcc 0.9334 0.9500
epoch 2400 LossPred 0.1085 LossAtt 0.3439 TrainAcc 0.9900 TestAcc 0.9424 0.9650
epoch 2500 LossPred 0.1683 LossAtt 0.3561 TrainAcc 0.9400 TestAcc 0.8829 0.9350
Optimization Finished!
********** replication  90  **********
epoch   0 LossPred 1.2448 LossAtt 1.0054 TrainAcc 0.5200 TestAcc 0.4287 0.5100
epoch 100 LossPred 0.9827 LossAtt 0.5124 TrainAcc 0.5500 TestAcc 0.4815 0.5600
epoch 200 LossPred 0.8991 LossAtt 0.5621 TrainAcc 0.6800 TestAcc 0.6034 0.6650
epoch 300 LossPred 0.8147 LossAtt 0.5687 TrainAcc 0.7200 TestAcc 0.6542 0.7350
epoch 400 LossPred 0.3245 LossAtt 0.5181 TrainAcc 0.9100 TestAcc 0.8766 0.9050
epoch 500 LossPred 0.2564 LossAtt 0.5203 TrainAcc 0.9400 TestAcc 0.9007 0.9150
epoch 600 LossPred 0.2061 LossAtt 0.5052 TrainAcc 0.9100 TestAcc 0.8939 0.9400
epoch 700 LossPred 0.2403 LossAtt 0.5234 TrainAcc 0.8800 TestAcc 0.8906 0.9000
epoch 800 LossPred 0.1786 LossAtt 0.5028 TrainAcc 0.9400 TestAcc 0.8836 0.9350
epoch 900 LossPred 0.1754 LossAtt 0.5019 TrainAcc 0.9600 TestAcc 0.9072 0.9500
epoch 1000 LossPred 0.1588 LossAtt 0.4877 TrainAcc 0.9400 TestAcc 0.8804 0.9500
epoch 1100 LossPred 0.1472 LossAtt 0.4790 TrainAcc 0.9500 TestAcc 0.8944 0.9500
epoch 1200 LossPred 0.1497 LossAtt 0.4881 TrainAcc 0.9500 TestAcc 0.8846 0.9500
epoch 1300 LossPred 0.1407 LossAtt 0.4659 TrainAcc 0.9500 TestAcc 0.8876 0.9500
epoch 1400 LossPred 0.1364 LossAtt 0.4616 TrainAcc 0.9500 TestAcc 0.8919 0.9500
epoch 1500 LossPred 0.1701 LossAtt 0.4557 TrainAcc 0.9400 TestAcc 0.9084 0.9600
epoch 1600 LossPred 0.1384 LossAtt 0.4453 TrainAcc 0.9600 TestAcc 0.8826 0.9500
epoch 1700 LossPred 0.1296 LossAtt 0.4567 TrainAcc 0.9600 TestAcc 0.8931 0.9500
epoch 1800 LossPred 0.1337 LossAtt 0.4362 TrainAcc 0.9600 TestAcc 0.9004 0.9600
epoch 1900 LossPred 0.1231 LossAtt 0.4265 TrainAcc 0.9700 TestAcc 0.8979 0.9500
epoch 2000 LossPred 0.1222 LossAtt 0.4366 TrainAcc 0.9700 TestAcc 0.8934 0.9550
epoch 2100 LossPred 0.1240 LossAtt 0.4194 TrainAcc 0.9600 TestAcc 0.9014 0.9500
epoch 2200 LossPred 0.1346 LossAtt 0.4458 TrainAcc 0.9600 TestAcc 0.9022 0.9600
epoch 2300 LossPred 0.1337 LossAtt 0.4356 TrainAcc 0.9600 TestAcc 0.9099 0.9650
epoch 2400 LossPred 0.1095 LossAtt 0.4280 TrainAcc 0.9700 TestAcc 0.9037 0.9600
epoch 2500 LossPred 0.1581 LossAtt 0.4266 TrainAcc 0.9300 TestAcc 0.8746 0.9350
Optimization Finished!
********** replication  91  **********
epoch   0 LossPred 0.9808 LossAtt 0.9876 TrainAcc 0.5400 TestAcc 0.4970 0.5350
epoch 100 LossPred 0.8890 LossAtt 0.4524 TrainAcc 0.6500 TestAcc 0.6004 0.6500
epoch 200 LossPred 0.8816 LossAtt 0.3424 TrainAcc 0.6500 TestAcc 0.6004 0.6550
epoch 300 LossPred 0.8892 LossAtt 0.3151 TrainAcc 0.6500 TestAcc 0.6004 0.6500
epoch 400 LossPred 0.7643 LossAtt 0.3885 TrainAcc 0.6600 TestAcc 0.7523 0.6650
epoch 500 LossPred 0.3343 LossAtt 0.4351 TrainAcc 0.9200 TestAcc 0.8934 0.9100
epoch 600 LossPred 0.2926 LossAtt 0.4544 TrainAcc 0.9300 TestAcc 0.8844 0.9000
epoch 700 LossPred 0.3135 LossAtt 0.4007 TrainAcc 0.9200 TestAcc 0.8589 0.8850
epoch 800 LossPred 0.3568 LossAtt 0.4103 TrainAcc 0.8900 TestAcc 0.8306 0.8800
epoch 900 LossPred 0.3244 LossAtt 0.3802 TrainAcc 0.9000 TestAcc 0.8861 0.9150
epoch 1000 LossPred 0.3241 LossAtt 0.4450 TrainAcc 0.8900 TestAcc 0.8781 0.9000
epoch 1100 LossPred 0.3465 LossAtt 0.4391 TrainAcc 0.8700 TestAcc 0.8373 0.8650
epoch 1200 LossPred 0.3355 LossAtt 0.4338 TrainAcc 0.9000 TestAcc 0.8531 0.8650
epoch 1300 LossPred 0.2717 LossAtt 0.4349 TrainAcc 0.9200 TestAcc 0.9007 0.9000
epoch 1400 LossPred 0.3176 LossAtt 0.3941 TrainAcc 0.9000 TestAcc 0.8841 0.8850
epoch 1500 LossPred 0.2417 LossAtt 0.4065 TrainAcc 0.9100 TestAcc 0.9059 0.9100
epoch 1600 LossPred 0.3225 LossAtt 0.4072 TrainAcc 0.8900 TestAcc 0.8699 0.8950
epoch 1700 LossPred 0.2376 LossAtt 0.3732 TrainAcc 0.9200 TestAcc 0.8936 0.9100
epoch 1800 LossPred 0.3178 LossAtt 0.3631 TrainAcc 0.8800 TestAcc 0.8619 0.8750
epoch 1900 LossPred 0.3573 LossAtt 0.3672 TrainAcc 0.8700 TestAcc 0.8519 0.8750
epoch 2000 LossPred 0.2094 LossAtt 0.3444 TrainAcc 0.9400 TestAcc 0.9054 0.9150
epoch 2100 LossPred 0.2470 LossAtt 0.3539 TrainAcc 0.9200 TestAcc 0.8989 0.9100
epoch 2200 LossPred 0.3571 LossAtt 0.3407 TrainAcc 0.8600 TestAcc 0.8591 0.8650
epoch 2300 LossPred 0.1659 LossAtt 0.3504 TrainAcc 0.9600 TestAcc 0.9247 0.9350
epoch 2400 LossPred 0.1597 LossAtt 0.3701 TrainAcc 0.9600 TestAcc 0.9244 0.9400
epoch 2500 LossPred 0.3067 LossAtt 0.3373 TrainAcc 0.8900 TestAcc 0.8829 0.9050
Optimization Finished!
********** replication  92  **********
epoch   0 LossPred 1.3354 LossAtt 0.9970 TrainAcc 0.4200 TestAcc 0.4484 0.4250
epoch 100 LossPred 1.0296 LossAtt 0.3952 TrainAcc 0.5200 TestAcc 0.5078 0.4900
epoch 200 LossPred 0.9311 LossAtt 0.2793 TrainAcc 0.6500 TestAcc 0.6111 0.6500
epoch 300 LossPred 0.9084 LossAtt 0.2241 TrainAcc 0.6500 TestAcc 0.6111 0.6500
epoch 400 LossPred 0.8935 LossAtt 0.2396 TrainAcc 0.6500 TestAcc 0.6111 0.6500
epoch 500 LossPred 0.6563 LossAtt 0.4265 TrainAcc 0.8100 TestAcc 0.8391 0.7900
epoch 600 LossPred 0.6000 LossAtt 0.4122 TrainAcc 0.7500 TestAcc 0.8011 0.7750
epoch 700 LossPred 0.5064 LossAtt 0.4176 TrainAcc 0.8600 TestAcc 0.8246 0.8300
epoch 800 LossPred 0.5133 LossAtt 0.4263 TrainAcc 0.8300 TestAcc 0.8288 0.8250
epoch 900 LossPred 0.3367 LossAtt 0.4421 TrainAcc 0.9000 TestAcc 0.8579 0.8900
epoch 1000 LossPred 0.3470 LossAtt 0.4462 TrainAcc 0.9200 TestAcc 0.8483 0.8550
epoch 1100 LossPred 0.3707 LossAtt 0.4765 TrainAcc 0.8900 TestAcc 0.8466 0.8700
epoch 1200 LossPred 0.2807 LossAtt 0.5097 TrainAcc 0.9200 TestAcc 0.8524 0.8950
epoch 1300 LossPred 0.4046 LossAtt 0.4751 TrainAcc 0.8600 TestAcc 0.8088 0.8650
epoch 1400 LossPred 0.3393 LossAtt 0.4964 TrainAcc 0.9200 TestAcc 0.8398 0.8850
epoch 1500 LossPred 0.3336 LossAtt 0.4814 TrainAcc 0.8900 TestAcc 0.8178 0.9050
epoch 1600 LossPred 0.2326 LossAtt 0.4909 TrainAcc 0.9500 TestAcc 0.8509 0.8950
epoch 1700 LossPred 0.3074 LossAtt 0.4846 TrainAcc 0.9100 TestAcc 0.8293 0.9000
epoch 1800 LossPred 0.3302 LossAtt 0.4713 TrainAcc 0.9000 TestAcc 0.8446 0.8700
epoch 1900 LossPred 0.2300 LossAtt 0.4818 TrainAcc 0.9300 TestAcc 0.8501 0.8950
epoch 2000 LossPred 0.1694 LossAtt 0.4795 TrainAcc 0.9600 TestAcc 0.8514 0.9250
epoch 2100 LossPred 0.3721 LossAtt 0.4762 TrainAcc 0.8700 TestAcc 0.8186 0.8900
epoch 2200 LossPred 0.3473 LossAtt 0.4905 TrainAcc 0.8800 TestAcc 0.8208 0.8600
epoch 2300 LossPred 0.2081 LossAtt 0.4848 TrainAcc 0.9500 TestAcc 0.8428 0.9000
epoch 2400 LossPred 0.1673 LossAtt 0.4640 TrainAcc 0.9600 TestAcc 0.8531 0.8850
epoch 2500 LossPred 0.3659 LossAtt 0.4697 TrainAcc 0.8800 TestAcc 0.8333 0.8700
Optimization Finished!
********** replication  93  **********
epoch   0 LossPred 1.0851 LossAtt 1.0284 TrainAcc 0.5400 TestAcc 0.5445 0.5400
epoch 100 LossPred 0.9293 LossAtt 0.4971 TrainAcc 0.6300 TestAcc 0.5956 0.6300
epoch 200 LossPred 0.8892 LossAtt 0.5122 TrainAcc 0.6300 TestAcc 0.5956 0.6300
epoch 300 LossPred 0.7959 LossAtt 0.5295 TrainAcc 0.7400 TestAcc 0.6837 0.7100
epoch 400 LossPred 0.4375 LossAtt 0.4771 TrainAcc 0.8300 TestAcc 0.8724 0.8550
epoch 500 LossPred 0.4406 LossAtt 0.4391 TrainAcc 0.8500 TestAcc 0.8306 0.8550
epoch 600 LossPred 0.3288 LossAtt 0.4408 TrainAcc 0.8800 TestAcc 0.8706 0.8800
epoch 700 LossPred 0.3023 LossAtt 0.4165 TrainAcc 0.9100 TestAcc 0.9037 0.8850
epoch 800 LossPred 0.2800 LossAtt 0.4416 TrainAcc 0.8800 TestAcc 0.8919 0.9100
epoch 900 LossPred 0.1622 LossAtt 0.4335 TrainAcc 0.9700 TestAcc 0.9452 0.9300
epoch 1000 LossPred 0.1459 LossAtt 0.4635 TrainAcc 0.9600 TestAcc 0.9472 0.9450
epoch 1100 LossPred 0.1522 LossAtt 0.4326 TrainAcc 0.9800 TestAcc 0.9525 0.9500
epoch 1200 LossPred 0.1307 LossAtt 0.4502 TrainAcc 0.9700 TestAcc 0.9627 0.9500
epoch 1300 LossPred 0.1273 LossAtt 0.4457 TrainAcc 0.9800 TestAcc 0.9535 0.9500
epoch 1400 LossPred 0.1735 LossAtt 0.4279 TrainAcc 0.9300 TestAcc 0.9222 0.9250
epoch 1500 LossPred 0.1061 LossAtt 0.4080 TrainAcc 0.9700 TestAcc 0.9650 0.9450
epoch 1600 LossPred 0.1805 LossAtt 0.4198 TrainAcc 0.9300 TestAcc 0.9259 0.9500
epoch 1700 LossPred 0.2205 LossAtt 0.4228 TrainAcc 0.9300 TestAcc 0.9094 0.9300
epoch 1800 LossPred 0.0985 LossAtt 0.4213 TrainAcc 0.9900 TestAcc 0.9525 0.9400
epoch 1900 LossPred 0.1012 LossAtt 0.4215 TrainAcc 0.9500 TestAcc 0.9797 0.9550
epoch 2000 LossPred 0.1291 LossAtt 0.4296 TrainAcc 0.9500 TestAcc 0.9327 0.9450
epoch 2100 LossPred 0.1295 LossAtt 0.4002 TrainAcc 0.9500 TestAcc 0.9354 0.9550
epoch 2200 LossPred 0.1171 LossAtt 0.4377 TrainAcc 0.9400 TestAcc 0.9542 0.9550
epoch 2300 LossPred 0.0677 LossAtt 0.4289 TrainAcc 0.9900 TestAcc 0.9702 0.9650
epoch 2400 LossPred 0.0853 LossAtt 0.4161 TrainAcc 0.9800 TestAcc 0.9580 0.9650
epoch 2500 LossPred 0.1036 LossAtt 0.4071 TrainAcc 0.9600 TestAcc 0.9389 0.9550
Optimization Finished!
********** replication  94  **********
epoch   0 LossPred 1.0494 LossAtt 0.9865 TrainAcc 0.4900 TestAcc 0.4272 0.5250
epoch 100 LossPred 0.9475 LossAtt 0.4386 TrainAcc 0.6600 TestAcc 0.6181 0.6550
epoch 200 LossPred 0.8932 LossAtt 0.3959 TrainAcc 0.6600 TestAcc 0.6181 0.6600
epoch 300 LossPred 0.8638 LossAtt 0.3788 TrainAcc 0.6600 TestAcc 0.6181 0.6600
epoch 400 LossPred 0.8376 LossAtt 0.3676 TrainAcc 0.6600 TestAcc 0.6181 0.6700
epoch 500 LossPred 0.8592 LossAtt 0.4916 TrainAcc 0.6700 TestAcc 0.6572 0.6500
epoch 600 LossPred 0.4095 LossAtt 0.4251 TrainAcc 0.8700 TestAcc 0.8488 0.8600
epoch 700 LossPred 0.2837 LossAtt 0.3970 TrainAcc 0.9200 TestAcc 0.8994 0.8900
epoch 800 LossPred 0.1563 LossAtt 0.3407 TrainAcc 0.9600 TestAcc 0.9527 0.9350
epoch 900 LossPred 0.1349 LossAtt 0.3392 TrainAcc 0.9600 TestAcc 0.9434 0.9350
epoch 1000 LossPred 0.1353 LossAtt 0.3296 TrainAcc 0.9700 TestAcc 0.9537 0.9200
epoch 1100 LossPred 0.1086 LossAtt 0.3371 TrainAcc 0.9800 TestAcc 0.9662 0.9600
epoch 1200 LossPred 0.1508 LossAtt 0.3244 TrainAcc 0.9600 TestAcc 0.9542 0.9200
epoch 1300 LossPred 0.0977 LossAtt 0.3101 TrainAcc 0.9700 TestAcc 0.9577 0.9550
epoch 1400 LossPred 0.0895 LossAtt 0.3313 TrainAcc 0.9800 TestAcc 0.9647 0.9650
epoch 1500 LossPred 0.2060 LossAtt 0.3159 TrainAcc 0.9300 TestAcc 0.9262 0.9200
epoch 1600 LossPred 0.1242 LossAtt 0.3379 TrainAcc 0.9600 TestAcc 0.9392 0.9100
epoch 1700 LossPred 0.0951 LossAtt 0.3267 TrainAcc 0.9700 TestAcc 0.9560 0.9250
epoch 1800 LossPred 0.0957 LossAtt 0.3519 TrainAcc 0.9800 TestAcc 0.9620 0.9550
epoch 1900 LossPred 0.0903 LossAtt 0.3036 TrainAcc 0.9600 TestAcc 0.9590 0.9300
epoch 2000 LossPred 0.2086 LossAtt 0.3095 TrainAcc 0.9300 TestAcc 0.8851 0.8800
epoch 2100 LossPred 0.1127 LossAtt 0.3313 TrainAcc 0.9700 TestAcc 0.9542 0.9550
epoch 2200 LossPred 0.1967 LossAtt 0.3223 TrainAcc 0.9400 TestAcc 0.9007 0.8800
epoch 2300 LossPred 0.2953 LossAtt 0.3540 TrainAcc 0.8700 TestAcc 0.9054 0.8750
epoch 2400 LossPred 0.0912 LossAtt 0.3379 TrainAcc 0.9700 TestAcc 0.9612 0.9650
epoch 2500 LossPred 0.0834 LossAtt 0.3099 TrainAcc 0.9600 TestAcc 0.9560 0.9250
Optimization Finished!
********** replication  95  **********
epoch   0 LossPred 1.1953 LossAtt 0.9881 TrainAcc 0.4000 TestAcc 0.4525 0.3900
epoch 100 LossPred 0.9187 LossAtt 0.3511 TrainAcc 0.6400 TestAcc 0.6056 0.6400
epoch 200 LossPred 0.8817 LossAtt 0.2828 TrainAcc 0.6400 TestAcc 0.6056 0.6400
epoch 300 LossPred 0.4377 LossAtt 0.3769 TrainAcc 0.8800 TestAcc 0.8473 0.8900
epoch 400 LossPred 0.3838 LossAtt 0.3626 TrainAcc 0.8900 TestAcc 0.8498 0.8750
epoch 500 LossPred 0.3876 LossAtt 0.3482 TrainAcc 0.9100 TestAcc 0.8759 0.8750
epoch 600 LossPred 0.3555 LossAtt 0.3654 TrainAcc 0.9000 TestAcc 0.8864 0.9150
epoch 700 LossPred 0.3373 LossAtt 0.4169 TrainAcc 0.8800 TestAcc 0.8606 0.8850
epoch 800 LossPred 0.3764 LossAtt 0.4292 TrainAcc 0.8700 TestAcc 0.8246 0.8450
epoch 900 LossPred 0.2899 LossAtt 0.4515 TrainAcc 0.9100 TestAcc 0.8794 0.8850
epoch 1000 LossPred 0.3180 LossAtt 0.4640 TrainAcc 0.8900 TestAcc 0.8736 0.9100
epoch 1100 LossPred 0.2551 LossAtt 0.4571 TrainAcc 0.9200 TestAcc 0.9069 0.9150
epoch 1200 LossPred 0.2975 LossAtt 0.4485 TrainAcc 0.8900 TestAcc 0.8566 0.9050
epoch 1300 LossPred 0.2683 LossAtt 0.4627 TrainAcc 0.9100 TestAcc 0.8904 0.9150
epoch 1400 LossPred 0.4721 LossAtt 0.4840 TrainAcc 0.7900 TestAcc 0.7860 0.8250
epoch 1500 LossPred 0.2840 LossAtt 0.4788 TrainAcc 0.8800 TestAcc 0.8956 0.9100
epoch 1600 LossPred 0.2431 LossAtt 0.4974 TrainAcc 0.9100 TestAcc 0.8741 0.9050
epoch 1700 LossPred 0.3639 LossAtt 0.4933 TrainAcc 0.8700 TestAcc 0.8556 0.8750
epoch 1800 LossPred 0.2159 LossAtt 0.5111 TrainAcc 0.9300 TestAcc 0.8719 0.9200
epoch 1900 LossPred 0.1346 LossAtt 0.5143 TrainAcc 0.9700 TestAcc 0.9124 0.9500
epoch 2000 LossPred 0.1711 LossAtt 0.5379 TrainAcc 0.9400 TestAcc 0.9052 0.9350
epoch 2100 LossPred 0.2234 LossAtt 0.5121 TrainAcc 0.9400 TestAcc 0.8541 0.9100
epoch 2200 LossPred 0.1320 LossAtt 0.5128 TrainAcc 0.9500 TestAcc 0.9029 0.9500
epoch 2300 LossPred 0.1580 LossAtt 0.5107 TrainAcc 0.9400 TestAcc 0.8994 0.9500
epoch 2400 LossPred 0.1380 LossAtt 0.5224 TrainAcc 0.9500 TestAcc 0.9017 0.9500
epoch 2500 LossPred 0.1151 LossAtt 0.4953 TrainAcc 0.9600 TestAcc 0.8981 0.9550
Optimization Finished!
********** replication  96  **********
epoch   0 LossPred 1.0835 LossAtt 1.0013 TrainAcc 0.5300 TestAcc 0.5008 0.5250
epoch 100 LossPred 0.9585 LossAtt 0.5138 TrainAcc 0.5900 TestAcc 0.5836 0.5900
epoch 200 LossPred 0.8785 LossAtt 0.6066 TrainAcc 0.6700 TestAcc 0.5816 0.6850
epoch 300 LossPred 0.4870 LossAtt 0.6394 TrainAcc 0.8700 TestAcc 0.8436 0.8500
epoch 400 LossPred 0.4667 LossAtt 0.5836 TrainAcc 0.8400 TestAcc 0.8471 0.8600
epoch 500 LossPred 0.3618 LossAtt 0.6047 TrainAcc 0.8700 TestAcc 0.8846 0.8650
epoch 600 LossPred 0.5050 LossAtt 0.5692 TrainAcc 0.7900 TestAcc 0.8301 0.8150
epoch 700 LossPred 0.3943 LossAtt 0.5843 TrainAcc 0.9000 TestAcc 0.8599 0.8600
epoch 800 LossPred 0.2190 LossAtt 0.5549 TrainAcc 0.9300 TestAcc 0.8864 0.9150
epoch 900 LossPred 0.2345 LossAtt 0.5657 TrainAcc 0.9200 TestAcc 0.8856 0.9150
epoch 1000 LossPred 0.2217 LossAtt 0.5818 TrainAcc 0.9400 TestAcc 0.8881 0.9150
epoch 1100 LossPred 0.3241 LossAtt 0.5804 TrainAcc 0.9100 TestAcc 0.8719 0.8700
epoch 1200 LossPred 0.2430 LossAtt 0.5411 TrainAcc 0.9200 TestAcc 0.8816 0.9050
epoch 1300 LossPred 0.2770 LossAtt 0.5519 TrainAcc 0.9000 TestAcc 0.8761 0.9100
epoch 1400 LossPred 0.2197 LossAtt 0.5465 TrainAcc 0.9500 TestAcc 0.8854 0.9150
epoch 1500 LossPred 0.2246 LossAtt 0.5360 TrainAcc 0.9200 TestAcc 0.8829 0.9150
epoch 1600 LossPred 0.2355 LossAtt 0.5751 TrainAcc 0.9400 TestAcc 0.8779 0.8900
epoch 1700 LossPred 0.3818 LossAtt 0.5869 TrainAcc 0.8500 TestAcc 0.8616 0.8800
epoch 1800 LossPred 0.2039 LossAtt 0.5959 TrainAcc 0.9500 TestAcc 0.8849 0.9100
epoch 1900 LossPred 0.2002 LossAtt 0.5810 TrainAcc 0.9500 TestAcc 0.8859 0.9200
epoch 2000 LossPred 0.3532 LossAtt 0.5761 TrainAcc 0.8800 TestAcc 0.8704 0.8850
epoch 2100 LossPred 0.2084 LossAtt 0.5744 TrainAcc 0.9300 TestAcc 0.8846 0.9250
epoch 2200 LossPred 0.2859 LossAtt 0.5619 TrainAcc 0.9200 TestAcc 0.8831 0.9000
epoch 2300 LossPred 0.2049 LossAtt 0.5675 TrainAcc 0.9600 TestAcc 0.8879 0.9150
epoch 2400 LossPred 0.1935 LossAtt 0.5712 TrainAcc 0.9400 TestAcc 0.8826 0.9300
epoch 2500 LossPred 0.1859 LossAtt 0.5607 TrainAcc 0.9400 TestAcc 0.8779 0.9200
Optimization Finished!
********** replication  97  **********
epoch   0 LossPred 1.0270 LossAtt 0.9973 TrainAcc 0.5300 TestAcc 0.5295 0.5150
epoch 100 LossPred 0.9638 LossAtt 0.4429 TrainAcc 0.5700 TestAcc 0.5335 0.5400
epoch 200 LossPred 0.8602 LossAtt 0.5428 TrainAcc 0.6900 TestAcc 0.5993 0.6950
epoch 300 LossPred 0.7000 LossAtt 0.6090 TrainAcc 0.7500 TestAcc 0.6582 0.7500
epoch 400 LossPred 0.2000 LossAtt 0.5738 TrainAcc 0.9400 TestAcc 0.8764 0.9150
epoch 500 LossPred 0.1543 LossAtt 0.5550 TrainAcc 0.9500 TestAcc 0.8699 0.9300
epoch 600 LossPred 0.1488 LossAtt 0.5246 TrainAcc 0.9500 TestAcc 0.8531 0.9250
epoch 700 LossPred 0.1243 LossAtt 0.5180 TrainAcc 0.9700 TestAcc 0.8614 0.9400
epoch 800 LossPred 0.1299 LossAtt 0.4950 TrainAcc 0.9600 TestAcc 0.8561 0.9300
epoch 900 LossPred 0.1283 LossAtt 0.4850 TrainAcc 0.9600 TestAcc 0.8539 0.9200
epoch 1000 LossPred 0.1269 LossAtt 0.4717 TrainAcc 0.9600 TestAcc 0.8611 0.9200
epoch 1100 LossPred 0.1194 LossAtt 0.4572 TrainAcc 0.9700 TestAcc 0.8564 0.9250
epoch 1200 LossPred 0.1186 LossAtt 0.4419 TrainAcc 0.9600 TestAcc 0.8501 0.9350
epoch 1300 LossPred 0.2025 LossAtt 0.4784 TrainAcc 0.9400 TestAcc 0.8298 0.9200
epoch 1400 LossPred 0.1180 LossAtt 0.4311 TrainAcc 0.9600 TestAcc 0.8491 0.9350
epoch 1500 LossPred 0.1343 LossAtt 0.4426 TrainAcc 0.9500 TestAcc 0.8463 0.9300
epoch 1600 LossPred 0.1187 LossAtt 0.4437 TrainAcc 0.9600 TestAcc 0.8408 0.9200
epoch 1700 LossPred 0.1370 LossAtt 0.4341 TrainAcc 0.9500 TestAcc 0.8438 0.9300
epoch 1800 LossPred 0.1058 LossAtt 0.4283 TrainAcc 0.9700 TestAcc 0.8471 0.9300
epoch 1900 LossPred 0.1198 LossAtt 0.4139 TrainAcc 0.9600 TestAcc 0.8416 0.9300
epoch 2000 LossPred 0.1034 LossAtt 0.4063 TrainAcc 0.9700 TestAcc 0.8401 0.9350
epoch 2100 LossPred 0.1020 LossAtt 0.4348 TrainAcc 0.9700 TestAcc 0.8423 0.9400
epoch 2200 LossPred 0.1071 LossAtt 0.4319 TrainAcc 0.9800 TestAcc 0.8376 0.9300
epoch 2300 LossPred 0.1168 LossAtt 0.4401 TrainAcc 0.9700 TestAcc 0.8396 0.9400
epoch 2400 LossPred 0.0982 LossAtt 0.4457 TrainAcc 0.9700 TestAcc 0.8358 0.9600
epoch 2500 LossPred 0.1006 LossAtt 0.4178 TrainAcc 0.9700 TestAcc 0.8338 0.9300
Optimization Finished!
********** replication  98  **********
epoch   0 LossPred 1.2018 LossAtt 1.0021 TrainAcc 0.4500 TestAcc 0.5255 0.4600
epoch 100 LossPred 0.9992 LossAtt 0.4370 TrainAcc 0.5700 TestAcc 0.6374 0.5650
epoch 200 LossPred 0.9804 LossAtt 0.4064 TrainAcc 0.5400 TestAcc 0.6391 0.5700
epoch 300 LossPred 0.9238 LossAtt 0.4594 TrainAcc 0.6200 TestAcc 0.6436 0.6000
epoch 400 LossPred 0.4325 LossAtt 0.4528 TrainAcc 0.8900 TestAcc 0.8566 0.8100
epoch 500 LossPred 0.3666 LossAtt 0.3571 TrainAcc 0.9000 TestAcc 0.8646 0.8650
epoch 600 LossPred 0.3291 LossAtt 0.3477 TrainAcc 0.9100 TestAcc 0.8754 0.8600
epoch 700 LossPred 0.3256 LossAtt 0.3607 TrainAcc 0.9000 TestAcc 0.8871 0.8800
epoch 800 LossPred 0.2741 LossAtt 0.3948 TrainAcc 0.9400 TestAcc 0.9039 0.8950
epoch 900 LossPred 0.1959 LossAtt 0.4332 TrainAcc 0.9400 TestAcc 0.9032 0.9250
epoch 1000 LossPred 0.3008 LossAtt 0.4205 TrainAcc 0.9000 TestAcc 0.8519 0.8650
epoch 1100 LossPred 0.1840 LossAtt 0.4526 TrainAcc 0.9500 TestAcc 0.8911 0.9000
epoch 1200 LossPred 0.1376 LossAtt 0.4111 TrainAcc 0.9600 TestAcc 0.9127 0.9400
epoch 1300 LossPred 0.1236 LossAtt 0.4212 TrainAcc 0.9800 TestAcc 0.9217 0.9700
epoch 1400 LossPred 0.1252 LossAtt 0.4256 TrainAcc 0.9800 TestAcc 0.9329 0.9700
epoch 1500 LossPred 0.1108 LossAtt 0.4247 TrainAcc 0.9800 TestAcc 0.9352 0.9700
epoch 1600 LossPred 0.1126 LossAtt 0.4326 TrainAcc 0.9800 TestAcc 0.9217 0.9650
epoch 1700 LossPred 0.0960 LossAtt 0.4089 TrainAcc 0.9800 TestAcc 0.9414 0.9750
epoch 1800 LossPred 0.0922 LossAtt 0.4207 TrainAcc 0.9800 TestAcc 0.9404 0.9750
epoch 1900 LossPred 0.0993 LossAtt 0.4590 TrainAcc 0.9800 TestAcc 0.9382 0.9750
epoch 2000 LossPred 0.0873 LossAtt 0.4211 TrainAcc 0.9800 TestAcc 0.9332 0.9750
epoch 2100 LossPred 0.0895 LossAtt 0.4368 TrainAcc 0.9800 TestAcc 0.9352 0.9700
epoch 2200 LossPred 0.0881 LossAtt 0.4589 TrainAcc 0.9800 TestAcc 0.9447 0.9750
epoch 2300 LossPred 0.1605 LossAtt 0.4386 TrainAcc 0.9500 TestAcc 0.9189 0.9400
epoch 2400 LossPred 0.0742 LossAtt 0.4528 TrainAcc 0.9800 TestAcc 0.9387 0.9850
epoch 2500 LossPred 0.1386 LossAtt 0.4758 TrainAcc 0.9600 TestAcc 0.9092 0.9500
Optimization Finished!
********** replication  99  **********
epoch   0 LossPred 0.9820 LossAtt 1.0167 TrainAcc 0.5400 TestAcc 0.4967 0.5700
epoch 100 LossPred 0.8971 LossAtt 0.3291 TrainAcc 0.6400 TestAcc 0.6074 0.6400
epoch 200 LossPred 0.8595 LossAtt 0.3730 TrainAcc 0.6400 TestAcc 0.6074 0.6700
epoch 300 LossPred 0.9065 LossAtt 0.3957 TrainAcc 0.6200 TestAcc 0.5978 0.6200
epoch 400 LossPred 0.8191 LossAtt 0.3780 TrainAcc 0.6900 TestAcc 0.6391 0.7200
epoch 500 LossPred 0.8078 LossAtt 0.3621 TrainAcc 0.6900 TestAcc 0.6504 0.6950
epoch 600 LossPred 0.8129 LossAtt 0.3549 TrainAcc 0.6800 TestAcc 0.6504 0.6950
epoch 700 LossPred 0.7790 LossAtt 0.3496 TrainAcc 0.6900 TestAcc 0.6559 0.7100
epoch 800 LossPred 0.7819 LossAtt 0.3141 TrainAcc 0.7000 TestAcc 0.6542 0.7150
epoch 900 LossPred 0.7510 LossAtt 0.3441 TrainAcc 0.6900 TestAcc 0.6614 0.7200
epoch 1000 LossPred 0.7460 LossAtt 0.3355 TrainAcc 0.7200 TestAcc 0.7107 0.7200
epoch 1100 LossPred 0.7076 LossAtt 0.3384 TrainAcc 0.7400 TestAcc 0.7020 0.7200
epoch 1200 LossPred 0.5853 LossAtt 0.3997 TrainAcc 0.8300 TestAcc 0.8183 0.8250
epoch 1300 LossPred 0.3320 LossAtt 0.3804 TrainAcc 0.9000 TestAcc 0.9059 0.8850
epoch 1400 LossPred 0.3499 LossAtt 0.3569 TrainAcc 0.8700 TestAcc 0.8901 0.8650
epoch 1500 LossPred 0.2574 LossAtt 0.3673 TrainAcc 0.9500 TestAcc 0.9357 0.9200
epoch 1600 LossPred 0.3002 LossAtt 0.3940 TrainAcc 0.8900 TestAcc 0.8804 0.8900
epoch 1700 LossPred 0.3650 LossAtt 0.3752 TrainAcc 0.8400 TestAcc 0.8231 0.8450
epoch 1800 LossPred 0.2363 LossAtt 0.3828 TrainAcc 0.9300 TestAcc 0.9404 0.9200
epoch 1900 LossPred 0.4760 LossAtt 0.3681 TrainAcc 0.7900 TestAcc 0.7830 0.8100
epoch 2000 LossPred 0.3281 LossAtt 0.3771 TrainAcc 0.8900 TestAcc 0.8381 0.8700
epoch 2100 LossPred 0.2678 LossAtt 0.3760 TrainAcc 0.9200 TestAcc 0.9264 0.9100
epoch 2200 LossPred 0.2082 LossAtt 0.3747 TrainAcc 0.9600 TestAcc 0.9297 0.9350
epoch 2300 LossPred 0.2704 LossAtt 0.3723 TrainAcc 0.9000 TestAcc 0.9194 0.8950
epoch 2400 LossPred 0.2206 LossAtt 0.3590 TrainAcc 0.9200 TestAcc 0.9452 0.9050
epoch 2500 LossPred 0.2014 LossAtt 0.3804 TrainAcc 0.9600 TestAcc 0.9384 0.9400
Optimization Finished!
********************************************************************
Namespace(arch='tanh', batch_size=256, display_epoch=100, input_noise_level=0.15, latent_attractor_space=True, loss_switch_frequency=0, lrate_attractor=0.002, lrate_prediction=0.002, lrate_wt_penalty=0.0, n_attractor_hidden=10, n_attractor_steps=5, n_hidden=5, n_replications=100, noise_level=0.5, report_best_train_performance=True, seq_len=15, task='majority', train_attr_weights_on_prediction=False, training_epochs=2500)
********************************************************************
mean train accuracy 0.94350004
indiv runs  [0.99, 0.71, 0.95, 0.99, 0.93, 0.99, 0.95, 0.96, 0.98, 0.95, 0.97, 0.98, 0.88, 0.94, 0.98, 0.99, 0.72, 0.77, 1.0, 0.97, 0.95, 0.97, 0.99, 0.95, 0.85, 1.0, 0.97, 1.0, 0.97, 0.99, 0.99, 0.97, 0.96, 0.97, 0.99, 0.92, 0.74, 0.99, 0.96, 0.95, 0.91, 0.97, 0.98, 0.96, 0.89, 0.96, 0.98, 0.96, 0.97, 0.97, 0.94, 0.82, 0.97, 0.95, 0.98, 0.78, 0.91, 0.99, 0.96, 0.98, 0.99, 0.93, 0.98, 0.99, 0.74, 0.97, 0.97, 0.72, 0.8, 0.97, 0.89, 0.95, 1.0, 0.97, 0.98, 0.94, 0.97, 0.96, 0.92, 0.95, 0.87, 0.99, 0.94, 0.94, 0.94, 0.97, 0.98, 0.95, 0.97, 0.99, 0.97, 0.96, 0.96, 0.99, 0.98, 0.97, 0.96, 0.98, 0.98, 0.96]
mean epoch 1701.0
indiv epochs  [1701, 2301, 701, 2101]
test1 accuracy mean  0.87798285  median  0.9042793
test2 accuracy mean  0.91190004  median  0.935
test1 indiv runs  [0.9727227, 0.6073574, 0.9281782, 0.9391892, 0.8766266, 0.9316817, 0.9194194, 0.8743744, 0.9491992, 0.8603604, 0.9141642, 0.8796296, 0.7012012, 0.8488488, 0.9424424, 0.962963, 0.5710711, 0.6166166, 0.9464464, 0.9036537, 0.9119119, 0.9429429, 0.9481982, 0.8678679, 0.8330831, 0.9026527, 0.9572072, 0.9399399, 0.9094094, 0.8848849, 0.9817317, 0.9324324, 0.9026527, 0.9647147, 0.9271772, 0.8648649, 0.54004, 0.950951, 0.9426927, 0.8738739, 0.8866366, 0.9384384, 0.955956, 0.9039039, 0.8425926, 0.9084084, 0.9044044, 0.9356857, 0.9582082, 0.9289289, 0.8938939, 0.5940941, 0.8961461, 0.9041542, 0.8918919, 0.5275275, 0.8748749, 0.9464464, 0.9029029, 0.9264264, 0.985986, 0.8823824, 0.8951451, 0.9134134, 0.5895896, 0.8753754, 0.8658659, 0.5720721, 0.5705706, 0.9314314, 0.8751251, 0.8973974, 0.9164164, 0.9296797, 0.8993994, 0.9216717, 0.8430931, 0.8588589, 0.8238238, 0.9264264, 0.8295796, 0.9311812, 0.9296797, 0.9184184, 0.9114114, 0.8966466, 0.8926426, 0.963964, 0.8721221, 0.9502002, 0.8978979, 0.9246747, 0.8513514, 0.9524525, 0.9662162, 0.9124124, 0.8878879, 0.8375876, 0.9216717, 0.9296797]
test2 indiv runs  [0.915, 0.71, 0.955, 0.965, 0.885, 0.97, 0.92, 0.935, 0.97, 0.945, 0.955, 0.94, 0.835, 0.915, 0.91, 0.935, 0.68, 0.685, 0.985, 0.955, 0.915, 0.89, 0.955, 0.945, 0.815, 0.995, 0.95, 0.965, 0.9, 0.975, 0.96, 0.955, 0.89, 0.945, 0.985, 0.87, 0.705, 0.945, 0.915, 0.95, 0.895, 0.925, 0.955, 0.91, 0.825, 0.955, 0.94, 0.92, 0.945, 0.93, 0.905, 0.8, 0.94, 0.94, 0.92, 0.735, 0.905, 0.965, 0.925, 0.98, 0.93, 0.89, 0.955, 0.97, 0.7, 0.97, 0.94, 0.67, 0.775, 0.965, 0.89, 0.925, 0.965, 0.91, 0.96, 0.91, 0.93, 0.92, 0.88, 0.94, 0.86, 0.945, 0.91, 0.905, 0.885, 0.94, 0.955, 0.86, 0.96, 0.96, 0.95, 0.935, 0.925, 0.94, 0.96, 0.95, 0.915, 0.93, 0.97, 0.935]
