Namespace(arch='tanh', batch_size=256, display_epoch=100, input_noise_level=0.15, latent_attractor_space=True, loss_switch_frequency=0, lrate_attractor=0.002, lrate_prediction=0.002, lrate_wt_penalty=0.0, n_attractor_hidden=20, n_attractor_steps=5, n_hidden=10, n_replications=100, noise_level=0.5, report_best_train_performance=True, seq_len=20, task='majority', train_attr_weights_on_prediction=False, training_epochs=2500)
TRAINING ON 100 EXAMPLES, TESTING ON 3996
********** replication  0  **********
epoch   0 LossPred 1.0955 LossAtt 1.0198 TrainAcc 0.6000 TestAcc 0.5120 0.5300
epoch 100 LossPred 0.9057 LossAtt 0.2419 TrainAcc 0.6500 TestAcc 0.5916 0.6350
epoch 200 LossPred 0.8874 LossAtt 0.1398 TrainAcc 0.6500 TestAcc 0.5916 0.6500
epoch 300 LossPred 0.8396 LossAtt 0.1867 TrainAcc 0.6500 TestAcc 0.5916 0.6600
epoch 400 LossPred 0.7809 LossAtt 0.2280 TrainAcc 0.6400 TestAcc 0.5283 0.6400
epoch 500 LossPred 0.7687 LossAtt 0.2058 TrainAcc 0.6400 TestAcc 0.5258 0.6500
epoch 600 LossPred 0.7559 LossAtt 0.2353 TrainAcc 0.7000 TestAcc 0.5425 0.6750
epoch 700 LossPred 0.7345 LossAtt 0.2518 TrainAcc 0.7300 TestAcc 0.5435 0.6950
epoch 800 LossPred 0.7152 LossAtt 0.2689 TrainAcc 0.7400 TestAcc 0.5616 0.7150
epoch 900 LossPred 0.7202 LossAtt 0.2454 TrainAcc 0.7400 TestAcc 0.5586 0.6900
epoch 1000 LossPred 0.6833 LossAtt 0.2255 TrainAcc 0.7600 TestAcc 0.5641 0.6950
epoch 1100 LossPred 0.6693 LossAtt 0.2200 TrainAcc 0.7800 TestAcc 0.5385 0.7150
epoch 1200 LossPred 0.7181 LossAtt 0.2205 TrainAcc 0.7000 TestAcc 0.5465 0.7100
epoch 1300 LossPred 0.6606 LossAtt 0.2185 TrainAcc 0.7700 TestAcc 0.5343 0.7300
epoch 1400 LossPred 0.6479 LossAtt 0.2133 TrainAcc 0.7800 TestAcc 0.5343 0.7350
epoch 1500 LossPred 0.6582 LossAtt 0.2269 TrainAcc 0.7700 TestAcc 0.5343 0.7350
epoch 1600 LossPred 0.7112 LossAtt 0.2506 TrainAcc 0.7200 TestAcc 0.5708 0.6850
epoch 1700 LossPred 0.6614 LossAtt 0.2600 TrainAcc 0.7400 TestAcc 0.6159 0.7500
epoch 1800 LossPred 0.6597 LossAtt 0.2542 TrainAcc 0.7800 TestAcc 0.6261 0.7300
epoch 1900 LossPred 0.6456 LossAtt 0.2406 TrainAcc 0.7700 TestAcc 0.6181 0.7450
epoch 2000 LossPred 0.6584 LossAtt 0.2462 TrainAcc 0.7500 TestAcc 0.6206 0.7650
epoch 2100 LossPred 0.6435 LossAtt 0.2467 TrainAcc 0.7500 TestAcc 0.6344 0.7450
epoch 2200 LossPred 0.6442 LossAtt 0.2396 TrainAcc 0.7200 TestAcc 0.6276 0.7050
epoch 2300 LossPred 0.6418 LossAtt 0.2278 TrainAcc 0.7300 TestAcc 0.6409 0.7500
epoch 2400 LossPred 0.6231 LossAtt 0.2281 TrainAcc 0.7600 TestAcc 0.6567 0.7700
epoch 2500 LossPred 0.5863 LossAtt 0.2352 TrainAcc 0.7700 TestAcc 0.6672 0.7450
Optimization Finished!
********** replication  1  **********
epoch   0 LossPred 1.1419 LossAtt 1.0232 TrainAcc 0.4900 TestAcc 0.5458 0.4850
epoch 100 LossPred 0.7637 LossAtt 0.3235 TrainAcc 0.7200 TestAcc 0.5906 0.7200
epoch 200 LossPred 0.6612 LossAtt 0.3011 TrainAcc 0.7800 TestAcc 0.6439 0.7900
epoch 300 LossPred 0.3137 LossAtt 0.3384 TrainAcc 0.9000 TestAcc 0.8564 0.9100
epoch 400 LossPred 0.2376 LossAtt 0.3320 TrainAcc 0.9500 TestAcc 0.8699 0.9150
epoch 500 LossPred 0.1808 LossAtt 0.3466 TrainAcc 0.9500 TestAcc 0.8834 0.9450
epoch 600 LossPred 0.1525 LossAtt 0.3414 TrainAcc 0.9700 TestAcc 0.8866 0.9500
epoch 700 LossPred 0.1597 LossAtt 0.3378 TrainAcc 0.9600 TestAcc 0.8709 0.9500
epoch 800 LossPred 0.1996 LossAtt 0.3304 TrainAcc 0.9400 TestAcc 0.8619 0.9300
epoch 900 LossPred 0.1794 LossAtt 0.3378 TrainAcc 0.9500 TestAcc 0.8851 0.9500
epoch 1000 LossPred 0.1607 LossAtt 0.3242 TrainAcc 0.9600 TestAcc 0.8751 0.9450
epoch 1100 LossPred 0.0906 LossAtt 0.3253 TrainAcc 0.9800 TestAcc 0.9302 0.9650
epoch 1200 LossPred 0.0868 LossAtt 0.3262 TrainAcc 0.9800 TestAcc 0.9254 0.9750
epoch 1300 LossPred 0.1316 LossAtt 0.3265 TrainAcc 0.9800 TestAcc 0.8924 0.9400
epoch 1400 LossPred 0.1836 LossAtt 0.3237 TrainAcc 0.9200 TestAcc 0.8844 0.9250
epoch 1500 LossPred 0.1572 LossAtt 0.3204 TrainAcc 0.9400 TestAcc 0.8679 0.9200
epoch 1600 LossPred 0.1726 LossAtt 0.3293 TrainAcc 0.9500 TestAcc 0.8764 0.9300
epoch 1700 LossPred 0.1477 LossAtt 0.3329 TrainAcc 0.9500 TestAcc 0.8751 0.9400
epoch 1800 LossPred 0.2825 LossAtt 0.3378 TrainAcc 0.8900 TestAcc 0.8348 0.9000
epoch 1900 LossPred 0.2887 LossAtt 0.3397 TrainAcc 0.8800 TestAcc 0.8674 0.9100
epoch 2000 LossPred 0.1532 LossAtt 0.3512 TrainAcc 0.9700 TestAcc 0.8889 0.9550
epoch 2100 LossPred 0.1148 LossAtt 0.3600 TrainAcc 0.9700 TestAcc 0.8926 0.9650
epoch 2200 LossPred 0.1137 LossAtt 0.3701 TrainAcc 0.9600 TestAcc 0.8779 0.9750
epoch 2300 LossPred 0.1041 LossAtt 0.3596 TrainAcc 0.9600 TestAcc 0.8784 0.9700
epoch 2400 LossPred 0.0801 LossAtt 0.3667 TrainAcc 0.9800 TestAcc 0.8766 0.9800
epoch 2500 LossPred 0.0531 LossAtt 0.3597 TrainAcc 1.0000 TestAcc 0.9062 0.9800
Optimization Finished!
********** replication  2  **********
epoch   0 LossPred 1.0509 LossAtt 1.0108 TrainAcc 0.5300 TestAcc 0.4587 0.5250
epoch 100 LossPred 0.8701 LossAtt 0.2459 TrainAcc 0.6800 TestAcc 0.5846 0.6750
epoch 200 LossPred 0.6486 LossAtt 0.2206 TrainAcc 0.8000 TestAcc 0.7743 0.8000
epoch 300 LossPred 0.4408 LossAtt 0.1918 TrainAcc 0.8800 TestAcc 0.8496 0.8350
epoch 400 LossPred 0.5018 LossAtt 0.1649 TrainAcc 0.8400 TestAcc 0.8068 0.8300
epoch 500 LossPred 0.4004 LossAtt 0.1679 TrainAcc 0.9000 TestAcc 0.8486 0.8550
epoch 600 LossPred 0.3771 LossAtt 0.1508 TrainAcc 0.8800 TestAcc 0.8418 0.8500
epoch 700 LossPred 0.3867 LossAtt 0.1500 TrainAcc 0.8900 TestAcc 0.8431 0.8600
epoch 800 LossPred 0.3932 LossAtt 0.1516 TrainAcc 0.8600 TestAcc 0.8291 0.8500
epoch 900 LossPred 0.3681 LossAtt 0.1412 TrainAcc 0.8800 TestAcc 0.8371 0.8550
epoch 1000 LossPred 0.4415 LossAtt 0.1335 TrainAcc 0.8700 TestAcc 0.8353 0.8300
epoch 1100 LossPred 0.6370 LossAtt 0.1468 TrainAcc 0.8000 TestAcc 0.7410 0.7750
epoch 1200 LossPred 0.4443 LossAtt 0.1426 TrainAcc 0.8600 TestAcc 0.8231 0.8600
epoch 1300 LossPred 0.4723 LossAtt 0.1459 TrainAcc 0.8500 TestAcc 0.8436 0.8600
epoch 1400 LossPred 0.3568 LossAtt 0.1450 TrainAcc 0.8800 TestAcc 0.8238 0.8700
epoch 1500 LossPred 0.4650 LossAtt 0.1422 TrainAcc 0.8700 TestAcc 0.8153 0.8500
epoch 1600 LossPred 0.3192 LossAtt 0.1438 TrainAcc 0.8800 TestAcc 0.8288 0.8450
epoch 1700 LossPred 0.4263 LossAtt 0.1440 TrainAcc 0.8700 TestAcc 0.8301 0.8600
epoch 1800 LossPred 0.3202 LossAtt 0.1505 TrainAcc 0.8700 TestAcc 0.8396 0.8750
epoch 1900 LossPred 0.3773 LossAtt 0.1366 TrainAcc 0.8700 TestAcc 0.8498 0.8750
epoch 2000 LossPred 0.4391 LossAtt 0.1329 TrainAcc 0.8400 TestAcc 0.8041 0.8450
epoch 2100 LossPred 0.3094 LossAtt 0.1262 TrainAcc 0.9200 TestAcc 0.8403 0.8750
epoch 2200 LossPred 0.3151 LossAtt 0.1352 TrainAcc 0.8800 TestAcc 0.8258 0.8650
epoch 2300 LossPred 0.3074 LossAtt 0.1307 TrainAcc 0.9100 TestAcc 0.8403 0.9050
epoch 2400 LossPred 0.4381 LossAtt 0.1318 TrainAcc 0.8800 TestAcc 0.8368 0.8800
epoch 2500 LossPred 0.5110 LossAtt 0.1345 TrainAcc 0.8200 TestAcc 0.7790 0.8000
Optimization Finished!
********** replication  3  **********
epoch   0 LossPred 1.0257 LossAtt 1.0281 TrainAcc 0.4400 TestAcc 0.4499 0.4350
epoch 100 LossPred 0.8716 LossAtt 0.2832 TrainAcc 0.6100 TestAcc 0.5866 0.6100
epoch 200 LossPred 0.8654 LossAtt 0.1817 TrainAcc 0.6400 TestAcc 0.6264 0.6250
epoch 300 LossPred 0.8567 LossAtt 0.1676 TrainAcc 0.6400 TestAcc 0.6264 0.6400
epoch 400 LossPred 0.8512 LossAtt 0.2090 TrainAcc 0.6400 TestAcc 0.5898 0.6350
epoch 500 LossPred 0.8528 LossAtt 0.2015 TrainAcc 0.6300 TestAcc 0.5988 0.6550
epoch 600 LossPred 0.8454 LossAtt 0.1801 TrainAcc 0.6300 TestAcc 0.5988 0.6300
epoch 700 LossPred 0.8386 LossAtt 0.2056 TrainAcc 0.6500 TestAcc 0.5776 0.6600
epoch 800 LossPred 0.7819 LossAtt 0.2375 TrainAcc 0.6800 TestAcc 0.5736 0.6700
epoch 900 LossPred 0.7736 LossAtt 0.2464 TrainAcc 0.7000 TestAcc 0.5891 0.6800
epoch 1000 LossPred 0.8577 LossAtt 0.2628 TrainAcc 0.6500 TestAcc 0.5901 0.6550
epoch 1100 LossPred 0.8032 LossAtt 0.2162 TrainAcc 0.7200 TestAcc 0.5908 0.6700
epoch 1200 LossPred 0.7818 LossAtt 0.2573 TrainAcc 0.7100 TestAcc 0.6144 0.6950
epoch 1300 LossPred 0.7870 LossAtt 0.2088 TrainAcc 0.7000 TestAcc 0.6469 0.6800
epoch 1400 LossPred 0.7867 LossAtt 0.2760 TrainAcc 0.7100 TestAcc 0.6336 0.6550
epoch 1500 LossPred 0.7499 LossAtt 0.2002 TrainAcc 0.7300 TestAcc 0.6134 0.6800
epoch 1600 LossPred 0.7748 LossAtt 0.2322 TrainAcc 0.7200 TestAcc 0.6231 0.6800
epoch 1700 LossPred 0.7969 LossAtt 0.2647 TrainAcc 0.7000 TestAcc 0.6446 0.6650
epoch 1800 LossPred 0.7618 LossAtt 0.2459 TrainAcc 0.7100 TestAcc 0.6311 0.6850
epoch 1900 LossPred 0.8781 LossAtt 0.5241 TrainAcc 0.6500 TestAcc 0.5748 0.6350
epoch 2000 LossPred 0.7605 LossAtt 0.2851 TrainAcc 0.7100 TestAcc 0.6251 0.6800
epoch 2100 LossPred 0.7104 LossAtt 0.2752 TrainAcc 0.7500 TestAcc 0.6219 0.6750
epoch 2200 LossPred 0.7097 LossAtt 0.2736 TrainAcc 0.7400 TestAcc 0.6249 0.6950
epoch 2300 LossPred 0.7523 LossAtt 0.3003 TrainAcc 0.7300 TestAcc 0.6076 0.7050
epoch 2400 LossPred 0.8072 LossAtt 0.2967 TrainAcc 0.6600 TestAcc 0.6161 0.6650
epoch 2500 LossPred 0.7987 LossAtt 0.2792 TrainAcc 0.7100 TestAcc 0.5896 0.6900
Optimization Finished!
********** replication  4  **********
epoch   0 LossPred 1.0806 LossAtt 1.0115 TrainAcc 0.3600 TestAcc 0.4047 0.3600
epoch 100 LossPred 0.8013 LossAtt 0.2804 TrainAcc 0.7200 TestAcc 0.6436 0.7150
epoch 200 LossPred 0.7475 LossAtt 0.2795 TrainAcc 0.7200 TestAcc 0.5938 0.7200
epoch 300 LossPred 0.7281 LossAtt 0.2887 TrainAcc 0.7200 TestAcc 0.5938 0.7300
epoch 400 LossPred 0.7142 LossAtt 0.2754 TrainAcc 0.7500 TestAcc 0.6049 0.7550
epoch 500 LossPred 0.6880 LossAtt 0.2844 TrainAcc 0.7700 TestAcc 0.6081 0.7650
epoch 600 LossPred 0.6685 LossAtt 0.2619 TrainAcc 0.7700 TestAcc 0.6169 0.7700
epoch 700 LossPred 0.6951 LossAtt 0.2766 TrainAcc 0.7500 TestAcc 0.6114 0.7250
epoch 800 LossPred 0.5850 LossAtt 0.3185 TrainAcc 0.8000 TestAcc 0.6572 0.7950
epoch 900 LossPred 0.6343 LossAtt 0.2741 TrainAcc 0.7900 TestAcc 0.6499 0.7850
epoch 1000 LossPred 0.5401 LossAtt 0.3105 TrainAcc 0.8100 TestAcc 0.6792 0.8100
epoch 1100 LossPred 0.5755 LossAtt 0.2802 TrainAcc 0.7500 TestAcc 0.6894 0.7700
epoch 1200 LossPred 0.5870 LossAtt 0.3040 TrainAcc 0.7800 TestAcc 0.6947 0.7800
epoch 1300 LossPred 0.2928 LossAtt 0.3799 TrainAcc 0.8700 TestAcc 0.8596 0.8800
epoch 1400 LossPred 0.3880 LossAtt 0.3474 TrainAcc 0.8300 TestAcc 0.7560 0.8400
epoch 1500 LossPred 0.3251 LossAtt 0.3243 TrainAcc 0.9000 TestAcc 0.7873 0.8650
epoch 1600 LossPred 0.3541 LossAtt 0.3418 TrainAcc 0.8600 TestAcc 0.8068 0.8750
epoch 1700 LossPred 0.3704 LossAtt 0.3073 TrainAcc 0.8400 TestAcc 0.7690 0.8350
epoch 1800 LossPred 0.2149 LossAtt 0.3120 TrainAcc 0.9200 TestAcc 0.8326 0.9100
epoch 1900 LossPred 0.2677 LossAtt 0.3121 TrainAcc 0.9000 TestAcc 0.8098 0.8850
epoch 2000 LossPred 0.1621 LossAtt 0.2956 TrainAcc 0.9500 TestAcc 0.8684 0.9450
epoch 2100 LossPred 0.3246 LossAtt 0.2908 TrainAcc 0.8900 TestAcc 0.7973 0.8900
epoch 2200 LossPred 0.1485 LossAtt 0.3100 TrainAcc 0.9700 TestAcc 0.8594 0.9400
epoch 2300 LossPred 0.1814 LossAtt 0.2958 TrainAcc 0.9500 TestAcc 0.8411 0.8950
epoch 2400 LossPred 0.1017 LossAtt 0.2901 TrainAcc 0.9600 TestAcc 0.8686 0.9450
epoch 2500 LossPred 0.2407 LossAtt 0.3177 TrainAcc 0.9100 TestAcc 0.8514 0.9100
Optimization Finished!
********** replication  5  **********
epoch   0 LossPred 1.0387 LossAtt 1.0046 TrainAcc 0.4800 TestAcc 0.5095 0.4800
epoch 100 LossPred 0.9136 LossAtt 0.3009 TrainAcc 0.6500 TestAcc 0.5893 0.6400
epoch 200 LossPred 0.4561 LossAtt 0.3199 TrainAcc 0.8600 TestAcc 0.8298 0.8300
epoch 300 LossPred 0.3281 LossAtt 0.2655 TrainAcc 0.9100 TestAcc 0.8531 0.9000
epoch 400 LossPred 0.2699 LossAtt 0.2714 TrainAcc 0.9200 TestAcc 0.8719 0.9100
epoch 500 LossPred 0.2549 LossAtt 0.2675 TrainAcc 0.9200 TestAcc 0.8739 0.9100
epoch 600 LossPred 0.2188 LossAtt 0.2561 TrainAcc 0.9200 TestAcc 0.9069 0.9150
epoch 700 LossPred 0.2287 LossAtt 0.2532 TrainAcc 0.9200 TestAcc 0.9007 0.8950
epoch 800 LossPred 0.1904 LossAtt 0.2585 TrainAcc 0.9300 TestAcc 0.9134 0.9050
epoch 900 LossPred 0.1762 LossAtt 0.2704 TrainAcc 0.9300 TestAcc 0.9244 0.9250
epoch 1000 LossPred 0.1963 LossAtt 0.2554 TrainAcc 0.9200 TestAcc 0.9052 0.9150
epoch 1100 LossPred 0.2022 LossAtt 0.2685 TrainAcc 0.9300 TestAcc 0.9132 0.9100
epoch 1200 LossPred 0.2536 LossAtt 0.2654 TrainAcc 0.9100 TestAcc 0.9017 0.9150
epoch 1300 LossPred 0.2344 LossAtt 0.2761 TrainAcc 0.9100 TestAcc 0.9072 0.9250
epoch 1400 LossPred 0.2025 LossAtt 0.2766 TrainAcc 0.9300 TestAcc 0.9202 0.9250
epoch 1500 LossPred 0.1588 LossAtt 0.2739 TrainAcc 0.9400 TestAcc 0.9364 0.9300
epoch 1600 LossPred 0.1188 LossAtt 0.2810 TrainAcc 0.9600 TestAcc 0.9399 0.9350
epoch 1700 LossPred 0.2374 LossAtt 0.2707 TrainAcc 0.9100 TestAcc 0.8739 0.9200
epoch 1800 LossPred 0.4707 LossAtt 0.2704 TrainAcc 0.8300 TestAcc 0.8401 0.8550
epoch 1900 LossPred 0.1137 LossAtt 0.2749 TrainAcc 0.9700 TestAcc 0.9352 0.9600
epoch 2000 LossPred 0.1100 LossAtt 0.2798 TrainAcc 0.9800 TestAcc 0.9454 0.9450
epoch 2100 LossPred 0.1194 LossAtt 0.2725 TrainAcc 0.9700 TestAcc 0.9372 0.9450
epoch 2200 LossPred 0.1058 LossAtt 0.2679 TrainAcc 0.9700 TestAcc 0.9319 0.9650
epoch 2300 LossPred 0.1342 LossAtt 0.2560 TrainAcc 0.9700 TestAcc 0.9109 0.9600
epoch 2400 LossPred 0.1652 LossAtt 0.2738 TrainAcc 0.9400 TestAcc 0.9267 0.9700
epoch 2500 LossPred 0.2214 LossAtt 0.2483 TrainAcc 0.9000 TestAcc 0.8799 0.9300
Optimization Finished!
********** replication  6  **********
epoch   0 LossPred 1.4593 LossAtt 1.0031 TrainAcc 0.3300 TestAcc 0.4124 0.3900
epoch 100 LossPred 0.9066 LossAtt 0.2239 TrainAcc 0.6700 TestAcc 0.5876 0.6700
epoch 200 LossPred 0.8755 LossAtt 0.1693 TrainAcc 0.6700 TestAcc 0.5876 0.6700
epoch 300 LossPred 0.8588 LossAtt 0.1682 TrainAcc 0.6700 TestAcc 0.5876 0.6700
epoch 400 LossPred 0.8564 LossAtt 0.2090 TrainAcc 0.6300 TestAcc 0.5648 0.6200
epoch 500 LossPred 0.6709 LossAtt 0.1975 TrainAcc 0.7300 TestAcc 0.6982 0.7500
epoch 600 LossPred 0.5846 LossAtt 0.2018 TrainAcc 0.8100 TestAcc 0.7855 0.8200
epoch 700 LossPred 0.6139 LossAtt 0.1950 TrainAcc 0.8000 TestAcc 0.7658 0.8100
epoch 800 LossPred 0.8943 LossAtt 0.1964 TrainAcc 0.6900 TestAcc 0.6391 0.7050
epoch 900 LossPred 0.4062 LossAtt 0.1857 TrainAcc 0.8900 TestAcc 0.8208 0.8350
epoch 1000 LossPred 0.4319 LossAtt 0.1723 TrainAcc 0.8600 TestAcc 0.8463 0.8750
epoch 1100 LossPred 0.5353 LossAtt 0.1808 TrainAcc 0.8300 TestAcc 0.8016 0.8550
epoch 1200 LossPred 0.3682 LossAtt 0.1775 TrainAcc 0.9000 TestAcc 0.8306 0.8850
epoch 1300 LossPred 0.3540 LossAtt 0.1691 TrainAcc 0.9000 TestAcc 0.8343 0.8900
epoch 1400 LossPred 0.3653 LossAtt 0.1687 TrainAcc 0.8800 TestAcc 0.8346 0.8900
epoch 1500 LossPred 0.4759 LossAtt 0.1550 TrainAcc 0.8200 TestAcc 0.8231 0.8250
epoch 1600 LossPred 0.3663 LossAtt 0.1523 TrainAcc 0.8800 TestAcc 0.8023 0.8500
epoch 1700 LossPred 0.4515 LossAtt 0.1539 TrainAcc 0.8300 TestAcc 0.8351 0.8600
epoch 1800 LossPred 0.3725 LossAtt 0.1509 TrainAcc 0.8700 TestAcc 0.8218 0.8550
epoch 1900 LossPred 0.3377 LossAtt 0.1506 TrainAcc 0.9000 TestAcc 0.8368 0.8700
epoch 2000 LossPred 0.5895 LossAtt 0.1535 TrainAcc 0.8100 TestAcc 0.8031 0.8300
epoch 2100 LossPred 0.3811 LossAtt 0.1560 TrainAcc 0.8900 TestAcc 0.8436 0.8500
epoch 2200 LossPred 0.4651 LossAtt 0.1493 TrainAcc 0.8200 TestAcc 0.8343 0.8550
epoch 2300 LossPred 0.4489 LossAtt 0.1613 TrainAcc 0.8500 TestAcc 0.8326 0.8650
epoch 2400 LossPred 0.6812 LossAtt 0.1439 TrainAcc 0.7700 TestAcc 0.7150 0.7700
epoch 2500 LossPred 0.7523 LossAtt 0.1487 TrainAcc 0.7700 TestAcc 0.6967 0.7700
Optimization Finished!
********** replication  7  **********
epoch   0 LossPred 0.9990 LossAtt 1.0166 TrainAcc 0.5200 TestAcc 0.5315 0.5500
epoch 100 LossPred 0.8379 LossAtt 0.3163 TrainAcc 0.6500 TestAcc 0.5606 0.6500
epoch 200 LossPred 0.3795 LossAtt 0.3143 TrainAcc 0.8700 TestAcc 0.8634 0.8700
epoch 300 LossPred 0.2738 LossAtt 0.2656 TrainAcc 0.9100 TestAcc 0.8676 0.8750
epoch 400 LossPred 0.3228 LossAtt 0.2616 TrainAcc 0.8900 TestAcc 0.8473 0.8550
epoch 500 LossPred 0.2462 LossAtt 0.2529 TrainAcc 0.9100 TestAcc 0.8621 0.8750
epoch 600 LossPred 0.2464 LossAtt 0.2609 TrainAcc 0.9200 TestAcc 0.8554 0.8850
epoch 700 LossPred 0.2645 LossAtt 0.2642 TrainAcc 0.9200 TestAcc 0.8574 0.8850
epoch 800 LossPred 0.2742 LossAtt 0.2528 TrainAcc 0.9000 TestAcc 0.8534 0.8700
epoch 900 LossPred 0.3088 LossAtt 0.2499 TrainAcc 0.8900 TestAcc 0.8504 0.8800
epoch 1000 LossPred 0.2936 LossAtt 0.2525 TrainAcc 0.9100 TestAcc 0.8468 0.9000
epoch 1100 LossPred 0.2778 LossAtt 0.2453 TrainAcc 0.9200 TestAcc 0.8373 0.8850
epoch 1200 LossPred 0.2118 LossAtt 0.2509 TrainAcc 0.9500 TestAcc 0.8511 0.8850
epoch 1300 LossPred 0.2553 LossAtt 0.2473 TrainAcc 0.9200 TestAcc 0.8398 0.8800
epoch 1400 LossPred 0.3446 LossAtt 0.2486 TrainAcc 0.8600 TestAcc 0.8286 0.8700
epoch 1500 LossPred 0.2258 LossAtt 0.2364 TrainAcc 0.9000 TestAcc 0.8358 0.9050
epoch 1600 LossPred 0.2085 LossAtt 0.2351 TrainAcc 0.9300 TestAcc 0.8313 0.8950
epoch 1700 LossPred 0.1716 LossAtt 0.2312 TrainAcc 0.9300 TestAcc 0.8383 0.9050
epoch 1800 LossPred 0.2209 LossAtt 0.2403 TrainAcc 0.9300 TestAcc 0.8243 0.9050
epoch 1900 LossPred 0.2262 LossAtt 0.2444 TrainAcc 0.9100 TestAcc 0.8318 0.9300
epoch 2000 LossPred 0.1451 LossAtt 0.2349 TrainAcc 0.9700 TestAcc 0.8288 0.8900
epoch 2100 LossPred 0.4041 LossAtt 0.2356 TrainAcc 0.8700 TestAcc 0.8078 0.8800
epoch 2200 LossPred 0.3234 LossAtt 0.2424 TrainAcc 0.9000 TestAcc 0.8133 0.8850
epoch 2300 LossPred 0.1580 LossAtt 0.2325 TrainAcc 0.9500 TestAcc 0.8313 0.9050
epoch 2400 LossPred 0.1502 LossAtt 0.2309 TrainAcc 0.9500 TestAcc 0.8321 0.9250
epoch 2500 LossPred 0.1549 LossAtt 0.2259 TrainAcc 0.9600 TestAcc 0.8136 0.9200
Optimization Finished!
********** replication  8  **********
epoch   0 LossPred 1.0827 LossAtt 1.0157 TrainAcc 0.4900 TestAcc 0.5028 0.4900
epoch 100 LossPred 0.8076 LossAtt 0.2744 TrainAcc 0.6800 TestAcc 0.5931 0.6800
epoch 200 LossPred 0.7084 LossAtt 0.2502 TrainAcc 0.7500 TestAcc 0.6381 0.7450
epoch 300 LossPred 0.6788 LossAtt 0.2195 TrainAcc 0.7500 TestAcc 0.6381 0.7500
epoch 400 LossPred 0.6664 LossAtt 0.2490 TrainAcc 0.7400 TestAcc 0.6544 0.7450
epoch 500 LossPred 0.6801 LossAtt 0.2811 TrainAcc 0.7500 TestAcc 0.6371 0.7400
epoch 600 LossPred 0.8569 LossAtt 0.3271 TrainAcc 0.6500 TestAcc 0.7490 0.6650
epoch 700 LossPred 0.6728 LossAtt 0.2899 TrainAcc 0.7500 TestAcc 0.6411 0.7550
epoch 800 LossPred 0.6406 LossAtt 0.2848 TrainAcc 0.7500 TestAcc 0.6567 0.7550
epoch 900 LossPred 0.6045 LossAtt 0.3112 TrainAcc 0.7900 TestAcc 0.7107 0.7900
epoch 1000 LossPred 0.5970 LossAtt 0.3481 TrainAcc 0.7700 TestAcc 0.7523 0.7700
epoch 1100 LossPred 0.4178 LossAtt 0.3484 TrainAcc 0.8600 TestAcc 0.8061 0.8400
epoch 1200 LossPred 0.4559 LossAtt 0.3250 TrainAcc 0.8600 TestAcc 0.7783 0.8300
epoch 1300 LossPred 0.3895 LossAtt 0.3223 TrainAcc 0.8600 TestAcc 0.8121 0.8500
epoch 1400 LossPred 0.4561 LossAtt 0.3112 TrainAcc 0.8300 TestAcc 0.8023 0.8350
epoch 1500 LossPred 0.5487 LossAtt 0.2938 TrainAcc 0.8100 TestAcc 0.7548 0.8000
epoch 1600 LossPred 0.3548 LossAtt 0.2952 TrainAcc 0.8700 TestAcc 0.8243 0.8700
epoch 1700 LossPred 0.5007 LossAtt 0.2807 TrainAcc 0.8500 TestAcc 0.8183 0.8450
epoch 1800 LossPred 0.3221 LossAtt 0.2688 TrainAcc 0.8800 TestAcc 0.8266 0.8600
epoch 1900 LossPred 0.3511 LossAtt 0.2517 TrainAcc 0.8900 TestAcc 0.8361 0.8750
epoch 2000 LossPred 0.3540 LossAtt 0.2494 TrainAcc 0.8900 TestAcc 0.8636 0.8900
epoch 2100 LossPred 0.2496 LossAtt 0.2609 TrainAcc 0.9200 TestAcc 0.8764 0.8900
epoch 2200 LossPred 0.3498 LossAtt 0.2558 TrainAcc 0.8800 TestAcc 0.8841 0.8800
epoch 2300 LossPred 0.4013 LossAtt 0.2744 TrainAcc 0.8600 TestAcc 0.8644 0.8350
epoch 2400 LossPred 0.2756 LossAtt 0.2838 TrainAcc 0.9200 TestAcc 0.8804 0.8900
epoch 2500 LossPred 0.4095 LossAtt 0.2955 TrainAcc 0.8400 TestAcc 0.8108 0.8400
Optimization Finished!
********** replication  9  **********
epoch   0 LossPred 1.1822 LossAtt 1.0263 TrainAcc 0.3900 TestAcc 0.4014 0.4000
epoch 100 LossPred 0.9108 LossAtt 0.2654 TrainAcc 0.6200 TestAcc 0.5508 0.6300
epoch 200 LossPred 0.9004 LossAtt 0.2401 TrainAcc 0.6200 TestAcc 0.5508 0.6200
epoch 300 LossPred 0.8854 LossAtt 0.2413 TrainAcc 0.6600 TestAcc 0.5906 0.6600
epoch 400 LossPred 0.8712 LossAtt 0.2251 TrainAcc 0.6500 TestAcc 0.5868 0.6500
epoch 500 LossPred 0.8549 LossAtt 0.2461 TrainAcc 0.6400 TestAcc 0.5871 0.6400
epoch 600 LossPred 0.8550 LossAtt 0.2474 TrainAcc 0.6700 TestAcc 0.5768 0.6750
epoch 700 LossPred 0.8591 LossAtt 0.2154 TrainAcc 0.6700 TestAcc 0.5923 0.6750
epoch 800 LossPred 0.8272 LossAtt 0.2403 TrainAcc 0.6800 TestAcc 0.5858 0.6750
epoch 900 LossPred 0.7279 LossAtt 0.3246 TrainAcc 0.7400 TestAcc 0.6276 0.7200
epoch 1000 LossPred 0.6742 LossAtt 0.3148 TrainAcc 0.7700 TestAcc 0.6104 0.7750
epoch 1100 LossPred 0.6308 LossAtt 0.3782 TrainAcc 0.8100 TestAcc 0.5903 0.7750
epoch 1200 LossPred 0.5842 LossAtt 0.4317 TrainAcc 0.7900 TestAcc 0.5741 0.7850
epoch 1300 LossPred 0.5513 LossAtt 0.4470 TrainAcc 0.7800 TestAcc 0.5668 0.7550
epoch 1400 LossPred 0.5369 LossAtt 0.4153 TrainAcc 0.7900 TestAcc 0.5951 0.7850
epoch 1500 LossPred 0.4861 LossAtt 0.4289 TrainAcc 0.8500 TestAcc 0.5803 0.7950
epoch 1600 LossPred 0.4627 LossAtt 0.4347 TrainAcc 0.8600 TestAcc 0.5883 0.8000
epoch 1700 LossPred 0.4472 LossAtt 0.4112 TrainAcc 0.8500 TestAcc 0.5953 0.7800
epoch 1800 LossPred 0.4385 LossAtt 0.4254 TrainAcc 0.8600 TestAcc 0.5983 0.7700
epoch 1900 LossPred 0.4090 LossAtt 0.4006 TrainAcc 0.8800 TestAcc 0.6144 0.8000
epoch 2000 LossPred 0.3818 LossAtt 0.3958 TrainAcc 0.8900 TestAcc 0.6081 0.8300
epoch 2100 LossPred 0.3537 LossAtt 0.4108 TrainAcc 0.9000 TestAcc 0.6034 0.8200
epoch 2200 LossPred 0.3288 LossAtt 0.3992 TrainAcc 0.9100 TestAcc 0.5923 0.8250
epoch 2300 LossPred 0.4052 LossAtt 0.4083 TrainAcc 0.8600 TestAcc 0.5753 0.8450
epoch 2400 LossPred 0.4142 LossAtt 0.3995 TrainAcc 0.8500 TestAcc 0.5988 0.8050
epoch 2500 LossPred 0.3801 LossAtt 0.4128 TrainAcc 0.9000 TestAcc 0.5906 0.8400
Optimization Finished!
********** replication  10  **********
epoch   0 LossPred 1.0719 LossAtt 1.0066 TrainAcc 0.5100 TestAcc 0.4850 0.5000
epoch 100 LossPred 0.8169 LossAtt 0.2568 TrainAcc 0.6800 TestAcc 0.6339 0.6600
epoch 200 LossPred 0.5947 LossAtt 0.2468 TrainAcc 0.7900 TestAcc 0.8011 0.7500
epoch 300 LossPred 0.5403 LossAtt 0.2488 TrainAcc 0.8400 TestAcc 0.7760 0.8150
epoch 400 LossPred 0.3010 LossAtt 0.2429 TrainAcc 0.9400 TestAcc 0.8619 0.8800
epoch 500 LossPred 0.3175 LossAtt 0.2330 TrainAcc 0.9000 TestAcc 0.8463 0.8650
epoch 600 LossPred 0.3932 LossAtt 0.2257 TrainAcc 0.8400 TestAcc 0.8338 0.8550
epoch 700 LossPred 0.2709 LossAtt 0.2139 TrainAcc 0.9100 TestAcc 0.9182 0.9000
epoch 800 LossPred 0.1918 LossAtt 0.2248 TrainAcc 0.9500 TestAcc 0.9114 0.9100
epoch 900 LossPred 0.1718 LossAtt 0.2251 TrainAcc 0.9300 TestAcc 0.9227 0.9300
epoch 1000 LossPred 0.1646 LossAtt 0.2290 TrainAcc 0.9700 TestAcc 0.9052 0.9400
epoch 1100 LossPred 0.6711 LossAtt 0.2110 TrainAcc 0.7700 TestAcc 0.7670 0.7950
epoch 1200 LossPred 0.2203 LossAtt 0.2130 TrainAcc 0.9500 TestAcc 0.8671 0.9400
epoch 1300 LossPred 0.1727 LossAtt 0.2063 TrainAcc 0.9500 TestAcc 0.9162 0.9500
epoch 1400 LossPred 0.2990 LossAtt 0.2106 TrainAcc 0.8900 TestAcc 0.8296 0.9000
epoch 1500 LossPred 0.6606 LossAtt 0.2193 TrainAcc 0.7800 TestAcc 0.7828 0.7350
epoch 1600 LossPred 0.3548 LossAtt 0.2200 TrainAcc 0.8800 TestAcc 0.8116 0.8900
epoch 1700 LossPred 0.4557 LossAtt 0.2094 TrainAcc 0.8500 TestAcc 0.7943 0.8500
epoch 1800 LossPred 0.6898 LossAtt 0.2167 TrainAcc 0.8000 TestAcc 0.7472 0.8000
epoch 1900 LossPred 0.2967 LossAtt 0.2153 TrainAcc 0.9100 TestAcc 0.8711 0.9200
epoch 2000 LossPred 0.5060 LossAtt 0.2030 TrainAcc 0.8500 TestAcc 0.7858 0.8600
epoch 2100 LossPred 0.4013 LossAtt 0.2041 TrainAcc 0.8700 TestAcc 0.8121 0.8750
epoch 2200 LossPred 0.7239 LossAtt 0.2034 TrainAcc 0.7700 TestAcc 0.7315 0.7750
epoch 2300 LossPred 0.4542 LossAtt 0.1907 TrainAcc 0.8600 TestAcc 0.8013 0.8700
epoch 2400 LossPred 1.1127 LossAtt 0.2060 TrainAcc 0.5900 TestAcc 0.5758 0.5750
epoch 2500 LossPred 0.4199 LossAtt 0.1799 TrainAcc 0.8600 TestAcc 0.8111 0.8850
Optimization Finished!
********** replication  11  **********
epoch   0 LossPred 1.0182 LossAtt 0.9880 TrainAcc 0.5900 TestAcc 0.5893 0.5900
epoch 100 LossPred 0.8856 LossAtt 0.2919 TrainAcc 0.6300 TestAcc 0.5908 0.6300
epoch 200 LossPred 0.4550 LossAtt 0.2747 TrainAcc 0.8900 TestAcc 0.8418 0.8550
epoch 300 LossPred 0.3942 LossAtt 0.2814 TrainAcc 0.9000 TestAcc 0.8366 0.8850
epoch 400 LossPred 0.3003 LossAtt 0.2666 TrainAcc 0.9200 TestAcc 0.8606 0.9050
epoch 500 LossPred 0.3017 LossAtt 0.2524 TrainAcc 0.9200 TestAcc 0.8514 0.8550
epoch 600 LossPred 0.2245 LossAtt 0.2439 TrainAcc 0.9400 TestAcc 0.8754 0.9350
epoch 700 LossPred 0.2327 LossAtt 0.2445 TrainAcc 0.9400 TestAcc 0.8629 0.9200
epoch 800 LossPred 0.2149 LossAtt 0.2495 TrainAcc 0.9400 TestAcc 0.8579 0.9250
epoch 900 LossPred 0.1393 LossAtt 0.2302 TrainAcc 0.9600 TestAcc 0.8794 0.9550
epoch 1000 LossPred 0.3697 LossAtt 0.2249 TrainAcc 0.8700 TestAcc 0.7895 0.8800
epoch 1100 LossPred 0.1863 LossAtt 0.2257 TrainAcc 0.9400 TestAcc 0.8606 0.9450
epoch 1200 LossPred 0.1686 LossAtt 0.2220 TrainAcc 0.9500 TestAcc 0.8669 0.9500
epoch 1300 LossPred 0.1610 LossAtt 0.2177 TrainAcc 0.9700 TestAcc 0.8341 0.9550
epoch 1400 LossPred 0.1754 LossAtt 0.2073 TrainAcc 0.9400 TestAcc 0.8614 0.9400
epoch 1500 LossPred 0.2196 LossAtt 0.2101 TrainAcc 0.9400 TestAcc 0.8443 0.8950
epoch 1600 LossPred 0.1082 LossAtt 0.2062 TrainAcc 0.9700 TestAcc 0.8534 0.9600
epoch 1700 LossPred 0.1202 LossAtt 0.1963 TrainAcc 0.9700 TestAcc 0.8381 0.9550
epoch 1800 LossPred 0.1621 LossAtt 0.2054 TrainAcc 0.9500 TestAcc 0.8549 0.9400
epoch 1900 LossPred 0.2106 LossAtt 0.2030 TrainAcc 0.9500 TestAcc 0.8168 0.9500
epoch 2000 LossPred 0.1714 LossAtt 0.2059 TrainAcc 0.9400 TestAcc 0.8438 0.9500
epoch 2100 LossPred 0.1421 LossAtt 0.1971 TrainAcc 0.9600 TestAcc 0.8498 0.9550
epoch 2200 LossPred 0.1614 LossAtt 0.1980 TrainAcc 0.9500 TestAcc 0.8569 0.9650
epoch 2300 LossPred 0.3837 LossAtt 0.2069 TrainAcc 0.8500 TestAcc 0.7795 0.8550
epoch 2400 LossPred 0.1056 LossAtt 0.1925 TrainAcc 0.9700 TestAcc 0.8611 0.9700
epoch 2500 LossPred 0.2875 LossAtt 0.2035 TrainAcc 0.9300 TestAcc 0.8131 0.8600
Optimization Finished!
********** replication  12  **********
epoch   0 LossPred 0.9713 LossAtt 1.0053 TrainAcc 0.5800 TestAcc 0.5215 0.5800
epoch 100 LossPred 0.8364 LossAtt 0.3742 TrainAcc 0.6800 TestAcc 0.5661 0.6600
epoch 200 LossPred 0.7376 LossAtt 0.3492 TrainAcc 0.7300 TestAcc 0.5856 0.7150
epoch 300 LossPred 0.6804 LossAtt 0.3449 TrainAcc 0.7300 TestAcc 0.5811 0.7250
epoch 400 LossPred 0.6251 LossAtt 0.3449 TrainAcc 0.8100 TestAcc 0.5728 0.7400
epoch 500 LossPred 0.5844 LossAtt 0.3465 TrainAcc 0.8300 TestAcc 0.5721 0.7600
epoch 600 LossPred 0.5528 LossAtt 0.3424 TrainAcc 0.8400 TestAcc 0.5773 0.7850
epoch 700 LossPred 0.5341 LossAtt 0.3151 TrainAcc 0.8600 TestAcc 0.5713 0.7900
epoch 800 LossPred 0.5221 LossAtt 0.3124 TrainAcc 0.8600 TestAcc 0.5746 0.8000
epoch 900 LossPred 0.4934 LossAtt 0.3216 TrainAcc 0.8500 TestAcc 0.5571 0.8000
epoch 1000 LossPred 0.4785 LossAtt 0.3061 TrainAcc 0.8600 TestAcc 0.5661 0.8150
epoch 1100 LossPred 0.4749 LossAtt 0.3124 TrainAcc 0.8400 TestAcc 0.5583 0.8150
epoch 1200 LossPred 0.4531 LossAtt 0.2983 TrainAcc 0.8700 TestAcc 0.5621 0.8000
epoch 1300 LossPred 0.4410 LossAtt 0.2840 TrainAcc 0.8700 TestAcc 0.5646 0.8200
epoch 1400 LossPred 0.4990 LossAtt 0.3061 TrainAcc 0.8400 TestAcc 0.5553 0.7850
epoch 1500 LossPred 0.4254 LossAtt 0.3060 TrainAcc 0.8600 TestAcc 0.5573 0.8100
epoch 1600 LossPred 0.5073 LossAtt 0.2849 TrainAcc 0.8500 TestAcc 0.5543 0.8050
epoch 1700 LossPred 0.4441 LossAtt 0.2920 TrainAcc 0.8400 TestAcc 0.5470 0.8100
epoch 1800 LossPred 0.4587 LossAtt 0.2849 TrainAcc 0.8500 TestAcc 0.5425 0.7950
epoch 1900 LossPred 0.5029 LossAtt 0.2949 TrainAcc 0.8300 TestAcc 0.5528 0.7850
epoch 2000 LossPred 0.4791 LossAtt 0.2906 TrainAcc 0.8400 TestAcc 0.5408 0.7800
epoch 2100 LossPred 0.4757 LossAtt 0.2866 TrainAcc 0.8300 TestAcc 0.5541 0.7650
epoch 2200 LossPred 0.4698 LossAtt 0.2749 TrainAcc 0.8400 TestAcc 0.5568 0.7600
epoch 2300 LossPred 0.4574 LossAtt 0.2774 TrainAcc 0.8300 TestAcc 0.5498 0.7600
epoch 2400 LossPred 0.4697 LossAtt 0.2762 TrainAcc 0.8300 TestAcc 0.5490 0.7700
epoch 2500 LossPred 0.4717 LossAtt 0.2630 TrainAcc 0.8300 TestAcc 0.5455 0.7800
Optimization Finished!
********** replication  13  **********
epoch   0 LossPred 1.1193 LossAtt 1.0185 TrainAcc 0.4600 TestAcc 0.4580 0.4650
epoch 100 LossPred 0.8306 LossAtt 0.3038 TrainAcc 0.6900 TestAcc 0.6544 0.6850
epoch 200 LossPred 0.3643 LossAtt 0.2690 TrainAcc 0.9000 TestAcc 0.8679 0.8800
epoch 300 LossPred 0.3133 LossAtt 0.2677 TrainAcc 0.9000 TestAcc 0.8976 0.8500
epoch 400 LossPred 0.2956 LossAtt 0.2255 TrainAcc 0.9100 TestAcc 0.8544 0.8900
epoch 500 LossPred 0.2181 LossAtt 0.2169 TrainAcc 0.9300 TestAcc 0.9127 0.9100
epoch 600 LossPred 0.3023 LossAtt 0.2196 TrainAcc 0.9000 TestAcc 0.8961 0.8350
epoch 700 LossPred 0.2034 LossAtt 0.2038 TrainAcc 0.9400 TestAcc 0.8981 0.8750
epoch 800 LossPred 0.2939 LossAtt 0.1944 TrainAcc 0.9400 TestAcc 0.8629 0.9050
epoch 900 LossPred 0.2933 LossAtt 0.1787 TrainAcc 0.9300 TestAcc 0.8684 0.9150
epoch 1000 LossPred 0.3441 LossAtt 0.1689 TrainAcc 0.8900 TestAcc 0.8388 0.8850
epoch 1100 LossPred 0.4333 LossAtt 0.1773 TrainAcc 0.8500 TestAcc 0.8336 0.8350
epoch 1200 LossPred 0.5031 LossAtt 0.1895 TrainAcc 0.8100 TestAcc 0.7550 0.8100
epoch 1300 LossPred 0.7208 LossAtt 0.1855 TrainAcc 0.7600 TestAcc 0.6904 0.7600
epoch 1400 LossPred 0.4521 LossAtt 0.1967 TrainAcc 0.8200 TestAcc 0.8146 0.8300
epoch 1500 LossPred 0.3809 LossAtt 0.2052 TrainAcc 0.8800 TestAcc 0.8458 0.8900
epoch 1600 LossPred 0.3008 LossAtt 0.2039 TrainAcc 0.9100 TestAcc 0.8794 0.8800
epoch 1700 LossPred 0.4472 LossAtt 0.1883 TrainAcc 0.8500 TestAcc 0.8118 0.8550
epoch 1800 LossPred 0.6529 LossAtt 0.1766 TrainAcc 0.7900 TestAcc 0.7252 0.7850
epoch 1900 LossPred 0.5602 LossAtt 0.1685 TrainAcc 0.8100 TestAcc 0.7510 0.8150
epoch 2000 LossPred 0.3587 LossAtt 0.1840 TrainAcc 0.9100 TestAcc 0.8604 0.8800
epoch 2100 LossPred 0.3463 LossAtt 0.1799 TrainAcc 0.9200 TestAcc 0.8666 0.8800
epoch 2200 LossPred 0.3474 LossAtt 0.1684 TrainAcc 0.9000 TestAcc 0.8666 0.8750
epoch 2300 LossPred 0.3891 LossAtt 0.1764 TrainAcc 0.8700 TestAcc 0.8711 0.8750
epoch 2400 LossPred 0.3034 LossAtt 0.1695 TrainAcc 0.9000 TestAcc 0.8771 0.8800
epoch 2500 LossPred 0.3530 LossAtt 0.1673 TrainAcc 0.8800 TestAcc 0.8706 0.8800
Optimization Finished!
********** replication  14  **********
epoch   0 LossPred 1.0360 LossAtt 1.0071 TrainAcc 0.5200 TestAcc 0.4970 0.5200
epoch 100 LossPred 0.9700 LossAtt 0.2528 TrainAcc 0.6000 TestAcc 0.5518 0.6000
epoch 200 LossPred 0.9299 LossAtt 0.3008 TrainAcc 0.6400 TestAcc 0.5633 0.6450
epoch 300 LossPred 0.8489 LossAtt 0.3012 TrainAcc 0.6400 TestAcc 0.5443 0.6600
epoch 400 LossPred 0.8309 LossAtt 0.3534 TrainAcc 0.6800 TestAcc 0.5418 0.7050
epoch 500 LossPred 0.7625 LossAtt 0.3691 TrainAcc 0.7600 TestAcc 0.5473 0.7250
epoch 600 LossPred 0.6856 LossAtt 0.3831 TrainAcc 0.7800 TestAcc 0.5460 0.7350
epoch 700 LossPred 0.6628 LossAtt 0.4042 TrainAcc 0.7800 TestAcc 0.5445 0.7450
epoch 800 LossPred 0.7032 LossAtt 0.4064 TrainAcc 0.7600 TestAcc 0.5353 0.6850
epoch 900 LossPred 0.5962 LossAtt 0.3989 TrainAcc 0.8000 TestAcc 0.5310 0.7400
epoch 1000 LossPred 0.6715 LossAtt 0.4095 TrainAcc 0.7700 TestAcc 0.5383 0.7150
epoch 1100 LossPred 0.6309 LossAtt 0.4074 TrainAcc 0.8100 TestAcc 0.5320 0.7650
epoch 1200 LossPred 0.5937 LossAtt 0.3929 TrainAcc 0.8000 TestAcc 0.5378 0.7600
epoch 1300 LossPred 0.6132 LossAtt 0.3929 TrainAcc 0.7700 TestAcc 0.5365 0.7550
epoch 1400 LossPred 0.6087 LossAtt 0.3970 TrainAcc 0.7900 TestAcc 0.5255 0.7350
epoch 1500 LossPred 0.5650 LossAtt 0.4111 TrainAcc 0.7900 TestAcc 0.5340 0.7300
epoch 1600 LossPred 0.5866 LossAtt 0.4065 TrainAcc 0.7600 TestAcc 0.5363 0.7250
epoch 1700 LossPred 0.5661 LossAtt 0.3828 TrainAcc 0.8200 TestAcc 0.5345 0.7300
epoch 1800 LossPred 0.5232 LossAtt 0.3757 TrainAcc 0.8200 TestAcc 0.5400 0.7350
epoch 1900 LossPred 0.5069 LossAtt 0.3610 TrainAcc 0.8400 TestAcc 0.5423 0.7500
epoch 2000 LossPred 0.5062 LossAtt 0.3628 TrainAcc 0.8300 TestAcc 0.5400 0.7350
epoch 2100 LossPred 0.5226 LossAtt 0.3747 TrainAcc 0.8400 TestAcc 0.5400 0.7400
epoch 2200 LossPred 0.4824 LossAtt 0.3816 TrainAcc 0.8500 TestAcc 0.5383 0.7500
epoch 2300 LossPred 0.5309 LossAtt 0.3870 TrainAcc 0.8000 TestAcc 0.5490 0.7500
epoch 2400 LossPred 0.5358 LossAtt 0.3685 TrainAcc 0.8300 TestAcc 0.5365 0.7400
epoch 2500 LossPred 0.5043 LossAtt 0.3627 TrainAcc 0.8300 TestAcc 0.5373 0.7250
Optimization Finished!
********** replication  15  **********
epoch   0 LossPred 1.0710 LossAtt 1.0216 TrainAcc 0.5400 TestAcc 0.5378 0.5050
epoch 100 LossPred 0.9089 LossAtt 0.2900 TrainAcc 0.6200 TestAcc 0.5583 0.6150
epoch 200 LossPred 0.8447 LossAtt 0.3074 TrainAcc 0.6500 TestAcc 0.5400 0.6500
epoch 300 LossPred 0.8144 LossAtt 0.3475 TrainAcc 0.6900 TestAcc 0.5711 0.6950
epoch 400 LossPred 0.7694 LossAtt 0.3610 TrainAcc 0.7300 TestAcc 0.5568 0.7100
epoch 500 LossPred 0.6656 LossAtt 0.4014 TrainAcc 0.7700 TestAcc 0.5508 0.7450
epoch 600 LossPred 0.5560 LossAtt 0.4170 TrainAcc 0.8300 TestAcc 0.5185 0.7700
epoch 700 LossPred 0.5324 LossAtt 0.4166 TrainAcc 0.8000 TestAcc 0.5073 0.7700
epoch 800 LossPred 0.4501 LossAtt 0.4227 TrainAcc 0.8900 TestAcc 0.5015 0.8300
epoch 900 LossPred 0.4823 LossAtt 0.4254 TrainAcc 0.8600 TestAcc 0.4952 0.8050
epoch 1000 LossPred 0.4177 LossAtt 0.4275 TrainAcc 0.8900 TestAcc 0.4955 0.8200
epoch 1100 LossPred 0.4029 LossAtt 0.4133 TrainAcc 0.9100 TestAcc 0.4890 0.8300
epoch 1200 LossPred 0.3758 LossAtt 0.4061 TrainAcc 0.9100 TestAcc 0.4935 0.8050
epoch 1300 LossPred 0.3990 LossAtt 0.4067 TrainAcc 0.9000 TestAcc 0.4892 0.8150
epoch 1400 LossPred 0.3777 LossAtt 0.4031 TrainAcc 0.9100 TestAcc 0.4910 0.8100
epoch 1500 LossPred 0.3637 LossAtt 0.4139 TrainAcc 0.9300 TestAcc 0.4820 0.8000
epoch 1600 LossPred 0.3934 LossAtt 0.3990 TrainAcc 0.9100 TestAcc 0.4877 0.8500
epoch 1700 LossPred 0.3379 LossAtt 0.3954 TrainAcc 0.9200 TestAcc 0.4822 0.8150
epoch 1800 LossPred 0.3256 LossAtt 0.4089 TrainAcc 0.9100 TestAcc 0.4865 0.8250
epoch 1900 LossPred 0.3242 LossAtt 0.4109 TrainAcc 0.9300 TestAcc 0.4832 0.8000
epoch 2000 LossPred 0.3282 LossAtt 0.4188 TrainAcc 0.9300 TestAcc 0.4870 0.8300
epoch 2100 LossPred 0.3339 LossAtt 0.4063 TrainAcc 0.9200 TestAcc 0.4882 0.8150
epoch 2200 LossPred 0.2914 LossAtt 0.3998 TrainAcc 0.9300 TestAcc 0.4832 0.8000
epoch 2300 LossPred 0.3070 LossAtt 0.3999 TrainAcc 0.9200 TestAcc 0.4875 0.8400
epoch 2400 LossPred 0.2833 LossAtt 0.4088 TrainAcc 0.9400 TestAcc 0.4855 0.8400
epoch 2500 LossPred 0.2898 LossAtt 0.4054 TrainAcc 0.9300 TestAcc 0.4847 0.8200
Optimization Finished!
********** replication  16  **********
epoch   0 LossPred 1.4711 LossAtt 0.9759 TrainAcc 0.3900 TestAcc 0.4062 0.3900
epoch 100 LossPred 0.9310 LossAtt 0.3048 TrainAcc 0.6100 TestAcc 0.5938 0.6100
epoch 200 LossPred 0.9041 LossAtt 0.2367 TrainAcc 0.6200 TestAcc 0.5118 0.6050
epoch 300 LossPred 0.8716 LossAtt 0.2662 TrainAcc 0.6400 TestAcc 0.5340 0.6450
epoch 400 LossPred 0.8397 LossAtt 0.2711 TrainAcc 0.6900 TestAcc 0.5618 0.6850
epoch 500 LossPred 0.7949 LossAtt 0.2699 TrainAcc 0.7100 TestAcc 0.5608 0.6800
epoch 600 LossPred 0.7565 LossAtt 0.2549 TrainAcc 0.7600 TestAcc 0.5450 0.7150
epoch 700 LossPred 0.7297 LossAtt 0.2562 TrainAcc 0.7700 TestAcc 0.5448 0.7150
epoch 800 LossPred 0.7197 LossAtt 0.2613 TrainAcc 0.7500 TestAcc 0.5405 0.7250
epoch 900 LossPred 0.6957 LossAtt 0.2648 TrainAcc 0.7700 TestAcc 0.5393 0.7250
epoch 1000 LossPred 0.6890 LossAtt 0.2566 TrainAcc 0.7800 TestAcc 0.5413 0.7300
epoch 1100 LossPred 0.6828 LossAtt 0.2543 TrainAcc 0.7700 TestAcc 0.5473 0.7400
epoch 1200 LossPred 0.6809 LossAtt 0.2600 TrainAcc 0.7600 TestAcc 0.5508 0.7550
epoch 1300 LossPred 0.6685 LossAtt 0.2579 TrainAcc 0.7800 TestAcc 0.5398 0.7650
epoch 1400 LossPred 0.6649 LossAtt 0.2702 TrainAcc 0.7900 TestAcc 0.5480 0.7500
epoch 1500 LossPred 0.6651 LossAtt 0.2627 TrainAcc 0.8000 TestAcc 0.5435 0.7600
epoch 1600 LossPred 0.6563 LossAtt 0.2602 TrainAcc 0.8000 TestAcc 0.5448 0.7650
epoch 1700 LossPred 0.6739 LossAtt 0.2409 TrainAcc 0.8000 TestAcc 0.5453 0.7450
epoch 1800 LossPred 0.6913 LossAtt 0.2451 TrainAcc 0.7600 TestAcc 0.5445 0.7500
epoch 1900 LossPred 0.6433 LossAtt 0.2362 TrainAcc 0.8000 TestAcc 0.5423 0.7650
epoch 2000 LossPred 0.6667 LossAtt 0.2314 TrainAcc 0.7700 TestAcc 0.5533 0.7600
epoch 2100 LossPred 0.6505 LossAtt 0.2250 TrainAcc 0.8000 TestAcc 0.5506 0.7650
epoch 2200 LossPred 0.6358 LossAtt 0.2343 TrainAcc 0.8000 TestAcc 0.5503 0.7700
epoch 2300 LossPred 0.6516 LossAtt 0.2195 TrainAcc 0.7800 TestAcc 0.5541 0.7600
epoch 2400 LossPred 0.6472 LossAtt 0.2178 TrainAcc 0.7800 TestAcc 0.5438 0.7600
epoch 2500 LossPred 0.6360 LossAtt 0.2220 TrainAcc 0.7900 TestAcc 0.5445 0.7350
Optimization Finished!
********** replication  17  **********
epoch   0 LossPred 1.0014 LossAtt 1.0223 TrainAcc 0.5100 TestAcc 0.5053 0.5100
epoch 100 LossPred 0.8255 LossAtt 0.2600 TrainAcc 0.6400 TestAcc 0.5888 0.6500
epoch 200 LossPred 0.7980 LossAtt 0.1794 TrainAcc 0.7000 TestAcc 0.6396 0.7000
epoch 300 LossPred 0.7504 LossAtt 0.2577 TrainAcc 0.7000 TestAcc 0.6396 0.7050
epoch 400 LossPred 0.5265 LossAtt 0.3254 TrainAcc 0.8300 TestAcc 0.8051 0.8350
epoch 500 LossPred 0.4623 LossAtt 0.2863 TrainAcc 0.8400 TestAcc 0.8426 0.8350
epoch 600 LossPred 0.5240 LossAtt 0.2912 TrainAcc 0.8200 TestAcc 0.8216 0.8300
epoch 700 LossPred 0.5340 LossAtt 0.2935 TrainAcc 0.8300 TestAcc 0.8326 0.8100
epoch 800 LossPred 0.4153 LossAtt 0.2885 TrainAcc 0.8500 TestAcc 0.8366 0.8550
epoch 900 LossPred 0.4429 LossAtt 0.3001 TrainAcc 0.8500 TestAcc 0.8308 0.8450
epoch 1000 LossPred 0.4978 LossAtt 0.2962 TrainAcc 0.8400 TestAcc 0.7948 0.8200
epoch 1100 LossPred 0.3465 LossAtt 0.2970 TrainAcc 0.9000 TestAcc 0.8924 0.8600
epoch 1200 LossPred 0.4465 LossAtt 0.2842 TrainAcc 0.8400 TestAcc 0.8121 0.8350
epoch 1300 LossPred 0.5611 LossAtt 0.2865 TrainAcc 0.7700 TestAcc 0.8413 0.7700
epoch 1400 LossPred 0.3924 LossAtt 0.2809 TrainAcc 0.8700 TestAcc 0.8931 0.8450
epoch 1500 LossPred 0.4699 LossAtt 0.2748 TrainAcc 0.8400 TestAcc 0.8031 0.8100
epoch 1600 LossPred 0.5475 LossAtt 0.2874 TrainAcc 0.7700 TestAcc 0.8478 0.7700
epoch 1700 LossPred 0.4142 LossAtt 0.2803 TrainAcc 0.8700 TestAcc 0.8228 0.8400
epoch 1800 LossPred 0.3422 LossAtt 0.2711 TrainAcc 0.8900 TestAcc 0.8566 0.8650
epoch 1900 LossPred 0.4853 LossAtt 0.2707 TrainAcc 0.8200 TestAcc 0.8729 0.8000
epoch 2000 LossPred 0.2650 LossAtt 0.2624 TrainAcc 0.9400 TestAcc 0.9024 0.8950
epoch 2100 LossPred 0.2114 LossAtt 0.2498 TrainAcc 0.9600 TestAcc 0.9249 0.8950
epoch 2200 LossPred 0.2321 LossAtt 0.2474 TrainAcc 0.9300 TestAcc 0.8836 0.9000
epoch 2300 LossPred 0.1682 LossAtt 0.2476 TrainAcc 0.9500 TestAcc 0.9199 0.9200
epoch 2400 LossPred 0.1648 LossAtt 0.2562 TrainAcc 0.9500 TestAcc 0.9102 0.9200
epoch 2500 LossPred 0.1530 LossAtt 0.2508 TrainAcc 0.9600 TestAcc 0.9149 0.9300
Optimization Finished!
********** replication  18  **********
epoch   0 LossPred 1.1057 LossAtt 1.0341 TrainAcc 0.4400 TestAcc 0.4472 0.4750
epoch 100 LossPred 0.8059 LossAtt 0.2295 TrainAcc 0.6600 TestAcc 0.5851 0.6700
epoch 200 LossPred 0.5505 LossAtt 0.2044 TrainAcc 0.8000 TestAcc 0.8193 0.8000
epoch 300 LossPred 0.4022 LossAtt 0.1749 TrainAcc 0.8700 TestAcc 0.8511 0.8500
epoch 400 LossPred 0.4050 LossAtt 0.1760 TrainAcc 0.8800 TestAcc 0.8368 0.8250
epoch 500 LossPred 0.5300 LossAtt 0.1627 TrainAcc 0.8200 TestAcc 0.7960 0.8150
epoch 600 LossPred 0.6287 LossAtt 0.1529 TrainAcc 0.7700 TestAcc 0.7945 0.7750
epoch 700 LossPred 0.9807 LossAtt 0.1260 TrainAcc 0.6400 TestAcc 0.6647 0.6700
epoch 800 LossPred 0.4164 LossAtt 0.1248 TrainAcc 0.8500 TestAcc 0.8446 0.8500
epoch 900 LossPred 0.5214 LossAtt 0.1484 TrainAcc 0.8200 TestAcc 0.8021 0.8150
epoch 1000 LossPred 0.5007 LossAtt 0.1228 TrainAcc 0.8400 TestAcc 0.7800 0.7900
epoch 1100 LossPred 0.5722 LossAtt 0.1372 TrainAcc 0.7900 TestAcc 0.7417 0.7950
epoch 1200 LossPred 0.9255 LossAtt 0.1151 TrainAcc 0.6500 TestAcc 0.6912 0.6900
epoch 1300 LossPred 0.4145 LossAtt 0.1180 TrainAcc 0.8400 TestAcc 0.8418 0.8450
epoch 1400 LossPred 0.4563 LossAtt 0.1243 TrainAcc 0.8400 TestAcc 0.8181 0.8400
epoch 1500 LossPred 0.4840 LossAtt 0.1529 TrainAcc 0.8300 TestAcc 0.8001 0.8150
epoch 1600 LossPred 0.5881 LossAtt 0.1939 TrainAcc 0.8200 TestAcc 0.7570 0.7950
epoch 1700 LossPred 0.5361 LossAtt 0.1681 TrainAcc 0.8300 TestAcc 0.8073 0.8150
epoch 1800 LossPred 0.5048 LossAtt 0.1672 TrainAcc 0.8400 TestAcc 0.8161 0.8400
epoch 1900 LossPred 0.4637 LossAtt 0.1625 TrainAcc 0.8400 TestAcc 0.8423 0.8500
epoch 2000 LossPred 0.4223 LossAtt 0.1635 TrainAcc 0.8500 TestAcc 0.8458 0.8500
epoch 2100 LossPred 0.4729 LossAtt 0.1616 TrainAcc 0.8500 TestAcc 0.8208 0.8350
epoch 2200 LossPred 0.4417 LossAtt 0.1651 TrainAcc 0.8500 TestAcc 0.8351 0.8450
epoch 2300 LossPred 0.4139 LossAtt 0.1504 TrainAcc 0.8700 TestAcc 0.8356 0.8550
epoch 2400 LossPred 0.4209 LossAtt 0.1664 TrainAcc 0.8700 TestAcc 0.8343 0.8750
epoch 2500 LossPred 0.6396 LossAtt 0.1672 TrainAcc 0.7600 TestAcc 0.7670 0.7500
Optimization Finished!
********** replication  19  **********
epoch   0 LossPred 1.1006 LossAtt 1.0005 TrainAcc 0.3900 TestAcc 0.4279 0.4200
epoch 100 LossPred 0.8116 LossAtt 0.3529 TrainAcc 0.6500 TestAcc 0.5856 0.6400
epoch 200 LossPred 0.4535 LossAtt 0.3270 TrainAcc 0.8600 TestAcc 0.8111 0.8550
epoch 300 LossPred 0.3486 LossAtt 0.2918 TrainAcc 0.8900 TestAcc 0.8273 0.8800
epoch 400 LossPred 0.2958 LossAtt 0.2834 TrainAcc 0.9300 TestAcc 0.8471 0.9200
epoch 500 LossPred 0.3017 LossAtt 0.2843 TrainAcc 0.9200 TestAcc 0.8276 0.9050
epoch 600 LossPred 0.2279 LossAtt 0.2677 TrainAcc 0.9400 TestAcc 0.8634 0.9150
epoch 700 LossPred 0.3109 LossAtt 0.2697 TrainAcc 0.9000 TestAcc 0.8521 0.9050
epoch 800 LossPred 0.1709 LossAtt 0.2841 TrainAcc 0.9500 TestAcc 0.8919 0.9450
epoch 900 LossPred 0.1605 LossAtt 0.2930 TrainAcc 0.9500 TestAcc 0.8734 0.9500
epoch 1000 LossPred 0.1693 LossAtt 0.2706 TrainAcc 0.9400 TestAcc 0.8481 0.9400
epoch 1100 LossPred 0.1419 LossAtt 0.2679 TrainAcc 0.9500 TestAcc 0.8604 0.9550
epoch 1200 LossPred 0.0936 LossAtt 0.2663 TrainAcc 0.9800 TestAcc 0.8794 0.9700
epoch 1300 LossPred 0.0848 LossAtt 0.2381 TrainAcc 0.9800 TestAcc 0.8839 0.9700
epoch 1400 LossPred 0.0931 LossAtt 0.2572 TrainAcc 0.9800 TestAcc 0.8836 0.9750
epoch 1500 LossPred 0.5209 LossAtt 0.2200 TrainAcc 0.8400 TestAcc 0.7823 0.8350
epoch 1600 LossPred 0.1135 LossAtt 0.2274 TrainAcc 0.9700 TestAcc 0.8496 0.9650
epoch 1700 LossPred 0.0980 LossAtt 0.2216 TrainAcc 0.9700 TestAcc 0.8909 0.9700
epoch 1800 LossPred 0.0948 LossAtt 0.2110 TrainAcc 0.9600 TestAcc 0.8874 0.9650
epoch 1900 LossPred 0.1454 LossAtt 0.2013 TrainAcc 0.9500 TestAcc 0.8601 0.9600
epoch 2000 LossPred 0.0903 LossAtt 0.2141 TrainAcc 0.9800 TestAcc 0.8786 0.9800
epoch 2100 LossPred 0.2943 LossAtt 0.2106 TrainAcc 0.9100 TestAcc 0.8131 0.9100
epoch 2200 LossPred 0.5373 LossAtt 0.2052 TrainAcc 0.8400 TestAcc 0.7693 0.8400
epoch 2300 LossPred 0.4019 LossAtt 0.1998 TrainAcc 0.8700 TestAcc 0.7975 0.8650
epoch 2400 LossPred 0.0623 LossAtt 0.1956 TrainAcc 0.9900 TestAcc 0.8786 0.9950
epoch 2500 LossPred 0.4304 LossAtt 0.1942 TrainAcc 0.8800 TestAcc 0.7793 0.8700
Optimization Finished!
********** replication  20  **********
epoch   0 LossPred 0.9758 LossAtt 1.0270 TrainAcc 0.6000 TestAcc 0.5418 0.5950
epoch 100 LossPred 0.6134 LossAtt 0.3441 TrainAcc 0.7900 TestAcc 0.7525 0.7900
epoch 200 LossPred 0.4581 LossAtt 0.2771 TrainAcc 0.8300 TestAcc 0.7840 0.8350
epoch 300 LossPred 0.3614 LossAtt 0.2514 TrainAcc 0.9000 TestAcc 0.8656 0.8800
epoch 400 LossPred 0.3202 LossAtt 0.2510 TrainAcc 0.8800 TestAcc 0.8358 0.8650
epoch 500 LossPred 0.5736 LossAtt 0.2466 TrainAcc 0.7600 TestAcc 0.7505 0.7750
epoch 600 LossPred 0.2696 LossAtt 0.2455 TrainAcc 0.9000 TestAcc 0.8646 0.8750
epoch 700 LossPred 0.3520 LossAtt 0.2404 TrainAcc 0.8800 TestAcc 0.8546 0.8950
epoch 800 LossPred 0.3341 LossAtt 0.2284 TrainAcc 0.9000 TestAcc 0.8053 0.8600
epoch 900 LossPred 0.3210 LossAtt 0.2290 TrainAcc 0.8800 TestAcc 0.8243 0.8600
epoch 1000 LossPred 0.5873 LossAtt 0.2268 TrainAcc 0.7900 TestAcc 0.8011 0.8000
epoch 1100 LossPred 0.4122 LossAtt 0.2196 TrainAcc 0.8900 TestAcc 0.8611 0.8800
epoch 1200 LossPred 0.3732 LossAtt 0.2281 TrainAcc 0.8800 TestAcc 0.8636 0.8750
epoch 1300 LossPred 0.3672 LossAtt 0.2120 TrainAcc 0.8600 TestAcc 0.8221 0.8400
epoch 1400 LossPred 0.2196 LossAtt 0.2077 TrainAcc 0.9400 TestAcc 0.9099 0.9150
epoch 1500 LossPred 0.2405 LossAtt 0.2052 TrainAcc 0.9100 TestAcc 0.8894 0.8900
epoch 1600 LossPred 0.6726 LossAtt 0.2106 TrainAcc 0.7800 TestAcc 0.7948 0.7700
epoch 1700 LossPred 0.4972 LossAtt 0.2055 TrainAcc 0.8200 TestAcc 0.8106 0.8200
epoch 1800 LossPred 0.3415 LossAtt 0.2282 TrainAcc 0.8800 TestAcc 0.8814 0.8800
epoch 1900 LossPred 0.6441 LossAtt 0.2049 TrainAcc 0.7600 TestAcc 0.7270 0.7400
epoch 2000 LossPred 0.4728 LossAtt 0.1979 TrainAcc 0.8400 TestAcc 0.8156 0.8150
epoch 2100 LossPred 0.5814 LossAtt 0.2014 TrainAcc 0.7900 TestAcc 0.7688 0.7850
epoch 2200 LossPred 0.6338 LossAtt 0.1788 TrainAcc 0.7800 TestAcc 0.7898 0.7950
epoch 2300 LossPred 0.3501 LossAtt 0.1760 TrainAcc 0.8800 TestAcc 0.8691 0.8700
epoch 2400 LossPred 0.5081 LossAtt 0.1797 TrainAcc 0.8000 TestAcc 0.7958 0.8050
epoch 2500 LossPred 0.5955 LossAtt 0.1764 TrainAcc 0.8200 TestAcc 0.8246 0.8100
Optimization Finished!
********** replication  21  **********
epoch   0 LossPred 1.0046 LossAtt 1.0187 TrainAcc 0.5500 TestAcc 0.4910 0.5450
epoch 100 LossPred 0.8785 LossAtt 0.2766 TrainAcc 0.6400 TestAcc 0.5946 0.6400
epoch 200 LossPred 0.5837 LossAtt 0.2601 TrainAcc 0.8000 TestAcc 0.8248 0.8000
epoch 300 LossPred 0.3455 LossAtt 0.2333 TrainAcc 0.8900 TestAcc 0.7803 0.8500
epoch 400 LossPred 0.5147 LossAtt 0.2307 TrainAcc 0.8400 TestAcc 0.8293 0.7900
epoch 500 LossPred 0.4732 LossAtt 0.2355 TrainAcc 0.8300 TestAcc 0.7195 0.8300
epoch 600 LossPred 0.2717 LossAtt 0.2352 TrainAcc 0.9000 TestAcc 0.8841 0.8800
epoch 700 LossPred 0.2130 LossAtt 0.2398 TrainAcc 0.9200 TestAcc 0.8096 0.9000
epoch 800 LossPred 0.3166 LossAtt 0.2633 TrainAcc 0.8900 TestAcc 0.7548 0.8700
epoch 900 LossPred 0.1809 LossAtt 0.2526 TrainAcc 0.9300 TestAcc 0.8453 0.9150
epoch 1000 LossPred 0.2511 LossAtt 0.2399 TrainAcc 0.9400 TestAcc 0.8916 0.8900
epoch 1100 LossPred 0.2594 LossAtt 0.2470 TrainAcc 0.9400 TestAcc 0.8844 0.8800
epoch 1200 LossPred 0.2277 LossAtt 0.2374 TrainAcc 0.9400 TestAcc 0.8971 0.9100
epoch 1300 LossPred 0.1398 LossAtt 0.2423 TrainAcc 0.9400 TestAcc 0.8631 0.9250
epoch 1400 LossPred 0.1385 LossAtt 0.2317 TrainAcc 0.9600 TestAcc 0.8781 0.9350
epoch 1500 LossPred 0.2026 LossAtt 0.2420 TrainAcc 0.9300 TestAcc 0.8561 0.9250
epoch 1600 LossPred 0.1515 LossAtt 0.2240 TrainAcc 0.9600 TestAcc 0.8811 0.9250
epoch 1700 LossPred 0.1765 LossAtt 0.2204 TrainAcc 0.9500 TestAcc 0.8901 0.9450
epoch 1800 LossPred 0.1980 LossAtt 0.2143 TrainAcc 0.9200 TestAcc 0.8378 0.9400
epoch 1900 LossPred 0.1420 LossAtt 0.2028 TrainAcc 0.9500 TestAcc 0.8796 0.9500
epoch 2000 LossPred 0.1753 LossAtt 0.2295 TrainAcc 0.9400 TestAcc 0.8726 0.9350
epoch 2100 LossPred 0.1494 LossAtt 0.2274 TrainAcc 0.9500 TestAcc 0.8814 0.9200
epoch 2200 LossPred 0.2064 LossAtt 0.2229 TrainAcc 0.9400 TestAcc 0.8921 0.9300
epoch 2300 LossPred 0.1447 LossAtt 0.2510 TrainAcc 0.9500 TestAcc 0.8709 0.9400
epoch 2400 LossPred 0.1635 LossAtt 0.2342 TrainAcc 0.9400 TestAcc 0.8894 0.9200
epoch 2500 LossPred 0.1621 LossAtt 0.2354 TrainAcc 0.9400 TestAcc 0.9002 0.9400
Optimization Finished!
********** replication  22  **********
epoch   0 LossPred 1.0884 LossAtt 0.9900 TrainAcc 0.5200 TestAcc 0.5323 0.5000
epoch 100 LossPred 0.9119 LossAtt 0.2837 TrainAcc 0.6100 TestAcc 0.6201 0.6000
epoch 200 LossPred 0.5465 LossAtt 0.2994 TrainAcc 0.7900 TestAcc 0.8226 0.7850
epoch 300 LossPred 0.4443 LossAtt 0.2597 TrainAcc 0.8200 TestAcc 0.8584 0.8000
epoch 400 LossPred 0.3607 LossAtt 0.2433 TrainAcc 0.8700 TestAcc 0.8856 0.8300
epoch 500 LossPred 0.2915 LossAtt 0.2414 TrainAcc 0.9000 TestAcc 0.8901 0.8350
epoch 600 LossPred 0.3358 LossAtt 0.2338 TrainAcc 0.9100 TestAcc 0.8704 0.8650
epoch 700 LossPred 0.2830 LossAtt 0.2229 TrainAcc 0.9100 TestAcc 0.8794 0.8650
epoch 800 LossPred 0.2800 LossAtt 0.2286 TrainAcc 0.9100 TestAcc 0.8846 0.8450
epoch 900 LossPred 0.3845 LossAtt 0.2317 TrainAcc 0.8700 TestAcc 0.8559 0.8450
epoch 1000 LossPred 0.2812 LossAtt 0.2209 TrainAcc 0.9200 TestAcc 0.8881 0.8350
epoch 1100 LossPred 0.3037 LossAtt 0.2101 TrainAcc 0.9100 TestAcc 0.8829 0.8350
epoch 1200 LossPred 0.2976 LossAtt 0.2139 TrainAcc 0.9000 TestAcc 0.8821 0.8400
epoch 1300 LossPred 0.3325 LossAtt 0.2045 TrainAcc 0.8800 TestAcc 0.8809 0.8150
epoch 1400 LossPred 0.3073 LossAtt 0.2042 TrainAcc 0.9100 TestAcc 0.8801 0.8400
epoch 1500 LossPred 0.3112 LossAtt 0.1950 TrainAcc 0.8900 TestAcc 0.8719 0.8750
epoch 1600 LossPred 0.3007 LossAtt 0.2012 TrainAcc 0.8800 TestAcc 0.8784 0.8600
epoch 1700 LossPred 0.4912 LossAtt 0.1985 TrainAcc 0.8400 TestAcc 0.8326 0.8350
epoch 1800 LossPred 0.2716 LossAtt 0.1769 TrainAcc 0.9100 TestAcc 0.8801 0.8650
epoch 1900 LossPred 0.2647 LossAtt 0.1705 TrainAcc 0.9300 TestAcc 0.8836 0.8350
epoch 2000 LossPred 0.2600 LossAtt 0.1723 TrainAcc 0.9200 TestAcc 0.8814 0.8600
epoch 2100 LossPred 0.3277 LossAtt 0.1732 TrainAcc 0.8800 TestAcc 0.8706 0.8200
epoch 2200 LossPred 0.2860 LossAtt 0.1762 TrainAcc 0.9000 TestAcc 0.8761 0.8600
epoch 2300 LossPred 0.2943 LossAtt 0.1725 TrainAcc 0.9000 TestAcc 0.8794 0.8400
epoch 2400 LossPred 0.2839 LossAtt 0.1723 TrainAcc 0.9200 TestAcc 0.8826 0.8500
epoch 2500 LossPred 0.3740 LossAtt 0.1713 TrainAcc 0.8800 TestAcc 0.8644 0.8500
Optimization Finished!
********** replication  23  **********
epoch   0 LossPred 1.0474 LossAtt 1.0046 TrainAcc 0.5500 TestAcc 0.5093 0.5250
epoch 100 LossPred 0.8800 LossAtt 0.2326 TrainAcc 0.6300 TestAcc 0.6296 0.6250
epoch 200 LossPred 0.7508 LossAtt 0.2761 TrainAcc 0.7300 TestAcc 0.7467 0.7000
epoch 300 LossPred 0.5899 LossAtt 0.2641 TrainAcc 0.7700 TestAcc 0.8293 0.7900
epoch 400 LossPred 0.5122 LossAtt 0.2266 TrainAcc 0.8300 TestAcc 0.8391 0.8150
epoch 500 LossPred 0.5419 LossAtt 0.2283 TrainAcc 0.8100 TestAcc 0.8393 0.7950
epoch 600 LossPred 0.4852 LossAtt 0.2358 TrainAcc 0.8200 TestAcc 0.8431 0.8200
epoch 700 LossPred 0.5010 LossAtt 0.2371 TrainAcc 0.8100 TestAcc 0.8471 0.8050
epoch 800 LossPred 0.4899 LossAtt 0.2050 TrainAcc 0.8300 TestAcc 0.8461 0.8200
epoch 900 LossPred 0.4403 LossAtt 0.2079 TrainAcc 0.8600 TestAcc 0.8641 0.8450
epoch 1000 LossPred 0.4461 LossAtt 0.1968 TrainAcc 0.8200 TestAcc 0.8679 0.8450
epoch 1100 LossPred 0.5725 LossAtt 0.2138 TrainAcc 0.7800 TestAcc 0.8153 0.7900
epoch 1200 LossPred 0.4352 LossAtt 0.1934 TrainAcc 0.8400 TestAcc 0.8629 0.8300
epoch 1300 LossPred 0.7653 LossAtt 0.1961 TrainAcc 0.7300 TestAcc 0.7695 0.7250
epoch 1400 LossPred 0.4659 LossAtt 0.2141 TrainAcc 0.8500 TestAcc 0.8536 0.8300
epoch 1500 LossPred 0.6377 LossAtt 0.2097 TrainAcc 0.7600 TestAcc 0.8078 0.7700
epoch 1600 LossPred 0.5270 LossAtt 0.1771 TrainAcc 0.8000 TestAcc 0.8569 0.8050
epoch 1700 LossPred 0.4326 LossAtt 0.1889 TrainAcc 0.8400 TestAcc 0.8761 0.8550
epoch 1800 LossPred 0.4607 LossAtt 0.1863 TrainAcc 0.8500 TestAcc 0.8579 0.8300
epoch 1900 LossPred 0.4056 LossAtt 0.1869 TrainAcc 0.8600 TestAcc 0.8844 0.8550
epoch 2000 LossPred 0.3988 LossAtt 0.1832 TrainAcc 0.8700 TestAcc 0.8819 0.8400
epoch 2100 LossPred 0.4373 LossAtt 0.1644 TrainAcc 0.8300 TestAcc 0.8789 0.8500
epoch 2200 LossPred 0.4649 LossAtt 0.1735 TrainAcc 0.8300 TestAcc 0.8774 0.8150
epoch 2300 LossPred 0.3692 LossAtt 0.1854 TrainAcc 0.8600 TestAcc 0.8924 0.8650
epoch 2400 LossPred 0.4457 LossAtt 0.1874 TrainAcc 0.8400 TestAcc 0.8744 0.8450
epoch 2500 LossPred 0.3481 LossAtt 0.1829 TrainAcc 0.9000 TestAcc 0.8964 0.8600
Optimization Finished!
********** replication  24  **********
epoch   0 LossPred 1.0756 LossAtt 1.0057 TrainAcc 0.4100 TestAcc 0.5198 0.4200
epoch 100 LossPred 0.8233 LossAtt 0.2450 TrainAcc 0.7100 TestAcc 0.5893 0.7100
epoch 200 LossPred 0.8211 LossAtt 0.2012 TrainAcc 0.7100 TestAcc 0.5893 0.7100
epoch 300 LossPred 0.8129 LossAtt 0.2083 TrainAcc 0.7100 TestAcc 0.5893 0.7100
epoch 400 LossPred 0.7820 LossAtt 0.1773 TrainAcc 0.7100 TestAcc 0.5893 0.7100
epoch 500 LossPred 0.7694 LossAtt 0.1844 TrainAcc 0.7100 TestAcc 0.5893 0.7100
epoch 600 LossPred 0.7552 LossAtt 0.2085 TrainAcc 0.7100 TestAcc 0.5893 0.7200
epoch 700 LossPred 0.7491 LossAtt 0.2417 TrainAcc 0.7100 TestAcc 0.5893 0.7100
epoch 800 LossPred 0.7160 LossAtt 0.2858 TrainAcc 0.7100 TestAcc 0.5893 0.7100
epoch 900 LossPred 0.7028 LossAtt 0.2835 TrainAcc 0.7100 TestAcc 0.5893 0.7100
epoch 1000 LossPred 0.6870 LossAtt 0.2921 TrainAcc 0.7500 TestAcc 0.6301 0.7150
epoch 1100 LossPred 0.6380 LossAtt 0.2952 TrainAcc 0.7300 TestAcc 0.6146 0.7350
epoch 1200 LossPred 0.4336 LossAtt 0.3147 TrainAcc 0.8600 TestAcc 0.6907 0.8500
epoch 1300 LossPred 0.2904 LossAtt 0.3099 TrainAcc 0.9200 TestAcc 0.7495 0.9100
epoch 1400 LossPred 0.2908 LossAtt 0.3033 TrainAcc 0.9300 TestAcc 0.7588 0.8950
epoch 1500 LossPred 0.3618 LossAtt 0.3254 TrainAcc 0.9000 TestAcc 0.7745 0.8850
epoch 1600 LossPred 0.2762 LossAtt 0.2797 TrainAcc 0.9300 TestAcc 0.7835 0.9100
epoch 1700 LossPred 0.2904 LossAtt 0.2822 TrainAcc 0.9400 TestAcc 0.8123 0.9150
epoch 1800 LossPred 0.2473 LossAtt 0.2676 TrainAcc 0.9500 TestAcc 0.8213 0.9250
epoch 1900 LossPred 0.3144 LossAtt 0.2656 TrainAcc 0.9200 TestAcc 0.8118 0.8850
epoch 2000 LossPred 0.2589 LossAtt 0.2660 TrainAcc 0.9400 TestAcc 0.8088 0.9150
epoch 2100 LossPred 0.2092 LossAtt 0.2573 TrainAcc 0.9500 TestAcc 0.8143 0.9350
epoch 2200 LossPred 0.1895 LossAtt 0.2666 TrainAcc 0.9600 TestAcc 0.8233 0.9200
epoch 2300 LossPred 0.2271 LossAtt 0.2684 TrainAcc 0.9400 TestAcc 0.8211 0.9100
epoch 2400 LossPred 0.2563 LossAtt 0.2508 TrainAcc 0.9300 TestAcc 0.8136 0.9000
epoch 2500 LossPred 0.2422 LossAtt 0.2742 TrainAcc 0.9400 TestAcc 0.8108 0.9100
Optimization Finished!
********** replication  25  **********
epoch   0 LossPred 0.9968 LossAtt 1.0253 TrainAcc 0.5100 TestAcc 0.4595 0.5300
epoch 100 LossPred 0.8766 LossAtt 0.2390 TrainAcc 0.6500 TestAcc 0.6206 0.6100
epoch 200 LossPred 1.1333 LossAtt 0.2811 TrainAcc 0.6300 TestAcc 0.6014 0.6350
epoch 300 LossPred 0.6643 LossAtt 0.2615 TrainAcc 0.7900 TestAcc 0.7830 0.7450
epoch 400 LossPred 0.4515 LossAtt 0.2414 TrainAcc 0.8400 TestAcc 0.8326 0.8450
epoch 500 LossPred 0.4740 LossAtt 0.2443 TrainAcc 0.8200 TestAcc 0.8328 0.8050
epoch 600 LossPred 0.3546 LossAtt 0.2374 TrainAcc 0.9000 TestAcc 0.8559 0.8450
epoch 700 LossPred 0.3275 LossAtt 0.2412 TrainAcc 0.9000 TestAcc 0.8631 0.8800
epoch 800 LossPred 0.3706 LossAtt 0.2353 TrainAcc 0.8400 TestAcc 0.8509 0.8350
epoch 900 LossPred 0.2906 LossAtt 0.2305 TrainAcc 0.9400 TestAcc 0.8666 0.8900
epoch 1000 LossPred 0.4560 LossAtt 0.2305 TrainAcc 0.8500 TestAcc 0.8271 0.8350
epoch 1100 LossPred 0.2497 LossAtt 0.2328 TrainAcc 0.9300 TestAcc 0.8869 0.9050
epoch 1200 LossPred 0.6055 LossAtt 0.2184 TrainAcc 0.8000 TestAcc 0.7723 0.8050
epoch 1300 LossPred 0.3920 LossAtt 0.2096 TrainAcc 0.9000 TestAcc 0.8338 0.8800
epoch 1400 LossPred 0.4375 LossAtt 0.2191 TrainAcc 0.8600 TestAcc 0.8386 0.8400
epoch 1500 LossPred 0.3093 LossAtt 0.1947 TrainAcc 0.9200 TestAcc 0.8569 0.9150
epoch 1600 LossPred 0.3206 LossAtt 0.1883 TrainAcc 0.9100 TestAcc 0.8679 0.9100
epoch 1700 LossPred 0.4863 LossAtt 0.1890 TrainAcc 0.8200 TestAcc 0.8021 0.8250
epoch 1800 LossPred 0.3084 LossAtt 0.1875 TrainAcc 0.9200 TestAcc 0.8561 0.9200
epoch 1900 LossPred 0.2859 LossAtt 0.1841 TrainAcc 0.9200 TestAcc 0.8619 0.9150
epoch 2000 LossPred 0.2808 LossAtt 0.1762 TrainAcc 0.9300 TestAcc 0.8611 0.9300
epoch 2100 LossPred 0.2780 LossAtt 0.1749 TrainAcc 0.9100 TestAcc 0.8689 0.9200
epoch 2200 LossPred 0.2973 LossAtt 0.1882 TrainAcc 0.9200 TestAcc 0.8529 0.9000
epoch 2300 LossPred 0.2686 LossAtt 0.1741 TrainAcc 0.9300 TestAcc 0.8596 0.9300
epoch 2400 LossPred 0.2689 LossAtt 0.1811 TrainAcc 0.9200 TestAcc 0.8621 0.9250
epoch 2500 LossPred 0.3204 LossAtt 0.1992 TrainAcc 0.9100 TestAcc 0.8666 0.9100
Optimization Finished!
********** replication  26  **********
epoch   0 LossPred 0.9819 LossAtt 1.0043 TrainAcc 0.5700 TestAcc 0.5668 0.5650
epoch 100 LossPred 0.9434 LossAtt 0.3404 TrainAcc 0.6400 TestAcc 0.5816 0.6400
epoch 200 LossPred 0.9007 LossAtt 0.3209 TrainAcc 0.6700 TestAcc 0.5698 0.6700
epoch 300 LossPred 0.7748 LossAtt 0.3713 TrainAcc 0.7100 TestAcc 0.5423 0.6850
epoch 400 LossPred 0.6408 LossAtt 0.3866 TrainAcc 0.7900 TestAcc 0.5205 0.7400
epoch 500 LossPred 0.6052 LossAtt 0.3836 TrainAcc 0.8000 TestAcc 0.5165 0.7350
epoch 600 LossPred 0.5664 LossAtt 0.3924 TrainAcc 0.8000 TestAcc 0.5233 0.7350
epoch 700 LossPred 0.5347 LossAtt 0.3613 TrainAcc 0.8400 TestAcc 0.5198 0.7500
epoch 800 LossPred 0.5238 LossAtt 0.3728 TrainAcc 0.8200 TestAcc 0.5200 0.7200
epoch 900 LossPred 0.5129 LossAtt 0.3548 TrainAcc 0.8700 TestAcc 0.5153 0.7450
epoch 1000 LossPred 0.4987 LossAtt 0.3299 TrainAcc 0.8800 TestAcc 0.5125 0.7600
epoch 1100 LossPred 0.5125 LossAtt 0.3395 TrainAcc 0.8400 TestAcc 0.5113 0.7350
epoch 1200 LossPred 0.4521 LossAtt 0.3494 TrainAcc 0.8500 TestAcc 0.5018 0.7400
epoch 1300 LossPred 0.4269 LossAtt 0.3527 TrainAcc 0.8500 TestAcc 0.5063 0.7600
epoch 1400 LossPred 0.4034 LossAtt 0.3569 TrainAcc 0.8500 TestAcc 0.5088 0.7900
epoch 1500 LossPred 0.3875 LossAtt 0.3577 TrainAcc 0.8900 TestAcc 0.5170 0.8150
epoch 1600 LossPred 0.3614 LossAtt 0.3723 TrainAcc 0.8900 TestAcc 0.5093 0.7850
epoch 1700 LossPred 0.3534 LossAtt 0.3617 TrainAcc 0.9100 TestAcc 0.5088 0.8150
epoch 1800 LossPred 0.3257 LossAtt 0.3685 TrainAcc 0.8900 TestAcc 0.5118 0.8450
epoch 1900 LossPred 0.3332 LossAtt 0.3708 TrainAcc 0.8900 TestAcc 0.5173 0.8350
epoch 2000 LossPred 0.2929 LossAtt 0.3655 TrainAcc 0.9100 TestAcc 0.5118 0.8400
epoch 2100 LossPred 0.2820 LossAtt 0.3640 TrainAcc 0.9300 TestAcc 0.5048 0.8300
epoch 2200 LossPred 0.2758 LossAtt 0.3582 TrainAcc 0.9400 TestAcc 0.5013 0.8350
epoch 2300 LossPred 0.2410 LossAtt 0.3546 TrainAcc 0.9300 TestAcc 0.5048 0.8450
epoch 2400 LossPred 0.2277 LossAtt 0.3550 TrainAcc 0.9400 TestAcc 0.5005 0.8150
epoch 2500 LossPred 0.2153 LossAtt 0.3631 TrainAcc 0.9400 TestAcc 0.4997 0.8300
Optimization Finished!
********** replication  27  **********
epoch   0 LossPred 1.0968 LossAtt 1.0093 TrainAcc 0.4600 TestAcc 0.4484 0.4450
epoch 100 LossPred 0.9523 LossAtt 0.2035 TrainAcc 0.5900 TestAcc 0.5976 0.5850
epoch 200 LossPred 0.9455 LossAtt 0.1586 TrainAcc 0.5900 TestAcc 0.5976 0.5950
epoch 300 LossPred 0.9355 LossAtt 0.1496 TrainAcc 0.6000 TestAcc 0.6291 0.6200
epoch 400 LossPred 0.8830 LossAtt 0.2491 TrainAcc 0.6100 TestAcc 0.5996 0.6250
epoch 500 LossPred 0.8343 LossAtt 0.2116 TrainAcc 0.5800 TestAcc 0.5838 0.5750
epoch 600 LossPred 0.8724 LossAtt 0.2212 TrainAcc 0.6400 TestAcc 0.6522 0.6500
epoch 700 LossPred 0.8394 LossAtt 0.2189 TrainAcc 0.5900 TestAcc 0.6209 0.6000
epoch 800 LossPred 0.8008 LossAtt 0.2125 TrainAcc 0.6600 TestAcc 0.6329 0.6650
epoch 900 LossPred 0.7724 LossAtt 0.2061 TrainAcc 0.6700 TestAcc 0.6514 0.6800
epoch 1000 LossPred 0.7368 LossAtt 0.1965 TrainAcc 0.6900 TestAcc 0.6564 0.6900
epoch 1100 LossPred 0.7288 LossAtt 0.1908 TrainAcc 0.6900 TestAcc 0.6549 0.6900
epoch 1200 LossPred 0.7243 LossAtt 0.1950 TrainAcc 0.6800 TestAcc 0.6592 0.6900
epoch 1300 LossPred 0.7040 LossAtt 0.1860 TrainAcc 0.7000 TestAcc 0.6827 0.6850
epoch 1400 LossPred 0.6641 LossAtt 0.1804 TrainAcc 0.7300 TestAcc 0.7530 0.7150
epoch 1500 LossPred 0.8445 LossAtt 0.1741 TrainAcc 0.6300 TestAcc 0.6074 0.6250
epoch 1600 LossPred 0.8980 LossAtt 0.1622 TrainAcc 0.6800 TestAcc 0.6834 0.6700
epoch 1700 LossPred 0.7579 LossAtt 0.1720 TrainAcc 0.6700 TestAcc 0.6504 0.6900
epoch 1800 LossPred 0.8665 LossAtt 0.1600 TrainAcc 0.5900 TestAcc 0.5838 0.6100
epoch 1900 LossPred 0.6126 LossAtt 0.1599 TrainAcc 0.7900 TestAcc 0.8186 0.7900
epoch 2000 LossPred 0.6710 LossAtt 0.1648 TrainAcc 0.7200 TestAcc 0.7430 0.7250
epoch 2100 LossPred 0.7280 LossAtt 0.1710 TrainAcc 0.7500 TestAcc 0.7145 0.7100
epoch 2200 LossPred 0.7623 LossAtt 0.1866 TrainAcc 0.7000 TestAcc 0.6276 0.7000
epoch 2300 LossPred 0.8606 LossAtt 0.2177 TrainAcc 0.6300 TestAcc 0.6171 0.6300
epoch 2400 LossPred 0.7417 LossAtt 0.1906 TrainAcc 0.7200 TestAcc 0.6727 0.7100
epoch 2500 LossPred 0.6622 LossAtt 0.1913 TrainAcc 0.7200 TestAcc 0.7545 0.7350
Optimization Finished!
********** replication  28  **********
epoch   0 LossPred 1.2967 LossAtt 0.9944 TrainAcc 0.3300 TestAcc 0.4254 0.3850
epoch 100 LossPred 0.8901 LossAtt 0.2666 TrainAcc 0.6700 TestAcc 0.5901 0.6700
epoch 200 LossPred 0.8645 LossAtt 0.2243 TrainAcc 0.6700 TestAcc 0.5901 0.6700
epoch 300 LossPred 0.8470 LossAtt 0.2649 TrainAcc 0.6700 TestAcc 0.5901 0.6700
epoch 400 LossPred 0.8262 LossAtt 0.2943 TrainAcc 0.6700 TestAcc 0.5901 0.6700
epoch 500 LossPred 0.8011 LossAtt 0.3361 TrainAcc 0.6700 TestAcc 0.5906 0.6650
epoch 600 LossPred 0.5565 LossAtt 0.3496 TrainAcc 0.8200 TestAcc 0.7725 0.8100
epoch 700 LossPred 0.4663 LossAtt 0.3226 TrainAcc 0.8200 TestAcc 0.8296 0.8300
epoch 800 LossPred 0.3800 LossAtt 0.3200 TrainAcc 0.8500 TestAcc 0.8574 0.8550
epoch 900 LossPred 0.2534 LossAtt 0.3327 TrainAcc 0.9200 TestAcc 0.8806 0.8900
epoch 1000 LossPred 0.2820 LossAtt 0.3201 TrainAcc 0.9100 TestAcc 0.8671 0.9000
epoch 1100 LossPred 0.2285 LossAtt 0.3341 TrainAcc 0.9200 TestAcc 0.8699 0.9100
epoch 1200 LossPred 0.1727 LossAtt 0.3196 TrainAcc 0.9500 TestAcc 0.8606 0.9100
epoch 1300 LossPred 0.1489 LossAtt 0.3206 TrainAcc 0.9600 TestAcc 0.8601 0.9200
epoch 1400 LossPred 0.2040 LossAtt 0.3217 TrainAcc 0.9200 TestAcc 0.8496 0.9050
epoch 1500 LossPred 0.1347 LossAtt 0.2978 TrainAcc 0.9600 TestAcc 0.8604 0.9250
epoch 1600 LossPred 0.1903 LossAtt 0.2945 TrainAcc 0.9400 TestAcc 0.8441 0.9250
epoch 1700 LossPred 0.1544 LossAtt 0.2961 TrainAcc 0.9500 TestAcc 0.8478 0.9300
epoch 1800 LossPred 0.1247 LossAtt 0.2927 TrainAcc 0.9600 TestAcc 0.8551 0.9450
epoch 1900 LossPred 0.1641 LossAtt 0.2871 TrainAcc 0.9500 TestAcc 0.8428 0.9500
epoch 2000 LossPred 0.0894 LossAtt 0.3005 TrainAcc 0.9800 TestAcc 0.8456 0.9500
epoch 2100 LossPred 0.0834 LossAtt 0.2766 TrainAcc 0.9800 TestAcc 0.8456 0.9550
epoch 2200 LossPred 0.1046 LossAtt 0.2867 TrainAcc 0.9700 TestAcc 0.8408 0.9550
epoch 2300 LossPred 0.0775 LossAtt 0.2816 TrainAcc 0.9800 TestAcc 0.8491 0.9500
epoch 2400 LossPred 0.0748 LossAtt 0.2860 TrainAcc 0.9800 TestAcc 0.8556 0.9400
epoch 2500 LossPred 0.0716 LossAtt 0.2770 TrainAcc 0.9800 TestAcc 0.8516 0.9550
Optimization Finished!
********** replication  29  **********
epoch   0 LossPred 1.0209 LossAtt 1.0345 TrainAcc 0.4800 TestAcc 0.4537 0.4800
epoch 100 LossPred 0.9370 LossAtt 0.3004 TrainAcc 0.5500 TestAcc 0.6009 0.5600
epoch 200 LossPred 0.4014 LossAtt 0.2640 TrainAcc 0.9000 TestAcc 0.8491 0.8650
epoch 300 LossPred 0.3163 LossAtt 0.2514 TrainAcc 0.9400 TestAcc 0.8263 0.8950
epoch 400 LossPred 0.3431 LossAtt 0.2464 TrainAcc 0.8800 TestAcc 0.7998 0.8500
epoch 500 LossPred 0.4089 LossAtt 0.2309 TrainAcc 0.8500 TestAcc 0.8644 0.8600
epoch 600 LossPred 0.5373 LossAtt 0.2209 TrainAcc 0.8100 TestAcc 0.8411 0.8550
epoch 700 LossPred 0.6509 LossAtt 0.2048 TrainAcc 0.8000 TestAcc 0.8166 0.8100
epoch 800 LossPred 0.2739 LossAtt 0.2127 TrainAcc 0.9300 TestAcc 0.8376 0.9000
epoch 900 LossPred 0.4321 LossAtt 0.2164 TrainAcc 0.8500 TestAcc 0.7848 0.8350
epoch 1000 LossPred 0.3702 LossAtt 0.2056 TrainAcc 0.8600 TestAcc 0.7960 0.8450
epoch 1100 LossPred 0.2984 LossAtt 0.1932 TrainAcc 0.9100 TestAcc 0.8671 0.9300
epoch 1200 LossPred 0.4516 LossAtt 0.1903 TrainAcc 0.8500 TestAcc 0.8754 0.8350
epoch 1300 LossPred 0.4067 LossAtt 0.2140 TrainAcc 0.8900 TestAcc 0.8641 0.8950
epoch 1400 LossPred 0.2943 LossAtt 0.2200 TrainAcc 0.9100 TestAcc 0.8496 0.9200
epoch 1500 LossPred 0.2982 LossAtt 0.2261 TrainAcc 0.8900 TestAcc 0.7993 0.9200
epoch 1600 LossPred 0.2545 LossAtt 0.2195 TrainAcc 0.9200 TestAcc 0.8416 0.9300
epoch 1700 LossPred 0.6801 LossAtt 0.2129 TrainAcc 0.7900 TestAcc 0.8248 0.7800
epoch 1800 LossPred 0.2991 LossAtt 0.2094 TrainAcc 0.9200 TestAcc 0.8714 0.9200
epoch 1900 LossPred 0.4624 LossAtt 0.2049 TrainAcc 0.8600 TestAcc 0.8719 0.8550
epoch 2000 LossPred 0.4212 LossAtt 0.2156 TrainAcc 0.8900 TestAcc 0.8584 0.8650
epoch 2100 LossPred 0.2489 LossAtt 0.1994 TrainAcc 0.9100 TestAcc 0.8406 0.9250
epoch 2200 LossPred 0.4592 LossAtt 0.1957 TrainAcc 0.8400 TestAcc 0.7673 0.8350
epoch 2300 LossPred 0.2856 LossAtt 0.1833 TrainAcc 0.9100 TestAcc 0.8581 0.9250
epoch 2400 LossPred 0.2879 LossAtt 0.1815 TrainAcc 0.9000 TestAcc 0.8466 0.9150
epoch 2500 LossPred 0.2621 LossAtt 0.1867 TrainAcc 0.9000 TestAcc 0.8408 0.9100
Optimization Finished!
********** replication  30  **********
epoch   0 LossPred 1.0432 LossAtt 1.0387 TrainAcc 0.4400 TestAcc 0.4117 0.5100
epoch 100 LossPred 0.8899 LossAtt 0.2707 TrainAcc 0.6200 TestAcc 0.5866 0.6200
epoch 200 LossPred 0.8507 LossAtt 0.2629 TrainAcc 0.6500 TestAcc 0.6039 0.6600
epoch 300 LossPred 1.0766 LossAtt 0.3531 TrainAcc 0.5900 TestAcc 0.5846 0.5850
epoch 400 LossPred 0.5086 LossAtt 0.3413 TrainAcc 0.8400 TestAcc 0.7437 0.8450
epoch 500 LossPred 0.3142 LossAtt 0.3326 TrainAcc 0.9100 TestAcc 0.8333 0.9050
epoch 600 LossPred 0.2631 LossAtt 0.3279 TrainAcc 0.9300 TestAcc 0.8238 0.9300
epoch 700 LossPred 0.2273 LossAtt 0.3355 TrainAcc 0.9400 TestAcc 0.8498 0.9150
epoch 800 LossPred 0.1870 LossAtt 0.3386 TrainAcc 0.9500 TestAcc 0.8326 0.9350
epoch 900 LossPred 0.2154 LossAtt 0.3428 TrainAcc 0.9500 TestAcc 0.8398 0.9300
epoch 1000 LossPred 0.1622 LossAtt 0.3479 TrainAcc 0.9400 TestAcc 0.8388 0.9200
epoch 1100 LossPred 0.1911 LossAtt 0.3528 TrainAcc 0.9300 TestAcc 0.8178 0.9100
epoch 1200 LossPred 0.1569 LossAtt 0.3318 TrainAcc 0.9600 TestAcc 0.8308 0.9500
epoch 1300 LossPred 0.2366 LossAtt 0.3346 TrainAcc 0.9200 TestAcc 0.8223 0.9250
epoch 1400 LossPred 0.2161 LossAtt 0.3364 TrainAcc 0.9200 TestAcc 0.8291 0.9100
epoch 1500 LossPred 0.1347 LossAtt 0.3313 TrainAcc 0.9600 TestAcc 0.8333 0.9450
epoch 1600 LossPred 0.2612 LossAtt 0.3211 TrainAcc 0.9100 TestAcc 0.8091 0.9100
epoch 1700 LossPred 0.1605 LossAtt 0.3298 TrainAcc 0.9500 TestAcc 0.8003 0.9300
epoch 1800 LossPred 0.1430 LossAtt 0.3155 TrainAcc 0.9600 TestAcc 0.7980 0.9400
epoch 1900 LossPred 0.1431 LossAtt 0.3044 TrainAcc 0.9400 TestAcc 0.8208 0.9500
epoch 2000 LossPred 0.1588 LossAtt 0.3138 TrainAcc 0.9600 TestAcc 0.7990 0.9350
epoch 2100 LossPred 0.1203 LossAtt 0.2969 TrainAcc 0.9700 TestAcc 0.8206 0.9500
epoch 2200 LossPred 0.1879 LossAtt 0.2934 TrainAcc 0.9400 TestAcc 0.8113 0.9250
epoch 2300 LossPred 0.1744 LossAtt 0.2947 TrainAcc 0.9400 TestAcc 0.8043 0.9500
epoch 2400 LossPred 0.1541 LossAtt 0.2911 TrainAcc 0.9500 TestAcc 0.8101 0.9500
epoch 2500 LossPred 0.1903 LossAtt 0.3057 TrainAcc 0.9400 TestAcc 0.8061 0.9300
Optimization Finished!
********** replication  31  **********
epoch   0 LossPred 1.0262 LossAtt 1.0041 TrainAcc 0.4600 TestAcc 0.4192 0.5250
epoch 100 LossPred 0.8955 LossAtt 0.2797 TrainAcc 0.6300 TestAcc 0.5861 0.6300
epoch 200 LossPred 0.8419 LossAtt 0.2706 TrainAcc 0.6300 TestAcc 0.5861 0.6350
epoch 300 LossPred 0.6100 LossAtt 0.2101 TrainAcc 0.7900 TestAcc 0.8091 0.7850
epoch 400 LossPred 0.5664 LossAtt 0.1694 TrainAcc 0.7700 TestAcc 0.8291 0.7900
epoch 500 LossPred 1.2269 LossAtt 0.2217 TrainAcc 0.6300 TestAcc 0.5861 0.6300
epoch 600 LossPred 0.9138 LossAtt 0.1704 TrainAcc 0.6300 TestAcc 0.5861 0.6300
epoch 700 LossPred 0.5810 LossAtt 0.1691 TrainAcc 0.8500 TestAcc 0.8236 0.8200
epoch 800 LossPred 0.4043 LossAtt 0.1478 TrainAcc 0.8700 TestAcc 0.9002 0.8800
epoch 900 LossPred 0.5526 LossAtt 0.1489 TrainAcc 0.7900 TestAcc 0.8483 0.8050
epoch 1000 LossPred 0.3658 LossAtt 0.1483 TrainAcc 0.8800 TestAcc 0.9007 0.8800
epoch 1100 LossPred 0.3858 LossAtt 0.1607 TrainAcc 0.9000 TestAcc 0.8921 0.9000
epoch 1200 LossPred 0.4017 LossAtt 0.1651 TrainAcc 0.9000 TestAcc 0.8816 0.8800
epoch 1300 LossPred 0.3550 LossAtt 0.1697 TrainAcc 0.8800 TestAcc 0.9047 0.8750
epoch 1400 LossPred 0.8080 LossAtt 0.1891 TrainAcc 0.6800 TestAcc 0.7207 0.6750
epoch 1500 LossPred 0.6331 LossAtt 0.1956 TrainAcc 0.7700 TestAcc 0.7908 0.7500
epoch 1600 LossPred 0.5734 LossAtt 0.1990 TrainAcc 0.7600 TestAcc 0.8136 0.7850
epoch 1700 LossPred 0.4400 LossAtt 0.1805 TrainAcc 0.8700 TestAcc 0.8841 0.8550
epoch 1800 LossPred 0.6728 LossAtt 0.1687 TrainAcc 0.7800 TestAcc 0.7673 0.7700
epoch 1900 LossPred 0.6156 LossAtt 0.1869 TrainAcc 0.7400 TestAcc 0.7918 0.7800
epoch 2000 LossPred 0.4673 LossAtt 0.1676 TrainAcc 0.8400 TestAcc 0.8741 0.8600
epoch 2100 LossPred 0.4685 LossAtt 0.1530 TrainAcc 0.8600 TestAcc 0.8531 0.8550
epoch 2200 LossPred 0.4529 LossAtt 0.1769 TrainAcc 0.8600 TestAcc 0.8564 0.8500
epoch 2300 LossPred 0.4263 LossAtt 0.1738 TrainAcc 0.8600 TestAcc 0.8721 0.8450
epoch 2400 LossPred 0.4241 LossAtt 0.1813 TrainAcc 0.8800 TestAcc 0.8641 0.8650
epoch 2500 LossPred 0.4145 LossAtt 0.1871 TrainAcc 0.8700 TestAcc 0.8769 0.8600
Optimization Finished!
********** replication  32  **********
epoch   0 LossPred 1.0043 LossAtt 0.9830 TrainAcc 0.5100 TestAcc 0.4780 0.5100
epoch 100 LossPred 0.8925 LossAtt 0.2776 TrainAcc 0.6800 TestAcc 0.6406 0.6800
epoch 200 LossPred 0.4740 LossAtt 0.2345 TrainAcc 0.8300 TestAcc 0.8381 0.7900
epoch 300 LossPred 0.2467 LossAtt 0.2024 TrainAcc 0.9200 TestAcc 0.8976 0.8650
epoch 400 LossPred 0.3010 LossAtt 0.1951 TrainAcc 0.8800 TestAcc 0.8729 0.8450
epoch 500 LossPred 0.4122 LossAtt 0.1781 TrainAcc 0.8600 TestAcc 0.8336 0.8400
epoch 600 LossPred 0.2729 LossAtt 0.1756 TrainAcc 0.9000 TestAcc 0.8929 0.8700
epoch 700 LossPred 0.2250 LossAtt 0.1795 TrainAcc 0.9200 TestAcc 0.8901 0.8800
epoch 800 LossPred 0.2178 LossAtt 0.1749 TrainAcc 0.9400 TestAcc 0.8926 0.8800
epoch 900 LossPred 0.4818 LossAtt 0.1790 TrainAcc 0.8100 TestAcc 0.8296 0.7950
epoch 1000 LossPred 0.6007 LossAtt 0.1945 TrainAcc 0.7800 TestAcc 0.8048 0.7500
epoch 1100 LossPred 0.5778 LossAtt 0.2126 TrainAcc 0.7900 TestAcc 0.7743 0.8050
epoch 1200 LossPred 0.4713 LossAtt 0.1973 TrainAcc 0.8000 TestAcc 0.8366 0.7850
epoch 1300 LossPred 0.3468 LossAtt 0.2067 TrainAcc 0.8500 TestAcc 0.8694 0.8350
epoch 1400 LossPred 0.2784 LossAtt 0.2064 TrainAcc 0.9200 TestAcc 0.8699 0.8800
epoch 1500 LossPred 0.2711 LossAtt 0.2015 TrainAcc 0.9200 TestAcc 0.8654 0.9000
epoch 1600 LossPred 0.3637 LossAtt 0.1781 TrainAcc 0.8400 TestAcc 0.8606 0.8250
epoch 1700 LossPred 0.2882 LossAtt 0.1769 TrainAcc 0.9100 TestAcc 0.8694 0.8750
epoch 1800 LossPred 0.2903 LossAtt 0.1860 TrainAcc 0.9200 TestAcc 0.8579 0.8800
epoch 1900 LossPred 0.2878 LossAtt 0.1728 TrainAcc 0.9200 TestAcc 0.8584 0.8850
epoch 2000 LossPred 0.3203 LossAtt 0.1781 TrainAcc 0.8700 TestAcc 0.8714 0.8450
epoch 2100 LossPred 0.3448 LossAtt 0.1807 TrainAcc 0.8500 TestAcc 0.8636 0.8400
epoch 2200 LossPred 0.2938 LossAtt 0.1804 TrainAcc 0.9000 TestAcc 0.8589 0.8900
epoch 2300 LossPred 0.3695 LossAtt 0.1625 TrainAcc 0.8500 TestAcc 0.8691 0.8350
epoch 2400 LossPred 0.2419 LossAtt 0.1655 TrainAcc 0.9100 TestAcc 0.8861 0.8950
epoch 2500 LossPred 0.2596 LossAtt 0.1782 TrainAcc 0.9200 TestAcc 0.8871 0.9000
Optimization Finished!
********** replication  33  **********
epoch   0 LossPred 1.0488 LossAtt 1.0224 TrainAcc 0.4700 TestAcc 0.4997 0.4750
epoch 100 LossPred 0.9435 LossAtt 0.3129 TrainAcc 0.5800 TestAcc 0.5923 0.5800
epoch 200 LossPred 0.8915 LossAtt 0.3027 TrainAcc 0.6600 TestAcc 0.5896 0.6300
epoch 300 LossPred 0.3515 LossAtt 0.3273 TrainAcc 0.8900 TestAcc 0.8051 0.8750
epoch 400 LossPred 0.2953 LossAtt 0.3308 TrainAcc 0.9300 TestAcc 0.8601 0.8950
epoch 500 LossPred 0.1976 LossAtt 0.3363 TrainAcc 0.9400 TestAcc 0.8514 0.9100
epoch 600 LossPred 0.1893 LossAtt 0.3409 TrainAcc 0.9400 TestAcc 0.8433 0.9250
epoch 700 LossPred 0.2082 LossAtt 0.3348 TrainAcc 0.9300 TestAcc 0.8521 0.9150
epoch 800 LossPred 0.1804 LossAtt 0.3237 TrainAcc 0.9400 TestAcc 0.8373 0.9200
epoch 900 LossPred 0.1619 LossAtt 0.3042 TrainAcc 0.9500 TestAcc 0.8271 0.9350
epoch 1000 LossPred 0.1566 LossAtt 0.2930 TrainAcc 0.9600 TestAcc 0.8318 0.9450
epoch 1100 LossPred 0.1551 LossAtt 0.3046 TrainAcc 0.9600 TestAcc 0.8574 0.9400
epoch 1200 LossPred 0.1881 LossAtt 0.2778 TrainAcc 0.9400 TestAcc 0.8619 0.9400
epoch 1300 LossPred 0.1301 LossAtt 0.2850 TrainAcc 0.9700 TestAcc 0.8506 0.9600
epoch 1400 LossPred 0.1621 LossAtt 0.2727 TrainAcc 0.9500 TestAcc 0.8524 0.9250
epoch 1500 LossPred 0.1248 LossAtt 0.2830 TrainAcc 0.9700 TestAcc 0.8441 0.9550
epoch 1600 LossPred 0.1620 LossAtt 0.2674 TrainAcc 0.9600 TestAcc 0.8534 0.9350
epoch 1700 LossPred 0.1222 LossAtt 0.2739 TrainAcc 0.9700 TestAcc 0.8403 0.9600
epoch 1800 LossPred 0.1649 LossAtt 0.2647 TrainAcc 0.9500 TestAcc 0.8208 0.9450
epoch 1900 LossPred 0.1209 LossAtt 0.2812 TrainAcc 0.9700 TestAcc 0.8348 0.9700
epoch 2000 LossPred 0.1530 LossAtt 0.2754 TrainAcc 0.9600 TestAcc 0.8301 0.9400
epoch 2100 LossPred 0.1400 LossAtt 0.2722 TrainAcc 0.9700 TestAcc 0.8313 0.9600
epoch 2200 LossPred 0.1428 LossAtt 0.2664 TrainAcc 0.9600 TestAcc 0.8436 0.9600
epoch 2300 LossPred 0.1204 LossAtt 0.2604 TrainAcc 0.9700 TestAcc 0.8356 0.9650
epoch 2400 LossPred 0.1195 LossAtt 0.2538 TrainAcc 0.9700 TestAcc 0.8343 0.9650
epoch 2500 LossPred 0.1159 LossAtt 0.2586 TrainAcc 0.9700 TestAcc 0.8328 0.9700
Optimization Finished!
********** replication  34  **********
epoch   0 LossPred 1.0819 LossAtt 1.0266 TrainAcc 0.5000 TestAcc 0.4805 0.5450
epoch 100 LossPred 0.8640 LossAtt 0.2333 TrainAcc 0.6600 TestAcc 0.6416 0.6400
epoch 200 LossPred 0.4629 LossAtt 0.2202 TrainAcc 0.8800 TestAcc 0.8131 0.8550
epoch 300 LossPred 0.3571 LossAtt 0.2093 TrainAcc 0.8600 TestAcc 0.8594 0.8350
epoch 400 LossPred 0.4040 LossAtt 0.2115 TrainAcc 0.8600 TestAcc 0.8111 0.8350
epoch 500 LossPred 0.2597 LossAtt 0.2202 TrainAcc 0.9000 TestAcc 0.8629 0.8650
epoch 600 LossPred 0.2263 LossAtt 0.2117 TrainAcc 0.9300 TestAcc 0.8716 0.9050
epoch 700 LossPred 0.2052 LossAtt 0.2201 TrainAcc 0.9500 TestAcc 0.8779 0.8950
epoch 800 LossPred 0.1799 LossAtt 0.2008 TrainAcc 0.9300 TestAcc 0.8884 0.8850
epoch 900 LossPred 0.2171 LossAtt 0.2029 TrainAcc 0.9400 TestAcc 0.8756 0.8900
epoch 1000 LossPred 0.2258 LossAtt 0.1924 TrainAcc 0.9200 TestAcc 0.8611 0.8900
epoch 1100 LossPred 0.3082 LossAtt 0.1941 TrainAcc 0.8900 TestAcc 0.8478 0.9000
epoch 1200 LossPred 0.1689 LossAtt 0.1813 TrainAcc 0.9600 TestAcc 0.8831 0.9350
epoch 1300 LossPred 0.1894 LossAtt 0.1846 TrainAcc 0.9600 TestAcc 0.8759 0.9300
epoch 1400 LossPred 0.2666 LossAtt 0.1904 TrainAcc 0.9100 TestAcc 0.8641 0.8950
epoch 1500 LossPred 0.1704 LossAtt 0.1873 TrainAcc 0.9400 TestAcc 0.8704 0.9200
epoch 1600 LossPred 0.3332 LossAtt 0.1872 TrainAcc 0.8700 TestAcc 0.8641 0.8750
epoch 1700 LossPred 0.1646 LossAtt 0.1833 TrainAcc 0.9500 TestAcc 0.8721 0.9450
epoch 1800 LossPred 0.1585 LossAtt 0.1896 TrainAcc 0.9600 TestAcc 0.8764 0.9450
epoch 1900 LossPred 0.2406 LossAtt 0.1919 TrainAcc 0.9100 TestAcc 0.8456 0.8950
epoch 2000 LossPred 0.2111 LossAtt 0.2063 TrainAcc 0.9300 TestAcc 0.8639 0.9350
epoch 2100 LossPred 0.1708 LossAtt 0.2045 TrainAcc 0.9600 TestAcc 0.8671 0.9500
epoch 2200 LossPred 0.1870 LossAtt 0.2100 TrainAcc 0.9400 TestAcc 0.8581 0.9300
epoch 2300 LossPred 0.1980 LossAtt 0.2021 TrainAcc 0.9400 TestAcc 0.8509 0.9450
epoch 2400 LossPred 0.2595 LossAtt 0.2000 TrainAcc 0.9100 TestAcc 0.8719 0.9050
epoch 2500 LossPred 0.1347 LossAtt 0.1884 TrainAcc 0.9500 TestAcc 0.8671 0.9550
Optimization Finished!
********** replication  35  **********
epoch   0 LossPred 1.0276 LossAtt 1.0164 TrainAcc 0.5600 TestAcc 0.4940 0.5850
epoch 100 LossPred 0.8202 LossAtt 0.2996 TrainAcc 0.6800 TestAcc 0.5833 0.6800
epoch 200 LossPred 0.7544 LossAtt 0.2245 TrainAcc 0.7300 TestAcc 0.6324 0.7300
epoch 300 LossPred 0.6658 LossAtt 0.2751 TrainAcc 0.7400 TestAcc 0.6657 0.7500
epoch 400 LossPred 0.3392 LossAtt 0.3197 TrainAcc 0.9000 TestAcc 0.8986 0.8850
epoch 500 LossPred 0.5028 LossAtt 0.3243 TrainAcc 0.8300 TestAcc 0.8436 0.8000
epoch 600 LossPred 0.3316 LossAtt 0.3063 TrainAcc 0.8800 TestAcc 0.8969 0.8750
epoch 700 LossPred 0.1782 LossAtt 0.2863 TrainAcc 0.9300 TestAcc 0.9239 0.9300
epoch 800 LossPred 0.1606 LossAtt 0.2880 TrainAcc 0.9500 TestAcc 0.9057 0.9250
epoch 900 LossPred 0.1260 LossAtt 0.2731 TrainAcc 0.9600 TestAcc 0.9219 0.9400
epoch 1000 LossPred 0.1303 LossAtt 0.2726 TrainAcc 0.9500 TestAcc 0.9054 0.9350
epoch 1100 LossPred 0.0992 LossAtt 0.2590 TrainAcc 0.9600 TestAcc 0.9214 0.9450
epoch 1200 LossPred 0.2105 LossAtt 0.2533 TrainAcc 0.9400 TestAcc 0.8889 0.9150
epoch 1300 LossPred 0.0651 LossAtt 0.2571 TrainAcc 0.9900 TestAcc 0.9284 0.9600
epoch 1400 LossPred 0.1259 LossAtt 0.2469 TrainAcc 0.9500 TestAcc 0.9209 0.9300
epoch 1500 LossPred 0.3705 LossAtt 0.2420 TrainAcc 0.8800 TestAcc 0.8233 0.8300
epoch 1600 LossPred 0.0674 LossAtt 0.2654 TrainAcc 0.9800 TestAcc 0.9064 0.9650
epoch 1700 LossPred 0.1098 LossAtt 0.2663 TrainAcc 0.9500 TestAcc 0.9137 0.9450
epoch 1800 LossPred 0.2604 LossAtt 0.2550 TrainAcc 0.9100 TestAcc 0.8644 0.8800
epoch 1900 LossPred 0.0756 LossAtt 0.2490 TrainAcc 0.9700 TestAcc 0.9132 0.9600
epoch 2000 LossPred 0.2847 LossAtt 0.2604 TrainAcc 0.9100 TestAcc 0.8559 0.9100
epoch 2100 LossPred 0.0525 LossAtt 0.2505 TrainAcc 0.9800 TestAcc 0.9014 0.9750
epoch 2200 LossPred 0.2079 LossAtt 0.2542 TrainAcc 0.9100 TestAcc 0.8854 0.9050
epoch 2300 LossPred 0.0504 LossAtt 0.2474 TrainAcc 0.9700 TestAcc 0.9177 0.9450
epoch 2400 LossPred 0.0516 LossAtt 0.2424 TrainAcc 0.9900 TestAcc 0.9154 0.9450
epoch 2500 LossPred 0.1607 LossAtt 0.2403 TrainAcc 0.9600 TestAcc 0.8671 0.9350
Optimization Finished!
********** replication  36  **********
epoch   0 LossPred 1.0238 LossAtt 1.0287 TrainAcc 0.4400 TestAcc 0.4657 0.4850
epoch 100 LossPred 0.7282 LossAtt 0.2829 TrainAcc 0.7400 TestAcc 0.6301 0.7400
epoch 200 LossPred 0.6472 LossAtt 0.2676 TrainAcc 0.7400 TestAcc 0.6301 0.7400
epoch 300 LossPred 0.2418 LossAtt 0.3030 TrainAcc 0.9600 TestAcc 0.8516 0.9400
epoch 400 LossPred 0.2410 LossAtt 0.2757 TrainAcc 0.9400 TestAcc 0.8488 0.9150
epoch 500 LossPred 0.1778 LossAtt 0.2554 TrainAcc 0.9500 TestAcc 0.8561 0.9350
epoch 600 LossPred 0.1766 LossAtt 0.2369 TrainAcc 0.9500 TestAcc 0.8529 0.9400
epoch 700 LossPred 0.2225 LossAtt 0.2206 TrainAcc 0.9500 TestAcc 0.8361 0.9400
epoch 800 LossPred 0.1810 LossAtt 0.2277 TrainAcc 0.9400 TestAcc 0.8656 0.9550
epoch 900 LossPred 0.1479 LossAtt 0.2174 TrainAcc 0.9600 TestAcc 0.8656 0.9600
epoch 1000 LossPred 0.2412 LossAtt 0.2272 TrainAcc 0.9100 TestAcc 0.8521 0.9050
epoch 1100 LossPred 0.1677 LossAtt 0.2168 TrainAcc 0.9400 TestAcc 0.8591 0.9400
epoch 1200 LossPred 0.1867 LossAtt 0.2335 TrainAcc 0.9200 TestAcc 0.8461 0.9150
epoch 1300 LossPred 0.1643 LossAtt 0.2169 TrainAcc 0.9500 TestAcc 0.8544 0.9350
epoch 1400 LossPred 0.1373 LossAtt 0.2125 TrainAcc 0.9700 TestAcc 0.8626 0.9650
epoch 1500 LossPred 0.1615 LossAtt 0.2037 TrainAcc 0.9400 TestAcc 0.8614 0.9450
epoch 1600 LossPred 0.1649 LossAtt 0.1997 TrainAcc 0.9500 TestAcc 0.8564 0.9250
epoch 1700 LossPred 0.1629 LossAtt 0.2064 TrainAcc 0.9400 TestAcc 0.8626 0.9350
epoch 1800 LossPred 0.1274 LossAtt 0.2035 TrainAcc 0.9600 TestAcc 0.8656 0.9600
epoch 1900 LossPred 0.1219 LossAtt 0.2042 TrainAcc 0.9700 TestAcc 0.8624 0.9550
epoch 2000 LossPred 0.1900 LossAtt 0.2048 TrainAcc 0.9300 TestAcc 0.8406 0.9150
epoch 2100 LossPred 0.1547 LossAtt 0.1913 TrainAcc 0.9600 TestAcc 0.8644 0.9500
epoch 2200 LossPred 0.1174 LossAtt 0.1907 TrainAcc 0.9700 TestAcc 0.8731 0.9550
epoch 2300 LossPred 0.1432 LossAtt 0.1968 TrainAcc 0.9600 TestAcc 0.8684 0.9450
epoch 2400 LossPred 0.3219 LossAtt 0.1849 TrainAcc 0.9000 TestAcc 0.8476 0.9050
epoch 2500 LossPred 0.1506 LossAtt 0.2111 TrainAcc 0.9600 TestAcc 0.8451 0.9300
Optimization Finished!
********** replication  37  **********
epoch   0 LossPred 1.0346 LossAtt 1.0133 TrainAcc 0.4900 TestAcc 0.4772 0.4800
epoch 100 LossPred 0.8820 LossAtt 0.3079 TrainAcc 0.6800 TestAcc 0.6374 0.6600
epoch 200 LossPred 0.5667 LossAtt 0.3042 TrainAcc 0.8500 TestAcc 0.7903 0.8100
epoch 300 LossPred 0.3210 LossAtt 0.2945 TrainAcc 0.8900 TestAcc 0.8904 0.8650
epoch 400 LossPred 0.3741 LossAtt 0.2784 TrainAcc 0.9000 TestAcc 0.8481 0.8600
epoch 500 LossPred 0.5367 LossAtt 0.2894 TrainAcc 0.8000 TestAcc 0.7758 0.7550
epoch 600 LossPred 0.3317 LossAtt 0.2729 TrainAcc 0.9000 TestAcc 0.8774 0.8500
epoch 700 LossPred 0.3421 LossAtt 0.2637 TrainAcc 0.8900 TestAcc 0.8794 0.8550
epoch 800 LossPred 0.4002 LossAtt 0.2555 TrainAcc 0.8600 TestAcc 0.8068 0.8450
epoch 900 LossPred 0.3421 LossAtt 0.2451 TrainAcc 0.8900 TestAcc 0.8756 0.8700
epoch 1000 LossPred 0.3043 LossAtt 0.2538 TrainAcc 0.9200 TestAcc 0.8544 0.9050
epoch 1100 LossPred 0.5384 LossAtt 0.2435 TrainAcc 0.8000 TestAcc 0.7735 0.7650
epoch 1200 LossPred 0.2941 LossAtt 0.2569 TrainAcc 0.9000 TestAcc 0.8348 0.8700
epoch 1300 LossPred 0.5631 LossAtt 0.2564 TrainAcc 0.8100 TestAcc 0.8036 0.8150
epoch 1400 LossPred 0.3348 LossAtt 0.2437 TrainAcc 0.8700 TestAcc 0.9144 0.8550
epoch 1500 LossPred 0.3619 LossAtt 0.2611 TrainAcc 0.9200 TestAcc 0.8416 0.8650
epoch 1600 LossPred 0.2621 LossAtt 0.2495 TrainAcc 0.9200 TestAcc 0.9002 0.9000
epoch 1700 LossPred 0.3860 LossAtt 0.2320 TrainAcc 0.8400 TestAcc 0.8839 0.8800
epoch 1800 LossPred 0.4115 LossAtt 0.2480 TrainAcc 0.8700 TestAcc 0.8346 0.8650
epoch 1900 LossPred 0.4850 LossAtt 0.2527 TrainAcc 0.8500 TestAcc 0.8161 0.8150
epoch 2000 LossPred 0.2636 LossAtt 0.2500 TrainAcc 0.9200 TestAcc 0.8899 0.8750
epoch 2100 LossPred 0.2642 LossAtt 0.2604 TrainAcc 0.9100 TestAcc 0.8849 0.8500
epoch 2200 LossPred 0.2808 LossAtt 0.2741 TrainAcc 0.9300 TestAcc 0.8764 0.8950
epoch 2300 LossPred 0.3149 LossAtt 0.2740 TrainAcc 0.9000 TestAcc 0.8313 0.8450
epoch 2400 LossPred 0.2470 LossAtt 0.2691 TrainAcc 0.9000 TestAcc 0.8749 0.9050
epoch 2500 LossPred 0.2171 LossAtt 0.2568 TrainAcc 0.9400 TestAcc 0.8624 0.8950
Optimization Finished!
********** replication  38  **********
epoch   0 LossPred 1.0041 LossAtt 1.0076 TrainAcc 0.5200 TestAcc 0.4947 0.5100
epoch 100 LossPred 0.9793 LossAtt 0.2343 TrainAcc 0.5600 TestAcc 0.4910 0.5500
epoch 200 LossPred 0.9762 LossAtt 0.1715 TrainAcc 0.5600 TestAcc 0.4910 0.5600
epoch 300 LossPred 0.9750 LossAtt 0.1684 TrainAcc 0.5600 TestAcc 0.4910 0.5600
epoch 400 LossPred 0.9741 LossAtt 0.1801 TrainAcc 0.5600 TestAcc 0.4910 0.5600
epoch 500 LossPred 0.9717 LossAtt 0.1707 TrainAcc 0.5700 TestAcc 0.4995 0.5650
epoch 600 LossPred 0.9683 LossAtt 0.1662 TrainAcc 0.6000 TestAcc 0.5283 0.5900
epoch 700 LossPred 0.9427 LossAtt 0.2177 TrainAcc 0.6100 TestAcc 0.5761 0.6100
epoch 800 LossPred 0.3864 LossAtt 0.2768 TrainAcc 0.8700 TestAcc 0.8383 0.8300
epoch 900 LossPred 0.2964 LossAtt 0.2555 TrainAcc 0.8800 TestAcc 0.8486 0.8650
epoch 1000 LossPred 0.2648 LossAtt 0.2371 TrainAcc 0.9100 TestAcc 0.8599 0.9000
epoch 1100 LossPred 0.1719 LossAtt 0.2320 TrainAcc 0.9300 TestAcc 0.8726 0.9000
epoch 1200 LossPred 0.0810 LossAtt 0.2529 TrainAcc 0.9900 TestAcc 0.8826 0.9200
epoch 1300 LossPred 0.1351 LossAtt 0.2464 TrainAcc 0.9600 TestAcc 0.8731 0.9150
epoch 1400 LossPred 0.0520 LossAtt 0.2469 TrainAcc 0.9900 TestAcc 0.8844 0.9350
epoch 1500 LossPred 0.0688 LossAtt 0.2278 TrainAcc 0.9800 TestAcc 0.8811 0.9450
epoch 1600 LossPred 0.0455 LossAtt 0.2228 TrainAcc 0.9900 TestAcc 0.8861 0.9450
epoch 1700 LossPred 0.1954 LossAtt 0.2205 TrainAcc 0.9600 TestAcc 0.8724 0.9250
epoch 1800 LossPred 0.0916 LossAtt 0.2209 TrainAcc 0.9800 TestAcc 0.8814 0.9500
epoch 1900 LossPred 0.0274 LossAtt 0.2223 TrainAcc 0.9900 TestAcc 0.8916 0.9600
epoch 2000 LossPred 0.0382 LossAtt 0.2289 TrainAcc 0.9900 TestAcc 0.8904 0.9300
epoch 2100 LossPred 0.0166 LossAtt 0.2177 TrainAcc 1.0000 TestAcc 0.8909 0.9550
Optimization Finished!
********** replication  39  **********
epoch   0 LossPred 0.9810 LossAtt 1.0027 TrainAcc 0.5900 TestAcc 0.5678 0.6000
epoch 100 LossPred 0.8412 LossAtt 0.3243 TrainAcc 0.6600 TestAcc 0.6396 0.6550
epoch 200 LossPred 0.5820 LossAtt 0.3027 TrainAcc 0.7800 TestAcc 0.7573 0.8000
epoch 300 LossPred 0.4064 LossAtt 0.2649 TrainAcc 0.8600 TestAcc 0.7993 0.8500
epoch 400 LossPred 0.3714 LossAtt 0.2493 TrainAcc 0.8900 TestAcc 0.8123 0.8700
epoch 500 LossPred 0.3185 LossAtt 0.2688 TrainAcc 0.9200 TestAcc 0.8158 0.8650
epoch 600 LossPred 0.3059 LossAtt 0.2672 TrainAcc 0.9000 TestAcc 0.8078 0.8800
epoch 700 LossPred 0.2264 LossAtt 0.2718 TrainAcc 0.9300 TestAcc 0.8306 0.8850
epoch 800 LossPred 0.1883 LossAtt 0.2587 TrainAcc 0.9500 TestAcc 0.8391 0.9100
epoch 900 LossPred 0.2445 LossAtt 0.2806 TrainAcc 0.9300 TestAcc 0.8003 0.9050
epoch 1000 LossPred 0.1763 LossAtt 0.2738 TrainAcc 0.9500 TestAcc 0.8096 0.9000
epoch 1100 LossPred 0.1497 LossAtt 0.2814 TrainAcc 0.9500 TestAcc 0.8278 0.8950
epoch 1200 LossPred 0.1321 LossAtt 0.2806 TrainAcc 0.9500 TestAcc 0.8271 0.9000
epoch 1300 LossPred 0.1679 LossAtt 0.2862 TrainAcc 0.9400 TestAcc 0.8001 0.8950
epoch 1400 LossPred 0.1758 LossAtt 0.2774 TrainAcc 0.9400 TestAcc 0.8188 0.9000
epoch 1500 LossPred 0.1070 LossAtt 0.2661 TrainAcc 0.9600 TestAcc 0.8131 0.9100
epoch 1600 LossPred 0.1078 LossAtt 0.2679 TrainAcc 0.9700 TestAcc 0.8061 0.9100
epoch 1700 LossPred 0.1194 LossAtt 0.2667 TrainAcc 0.9600 TestAcc 0.8093 0.9100
epoch 1800 LossPred 0.1225 LossAtt 0.2527 TrainAcc 0.9700 TestAcc 0.7733 0.9200
epoch 1900 LossPred 0.1034 LossAtt 0.2529 TrainAcc 0.9700 TestAcc 0.8073 0.9250
epoch 2000 LossPred 0.1139 LossAtt 0.2577 TrainAcc 0.9700 TestAcc 0.7768 0.9000
epoch 2100 LossPred 0.1012 LossAtt 0.2348 TrainAcc 0.9700 TestAcc 0.7990 0.9300
epoch 2200 LossPred 0.1109 LossAtt 0.2320 TrainAcc 0.9700 TestAcc 0.7908 0.9250
epoch 2300 LossPred 0.0963 LossAtt 0.2276 TrainAcc 0.9700 TestAcc 0.7908 0.9250
epoch 2400 LossPred 0.0966 LossAtt 0.2329 TrainAcc 0.9700 TestAcc 0.7810 0.9300
epoch 2500 LossPred 0.2443 LossAtt 0.2362 TrainAcc 0.9300 TestAcc 0.7763 0.9000
Optimization Finished!
********** replication  40  **********
epoch   0 LossPred 1.2252 LossAtt 0.9853 TrainAcc 0.5000 TestAcc 0.5363 0.5150
epoch 100 LossPred 0.8651 LossAtt 0.2961 TrainAcc 0.6100 TestAcc 0.5926 0.6300
epoch 200 LossPred 0.9151 LossAtt 0.2193 TrainAcc 0.6100 TestAcc 0.5926 0.6100
epoch 300 LossPred 0.8633 LossAtt 0.1598 TrainAcc 0.6100 TestAcc 0.5926 0.6100
epoch 400 LossPred 0.7066 LossAtt 0.2326 TrainAcc 0.7800 TestAcc 0.6827 0.7800
epoch 500 LossPred 0.2981 LossAtt 0.2371 TrainAcc 0.9200 TestAcc 0.8461 0.9000
epoch 600 LossPred 0.2310 LossAtt 0.2379 TrainAcc 0.9300 TestAcc 0.8488 0.8950
epoch 700 LossPred 0.2668 LossAtt 0.2209 TrainAcc 0.9200 TestAcc 0.8453 0.9000
epoch 800 LossPred 0.3811 LossAtt 0.2220 TrainAcc 0.8900 TestAcc 0.7968 0.8400
epoch 900 LossPred 0.1938 LossAtt 0.2042 TrainAcc 0.9500 TestAcc 0.8478 0.9100
epoch 1000 LossPred 0.1905 LossAtt 0.2025 TrainAcc 0.9500 TestAcc 0.8433 0.9050
epoch 1100 LossPred 0.1736 LossAtt 0.1983 TrainAcc 0.9500 TestAcc 0.8539 0.9000
epoch 1200 LossPred 0.3378 LossAtt 0.2147 TrainAcc 0.9000 TestAcc 0.8353 0.9050
epoch 1300 LossPred 0.2150 LossAtt 0.2022 TrainAcc 0.9400 TestAcc 0.8351 0.8800
epoch 1400 LossPred 0.2723 LossAtt 0.2026 TrainAcc 0.9100 TestAcc 0.8198 0.8600
epoch 1500 LossPred 0.2497 LossAtt 0.1939 TrainAcc 0.9200 TestAcc 0.8468 0.9150
epoch 1600 LossPred 0.2006 LossAtt 0.1883 TrainAcc 0.9400 TestAcc 0.8398 0.9000
epoch 1700 LossPred 0.2736 LossAtt 0.2058 TrainAcc 0.9100 TestAcc 0.8471 0.9050
epoch 1800 LossPred 0.1983 LossAtt 0.1913 TrainAcc 0.9300 TestAcc 0.8431 0.8900
epoch 1900 LossPred 0.2174 LossAtt 0.2005 TrainAcc 0.9300 TestAcc 0.8496 0.9200
epoch 2000 LossPred 0.4045 LossAtt 0.1958 TrainAcc 0.8900 TestAcc 0.8186 0.8900
epoch 2100 LossPred 0.1722 LossAtt 0.1826 TrainAcc 0.9400 TestAcc 0.8456 0.9100
epoch 2200 LossPred 0.2873 LossAtt 0.1932 TrainAcc 0.9200 TestAcc 0.8203 0.8950
epoch 2300 LossPred 0.2110 LossAtt 0.1926 TrainAcc 0.9300 TestAcc 0.8323 0.9100
epoch 2400 LossPred 0.1792 LossAtt 0.1835 TrainAcc 0.9400 TestAcc 0.8406 0.9200
epoch 2500 LossPred 0.1436 LossAtt 0.1948 TrainAcc 0.9600 TestAcc 0.8438 0.9300
Optimization Finished!
********** replication  41  **********
epoch   0 LossPred 1.0471 LossAtt 1.0022 TrainAcc 0.4600 TestAcc 0.4952 0.4600
epoch 100 LossPred 0.8451 LossAtt 0.2104 TrainAcc 0.6700 TestAcc 0.6246 0.6650
epoch 200 LossPred 0.8065 LossAtt 0.1980 TrainAcc 0.6800 TestAcc 0.6369 0.6950
epoch 300 LossPred 0.3859 LossAtt 0.2338 TrainAcc 0.8900 TestAcc 0.8574 0.8800
epoch 400 LossPred 0.4142 LossAtt 0.2172 TrainAcc 0.8700 TestAcc 0.8401 0.8150
epoch 500 LossPred 0.4417 LossAtt 0.2283 TrainAcc 0.8400 TestAcc 0.8081 0.8550
epoch 600 LossPred 0.3652 LossAtt 0.2327 TrainAcc 0.8700 TestAcc 0.8286 0.8750
epoch 700 LossPred 0.3405 LossAtt 0.2410 TrainAcc 0.8700 TestAcc 0.8676 0.8650
epoch 800 LossPred 0.3641 LossAtt 0.2329 TrainAcc 0.8700 TestAcc 0.8704 0.8450
epoch 900 LossPred 0.2339 LossAtt 0.2365 TrainAcc 0.9200 TestAcc 0.8986 0.8900
epoch 1000 LossPred 0.1852 LossAtt 0.2457 TrainAcc 0.9400 TestAcc 0.9064 0.9050
epoch 1100 LossPred 0.2074 LossAtt 0.2310 TrainAcc 0.9400 TestAcc 0.9119 0.9050
epoch 1200 LossPred 0.2313 LossAtt 0.2207 TrainAcc 0.9400 TestAcc 0.8726 0.9250
epoch 1300 LossPred 0.1969 LossAtt 0.2346 TrainAcc 0.9300 TestAcc 0.9047 0.9050
epoch 1400 LossPred 0.5326 LossAtt 0.2159 TrainAcc 0.8300 TestAcc 0.7735 0.8350
epoch 1500 LossPred 0.2113 LossAtt 0.2310 TrainAcc 0.9400 TestAcc 0.8906 0.9250
epoch 1600 LossPred 0.4717 LossAtt 0.2181 TrainAcc 0.8500 TestAcc 0.7828 0.8550
epoch 1700 LossPred 0.5265 LossAtt 0.2167 TrainAcc 0.8300 TestAcc 0.7615 0.8150
epoch 1800 LossPred 0.1560 LossAtt 0.2229 TrainAcc 0.9700 TestAcc 0.9207 0.9250
epoch 1900 LossPred 0.4360 LossAtt 0.2141 TrainAcc 0.8500 TestAcc 0.8031 0.8650
epoch 2000 LossPred 0.2331 LossAtt 0.2093 TrainAcc 0.9400 TestAcc 0.8721 0.9250
epoch 2100 LossPred 0.2701 LossAtt 0.2115 TrainAcc 0.8900 TestAcc 0.8864 0.8800
epoch 2200 LossPred 0.2385 LossAtt 0.2065 TrainAcc 0.9200 TestAcc 0.9032 0.9200
epoch 2300 LossPred 0.4766 LossAtt 0.2148 TrainAcc 0.8700 TestAcc 0.7870 0.8500
epoch 2400 LossPred 0.2837 LossAtt 0.2144 TrainAcc 0.9200 TestAcc 0.8549 0.9050
epoch 2500 LossPred 0.4739 LossAtt 0.2031 TrainAcc 0.8500 TestAcc 0.8218 0.8500
Optimization Finished!
********** replication  42  **********
epoch   0 LossPred 1.0110 LossAtt 1.0097 TrainAcc 0.5100 TestAcc 0.5070 0.5400
epoch 100 LossPred 0.8940 LossAtt 0.2999 TrainAcc 0.6800 TestAcc 0.6304 0.6800
epoch 200 LossPred 0.8755 LossAtt 0.1787 TrainAcc 0.6800 TestAcc 0.6304 0.6800
epoch 300 LossPred 0.9734 LossAtt 0.1737 TrainAcc 0.5600 TestAcc 0.5388 0.5600
epoch 400 LossPred 0.9098 LossAtt 0.1252 TrainAcc 0.6100 TestAcc 0.5931 0.6350
epoch 500 LossPred 0.8698 LossAtt 0.1800 TrainAcc 0.6800 TestAcc 0.6304 0.6800
epoch 600 LossPred 0.8406 LossAtt 0.2034 TrainAcc 0.6800 TestAcc 0.6304 0.6800
epoch 700 LossPred 0.4238 LossAtt 0.3562 TrainAcc 0.8700 TestAcc 0.8216 0.8600
epoch 800 LossPred 0.2685 LossAtt 0.2971 TrainAcc 0.9300 TestAcc 0.8904 0.9250
epoch 900 LossPred 0.2415 LossAtt 0.2906 TrainAcc 0.9200 TestAcc 0.9099 0.9200
epoch 1000 LossPred 0.1399 LossAtt 0.2830 TrainAcc 0.9800 TestAcc 0.9247 0.9750
epoch 1100 LossPred 0.1317 LossAtt 0.2657 TrainAcc 0.9800 TestAcc 0.9302 0.9800
epoch 1200 LossPred 0.2149 LossAtt 0.2547 TrainAcc 0.9300 TestAcc 0.9299 0.9300
epoch 1300 LossPred 0.2563 LossAtt 0.2589 TrainAcc 0.9200 TestAcc 0.9044 0.9200
epoch 1400 LossPred 0.2756 LossAtt 0.2663 TrainAcc 0.9200 TestAcc 0.9029 0.9100
epoch 1500 LossPred 0.1507 LossAtt 0.2466 TrainAcc 0.9500 TestAcc 0.8981 0.9550
epoch 1600 LossPred 0.1127 LossAtt 0.2474 TrainAcc 0.9500 TestAcc 0.9362 0.9650
epoch 1700 LossPred 0.1092 LossAtt 0.2445 TrainAcc 0.9600 TestAcc 0.9374 0.9650
epoch 1800 LossPred 0.0651 LossAtt 0.2337 TrainAcc 0.9900 TestAcc 0.9359 0.9800
epoch 1900 LossPred 0.1513 LossAtt 0.2467 TrainAcc 0.9400 TestAcc 0.8856 0.9450
epoch 2000 LossPred 0.0620 LossAtt 0.2310 TrainAcc 0.9900 TestAcc 0.9394 0.9750
epoch 2100 LossPred 0.0772 LossAtt 0.2352 TrainAcc 0.9800 TestAcc 0.9342 0.9600
epoch 2200 LossPred 0.1273 LossAtt 0.2533 TrainAcc 0.9500 TestAcc 0.9382 0.9450
epoch 2300 LossPred 0.1903 LossAtt 0.2409 TrainAcc 0.9300 TestAcc 0.8779 0.9400
epoch 2400 LossPred 0.1458 LossAtt 0.2413 TrainAcc 0.9400 TestAcc 0.9337 0.9350
epoch 2500 LossPred 0.1012 LossAtt 0.2345 TrainAcc 0.9700 TestAcc 0.9249 0.9700
Optimization Finished!
********** replication  43  **********
epoch   0 LossPred 1.0439 LossAtt 1.0358 TrainAcc 0.4700 TestAcc 0.4084 0.4750
epoch 100 LossPred 0.9415 LossAtt 0.1691 TrainAcc 0.6100 TestAcc 0.5853 0.6100
epoch 200 LossPred 0.9073 LossAtt 0.1498 TrainAcc 0.6100 TestAcc 0.5853 0.6100
epoch 300 LossPred 0.8826 LossAtt 0.1716 TrainAcc 0.6700 TestAcc 0.6319 0.6700
epoch 400 LossPred 0.8263 LossAtt 0.1724 TrainAcc 0.7200 TestAcc 0.6049 0.7200
epoch 500 LossPred 0.7287 LossAtt 0.2141 TrainAcc 0.7700 TestAcc 0.5896 0.7700
epoch 600 LossPred 0.5628 LossAtt 0.2694 TrainAcc 0.8100 TestAcc 0.6662 0.7800
epoch 700 LossPred 0.4687 LossAtt 0.2795 TrainAcc 0.8400 TestAcc 0.6862 0.7900
epoch 800 LossPred 0.3714 LossAtt 0.3147 TrainAcc 0.8800 TestAcc 0.6857 0.8450
epoch 900 LossPred 0.3339 LossAtt 0.3019 TrainAcc 0.8800 TestAcc 0.6932 0.8600
epoch 1000 LossPred 0.5696 LossAtt 0.2931 TrainAcc 0.7800 TestAcc 0.6827 0.7900
epoch 1100 LossPred 0.3081 LossAtt 0.2808 TrainAcc 0.9000 TestAcc 0.6972 0.8600
epoch 1200 LossPred 0.2956 LossAtt 0.2751 TrainAcc 0.9000 TestAcc 0.6957 0.8500
epoch 1300 LossPred 0.2835 LossAtt 0.2936 TrainAcc 0.9200 TestAcc 0.7020 0.8600
epoch 1400 LossPred 0.2870 LossAtt 0.2810 TrainAcc 0.9100 TestAcc 0.6884 0.8650
epoch 1500 LossPred 0.2765 LossAtt 0.2813 TrainAcc 0.9200 TestAcc 0.6994 0.8700
epoch 1600 LossPred 0.2895 LossAtt 0.2746 TrainAcc 0.9000 TestAcc 0.6934 0.8750
epoch 1700 LossPred 0.2686 LossAtt 0.2749 TrainAcc 0.9100 TestAcc 0.7060 0.8800
epoch 1800 LossPred 0.2636 LossAtt 0.2794 TrainAcc 0.9200 TestAcc 0.6982 0.8750
epoch 1900 LossPred 0.2573 LossAtt 0.2797 TrainAcc 0.9200 TestAcc 0.6964 0.8800
epoch 2000 LossPred 0.2549 LossAtt 0.2730 TrainAcc 0.9100 TestAcc 0.6992 0.8850
epoch 2100 LossPred 0.2487 LossAtt 0.2608 TrainAcc 0.9100 TestAcc 0.6967 0.8750
epoch 2200 LossPred 0.2413 LossAtt 0.2573 TrainAcc 0.9200 TestAcc 0.7030 0.8800
epoch 2300 LossPred 0.2349 LossAtt 0.2564 TrainAcc 0.9300 TestAcc 0.7017 0.8800
epoch 2400 LossPred 0.3033 LossAtt 0.2631 TrainAcc 0.9000 TestAcc 0.7170 0.8800
epoch 2500 LossPred 0.2407 LossAtt 0.2829 TrainAcc 0.9000 TestAcc 0.6957 0.8700
Optimization Finished!
********** replication  44  **********
epoch   0 LossPred 1.1959 LossAtt 0.9871 TrainAcc 0.3900 TestAcc 0.4139 0.4150
epoch 100 LossPred 0.8732 LossAtt 0.3243 TrainAcc 0.6800 TestAcc 0.6206 0.6900
epoch 200 LossPred 0.7395 LossAtt 0.3262 TrainAcc 0.7100 TestAcc 0.6997 0.7200
epoch 300 LossPred 0.6592 LossAtt 0.2976 TrainAcc 0.7600 TestAcc 0.7417 0.7700
epoch 400 LossPred 0.4491 LossAtt 0.2493 TrainAcc 0.8500 TestAcc 0.8173 0.8800
epoch 500 LossPred 0.3226 LossAtt 0.2485 TrainAcc 0.9200 TestAcc 0.8771 0.8900
epoch 600 LossPred 0.6087 LossAtt 0.2460 TrainAcc 0.7900 TestAcc 0.7588 0.8100
epoch 700 LossPred 0.7355 LossAtt 0.2518 TrainAcc 0.7800 TestAcc 0.7390 0.7750
epoch 800 LossPred 0.3415 LossAtt 0.2473 TrainAcc 0.9000 TestAcc 0.8574 0.8800
epoch 900 LossPred 0.4435 LossAtt 0.2307 TrainAcc 0.8400 TestAcc 0.8048 0.8500
epoch 1000 LossPred 0.5230 LossAtt 0.2460 TrainAcc 0.8000 TestAcc 0.7873 0.8300
epoch 1100 LossPred 0.3506 LossAtt 0.2490 TrainAcc 0.8700 TestAcc 0.8413 0.8550
epoch 1200 LossPred 0.6802 LossAtt 0.2527 TrainAcc 0.7900 TestAcc 0.7668 0.7900
epoch 1300 LossPred 0.3084 LossAtt 0.2276 TrainAcc 0.9000 TestAcc 0.8516 0.8650
epoch 1400 LossPred 0.3452 LossAtt 0.2224 TrainAcc 0.8800 TestAcc 0.8408 0.9000
epoch 1500 LossPred 0.4551 LossAtt 0.2276 TrainAcc 0.8600 TestAcc 0.7983 0.8450
epoch 1600 LossPred 0.3811 LossAtt 0.2120 TrainAcc 0.8900 TestAcc 0.8218 0.8450
epoch 1700 LossPred 0.3495 LossAtt 0.2096 TrainAcc 0.9000 TestAcc 0.8308 0.9000
epoch 1800 LossPred 0.2530 LossAtt 0.2015 TrainAcc 0.9400 TestAcc 0.8436 0.9250
epoch 1900 LossPred 0.2583 LossAtt 0.2039 TrainAcc 0.9100 TestAcc 0.8478 0.9050
epoch 2000 LossPred 0.2409 LossAtt 0.1970 TrainAcc 0.9200 TestAcc 0.8561 0.9250
epoch 2100 LossPred 0.2789 LossAtt 0.1989 TrainAcc 0.9200 TestAcc 0.8611 0.9400
epoch 2200 LossPred 0.2168 LossAtt 0.1962 TrainAcc 0.9300 TestAcc 0.8656 0.9250
epoch 2300 LossPred 0.2081 LossAtt 0.1861 TrainAcc 0.9300 TestAcc 0.8699 0.9150
epoch 2400 LossPred 0.2043 LossAtt 0.1896 TrainAcc 0.9500 TestAcc 0.8786 0.9350
epoch 2500 LossPred 0.2003 LossAtt 0.1976 TrainAcc 0.9400 TestAcc 0.8716 0.9100
Optimization Finished!
********** replication  45  **********
epoch   0 LossPred 0.9900 LossAtt 1.0137 TrainAcc 0.5100 TestAcc 0.4990 0.5450
epoch 100 LossPred 0.9130 LossAtt 0.2458 TrainAcc 0.6400 TestAcc 0.5936 0.6400
epoch 200 LossPred 0.7657 LossAtt 0.2565 TrainAcc 0.6400 TestAcc 0.5936 0.6400
epoch 300 LossPred 0.3964 LossAtt 0.2491 TrainAcc 0.9000 TestAcc 0.8256 0.8900
epoch 400 LossPred 0.4287 LossAtt 0.2523 TrainAcc 0.8900 TestAcc 0.8461 0.8550
epoch 500 LossPred 0.3348 LossAtt 0.2554 TrainAcc 0.9100 TestAcc 0.8333 0.8850
epoch 600 LossPred 0.3652 LossAtt 0.2324 TrainAcc 0.9000 TestAcc 0.8446 0.8800
epoch 700 LossPred 0.3344 LossAtt 0.2384 TrainAcc 0.8800 TestAcc 0.8644 0.8700
epoch 800 LossPred 0.3755 LossAtt 0.2212 TrainAcc 0.8300 TestAcc 0.8664 0.8250
epoch 900 LossPred 0.5821 LossAtt 0.2221 TrainAcc 0.7600 TestAcc 0.8048 0.7900
epoch 1000 LossPred 0.3539 LossAtt 0.2192 TrainAcc 0.8700 TestAcc 0.8904 0.8750
epoch 1100 LossPred 0.3013 LossAtt 0.2111 TrainAcc 0.9300 TestAcc 0.8671 0.9050
epoch 1200 LossPred 0.4838 LossAtt 0.2076 TrainAcc 0.8300 TestAcc 0.8351 0.8250
epoch 1300 LossPred 0.3845 LossAtt 0.2029 TrainAcc 0.8900 TestAcc 0.8554 0.8950
epoch 1400 LossPred 0.5988 LossAtt 0.1852 TrainAcc 0.8300 TestAcc 0.8131 0.8300
epoch 1500 LossPred 0.5055 LossAtt 0.1960 TrainAcc 0.8400 TestAcc 0.8331 0.8400
epoch 1600 LossPred 0.4778 LossAtt 0.1965 TrainAcc 0.8700 TestAcc 0.8471 0.8600
epoch 1700 LossPred 0.4945 LossAtt 0.1911 TrainAcc 0.8100 TestAcc 0.8251 0.8150
epoch 1800 LossPred 0.4633 LossAtt 0.1978 TrainAcc 0.8600 TestAcc 0.8321 0.8700
epoch 1900 LossPred 0.3920 LossAtt 0.1977 TrainAcc 0.8700 TestAcc 0.8529 0.8750
epoch 2000 LossPred 0.4294 LossAtt 0.1897 TrainAcc 0.8300 TestAcc 0.8068 0.8200
epoch 2100 LossPred 0.3625 LossAtt 0.1823 TrainAcc 0.8800 TestAcc 0.8216 0.8550
epoch 2200 LossPred 0.5203 LossAtt 0.1823 TrainAcc 0.8000 TestAcc 0.7955 0.7550
epoch 2300 LossPred 0.4332 LossAtt 0.1749 TrainAcc 0.8400 TestAcc 0.7925 0.8450
epoch 2400 LossPred 0.6222 LossAtt 0.1940 TrainAcc 0.7400 TestAcc 0.7573 0.7150
epoch 2500 LossPred 1.0499 LossAtt 0.2006 TrainAcc 0.5800 TestAcc 0.6464 0.5550
Optimization Finished!
********** replication  46  **********
epoch   0 LossPred 1.1805 LossAtt 1.0069 TrainAcc 0.4500 TestAcc 0.5045 0.4450
epoch 100 LossPred 0.9257 LossAtt 0.2334 TrainAcc 0.5900 TestAcc 0.5858 0.5900
epoch 200 LossPred 0.8909 LossAtt 0.1660 TrainAcc 0.6100 TestAcc 0.5428 0.6100
epoch 300 LossPred 0.8785 LossAtt 0.1622 TrainAcc 0.6200 TestAcc 0.6234 0.6200
epoch 400 LossPred 0.5171 LossAtt 0.2260 TrainAcc 0.8100 TestAcc 0.8173 0.7950
epoch 500 LossPred 0.4846 LossAtt 0.1964 TrainAcc 0.8300 TestAcc 0.8258 0.8100
epoch 600 LossPred 0.4423 LossAtt 0.1740 TrainAcc 0.8600 TestAcc 0.8541 0.8400
epoch 700 LossPred 0.4217 LossAtt 0.1644 TrainAcc 0.8600 TestAcc 0.8556 0.8400
epoch 800 LossPred 0.5289 LossAtt 0.1561 TrainAcc 0.8500 TestAcc 0.8096 0.8200
epoch 900 LossPred 0.4660 LossAtt 0.1608 TrainAcc 0.8600 TestAcc 0.8451 0.8600
epoch 1000 LossPred 0.5097 LossAtt 0.1517 TrainAcc 0.8400 TestAcc 0.8213 0.8400
epoch 1100 LossPred 0.4318 LossAtt 0.1509 TrainAcc 0.8600 TestAcc 0.8491 0.8450
epoch 1200 LossPred 0.4315 LossAtt 0.1435 TrainAcc 0.8500 TestAcc 0.8556 0.8200
epoch 1300 LossPred 0.3919 LossAtt 0.1375 TrainAcc 0.8700 TestAcc 0.8629 0.8300
epoch 1400 LossPred 0.5137 LossAtt 0.1565 TrainAcc 0.8200 TestAcc 0.8273 0.7750
epoch 1500 LossPred 0.4390 LossAtt 0.1601 TrainAcc 0.8500 TestAcc 0.8619 0.8300
epoch 1600 LossPred 0.4177 LossAtt 0.1395 TrainAcc 0.8600 TestAcc 0.8704 0.8200
epoch 1700 LossPred 0.4526 LossAtt 0.1435 TrainAcc 0.8500 TestAcc 0.8436 0.8100
epoch 1800 LossPred 0.4923 LossAtt 0.1596 TrainAcc 0.8300 TestAcc 0.8303 0.8050
epoch 1900 LossPred 0.4202 LossAtt 0.1532 TrainAcc 0.8600 TestAcc 0.8541 0.8400
epoch 2000 LossPred 0.4898 LossAtt 0.1486 TrainAcc 0.8600 TestAcc 0.8366 0.8550
epoch 2100 LossPred 0.5410 LossAtt 0.1545 TrainAcc 0.8100 TestAcc 0.8163 0.7900
epoch 2200 LossPred 0.5107 LossAtt 0.1486 TrainAcc 0.8500 TestAcc 0.8273 0.8200
epoch 2300 LossPred 0.5164 LossAtt 0.1446 TrainAcc 0.8600 TestAcc 0.8253 0.8300
epoch 2400 LossPred 0.5759 LossAtt 0.1522 TrainAcc 0.8000 TestAcc 0.8121 0.8000
epoch 2500 LossPred 0.4985 LossAtt 0.1497 TrainAcc 0.8400 TestAcc 0.8218 0.8000
Optimization Finished!
********** replication  47  **********
epoch   0 LossPred 1.2486 LossAtt 1.0117 TrainAcc 0.4300 TestAcc 0.4732 0.4100
epoch 100 LossPred 0.9361 LossAtt 0.3047 TrainAcc 0.5700 TestAcc 0.5008 0.5750
epoch 200 LossPred 0.9019 LossAtt 0.2767 TrainAcc 0.6200 TestAcc 0.5816 0.6200
epoch 300 LossPred 0.5285 LossAtt 0.3098 TrainAcc 0.8400 TestAcc 0.7715 0.8250
epoch 400 LossPred 0.2732 LossAtt 0.2794 TrainAcc 0.9700 TestAcc 0.9537 0.9450
epoch 500 LossPred 0.4684 LossAtt 0.2863 TrainAcc 0.8400 TestAcc 0.7828 0.8550
epoch 600 LossPred 0.3703 LossAtt 0.2815 TrainAcc 0.8700 TestAcc 0.8619 0.8600
epoch 700 LossPred 0.2033 LossAtt 0.2732 TrainAcc 0.9500 TestAcc 0.9234 0.9400
epoch 800 LossPred 0.2024 LossAtt 0.2666 TrainAcc 0.9500 TestAcc 0.9087 0.9400
epoch 900 LossPred 0.1693 LossAtt 0.2561 TrainAcc 0.9600 TestAcc 0.9232 0.9450
epoch 1000 LossPred 0.1580 LossAtt 0.2570 TrainAcc 0.9500 TestAcc 0.9207 0.9550
epoch 1100 LossPred 0.1810 LossAtt 0.2552 TrainAcc 0.9600 TestAcc 0.8956 0.9550
epoch 1200 LossPred 0.1502 LossAtt 0.2490 TrainAcc 0.9500 TestAcc 0.9017 0.9600
epoch 1300 LossPred 0.2737 LossAtt 0.2605 TrainAcc 0.8900 TestAcc 0.8901 0.8750
epoch 1400 LossPred 0.1657 LossAtt 0.2529 TrainAcc 0.9400 TestAcc 0.8994 0.9300
epoch 1500 LossPred 0.1982 LossAtt 0.2642 TrainAcc 0.9300 TestAcc 0.8816 0.9450
epoch 1600 LossPred 0.1365 LossAtt 0.2651 TrainAcc 0.9700 TestAcc 0.9069 0.9600
epoch 1700 LossPred 0.2779 LossAtt 0.2569 TrainAcc 0.9300 TestAcc 0.8506 0.9200
epoch 1800 LossPred 0.1170 LossAtt 0.2516 TrainAcc 0.9800 TestAcc 0.9142 0.9600
epoch 1900 LossPred 0.1882 LossAtt 0.2563 TrainAcc 0.9400 TestAcc 0.9069 0.9350
epoch 2000 LossPred 0.1132 LossAtt 0.2488 TrainAcc 0.9700 TestAcc 0.9174 0.9600
epoch 2100 LossPred 0.1365 LossAtt 0.2564 TrainAcc 0.9600 TestAcc 0.9102 0.9550
epoch 2200 LossPred 0.1318 LossAtt 0.2446 TrainAcc 0.9600 TestAcc 0.9034 0.9450
epoch 2300 LossPred 0.2741 LossAtt 0.2441 TrainAcc 0.9100 TestAcc 0.8564 0.9150
epoch 2400 LossPred 0.3420 LossAtt 0.2573 TrainAcc 0.8600 TestAcc 0.8654 0.8800
epoch 2500 LossPred 0.1295 LossAtt 0.2422 TrainAcc 0.9700 TestAcc 0.9019 0.9550
Optimization Finished!
********** replication  48  **********
epoch   0 LossPred 1.0989 LossAtt 1.0153 TrainAcc 0.4800 TestAcc 0.5355 0.4900
epoch 100 LossPred 0.6350 LossAtt 0.2890 TrainAcc 0.8300 TestAcc 0.7800 0.8000
epoch 200 LossPred 0.5611 LossAtt 0.2117 TrainAcc 0.8300 TestAcc 0.8433 0.7900
epoch 300 LossPred 0.5533 LossAtt 0.1970 TrainAcc 0.8300 TestAcc 0.8413 0.7950
epoch 400 LossPred 0.4785 LossAtt 0.1892 TrainAcc 0.8600 TestAcc 0.8006 0.8000
epoch 500 LossPred 0.4533 LossAtt 0.1781 TrainAcc 0.8300 TestAcc 0.8181 0.8250
epoch 600 LossPred 0.4862 LossAtt 0.1657 TrainAcc 0.8400 TestAcc 0.7885 0.8100
epoch 700 LossPred 0.7643 LossAtt 0.2006 TrainAcc 0.7000 TestAcc 0.6894 0.7050
epoch 800 LossPred 0.5401 LossAtt 0.1591 TrainAcc 0.8100 TestAcc 0.7808 0.7950
epoch 900 LossPred 0.5067 LossAtt 0.1516 TrainAcc 0.8200 TestAcc 0.8406 0.8250
epoch 1000 LossPred 0.5301 LossAtt 0.1521 TrainAcc 0.8100 TestAcc 0.8288 0.8300
epoch 1100 LossPred 0.5135 LossAtt 0.1478 TrainAcc 0.8300 TestAcc 0.8368 0.8300
epoch 1200 LossPred 0.5514 LossAtt 0.1602 TrainAcc 0.8000 TestAcc 0.8161 0.8100
epoch 1300 LossPred 0.4958 LossAtt 0.1619 TrainAcc 0.8500 TestAcc 0.8383 0.8350
epoch 1400 LossPred 0.4906 LossAtt 0.1660 TrainAcc 0.8300 TestAcc 0.8396 0.8400
epoch 1500 LossPred 0.4632 LossAtt 0.1721 TrainAcc 0.8500 TestAcc 0.8519 0.8250
epoch 1600 LossPred 0.4631 LossAtt 0.1649 TrainAcc 0.8600 TestAcc 0.8519 0.8250
epoch 1700 LossPred 0.4557 LossAtt 0.1664 TrainAcc 0.8600 TestAcc 0.8481 0.8250
epoch 1800 LossPred 0.4566 LossAtt 0.1646 TrainAcc 0.8800 TestAcc 0.8448 0.8150
epoch 1900 LossPred 0.4895 LossAtt 0.1646 TrainAcc 0.8400 TestAcc 0.8386 0.8300
epoch 2000 LossPred 0.4520 LossAtt 0.1622 TrainAcc 0.8300 TestAcc 0.8458 0.8250
epoch 2100 LossPred 0.4598 LossAtt 0.1563 TrainAcc 0.8300 TestAcc 0.8426 0.8350
epoch 2200 LossPred 0.5150 LossAtt 0.1608 TrainAcc 0.8400 TestAcc 0.8181 0.8250
epoch 2300 LossPred 0.5064 LossAtt 0.1575 TrainAcc 0.8100 TestAcc 0.8148 0.8050
epoch 2400 LossPred 0.6032 LossAtt 0.1565 TrainAcc 0.8000 TestAcc 0.7755 0.8000
epoch 2500 LossPred 0.4860 LossAtt 0.1470 TrainAcc 0.8300 TestAcc 0.8278 0.8400
Optimization Finished!
********** replication  49  **********
epoch   0 LossPred 0.9893 LossAtt 1.0010 TrainAcc 0.5500 TestAcc 0.4702 0.5550
epoch 100 LossPred 0.5455 LossAtt 0.3389 TrainAcc 0.8800 TestAcc 0.7197 0.8650
epoch 200 LossPred 0.2083 LossAtt 0.2761 TrainAcc 0.9300 TestAcc 0.8649 0.9100
epoch 300 LossPred 0.1834 LossAtt 0.2415 TrainAcc 0.9600 TestAcc 0.8721 0.9250
epoch 400 LossPred 0.1761 LossAtt 0.2363 TrainAcc 0.9400 TestAcc 0.8719 0.9050
epoch 500 LossPred 0.3317 LossAtt 0.2401 TrainAcc 0.8800 TestAcc 0.8193 0.8500
epoch 600 LossPred 0.2120 LossAtt 0.2456 TrainAcc 0.9100 TestAcc 0.8411 0.8900
epoch 700 LossPred 0.1036 LossAtt 0.2442 TrainAcc 0.9700 TestAcc 0.8639 0.9250
epoch 800 LossPred 0.2148 LossAtt 0.2471 TrainAcc 0.9200 TestAcc 0.8311 0.9150
epoch 900 LossPred 0.1379 LossAtt 0.2413 TrainAcc 0.9600 TestAcc 0.8554 0.9300
epoch 1000 LossPred 0.1619 LossAtt 0.2320 TrainAcc 0.9400 TestAcc 0.8336 0.9100
epoch 1100 LossPred 0.1995 LossAtt 0.2194 TrainAcc 0.9200 TestAcc 0.8448 0.9100
epoch 1200 LossPred 0.1062 LossAtt 0.2247 TrainAcc 0.9600 TestAcc 0.8714 0.9450
epoch 1300 LossPred 0.1177 LossAtt 0.2103 TrainAcc 0.9600 TestAcc 0.8438 0.9350
epoch 1400 LossPred 0.1127 LossAtt 0.2112 TrainAcc 0.9600 TestAcc 0.8564 0.9550
epoch 1500 LossPred 0.1296 LossAtt 0.1982 TrainAcc 0.9500 TestAcc 0.8629 0.9550
epoch 1600 LossPred 0.3718 LossAtt 0.2079 TrainAcc 0.8800 TestAcc 0.8106 0.8800
epoch 1700 LossPred 0.1017 LossAtt 0.1986 TrainAcc 0.9700 TestAcc 0.8601 0.9450
epoch 1800 LossPred 0.1141 LossAtt 0.2013 TrainAcc 0.9600 TestAcc 0.8451 0.9400
epoch 1900 LossPred 0.2182 LossAtt 0.1972 TrainAcc 0.9200 TestAcc 0.8163 0.9150
epoch 2000 LossPred 0.1028 LossAtt 0.1880 TrainAcc 0.9600 TestAcc 0.8609 0.9500
epoch 2100 LossPred 0.1062 LossAtt 0.1902 TrainAcc 0.9600 TestAcc 0.8524 0.9450
epoch 2200 LossPred 0.1530 LossAtt 0.1802 TrainAcc 0.9400 TestAcc 0.8306 0.9300
epoch 2300 LossPred 0.1163 LossAtt 0.1961 TrainAcc 0.9700 TestAcc 0.8483 0.9200
epoch 2400 LossPred 0.2331 LossAtt 0.1817 TrainAcc 0.9100 TestAcc 0.8293 0.9000
epoch 2500 LossPred 0.1074 LossAtt 0.1840 TrainAcc 0.9600 TestAcc 0.8493 0.9450
Optimization Finished!
********** replication  50  **********
epoch   0 LossPred 0.9632 LossAtt 1.0364 TrainAcc 0.6300 TestAcc 0.5155 0.6250
epoch 100 LossPred 0.7170 LossAtt 0.3256 TrainAcc 0.7200 TestAcc 0.5903 0.7150
epoch 200 LossPred 0.3727 LossAtt 0.3608 TrainAcc 0.8900 TestAcc 0.8373 0.8550
epoch 300 LossPred 0.2025 LossAtt 0.3369 TrainAcc 0.9500 TestAcc 0.8488 0.8900
epoch 400 LossPred 0.1876 LossAtt 0.3202 TrainAcc 0.9400 TestAcc 0.8529 0.8950
epoch 500 LossPred 0.1699 LossAtt 0.3112 TrainAcc 0.9500 TestAcc 0.8761 0.9200
epoch 600 LossPred 0.1607 LossAtt 0.3083 TrainAcc 0.9400 TestAcc 0.8884 0.8900
epoch 700 LossPred 0.1442 LossAtt 0.3143 TrainAcc 0.9600 TestAcc 0.8786 0.9300
epoch 800 LossPred 0.1372 LossAtt 0.3136 TrainAcc 0.9600 TestAcc 0.8874 0.9150
epoch 900 LossPred 0.1363 LossAtt 0.3160 TrainAcc 0.9600 TestAcc 0.8771 0.9400
epoch 1000 LossPred 0.1250 LossAtt 0.3046 TrainAcc 0.9700 TestAcc 0.8979 0.9500
epoch 1100 LossPred 0.1415 LossAtt 0.3111 TrainAcc 0.9600 TestAcc 0.8666 0.9400
epoch 1200 LossPred 0.1145 LossAtt 0.3062 TrainAcc 0.9600 TestAcc 0.8854 0.9600
epoch 1300 LossPred 0.1797 LossAtt 0.2994 TrainAcc 0.9400 TestAcc 0.8784 0.9300
epoch 1400 LossPred 0.0933 LossAtt 0.3040 TrainAcc 0.9600 TestAcc 0.8759 0.9600
epoch 1500 LossPred 0.0948 LossAtt 0.3100 TrainAcc 0.9700 TestAcc 0.8964 0.9650
epoch 1600 LossPred 0.1009 LossAtt 0.3233 TrainAcc 0.9700 TestAcc 0.8921 0.9650
epoch 1700 LossPred 0.1169 LossAtt 0.3204 TrainAcc 0.9700 TestAcc 0.8919 0.9450
epoch 1800 LossPred 0.0704 LossAtt 0.3186 TrainAcc 0.9800 TestAcc 0.8924 0.9600
epoch 1900 LossPred 0.0566 LossAtt 0.3121 TrainAcc 0.9900 TestAcc 0.8911 0.9850
epoch 2000 LossPred 0.0657 LossAtt 0.3184 TrainAcc 0.9900 TestAcc 0.8836 0.9700
epoch 2100 LossPred 0.0949 LossAtt 0.3249 TrainAcc 0.9700 TestAcc 0.8986 0.9500
epoch 2200 LossPred 0.0291 LossAtt 0.3214 TrainAcc 1.0000 TestAcc 0.8839 0.9800
Optimization Finished!
********** replication  51  **********
epoch   0 LossPred 1.2132 LossAtt 1.0064 TrainAcc 0.5200 TestAcc 0.5626 0.4600
epoch 100 LossPred 0.9492 LossAtt 0.2179 TrainAcc 0.6100 TestAcc 0.5350 0.5950
epoch 200 LossPred 0.9465 LossAtt 0.1876 TrainAcc 0.5800 TestAcc 0.5443 0.5800
epoch 300 LossPred 0.9413 LossAtt 0.1792 TrainAcc 0.6000 TestAcc 0.5245 0.5700
epoch 400 LossPred 0.9328 LossAtt 0.1990 TrainAcc 0.6000 TestAcc 0.5315 0.5750
epoch 500 LossPred 0.9217 LossAtt 0.2082 TrainAcc 0.6000 TestAcc 0.5385 0.5900
epoch 600 LossPred 0.9042 LossAtt 0.2145 TrainAcc 0.5700 TestAcc 0.5225 0.5850
epoch 700 LossPred 0.8728 LossAtt 0.2174 TrainAcc 0.6100 TestAcc 0.5155 0.6000
epoch 800 LossPred 0.8510 LossAtt 0.2336 TrainAcc 0.6800 TestAcc 0.5288 0.6550
epoch 900 LossPred 0.8226 LossAtt 0.2464 TrainAcc 0.6400 TestAcc 0.5598 0.6400
epoch 1000 LossPred 0.7199 LossAtt 0.2935 TrainAcc 0.7100 TestAcc 0.6717 0.7150
epoch 1100 LossPred 0.6116 LossAtt 0.2868 TrainAcc 0.7800 TestAcc 0.7277 0.7600
epoch 1200 LossPred 0.4939 LossAtt 0.3398 TrainAcc 0.8300 TestAcc 0.7590 0.7650
epoch 1300 LossPred 0.4786 LossAtt 0.3082 TrainAcc 0.8400 TestAcc 0.7613 0.7700
epoch 1400 LossPred 0.4324 LossAtt 0.3168 TrainAcc 0.8400 TestAcc 0.7820 0.7750
epoch 1500 LossPred 0.4229 LossAtt 0.3273 TrainAcc 0.8600 TestAcc 0.8031 0.7850
epoch 1600 LossPred 0.4007 LossAtt 0.3139 TrainAcc 0.8700 TestAcc 0.7693 0.8000
epoch 1700 LossPred 0.3982 LossAtt 0.3215 TrainAcc 0.8600 TestAcc 0.7643 0.8250
epoch 1800 LossPred 0.3578 LossAtt 0.3200 TrainAcc 0.8800 TestAcc 0.7690 0.8250
epoch 1900 LossPred 0.3503 LossAtt 0.3100 TrainAcc 0.8800 TestAcc 0.7580 0.8000
epoch 2000 LossPred 0.3394 LossAtt 0.3009 TrainAcc 0.9000 TestAcc 0.7673 0.8000
epoch 2100 LossPred 0.3671 LossAtt 0.2824 TrainAcc 0.8600 TestAcc 0.7865 0.8250
epoch 2200 LossPred 0.3568 LossAtt 0.2861 TrainAcc 0.8700 TestAcc 0.7793 0.8150
epoch 2300 LossPred 0.3820 LossAtt 0.2697 TrainAcc 0.8600 TestAcc 0.7758 0.8300
epoch 2400 LossPred 0.3685 LossAtt 0.2836 TrainAcc 0.8700 TestAcc 0.7980 0.8450
epoch 2500 LossPred 0.3721 LossAtt 0.2631 TrainAcc 0.8700 TestAcc 0.7930 0.8250
Optimization Finished!
********** replication  52  **********
epoch   0 LossPred 0.9869 LossAtt 1.0171 TrainAcc 0.6100 TestAcc 0.6024 0.5600
epoch 100 LossPred 0.7217 LossAtt 0.3230 TrainAcc 0.7200 TestAcc 0.7092 0.7350
epoch 200 LossPred 0.4135 LossAtt 0.2431 TrainAcc 0.8800 TestAcc 0.8353 0.8500
epoch 300 LossPred 0.4655 LossAtt 0.2164 TrainAcc 0.8400 TestAcc 0.8113 0.8050
epoch 400 LossPred 0.4090 LossAtt 0.2287 TrainAcc 0.8600 TestAcc 0.8281 0.8450
epoch 500 LossPred 0.4085 LossAtt 0.2243 TrainAcc 0.8500 TestAcc 0.8293 0.8750
epoch 600 LossPred 0.4165 LossAtt 0.2418 TrainAcc 0.8600 TestAcc 0.8281 0.8400
epoch 700 LossPred 0.4627 LossAtt 0.2310 TrainAcc 0.8300 TestAcc 0.8108 0.8500
epoch 800 LossPred 0.3437 LossAtt 0.2213 TrainAcc 0.8700 TestAcc 0.8448 0.8700
epoch 900 LossPred 0.4413 LossAtt 0.2322 TrainAcc 0.8400 TestAcc 0.8178 0.8500
epoch 1000 LossPred 0.5234 LossAtt 0.2485 TrainAcc 0.8100 TestAcc 0.8138 0.8250
epoch 1100 LossPred 0.5413 LossAtt 0.2275 TrainAcc 0.8000 TestAcc 0.7898 0.7900
epoch 1200 LossPred 0.5256 LossAtt 0.2653 TrainAcc 0.8200 TestAcc 0.7930 0.8250
epoch 1300 LossPred 0.2920 LossAtt 0.2502 TrainAcc 0.8900 TestAcc 0.8796 0.9000
epoch 1400 LossPred 0.5046 LossAtt 0.2352 TrainAcc 0.8100 TestAcc 0.8046 0.7950
epoch 1500 LossPred 0.4281 LossAtt 0.2568 TrainAcc 0.8600 TestAcc 0.8386 0.8850
epoch 1600 LossPred 0.3277 LossAtt 0.2397 TrainAcc 0.8900 TestAcc 0.8501 0.8700
epoch 1700 LossPred 0.2155 LossAtt 0.2429 TrainAcc 0.9200 TestAcc 0.8724 0.9200
epoch 1800 LossPred 0.2372 LossAtt 0.2421 TrainAcc 0.9200 TestAcc 0.8736 0.9100
epoch 1900 LossPred 0.1889 LossAtt 0.2319 TrainAcc 0.9500 TestAcc 0.8736 0.9350
epoch 2000 LossPred 0.2236 LossAtt 0.2222 TrainAcc 0.9400 TestAcc 0.8804 0.9300
epoch 2100 LossPred 0.2076 LossAtt 0.2115 TrainAcc 0.9200 TestAcc 0.8749 0.9250
epoch 2200 LossPred 0.1842 LossAtt 0.2234 TrainAcc 0.9200 TestAcc 0.8794 0.9300
epoch 2300 LossPred 0.1254 LossAtt 0.2259 TrainAcc 0.9600 TestAcc 0.8966 0.9550
epoch 2400 LossPred 0.1879 LossAtt 0.2347 TrainAcc 0.9200 TestAcc 0.8781 0.9200
epoch 2500 LossPred 0.1854 LossAtt 0.2295 TrainAcc 0.9400 TestAcc 0.8896 0.9400
Optimization Finished!
********** replication  53  **********
epoch   0 LossPred 1.1464 LossAtt 1.0136 TrainAcc 0.5100 TestAcc 0.4862 0.5300
epoch 100 LossPred 0.8702 LossAtt 0.2348 TrainAcc 0.6000 TestAcc 0.5871 0.6000
epoch 200 LossPred 0.8305 LossAtt 0.1753 TrainAcc 0.6200 TestAcc 0.6299 0.6300
epoch 300 LossPred 0.4007 LossAtt 0.2844 TrainAcc 0.8800 TestAcc 0.8233 0.8450
epoch 400 LossPred 0.3110 LossAtt 0.2660 TrainAcc 0.8900 TestAcc 0.8686 0.9000
epoch 500 LossPred 0.2514 LossAtt 0.2469 TrainAcc 0.9100 TestAcc 0.8679 0.9150
epoch 600 LossPred 0.2552 LossAtt 0.2555 TrainAcc 0.9200 TestAcc 0.8939 0.9050
epoch 700 LossPred 0.2758 LossAtt 0.2542 TrainAcc 0.9100 TestAcc 0.8151 0.9050
epoch 800 LossPred 0.2468 LossAtt 0.2417 TrainAcc 0.9200 TestAcc 0.8386 0.8900
epoch 900 LossPred 0.4367 LossAtt 0.2301 TrainAcc 0.8800 TestAcc 0.8178 0.8600
epoch 1000 LossPred 0.2919 LossAtt 0.2352 TrainAcc 0.9100 TestAcc 0.8859 0.9000
epoch 1100 LossPred 0.2487 LossAtt 0.2204 TrainAcc 0.9300 TestAcc 0.8984 0.9150
epoch 1200 LossPred 0.2573 LossAtt 0.2172 TrainAcc 0.9400 TestAcc 0.8911 0.9150
epoch 1300 LossPred 0.2399 LossAtt 0.2132 TrainAcc 0.9300 TestAcc 0.9027 0.9200
epoch 1400 LossPred 0.2360 LossAtt 0.2141 TrainAcc 0.9000 TestAcc 0.8576 0.9000
epoch 1500 LossPred 0.1938 LossAtt 0.1982 TrainAcc 0.9500 TestAcc 0.8771 0.9300
epoch 1600 LossPred 0.2173 LossAtt 0.1923 TrainAcc 0.9100 TestAcc 0.8759 0.9150
epoch 1700 LossPred 0.3767 LossAtt 0.2042 TrainAcc 0.8900 TestAcc 0.8441 0.8850
epoch 1800 LossPred 0.2710 LossAtt 0.1928 TrainAcc 0.9100 TestAcc 0.8979 0.9050
epoch 1900 LossPred 0.3633 LossAtt 0.1805 TrainAcc 0.8900 TestAcc 0.8276 0.8800
epoch 2000 LossPred 0.1865 LossAtt 0.1942 TrainAcc 0.9500 TestAcc 0.8646 0.9350
epoch 2100 LossPred 0.2232 LossAtt 0.1882 TrainAcc 0.9200 TestAcc 0.8599 0.9200
epoch 2200 LossPred 0.2262 LossAtt 0.1933 TrainAcc 0.9300 TestAcc 0.8729 0.9250
epoch 2300 LossPred 0.2327 LossAtt 0.1903 TrainAcc 0.9200 TestAcc 0.8719 0.9400
epoch 2400 LossPred 0.2393 LossAtt 0.1888 TrainAcc 0.9200 TestAcc 0.8551 0.9150
epoch 2500 LossPred 0.1693 LossAtt 0.1870 TrainAcc 0.9500 TestAcc 0.8774 0.9600
Optimization Finished!
********** replication  54  **********
epoch   0 LossPred 1.0467 LossAtt 1.0137 TrainAcc 0.5800 TestAcc 0.5976 0.5050
epoch 100 LossPred 0.8904 LossAtt 0.2732 TrainAcc 0.6200 TestAcc 0.5866 0.6200
epoch 200 LossPred 0.7914 LossAtt 0.3307 TrainAcc 0.7300 TestAcc 0.5450 0.7350
epoch 300 LossPred 0.7394 LossAtt 0.3243 TrainAcc 0.7400 TestAcc 0.5330 0.7400
epoch 400 LossPred 0.7048 LossAtt 0.3231 TrainAcc 0.7600 TestAcc 0.5270 0.7450
epoch 500 LossPred 0.6663 LossAtt 0.3218 TrainAcc 0.7500 TestAcc 0.5228 0.7300
epoch 600 LossPred 0.6404 LossAtt 0.3308 TrainAcc 0.7900 TestAcc 0.5198 0.7500
epoch 700 LossPred 0.6126 LossAtt 0.3270 TrainAcc 0.8200 TestAcc 0.5265 0.7600
epoch 800 LossPred 0.6030 LossAtt 0.3273 TrainAcc 0.8100 TestAcc 0.5290 0.7500
epoch 900 LossPred 0.5930 LossAtt 0.3381 TrainAcc 0.8100 TestAcc 0.5340 0.7650
epoch 1000 LossPred 0.5818 LossAtt 0.3234 TrainAcc 0.8200 TestAcc 0.5315 0.7750
epoch 1100 LossPred 0.5847 LossAtt 0.3296 TrainAcc 0.8000 TestAcc 0.5325 0.7750
epoch 1200 LossPred 0.5749 LossAtt 0.3204 TrainAcc 0.8000 TestAcc 0.5325 0.7750
epoch 1300 LossPred 0.5672 LossAtt 0.3226 TrainAcc 0.8000 TestAcc 0.5343 0.7700
epoch 1400 LossPred 0.5452 LossAtt 0.3196 TrainAcc 0.8200 TestAcc 0.5338 0.7950
epoch 1500 LossPred 0.5453 LossAtt 0.3195 TrainAcc 0.8200 TestAcc 0.5343 0.7850
epoch 1600 LossPred 0.5570 LossAtt 0.3219 TrainAcc 0.8100 TestAcc 0.5338 0.7850
epoch 1700 LossPred 0.5283 LossAtt 0.3315 TrainAcc 0.8100 TestAcc 0.5333 0.8050
epoch 1800 LossPred 0.4910 LossAtt 0.3278 TrainAcc 0.8400 TestAcc 0.5348 0.7950
epoch 1900 LossPred 0.5051 LossAtt 0.3101 TrainAcc 0.8300 TestAcc 0.5348 0.7950
epoch 2000 LossPred 0.4706 LossAtt 0.3183 TrainAcc 0.8400 TestAcc 0.5318 0.7900
epoch 2100 LossPred 0.5491 LossAtt 0.2962 TrainAcc 0.8000 TestAcc 0.5315 0.7700
epoch 2200 LossPred 0.4981 LossAtt 0.3040 TrainAcc 0.8400 TestAcc 0.5310 0.7750
epoch 2300 LossPred 0.4429 LossAtt 0.2933 TrainAcc 0.8500 TestAcc 0.5300 0.7850
epoch 2400 LossPred 0.4272 LossAtt 0.2762 TrainAcc 0.8600 TestAcc 0.5260 0.7800
epoch 2500 LossPred 0.4385 LossAtt 0.2895 TrainAcc 0.8600 TestAcc 0.5303 0.7800
Optimization Finished!
********** replication  55  **********
epoch   0 LossPred 1.1372 LossAtt 1.0133 TrainAcc 0.4400 TestAcc 0.4064 0.4600
epoch 100 LossPred 0.9228 LossAtt 0.2008 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 200 LossPred 0.9131 LossAtt 0.1399 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 300 LossPred 0.9016 LossAtt 0.1681 TrainAcc 0.6300 TestAcc 0.6079 0.6150
epoch 400 LossPred 0.2873 LossAtt 0.2190 TrainAcc 0.9500 TestAcc 0.8609 0.9100
epoch 500 LossPred 0.2144 LossAtt 0.2097 TrainAcc 0.9500 TestAcc 0.8634 0.9300
epoch 600 LossPred 0.2118 LossAtt 0.2048 TrainAcc 0.9500 TestAcc 0.8596 0.9150
epoch 700 LossPred 0.2161 LossAtt 0.1978 TrainAcc 0.9400 TestAcc 0.8574 0.9100
epoch 800 LossPred 0.2423 LossAtt 0.1978 TrainAcc 0.9400 TestAcc 0.8456 0.9000
epoch 900 LossPred 0.1993 LossAtt 0.1927 TrainAcc 0.9300 TestAcc 0.8591 0.9100
epoch 1000 LossPred 0.1751 LossAtt 0.2022 TrainAcc 0.9400 TestAcc 0.8619 0.9250
epoch 1100 LossPred 0.1496 LossAtt 0.1947 TrainAcc 0.9500 TestAcc 0.8621 0.9300
epoch 1200 LossPred 0.2185 LossAtt 0.1916 TrainAcc 0.9300 TestAcc 0.8468 0.9150
epoch 1300 LossPred 0.2106 LossAtt 0.1981 TrainAcc 0.9300 TestAcc 0.8468 0.9050
epoch 1400 LossPred 0.1807 LossAtt 0.1933 TrainAcc 0.9400 TestAcc 0.8631 0.9000
epoch 1500 LossPred 0.1303 LossAtt 0.1981 TrainAcc 0.9500 TestAcc 0.8659 0.9350
epoch 1600 LossPred 0.1470 LossAtt 0.1934 TrainAcc 0.9500 TestAcc 0.8576 0.9300
epoch 1700 LossPred 0.5290 LossAtt 0.2005 TrainAcc 0.8300 TestAcc 0.8206 0.8450
epoch 1800 LossPred 0.5961 LossAtt 0.1917 TrainAcc 0.8200 TestAcc 0.8116 0.8250
epoch 1900 LossPred 0.3171 LossAtt 0.1938 TrainAcc 0.8900 TestAcc 0.8539 0.8850
epoch 2000 LossPred 0.1279 LossAtt 0.1862 TrainAcc 0.9500 TestAcc 0.8671 0.9250
epoch 2100 LossPred 0.1224 LossAtt 0.1944 TrainAcc 0.9500 TestAcc 0.8699 0.9300
epoch 2200 LossPred 0.1241 LossAtt 0.1947 TrainAcc 0.9700 TestAcc 0.8676 0.9250
epoch 2300 LossPred 0.1246 LossAtt 0.1897 TrainAcc 0.9500 TestAcc 0.8726 0.9250
epoch 2400 LossPred 0.2488 LossAtt 0.1893 TrainAcc 0.9300 TestAcc 0.8413 0.9250
epoch 2500 LossPred 0.4206 LossAtt 0.1918 TrainAcc 0.8600 TestAcc 0.8078 0.8950
Optimization Finished!
********** replication  56  **********
epoch   0 LossPred 1.0150 LossAtt 1.0143 TrainAcc 0.4900 TestAcc 0.4795 0.5150
epoch 100 LossPred 0.9042 LossAtt 0.3016 TrainAcc 0.6100 TestAcc 0.5991 0.6100
epoch 200 LossPred 0.4480 LossAtt 0.3042 TrainAcc 0.8700 TestAcc 0.8669 0.8650
epoch 300 LossPred 0.4532 LossAtt 0.2797 TrainAcc 0.8500 TestAcc 0.8173 0.8550
epoch 400 LossPred 0.3851 LossAtt 0.2749 TrainAcc 0.8700 TestAcc 0.8386 0.8750
epoch 500 LossPred 0.3591 LossAtt 0.2875 TrainAcc 0.8900 TestAcc 0.8636 0.8650
epoch 600 LossPred 0.4437 LossAtt 0.2890 TrainAcc 0.8500 TestAcc 0.8589 0.8700
epoch 700 LossPred 0.3469 LossAtt 0.2830 TrainAcc 0.8700 TestAcc 0.8338 0.8700
epoch 800 LossPred 0.5746 LossAtt 0.2761 TrainAcc 0.8300 TestAcc 0.7703 0.8000
epoch 900 LossPred 0.5096 LossAtt 0.2732 TrainAcc 0.8200 TestAcc 0.8406 0.8400
epoch 1000 LossPred 0.4026 LossAtt 0.2629 TrainAcc 0.8600 TestAcc 0.8076 0.8650
epoch 1100 LossPred 0.3543 LossAtt 0.2686 TrainAcc 0.8700 TestAcc 0.8669 0.8850
epoch 1200 LossPred 0.3342 LossAtt 0.2667 TrainAcc 0.8900 TestAcc 0.8541 0.9050
epoch 1300 LossPred 0.3521 LossAtt 0.2698 TrainAcc 0.8900 TestAcc 0.8581 0.8950
epoch 1400 LossPred 0.4504 LossAtt 0.2648 TrainAcc 0.8500 TestAcc 0.8478 0.8400
epoch 1500 LossPred 0.4242 LossAtt 0.2838 TrainAcc 0.8700 TestAcc 0.7908 0.8750
epoch 1600 LossPred 0.3127 LossAtt 0.2596 TrainAcc 0.8900 TestAcc 0.8599 0.9000
epoch 1700 LossPred 0.2539 LossAtt 0.2565 TrainAcc 0.9200 TestAcc 0.8606 0.9100
epoch 1800 LossPred 0.2696 LossAtt 0.2520 TrainAcc 0.9100 TestAcc 0.8761 0.9000
epoch 1900 LossPred 0.2236 LossAtt 0.2447 TrainAcc 0.9200 TestAcc 0.8776 0.9300
epoch 2000 LossPred 0.2165 LossAtt 0.2526 TrainAcc 0.9400 TestAcc 0.8679 0.9400
epoch 2100 LossPred 0.2224 LossAtt 0.2503 TrainAcc 0.9300 TestAcc 0.8591 0.9300
epoch 2200 LossPred 0.2747 LossAtt 0.2516 TrainAcc 0.9000 TestAcc 0.8323 0.9100
epoch 2300 LossPred 0.1976 LossAtt 0.2481 TrainAcc 0.9300 TestAcc 0.8769 0.9200
epoch 2400 LossPred 0.2877 LossAtt 0.2530 TrainAcc 0.9000 TestAcc 0.8313 0.9250
epoch 2500 LossPred 0.2870 LossAtt 0.2451 TrainAcc 0.9100 TestAcc 0.8841 0.9100
Optimization Finished!
********** replication  57  **********
epoch   0 LossPred 1.2262 LossAtt 1.0503 TrainAcc 0.4100 TestAcc 0.4434 0.4850
epoch 100 LossPred 0.9108 LossAtt 0.2921 TrainAcc 0.6500 TestAcc 0.6406 0.6500
epoch 200 LossPred 0.7864 LossAtt 0.3259 TrainAcc 0.6900 TestAcc 0.6762 0.7150
epoch 300 LossPred 0.5708 LossAtt 0.3155 TrainAcc 0.7800 TestAcc 0.8113 0.8050
epoch 400 LossPred 0.2722 LossAtt 0.3037 TrainAcc 0.9100 TestAcc 0.8771 0.9050
epoch 500 LossPred 0.2296 LossAtt 0.2995 TrainAcc 0.9400 TestAcc 0.8869 0.9100
epoch 600 LossPred 0.1806 LossAtt 0.3161 TrainAcc 0.9600 TestAcc 0.8871 0.9400
epoch 700 LossPred 0.1984 LossAtt 0.2954 TrainAcc 0.9200 TestAcc 0.8756 0.9150
epoch 800 LossPred 0.1294 LossAtt 0.3051 TrainAcc 0.9800 TestAcc 0.9017 0.9450
epoch 900 LossPred 0.1646 LossAtt 0.2850 TrainAcc 0.9600 TestAcc 0.8721 0.9450
epoch 1000 LossPred 0.0937 LossAtt 0.2680 TrainAcc 0.9900 TestAcc 0.9062 0.9550
epoch 1100 LossPred 0.1720 LossAtt 0.2805 TrainAcc 0.9500 TestAcc 0.8634 0.9400
epoch 1200 LossPred 0.0812 LossAtt 0.2728 TrainAcc 0.9900 TestAcc 0.9064 0.9550
epoch 1300 LossPred 0.0733 LossAtt 0.2611 TrainAcc 0.9800 TestAcc 0.8984 0.9650
epoch 1400 LossPred 0.0600 LossAtt 0.2676 TrainAcc 0.9900 TestAcc 0.8951 0.9600
epoch 1500 LossPred 0.1254 LossAtt 0.2474 TrainAcc 0.9600 TestAcc 0.8629 0.9450
epoch 1600 LossPred 0.1602 LossAtt 0.2595 TrainAcc 0.9500 TestAcc 0.8624 0.9350
epoch 1700 LossPred 0.0752 LossAtt 0.2641 TrainAcc 0.9900 TestAcc 0.9022 0.9500
epoch 1800 LossPred 0.0707 LossAtt 0.2587 TrainAcc 0.9900 TestAcc 0.8756 0.9550
epoch 1900 LossPred 0.0678 LossAtt 0.2590 TrainAcc 0.9900 TestAcc 0.9157 0.9550
epoch 2000 LossPred 0.1560 LossAtt 0.2602 TrainAcc 0.9400 TestAcc 0.9057 0.9150
epoch 2100 LossPred 0.0344 LossAtt 0.2611 TrainAcc 1.0000 TestAcc 0.8951 0.9800
Optimization Finished!
********** replication  58  **********
epoch   0 LossPred 1.0523 LossAtt 1.0073 TrainAcc 0.5100 TestAcc 0.5000 0.5250
epoch 100 LossPred 0.8122 LossAtt 0.2915 TrainAcc 0.6700 TestAcc 0.6041 0.6850
epoch 200 LossPred 0.6930 LossAtt 0.2689 TrainAcc 0.7500 TestAcc 0.8133 0.8000
epoch 300 LossPred 0.5075 LossAtt 0.2300 TrainAcc 0.8600 TestAcc 0.8126 0.8150
epoch 400 LossPred 0.4774 LossAtt 0.2129 TrainAcc 0.8400 TestAcc 0.8534 0.8350
epoch 500 LossPred 0.4755 LossAtt 0.1977 TrainAcc 0.8400 TestAcc 0.8201 0.8350
epoch 600 LossPred 0.3620 LossAtt 0.1767 TrainAcc 0.9200 TestAcc 0.8659 0.8550
epoch 700 LossPred 0.4333 LossAtt 0.1905 TrainAcc 0.8400 TestAcc 0.8331 0.7950
epoch 800 LossPred 0.5738 LossAtt 0.1708 TrainAcc 0.8100 TestAcc 0.7325 0.8100
epoch 900 LossPred 0.4294 LossAtt 0.1724 TrainAcc 0.8500 TestAcc 0.8281 0.8150
epoch 1000 LossPred 0.4176 LossAtt 0.1584 TrainAcc 0.8700 TestAcc 0.8476 0.8800
epoch 1100 LossPred 0.6425 LossAtt 0.1596 TrainAcc 0.7800 TestAcc 0.7430 0.7700
epoch 1200 LossPred 0.3609 LossAtt 0.1411 TrainAcc 0.8900 TestAcc 0.8544 0.8850
epoch 1300 LossPred 0.8316 LossAtt 0.1508 TrainAcc 0.7200 TestAcc 0.7102 0.7250
epoch 1400 LossPred 0.3682 LossAtt 0.1491 TrainAcc 0.9000 TestAcc 0.8519 0.8900
epoch 1500 LossPred 0.6745 LossAtt 0.1549 TrainAcc 0.7600 TestAcc 0.7252 0.7600
epoch 1600 LossPred 1.1543 LossAtt 0.1355 TrainAcc 0.6500 TestAcc 0.5501 0.6450
epoch 1700 LossPred 0.4056 LossAtt 0.1435 TrainAcc 0.8800 TestAcc 0.8443 0.8950
epoch 1800 LossPred 0.5083 LossAtt 0.1565 TrainAcc 0.8400 TestAcc 0.7490 0.8500
epoch 1900 LossPred 0.6718 LossAtt 0.1438 TrainAcc 0.7600 TestAcc 0.7660 0.7750
epoch 2000 LossPred 0.4362 LossAtt 0.1377 TrainAcc 0.8500 TestAcc 0.8231 0.8550
epoch 2100 LossPred 0.5356 LossAtt 0.1374 TrainAcc 0.8400 TestAcc 0.7925 0.8450
epoch 2200 LossPred 0.4130 LossAtt 0.1447 TrainAcc 0.8200 TestAcc 0.8388 0.8550
epoch 2300 LossPred 0.3982 LossAtt 0.1424 TrainAcc 0.8700 TestAcc 0.8361 0.8700
epoch 2400 LossPred 0.4797 LossAtt 0.1527 TrainAcc 0.8400 TestAcc 0.8238 0.8500
epoch 2500 LossPred 0.4065 LossAtt 0.1662 TrainAcc 0.8800 TestAcc 0.8241 0.8700
Optimization Finished!
********** replication  59  **********
epoch   0 LossPred 1.1163 LossAtt 1.0209 TrainAcc 0.5300 TestAcc 0.5055 0.5200
epoch 100 LossPred 0.8450 LossAtt 0.2571 TrainAcc 0.6800 TestAcc 0.5983 0.6800
epoch 200 LossPred 0.7854 LossAtt 0.2441 TrainAcc 0.7200 TestAcc 0.6406 0.7100
epoch 300 LossPred 0.4724 LossAtt 0.2527 TrainAcc 0.7800 TestAcc 0.8011 0.8050
epoch 400 LossPred 0.3617 LossAtt 0.2374 TrainAcc 0.8600 TestAcc 0.8631 0.8500
epoch 500 LossPred 0.3254 LossAtt 0.2518 TrainAcc 0.8800 TestAcc 0.8691 0.8500
epoch 600 LossPred 0.3662 LossAtt 0.2512 TrainAcc 0.8500 TestAcc 0.8521 0.8450
epoch 700 LossPred 0.3266 LossAtt 0.2508 TrainAcc 0.8800 TestAcc 0.8801 0.8450
epoch 800 LossPred 0.3772 LossAtt 0.2573 TrainAcc 0.8600 TestAcc 0.8671 0.8350
epoch 900 LossPred 0.4590 LossAtt 0.2552 TrainAcc 0.8200 TestAcc 0.8028 0.8350
epoch 1000 LossPred 0.2614 LossAtt 0.2560 TrainAcc 0.9100 TestAcc 0.8944 0.8700
epoch 1100 LossPred 0.3288 LossAtt 0.2426 TrainAcc 0.8600 TestAcc 0.8691 0.8650
epoch 1200 LossPred 0.3094 LossAtt 0.2317 TrainAcc 0.9100 TestAcc 0.8631 0.8850
epoch 1300 LossPred 0.3345 LossAtt 0.2179 TrainAcc 0.8700 TestAcc 0.8611 0.8550
epoch 1400 LossPred 0.3619 LossAtt 0.2081 TrainAcc 0.8700 TestAcc 0.8293 0.8600
epoch 1500 LossPred 0.3273 LossAtt 0.2059 TrainAcc 0.8800 TestAcc 0.8514 0.8800
epoch 1600 LossPred 0.3113 LossAtt 0.2081 TrainAcc 0.8900 TestAcc 0.8594 0.8950
epoch 1700 LossPred 0.3462 LossAtt 0.2170 TrainAcc 0.8500 TestAcc 0.8544 0.8400
epoch 1800 LossPred 0.3088 LossAtt 0.2025 TrainAcc 0.8800 TestAcc 0.8609 0.8850
epoch 1900 LossPred 0.3350 LossAtt 0.2023 TrainAcc 0.8800 TestAcc 0.8516 0.8700
epoch 2000 LossPred 0.3106 LossAtt 0.2008 TrainAcc 0.8700 TestAcc 0.8524 0.8750
epoch 2100 LossPred 0.3442 LossAtt 0.2054 TrainAcc 0.8600 TestAcc 0.8373 0.8700
epoch 2200 LossPred 0.3359 LossAtt 0.1904 TrainAcc 0.8700 TestAcc 0.8433 0.8700
epoch 2300 LossPred 0.3488 LossAtt 0.1875 TrainAcc 0.8500 TestAcc 0.8406 0.8750
epoch 2400 LossPred 0.3014 LossAtt 0.1937 TrainAcc 0.9000 TestAcc 0.8323 0.8850
epoch 2500 LossPred 0.3074 LossAtt 0.2001 TrainAcc 0.8900 TestAcc 0.8581 0.8800
Optimization Finished!
********** replication  60  **********
epoch   0 LossPred 0.9836 LossAtt 1.0162 TrainAcc 0.5400 TestAcc 0.4945 0.5500
epoch 100 LossPred 0.9105 LossAtt 0.2662 TrainAcc 0.6400 TestAcc 0.5606 0.6600
epoch 200 LossPred 0.7967 LossAtt 0.3602 TrainAcc 0.6900 TestAcc 0.5536 0.7000
epoch 300 LossPred 0.6296 LossAtt 0.3718 TrainAcc 0.7900 TestAcc 0.5488 0.7550
epoch 400 LossPred 0.5821 LossAtt 0.3845 TrainAcc 0.8200 TestAcc 0.5536 0.7900
epoch 500 LossPred 0.5547 LossAtt 0.3760 TrainAcc 0.8100 TestAcc 0.5513 0.7850
epoch 600 LossPred 0.5250 LossAtt 0.3779 TrainAcc 0.8200 TestAcc 0.5498 0.7750
epoch 700 LossPred 0.4987 LossAtt 0.3935 TrainAcc 0.8500 TestAcc 0.5490 0.7850
epoch 800 LossPred 0.5101 LossAtt 0.3741 TrainAcc 0.8200 TestAcc 0.5516 0.7400
epoch 900 LossPred 0.5261 LossAtt 0.3330 TrainAcc 0.8300 TestAcc 0.5455 0.7850
epoch 1000 LossPred 0.4904 LossAtt 0.3236 TrainAcc 0.8300 TestAcc 0.5455 0.7900
epoch 1100 LossPred 0.4764 LossAtt 0.3291 TrainAcc 0.8100 TestAcc 0.5338 0.8050
epoch 1200 LossPred 0.4766 LossAtt 0.3129 TrainAcc 0.8400 TestAcc 0.5368 0.8050
epoch 1300 LossPred 0.4617 LossAtt 0.3155 TrainAcc 0.8700 TestAcc 0.5355 0.8200
epoch 1400 LossPred 0.4621 LossAtt 0.3107 TrainAcc 0.8600 TestAcc 0.5323 0.8300
epoch 1500 LossPred 0.4519 LossAtt 0.3226 TrainAcc 0.8700 TestAcc 0.5345 0.8300
epoch 1600 LossPred 0.4757 LossAtt 0.3114 TrainAcc 0.8400 TestAcc 0.5285 0.8150
epoch 1700 LossPred 0.4438 LossAtt 0.3122 TrainAcc 0.8400 TestAcc 0.5275 0.8100
epoch 1800 LossPred 0.4387 LossAtt 0.2958 TrainAcc 0.8500 TestAcc 0.5315 0.8350
epoch 1900 LossPred 0.4521 LossAtt 0.3078 TrainAcc 0.8200 TestAcc 0.5295 0.8300
epoch 2000 LossPred 0.4594 LossAtt 0.2987 TrainAcc 0.8400 TestAcc 0.5260 0.8200
epoch 2100 LossPred 0.4144 LossAtt 0.2984 TrainAcc 0.8700 TestAcc 0.5258 0.8100
epoch 2200 LossPred 0.4127 LossAtt 0.2924 TrainAcc 0.8500 TestAcc 0.5258 0.8100
epoch 2300 LossPred 0.4131 LossAtt 0.2918 TrainAcc 0.8500 TestAcc 0.5240 0.8350
epoch 2400 LossPred 0.4109 LossAtt 0.2957 TrainAcc 0.8500 TestAcc 0.5260 0.8350
epoch 2500 LossPred 0.4020 LossAtt 0.2823 TrainAcc 0.8600 TestAcc 0.5273 0.8350
Optimization Finished!
********** replication  61  **********
epoch   0 LossPred 0.9786 LossAtt 1.0076 TrainAcc 0.6300 TestAcc 0.5275 0.6150
epoch 100 LossPred 0.7292 LossAtt 0.3634 TrainAcc 0.7300 TestAcc 0.6489 0.7300
epoch 200 LossPred 0.2767 LossAtt 0.3567 TrainAcc 0.9000 TestAcc 0.8596 0.9100
epoch 300 LossPred 0.2348 LossAtt 0.3365 TrainAcc 0.9400 TestAcc 0.8511 0.9300
epoch 400 LossPred 0.2098 LossAtt 0.3182 TrainAcc 0.9300 TestAcc 0.8498 0.9100
epoch 500 LossPred 0.5642 LossAtt 0.3293 TrainAcc 0.8300 TestAcc 0.7377 0.8250
epoch 600 LossPred 0.2845 LossAtt 0.3118 TrainAcc 0.9400 TestAcc 0.8336 0.9200
epoch 700 LossPred 0.2739 LossAtt 0.3099 TrainAcc 0.9400 TestAcc 0.8196 0.9200
epoch 800 LossPred 0.3652 LossAtt 0.2882 TrainAcc 0.8800 TestAcc 0.7818 0.8700
epoch 900 LossPred 0.1947 LossAtt 0.3096 TrainAcc 0.9500 TestAcc 0.8799 0.9350
epoch 1000 LossPred 0.1718 LossAtt 0.3032 TrainAcc 0.9600 TestAcc 0.8814 0.9550
epoch 1100 LossPred 0.1786 LossAtt 0.2837 TrainAcc 0.9600 TestAcc 0.8446 0.9400
epoch 1200 LossPred 0.1848 LossAtt 0.2711 TrainAcc 0.9500 TestAcc 0.8423 0.9350
epoch 1300 LossPred 0.1524 LossAtt 0.2724 TrainAcc 0.9700 TestAcc 0.8671 0.9450
epoch 1400 LossPred 0.1071 LossAtt 0.2685 TrainAcc 0.9700 TestAcc 0.8804 0.9350
epoch 1500 LossPred 0.1296 LossAtt 0.2783 TrainAcc 0.9600 TestAcc 0.8826 0.9550
epoch 1600 LossPred 0.1305 LossAtt 0.2753 TrainAcc 0.9500 TestAcc 0.8534 0.9450
epoch 1700 LossPred 0.0648 LossAtt 0.2622 TrainAcc 0.9900 TestAcc 0.8726 0.9550
epoch 1800 LossPred 0.0998 LossAtt 0.2606 TrainAcc 0.9700 TestAcc 0.8506 0.9650
epoch 1900 LossPred 0.0421 LossAtt 0.2783 TrainAcc 1.0000 TestAcc 0.8744 0.9550
Optimization Finished!
********** replication  62  **********
epoch   0 LossPred 1.0854 LossAtt 1.0141 TrainAcc 0.5700 TestAcc 0.5688 0.5300
epoch 100 LossPred 0.8649 LossAtt 0.3452 TrainAcc 0.6900 TestAcc 0.6369 0.6850
epoch 200 LossPred 0.5418 LossAtt 0.2999 TrainAcc 0.8200 TestAcc 0.7508 0.7950
epoch 300 LossPred 0.3516 LossAtt 0.2973 TrainAcc 0.8900 TestAcc 0.8388 0.8400
epoch 400 LossPred 0.3256 LossAtt 0.3099 TrainAcc 0.8900 TestAcc 0.8589 0.8800
epoch 500 LossPred 0.3165 LossAtt 0.3243 TrainAcc 0.8900 TestAcc 0.8383 0.8950
epoch 600 LossPred 0.4008 LossAtt 0.3160 TrainAcc 0.8800 TestAcc 0.7873 0.8300
epoch 700 LossPred 0.2913 LossAtt 0.3134 TrainAcc 0.9100 TestAcc 0.8381 0.9150
epoch 800 LossPred 0.4507 LossAtt 0.2926 TrainAcc 0.8300 TestAcc 0.7615 0.8250
epoch 900 LossPred 0.3255 LossAtt 0.2906 TrainAcc 0.8800 TestAcc 0.8181 0.8750
epoch 1000 LossPred 0.4437 LossAtt 0.2955 TrainAcc 0.8600 TestAcc 0.8123 0.8550
epoch 1100 LossPred 0.2551 LossAtt 0.2811 TrainAcc 0.9400 TestAcc 0.8306 0.9150
epoch 1200 LossPred 0.2483 LossAtt 0.2730 TrainAcc 0.9400 TestAcc 0.8341 0.9300
epoch 1300 LossPred 0.4094 LossAtt 0.2583 TrainAcc 0.8500 TestAcc 0.8093 0.8550
epoch 1400 LossPred 0.2884 LossAtt 0.2715 TrainAcc 0.9100 TestAcc 0.8233 0.9150
epoch 1500 LossPred 0.6012 LossAtt 0.2745 TrainAcc 0.8100 TestAcc 0.7140 0.8150
epoch 1600 LossPred 0.2686 LossAtt 0.2789 TrainAcc 0.9300 TestAcc 0.8328 0.9250
epoch 1700 LossPred 0.2808 LossAtt 0.2790 TrainAcc 0.9100 TestAcc 0.8441 0.9100
epoch 1800 LossPred 0.2594 LossAtt 0.2721 TrainAcc 0.9200 TestAcc 0.8381 0.9250
epoch 1900 LossPred 0.2857 LossAtt 0.2833 TrainAcc 0.9000 TestAcc 0.8346 0.9050
epoch 2000 LossPred 0.2894 LossAtt 0.2894 TrainAcc 0.9000 TestAcc 0.8351 0.8900
epoch 2100 LossPred 0.4079 LossAtt 0.2715 TrainAcc 0.8300 TestAcc 0.8138 0.8400
epoch 2200 LossPred 0.2227 LossAtt 0.2872 TrainAcc 0.9400 TestAcc 0.8514 0.9400
epoch 2300 LossPred 0.2057 LossAtt 0.2861 TrainAcc 0.9300 TestAcc 0.8448 0.9300
epoch 2400 LossPred 0.2372 LossAtt 0.2869 TrainAcc 0.9200 TestAcc 0.8468 0.9100
epoch 2500 LossPred 0.1881 LossAtt 0.2747 TrainAcc 0.9400 TestAcc 0.8498 0.9300
Optimization Finished!
********** replication  63  **********
epoch   0 LossPred 1.0042 LossAtt 1.0032 TrainAcc 0.5300 TestAcc 0.4835 0.5100
epoch 100 LossPred 0.8595 LossAtt 0.2345 TrainAcc 0.6200 TestAcc 0.5928 0.6350
epoch 200 LossPred 0.5318 LossAtt 0.3167 TrainAcc 0.8300 TestAcc 0.8191 0.8050
epoch 300 LossPred 0.5811 LossAtt 0.2848 TrainAcc 0.7800 TestAcc 0.7843 0.8000
epoch 400 LossPred 0.3947 LossAtt 0.2768 TrainAcc 0.8700 TestAcc 0.8448 0.8700
epoch 500 LossPred 0.3567 LossAtt 0.2615 TrainAcc 0.8700 TestAcc 0.8498 0.8600
epoch 600 LossPred 0.3601 LossAtt 0.2576 TrainAcc 0.8700 TestAcc 0.8466 0.8550
epoch 700 LossPred 0.3532 LossAtt 0.2647 TrainAcc 0.8900 TestAcc 0.8509 0.8650
epoch 800 LossPred 0.3638 LossAtt 0.2648 TrainAcc 0.8800 TestAcc 0.8413 0.8400
epoch 900 LossPred 0.4169 LossAtt 0.2628 TrainAcc 0.8500 TestAcc 0.8441 0.8500
epoch 1000 LossPred 0.3721 LossAtt 0.2569 TrainAcc 0.8800 TestAcc 0.8471 0.8500
epoch 1100 LossPred 0.3946 LossAtt 0.2675 TrainAcc 0.8600 TestAcc 0.8406 0.8450
epoch 1200 LossPred 0.5058 LossAtt 0.2559 TrainAcc 0.8100 TestAcc 0.7990 0.8350
epoch 1300 LossPred 0.3742 LossAtt 0.2568 TrainAcc 0.8700 TestAcc 0.8511 0.8600
epoch 1400 LossPred 0.3528 LossAtt 0.2605 TrainAcc 0.8800 TestAcc 0.8549 0.8600
epoch 1500 LossPred 0.3600 LossAtt 0.2523 TrainAcc 0.8600 TestAcc 0.8629 0.8550
epoch 1600 LossPred 0.3694 LossAtt 0.2545 TrainAcc 0.8600 TestAcc 0.8611 0.8650
epoch 1700 LossPred 0.5045 LossAtt 0.2582 TrainAcc 0.8100 TestAcc 0.7820 0.8050
epoch 1800 LossPred 0.5285 LossAtt 0.2484 TrainAcc 0.7900 TestAcc 0.7605 0.8000
epoch 1900 LossPred 0.3461 LossAtt 0.2558 TrainAcc 0.8600 TestAcc 0.8606 0.8700
epoch 2000 LossPred 0.4564 LossAtt 0.2561 TrainAcc 0.8700 TestAcc 0.8298 0.8550
epoch 2100 LossPred 0.3432 LossAtt 0.2463 TrainAcc 0.8700 TestAcc 0.8516 0.8650
epoch 2200 LossPred 0.4431 LossAtt 0.2397 TrainAcc 0.8700 TestAcc 0.8131 0.8650
epoch 2300 LossPred 0.3520 LossAtt 0.2395 TrainAcc 0.8700 TestAcc 0.8534 0.8700
epoch 2400 LossPred 0.4494 LossAtt 0.2403 TrainAcc 0.8500 TestAcc 0.8033 0.8450
epoch 2500 LossPred 0.4870 LossAtt 0.2597 TrainAcc 0.8400 TestAcc 0.7793 0.8350
Optimization Finished!
********** replication  64  **********
epoch   0 LossPred 0.9549 LossAtt 1.0121 TrainAcc 0.6200 TestAcc 0.5543 0.6050
epoch 100 LossPred 0.8757 LossAtt 0.3412 TrainAcc 0.6600 TestAcc 0.5836 0.6600
epoch 200 LossPred 0.3371 LossAtt 0.3358 TrainAcc 0.8900 TestAcc 0.8701 0.8850
epoch 300 LossPred 0.2462 LossAtt 0.3169 TrainAcc 0.9300 TestAcc 0.8844 0.9150
epoch 400 LossPred 0.2085 LossAtt 0.3178 TrainAcc 0.9300 TestAcc 0.8991 0.9250
epoch 500 LossPred 0.2561 LossAtt 0.2850 TrainAcc 0.9100 TestAcc 0.8609 0.9250
epoch 600 LossPred 0.2159 LossAtt 0.2514 TrainAcc 0.9300 TestAcc 0.8684 0.9350
epoch 700 LossPred 0.1964 LossAtt 0.2574 TrainAcc 0.9500 TestAcc 0.8819 0.9450
epoch 800 LossPred 0.1746 LossAtt 0.2446 TrainAcc 0.9500 TestAcc 0.9004 0.9400
epoch 900 LossPred 0.2031 LossAtt 0.2349 TrainAcc 0.9300 TestAcc 0.8764 0.9400
epoch 1000 LossPred 0.1567 LossAtt 0.2294 TrainAcc 0.9700 TestAcc 0.8966 0.9700
epoch 1100 LossPred 0.1561 LossAtt 0.2305 TrainAcc 0.9700 TestAcc 0.8914 0.9700
epoch 1200 LossPred 0.1420 LossAtt 0.2328 TrainAcc 0.9700 TestAcc 0.8939 0.9700
epoch 1300 LossPred 0.2639 LossAtt 0.2232 TrainAcc 0.9000 TestAcc 0.8406 0.9000
epoch 1400 LossPred 0.1339 LossAtt 0.2267 TrainAcc 0.9700 TestAcc 0.8894 0.9700
epoch 1500 LossPred 0.1236 LossAtt 0.2302 TrainAcc 0.9800 TestAcc 0.8914 0.9700
epoch 1600 LossPred 0.1316 LossAtt 0.2231 TrainAcc 0.9700 TestAcc 0.8884 0.9750
epoch 1700 LossPred 0.2028 LossAtt 0.2190 TrainAcc 0.9200 TestAcc 0.8799 0.9300
epoch 1800 LossPred 0.1395 LossAtt 0.2215 TrainAcc 0.9800 TestAcc 0.8841 0.9600
epoch 1900 LossPred 0.2373 LossAtt 0.2174 TrainAcc 0.9000 TestAcc 0.8481 0.9000
epoch 2000 LossPred 0.1757 LossAtt 0.2110 TrainAcc 0.9300 TestAcc 0.8636 0.9350
epoch 2100 LossPred 0.1180 LossAtt 0.2218 TrainAcc 0.9800 TestAcc 0.8834 0.9700
epoch 2200 LossPred 0.1920 LossAtt 0.2173 TrainAcc 0.9200 TestAcc 0.8804 0.9350
epoch 2300 LossPred 0.1596 LossAtt 0.2094 TrainAcc 0.9300 TestAcc 0.8701 0.9400
epoch 2400 LossPred 0.1209 LossAtt 0.2113 TrainAcc 0.9800 TestAcc 0.8789 0.9700
epoch 2500 LossPred 0.1713 LossAtt 0.2179 TrainAcc 0.9600 TestAcc 0.8826 0.9550
Optimization Finished!
********** replication  65  **********
epoch   0 LossPred 1.0156 LossAtt 1.0054 TrainAcc 0.5400 TestAcc 0.5633 0.5650
epoch 100 LossPred 0.8400 LossAtt 0.3029 TrainAcc 0.6500 TestAcc 0.6612 0.6600
epoch 200 LossPred 0.2844 LossAtt 0.2992 TrainAcc 0.9100 TestAcc 0.8761 0.8950
epoch 300 LossPred 0.2470 LossAtt 0.2715 TrainAcc 0.9300 TestAcc 0.8764 0.8850
epoch 400 LossPred 0.1995 LossAtt 0.2725 TrainAcc 0.9100 TestAcc 0.8784 0.8650
epoch 500 LossPred 0.2420 LossAtt 0.2682 TrainAcc 0.9200 TestAcc 0.8691 0.8650
epoch 600 LossPred 0.1970 LossAtt 0.2601 TrainAcc 0.9300 TestAcc 0.8851 0.8900
epoch 700 LossPred 0.1757 LossAtt 0.2744 TrainAcc 0.9600 TestAcc 0.8901 0.8850
epoch 800 LossPred 0.1415 LossAtt 0.2757 TrainAcc 0.9400 TestAcc 0.8839 0.8850
epoch 900 LossPred 0.1926 LossAtt 0.2900 TrainAcc 0.9300 TestAcc 0.8676 0.8900
epoch 1000 LossPred 0.1705 LossAtt 0.2841 TrainAcc 0.9400 TestAcc 0.8854 0.9050
epoch 1100 LossPred 0.2388 LossAtt 0.2676 TrainAcc 0.9100 TestAcc 0.8634 0.8900
epoch 1200 LossPred 0.2491 LossAtt 0.2674 TrainAcc 0.9200 TestAcc 0.8433 0.8950
epoch 1300 LossPred 0.2865 LossAtt 0.2618 TrainAcc 0.9100 TestAcc 0.8666 0.8900
epoch 1400 LossPred 0.1843 LossAtt 0.2743 TrainAcc 0.9400 TestAcc 0.8614 0.8900
epoch 1500 LossPred 0.1539 LossAtt 0.2781 TrainAcc 0.9400 TestAcc 0.8669 0.9250
epoch 1600 LossPred 0.1300 LossAtt 0.2630 TrainAcc 0.9600 TestAcc 0.8721 0.9300
epoch 1700 LossPred 0.2041 LossAtt 0.2565 TrainAcc 0.9200 TestAcc 0.8781 0.9150
epoch 1800 LossPred 0.1541 LossAtt 0.2458 TrainAcc 0.9600 TestAcc 0.8671 0.9300
epoch 1900 LossPred 0.1876 LossAtt 0.2557 TrainAcc 0.9300 TestAcc 0.8761 0.9250
epoch 2000 LossPred 0.1109 LossAtt 0.2380 TrainAcc 0.9700 TestAcc 0.8776 0.9650
epoch 2100 LossPred 0.2236 LossAtt 0.2532 TrainAcc 0.9000 TestAcc 0.8626 0.9050
epoch 2200 LossPred 0.1240 LossAtt 0.2329 TrainAcc 0.9600 TestAcc 0.8771 0.9650
epoch 2300 LossPred 0.1606 LossAtt 0.2429 TrainAcc 0.9400 TestAcc 0.8729 0.9450
epoch 2400 LossPred 0.1731 LossAtt 0.2403 TrainAcc 0.9400 TestAcc 0.8498 0.9250
epoch 2500 LossPred 0.1007 LossAtt 0.2455 TrainAcc 0.9800 TestAcc 0.8621 0.9450
Optimization Finished!
********** replication  66  **********
epoch   0 LossPred 1.0376 LossAtt 1.0343 TrainAcc 0.5300 TestAcc 0.5143 0.5250
epoch 100 LossPred 0.9701 LossAtt 0.2286 TrainAcc 0.5800 TestAcc 0.5831 0.5800
epoch 200 LossPred 0.9682 LossAtt 0.1443 TrainAcc 0.5800 TestAcc 0.5831 0.5800
epoch 300 LossPred 0.9667 LossAtt 0.1549 TrainAcc 0.5800 TestAcc 0.5831 0.5800
epoch 400 LossPred 0.7584 LossAtt 0.1865 TrainAcc 0.7300 TestAcc 0.7347 0.7200
epoch 500 LossPred 0.2943 LossAtt 0.1680 TrainAcc 0.9100 TestAcc 0.8531 0.8950
epoch 600 LossPred 0.3282 LossAtt 0.1922 TrainAcc 0.9000 TestAcc 0.8631 0.9050
epoch 700 LossPred 0.2591 LossAtt 0.1890 TrainAcc 0.9400 TestAcc 0.8579 0.9050
epoch 800 LossPred 0.2513 LossAtt 0.1901 TrainAcc 0.9400 TestAcc 0.8626 0.9050
epoch 900 LossPred 0.2382 LossAtt 0.1832 TrainAcc 0.9300 TestAcc 0.8684 0.8950
epoch 1000 LossPred 0.2492 LossAtt 0.1812 TrainAcc 0.9300 TestAcc 0.8644 0.9150
epoch 1100 LossPred 0.2341 LossAtt 0.1611 TrainAcc 0.9400 TestAcc 0.8784 0.9200
epoch 1200 LossPred 0.2294 LossAtt 0.1674 TrainAcc 0.9400 TestAcc 0.8651 0.9300
epoch 1300 LossPred 0.2250 LossAtt 0.1652 TrainAcc 0.9400 TestAcc 0.8764 0.9300
epoch 1400 LossPred 0.2188 LossAtt 0.1734 TrainAcc 0.9400 TestAcc 0.8721 0.9300
epoch 1500 LossPred 0.2286 LossAtt 0.1606 TrainAcc 0.9300 TestAcc 0.8639 0.9250
epoch 1600 LossPred 0.2626 LossAtt 0.1636 TrainAcc 0.9200 TestAcc 0.8559 0.9400
epoch 1700 LossPred 0.2124 LossAtt 0.1660 TrainAcc 0.9400 TestAcc 0.8659 0.9350
epoch 1800 LossPred 0.2319 LossAtt 0.1589 TrainAcc 0.9300 TestAcc 0.8601 0.9400
epoch 1900 LossPred 0.1963 LossAtt 0.1634 TrainAcc 0.9400 TestAcc 0.8699 0.9400
epoch 2000 LossPred 0.3114 LossAtt 0.1685 TrainAcc 0.9000 TestAcc 0.8541 0.8950
epoch 2100 LossPred 0.2106 LossAtt 0.1539 TrainAcc 0.9400 TestAcc 0.8636 0.9300
epoch 2200 LossPred 0.2126 LossAtt 0.1551 TrainAcc 0.9200 TestAcc 0.8581 0.9250
epoch 2300 LossPred 0.2248 LossAtt 0.1567 TrainAcc 0.9300 TestAcc 0.8488 0.9050
epoch 2400 LossPred 0.2158 LossAtt 0.1517 TrainAcc 0.9400 TestAcc 0.8616 0.9350
epoch 2500 LossPred 0.3121 LossAtt 0.1560 TrainAcc 0.9000 TestAcc 0.8769 0.9200
Optimization Finished!
********** replication  67  **********
epoch   0 LossPred 1.0827 LossAtt 1.0125 TrainAcc 0.3900 TestAcc 0.5038 0.5000
epoch 100 LossPred 0.9054 LossAtt 0.2724 TrainAcc 0.6000 TestAcc 0.5846 0.6050
epoch 200 LossPred 0.8844 LossAtt 0.2243 TrainAcc 0.6300 TestAcc 0.6154 0.6650
epoch 300 LossPred 0.8574 LossAtt 0.3013 TrainAcc 0.6700 TestAcc 0.6647 0.6650
epoch 400 LossPred 0.2798 LossAtt 0.2884 TrainAcc 0.9500 TestAcc 0.8526 0.9000
epoch 500 LossPred 0.2451 LossAtt 0.3024 TrainAcc 0.9300 TestAcc 0.8764 0.9150
epoch 600 LossPred 0.2073 LossAtt 0.2865 TrainAcc 0.9300 TestAcc 0.8781 0.9350
epoch 700 LossPred 0.1768 LossAtt 0.2935 TrainAcc 0.9500 TestAcc 0.8724 0.9150
epoch 800 LossPred 0.1711 LossAtt 0.2968 TrainAcc 0.9400 TestAcc 0.8509 0.9150
epoch 900 LossPred 0.1139 LossAtt 0.3085 TrainAcc 0.9800 TestAcc 0.8634 0.9450
epoch 1000 LossPred 0.1139 LossAtt 0.3154 TrainAcc 0.9600 TestAcc 0.8576 0.9250
epoch 1100 LossPred 0.1224 LossAtt 0.3334 TrainAcc 0.9600 TestAcc 0.8726 0.9450
epoch 1200 LossPred 0.0820 LossAtt 0.3436 TrainAcc 0.9800 TestAcc 0.8644 0.9600
epoch 1300 LossPred 0.0712 LossAtt 0.3428 TrainAcc 0.9800 TestAcc 0.8741 0.9600
epoch 1400 LossPred 0.0614 LossAtt 0.3461 TrainAcc 0.9900 TestAcc 0.8731 0.9800
epoch 1500 LossPred 0.0693 LossAtt 0.3409 TrainAcc 0.9800 TestAcc 0.8616 0.9600
epoch 1600 LossPred 0.0761 LossAtt 0.3394 TrainAcc 0.9800 TestAcc 0.8584 0.9550
epoch 1700 LossPred 0.0357 LossAtt 0.3182 TrainAcc 1.0000 TestAcc 0.8644 0.9750
Optimization Finished!
********** replication  68  **********
epoch   0 LossPred 1.0074 LossAtt 1.0187 TrainAcc 0.4800 TestAcc 0.5035 0.4850
epoch 100 LossPred 0.8725 LossAtt 0.3395 TrainAcc 0.6600 TestAcc 0.6306 0.6550
epoch 200 LossPred 0.3025 LossAtt 0.3489 TrainAcc 0.9300 TestAcc 0.9079 0.8800
epoch 300 LossPred 0.2447 LossAtt 0.3456 TrainAcc 0.9100 TestAcc 0.9014 0.9050
epoch 400 LossPred 0.1815 LossAtt 0.3347 TrainAcc 0.9500 TestAcc 0.9319 0.9150
epoch 500 LossPred 0.1591 LossAtt 0.3390 TrainAcc 0.9700 TestAcc 0.9327 0.9050
epoch 600 LossPred 0.1357 LossAtt 0.3059 TrainAcc 0.9600 TestAcc 0.9277 0.9500
epoch 700 LossPred 0.1308 LossAtt 0.2813 TrainAcc 0.9700 TestAcc 0.9309 0.9550
epoch 800 LossPred 0.1687 LossAtt 0.2686 TrainAcc 0.9300 TestAcc 0.9184 0.9300
epoch 900 LossPred 0.1434 LossAtt 0.2643 TrainAcc 0.9700 TestAcc 0.9172 0.9550
epoch 1000 LossPred 0.3903 LossAtt 0.2693 TrainAcc 0.8800 TestAcc 0.8353 0.8600
epoch 1100 LossPred 0.3164 LossAtt 0.2638 TrainAcc 0.9000 TestAcc 0.8844 0.9050
epoch 1200 LossPred 0.2079 LossAtt 0.2534 TrainAcc 0.9300 TestAcc 0.9002 0.9300
epoch 1300 LossPred 0.1871 LossAtt 0.2378 TrainAcc 0.9300 TestAcc 0.9217 0.9250
epoch 1400 LossPred 0.1733 LossAtt 0.2326 TrainAcc 0.9500 TestAcc 0.9232 0.9300
epoch 1500 LossPred 0.1426 LossAtt 0.2309 TrainAcc 0.9500 TestAcc 0.9224 0.9350
epoch 1600 LossPred 0.1529 LossAtt 0.2295 TrainAcc 0.9500 TestAcc 0.9122 0.9450
epoch 1700 LossPred 0.1844 LossAtt 0.2295 TrainAcc 0.9500 TestAcc 0.9087 0.9300
epoch 1800 LossPred 0.1901 LossAtt 0.2339 TrainAcc 0.9300 TestAcc 0.8966 0.9100
epoch 1900 LossPred 0.2459 LossAtt 0.2410 TrainAcc 0.9100 TestAcc 0.8891 0.9050
epoch 2000 LossPred 0.2525 LossAtt 0.2248 TrainAcc 0.9200 TestAcc 0.8831 0.9250
epoch 2100 LossPred 0.1792 LossAtt 0.2221 TrainAcc 0.9400 TestAcc 0.9084 0.9400
epoch 2200 LossPred 0.2113 LossAtt 0.2207 TrainAcc 0.9400 TestAcc 0.8966 0.9000
epoch 2300 LossPred 0.2389 LossAtt 0.2262 TrainAcc 0.9200 TestAcc 0.8906 0.9200
epoch 2400 LossPred 0.2368 LossAtt 0.2230 TrainAcc 0.9000 TestAcc 0.8994 0.9050
epoch 2500 LossPred 0.2265 LossAtt 0.2174 TrainAcc 0.9400 TestAcc 0.8914 0.9000
Optimization Finished!
********** replication  69  **********
epoch   0 LossPred 0.9970 LossAtt 1.0059 TrainAcc 0.5700 TestAcc 0.5633 0.5550
epoch 100 LossPred 0.8514 LossAtt 0.2683 TrainAcc 0.6600 TestAcc 0.5921 0.6600
epoch 200 LossPred 0.8442 LossAtt 0.1678 TrainAcc 0.6600 TestAcc 0.5921 0.6550
epoch 300 LossPred 0.6384 LossAtt 0.2769 TrainAcc 0.7200 TestAcc 0.7648 0.7250
epoch 400 LossPred 0.3898 LossAtt 0.2397 TrainAcc 0.8700 TestAcc 0.8208 0.8400
epoch 500 LossPred 0.4282 LossAtt 0.2320 TrainAcc 0.8300 TestAcc 0.7988 0.8350
epoch 600 LossPred 0.3730 LossAtt 0.2209 TrainAcc 0.9000 TestAcc 0.8383 0.8500
epoch 700 LossPred 0.3234 LossAtt 0.2075 TrainAcc 0.9100 TestAcc 0.8418 0.8700
epoch 800 LossPred 0.3436 LossAtt 0.2451 TrainAcc 0.9000 TestAcc 0.8406 0.8800
epoch 900 LossPred 0.3196 LossAtt 0.2025 TrainAcc 0.9100 TestAcc 0.8441 0.8800
epoch 1000 LossPred 0.3154 LossAtt 0.1963 TrainAcc 0.9100 TestAcc 0.8418 0.8800
epoch 1100 LossPred 0.3242 LossAtt 0.1765 TrainAcc 0.9100 TestAcc 0.8346 0.8650
epoch 1200 LossPred 0.2907 LossAtt 0.1654 TrainAcc 0.9300 TestAcc 0.8383 0.8850
epoch 1300 LossPred 0.2928 LossAtt 0.1571 TrainAcc 0.9200 TestAcc 0.8408 0.8700
epoch 1400 LossPred 0.2753 LossAtt 0.1612 TrainAcc 0.9300 TestAcc 0.8436 0.8850
epoch 1500 LossPred 0.3320 LossAtt 0.1672 TrainAcc 0.9000 TestAcc 0.8378 0.8750
epoch 1600 LossPred 0.2731 LossAtt 0.1629 TrainAcc 0.9300 TestAcc 0.8381 0.8900
epoch 1700 LossPred 0.2693 LossAtt 0.1701 TrainAcc 0.9300 TestAcc 0.8501 0.8900
epoch 1800 LossPred 0.3226 LossAtt 0.1594 TrainAcc 0.9100 TestAcc 0.8226 0.8800
epoch 1900 LossPred 0.2777 LossAtt 0.1570 TrainAcc 0.9300 TestAcc 0.8418 0.8800
epoch 2000 LossPred 0.8195 LossAtt 0.1779 TrainAcc 0.7300 TestAcc 0.6924 0.7450
epoch 2100 LossPred 0.3204 LossAtt 0.2168 TrainAcc 0.9100 TestAcc 0.8343 0.8750
epoch 2200 LossPred 0.2987 LossAtt 0.1689 TrainAcc 0.9200 TestAcc 0.8368 0.8850
epoch 2300 LossPred 0.3388 LossAtt 0.1544 TrainAcc 0.9000 TestAcc 0.8178 0.8750
epoch 2400 LossPred 0.3029 LossAtt 0.1548 TrainAcc 0.9100 TestAcc 0.8276 0.8750
epoch 2500 LossPred 0.2888 LossAtt 0.1487 TrainAcc 0.9200 TestAcc 0.8373 0.8650
Optimization Finished!
********** replication  70  **********
epoch   0 LossPred 1.1643 LossAtt 0.9794 TrainAcc 0.3500 TestAcc 0.4577 0.3450
epoch 100 LossPred 0.8571 LossAtt 0.2952 TrainAcc 0.6900 TestAcc 0.5811 0.6900
epoch 200 LossPred 0.8355 LossAtt 0.2369 TrainAcc 0.6900 TestAcc 0.5811 0.6900
epoch 300 LossPred 0.5853 LossAtt 0.3292 TrainAcc 0.7400 TestAcc 0.7232 0.7300
epoch 400 LossPred 0.3859 LossAtt 0.2833 TrainAcc 0.8900 TestAcc 0.8318 0.8300
epoch 500 LossPred 0.3507 LossAtt 0.2778 TrainAcc 0.8700 TestAcc 0.8178 0.8400
epoch 600 LossPred 0.1946 LossAtt 0.2673 TrainAcc 0.9400 TestAcc 0.8941 0.8950
epoch 700 LossPred 0.1510 LossAtt 0.2535 TrainAcc 0.9500 TestAcc 0.8956 0.8800
epoch 800 LossPred 0.1329 LossAtt 0.2354 TrainAcc 0.9700 TestAcc 0.9067 0.9100
epoch 900 LossPred 0.1638 LossAtt 0.2282 TrainAcc 0.9500 TestAcc 0.8951 0.8850
epoch 1000 LossPred 0.1041 LossAtt 0.2174 TrainAcc 0.9800 TestAcc 0.9262 0.9250
epoch 1100 LossPred 0.1201 LossAtt 0.2191 TrainAcc 0.9700 TestAcc 0.9189 0.9300
epoch 1200 LossPred 0.1315 LossAtt 0.2096 TrainAcc 0.9700 TestAcc 0.9224 0.9250
epoch 1300 LossPred 0.0959 LossAtt 0.2126 TrainAcc 0.9800 TestAcc 0.9219 0.9300
epoch 1400 LossPred 0.0895 LossAtt 0.2144 TrainAcc 0.9700 TestAcc 0.9339 0.9350
epoch 1500 LossPred 0.0903 LossAtt 0.2075 TrainAcc 0.9900 TestAcc 0.9242 0.9350
epoch 1600 LossPred 0.0932 LossAtt 0.2152 TrainAcc 0.9700 TestAcc 0.9327 0.9400
epoch 1700 LossPred 0.0997 LossAtt 0.2112 TrainAcc 0.9800 TestAcc 0.9114 0.9150
epoch 1800 LossPred 0.0880 LossAtt 0.2084 TrainAcc 0.9700 TestAcc 0.9337 0.9350
epoch 1900 LossPred 0.0864 LossAtt 0.1994 TrainAcc 0.9700 TestAcc 0.9332 0.9400
epoch 2000 LossPred 0.0823 LossAtt 0.2091 TrainAcc 0.9800 TestAcc 0.9289 0.9200
epoch 2100 LossPred 0.1046 LossAtt 0.1949 TrainAcc 0.9700 TestAcc 0.8994 0.9150
epoch 2200 LossPred 0.0869 LossAtt 0.2030 TrainAcc 0.9800 TestAcc 0.9214 0.9100
epoch 2300 LossPred 0.1147 LossAtt 0.2124 TrainAcc 0.9500 TestAcc 0.9217 0.9150
epoch 2400 LossPred 0.1292 LossAtt 0.2144 TrainAcc 0.9600 TestAcc 0.9234 0.9150
epoch 2500 LossPred 0.1368 LossAtt 0.2229 TrainAcc 0.9500 TestAcc 0.9002 0.9000
Optimization Finished!
********** replication  71  **********
epoch   0 LossPred 1.0719 LossAtt 0.9843 TrainAcc 0.4700 TestAcc 0.4515 0.4550
epoch 100 LossPred 0.9824 LossAtt 0.2236 TrainAcc 0.5500 TestAcc 0.5851 0.5500
epoch 200 LossPred 0.9794 LossAtt 0.1883 TrainAcc 0.5500 TestAcc 0.5851 0.5700
epoch 300 LossPred 0.9496 LossAtt 0.1723 TrainAcc 0.6400 TestAcc 0.6229 0.6350
epoch 400 LossPred 0.9359 LossAtt 0.1779 TrainAcc 0.6500 TestAcc 0.6071 0.6350
epoch 500 LossPred 0.9314 LossAtt 0.1675 TrainAcc 0.6300 TestAcc 0.6174 0.6600
epoch 600 LossPred 0.9139 LossAtt 0.1982 TrainAcc 0.6200 TestAcc 0.5851 0.6200
epoch 700 LossPred 0.8896 LossAtt 0.2132 TrainAcc 0.6800 TestAcc 0.6146 0.6950
epoch 800 LossPred 0.8447 LossAtt 0.2483 TrainAcc 0.6900 TestAcc 0.6151 0.6950
epoch 900 LossPred 0.8190 LossAtt 0.2849 TrainAcc 0.7100 TestAcc 0.6131 0.6850
epoch 1000 LossPred 0.8102 LossAtt 0.2962 TrainAcc 0.6900 TestAcc 0.6146 0.6850
epoch 1100 LossPred 0.7830 LossAtt 0.3059 TrainAcc 0.7200 TestAcc 0.6074 0.6500
epoch 1200 LossPred 0.7421 LossAtt 0.2896 TrainAcc 0.7400 TestAcc 0.6096 0.6750
epoch 1300 LossPred 0.7272 LossAtt 0.2928 TrainAcc 0.7200 TestAcc 0.5991 0.6750
epoch 1400 LossPred 0.7172 LossAtt 0.2974 TrainAcc 0.7000 TestAcc 0.5928 0.6850
epoch 1500 LossPred 0.6888 LossAtt 0.2873 TrainAcc 0.7500 TestAcc 0.5931 0.6600
epoch 1600 LossPred 0.7991 LossAtt 0.3355 TrainAcc 0.7200 TestAcc 0.5691 0.6350
epoch 1700 LossPred 0.7939 LossAtt 0.3168 TrainAcc 0.7100 TestAcc 0.5573 0.6650
epoch 1800 LossPred 0.6326 LossAtt 0.3251 TrainAcc 0.7800 TestAcc 0.5781 0.6750
epoch 1900 LossPred 0.6230 LossAtt 0.3025 TrainAcc 0.8200 TestAcc 0.5671 0.6750
epoch 2000 LossPred 0.6349 LossAtt 0.3119 TrainAcc 0.8100 TestAcc 0.5658 0.6700
epoch 2100 LossPred 0.6354 LossAtt 0.2972 TrainAcc 0.8200 TestAcc 0.5698 0.6450
epoch 2200 LossPred 0.6504 LossAtt 0.2876 TrainAcc 0.8100 TestAcc 0.5738 0.6500
epoch 2300 LossPred 0.7290 LossAtt 0.2860 TrainAcc 0.7500 TestAcc 0.5556 0.6650
epoch 2400 LossPred 0.6390 LossAtt 0.2897 TrainAcc 0.8100 TestAcc 0.5633 0.6600
epoch 2500 LossPred 0.6364 LossAtt 0.2720 TrainAcc 0.8400 TestAcc 0.5683 0.6650
Optimization Finished!
********** replication  72  **********
epoch   0 LossPred 1.1542 LossAtt 1.0311 TrainAcc 0.2800 TestAcc 0.4159 0.3550
epoch 100 LossPred 0.7709 LossAtt 0.2304 TrainAcc 0.7200 TestAcc 0.5841 0.7100
epoch 200 LossPred 0.7501 LossAtt 0.1982 TrainAcc 0.7200 TestAcc 0.5841 0.7200
epoch 300 LossPred 0.7368 LossAtt 0.2162 TrainAcc 0.7200 TestAcc 0.5841 0.7250
epoch 400 LossPred 0.7870 LossAtt 0.1952 TrainAcc 0.7000 TestAcc 0.6476 0.7200
epoch 500 LossPred 0.4745 LossAtt 0.1719 TrainAcc 0.8200 TestAcc 0.7840 0.7600
epoch 600 LossPred 0.4146 LossAtt 0.1769 TrainAcc 0.8500 TestAcc 0.8093 0.8350
epoch 700 LossPred 0.4426 LossAtt 0.1816 TrainAcc 0.8300 TestAcc 0.7975 0.8050
epoch 800 LossPred 0.7023 LossAtt 0.1750 TrainAcc 0.7300 TestAcc 0.6812 0.7550
epoch 900 LossPred 0.4209 LossAtt 0.1569 TrainAcc 0.8700 TestAcc 0.8186 0.8600
epoch 1000 LossPred 0.4743 LossAtt 0.1528 TrainAcc 0.8400 TestAcc 0.8271 0.8650
epoch 1100 LossPred 0.3871 LossAtt 0.1512 TrainAcc 0.8300 TestAcc 0.8238 0.8500
epoch 1200 LossPred 0.7278 LossAtt 0.1605 TrainAcc 0.7000 TestAcc 0.7090 0.7200
epoch 1300 LossPred 0.3767 LossAtt 0.1429 TrainAcc 0.8700 TestAcc 0.8241 0.8450
epoch 1400 LossPred 0.3598 LossAtt 0.1333 TrainAcc 0.8800 TestAcc 0.8353 0.8350
epoch 1500 LossPred 0.5006 LossAtt 0.1234 TrainAcc 0.8200 TestAcc 0.7900 0.8450
epoch 1600 LossPred 0.5243 LossAtt 0.1306 TrainAcc 0.8200 TestAcc 0.7743 0.8400
epoch 1700 LossPred 0.3852 LossAtt 0.1103 TrainAcc 0.8500 TestAcc 0.8043 0.8450
epoch 1800 LossPred 0.7411 LossAtt 0.0984 TrainAcc 0.7200 TestAcc 0.5846 0.7200
epoch 1900 LossPred 0.7417 LossAtt 0.0984 TrainAcc 0.7200 TestAcc 0.5846 0.7200
epoch 2000 LossPred 0.7401 LossAtt 0.0974 TrainAcc 0.7200 TestAcc 0.5848 0.7200
epoch 2100 LossPred 0.7402 LossAtt 0.0994 TrainAcc 0.7200 TestAcc 0.5848 0.7200
epoch 2200 LossPred 0.7388 LossAtt 0.0940 TrainAcc 0.7200 TestAcc 0.5851 0.7200
epoch 2300 LossPred 0.7371 LossAtt 0.0951 TrainAcc 0.7200 TestAcc 0.5851 0.7250
epoch 2400 LossPred 0.7369 LossAtt 0.1017 TrainAcc 0.7200 TestAcc 0.6039 0.7050
epoch 2500 LossPred 0.7358 LossAtt 0.0979 TrainAcc 0.7300 TestAcc 0.6489 0.7050
Optimization Finished!
********** replication  73  **********
epoch   0 LossPred 0.9807 LossAtt 1.0243 TrainAcc 0.6100 TestAcc 0.5888 0.6000
epoch 100 LossPred 0.8540 LossAtt 0.2637 TrainAcc 0.6200 TestAcc 0.5383 0.5950
epoch 200 LossPred 0.8405 LossAtt 0.2230 TrainAcc 0.6400 TestAcc 0.5603 0.6300
epoch 300 LossPred 0.7907 LossAtt 0.2757 TrainAcc 0.7100 TestAcc 0.5753 0.6850
epoch 400 LossPred 0.7698 LossAtt 0.2754 TrainAcc 0.7100 TestAcc 0.5693 0.7000
epoch 500 LossPred 0.7472 LossAtt 0.2786 TrainAcc 0.7300 TestAcc 0.5676 0.6700
epoch 600 LossPred 0.7249 LossAtt 0.3029 TrainAcc 0.7600 TestAcc 0.5691 0.6800
epoch 700 LossPred 0.7107 LossAtt 0.3100 TrainAcc 0.7600 TestAcc 0.5836 0.6850
epoch 800 LossPred 0.6901 LossAtt 0.3356 TrainAcc 0.7500 TestAcc 0.5913 0.7000
epoch 900 LossPred 0.6714 LossAtt 0.3332 TrainAcc 0.7600 TestAcc 0.5966 0.7200
epoch 1000 LossPred 0.6424 LossAtt 0.3671 TrainAcc 0.7600 TestAcc 0.5878 0.7300
epoch 1100 LossPred 0.5948 LossAtt 0.3569 TrainAcc 0.7900 TestAcc 0.5936 0.7600
epoch 1200 LossPred 0.5577 LossAtt 0.3399 TrainAcc 0.8100 TestAcc 0.6024 0.7750
epoch 1300 LossPred 0.5568 LossAtt 0.3416 TrainAcc 0.7800 TestAcc 0.6034 0.7600
epoch 1400 LossPred 0.4974 LossAtt 0.3545 TrainAcc 0.8400 TestAcc 0.6009 0.7600
epoch 1500 LossPred 0.4529 LossAtt 0.3489 TrainAcc 0.8600 TestAcc 0.5976 0.7500
epoch 1600 LossPred 0.4237 LossAtt 0.3554 TrainAcc 0.8700 TestAcc 0.5948 0.7600
epoch 1700 LossPred 0.4046 LossAtt 0.3314 TrainAcc 0.8800 TestAcc 0.6001 0.7350
epoch 1800 LossPred 0.4413 LossAtt 0.3415 TrainAcc 0.8500 TestAcc 0.6011 0.7150
epoch 1900 LossPred 0.4228 LossAtt 0.3400 TrainAcc 0.8700 TestAcc 0.6024 0.7150
epoch 2000 LossPred 0.3869 LossAtt 0.3327 TrainAcc 0.8900 TestAcc 0.6001 0.7550
epoch 2100 LossPred 0.3868 LossAtt 0.3368 TrainAcc 0.8900 TestAcc 0.6106 0.7500
epoch 2200 LossPred 0.3376 LossAtt 0.3319 TrainAcc 0.9000 TestAcc 0.6101 0.7450
epoch 2300 LossPred 0.3542 LossAtt 0.3294 TrainAcc 0.9100 TestAcc 0.6084 0.7500
epoch 2400 LossPred 0.3693 LossAtt 0.3337 TrainAcc 0.9100 TestAcc 0.6031 0.7800
epoch 2500 LossPred 0.3205 LossAtt 0.3236 TrainAcc 0.9100 TestAcc 0.6119 0.7600
Optimization Finished!
********** replication  74  **********
epoch   0 LossPred 1.1145 LossAtt 1.0407 TrainAcc 0.5200 TestAcc 0.5188 0.4650
epoch 100 LossPred 0.9067 LossAtt 0.2873 TrainAcc 0.6000 TestAcc 0.6261 0.6050
epoch 200 LossPred 0.3756 LossAtt 0.3310 TrainAcc 0.8800 TestAcc 0.8679 0.8900
epoch 300 LossPred 0.2115 LossAtt 0.3386 TrainAcc 0.9600 TestAcc 0.9034 0.9400
epoch 400 LossPred 0.1880 LossAtt 0.3190 TrainAcc 0.9700 TestAcc 0.8974 0.9300
epoch 500 LossPred 0.1641 LossAtt 0.3123 TrainAcc 0.9600 TestAcc 0.8984 0.9450
epoch 600 LossPred 0.1882 LossAtt 0.2966 TrainAcc 0.9200 TestAcc 0.8939 0.9300
epoch 700 LossPred 0.2021 LossAtt 0.2768 TrainAcc 0.9300 TestAcc 0.8976 0.9250
epoch 800 LossPred 0.2966 LossAtt 0.2610 TrainAcc 0.9000 TestAcc 0.8794 0.8900
epoch 900 LossPred 0.1879 LossAtt 0.2564 TrainAcc 0.9400 TestAcc 0.8789 0.9350
epoch 1000 LossPred 0.1527 LossAtt 0.2506 TrainAcc 0.9500 TestAcc 0.9029 0.9500
epoch 1100 LossPred 0.2316 LossAtt 0.2472 TrainAcc 0.9100 TestAcc 0.9014 0.9150
epoch 1200 LossPred 0.1409 LossAtt 0.2381 TrainAcc 0.9400 TestAcc 0.9059 0.9550
epoch 1300 LossPred 0.1207 LossAtt 0.2362 TrainAcc 0.9500 TestAcc 0.9102 0.9600
epoch 1400 LossPred 0.1154 LossAtt 0.2451 TrainAcc 0.9700 TestAcc 0.9034 0.9600
epoch 1500 LossPred 0.0801 LossAtt 0.2488 TrainAcc 0.9700 TestAcc 0.9099 0.9700
epoch 1600 LossPred 0.0796 LossAtt 0.2384 TrainAcc 0.9700 TestAcc 0.9097 0.9650
epoch 1700 LossPred 0.0816 LossAtt 0.2336 TrainAcc 0.9700 TestAcc 0.9072 0.9700
epoch 1800 LossPred 0.1674 LossAtt 0.2473 TrainAcc 0.9400 TestAcc 0.8629 0.9500
epoch 1900 LossPred 0.0625 LossAtt 0.2394 TrainAcc 0.9900 TestAcc 0.9089 0.9800
epoch 2000 LossPred 0.0513 LossAtt 0.2302 TrainAcc 0.9800 TestAcc 0.8991 0.9850
epoch 2100 LossPred 0.0845 LossAtt 0.2266 TrainAcc 0.9700 TestAcc 0.8811 0.9650
epoch 2200 LossPred 0.0369 LossAtt 0.2267 TrainAcc 0.9900 TestAcc 0.8989 0.9850
epoch 2300 LossPred 0.0368 LossAtt 0.2265 TrainAcc 0.9900 TestAcc 0.8994 0.9900
epoch 2400 LossPred 0.0343 LossAtt 0.2269 TrainAcc 0.9900 TestAcc 0.8979 0.9900
epoch 2500 LossPred 0.0416 LossAtt 0.2299 TrainAcc 0.9900 TestAcc 0.8846 0.9850
Optimization Finished!
********** replication  75  **********
epoch   0 LossPred 1.0755 LossAtt 1.0140 TrainAcc 0.4100 TestAcc 0.4522 0.3900
epoch 100 LossPred 0.8773 LossAtt 0.2420 TrainAcc 0.6400 TestAcc 0.5846 0.6400
epoch 200 LossPred 0.8463 LossAtt 0.2289 TrainAcc 0.6400 TestAcc 0.5846 0.6400
epoch 300 LossPred 0.5257 LossAtt 0.3030 TrainAcc 0.7700 TestAcc 0.8298 0.7600
epoch 400 LossPred 0.2662 LossAtt 0.2733 TrainAcc 0.9200 TestAcc 0.8774 0.9200
epoch 500 LossPred 0.2813 LossAtt 0.2701 TrainAcc 0.8900 TestAcc 0.9042 0.8850
epoch 600 LossPred 0.5226 LossAtt 0.2566 TrainAcc 0.8300 TestAcc 0.7580 0.8400
epoch 700 LossPred 0.3305 LossAtt 0.2476 TrainAcc 0.8800 TestAcc 0.8829 0.8500
epoch 800 LossPred 0.4755 LossAtt 0.2480 TrainAcc 0.8300 TestAcc 0.8281 0.8000
epoch 900 LossPred 0.2590 LossAtt 0.2465 TrainAcc 0.9100 TestAcc 0.8816 0.8950
epoch 1000 LossPred 0.2858 LossAtt 0.2312 TrainAcc 0.9100 TestAcc 0.8904 0.9100
epoch 1100 LossPred 0.2421 LossAtt 0.2233 TrainAcc 0.9200 TestAcc 0.8991 0.9200
epoch 1200 LossPred 0.4114 LossAtt 0.2261 TrainAcc 0.8200 TestAcc 0.8594 0.8250
epoch 1300 LossPred 0.4326 LossAtt 0.2224 TrainAcc 0.8400 TestAcc 0.8401 0.8500
epoch 1400 LossPred 0.3140 LossAtt 0.2146 TrainAcc 0.8700 TestAcc 0.8789 0.8700
epoch 1500 LossPred 0.3194 LossAtt 0.2111 TrainAcc 0.9000 TestAcc 0.8448 0.8950
epoch 1600 LossPred 0.3503 LossAtt 0.2115 TrainAcc 0.9000 TestAcc 0.8321 0.9000
epoch 1700 LossPred 0.2797 LossAtt 0.1878 TrainAcc 0.9000 TestAcc 0.8719 0.9150
epoch 1800 LossPred 0.2554 LossAtt 0.1965 TrainAcc 0.8900 TestAcc 0.8824 0.9150
epoch 1900 LossPred 0.3981 LossAtt 0.1940 TrainAcc 0.8300 TestAcc 0.8446 0.8450
epoch 2000 LossPred 0.2382 LossAtt 0.1800 TrainAcc 0.9300 TestAcc 0.8554 0.9250
epoch 2100 LossPred 0.2035 LossAtt 0.1800 TrainAcc 0.9400 TestAcc 0.8869 0.9350
epoch 2200 LossPred 0.1910 LossAtt 0.1625 TrainAcc 0.9500 TestAcc 0.8789 0.9350
epoch 2300 LossPred 0.2409 LossAtt 0.1754 TrainAcc 0.9300 TestAcc 0.9072 0.9200
epoch 2400 LossPred 0.2189 LossAtt 0.1623 TrainAcc 0.9200 TestAcc 0.9107 0.9250
epoch 2500 LossPred 0.1775 LossAtt 0.1602 TrainAcc 0.9400 TestAcc 0.9057 0.9350
Optimization Finished!
********** replication  76  **********
epoch   0 LossPred 1.3679 LossAtt 1.0558 TrainAcc 0.4400 TestAcc 0.4895 0.4300
epoch 100 LossPred 0.8815 LossAtt 0.3038 TrainAcc 0.6600 TestAcc 0.5891 0.6650
epoch 200 LossPred 0.8266 LossAtt 0.2677 TrainAcc 0.6700 TestAcc 0.6459 0.6750
epoch 300 LossPred 0.5328 LossAtt 0.2674 TrainAcc 0.8200 TestAcc 0.7608 0.7900
epoch 400 LossPred 0.3561 LossAtt 0.2584 TrainAcc 0.8800 TestAcc 0.8466 0.8650
epoch 500 LossPred 0.3546 LossAtt 0.2742 TrainAcc 0.8800 TestAcc 0.8221 0.8550
epoch 600 LossPred 0.4255 LossAtt 0.2606 TrainAcc 0.8600 TestAcc 0.7945 0.9000
epoch 700 LossPred 0.2659 LossAtt 0.2423 TrainAcc 0.9400 TestAcc 0.8171 0.8950
epoch 800 LossPred 0.2882 LossAtt 0.2294 TrainAcc 0.9300 TestAcc 0.8076 0.8700
epoch 900 LossPred 0.3833 LossAtt 0.2206 TrainAcc 0.8600 TestAcc 0.7848 0.8300
epoch 1000 LossPred 0.2654 LossAtt 0.2258 TrainAcc 0.9400 TestAcc 0.8006 0.9050
epoch 1100 LossPred 0.2304 LossAtt 0.2344 TrainAcc 0.9400 TestAcc 0.8126 0.9050
epoch 1200 LossPred 0.2664 LossAtt 0.2430 TrainAcc 0.9200 TestAcc 0.8161 0.9050
epoch 1300 LossPred 0.2446 LossAtt 0.2396 TrainAcc 0.9200 TestAcc 0.8268 0.9000
epoch 1400 LossPred 0.1875 LossAtt 0.2346 TrainAcc 0.9600 TestAcc 0.8341 0.9450
epoch 1500 LossPred 0.2440 LossAtt 0.2217 TrainAcc 0.9200 TestAcc 0.8313 0.8900
epoch 1600 LossPred 0.1753 LossAtt 0.2294 TrainAcc 0.9600 TestAcc 0.8396 0.9350
epoch 1700 LossPred 0.2878 LossAtt 0.2141 TrainAcc 0.9100 TestAcc 0.8281 0.8700
epoch 1800 LossPred 0.1754 LossAtt 0.2237 TrainAcc 0.9600 TestAcc 0.8416 0.9500
epoch 1900 LossPred 0.2012 LossAtt 0.2168 TrainAcc 0.9400 TestAcc 0.8599 0.9450
epoch 2000 LossPred 0.2077 LossAtt 0.2139 TrainAcc 0.9300 TestAcc 0.8539 0.9300
epoch 2100 LossPred 0.2152 LossAtt 0.2081 TrainAcc 0.9300 TestAcc 0.8569 0.9200
epoch 2200 LossPred 0.1613 LossAtt 0.2107 TrainAcc 0.9600 TestAcc 0.8541 0.9500
epoch 2300 LossPred 0.1778 LossAtt 0.2064 TrainAcc 0.9400 TestAcc 0.8488 0.9450
epoch 2400 LossPred 0.2311 LossAtt 0.2061 TrainAcc 0.9200 TestAcc 0.8526 0.9250
epoch 2500 LossPred 0.2953 LossAtt 0.1981 TrainAcc 0.8900 TestAcc 0.8368 0.8750
Optimization Finished!
********** replication  77  **********
epoch   0 LossPred 1.1128 LossAtt 1.0211 TrainAcc 0.3800 TestAcc 0.4159 0.3800
epoch 100 LossPred 0.8509 LossAtt 0.2631 TrainAcc 0.6900 TestAcc 0.6361 0.6900
epoch 200 LossPred 0.6800 LossAtt 0.3010 TrainAcc 0.7500 TestAcc 0.6824 0.7650
epoch 300 LossPred 0.5589 LossAtt 0.3008 TrainAcc 0.8000 TestAcc 0.7292 0.8050
epoch 400 LossPred 0.2085 LossAtt 0.2827 TrainAcc 0.9300 TestAcc 0.8904 0.9050
epoch 500 LossPred 0.1805 LossAtt 0.2744 TrainAcc 0.9400 TestAcc 0.8744 0.8950
epoch 600 LossPred 0.2226 LossAtt 0.2596 TrainAcc 0.9300 TestAcc 0.8614 0.9050
epoch 700 LossPred 0.2468 LossAtt 0.2540 TrainAcc 0.9300 TestAcc 0.8954 0.9150
epoch 800 LossPred 0.2547 LossAtt 0.2504 TrainAcc 0.9200 TestAcc 0.8366 0.9150
epoch 900 LossPred 0.2486 LossAtt 0.2463 TrainAcc 0.9100 TestAcc 0.8721 0.9100
epoch 1000 LossPred 0.3265 LossAtt 0.2421 TrainAcc 0.8900 TestAcc 0.8111 0.8850
epoch 1100 LossPred 0.2389 LossAtt 0.2425 TrainAcc 0.9200 TestAcc 0.8744 0.9150
epoch 1200 LossPred 0.2223 LossAtt 0.2281 TrainAcc 0.9100 TestAcc 0.8426 0.9000
epoch 1300 LossPred 0.1239 LossAtt 0.2160 TrainAcc 0.9600 TestAcc 0.8874 0.9500
epoch 1400 LossPred 0.1190 LossAtt 0.2238 TrainAcc 0.9600 TestAcc 0.8951 0.9450
epoch 1500 LossPred 0.1817 LossAtt 0.2144 TrainAcc 0.9300 TestAcc 0.8644 0.9200
epoch 1600 LossPred 0.2639 LossAtt 0.2137 TrainAcc 0.9000 TestAcc 0.8278 0.8950
epoch 1700 LossPred 0.1431 LossAtt 0.2092 TrainAcc 0.9600 TestAcc 0.8801 0.9450
epoch 1800 LossPred 0.1612 LossAtt 0.2104 TrainAcc 0.9500 TestAcc 0.8681 0.9400
epoch 1900 LossPred 0.1537 LossAtt 0.2082 TrainAcc 0.9300 TestAcc 0.8764 0.9300
epoch 2000 LossPred 0.2025 LossAtt 0.2091 TrainAcc 0.9300 TestAcc 0.9012 0.9150
epoch 2100 LossPred 0.1243 LossAtt 0.2101 TrainAcc 0.9700 TestAcc 0.8911 0.9500
epoch 2200 LossPred 0.1532 LossAtt 0.2017 TrainAcc 0.9500 TestAcc 0.8761 0.9500
epoch 2300 LossPred 0.1840 LossAtt 0.2043 TrainAcc 0.9300 TestAcc 0.9014 0.9350
epoch 2400 LossPred 0.1214 LossAtt 0.2139 TrainAcc 0.9500 TestAcc 0.8951 0.9400
epoch 2500 LossPred 0.1314 LossAtt 0.1998 TrainAcc 0.9600 TestAcc 0.8976 0.9400
Optimization Finished!
********** replication  78  **********
epoch   0 LossPred 1.2548 LossAtt 1.0071 TrainAcc 0.3900 TestAcc 0.4775 0.4500
epoch 100 LossPred 0.8613 LossAtt 0.2415 TrainAcc 0.6300 TestAcc 0.5938 0.6300
epoch 200 LossPred 0.5074 LossAtt 0.2769 TrainAcc 0.8800 TestAcc 0.8181 0.8750
epoch 300 LossPred 0.3661 LossAtt 0.2608 TrainAcc 0.8900 TestAcc 0.8681 0.8750
epoch 400 LossPred 0.3518 LossAtt 0.2712 TrainAcc 0.8400 TestAcc 0.8664 0.8700
epoch 500 LossPred 0.2947 LossAtt 0.2686 TrainAcc 0.8800 TestAcc 0.8741 0.8850
epoch 600 LossPred 0.2997 LossAtt 0.2436 TrainAcc 0.8800 TestAcc 0.8631 0.8950
epoch 700 LossPred 0.1997 LossAtt 0.2490 TrainAcc 0.9400 TestAcc 0.8749 0.9200
epoch 800 LossPred 0.1764 LossAtt 0.2431 TrainAcc 0.9400 TestAcc 0.8726 0.9350
epoch 900 LossPred 0.2106 LossAtt 0.2233 TrainAcc 0.9300 TestAcc 0.8674 0.9050
epoch 1000 LossPred 0.3508 LossAtt 0.2340 TrainAcc 0.8700 TestAcc 0.8519 0.9100
epoch 1100 LossPred 0.2277 LossAtt 0.2203 TrainAcc 0.9100 TestAcc 0.8671 0.9000
epoch 1200 LossPred 0.3387 LossAtt 0.2263 TrainAcc 0.8700 TestAcc 0.8501 0.9050
epoch 1300 LossPred 0.2055 LossAtt 0.2255 TrainAcc 0.9300 TestAcc 0.8679 0.9250
epoch 1400 LossPred 0.1530 LossAtt 0.2197 TrainAcc 0.9500 TestAcc 0.8774 0.9550
epoch 1500 LossPred 0.1360 LossAtt 0.2167 TrainAcc 0.9600 TestAcc 0.8759 0.9550
epoch 1600 LossPred 0.1934 LossAtt 0.2107 TrainAcc 0.9400 TestAcc 0.8664 0.9400
epoch 1700 LossPred 0.1771 LossAtt 0.2140 TrainAcc 0.9500 TestAcc 0.8579 0.9200
epoch 1800 LossPred 0.1558 LossAtt 0.2065 TrainAcc 0.9500 TestAcc 0.8691 0.9550
epoch 1900 LossPred 0.1455 LossAtt 0.2156 TrainAcc 0.9700 TestAcc 0.8531 0.9500
epoch 2000 LossPred 0.1332 LossAtt 0.2261 TrainAcc 0.9500 TestAcc 0.8534 0.9650
epoch 2100 LossPred 0.2054 LossAtt 0.2135 TrainAcc 0.9300 TestAcc 0.8579 0.9400
epoch 2200 LossPred 0.1674 LossAtt 0.2226 TrainAcc 0.9600 TestAcc 0.8581 0.9550
epoch 2300 LossPred 0.1558 LossAtt 0.2162 TrainAcc 0.9400 TestAcc 0.8483 0.9450
epoch 2400 LossPred 0.0986 LossAtt 0.2106 TrainAcc 0.9800 TestAcc 0.8726 0.9750
epoch 2500 LossPred 0.1062 LossAtt 0.2211 TrainAcc 0.9800 TestAcc 0.8631 0.9600
Optimization Finished!
********** replication  79  **********
epoch   0 LossPred 1.2803 LossAtt 1.0182 TrainAcc 0.3400 TestAcc 0.4399 0.4000
epoch 100 LossPred 0.9665 LossAtt 0.2623 TrainAcc 0.6500 TestAcc 0.5763 0.6550
epoch 200 LossPred 0.8750 LossAtt 0.2698 TrainAcc 0.7000 TestAcc 0.6054 0.7050
epoch 300 LossPred 0.4769 LossAtt 0.3182 TrainAcc 0.8900 TestAcc 0.8526 0.8850
epoch 400 LossPred 0.3311 LossAtt 0.2880 TrainAcc 0.9100 TestAcc 0.8729 0.9000
epoch 500 LossPred 0.2893 LossAtt 0.2935 TrainAcc 0.9100 TestAcc 0.8796 0.9050
epoch 600 LossPred 0.2760 LossAtt 0.2921 TrainAcc 0.9100 TestAcc 0.8779 0.9200
epoch 700 LossPred 0.3450 LossAtt 0.2772 TrainAcc 0.8900 TestAcc 0.8531 0.9000
epoch 800 LossPred 0.2690 LossAtt 0.2743 TrainAcc 0.9100 TestAcc 0.8736 0.9250
epoch 900 LossPred 0.2477 LossAtt 0.2598 TrainAcc 0.9300 TestAcc 0.8756 0.9350
epoch 1000 LossPred 0.2486 LossAtt 0.2487 TrainAcc 0.9300 TestAcc 0.8794 0.9250
epoch 1100 LossPred 0.2226 LossAtt 0.2415 TrainAcc 0.9500 TestAcc 0.8801 0.9200
epoch 1200 LossPred 0.2165 LossAtt 0.2471 TrainAcc 0.9400 TestAcc 0.8839 0.9350
epoch 1300 LossPred 0.2207 LossAtt 0.2511 TrainAcc 0.9200 TestAcc 0.8854 0.9250
epoch 1400 LossPred 0.1770 LossAtt 0.2373 TrainAcc 0.9500 TestAcc 0.8871 0.9500
epoch 1500 LossPred 0.2460 LossAtt 0.2375 TrainAcc 0.9100 TestAcc 0.8491 0.9000
epoch 1600 LossPred 0.1587 LossAtt 0.2390 TrainAcc 0.9700 TestAcc 0.8834 0.9600
epoch 1700 LossPred 0.1288 LossAtt 0.2330 TrainAcc 0.9700 TestAcc 0.8761 0.9650
epoch 1800 LossPred 0.1331 LossAtt 0.2354 TrainAcc 0.9700 TestAcc 0.8746 0.9700
epoch 1900 LossPred 0.1248 LossAtt 0.2412 TrainAcc 0.9700 TestAcc 0.8789 0.9700
epoch 2000 LossPred 0.1450 LossAtt 0.2306 TrainAcc 0.9600 TestAcc 0.8819 0.9600
epoch 2100 LossPred 0.1272 LossAtt 0.2299 TrainAcc 0.9800 TestAcc 0.8809 0.9800
epoch 2200 LossPred 0.1897 LossAtt 0.2389 TrainAcc 0.9400 TestAcc 0.8579 0.9350
epoch 2300 LossPred 0.1313 LossAtt 0.2275 TrainAcc 0.9700 TestAcc 0.8801 0.9700
epoch 2400 LossPred 0.1254 LossAtt 0.2348 TrainAcc 0.9800 TestAcc 0.8761 0.9750
epoch 2500 LossPred 0.1391 LossAtt 0.2295 TrainAcc 0.9700 TestAcc 0.8791 0.9700
Optimization Finished!
********** replication  80  **********
epoch   0 LossPred 1.1050 LossAtt 1.0132 TrainAcc 0.4700 TestAcc 0.4527 0.5050
epoch 100 LossPred 0.9217 LossAtt 0.2225 TrainAcc 0.6100 TestAcc 0.6024 0.6100
epoch 200 LossPred 0.5374 LossAtt 0.2628 TrainAcc 0.8900 TestAcc 0.8821 0.8900
epoch 300 LossPred 0.4512 LossAtt 0.2006 TrainAcc 0.8500 TestAcc 0.8296 0.8500
epoch 400 LossPred 0.3082 LossAtt 0.1877 TrainAcc 0.9200 TestAcc 0.8694 0.9150
epoch 500 LossPred 0.3597 LossAtt 0.1800 TrainAcc 0.8900 TestAcc 0.8536 0.8800
epoch 600 LossPred 0.2878 LossAtt 0.1507 TrainAcc 0.9100 TestAcc 0.8751 0.9150
epoch 700 LossPred 0.2852 LossAtt 0.1492 TrainAcc 0.8800 TestAcc 0.8689 0.9000
epoch 800 LossPred 0.6083 LossAtt 0.1568 TrainAcc 0.7700 TestAcc 0.8006 0.7800
epoch 900 LossPred 0.3065 LossAtt 0.1887 TrainAcc 0.9100 TestAcc 0.8661 0.8950
epoch 1000 LossPred 0.3202 LossAtt 0.1712 TrainAcc 0.9100 TestAcc 0.8814 0.9050
epoch 1100 LossPred 0.4553 LossAtt 0.1713 TrainAcc 0.8800 TestAcc 0.8416 0.8450
epoch 1200 LossPred 1.1943 LossAtt 0.1736 TrainAcc 0.6100 TestAcc 0.6044 0.6100
epoch 1300 LossPred 0.9349 LossAtt 0.1589 TrainAcc 0.6100 TestAcc 0.6106 0.6050
epoch 1400 LossPred 0.9321 LossAtt 0.1344 TrainAcc 0.6100 TestAcc 0.6176 0.6100
epoch 1500 LossPred 0.9304 LossAtt 0.1301 TrainAcc 0.6100 TestAcc 0.6211 0.6100
epoch 1600 LossPred 0.9290 LossAtt 0.1321 TrainAcc 0.6100 TestAcc 0.6196 0.6100
epoch 1700 LossPred 0.9241 LossAtt 0.1307 TrainAcc 0.6100 TestAcc 0.6226 0.6100
epoch 1800 LossPred 0.9136 LossAtt 0.1354 TrainAcc 0.6300 TestAcc 0.6529 0.6250
epoch 1900 LossPred 0.5672 LossAtt 0.1511 TrainAcc 0.8200 TestAcc 0.8291 0.8300
epoch 2000 LossPred 1.1024 LossAtt 0.1660 TrainAcc 0.6100 TestAcc 0.6024 0.6100
epoch 2100 LossPred 0.9242 LossAtt 0.1413 TrainAcc 0.6100 TestAcc 0.6024 0.6050
epoch 2200 LossPred 0.9224 LossAtt 0.1366 TrainAcc 0.6100 TestAcc 0.6031 0.6100
epoch 2300 LossPred 0.9212 LossAtt 0.1360 TrainAcc 0.6100 TestAcc 0.6024 0.6150
epoch 2400 LossPred 0.9195 LossAtt 0.1355 TrainAcc 0.6200 TestAcc 0.5993 0.6150
epoch 2500 LossPred 0.9192 LossAtt 0.1344 TrainAcc 0.6100 TestAcc 0.6059 0.6200
Optimization Finished!
********** replication  81  **********
epoch   0 LossPred 1.1087 LossAtt 1.0263 TrainAcc 0.3700 TestAcc 0.4014 0.3750
epoch 100 LossPred 0.9057 LossAtt 0.2582 TrainAcc 0.6300 TestAcc 0.5986 0.6300
epoch 200 LossPred 0.9048 LossAtt 0.1839 TrainAcc 0.6300 TestAcc 0.5986 0.6300
epoch 300 LossPred 0.9031 LossAtt 0.1583 TrainAcc 0.6300 TestAcc 0.5986 0.6300
epoch 400 LossPred 0.9048 LossAtt 0.1666 TrainAcc 0.6300 TestAcc 0.5986 0.6300
epoch 500 LossPred 0.9054 LossAtt 0.1256 TrainAcc 0.6300 TestAcc 0.5986 0.6300
epoch 600 LossPred 0.8938 LossAtt 0.1865 TrainAcc 0.6300 TestAcc 0.5986 0.6300
epoch 700 LossPred 0.3928 LossAtt 0.1743 TrainAcc 0.8500 TestAcc 0.8171 0.8500
epoch 800 LossPred 0.3850 LossAtt 0.1720 TrainAcc 0.8500 TestAcc 0.8388 0.8600
epoch 900 LossPred 0.3627 LossAtt 0.1683 TrainAcc 0.8800 TestAcc 0.8456 0.8500
epoch 1000 LossPred 0.4251 LossAtt 0.1562 TrainAcc 0.8300 TestAcc 0.8243 0.8350
epoch 1100 LossPred 0.3404 LossAtt 0.1587 TrainAcc 0.8600 TestAcc 0.8263 0.8550
epoch 1200 LossPred 0.3901 LossAtt 0.1588 TrainAcc 0.8700 TestAcc 0.8186 0.8400
epoch 1300 LossPred 0.3556 LossAtt 0.1609 TrainAcc 0.8800 TestAcc 0.8361 0.8500
epoch 1400 LossPred 0.3476 LossAtt 0.1436 TrainAcc 0.8700 TestAcc 0.8221 0.8650
epoch 1500 LossPred 0.3489 LossAtt 0.1618 TrainAcc 0.8700 TestAcc 0.8413 0.8650
epoch 1600 LossPred 0.3349 LossAtt 0.1472 TrainAcc 0.8800 TestAcc 0.8278 0.8550
epoch 1700 LossPred 0.3241 LossAtt 0.1502 TrainAcc 0.8900 TestAcc 0.8143 0.8600
epoch 1800 LossPred 0.3257 LossAtt 0.1466 TrainAcc 0.8800 TestAcc 0.8141 0.8950
epoch 1900 LossPred 0.3527 LossAtt 0.1464 TrainAcc 0.8700 TestAcc 0.8383 0.8700
epoch 2000 LossPred 0.3513 LossAtt 0.1457 TrainAcc 0.8700 TestAcc 0.8338 0.8750
epoch 2100 LossPred 0.3411 LossAtt 0.1370 TrainAcc 0.8800 TestAcc 0.8316 0.8650
epoch 2200 LossPred 0.4104 LossAtt 0.1357 TrainAcc 0.8700 TestAcc 0.8098 0.8650
epoch 2300 LossPred 0.3616 LossAtt 0.1379 TrainAcc 0.8600 TestAcc 0.8321 0.8650
epoch 2400 LossPred 0.3466 LossAtt 0.1421 TrainAcc 0.8700 TestAcc 0.8306 0.8650
epoch 2500 LossPred 0.3695 LossAtt 0.1391 TrainAcc 0.8600 TestAcc 0.8306 0.8550
Optimization Finished!
********** replication  82  **********
epoch   0 LossPred 1.0437 LossAtt 1.0201 TrainAcc 0.5000 TestAcc 0.5160 0.4950
epoch 100 LossPred 0.7804 LossAtt 0.2862 TrainAcc 0.6900 TestAcc 0.5891 0.6900
epoch 200 LossPred 0.3788 LossAtt 0.2776 TrainAcc 0.8600 TestAcc 0.8151 0.8350
epoch 300 LossPred 0.3876 LossAtt 0.2621 TrainAcc 0.8600 TestAcc 0.8586 0.8600
epoch 400 LossPred 0.3599 LossAtt 0.2379 TrainAcc 0.8800 TestAcc 0.8536 0.8650
epoch 500 LossPred 0.7734 LossAtt 0.2498 TrainAcc 0.7600 TestAcc 0.7217 0.7500
epoch 600 LossPred 0.3393 LossAtt 0.2305 TrainAcc 0.8600 TestAcc 0.8403 0.8550
epoch 700 LossPred 0.7068 LossAtt 0.2236 TrainAcc 0.7600 TestAcc 0.7272 0.7550
epoch 800 LossPred 0.3537 LossAtt 0.2179 TrainAcc 0.8800 TestAcc 0.8669 0.8650
epoch 900 LossPred 0.3456 LossAtt 0.2045 TrainAcc 0.8700 TestAcc 0.8481 0.8850
epoch 1000 LossPred 0.2934 LossAtt 0.2149 TrainAcc 0.8900 TestAcc 0.8624 0.8850
epoch 1100 LossPred 0.2625 LossAtt 0.1993 TrainAcc 0.9100 TestAcc 0.8629 0.8950
epoch 1200 LossPred 0.2823 LossAtt 0.1998 TrainAcc 0.9000 TestAcc 0.8574 0.8700
epoch 1300 LossPred 0.3243 LossAtt 0.2079 TrainAcc 0.8800 TestAcc 0.8473 0.8600
epoch 1400 LossPred 0.4691 LossAtt 0.2129 TrainAcc 0.8400 TestAcc 0.8121 0.8400
epoch 1500 LossPred 0.1711 LossAtt 0.2000 TrainAcc 0.9500 TestAcc 0.8519 0.9000
epoch 1600 LossPred 0.3622 LossAtt 0.1945 TrainAcc 0.8800 TestAcc 0.8256 0.8600
epoch 1700 LossPred 0.3719 LossAtt 0.2024 TrainAcc 0.8800 TestAcc 0.8318 0.8750
epoch 1800 LossPred 0.2890 LossAtt 0.1959 TrainAcc 0.8900 TestAcc 0.8436 0.8600
epoch 1900 LossPred 0.1579 LossAtt 0.2132 TrainAcc 0.9400 TestAcc 0.8586 0.8950
epoch 2000 LossPred 0.1780 LossAtt 0.2035 TrainAcc 0.9400 TestAcc 0.8546 0.9100
epoch 2100 LossPred 0.1361 LossAtt 0.2061 TrainAcc 0.9500 TestAcc 0.8551 0.9200
epoch 2200 LossPred 0.1478 LossAtt 0.2128 TrainAcc 0.9400 TestAcc 0.8539 0.9400
epoch 2300 LossPred 0.1151 LossAtt 0.2017 TrainAcc 0.9600 TestAcc 0.8511 0.9350
epoch 2400 LossPred 0.1147 LossAtt 0.2108 TrainAcc 0.9700 TestAcc 0.8604 0.9450
epoch 2500 LossPred 0.1483 LossAtt 0.1981 TrainAcc 0.9500 TestAcc 0.8614 0.9150
Optimization Finished!
********** replication  83  **********
epoch   0 LossPred 1.0530 LossAtt 1.0200 TrainAcc 0.4300 TestAcc 0.4812 0.4200
epoch 100 LossPred 0.8303 LossAtt 0.2763 TrainAcc 0.6900 TestAcc 0.6309 0.7000
epoch 200 LossPred 0.8116 LossAtt 0.2536 TrainAcc 0.7100 TestAcc 0.5993 0.7150
epoch 300 LossPred 0.8075 LossAtt 0.2195 TrainAcc 0.7100 TestAcc 0.5961 0.7200
epoch 400 LossPred 0.8038 LossAtt 0.2116 TrainAcc 0.7100 TestAcc 0.5886 0.7250
epoch 500 LossPred 0.7902 LossAtt 0.2311 TrainAcc 0.7100 TestAcc 0.5761 0.7150
epoch 600 LossPred 0.7654 LossAtt 0.2414 TrainAcc 0.7200 TestAcc 0.5738 0.7300
epoch 700 LossPred 0.7368 LossAtt 0.2366 TrainAcc 0.7300 TestAcc 0.5863 0.7400
epoch 800 LossPred 0.6623 LossAtt 0.2670 TrainAcc 0.7500 TestAcc 0.5918 0.7350
epoch 900 LossPred 0.5905 LossAtt 0.3281 TrainAcc 0.7700 TestAcc 0.5716 0.7350
epoch 1000 LossPred 0.4643 LossAtt 0.3967 TrainAcc 0.8400 TestAcc 0.6339 0.8050
epoch 1100 LossPred 0.3964 LossAtt 0.4361 TrainAcc 0.8600 TestAcc 0.6737 0.8750
epoch 1200 LossPred 0.1801 LossAtt 0.4266 TrainAcc 0.9500 TestAcc 0.7455 0.9050
epoch 1300 LossPred 0.1283 LossAtt 0.4053 TrainAcc 0.9700 TestAcc 0.7543 0.9200
epoch 1400 LossPred 0.1088 LossAtt 0.4333 TrainAcc 0.9800 TestAcc 0.7543 0.9300
epoch 1500 LossPred 0.1010 LossAtt 0.4108 TrainAcc 0.9800 TestAcc 0.7568 0.9100
epoch 1600 LossPred 0.0883 LossAtt 0.4226 TrainAcc 0.9900 TestAcc 0.7538 0.9100
epoch 1700 LossPred 0.0762 LossAtt 0.3949 TrainAcc 0.9900 TestAcc 0.7638 0.9200
epoch 1800 LossPred 0.1252 LossAtt 0.3982 TrainAcc 0.9700 TestAcc 0.7620 0.8750
epoch 1900 LossPred 0.0819 LossAtt 0.3908 TrainAcc 0.9900 TestAcc 0.7750 0.9200
epoch 2000 LossPred 0.2533 LossAtt 0.4038 TrainAcc 0.9300 TestAcc 0.7673 0.8900
epoch 2100 LossPred 0.0751 LossAtt 0.3926 TrainAcc 0.9900 TestAcc 0.7763 0.9100
epoch 2200 LossPred 0.0685 LossAtt 0.3868 TrainAcc 0.9900 TestAcc 0.7690 0.9100
epoch 2300 LossPred 0.0700 LossAtt 0.3957 TrainAcc 0.9900 TestAcc 0.7700 0.9100
epoch 2400 LossPred 0.1043 LossAtt 0.3762 TrainAcc 0.9800 TestAcc 0.7738 0.9250
epoch 2500 LossPred 0.0818 LossAtt 0.3652 TrainAcc 0.9800 TestAcc 0.7580 0.9150
Optimization Finished!
********** replication  84  **********
epoch   0 LossPred 1.1020 LossAtt 1.0160 TrainAcc 0.5000 TestAcc 0.5070 0.5200
epoch 100 LossPred 0.8837 LossAtt 0.2718 TrainAcc 0.6800 TestAcc 0.6359 0.6800
epoch 200 LossPred 0.8247 LossAtt 0.2394 TrainAcc 0.7100 TestAcc 0.6466 0.7000
epoch 300 LossPred 0.4225 LossAtt 0.2895 TrainAcc 0.8600 TestAcc 0.8761 0.8450
epoch 400 LossPred 0.4135 LossAtt 0.2699 TrainAcc 0.8500 TestAcc 0.8046 0.8400
epoch 500 LossPred 0.2758 LossAtt 0.2605 TrainAcc 0.9000 TestAcc 0.8574 0.8850
epoch 600 LossPred 0.2801 LossAtt 0.2606 TrainAcc 0.9300 TestAcc 0.8966 0.8700
epoch 700 LossPred 0.2224 LossAtt 0.2484 TrainAcc 0.9300 TestAcc 0.9099 0.8850
epoch 800 LossPred 0.2039 LossAtt 0.2410 TrainAcc 0.9000 TestAcc 0.8934 0.8900
epoch 900 LossPred 0.1966 LossAtt 0.2475 TrainAcc 0.9200 TestAcc 0.8914 0.8900
epoch 1000 LossPred 0.1709 LossAtt 0.2333 TrainAcc 0.9300 TestAcc 0.9149 0.9050
epoch 1100 LossPred 0.1692 LossAtt 0.2371 TrainAcc 0.9400 TestAcc 0.9119 0.9000
epoch 1200 LossPred 0.1966 LossAtt 0.2305 TrainAcc 0.9400 TestAcc 0.9272 0.9050
epoch 1300 LossPred 0.2115 LossAtt 0.2377 TrainAcc 0.9400 TestAcc 0.8874 0.8700
epoch 1400 LossPred 0.1590 LossAtt 0.2394 TrainAcc 0.9500 TestAcc 0.9252 0.9150
epoch 1500 LossPred 0.1877 LossAtt 0.2393 TrainAcc 0.9400 TestAcc 0.9024 0.8950
epoch 1600 LossPred 0.1447 LossAtt 0.2251 TrainAcc 0.9700 TestAcc 0.9147 0.8950
epoch 1700 LossPred 0.3547 LossAtt 0.2352 TrainAcc 0.8600 TestAcc 0.8579 0.8400
epoch 1800 LossPred 0.2083 LossAtt 0.2287 TrainAcc 0.9100 TestAcc 0.8964 0.8800
epoch 1900 LossPred 0.1221 LossAtt 0.2344 TrainAcc 0.9700 TestAcc 0.9269 0.8950
epoch 2000 LossPred 0.1056 LossAtt 0.2226 TrainAcc 0.9700 TestAcc 0.9422 0.9250
epoch 2100 LossPred 0.1236 LossAtt 0.2244 TrainAcc 0.9700 TestAcc 0.9427 0.9300
epoch 2200 LossPred 0.1125 LossAtt 0.2165 TrainAcc 0.9700 TestAcc 0.9319 0.9100
epoch 2300 LossPred 0.0988 LossAtt 0.2144 TrainAcc 0.9700 TestAcc 0.9422 0.9250
epoch 2400 LossPred 0.0958 LossAtt 0.2107 TrainAcc 0.9700 TestAcc 0.9412 0.9100
epoch 2500 LossPred 0.0996 LossAtt 0.2053 TrainAcc 0.9700 TestAcc 0.9367 0.9100
Optimization Finished!
********** replication  85  **********
epoch   0 LossPred 1.0252 LossAtt 0.9998 TrainAcc 0.4900 TestAcc 0.5430 0.5200
epoch 100 LossPred 0.9301 LossAtt 0.2921 TrainAcc 0.6400 TestAcc 0.6494 0.6500
epoch 200 LossPred 0.5929 LossAtt 0.3062 TrainAcc 0.8000 TestAcc 0.8263 0.7450
epoch 300 LossPred 0.3797 LossAtt 0.2805 TrainAcc 0.8500 TestAcc 0.9037 0.8650
epoch 400 LossPred 0.3491 LossAtt 0.2785 TrainAcc 0.8900 TestAcc 0.8674 0.8900
epoch 500 LossPred 0.4379 LossAtt 0.2665 TrainAcc 0.8700 TestAcc 0.8001 0.8200
epoch 600 LossPred 0.4309 LossAtt 0.2531 TrainAcc 0.8600 TestAcc 0.8236 0.8400
epoch 700 LossPred 0.2568 LossAtt 0.2370 TrainAcc 0.9200 TestAcc 0.8919 0.8900
epoch 800 LossPred 0.2161 LossAtt 0.2435 TrainAcc 0.9400 TestAcc 0.8834 0.9100
epoch 900 LossPred 0.2369 LossAtt 0.2281 TrainAcc 0.9300 TestAcc 0.8724 0.9150
epoch 1000 LossPred 0.2370 LossAtt 0.1964 TrainAcc 0.9200 TestAcc 0.8699 0.9000
epoch 1100 LossPred 0.2950 LossAtt 0.1596 TrainAcc 0.8800 TestAcc 0.8724 0.8750
epoch 1200 LossPred 0.3976 LossAtt 0.1550 TrainAcc 0.8600 TestAcc 0.7933 0.8550
epoch 1300 LossPred 0.4213 LossAtt 0.1458 TrainAcc 0.8700 TestAcc 0.7930 0.8850
epoch 1400 LossPred 0.3214 LossAtt 0.1469 TrainAcc 0.9000 TestAcc 0.8253 0.9050
epoch 1500 LossPred 0.2250 LossAtt 0.1661 TrainAcc 0.9200 TestAcc 0.8483 0.9350
epoch 1600 LossPred 0.2224 LossAtt 0.1923 TrainAcc 0.9300 TestAcc 0.8381 0.9350
epoch 1700 LossPred 0.4393 LossAtt 0.2031 TrainAcc 0.8700 TestAcc 0.8584 0.8550
epoch 1800 LossPred 0.3564 LossAtt 0.1958 TrainAcc 0.8900 TestAcc 0.8168 0.8900
epoch 1900 LossPred 0.3627 LossAtt 0.2041 TrainAcc 0.9000 TestAcc 0.8661 0.8900
epoch 2000 LossPred 0.3215 LossAtt 0.1961 TrainAcc 0.9000 TestAcc 0.8206 0.9050
epoch 2100 LossPred 0.2677 LossAtt 0.2006 TrainAcc 0.9100 TestAcc 0.8584 0.9300
epoch 2200 LossPred 0.1549 LossAtt 0.1835 TrainAcc 0.9500 TestAcc 0.8699 0.9400
epoch 2300 LossPred 0.3324 LossAtt 0.1856 TrainAcc 0.9000 TestAcc 0.8226 0.9000
epoch 2400 LossPred 0.1894 LossAtt 0.1891 TrainAcc 0.9500 TestAcc 0.8619 0.9250
epoch 2500 LossPred 0.1761 LossAtt 0.1796 TrainAcc 0.9500 TestAcc 0.8586 0.9400
Optimization Finished!
********** replication  86  **********
epoch   0 LossPred 1.0082 LossAtt 1.0059 TrainAcc 0.5100 TestAcc 0.5253 0.4950
epoch 100 LossPred 0.7997 LossAtt 0.2964 TrainAcc 0.6700 TestAcc 0.5340 0.6850
epoch 200 LossPred 0.4092 LossAtt 0.3306 TrainAcc 0.8800 TestAcc 0.8231 0.8700
epoch 300 LossPred 0.3042 LossAtt 0.3398 TrainAcc 0.8900 TestAcc 0.8316 0.8650
epoch 400 LossPred 0.3006 LossAtt 0.3367 TrainAcc 0.8900 TestAcc 0.8188 0.8750
epoch 500 LossPred 0.2298 LossAtt 0.3329 TrainAcc 0.9400 TestAcc 0.8601 0.9000
epoch 600 LossPred 0.4484 LossAtt 0.3265 TrainAcc 0.8300 TestAcc 0.7840 0.8500
epoch 700 LossPred 0.5921 LossAtt 0.3149 TrainAcc 0.8000 TestAcc 0.7698 0.8250
epoch 800 LossPred 0.4449 LossAtt 0.3190 TrainAcc 0.8400 TestAcc 0.7800 0.8700
epoch 900 LossPred 0.3369 LossAtt 0.3052 TrainAcc 0.9000 TestAcc 0.8341 0.8800
epoch 1000 LossPred 0.2638 LossAtt 0.2969 TrainAcc 0.9200 TestAcc 0.8764 0.9050
epoch 1100 LossPred 0.2743 LossAtt 0.2964 TrainAcc 0.9000 TestAcc 0.8554 0.9000
epoch 1200 LossPred 0.1962 LossAtt 0.2847 TrainAcc 0.9400 TestAcc 0.8839 0.9200
epoch 1300 LossPred 0.1945 LossAtt 0.2810 TrainAcc 0.9300 TestAcc 0.8794 0.9100
epoch 1400 LossPred 0.2268 LossAtt 0.2723 TrainAcc 0.9200 TestAcc 0.8561 0.9100
epoch 1500 LossPred 0.1650 LossAtt 0.2655 TrainAcc 0.9500 TestAcc 0.8759 0.9400
epoch 1600 LossPred 0.1666 LossAtt 0.2758 TrainAcc 0.9400 TestAcc 0.8764 0.9350
epoch 1700 LossPred 0.1371 LossAtt 0.2846 TrainAcc 0.9700 TestAcc 0.8794 0.9650
epoch 1800 LossPred 0.1372 LossAtt 0.2877 TrainAcc 0.9500 TestAcc 0.8729 0.9600
epoch 1900 LossPred 0.1658 LossAtt 0.2978 TrainAcc 0.9200 TestAcc 0.8634 0.9200
epoch 2000 LossPred 0.1135 LossAtt 0.2712 TrainAcc 0.9600 TestAcc 0.8701 0.9450
epoch 2100 LossPred 0.1235 LossAtt 0.2821 TrainAcc 0.9500 TestAcc 0.8661 0.9400
epoch 2200 LossPred 0.1193 LossAtt 0.2789 TrainAcc 0.9600 TestAcc 0.8674 0.9600
epoch 2300 LossPred 0.1130 LossAtt 0.2785 TrainAcc 0.9600 TestAcc 0.8679 0.9550
epoch 2400 LossPred 0.1099 LossAtt 0.2717 TrainAcc 0.9700 TestAcc 0.8656 0.9550
epoch 2500 LossPred 0.1005 LossAtt 0.2851 TrainAcc 0.9700 TestAcc 0.8734 0.9650
Optimization Finished!
********** replication  87  **********
epoch   0 LossPred 1.0987 LossAtt 1.0237 TrainAcc 0.5400 TestAcc 0.5513 0.5450
epoch 100 LossPred 0.8651 LossAtt 0.3124 TrainAcc 0.6800 TestAcc 0.5983 0.6900
epoch 200 LossPred 0.4211 LossAtt 0.3063 TrainAcc 0.8500 TestAcc 0.8171 0.8200
epoch 300 LossPred 0.3157 LossAtt 0.2724 TrainAcc 0.9000 TestAcc 0.8576 0.8650
epoch 400 LossPred 0.2845 LossAtt 0.2634 TrainAcc 0.9000 TestAcc 0.8549 0.8650
epoch 500 LossPred 0.2705 LossAtt 0.2650 TrainAcc 0.9000 TestAcc 0.8549 0.8700
epoch 600 LossPred 0.2489 LossAtt 0.2722 TrainAcc 0.9200 TestAcc 0.8729 0.8850
epoch 700 LossPred 0.3610 LossAtt 0.2809 TrainAcc 0.8800 TestAcc 0.8368 0.8600
epoch 800 LossPred 0.2538 LossAtt 0.2713 TrainAcc 0.9300 TestAcc 0.8744 0.9050
epoch 900 LossPred 0.2035 LossAtt 0.2780 TrainAcc 0.9300 TestAcc 0.8686 0.9000
epoch 1000 LossPred 0.2472 LossAtt 0.2702 TrainAcc 0.9200 TestAcc 0.8619 0.8750
epoch 1100 LossPred 0.2861 LossAtt 0.2654 TrainAcc 0.9000 TestAcc 0.7993 0.8700
epoch 1200 LossPred 0.2107 LossAtt 0.2462 TrainAcc 0.9300 TestAcc 0.8103 0.8850
epoch 1300 LossPred 0.1769 LossAtt 0.2421 TrainAcc 0.9400 TestAcc 0.8243 0.8950
epoch 1400 LossPred 0.2014 LossAtt 0.2280 TrainAcc 0.9200 TestAcc 0.8308 0.8900
epoch 1500 LossPred 0.1831 LossAtt 0.2296 TrainAcc 0.9200 TestAcc 0.8448 0.9000
epoch 1600 LossPred 0.3451 LossAtt 0.2283 TrainAcc 0.8900 TestAcc 0.7858 0.8550
epoch 1700 LossPred 0.1737 LossAtt 0.2181 TrainAcc 0.9400 TestAcc 0.8206 0.8950
epoch 1800 LossPred 0.1721 LossAtt 0.2134 TrainAcc 0.9400 TestAcc 0.8318 0.8950
epoch 1900 LossPred 0.2087 LossAtt 0.2161 TrainAcc 0.9100 TestAcc 0.8098 0.8800
epoch 2000 LossPred 0.1817 LossAtt 0.2039 TrainAcc 0.9400 TestAcc 0.8251 0.9050
epoch 2100 LossPred 0.2093 LossAtt 0.2107 TrainAcc 0.9200 TestAcc 0.8443 0.9100
epoch 2200 LossPred 0.1878 LossAtt 0.2048 TrainAcc 0.9200 TestAcc 0.8391 0.9150
epoch 2300 LossPred 0.2046 LossAtt 0.1943 TrainAcc 0.9200 TestAcc 0.8406 0.9100
epoch 2400 LossPred 0.2384 LossAtt 0.1975 TrainAcc 0.9100 TestAcc 0.8103 0.8750
epoch 2500 LossPred 0.2268 LossAtt 0.2016 TrainAcc 0.9100 TestAcc 0.8486 0.9050
Optimization Finished!
********** replication  88  **********
epoch   0 LossPred 1.0099 LossAtt 0.9945 TrainAcc 0.5100 TestAcc 0.4394 0.4850
epoch 100 LossPred 0.8557 LossAtt 0.3096 TrainAcc 0.6700 TestAcc 0.6399 0.6400
epoch 200 LossPred 0.3662 LossAtt 0.3113 TrainAcc 0.9000 TestAcc 0.8806 0.8650
epoch 300 LossPred 0.2794 LossAtt 0.3053 TrainAcc 0.9000 TestAcc 0.8851 0.8850
epoch 400 LossPred 0.2782 LossAtt 0.2978 TrainAcc 0.8900 TestAcc 0.8979 0.8850
epoch 500 LossPred 0.3698 LossAtt 0.2916 TrainAcc 0.8500 TestAcc 0.8378 0.8300
epoch 600 LossPred 0.2033 LossAtt 0.2974 TrainAcc 0.9200 TestAcc 0.9049 0.9100
epoch 700 LossPred 0.4582 LossAtt 0.2983 TrainAcc 0.8100 TestAcc 0.8128 0.8000
epoch 800 LossPred 0.3966 LossAtt 0.2893 TrainAcc 0.8400 TestAcc 0.8483 0.8550
epoch 900 LossPred 0.2555 LossAtt 0.2890 TrainAcc 0.9000 TestAcc 0.8981 0.8900
epoch 1000 LossPred 0.4178 LossAtt 0.2806 TrainAcc 0.8200 TestAcc 0.8123 0.8250
epoch 1100 LossPred 0.5782 LossAtt 0.2831 TrainAcc 0.8400 TestAcc 0.8191 0.8150
epoch 1200 LossPred 0.3679 LossAtt 0.2734 TrainAcc 0.9000 TestAcc 0.8566 0.8950
epoch 1300 LossPred 0.4196 LossAtt 0.2852 TrainAcc 0.8400 TestAcc 0.8401 0.8150
epoch 1400 LossPred 0.6563 LossAtt 0.2634 TrainAcc 0.7700 TestAcc 0.7755 0.7850
epoch 1500 LossPred 0.4143 LossAtt 0.2613 TrainAcc 0.8700 TestAcc 0.8498 0.8700
epoch 1600 LossPred 0.3416 LossAtt 0.2605 TrainAcc 0.9300 TestAcc 0.8816 0.9100
epoch 1700 LossPred 0.3503 LossAtt 0.2635 TrainAcc 0.9100 TestAcc 0.8684 0.9050
epoch 1800 LossPred 0.4296 LossAtt 0.2522 TrainAcc 0.8700 TestAcc 0.8423 0.8750
epoch 1900 LossPred 0.2820 LossAtt 0.2419 TrainAcc 0.9200 TestAcc 0.9002 0.9050
epoch 2000 LossPred 0.2810 LossAtt 0.2425 TrainAcc 0.8800 TestAcc 0.8689 0.8700
epoch 2100 LossPred 0.3363 LossAtt 0.2473 TrainAcc 0.8600 TestAcc 0.8428 0.8600
epoch 2200 LossPred 0.2124 LossAtt 0.2433 TrainAcc 0.9100 TestAcc 0.9134 0.9200
epoch 2300 LossPred 0.3062 LossAtt 0.2396 TrainAcc 0.9000 TestAcc 0.8889 0.9000
epoch 2400 LossPred 0.2661 LossAtt 0.2290 TrainAcc 0.9100 TestAcc 0.8989 0.9100
epoch 2500 LossPred 0.2548 LossAtt 0.2405 TrainAcc 0.9300 TestAcc 0.8789 0.9250
Optimization Finished!
********** replication  89  **********
epoch   0 LossPred 1.0276 LossAtt 1.0033 TrainAcc 0.4400 TestAcc 0.4259 0.4450
epoch 100 LossPred 0.8709 LossAtt 0.2812 TrainAcc 0.6400 TestAcc 0.5918 0.6400
epoch 200 LossPred 0.7563 LossAtt 0.2544 TrainAcc 0.7200 TestAcc 0.6099 0.7050
epoch 300 LossPred 0.3092 LossAtt 0.2290 TrainAcc 0.8900 TestAcc 0.8859 0.8700
epoch 400 LossPred 0.6871 LossAtt 0.2388 TrainAcc 0.7600 TestAcc 0.7360 0.7400
epoch 500 LossPred 0.3818 LossAtt 0.1917 TrainAcc 0.8800 TestAcc 0.8516 0.8550
epoch 600 LossPred 0.2773 LossAtt 0.2074 TrainAcc 0.9000 TestAcc 0.8904 0.8850
epoch 700 LossPred 0.3304 LossAtt 0.2030 TrainAcc 0.9000 TestAcc 0.8624 0.8800
epoch 800 LossPred 0.2532 LossAtt 0.2217 TrainAcc 0.9300 TestAcc 0.8936 0.9050
epoch 900 LossPred 0.4172 LossAtt 0.2132 TrainAcc 0.8400 TestAcc 0.8486 0.8400
epoch 1000 LossPred 0.4999 LossAtt 0.1883 TrainAcc 0.8500 TestAcc 0.7883 0.8100
epoch 1100 LossPred 0.3244 LossAtt 0.1831 TrainAcc 0.8800 TestAcc 0.8781 0.8800
epoch 1200 LossPred 0.3327 LossAtt 0.1736 TrainAcc 0.9100 TestAcc 0.8696 0.9100
epoch 1300 LossPred 0.3277 LossAtt 0.1716 TrainAcc 0.9100 TestAcc 0.8709 0.9150
epoch 1400 LossPred 0.3644 LossAtt 0.1970 TrainAcc 0.9000 TestAcc 0.8631 0.8850
epoch 1500 LossPred 0.3724 LossAtt 0.2114 TrainAcc 0.8900 TestAcc 0.8634 0.8800
epoch 1600 LossPred 1.1951 LossAtt 0.2381 TrainAcc 0.6500 TestAcc 0.6817 0.6400
epoch 1700 LossPred 0.3540 LossAtt 0.2203 TrainAcc 0.8500 TestAcc 0.8478 0.8550
epoch 1800 LossPred 0.4621 LossAtt 0.2208 TrainAcc 0.8400 TestAcc 0.7925 0.8450
epoch 1900 LossPred 0.3670 LossAtt 0.2300 TrainAcc 0.8600 TestAcc 0.8198 0.8700
epoch 2000 LossPred 0.2668 LossAtt 0.2253 TrainAcc 0.8900 TestAcc 0.8461 0.9000
epoch 2100 LossPred 0.2689 LossAtt 0.2110 TrainAcc 0.9300 TestAcc 0.8581 0.9300
epoch 2200 LossPred 0.2271 LossAtt 0.2090 TrainAcc 0.9200 TestAcc 0.8721 0.9250
epoch 2300 LossPred 0.1820 LossAtt 0.1993 TrainAcc 0.9400 TestAcc 0.8831 0.9400
epoch 2400 LossPred 0.3016 LossAtt 0.2124 TrainAcc 0.9100 TestAcc 0.8541 0.9050
epoch 2500 LossPred 0.2697 LossAtt 0.2176 TrainAcc 0.8700 TestAcc 0.8834 0.8950
Optimization Finished!
********** replication  90  **********
epoch   0 LossPred 1.0602 LossAtt 1.0321 TrainAcc 0.4400 TestAcc 0.4920 0.4400
epoch 100 LossPred 0.8706 LossAtt 0.2965 TrainAcc 0.6500 TestAcc 0.6451 0.6200
epoch 200 LossPred 0.8287 LossAtt 0.2275 TrainAcc 0.6500 TestAcc 0.6451 0.6300
epoch 300 LossPred 0.7324 LossAtt 0.2414 TrainAcc 0.7100 TestAcc 0.6807 0.6700
epoch 400 LossPred 0.3733 LossAtt 0.2612 TrainAcc 0.8500 TestAcc 0.8321 0.8800
epoch 500 LossPred 0.5202 LossAtt 0.2811 TrainAcc 0.8400 TestAcc 0.7675 0.8050
epoch 600 LossPred 0.4327 LossAtt 0.2876 TrainAcc 0.8600 TestAcc 0.8173 0.8550
epoch 700 LossPred 0.2771 LossAtt 0.3128 TrainAcc 0.9200 TestAcc 0.8599 0.9100
epoch 800 LossPred 0.2335 LossAtt 0.3113 TrainAcc 0.9200 TestAcc 0.8554 0.8950
epoch 900 LossPred 0.2009 LossAtt 0.2746 TrainAcc 0.9500 TestAcc 0.8716 0.9400
epoch 1000 LossPred 0.2023 LossAtt 0.2605 TrainAcc 0.9300 TestAcc 0.8851 0.9300
epoch 1100 LossPred 0.2279 LossAtt 0.2427 TrainAcc 0.9500 TestAcc 0.8699 0.9450
epoch 1200 LossPred 0.2983 LossAtt 0.2267 TrainAcc 0.8700 TestAcc 0.8203 0.8750
epoch 1300 LossPred 0.6602 LossAtt 0.2201 TrainAcc 0.7700 TestAcc 0.7400 0.7850
epoch 1400 LossPred 0.2274 LossAtt 0.2143 TrainAcc 0.9400 TestAcc 0.8826 0.9250
epoch 1500 LossPred 0.1898 LossAtt 0.2092 TrainAcc 0.9500 TestAcc 0.8879 0.9350
epoch 1600 LossPred 0.2033 LossAtt 0.1958 TrainAcc 0.9500 TestAcc 0.8804 0.9400
epoch 1700 LossPred 0.3216 LossAtt 0.1884 TrainAcc 0.8900 TestAcc 0.8626 0.8700
epoch 1800 LossPred 0.3678 LossAtt 0.1902 TrainAcc 0.8600 TestAcc 0.8356 0.8400
epoch 1900 LossPred 0.1717 LossAtt 0.1779 TrainAcc 0.9300 TestAcc 0.8849 0.9250
epoch 2000 LossPred 0.2368 LossAtt 0.1744 TrainAcc 0.8900 TestAcc 0.8756 0.9000
epoch 2100 LossPred 0.5136 LossAtt 0.1733 TrainAcc 0.8200 TestAcc 0.8131 0.8400
epoch 2200 LossPred 0.1894 LossAtt 0.1839 TrainAcc 0.9100 TestAcc 0.8741 0.9350
epoch 2300 LossPred 0.2047 LossAtt 0.1852 TrainAcc 0.9300 TestAcc 0.8771 0.9350
epoch 2400 LossPred 0.3083 LossAtt 0.1724 TrainAcc 0.8900 TestAcc 0.8649 0.8950
epoch 2500 LossPred 0.1648 LossAtt 0.1781 TrainAcc 0.9400 TestAcc 0.8861 0.9300
Optimization Finished!
********** replication  91  **********
epoch   0 LossPred 1.0451 LossAtt 1.0335 TrainAcc 0.3800 TestAcc 0.4022 0.4450
epoch 100 LossPred 0.8099 LossAtt 0.2637 TrainAcc 0.7000 TestAcc 0.5913 0.7000
epoch 200 LossPred 0.7806 LossAtt 0.2098 TrainAcc 0.7000 TestAcc 0.5913 0.7000
epoch 300 LossPred 0.7604 LossAtt 0.1657 TrainAcc 0.7200 TestAcc 0.6439 0.7200
epoch 400 LossPred 0.7456 LossAtt 0.2013 TrainAcc 0.7200 TestAcc 0.6439 0.7200
epoch 500 LossPred 0.8429 LossAtt 0.2042 TrainAcc 0.7000 TestAcc 0.5936 0.7050
epoch 600 LossPred 0.4679 LossAtt 0.2155 TrainAcc 0.8600 TestAcc 0.7643 0.8450
epoch 700 LossPred 0.3001 LossAtt 0.2334 TrainAcc 0.9300 TestAcc 0.8626 0.9100
epoch 800 LossPred 0.2147 LossAtt 0.2590 TrainAcc 0.9400 TestAcc 0.8859 0.9300
epoch 900 LossPred 0.1504 LossAtt 0.2596 TrainAcc 0.9600 TestAcc 0.8964 0.9450
epoch 1000 LossPred 0.1322 LossAtt 0.2451 TrainAcc 0.9600 TestAcc 0.8906 0.9450
epoch 1100 LossPred 0.0985 LossAtt 0.2247 TrainAcc 0.9800 TestAcc 0.9104 0.9750
epoch 1200 LossPred 0.1792 LossAtt 0.2139 TrainAcc 0.9400 TestAcc 0.8764 0.9150
epoch 1300 LossPred 0.0760 LossAtt 0.2242 TrainAcc 0.9900 TestAcc 0.9154 0.9750
epoch 1400 LossPred 0.0651 LossAtt 0.2156 TrainAcc 0.9800 TestAcc 0.9069 0.9750
epoch 1500 LossPred 0.0847 LossAtt 0.2173 TrainAcc 0.9700 TestAcc 0.9157 0.9500
epoch 1600 LossPred 0.1254 LossAtt 0.2195 TrainAcc 0.9500 TestAcc 0.8924 0.9450
epoch 1700 LossPred 0.0710 LossAtt 0.2086 TrainAcc 0.9900 TestAcc 0.9112 0.9800
epoch 1800 LossPred 0.0798 LossAtt 0.2152 TrainAcc 0.9800 TestAcc 0.9179 0.9650
epoch 1900 LossPred 0.0882 LossAtt 0.2146 TrainAcc 0.9700 TestAcc 0.8954 0.9700
epoch 2000 LossPred 0.0495 LossAtt 0.2114 TrainAcc 0.9900 TestAcc 0.9217 0.9650
epoch 2100 LossPred 0.0490 LossAtt 0.2152 TrainAcc 0.9900 TestAcc 0.9137 0.9700
epoch 2200 LossPred 0.0598 LossAtt 0.2102 TrainAcc 0.9800 TestAcc 0.9142 0.9600
epoch 2300 LossPred 0.0678 LossAtt 0.2125 TrainAcc 0.9900 TestAcc 0.9242 0.9650
epoch 2400 LossPred 0.0425 LossAtt 0.2057 TrainAcc 0.9900 TestAcc 0.9039 0.9750
epoch 2500 LossPred 0.0838 LossAtt 0.2155 TrainAcc 0.9800 TestAcc 0.9164 0.9650
Optimization Finished!
********** replication  92  **********
epoch   0 LossPred 1.2221 LossAtt 1.0329 TrainAcc 0.5100 TestAcc 0.4737 0.5050
epoch 100 LossPred 0.9542 LossAtt 0.2688 TrainAcc 0.5800 TestAcc 0.5558 0.5850
epoch 200 LossPred 0.9416 LossAtt 0.2296 TrainAcc 0.5500 TestAcc 0.5170 0.6000
epoch 300 LossPred 0.9328 LossAtt 0.2367 TrainAcc 0.5700 TestAcc 0.5485 0.5650
epoch 400 LossPred 0.9104 LossAtt 0.2496 TrainAcc 0.6100 TestAcc 0.5453 0.6300
epoch 500 LossPred 0.8996 LossAtt 0.2623 TrainAcc 0.6000 TestAcc 0.5526 0.6200
epoch 600 LossPred 0.8925 LossAtt 0.2503 TrainAcc 0.6100 TestAcc 0.5611 0.6000
epoch 700 LossPred 0.8844 LossAtt 0.2495 TrainAcc 0.6300 TestAcc 0.5638 0.6150
epoch 800 LossPred 0.8801 LossAtt 0.2539 TrainAcc 0.6300 TestAcc 0.5666 0.6300
epoch 900 LossPred 0.8662 LossAtt 0.2564 TrainAcc 0.6600 TestAcc 0.5708 0.6200
epoch 1000 LossPred 0.8680 LossAtt 0.2778 TrainAcc 0.6400 TestAcc 0.5716 0.6500
epoch 1100 LossPred 0.8547 LossAtt 0.2590 TrainAcc 0.6600 TestAcc 0.5641 0.6450
epoch 1200 LossPred 0.8657 LossAtt 0.2376 TrainAcc 0.6900 TestAcc 0.5516 0.6650
epoch 1300 LossPred 0.9023 LossAtt 0.2481 TrainAcc 0.6000 TestAcc 0.5273 0.6350
epoch 1400 LossPred 0.8940 LossAtt 0.2215 TrainAcc 0.6100 TestAcc 0.5278 0.6350
epoch 1500 LossPred 0.8773 LossAtt 0.2330 TrainAcc 0.6400 TestAcc 0.5340 0.6400
epoch 1600 LossPred 0.8596 LossAtt 0.2327 TrainAcc 0.6700 TestAcc 0.5440 0.6250
epoch 1700 LossPred 0.8481 LossAtt 0.2433 TrainAcc 0.6900 TestAcc 0.5405 0.6300
epoch 1800 LossPred 0.8410 LossAtt 0.2391 TrainAcc 0.7200 TestAcc 0.5418 0.6350
epoch 1900 LossPred 0.8204 LossAtt 0.2388 TrainAcc 0.7200 TestAcc 0.5280 0.6700
epoch 2000 LossPred 0.8164 LossAtt 0.2430 TrainAcc 0.7000 TestAcc 0.5273 0.6700
epoch 2100 LossPred 0.8133 LossAtt 0.2635 TrainAcc 0.6900 TestAcc 0.5283 0.6450
epoch 2200 LossPred 0.8951 LossAtt 0.2590 TrainAcc 0.6200 TestAcc 0.5105 0.6400
epoch 2300 LossPred 0.8016 LossAtt 0.2562 TrainAcc 0.6900 TestAcc 0.5253 0.6550
epoch 2400 LossPred 0.7714 LossAtt 0.2549 TrainAcc 0.6900 TestAcc 0.5293 0.6550
epoch 2500 LossPred 0.7902 LossAtt 0.2490 TrainAcc 0.6800 TestAcc 0.5325 0.6800
Optimization Finished!
********** replication  93  **********
epoch   0 LossPred 1.0393 LossAtt 1.0043 TrainAcc 0.5700 TestAcc 0.5220 0.5600
epoch 100 LossPred 0.8918 LossAtt 0.2474 TrainAcc 0.6300 TestAcc 0.5816 0.6300
epoch 200 LossPred 0.8838 LossAtt 0.1658 TrainAcc 0.6300 TestAcc 0.5816 0.6300
epoch 300 LossPred 0.8753 LossAtt 0.1805 TrainAcc 0.6300 TestAcc 0.5816 0.6300
epoch 400 LossPred 0.5025 LossAtt 0.2294 TrainAcc 0.8400 TestAcc 0.8281 0.8250
epoch 500 LossPred 0.4390 LossAtt 0.2410 TrainAcc 0.8600 TestAcc 0.8383 0.8400
epoch 600 LossPred 0.2723 LossAtt 0.2442 TrainAcc 0.9100 TestAcc 0.8889 0.9050
epoch 700 LossPred 0.1812 LossAtt 0.2267 TrainAcc 0.9500 TestAcc 0.9077 0.9150
epoch 800 LossPred 0.2526 LossAtt 0.2185 TrainAcc 0.9100 TestAcc 0.8659 0.9100
epoch 900 LossPred 0.2532 LossAtt 0.2089 TrainAcc 0.9200 TestAcc 0.8781 0.9100
epoch 1000 LossPred 0.3474 LossAtt 0.1901 TrainAcc 0.8700 TestAcc 0.8569 0.8800
epoch 1100 LossPred 0.3429 LossAtt 0.1779 TrainAcc 0.8600 TestAcc 0.8491 0.8550
epoch 1200 LossPred 0.2469 LossAtt 0.1570 TrainAcc 0.9100 TestAcc 0.8754 0.8950
epoch 1300 LossPred 0.3229 LossAtt 0.1460 TrainAcc 0.8800 TestAcc 0.8726 0.9000
epoch 1400 LossPred 0.3551 LossAtt 0.1659 TrainAcc 0.8700 TestAcc 0.8724 0.8800
epoch 1500 LossPred 0.2119 LossAtt 0.1595 TrainAcc 0.9500 TestAcc 0.8809 0.9150
epoch 1600 LossPred 0.2625 LossAtt 0.1623 TrainAcc 0.9000 TestAcc 0.8624 0.8900
epoch 1700 LossPred 0.3973 LossAtt 0.1610 TrainAcc 0.8600 TestAcc 0.8316 0.8700
epoch 1800 LossPred 0.2164 LossAtt 0.1629 TrainAcc 0.9300 TestAcc 0.8754 0.9300
epoch 1900 LossPred 0.2570 LossAtt 0.1674 TrainAcc 0.9300 TestAcc 0.8779 0.9200
epoch 2000 LossPred 0.3851 LossAtt 0.1638 TrainAcc 0.8800 TestAcc 0.8601 0.8850
epoch 2100 LossPred 0.2290 LossAtt 0.1797 TrainAcc 0.9300 TestAcc 0.8651 0.9000
epoch 2200 LossPred 0.5418 LossAtt 0.1770 TrainAcc 0.8200 TestAcc 0.8033 0.8100
epoch 2300 LossPred 0.2645 LossAtt 0.1741 TrainAcc 0.9100 TestAcc 0.8744 0.8900
epoch 2400 LossPred 0.3132 LossAtt 0.1817 TrainAcc 0.9000 TestAcc 0.8701 0.9000
epoch 2500 LossPred 0.3588 LossAtt 0.1826 TrainAcc 0.8900 TestAcc 0.8619 0.8900
Optimization Finished!
********** replication  94  **********
epoch   0 LossPred 1.1711 LossAtt 1.0073 TrainAcc 0.4900 TestAcc 0.4827 0.4850
epoch 100 LossPred 0.9684 LossAtt 0.2715 TrainAcc 0.5600 TestAcc 0.5733 0.5600
epoch 200 LossPred 0.9513 LossAtt 0.1816 TrainAcc 0.6100 TestAcc 0.5833 0.6150
epoch 300 LossPred 0.9335 LossAtt 0.1768 TrainAcc 0.6100 TestAcc 0.5833 0.6100
epoch 400 LossPred 0.8748 LossAtt 0.2257 TrainAcc 0.6800 TestAcc 0.6321 0.6750
epoch 500 LossPred 0.8418 LossAtt 0.2010 TrainAcc 0.6800 TestAcc 0.6321 0.6800
epoch 600 LossPred 0.8295 LossAtt 0.2169 TrainAcc 0.6800 TestAcc 0.6264 0.6950
epoch 700 LossPred 0.7864 LossAtt 0.3140 TrainAcc 0.7100 TestAcc 0.6064 0.7000
epoch 800 LossPred 0.7236 LossAtt 0.3981 TrainAcc 0.7400 TestAcc 0.6141 0.7400
epoch 900 LossPred 0.6977 LossAtt 0.4169 TrainAcc 0.7500 TestAcc 0.6081 0.7500
epoch 1000 LossPred 0.6644 LossAtt 0.4124 TrainAcc 0.7900 TestAcc 0.6026 0.7800
epoch 1100 LossPred 0.6218 LossAtt 0.4152 TrainAcc 0.7900 TestAcc 0.6004 0.7850
epoch 1200 LossPred 0.5975 LossAtt 0.4165 TrainAcc 0.7900 TestAcc 0.5886 0.7850
epoch 1300 LossPred 0.6222 LossAtt 0.4021 TrainAcc 0.7700 TestAcc 0.5901 0.7700
epoch 1400 LossPred 0.5924 LossAtt 0.3987 TrainAcc 0.7700 TestAcc 0.5776 0.7800
epoch 1500 LossPred 0.5933 LossAtt 0.3691 TrainAcc 0.8000 TestAcc 0.5868 0.7700
epoch 1600 LossPred 0.5696 LossAtt 0.3781 TrainAcc 0.8300 TestAcc 0.5856 0.7950
epoch 1700 LossPred 0.5511 LossAtt 0.3974 TrainAcc 0.8300 TestAcc 0.5923 0.8250
epoch 1800 LossPred 0.5818 LossAtt 0.4373 TrainAcc 0.8200 TestAcc 0.5863 0.7800
epoch 1900 LossPred 0.5781 LossAtt 0.4249 TrainAcc 0.7900 TestAcc 0.5941 0.7950
epoch 2000 LossPred 0.5918 LossAtt 0.4221 TrainAcc 0.7900 TestAcc 0.5628 0.7650
epoch 2100 LossPred 0.4943 LossAtt 0.3889 TrainAcc 0.8300 TestAcc 0.5821 0.8050
epoch 2200 LossPred 0.4943 LossAtt 0.3841 TrainAcc 0.8400 TestAcc 0.5753 0.8200
epoch 2300 LossPred 0.5629 LossAtt 0.4087 TrainAcc 0.8100 TestAcc 0.5728 0.8050
epoch 2400 LossPred 0.5064 LossAtt 0.3970 TrainAcc 0.8400 TestAcc 0.5656 0.7950
epoch 2500 LossPred 0.4801 LossAtt 0.3981 TrainAcc 0.8300 TestAcc 0.5643 0.7950
Optimization Finished!
********** replication  95  **********
epoch   0 LossPred 1.0287 LossAtt 1.0307 TrainAcc 0.5100 TestAcc 0.4032 0.5300
epoch 100 LossPred 0.9153 LossAtt 0.3443 TrainAcc 0.6000 TestAcc 0.5210 0.6300
epoch 200 LossPred 0.7224 LossAtt 0.3581 TrainAcc 0.7300 TestAcc 0.5288 0.6750
epoch 300 LossPred 0.4506 LossAtt 0.3831 TrainAcc 0.8800 TestAcc 0.8041 0.8600
epoch 400 LossPred 0.2522 LossAtt 0.3769 TrainAcc 0.9200 TestAcc 0.8158 0.9150
epoch 500 LossPred 0.2726 LossAtt 0.3772 TrainAcc 0.9100 TestAcc 0.8023 0.9150
epoch 600 LossPred 0.2403 LossAtt 0.3713 TrainAcc 0.9200 TestAcc 0.8161 0.9100
epoch 700 LossPred 0.1800 LossAtt 0.3405 TrainAcc 0.9600 TestAcc 0.8391 0.9000
epoch 800 LossPred 0.1620 LossAtt 0.2995 TrainAcc 0.9600 TestAcc 0.8441 0.9350
epoch 900 LossPred 0.1644 LossAtt 0.3027 TrainAcc 0.9600 TestAcc 0.8353 0.9550
epoch 1000 LossPred 0.1400 LossAtt 0.2896 TrainAcc 0.9700 TestAcc 0.8411 0.9650
epoch 1100 LossPred 0.1634 LossAtt 0.2758 TrainAcc 0.9500 TestAcc 0.8356 0.9600
epoch 1200 LossPred 0.1532 LossAtt 0.2667 TrainAcc 0.9600 TestAcc 0.8268 0.9500
epoch 1300 LossPred 0.2703 LossAtt 0.2679 TrainAcc 0.9100 TestAcc 0.8043 0.9200
epoch 1400 LossPred 0.1209 LossAtt 0.2519 TrainAcc 0.9800 TestAcc 0.8358 0.9450
epoch 1500 LossPred 0.1590 LossAtt 0.2579 TrainAcc 0.9500 TestAcc 0.8363 0.9500
epoch 1600 LossPred 0.1592 LossAtt 0.2663 TrainAcc 0.9700 TestAcc 0.8241 0.9400
epoch 1700 LossPred 0.1537 LossAtt 0.2720 TrainAcc 0.9700 TestAcc 0.8238 0.9400
epoch 1800 LossPred 0.2498 LossAtt 0.2535 TrainAcc 0.9200 TestAcc 0.8116 0.9150
epoch 1900 LossPred 0.1275 LossAtt 0.2486 TrainAcc 0.9700 TestAcc 0.8308 0.9250
epoch 2000 LossPred 0.1456 LossAtt 0.2513 TrainAcc 0.9700 TestAcc 0.8338 0.9400
epoch 2100 LossPred 0.1323 LossAtt 0.2499 TrainAcc 0.9600 TestAcc 0.8196 0.9500
epoch 2200 LossPred 0.1444 LossAtt 0.2469 TrainAcc 0.9600 TestAcc 0.8186 0.9500
epoch 2300 LossPred 0.1318 LossAtt 0.2436 TrainAcc 0.9700 TestAcc 0.8388 0.9500
epoch 2400 LossPred 0.2661 LossAtt 0.2528 TrainAcc 0.9000 TestAcc 0.8113 0.9100
epoch 2500 LossPred 0.1274 LossAtt 0.2458 TrainAcc 0.9700 TestAcc 0.8411 0.9550
Optimization Finished!
********** replication  96  **********
epoch   0 LossPred 1.0488 LossAtt 1.0061 TrainAcc 0.4400 TestAcc 0.4617 0.4600
epoch 100 LossPred 0.8071 LossAtt 0.1675 TrainAcc 0.6900 TestAcc 0.5848 0.6900
epoch 200 LossPred 0.7860 LossAtt 0.1393 TrainAcc 0.6900 TestAcc 0.5848 0.6900
epoch 300 LossPred 0.4291 LossAtt 0.2126 TrainAcc 0.8900 TestAcc 0.8396 0.8050
epoch 400 LossPred 0.4106 LossAtt 0.1895 TrainAcc 0.8600 TestAcc 0.8043 0.8100
epoch 500 LossPred 0.4015 LossAtt 0.1906 TrainAcc 0.8600 TestAcc 0.8093 0.8150
epoch 600 LossPred 0.3086 LossAtt 0.1825 TrainAcc 0.8900 TestAcc 0.8574 0.8650
epoch 700 LossPred 0.3016 LossAtt 0.1732 TrainAcc 0.9000 TestAcc 0.8744 0.8600
epoch 800 LossPred 0.2758 LossAtt 0.1747 TrainAcc 0.8900 TestAcc 0.8776 0.8900
epoch 900 LossPred 0.4961 LossAtt 0.1701 TrainAcc 0.8400 TestAcc 0.7618 0.8150
epoch 1000 LossPred 0.3547 LossAtt 0.1485 TrainAcc 0.8800 TestAcc 0.8491 0.8450
epoch 1100 LossPred 0.4059 LossAtt 0.1481 TrainAcc 0.8700 TestAcc 0.8198 0.8650
epoch 1200 LossPred 0.2315 LossAtt 0.1617 TrainAcc 0.9300 TestAcc 0.8739 0.9100
epoch 1300 LossPred 0.2655 LossAtt 0.1695 TrainAcc 0.9100 TestAcc 0.8526 0.9050
epoch 1400 LossPred 0.2159 LossAtt 0.1893 TrainAcc 0.9200 TestAcc 0.8656 0.9100
epoch 1500 LossPred 0.2437 LossAtt 0.1897 TrainAcc 0.9100 TestAcc 0.8654 0.9000
epoch 1600 LossPred 0.1690 LossAtt 0.1930 TrainAcc 0.9400 TestAcc 0.8864 0.9150
epoch 1700 LossPred 0.5592 LossAtt 0.1832 TrainAcc 0.8000 TestAcc 0.7365 0.8000
epoch 1800 LossPred 0.2571 LossAtt 0.1903 TrainAcc 0.9200 TestAcc 0.8734 0.9150
epoch 1900 LossPred 0.2572 LossAtt 0.2023 TrainAcc 0.9100 TestAcc 0.8701 0.9200
epoch 2000 LossPred 0.2673 LossAtt 0.2067 TrainAcc 0.9100 TestAcc 0.8626 0.9000
epoch 2100 LossPred 0.2938 LossAtt 0.1887 TrainAcc 0.9100 TestAcc 0.8536 0.9050
epoch 2200 LossPred 0.2398 LossAtt 0.1921 TrainAcc 0.9200 TestAcc 0.8674 0.9150
epoch 2300 LossPred 0.1881 LossAtt 0.2058 TrainAcc 0.9500 TestAcc 0.8846 0.9350
epoch 2400 LossPred 0.4340 LossAtt 0.1934 TrainAcc 0.8400 TestAcc 0.7875 0.8300
epoch 2500 LossPred 0.1925 LossAtt 0.2068 TrainAcc 0.9500 TestAcc 0.8829 0.9450
Optimization Finished!
********** replication  97  **********
epoch   0 LossPred 1.0010 LossAtt 1.0274 TrainAcc 0.5100 TestAcc 0.4722 0.5200
epoch 100 LossPred 0.9016 LossAtt 0.3530 TrainAcc 0.6100 TestAcc 0.5636 0.6150
epoch 200 LossPred 0.4514 LossAtt 0.2426 TrainAcc 0.8500 TestAcc 0.8766 0.8450
epoch 300 LossPred 0.2961 LossAtt 0.2211 TrainAcc 0.9300 TestAcc 0.8736 0.8800
epoch 400 LossPred 0.2567 LossAtt 0.2139 TrainAcc 0.9400 TestAcc 0.8806 0.8900
epoch 500 LossPred 0.3223 LossAtt 0.2161 TrainAcc 0.8800 TestAcc 0.8806 0.8750
epoch 600 LossPred 0.3079 LossAtt 0.2114 TrainAcc 0.9000 TestAcc 0.8804 0.8750
epoch 700 LossPred 0.5048 LossAtt 0.2180 TrainAcc 0.8400 TestAcc 0.8266 0.8250
epoch 800 LossPred 0.2626 LossAtt 0.2122 TrainAcc 0.9300 TestAcc 0.8779 0.8950
epoch 900 LossPred 0.2744 LossAtt 0.2057 TrainAcc 0.8800 TestAcc 0.8726 0.8750
epoch 1000 LossPred 0.2620 LossAtt 0.1902 TrainAcc 0.9100 TestAcc 0.8819 0.8850
epoch 1100 LossPred 0.6807 LossAtt 0.1975 TrainAcc 0.7600 TestAcc 0.7350 0.7650
epoch 1200 LossPred 0.3780 LossAtt 0.1948 TrainAcc 0.8800 TestAcc 0.8196 0.8600
epoch 1300 LossPred 0.6407 LossAtt 0.1996 TrainAcc 0.7900 TestAcc 0.8081 0.8100
epoch 1400 LossPred 0.5544 LossAtt 0.1964 TrainAcc 0.8000 TestAcc 0.8143 0.8150
epoch 1500 LossPred 0.3950 LossAtt 0.2061 TrainAcc 0.8500 TestAcc 0.8586 0.8600
epoch 1600 LossPred 0.4588 LossAtt 0.2047 TrainAcc 0.8300 TestAcc 0.8043 0.8150
epoch 1700 LossPred 0.3207 LossAtt 0.1992 TrainAcc 0.8900 TestAcc 0.8679 0.8850
epoch 1800 LossPred 0.3132 LossAtt 0.1840 TrainAcc 0.8700 TestAcc 0.8676 0.8650
epoch 1900 LossPred 0.2502 LossAtt 0.1850 TrainAcc 0.9300 TestAcc 0.8729 0.8750
epoch 2000 LossPred 0.3637 LossAtt 0.1857 TrainAcc 0.8600 TestAcc 0.8669 0.8700
epoch 2100 LossPred 0.5014 LossAtt 0.1873 TrainAcc 0.8100 TestAcc 0.7833 0.8000
epoch 2200 LossPred 0.2712 LossAtt 0.1958 TrainAcc 0.9100 TestAcc 0.8651 0.8750
epoch 2300 LossPred 0.3441 LossAtt 0.1981 TrainAcc 0.9100 TestAcc 0.8403 0.8900
epoch 2400 LossPred 0.4839 LossAtt 0.1952 TrainAcc 0.8400 TestAcc 0.7875 0.8600
epoch 2500 LossPred 0.4613 LossAtt 0.2154 TrainAcc 0.8700 TestAcc 0.8021 0.8600
Optimization Finished!
********** replication  98  **********
epoch   0 LossPred 1.0053 LossAtt 1.0365 TrainAcc 0.5800 TestAcc 0.5878 0.5850
epoch 100 LossPred 0.9491 LossAtt 0.2297 TrainAcc 0.5800 TestAcc 0.5878 0.5900
epoch 200 LossPred 0.6963 LossAtt 0.3211 TrainAcc 0.7400 TestAcc 0.6446 0.7400
epoch 300 LossPred 0.1260 LossAtt 0.3186 TrainAcc 0.9600 TestAcc 0.8696 0.9350
epoch 400 LossPred 0.1069 LossAtt 0.2772 TrainAcc 0.9700 TestAcc 0.8759 0.9400
epoch 500 LossPred 0.0841 LossAtt 0.2656 TrainAcc 0.9700 TestAcc 0.8879 0.9450
epoch 600 LossPred 0.0623 LossAtt 0.2678 TrainAcc 0.9900 TestAcc 0.8986 0.9600
epoch 700 LossPred 0.0787 LossAtt 0.2730 TrainAcc 0.9900 TestAcc 0.9107 0.9450
epoch 800 LossPred 0.0471 LossAtt 0.2499 TrainAcc 0.9900 TestAcc 0.9037 0.9650
epoch 900 LossPred 0.0413 LossAtt 0.2720 TrainAcc 0.9900 TestAcc 0.9002 0.9650
epoch 1000 LossPred 0.0407 LossAtt 0.2545 TrainAcc 0.9900 TestAcc 0.9012 0.9700
epoch 1100 LossPred 0.0707 LossAtt 0.2528 TrainAcc 0.9800 TestAcc 0.8846 0.9600
epoch 1200 LossPred 0.0369 LossAtt 0.2697 TrainAcc 1.0000 TestAcc 0.8981 0.9700
Optimization Finished!
********** replication  99  **********
epoch   0 LossPred 1.0230 LossAtt 0.9965 TrainAcc 0.5200 TestAcc 0.4967 0.5200
epoch 100 LossPred 0.8846 LossAtt 0.1940 TrainAcc 0.6400 TestAcc 0.5883 0.6400
epoch 200 LossPred 0.7308 LossAtt 0.2343 TrainAcc 0.7100 TestAcc 0.7202 0.7150
epoch 300 LossPred 0.6887 LossAtt 0.1931 TrainAcc 0.7500 TestAcc 0.7362 0.7650
epoch 400 LossPred 0.4688 LossAtt 0.1857 TrainAcc 0.8700 TestAcc 0.8333 0.8350
epoch 500 LossPred 0.5545 LossAtt 0.1651 TrainAcc 0.8200 TestAcc 0.8183 0.8100
epoch 600 LossPred 0.4593 LossAtt 0.1593 TrainAcc 0.8500 TestAcc 0.8358 0.8400
epoch 700 LossPred 0.3874 LossAtt 0.1570 TrainAcc 0.9000 TestAcc 0.8626 0.8350
epoch 800 LossPred 0.3761 LossAtt 0.1569 TrainAcc 0.8700 TestAcc 0.8594 0.8500
epoch 900 LossPred 0.4318 LossAtt 0.1568 TrainAcc 0.8700 TestAcc 0.8463 0.8450
epoch 1000 LossPred 0.4155 LossAtt 0.1511 TrainAcc 0.8700 TestAcc 0.8519 0.8350
epoch 1100 LossPred 0.3715 LossAtt 0.1406 TrainAcc 0.8800 TestAcc 0.8586 0.8550
epoch 1200 LossPred 0.3475 LossAtt 0.1373 TrainAcc 0.8900 TestAcc 0.8646 0.8450
epoch 1300 LossPred 0.3993 LossAtt 0.1275 TrainAcc 0.8900 TestAcc 0.8611 0.8400
epoch 1400 LossPred 0.4278 LossAtt 0.1273 TrainAcc 0.8700 TestAcc 0.8493 0.8450
epoch 1500 LossPred 0.7438 LossAtt 0.1368 TrainAcc 0.7500 TestAcc 0.7387 0.7300
epoch 1600 LossPred 0.5625 LossAtt 0.1210 TrainAcc 0.7900 TestAcc 0.8013 0.8150
epoch 1700 LossPred 0.5334 LossAtt 0.1219 TrainAcc 0.8100 TestAcc 0.8063 0.8050
epoch 1800 LossPred 0.6242 LossAtt 0.1227 TrainAcc 0.7800 TestAcc 0.7492 0.7800
epoch 1900 LossPred 0.5862 LossAtt 0.1313 TrainAcc 0.8100 TestAcc 0.7835 0.7800
epoch 2000 LossPred 0.4223 LossAtt 0.1233 TrainAcc 0.8700 TestAcc 0.8483 0.8450
epoch 2100 LossPred 0.4710 LossAtt 0.1245 TrainAcc 0.8400 TestAcc 0.8371 0.8450
epoch 2200 LossPred 0.6404 LossAtt 0.1287 TrainAcc 0.7600 TestAcc 0.7362 0.7850
epoch 2300 LossPred 0.5233 LossAtt 0.1295 TrainAcc 0.8300 TestAcc 0.8073 0.8400
epoch 2400 LossPred 1.0140 LossAtt 0.1269 TrainAcc 0.6800 TestAcc 0.6514 0.6850
epoch 2500 LossPred 0.5689 LossAtt 0.1309 TrainAcc 0.7700 TestAcc 0.7938 0.8150
Optimization Finished!
********************************************************************
Namespace(arch='tanh', batch_size=256, display_epoch=100, input_noise_level=0.15, latent_attractor_space=True, loss_switch_frequency=0, lrate_attractor=0.002, lrate_prediction=0.002, lrate_wt_penalty=0.0, n_attractor_hidden=20, n_attractor_steps=5, n_hidden=10, n_replications=100, noise_level=0.5, report_best_train_performance=True, seq_len=20, task='majority', train_attr_weights_on_prediction=False, training_epochs=2500)
********************************************************************
mean train accuracy 0.9364
indiv runs  [0.78, 1.0, 0.92, 0.75, 0.97, 0.98, 0.9, 0.97, 0.92, 0.91, 0.97, 0.97, 0.87, 0.94, 0.85, 0.94, 0.8, 0.96, 0.88, 0.99, 0.94, 0.96, 0.93, 0.9, 0.96, 0.94, 0.94, 0.79, 0.98, 0.94, 0.97, 0.9, 0.94, 0.97, 0.96, 0.99, 0.97, 0.94, 1.0, 0.97, 0.96, 0.97, 0.99, 0.93, 0.95, 0.93, 0.87, 0.98, 0.88, 0.97, 1.0, 0.9, 0.96, 0.95, 0.86, 0.97, 0.94, 1.0, 0.92, 0.91, 0.87, 1.0, 0.94, 0.89, 0.98, 0.98, 0.94, 1.0, 0.97, 0.93, 0.99, 0.84, 0.88, 0.91, 0.99, 0.95, 0.96, 0.97, 0.98, 0.98, 0.92, 0.89, 0.97, 0.99, 0.97, 0.95, 0.97, 0.94, 0.93, 0.94, 0.95, 0.99, 0.72, 0.95, 0.84, 0.98, 0.95, 0.94, 1.0, 0.9]
mean epoch 1958.14285714
indiv epochs  [2501, 2101, 2201, 2101, 1901, 1701, 1201]
test1 accuracy mean  0.8242692  median  0.8662412
test2 accuracy mean  0.89615  median  0.915
test1 indiv runs  [0.5385385, 0.9061562, 0.8403403, 0.6218719, 0.8593594, 0.9454454, 0.8305806, 0.8288288, 0.8763764, 0.5923423, 0.9051552, 0.8340841, 0.5620621, 0.8981481, 0.5382883, 0.4854855, 0.5435435, 0.9249249, 0.8368368, 0.8786286, 0.9099099, 0.8781281, 0.8836336, 0.8963964, 0.8233233, 0.8666166, 0.5012513, 0.8185686, 0.8455956, 0.8263263, 0.8205706, 0.8921421, 0.8926426, 0.8506006, 0.8831331, 0.9284284, 0.8626126, 0.8623624, 0.8908909, 0.8060561, 0.8438438, 0.9206707, 0.9359359, 0.7017017, 0.8786286, 0.8671171, 0.8628629, 0.9141642, 0.8448448, 0.8638639, 0.8838839, 0.7672673, 0.8966466, 0.8771271, 0.526026, 0.8676176, 0.8678679, 0.8951451, 0.8658659, 0.8943944, 0.5355355, 0.8743744, 0.8305806, 0.8508509, 0.8913914, 0.8621121, 0.8578579, 0.8643644, 0.9326827, 0.8383383, 0.9241742, 0.5683183, 0.8353353, 0.6083584, 0.9089089, 0.8788789, 0.8340841, 0.8911411, 0.8726226, 0.8808809, 0.8693694, 0.8143143, 0.8603604, 0.7537538, 0.9146647, 0.8698699, 0.8793794, 0.8243243, 0.8816316, 0.8831331, 0.8716216, 0.9154154, 0.5417918, 0.9076577, 0.5753253, 0.8358358, 0.8846346, 0.8806306, 0.8981481, 0.8626126]
test2 indiv runs  [0.715, 0.98, 0.875, 0.675, 0.94, 0.945, 0.885, 0.89, 0.89, 0.825, 0.94, 0.955, 0.8, 0.875, 0.75, 0.84, 0.76, 0.895, 0.825, 0.995, 0.915, 0.935, 0.835, 0.86, 0.92, 0.89, 0.835, 0.79, 0.95, 0.895, 0.95, 0.9, 0.88, 0.96, 0.935, 0.96, 0.965, 0.895, 0.955, 0.91, 0.93, 0.925, 0.98, 0.88, 0.935, 0.905, 0.83, 0.96, 0.815, 0.925, 0.98, 0.8, 0.955, 0.93, 0.78, 0.925, 0.94, 0.98, 0.855, 0.87, 0.82, 0.955, 0.915, 0.865, 0.97, 0.945, 0.905, 0.975, 0.905, 0.885, 0.935, 0.665, 0.835, 0.75, 0.98, 0.935, 0.945, 0.95, 0.975, 0.98, 0.915, 0.86, 0.945, 0.91, 0.895, 0.94, 0.965, 0.895, 0.91, 0.94, 0.94, 0.975, 0.635, 0.915, 0.82, 0.945, 0.935, 0.89, 0.97, 0.835]
