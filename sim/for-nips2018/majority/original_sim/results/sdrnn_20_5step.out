Namespace(arch='tanh', batch_size=256, display_epoch=100, input_noise_level=0.15, latent_attractor_space=True, loss_switch_frequency=0, lrate_attractor=0.002, lrate_prediction=0.002, lrate_wt_penalty=0.0, n_attractor_hidden=10, n_attractor_steps=5, n_hidden=5, n_replications=100, noise_level=0.5, report_best_train_performance=True, seq_len=20, task='majority', train_attr_weights_on_prediction=False, training_epochs=2500)
TRAINING ON 100 EXAMPLES, TESTING ON 3996
********** replication  0  **********
epoch   0 LossPred 1.0475 LossAtt 1.0361 TrainAcc 0.5300 TestAcc 0.4820 0.5050
epoch 100 LossPred 0.8893 LossAtt 0.4561 TrainAcc 0.6500 TestAcc 0.5916 0.6500
epoch 200 LossPred 0.8481 LossAtt 0.4032 TrainAcc 0.6500 TestAcc 0.5916 0.6550
epoch 300 LossPred 0.6322 LossAtt 0.4886 TrainAcc 0.7600 TestAcc 0.7518 0.7250
epoch 400 LossPred 0.4853 LossAtt 0.4118 TrainAcc 0.8500 TestAcc 0.8514 0.7950
epoch 500 LossPred 0.4575 LossAtt 0.3810 TrainAcc 0.8500 TestAcc 0.8559 0.7950
epoch 600 LossPred 0.4365 LossAtt 0.3687 TrainAcc 0.8600 TestAcc 0.8584 0.8000
epoch 700 LossPred 0.4391 LossAtt 0.3678 TrainAcc 0.8600 TestAcc 0.8636 0.8000
epoch 800 LossPred 0.4176 LossAtt 0.3409 TrainAcc 0.8700 TestAcc 0.8629 0.8200
epoch 900 LossPred 0.3854 LossAtt 0.3389 TrainAcc 0.8900 TestAcc 0.8531 0.8100
epoch 1000 LossPred 0.3796 LossAtt 0.3471 TrainAcc 0.8900 TestAcc 0.8546 0.8150
epoch 1100 LossPred 0.3766 LossAtt 0.3317 TrainAcc 0.8900 TestAcc 0.8714 0.8250
epoch 1200 LossPred 0.3881 LossAtt 0.3493 TrainAcc 0.8700 TestAcc 0.8691 0.8200
epoch 1300 LossPred 0.3739 LossAtt 0.3413 TrainAcc 0.8600 TestAcc 0.8674 0.8300
epoch 1400 LossPred 0.3731 LossAtt 0.3419 TrainAcc 0.8800 TestAcc 0.8776 0.8300
epoch 1500 LossPred 0.3614 LossAtt 0.3461 TrainAcc 0.8800 TestAcc 0.8779 0.8450
epoch 1600 LossPred 0.3406 LossAtt 0.3393 TrainAcc 0.8900 TestAcc 0.8841 0.8450
epoch 1700 LossPred 0.3077 LossAtt 0.3606 TrainAcc 0.9100 TestAcc 0.8891 0.8800
epoch 1800 LossPred 0.3629 LossAtt 0.3479 TrainAcc 0.8900 TestAcc 0.8636 0.8550
epoch 1900 LossPred 0.3056 LossAtt 0.3692 TrainAcc 0.9100 TestAcc 0.8986 0.8650
epoch 2000 LossPred 0.2717 LossAtt 0.3671 TrainAcc 0.9300 TestAcc 0.8901 0.8750
epoch 2100 LossPred 0.2501 LossAtt 0.3733 TrainAcc 0.9000 TestAcc 0.9097 0.8950
epoch 2200 LossPred 0.2756 LossAtt 0.3622 TrainAcc 0.9200 TestAcc 0.9077 0.8600
epoch 2300 LossPred 0.2445 LossAtt 0.3476 TrainAcc 0.9300 TestAcc 0.9177 0.8800
epoch 2400 LossPred 0.3773 LossAtt 0.3593 TrainAcc 0.8500 TestAcc 0.8491 0.8500
epoch 2500 LossPred 0.3477 LossAtt 0.3505 TrainAcc 0.9000 TestAcc 0.8816 0.8450
Optimization Finished!
********** replication  1  **********
epoch   0 LossPred 1.5202 LossAtt 0.9973 TrainAcc 0.3400 TestAcc 0.4782 0.3450
epoch 100 LossPred 1.0424 LossAtt 0.2615 TrainAcc 0.5400 TestAcc 0.5838 0.5400
epoch 200 LossPred 0.8733 LossAtt 0.2121 TrainAcc 0.7200 TestAcc 0.5906 0.7200
epoch 300 LossPred 0.8102 LossAtt 0.1906 TrainAcc 0.7200 TestAcc 0.5906 0.7200
epoch 400 LossPred 0.4801 LossAtt 0.4213 TrainAcc 0.8800 TestAcc 0.7680 0.8750
epoch 500 LossPred 0.4038 LossAtt 0.4031 TrainAcc 0.8700 TestAcc 0.7685 0.8750
epoch 600 LossPred 0.3752 LossAtt 0.4278 TrainAcc 0.9000 TestAcc 0.8036 0.8700
epoch 700 LossPred 0.3603 LossAtt 0.4239 TrainAcc 0.8900 TestAcc 0.8278 0.8350
epoch 800 LossPred 0.3467 LossAtt 0.4201 TrainAcc 0.9000 TestAcc 0.8203 0.8650
epoch 900 LossPred 0.3380 LossAtt 0.4140 TrainAcc 0.9000 TestAcc 0.8268 0.8750
epoch 1000 LossPred 0.3374 LossAtt 0.4062 TrainAcc 0.8800 TestAcc 0.8366 0.8450
epoch 1100 LossPred 0.3176 LossAtt 0.4093 TrainAcc 0.9100 TestAcc 0.8311 0.8850
epoch 1200 LossPred 0.3014 LossAtt 0.4058 TrainAcc 0.9100 TestAcc 0.8381 0.8900
epoch 1300 LossPred 0.2824 LossAtt 0.3960 TrainAcc 0.9200 TestAcc 0.8584 0.8850
epoch 1400 LossPred 0.2701 LossAtt 0.4028 TrainAcc 0.9200 TestAcc 0.8836 0.9000
epoch 1500 LossPred 0.2615 LossAtt 0.3965 TrainAcc 0.9000 TestAcc 0.8901 0.9050
epoch 1600 LossPred 0.2722 LossAtt 0.3844 TrainAcc 0.9200 TestAcc 0.8864 0.8850
epoch 1700 LossPred 0.2632 LossAtt 0.3903 TrainAcc 0.9000 TestAcc 0.8796 0.8850
epoch 1800 LossPred 0.2847 LossAtt 0.3616 TrainAcc 0.8900 TestAcc 0.8896 0.8600
epoch 1900 LossPred 0.3068 LossAtt 0.3579 TrainAcc 0.8700 TestAcc 0.8316 0.8700
epoch 2000 LossPred 0.2907 LossAtt 0.3382 TrainAcc 0.9000 TestAcc 0.8759 0.8700
epoch 2100 LossPred 0.2612 LossAtt 0.3435 TrainAcc 0.9000 TestAcc 0.8586 0.8850
epoch 2200 LossPred 0.2603 LossAtt 0.3291 TrainAcc 0.8900 TestAcc 0.8896 0.8900
epoch 2300 LossPred 0.2397 LossAtt 0.3530 TrainAcc 0.9000 TestAcc 0.8714 0.9050
epoch 2400 LossPred 0.2363 LossAtt 0.3373 TrainAcc 0.9100 TestAcc 0.8914 0.9050
epoch 2500 LossPred 0.2759 LossAtt 0.3321 TrainAcc 0.8800 TestAcc 0.8629 0.8800
Optimization Finished!
********** replication  2  **********
epoch   0 LossPred 0.9776 LossAtt 1.0264 TrainAcc 0.5500 TestAcc 0.4494 0.5700
epoch 100 LossPred 0.8922 LossAtt 0.2992 TrainAcc 0.6600 TestAcc 0.5716 0.6600
epoch 200 LossPred 0.8836 LossAtt 0.1579 TrainAcc 0.6600 TestAcc 0.5716 0.6600
epoch 300 LossPred 0.8824 LossAtt 0.1494 TrainAcc 0.6600 TestAcc 0.5716 0.6600
epoch 400 LossPred 0.8800 LossAtt 0.2318 TrainAcc 0.6600 TestAcc 0.5716 0.6600
epoch 500 LossPred 0.8262 LossAtt 0.3444 TrainAcc 0.7200 TestAcc 0.6451 0.7150
epoch 600 LossPred 0.4705 LossAtt 0.3402 TrainAcc 0.8600 TestAcc 0.8171 0.8300
epoch 700 LossPred 0.3532 LossAtt 0.3539 TrainAcc 0.9100 TestAcc 0.8524 0.8350
epoch 800 LossPred 0.2968 LossAtt 0.3589 TrainAcc 0.9200 TestAcc 0.8716 0.8850
epoch 900 LossPred 0.3340 LossAtt 0.3598 TrainAcc 0.9200 TestAcc 0.8646 0.8500
epoch 1000 LossPred 0.3318 LossAtt 0.3540 TrainAcc 0.9000 TestAcc 0.8594 0.8500
epoch 1100 LossPred 0.3474 LossAtt 0.3470 TrainAcc 0.9200 TestAcc 0.8601 0.8400
epoch 1200 LossPred 0.2931 LossAtt 0.3525 TrainAcc 0.9300 TestAcc 0.8731 0.8850
epoch 1300 LossPred 0.2892 LossAtt 0.3490 TrainAcc 0.9400 TestAcc 0.8751 0.8750
epoch 1400 LossPred 0.3240 LossAtt 0.3356 TrainAcc 0.9400 TestAcc 0.8746 0.8600
epoch 1500 LossPred 0.3425 LossAtt 0.3287 TrainAcc 0.8800 TestAcc 0.8591 0.8750
epoch 1600 LossPred 0.3135 LossAtt 0.3363 TrainAcc 0.8900 TestAcc 0.8779 0.8750
epoch 1700 LossPred 0.3654 LossAtt 0.3232 TrainAcc 0.9000 TestAcc 0.8536 0.8350
epoch 1800 LossPred 0.3035 LossAtt 0.3369 TrainAcc 0.9200 TestAcc 0.8699 0.8600
epoch 1900 LossPred 0.6110 LossAtt 0.3371 TrainAcc 0.8100 TestAcc 0.7785 0.7750
epoch 2000 LossPred 0.2856 LossAtt 0.3255 TrainAcc 0.9100 TestAcc 0.8478 0.8450
epoch 2100 LossPred 0.4967 LossAtt 0.3374 TrainAcc 0.8400 TestAcc 0.8111 0.8400
epoch 2200 LossPred 0.6917 LossAtt 0.3075 TrainAcc 0.7900 TestAcc 0.7508 0.7900
epoch 2300 LossPred 1.0570 LossAtt 0.3190 TrainAcc 0.5700 TestAcc 0.6707 0.5750
epoch 2400 LossPred 1.1405 LossAtt 0.3405 TrainAcc 0.6600 TestAcc 0.5716 0.6600
epoch 2500 LossPred 0.4174 LossAtt 0.3294 TrainAcc 0.8500 TestAcc 0.8418 0.8550
Optimization Finished!
********** replication  3  **********
epoch   0 LossPred 1.1637 LossAtt 1.0175 TrainAcc 0.4000 TestAcc 0.4635 0.4550
epoch 100 LossPred 0.9609 LossAtt 0.2386 TrainAcc 0.5400 TestAcc 0.5843 0.6200
epoch 200 LossPred 0.9283 LossAtt 0.1201 TrainAcc 0.6400 TestAcc 0.5841 0.6400
epoch 300 LossPred 0.9460 LossAtt 0.0897 TrainAcc 0.6400 TestAcc 0.5841 0.6400
epoch 400 LossPred 0.9533 LossAtt 0.1090 TrainAcc 0.5400 TestAcc 0.5843 0.5800
epoch 500 LossPred 0.9653 LossAtt 0.1328 TrainAcc 0.5400 TestAcc 0.5843 0.5400
epoch 600 LossPred 0.9438 LossAtt 0.1941 TrainAcc 0.6400 TestAcc 0.5841 0.6450
epoch 700 LossPred 0.8852 LossAtt 0.2691 TrainAcc 0.6400 TestAcc 0.5841 0.6400
epoch 800 LossPred 0.7992 LossAtt 0.3673 TrainAcc 0.7300 TestAcc 0.6749 0.7050
epoch 900 LossPred 0.7710 LossAtt 0.3942 TrainAcc 0.7000 TestAcc 0.6441 0.6950
epoch 1000 LossPred 0.5119 LossAtt 0.4078 TrainAcc 0.8200 TestAcc 0.7810 0.7900
epoch 1100 LossPred 0.4544 LossAtt 0.3842 TrainAcc 0.8100 TestAcc 0.7995 0.7950
epoch 1200 LossPred 0.5749 LossAtt 0.3895 TrainAcc 0.8100 TestAcc 0.8068 0.8150
epoch 1300 LossPred 0.3903 LossAtt 0.3885 TrainAcc 0.8600 TestAcc 0.8266 0.8400
epoch 1400 LossPred 0.5063 LossAtt 0.3532 TrainAcc 0.8000 TestAcc 0.7688 0.7700
epoch 1500 LossPred 0.8170 LossAtt 0.3618 TrainAcc 0.7400 TestAcc 0.7680 0.7700
epoch 1600 LossPred 0.3984 LossAtt 0.3619 TrainAcc 0.8500 TestAcc 0.8346 0.8500
epoch 1700 LossPred 0.3755 LossAtt 0.3575 TrainAcc 0.8600 TestAcc 0.8338 0.8450
epoch 1800 LossPred 0.3988 LossAtt 0.3733 TrainAcc 0.8400 TestAcc 0.8286 0.8600
epoch 1900 LossPred 0.3874 LossAtt 0.3671 TrainAcc 0.8600 TestAcc 0.8341 0.8550
epoch 2000 LossPred 0.3602 LossAtt 0.3769 TrainAcc 0.8700 TestAcc 0.8393 0.8600
epoch 2100 LossPred 0.3520 LossAtt 0.3522 TrainAcc 0.8900 TestAcc 0.8393 0.8700
epoch 2200 LossPred 0.3320 LossAtt 0.3844 TrainAcc 0.8900 TestAcc 0.8496 0.8550
epoch 2300 LossPred 0.2867 LossAtt 0.4034 TrainAcc 0.8800 TestAcc 0.8696 0.8900
epoch 2400 LossPred 0.3164 LossAtt 0.3950 TrainAcc 0.8800 TestAcc 0.8576 0.8700
epoch 2500 LossPred 0.3086 LossAtt 0.3656 TrainAcc 0.9000 TestAcc 0.8488 0.8850
Optimization Finished!
********** replication  4  **********
epoch   0 LossPred 1.2503 LossAtt 1.0059 TrainAcc 0.5000 TestAcc 0.4857 0.4750
epoch 100 LossPred 0.9937 LossAtt 0.3858 TrainAcc 0.5900 TestAcc 0.6054 0.5600
epoch 200 LossPred 0.9707 LossAtt 0.3982 TrainAcc 0.5900 TestAcc 0.6054 0.5900
epoch 300 LossPred 0.9214 LossAtt 0.3146 TrainAcc 0.5700 TestAcc 0.5816 0.5700
epoch 400 LossPred 0.8805 LossAtt 0.2766 TrainAcc 0.6700 TestAcc 0.5891 0.6700
epoch 500 LossPred 0.8634 LossAtt 0.3125 TrainAcc 0.6700 TestAcc 0.5891 0.6650
epoch 600 LossPred 0.8445 LossAtt 0.3804 TrainAcc 0.6900 TestAcc 0.6296 0.6850
epoch 700 LossPred 0.8321 LossAtt 0.3319 TrainAcc 0.6900 TestAcc 0.6324 0.6900
epoch 800 LossPred 0.8035 LossAtt 0.3632 TrainAcc 0.7200 TestAcc 0.6582 0.7100
epoch 900 LossPred 0.6702 LossAtt 0.3227 TrainAcc 0.7700 TestAcc 0.7740 0.7600
epoch 1000 LossPred 0.4894 LossAtt 0.2849 TrainAcc 0.8400 TestAcc 0.8694 0.8050
epoch 1100 LossPred 0.4315 LossAtt 0.2765 TrainAcc 0.8600 TestAcc 0.8761 0.8250
epoch 1200 LossPred 0.4166 LossAtt 0.2617 TrainAcc 0.8700 TestAcc 0.8729 0.8100
epoch 1300 LossPred 0.4129 LossAtt 0.2923 TrainAcc 0.8400 TestAcc 0.8711 0.8150
epoch 1400 LossPred 0.3785 LossAtt 0.2819 TrainAcc 0.8500 TestAcc 0.8976 0.8500
epoch 1500 LossPred 0.3430 LossAtt 0.2822 TrainAcc 0.8800 TestAcc 0.9007 0.8650
epoch 1600 LossPred 0.3434 LossAtt 0.2945 TrainAcc 0.8900 TestAcc 0.9242 0.8500
epoch 1700 LossPred 0.3110 LossAtt 0.2893 TrainAcc 0.9000 TestAcc 0.9137 0.8600
epoch 1800 LossPred 0.3014 LossAtt 0.2956 TrainAcc 0.9000 TestAcc 0.9119 0.8700
epoch 1900 LossPred 0.2952 LossAtt 0.2843 TrainAcc 0.9000 TestAcc 0.9239 0.8700
epoch 2000 LossPred 0.2932 LossAtt 0.2724 TrainAcc 0.8900 TestAcc 0.9182 0.8700
epoch 2100 LossPred 0.2866 LossAtt 0.2714 TrainAcc 0.8900 TestAcc 0.9249 0.8750
epoch 2200 LossPred 0.2759 LossAtt 0.2740 TrainAcc 0.9200 TestAcc 0.9282 0.8800
epoch 2300 LossPred 0.2727 LossAtt 0.2691 TrainAcc 0.9100 TestAcc 0.9259 0.8800
epoch 2400 LossPred 0.2745 LossAtt 0.2872 TrainAcc 0.9000 TestAcc 0.9264 0.8800
epoch 2500 LossPred 0.2603 LossAtt 0.2649 TrainAcc 0.9300 TestAcc 0.9347 0.8900
Optimization Finished!
********** replication  5  **********
epoch   0 LossPred 1.1651 LossAtt 1.0054 TrainAcc 0.4400 TestAcc 0.4902 0.4500
epoch 100 LossPred 0.9298 LossAtt 0.4346 TrainAcc 0.6200 TestAcc 0.5430 0.6050
epoch 200 LossPred 0.9069 LossAtt 0.3788 TrainAcc 0.6200 TestAcc 0.5430 0.6150
epoch 300 LossPred 0.8827 LossAtt 0.2959 TrainAcc 0.6500 TestAcc 0.5415 0.6600
epoch 400 LossPred 0.8664 LossAtt 0.2355 TrainAcc 0.6600 TestAcc 0.5938 0.6600
epoch 500 LossPred 0.8589 LossAtt 0.2053 TrainAcc 0.6600 TestAcc 0.5938 0.6600
epoch 600 LossPred 0.8545 LossAtt 0.1819 TrainAcc 0.6600 TestAcc 0.5938 0.6600
epoch 700 LossPred 0.8499 LossAtt 0.2720 TrainAcc 0.6600 TestAcc 0.5938 0.6600
epoch 800 LossPred 0.8384 LossAtt 0.3297 TrainAcc 0.6600 TestAcc 0.5938 0.6600
epoch 900 LossPred 0.4997 LossAtt 0.4368 TrainAcc 0.8300 TestAcc 0.8186 0.8350
epoch 1000 LossPred 0.3925 LossAtt 0.4195 TrainAcc 0.8800 TestAcc 0.8696 0.8650
epoch 1100 LossPred 0.3293 LossAtt 0.3939 TrainAcc 0.8700 TestAcc 0.8864 0.8500
epoch 1200 LossPred 0.3807 LossAtt 0.4013 TrainAcc 0.8600 TestAcc 0.8604 0.8600
epoch 1300 LossPred 0.2776 LossAtt 0.3901 TrainAcc 0.9100 TestAcc 0.8966 0.8700
epoch 1400 LossPred 0.2929 LossAtt 0.3820 TrainAcc 0.8900 TestAcc 0.8946 0.8800
epoch 1500 LossPred 0.2960 LossAtt 0.3886 TrainAcc 0.9000 TestAcc 0.8751 0.8750
epoch 1600 LossPred 0.2849 LossAtt 0.3729 TrainAcc 0.9000 TestAcc 0.8749 0.8800
epoch 1700 LossPred 0.3236 LossAtt 0.3602 TrainAcc 0.8900 TestAcc 0.8551 0.8700
epoch 1800 LossPred 0.2672 LossAtt 0.3761 TrainAcc 0.9000 TestAcc 0.8759 0.8850
epoch 1900 LossPred 0.3174 LossAtt 0.3780 TrainAcc 0.8900 TestAcc 0.8519 0.8600
epoch 2000 LossPred 0.3935 LossAtt 0.3932 TrainAcc 0.8600 TestAcc 0.8241 0.8600
epoch 2100 LossPred 0.2725 LossAtt 0.3833 TrainAcc 0.9000 TestAcc 0.8894 0.8600
epoch 2200 LossPred 0.2861 LossAtt 0.3928 TrainAcc 0.8900 TestAcc 0.8884 0.9000
epoch 2300 LossPred 0.2494 LossAtt 0.3984 TrainAcc 0.9200 TestAcc 0.8929 0.8900
epoch 2400 LossPred 0.2697 LossAtt 0.3990 TrainAcc 0.9100 TestAcc 0.8689 0.8950
epoch 2500 LossPred 0.2561 LossAtt 0.3880 TrainAcc 0.9000 TestAcc 0.8951 0.9000
Optimization Finished!
********** replication  6  **********
epoch   0 LossPred 1.0520 LossAtt 1.0084 TrainAcc 0.4600 TestAcc 0.4937 0.4800
epoch 100 LossPred 0.9229 LossAtt 0.4852 TrainAcc 0.6200 TestAcc 0.6121 0.6800
epoch 200 LossPred 0.8381 LossAtt 0.4771 TrainAcc 0.7000 TestAcc 0.6341 0.7000
epoch 300 LossPred 0.6261 LossAtt 0.5451 TrainAcc 0.8300 TestAcc 0.7385 0.8350
epoch 400 LossPred 0.3876 LossAtt 0.4687 TrainAcc 0.8400 TestAcc 0.8013 0.8500
epoch 500 LossPred 0.2228 LossAtt 0.4475 TrainAcc 0.9300 TestAcc 0.9044 0.9100
epoch 600 LossPred 0.1945 LossAtt 0.4478 TrainAcc 0.9500 TestAcc 0.8946 0.9250
epoch 700 LossPred 0.2129 LossAtt 0.4485 TrainAcc 0.9300 TestAcc 0.8739 0.9100
epoch 800 LossPred 0.2003 LossAtt 0.4304 TrainAcc 0.9300 TestAcc 0.8779 0.9050
epoch 900 LossPred 0.2682 LossAtt 0.4121 TrainAcc 0.9100 TestAcc 0.8473 0.9100
epoch 1000 LossPred 0.1962 LossAtt 0.4342 TrainAcc 0.9400 TestAcc 0.8954 0.9300
epoch 1100 LossPred 0.3121 LossAtt 0.4296 TrainAcc 0.8900 TestAcc 0.8283 0.9000
epoch 1200 LossPred 0.1668 LossAtt 0.4162 TrainAcc 0.9700 TestAcc 0.8829 0.9200
epoch 1300 LossPred 0.1949 LossAtt 0.4093 TrainAcc 0.9400 TestAcc 0.8674 0.9100
epoch 1400 LossPred 0.2262 LossAtt 0.3910 TrainAcc 0.9200 TestAcc 0.8899 0.9150
epoch 1500 LossPred 0.1480 LossAtt 0.3785 TrainAcc 0.9600 TestAcc 0.8586 0.9450
epoch 1600 LossPred 0.1772 LossAtt 0.3659 TrainAcc 0.9300 TestAcc 0.8586 0.9450
epoch 1700 LossPred 0.2458 LossAtt 0.3666 TrainAcc 0.9200 TestAcc 0.8243 0.9050
epoch 1800 LossPred 0.1831 LossAtt 0.3462 TrainAcc 0.9400 TestAcc 0.8516 0.9250
epoch 1900 LossPred 0.2136 LossAtt 0.3463 TrainAcc 0.9200 TestAcc 0.8589 0.9350
epoch 2000 LossPred 0.1947 LossAtt 0.3587 TrainAcc 0.9400 TestAcc 0.8626 0.9200
epoch 2100 LossPred 0.1829 LossAtt 0.3242 TrainAcc 0.9200 TestAcc 0.8539 0.9300
epoch 2200 LossPred 0.1903 LossAtt 0.3195 TrainAcc 0.9500 TestAcc 0.8596 0.9400
epoch 2300 LossPred 0.2679 LossAtt 0.3028 TrainAcc 0.9200 TestAcc 0.8243 0.9000
epoch 2400 LossPred 0.2729 LossAtt 0.2991 TrainAcc 0.9100 TestAcc 0.8218 0.8950
epoch 2500 LossPred 0.6008 LossAtt 0.2933 TrainAcc 0.8100 TestAcc 0.8046 0.8000
Optimization Finished!
********** replication  7  **********
epoch   0 LossPred 0.9748 LossAtt 1.0055 TrainAcc 0.5900 TestAcc 0.5183 0.5600
epoch 100 LossPred 0.8714 LossAtt 0.4993 TrainAcc 0.6700 TestAcc 0.5783 0.6750
epoch 200 LossPred 0.8515 LossAtt 0.4662 TrainAcc 0.7000 TestAcc 0.5971 0.6900
epoch 300 LossPred 0.8323 LossAtt 0.4672 TrainAcc 0.7000 TestAcc 0.5818 0.6800
epoch 400 LossPred 0.8183 LossAtt 0.4092 TrainAcc 0.7100 TestAcc 0.5966 0.6950
epoch 500 LossPred 0.6721 LossAtt 0.5299 TrainAcc 0.7500 TestAcc 0.6789 0.7350
epoch 600 LossPred 0.8763 LossAtt 0.4694 TrainAcc 0.6600 TestAcc 0.5831 0.6550
epoch 700 LossPred 0.5384 LossAtt 0.4029 TrainAcc 0.8400 TestAcc 0.7965 0.8250
epoch 800 LossPred 0.4416 LossAtt 0.3861 TrainAcc 0.8500 TestAcc 0.8186 0.8700
epoch 900 LossPred 0.6482 LossAtt 0.3963 TrainAcc 0.7800 TestAcc 0.7710 0.7800
epoch 1000 LossPred 0.6821 LossAtt 0.3729 TrainAcc 0.7500 TestAcc 0.6767 0.7500
epoch 1100 LossPred 0.3953 LossAtt 0.3965 TrainAcc 0.8900 TestAcc 0.8076 0.8850
epoch 1200 LossPred 0.4923 LossAtt 0.4085 TrainAcc 0.8200 TestAcc 0.8208 0.8450
epoch 1300 LossPred 0.4315 LossAtt 0.4138 TrainAcc 0.8500 TestAcc 0.7560 0.8350
epoch 1400 LossPred 0.3824 LossAtt 0.3980 TrainAcc 0.8700 TestAcc 0.7865 0.8650
epoch 1500 LossPred 0.3445 LossAtt 0.4011 TrainAcc 0.9000 TestAcc 0.8251 0.8750
epoch 1600 LossPred 0.3280 LossAtt 0.4113 TrainAcc 0.9100 TestAcc 0.8296 0.8750
epoch 1700 LossPred 0.3198 LossAtt 0.4222 TrainAcc 0.9100 TestAcc 0.8316 0.8800
epoch 1800 LossPred 0.3211 LossAtt 0.4113 TrainAcc 0.8900 TestAcc 0.8203 0.8800
epoch 1900 LossPred 0.4682 LossAtt 0.3967 TrainAcc 0.8100 TestAcc 0.7325 0.8100
epoch 2000 LossPred 0.3468 LossAtt 0.3931 TrainAcc 0.9000 TestAcc 0.8166 0.8750
epoch 2100 LossPred 0.3039 LossAtt 0.4048 TrainAcc 0.9100 TestAcc 0.8193 0.9000
epoch 2200 LossPred 0.2949 LossAtt 0.3880 TrainAcc 0.9100 TestAcc 0.8221 0.9000
epoch 2300 LossPred 0.2875 LossAtt 0.4034 TrainAcc 0.9300 TestAcc 0.8183 0.9100
epoch 2400 LossPred 0.2986 LossAtt 0.3994 TrainAcc 0.9000 TestAcc 0.8166 0.8850
epoch 2500 LossPred 0.2880 LossAtt 0.3889 TrainAcc 0.9200 TestAcc 0.8076 0.8900
Optimization Finished!
********** replication  8  **********
epoch   0 LossPred 1.3164 LossAtt 1.0233 TrainAcc 0.3800 TestAcc 0.4114 0.3800
epoch 100 LossPred 0.9690 LossAtt 0.3352 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 200 LossPred 0.9359 LossAtt 0.2299 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 300 LossPred 0.9257 LossAtt 0.1527 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 400 LossPred 0.9214 LossAtt 0.1266 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 500 LossPred 0.9200 LossAtt 0.0948 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 600 LossPred 0.9198 LossAtt 0.0930 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 700 LossPred 0.9198 LossAtt 0.0782 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 800 LossPred 0.9198 LossAtt 0.0763 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 900 LossPred 0.9197 LossAtt 0.0891 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 1000 LossPred 0.9194 LossAtt 0.0917 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 1100 LossPred 0.9195 LossAtt 0.0802 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 1200 LossPred 0.9198 LossAtt 0.0786 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 1300 LossPred 0.9200 LossAtt 0.0964 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 1400 LossPred 0.9176 LossAtt 0.1809 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 1500 LossPred 0.8936 LossAtt 0.2178 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 1600 LossPred 0.8913 LossAtt 0.1901 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 1700 LossPred 0.8907 LossAtt 0.1725 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 1800 LossPred 0.8905 LossAtt 0.1806 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 1900 LossPred 0.8905 LossAtt 0.1733 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 2000 LossPred 0.8904 LossAtt 0.2016 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 2100 LossPred 0.8904 LossAtt 0.1635 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 2200 LossPred 0.8906 LossAtt 0.1864 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 2300 LossPred 0.8909 LossAtt 0.1796 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 2400 LossPred 0.8901 LossAtt 0.1655 TrainAcc 0.6200 TestAcc 0.5886 0.6200
epoch 2500 LossPred 0.8901 LossAtt 0.1510 TrainAcc 0.6200 TestAcc 0.5886 0.6200
Optimization Finished!
********** replication  9  **********
epoch   0 LossPred 0.9428 LossAtt 1.0036 TrainAcc 0.6200 TestAcc 0.4965 0.6150
epoch 100 LossPred 0.8582 LossAtt 0.3595 TrainAcc 0.6700 TestAcc 0.5871 0.6700
epoch 200 LossPred 0.8037 LossAtt 0.3315 TrainAcc 0.6700 TestAcc 0.5871 0.6950
epoch 300 LossPred 0.3730 LossAtt 0.4411 TrainAcc 0.8700 TestAcc 0.7930 0.8850
epoch 400 LossPred 0.3323 LossAtt 0.4232 TrainAcc 0.8800 TestAcc 0.8196 0.8800
epoch 500 LossPred 0.3106 LossAtt 0.4199 TrainAcc 0.9200 TestAcc 0.8443 0.8900
epoch 600 LossPred 0.2796 LossAtt 0.4190 TrainAcc 0.9100 TestAcc 0.8393 0.8950
epoch 700 LossPred 0.2960 LossAtt 0.4177 TrainAcc 0.9200 TestAcc 0.8576 0.9150
epoch 800 LossPred 0.2286 LossAtt 0.4340 TrainAcc 0.9400 TestAcc 0.8403 0.9000
epoch 900 LossPred 0.3541 LossAtt 0.4673 TrainAcc 0.9000 TestAcc 0.8516 0.9150
epoch 1000 LossPred 0.2679 LossAtt 0.4284 TrainAcc 0.9200 TestAcc 0.8243 0.9150
epoch 1100 LossPred 0.3124 LossAtt 0.4475 TrainAcc 0.8800 TestAcc 0.7818 0.8800
epoch 1200 LossPred 0.3043 LossAtt 0.4197 TrainAcc 0.8900 TestAcc 0.7863 0.8850
epoch 1300 LossPred 0.4131 LossAtt 0.4222 TrainAcc 0.8400 TestAcc 0.7455 0.8550
epoch 1400 LossPred 0.3660 LossAtt 0.4248 TrainAcc 0.8600 TestAcc 0.7628 0.8750
epoch 1500 LossPred 0.3842 LossAtt 0.4177 TrainAcc 0.8900 TestAcc 0.7402 0.8850
epoch 1600 LossPred 0.3193 LossAtt 0.4486 TrainAcc 0.9100 TestAcc 0.8473 0.8850
epoch 1700 LossPred 0.2571 LossAtt 0.4492 TrainAcc 0.9100 TestAcc 0.8313 0.9200
epoch 1800 LossPred 0.2561 LossAtt 0.4416 TrainAcc 0.9200 TestAcc 0.8253 0.9250
epoch 1900 LossPred 0.2128 LossAtt 0.4503 TrainAcc 0.9400 TestAcc 0.8654 0.9550
epoch 2000 LossPred 0.2410 LossAtt 0.4587 TrainAcc 0.9300 TestAcc 0.8706 0.9300
epoch 2100 LossPred 0.2029 LossAtt 0.4590 TrainAcc 0.9400 TestAcc 0.8721 0.9550
epoch 2200 LossPred 0.2452 LossAtt 0.4840 TrainAcc 0.9200 TestAcc 0.8206 0.9200
epoch 2300 LossPred 0.2119 LossAtt 0.4666 TrainAcc 0.9400 TestAcc 0.8363 0.9400
epoch 2400 LossPred 0.1501 LossAtt 0.4708 TrainAcc 0.9500 TestAcc 0.8681 0.9550
epoch 2500 LossPred 0.2547 LossAtt 0.4848 TrainAcc 0.9100 TestAcc 0.8431 0.9100
Optimization Finished!
********** replication  10  **********
epoch   0 LossPred 0.9682 LossAtt 1.0406 TrainAcc 0.6200 TestAcc 0.5856 0.6150
epoch 100 LossPred 0.8670 LossAtt 0.5101 TrainAcc 0.6900 TestAcc 0.6299 0.6750
epoch 200 LossPred 0.7467 LossAtt 0.5871 TrainAcc 0.7200 TestAcc 0.7242 0.7100
epoch 300 LossPred 0.5421 LossAtt 0.5503 TrainAcc 0.8300 TestAcc 0.7645 0.8300
epoch 400 LossPred 0.4968 LossAtt 0.5287 TrainAcc 0.8400 TestAcc 0.7900 0.8400
epoch 500 LossPred 0.4920 LossAtt 0.5320 TrainAcc 0.8500 TestAcc 0.7915 0.8450
epoch 600 LossPred 0.4635 LossAtt 0.5122 TrainAcc 0.8500 TestAcc 0.7993 0.8400
epoch 700 LossPred 0.4608 LossAtt 0.4780 TrainAcc 0.8500 TestAcc 0.7960 0.8550
epoch 800 LossPred 0.4571 LossAtt 0.4733 TrainAcc 0.8600 TestAcc 0.7990 0.8600
epoch 900 LossPred 0.4575 LossAtt 0.4657 TrainAcc 0.8500 TestAcc 0.8041 0.8650
epoch 1000 LossPred 0.6391 LossAtt 0.4488 TrainAcc 0.7900 TestAcc 0.7545 0.7750
epoch 1100 LossPred 0.6878 LossAtt 0.4466 TrainAcc 0.7400 TestAcc 0.7232 0.7350
epoch 1200 LossPred 0.9204 LossAtt 0.4159 TrainAcc 0.6300 TestAcc 0.6341 0.6250
epoch 1300 LossPred 0.6352 LossAtt 0.4247 TrainAcc 0.7700 TestAcc 0.7595 0.7800
epoch 1400 LossPred 0.7057 LossAtt 0.4111 TrainAcc 0.7400 TestAcc 0.7112 0.7250
epoch 1500 LossPred 0.6723 LossAtt 0.3763 TrainAcc 0.7400 TestAcc 0.7270 0.7350
epoch 1600 LossPred 0.5805 LossAtt 0.3849 TrainAcc 0.8000 TestAcc 0.7397 0.8000
epoch 1700 LossPred 0.6719 LossAtt 0.3880 TrainAcc 0.7400 TestAcc 0.6814 0.7350
epoch 1800 LossPred 0.5108 LossAtt 0.3824 TrainAcc 0.8300 TestAcc 0.7788 0.8350
epoch 1900 LossPred 0.5264 LossAtt 0.3804 TrainAcc 0.8300 TestAcc 0.7738 0.8350
epoch 2000 LossPred 0.5000 LossAtt 0.4012 TrainAcc 0.8500 TestAcc 0.7678 0.8300
epoch 2100 LossPred 0.5512 LossAtt 0.3719 TrainAcc 0.8200 TestAcc 0.7688 0.8100
epoch 2200 LossPred 0.5266 LossAtt 0.3441 TrainAcc 0.8300 TestAcc 0.7863 0.8400
epoch 2300 LossPred 0.4546 LossAtt 0.3644 TrainAcc 0.8600 TestAcc 0.7918 0.8450
epoch 2400 LossPred 0.4143 LossAtt 0.3581 TrainAcc 0.8800 TestAcc 0.8373 0.8500
epoch 2500 LossPred 0.4533 LossAtt 0.3522 TrainAcc 0.8600 TestAcc 0.8113 0.8500
Optimization Finished!
********** replication  11  **********
epoch   0 LossPred 1.1871 LossAtt 1.0053 TrainAcc 0.5700 TestAcc 0.5898 0.5400
epoch 100 LossPred 0.9807 LossAtt 0.4501 TrainAcc 0.5700 TestAcc 0.5898 0.5700
epoch 200 LossPred 0.9394 LossAtt 0.4279 TrainAcc 0.6000 TestAcc 0.6074 0.6100
epoch 300 LossPred 0.9183 LossAtt 0.3772 TrainAcc 0.6400 TestAcc 0.6001 0.6350
epoch 400 LossPred 0.9124 LossAtt 0.3884 TrainAcc 0.6400 TestAcc 0.6001 0.6400
epoch 500 LossPred 0.9020 LossAtt 0.4252 TrainAcc 0.6400 TestAcc 0.6011 0.6300
epoch 600 LossPred 0.8950 LossAtt 0.3946 TrainAcc 0.6800 TestAcc 0.6006 0.6400
epoch 700 LossPred 0.8922 LossAtt 0.4219 TrainAcc 0.6600 TestAcc 0.6024 0.6550
epoch 800 LossPred 0.8939 LossAtt 0.4042 TrainAcc 0.6300 TestAcc 0.6011 0.6350
epoch 900 LossPred 0.8852 LossAtt 0.4261 TrainAcc 0.6600 TestAcc 0.6151 0.6550
epoch 1000 LossPred 0.8031 LossAtt 0.5534 TrainAcc 0.7000 TestAcc 0.6819 0.7000
epoch 1100 LossPred 0.3964 LossAtt 0.6144 TrainAcc 0.9000 TestAcc 0.8468 0.8650
epoch 1200 LossPred 0.3768 LossAtt 0.5600 TrainAcc 0.8700 TestAcc 0.8431 0.8900
epoch 1300 LossPred 0.3515 LossAtt 0.5422 TrainAcc 0.8800 TestAcc 0.8481 0.9000
epoch 1400 LossPred 0.2659 LossAtt 0.5605 TrainAcc 0.9000 TestAcc 0.8554 0.9250
epoch 1500 LossPred 0.2568 LossAtt 0.5170 TrainAcc 0.9100 TestAcc 0.8614 0.9100
epoch 1600 LossPred 0.2685 LossAtt 0.4940 TrainAcc 0.9100 TestAcc 0.8549 0.9000
epoch 1700 LossPred 0.3486 LossAtt 0.4752 TrainAcc 0.8700 TestAcc 0.8604 0.8800
epoch 1800 LossPred 0.3434 LossAtt 0.4403 TrainAcc 0.8700 TestAcc 0.8596 0.8850
epoch 1900 LossPred 0.3528 LossAtt 0.4297 TrainAcc 0.8700 TestAcc 0.8659 0.8900
epoch 2000 LossPred 0.2862 LossAtt 0.4252 TrainAcc 0.9000 TestAcc 0.8629 0.8950
epoch 2100 LossPred 0.2732 LossAtt 0.4086 TrainAcc 0.9100 TestAcc 0.8544 0.9000
epoch 2200 LossPred 0.2767 LossAtt 0.3914 TrainAcc 0.9000 TestAcc 0.8549 0.8950
epoch 2300 LossPred 0.2840 LossAtt 0.4065 TrainAcc 0.8900 TestAcc 0.8601 0.8850
epoch 2400 LossPred 0.2598 LossAtt 0.3946 TrainAcc 0.9000 TestAcc 0.8534 0.8900
epoch 2500 LossPred 0.2840 LossAtt 0.3811 TrainAcc 0.8900 TestAcc 0.8526 0.8950
Optimization Finished!
********** replication  12  **********
epoch   0 LossPred 1.3986 LossAtt 1.0101 TrainAcc 0.4900 TestAcc 0.5100 0.4500
epoch 100 LossPred 1.0644 LossAtt 0.5205 TrainAcc 0.5300 TestAcc 0.5180 0.5350
epoch 200 LossPred 0.9566 LossAtt 0.5299 TrainAcc 0.5300 TestAcc 0.5313 0.5300
epoch 300 LossPred 0.9260 LossAtt 0.5596 TrainAcc 0.6100 TestAcc 0.5428 0.5800
epoch 400 LossPred 0.8855 LossAtt 0.5950 TrainAcc 0.6700 TestAcc 0.5328 0.6500
epoch 500 LossPred 0.8244 LossAtt 0.5865 TrainAcc 0.6800 TestAcc 0.5506 0.6950
epoch 600 LossPred 0.4218 LossAtt 0.5591 TrainAcc 0.8700 TestAcc 0.8246 0.8400
epoch 700 LossPred 0.4232 LossAtt 0.5801 TrainAcc 0.8600 TestAcc 0.8153 0.8450
epoch 800 LossPred 0.3615 LossAtt 0.5740 TrainAcc 0.9000 TestAcc 0.8266 0.8700
epoch 900 LossPred 0.2952 LossAtt 0.5829 TrainAcc 0.9100 TestAcc 0.8423 0.8800
epoch 1000 LossPred 0.2613 LossAtt 0.5462 TrainAcc 0.9300 TestAcc 0.8446 0.8900
epoch 1100 LossPred 0.2726 LossAtt 0.5303 TrainAcc 0.9200 TestAcc 0.8246 0.8800
epoch 1200 LossPred 0.2386 LossAtt 0.5178 TrainAcc 0.9300 TestAcc 0.8431 0.8850
epoch 1300 LossPred 0.2871 LossAtt 0.5509 TrainAcc 0.9000 TestAcc 0.8476 0.8850
epoch 1400 LossPred 0.2235 LossAtt 0.4989 TrainAcc 0.9500 TestAcc 0.8468 0.8950
epoch 1500 LossPred 0.2920 LossAtt 0.4883 TrainAcc 0.9100 TestAcc 0.8158 0.8950
epoch 1600 LossPred 0.2962 LossAtt 0.5250 TrainAcc 0.9000 TestAcc 0.8401 0.8800
epoch 1700 LossPred 0.2763 LossAtt 0.5207 TrainAcc 0.9100 TestAcc 0.8453 0.8800
epoch 1800 LossPred 0.2096 LossAtt 0.4825 TrainAcc 0.9300 TestAcc 0.8386 0.8950
epoch 1900 LossPred 0.2799 LossAtt 0.4781 TrainAcc 0.9200 TestAcc 0.8066 0.8950
epoch 2000 LossPred 0.2431 LossAtt 0.4765 TrainAcc 0.9400 TestAcc 0.8258 0.8950
epoch 2100 LossPred 0.2842 LossAtt 0.4510 TrainAcc 0.9200 TestAcc 0.8221 0.8950
epoch 2200 LossPred 0.2298 LossAtt 0.4911 TrainAcc 0.9400 TestAcc 0.8421 0.8800
epoch 2300 LossPred 0.2898 LossAtt 0.4991 TrainAcc 0.9200 TestAcc 0.8211 0.8750
epoch 2400 LossPred 0.3176 LossAtt 0.5220 TrainAcc 0.9000 TestAcc 0.8273 0.8800
epoch 2500 LossPred 0.2353 LossAtt 0.4861 TrainAcc 0.9300 TestAcc 0.8276 0.8950
Optimization Finished!
********** replication  13  **********
epoch   0 LossPred 1.0882 LossAtt 1.0260 TrainAcc 0.4700 TestAcc 0.4797 0.4650
epoch 100 LossPred 0.9015 LossAtt 0.4169 TrainAcc 0.6100 TestAcc 0.5821 0.6100
epoch 200 LossPred 0.8772 LossAtt 0.3918 TrainAcc 0.6100 TestAcc 0.5821 0.6100
epoch 300 LossPred 0.8090 LossAtt 0.4436 TrainAcc 0.7300 TestAcc 0.6649 0.6900
epoch 400 LossPred 0.4240 LossAtt 0.3932 TrainAcc 0.8700 TestAcc 0.8273 0.8300
epoch 500 LossPred 0.3720 LossAtt 0.3900 TrainAcc 0.8900 TestAcc 0.8111 0.8850
epoch 600 LossPred 0.3772 LossAtt 0.3625 TrainAcc 0.8900 TestAcc 0.8056 0.8900
epoch 700 LossPred 0.4481 LossAtt 0.3501 TrainAcc 0.8500 TestAcc 0.8166 0.8500
epoch 800 LossPred 0.4326 LossAtt 0.3699 TrainAcc 0.8500 TestAcc 0.8096 0.8700
epoch 900 LossPred 0.3797 LossAtt 0.3633 TrainAcc 0.8700 TestAcc 0.8356 0.8650
epoch 1000 LossPred 0.3444 LossAtt 0.3778 TrainAcc 0.8900 TestAcc 0.8323 0.8800
epoch 1100 LossPred 0.3534 LossAtt 0.3748 TrainAcc 0.8900 TestAcc 0.8183 0.8800
epoch 1200 LossPred 0.3379 LossAtt 0.3672 TrainAcc 0.9000 TestAcc 0.8246 0.8800
epoch 1300 LossPred 0.3643 LossAtt 0.3729 TrainAcc 0.8800 TestAcc 0.8226 0.8850
epoch 1400 LossPred 0.4086 LossAtt 0.3637 TrainAcc 0.8700 TestAcc 0.8151 0.8550
epoch 1500 LossPred 0.3449 LossAtt 0.3559 TrainAcc 0.8800 TestAcc 0.8321 0.8650
epoch 1600 LossPred 0.3653 LossAtt 0.3592 TrainAcc 0.8800 TestAcc 0.8283 0.8600
epoch 1700 LossPred 0.3154 LossAtt 0.3510 TrainAcc 0.8900 TestAcc 0.8128 0.8800
epoch 1800 LossPred 0.5685 LossAtt 0.3611 TrainAcc 0.8000 TestAcc 0.7683 0.8000
epoch 1900 LossPred 0.3788 LossAtt 0.3513 TrainAcc 0.8900 TestAcc 0.7978 0.8550
epoch 2000 LossPred 0.3620 LossAtt 0.3555 TrainAcc 0.8900 TestAcc 0.8226 0.8300
epoch 2100 LossPred 0.3380 LossAtt 0.3323 TrainAcc 0.9000 TestAcc 0.8341 0.8750
epoch 2200 LossPred 0.3887 LossAtt 0.3257 TrainAcc 0.8900 TestAcc 0.8111 0.8350
epoch 2300 LossPred 0.5298 LossAtt 0.3192 TrainAcc 0.8500 TestAcc 0.8158 0.8250
epoch 2400 LossPred 0.8947 LossAtt 0.1739 TrainAcc 0.6100 TestAcc 0.5821 0.6100
epoch 2500 LossPred 0.9052 LossAtt 0.1601 TrainAcc 0.6100 TestAcc 0.5821 0.6100
Optimization Finished!
********** replication  14  **********
epoch   0 LossPred 1.0948 LossAtt 1.0213 TrainAcc 0.4900 TestAcc 0.4354 0.4850
epoch 100 LossPred 0.9939 LossAtt 0.3658 TrainAcc 0.5900 TestAcc 0.6286 0.5850
epoch 200 LossPred 0.9786 LossAtt 0.3935 TrainAcc 0.6000 TestAcc 0.6296 0.6100
epoch 300 LossPred 0.9423 LossAtt 0.3532 TrainAcc 0.6100 TestAcc 0.5813 0.6350
epoch 400 LossPred 0.9250 LossAtt 0.3484 TrainAcc 0.6000 TestAcc 0.5551 0.6050
epoch 500 LossPred 0.9144 LossAtt 0.3464 TrainAcc 0.6200 TestAcc 0.5528 0.6500
epoch 600 LossPred 0.9155 LossAtt 0.3508 TrainAcc 0.6400 TestAcc 0.5353 0.6600
epoch 700 LossPred 0.9110 LossAtt 0.3716 TrainAcc 0.6300 TestAcc 0.5260 0.6250
epoch 800 LossPred 0.9031 LossAtt 0.3499 TrainAcc 0.6300 TestAcc 0.5423 0.6300
epoch 900 LossPred 0.9048 LossAtt 0.3107 TrainAcc 0.6600 TestAcc 0.5588 0.6600
epoch 1000 LossPred 0.9396 LossAtt 0.3391 TrainAcc 0.5900 TestAcc 0.5781 0.6050
epoch 1100 LossPred 0.9373 LossAtt 0.3449 TrainAcc 0.6000 TestAcc 0.5463 0.6250
epoch 1200 LossPred 0.9260 LossAtt 0.3259 TrainAcc 0.6100 TestAcc 0.5518 0.6200
epoch 1300 LossPred 0.9197 LossAtt 0.3751 TrainAcc 0.5800 TestAcc 0.5198 0.5850
epoch 1400 LossPred 0.9206 LossAtt 0.3613 TrainAcc 0.5800 TestAcc 0.5325 0.5750
epoch 1500 LossPred 0.9259 LossAtt 0.3369 TrainAcc 0.6100 TestAcc 0.5438 0.5900
epoch 1600 LossPred 0.9070 LossAtt 0.3676 TrainAcc 0.6300 TestAcc 0.5533 0.5950
epoch 1700 LossPred 0.9124 LossAtt 0.3466 TrainAcc 0.6400 TestAcc 0.5350 0.6250
epoch 1800 LossPred 0.9079 LossAtt 0.3417 TrainAcc 0.6500 TestAcc 0.5358 0.6300
epoch 1900 LossPred 0.9345 LossAtt 0.3095 TrainAcc 0.6300 TestAcc 0.5345 0.6400
epoch 2000 LossPred 0.9312 LossAtt 0.3094 TrainAcc 0.6500 TestAcc 0.5405 0.6450
epoch 2100 LossPred 0.9016 LossAtt 0.3203 TrainAcc 0.6700 TestAcc 0.5438 0.6400
epoch 2200 LossPred 0.8872 LossAtt 0.3063 TrainAcc 0.6600 TestAcc 0.5776 0.6200
epoch 2300 LossPred 0.8852 LossAtt 0.3113 TrainAcc 0.6600 TestAcc 0.5768 0.6250
epoch 2400 LossPred 0.8936 LossAtt 0.3194 TrainAcc 0.6700 TestAcc 0.5826 0.6450
epoch 2500 LossPred 0.9010 LossAtt 0.2989 TrainAcc 0.6500 TestAcc 0.5841 0.6100
Optimization Finished!
********** replication  15  **********
epoch   0 LossPred 1.0389 LossAtt 1.0502 TrainAcc 0.4800 TestAcc 0.4905 0.4900
epoch 100 LossPred 0.9083 LossAtt 0.4315 TrainAcc 0.6000 TestAcc 0.5963 0.6000
epoch 200 LossPred 0.8884 LossAtt 0.3833 TrainAcc 0.6600 TestAcc 0.6339 0.6550
epoch 300 LossPred 0.8776 LossAtt 0.3966 TrainAcc 0.6600 TestAcc 0.6339 0.6600
epoch 400 LossPred 0.8752 LossAtt 0.3671 TrainAcc 0.6600 TestAcc 0.6339 0.6600
epoch 500 LossPred 0.8693 LossAtt 0.3874 TrainAcc 0.6700 TestAcc 0.6049 0.6700
epoch 600 LossPred 0.8621 LossAtt 0.4204 TrainAcc 0.6700 TestAcc 0.6054 0.6700
epoch 700 LossPred 0.8492 LossAtt 0.4378 TrainAcc 0.6800 TestAcc 0.6131 0.6750
epoch 800 LossPred 0.7366 LossAtt 0.4760 TrainAcc 0.7800 TestAcc 0.7355 0.7850
epoch 900 LossPred 0.5891 LossAtt 0.3444 TrainAcc 0.8000 TestAcc 0.8023 0.8150
epoch 1000 LossPred 0.3596 LossAtt 0.3528 TrainAcc 0.8900 TestAcc 0.9044 0.9000
epoch 1100 LossPred 0.4398 LossAtt 0.3428 TrainAcc 0.8500 TestAcc 0.8946 0.8350
epoch 1200 LossPred 0.4631 LossAtt 0.3393 TrainAcc 0.8300 TestAcc 0.8776 0.8350
epoch 1300 LossPred 0.4039 LossAtt 0.3288 TrainAcc 0.8600 TestAcc 0.8691 0.8700
epoch 1400 LossPred 0.5407 LossAtt 0.3510 TrainAcc 0.8100 TestAcc 0.8056 0.8100
epoch 1500 LossPred 0.3459 LossAtt 0.3308 TrainAcc 0.8800 TestAcc 0.8894 0.8750
epoch 1600 LossPred 0.4367 LossAtt 0.3374 TrainAcc 0.8600 TestAcc 0.8994 0.8550
epoch 1700 LossPred 0.3700 LossAtt 0.3513 TrainAcc 0.8800 TestAcc 0.8844 0.8800
epoch 1800 LossPred 0.3505 LossAtt 0.3527 TrainAcc 0.8800 TestAcc 0.9102 0.8850
epoch 1900 LossPred 0.3417 LossAtt 0.3573 TrainAcc 0.8800 TestAcc 0.9112 0.8800
epoch 2000 LossPred 0.3797 LossAtt 0.3603 TrainAcc 0.8700 TestAcc 0.9062 0.8700
epoch 2100 LossPred 0.2940 LossAtt 0.4049 TrainAcc 0.9100 TestAcc 0.9052 0.9100
epoch 2200 LossPred 0.3827 LossAtt 0.4011 TrainAcc 0.8700 TestAcc 0.8231 0.8400
epoch 2300 LossPred 0.2744 LossAtt 0.4243 TrainAcc 0.9100 TestAcc 0.8991 0.9250
epoch 2400 LossPred 0.7703 LossAtt 0.4093 TrainAcc 0.7300 TestAcc 0.7320 0.7250
epoch 2500 LossPred 0.6205 LossAtt 0.4212 TrainAcc 0.8100 TestAcc 0.7760 0.7950
Optimization Finished!
********** replication  16  **********
epoch   0 LossPred 1.0090 LossAtt 1.0066 TrainAcc 0.5500 TestAcc 0.4832 0.5550
epoch 100 LossPred 0.8932 LossAtt 0.4864 TrainAcc 0.6400 TestAcc 0.5503 0.6500
epoch 200 LossPred 0.8727 LossAtt 0.3958 TrainAcc 0.6400 TestAcc 0.5480 0.6400
epoch 300 LossPred 0.8714 LossAtt 0.4072 TrainAcc 0.6400 TestAcc 0.5480 0.6500
epoch 400 LossPred 0.8673 LossAtt 0.3978 TrainAcc 0.6300 TestAcc 0.5330 0.6250
epoch 500 LossPred 0.8621 LossAtt 0.3820 TrainAcc 0.6400 TestAcc 0.5178 0.6400
epoch 600 LossPred 0.8584 LossAtt 0.3714 TrainAcc 0.6500 TestAcc 0.5198 0.6500
epoch 700 LossPred 0.8561 LossAtt 0.3689 TrainAcc 0.6500 TestAcc 0.5198 0.6500
epoch 800 LossPred 0.8492 LossAtt 0.3671 TrainAcc 0.6500 TestAcc 0.5193 0.6500
epoch 900 LossPred 0.8461 LossAtt 0.3622 TrainAcc 0.6400 TestAcc 0.5215 0.6550
epoch 1000 LossPred 0.8355 LossAtt 0.4022 TrainAcc 0.6800 TestAcc 0.5606 0.6750
epoch 1100 LossPred 0.8307 LossAtt 0.3899 TrainAcc 0.6800 TestAcc 0.5638 0.6700
epoch 1200 LossPred 0.8312 LossAtt 0.4360 TrainAcc 0.6800 TestAcc 0.5638 0.6800
epoch 1300 LossPred 0.8213 LossAtt 0.4980 TrainAcc 0.6800 TestAcc 0.5653 0.6850
epoch 1400 LossPred 0.8075 LossAtt 0.5392 TrainAcc 0.7200 TestAcc 0.5656 0.7000
epoch 1500 LossPred 0.8009 LossAtt 0.5058 TrainAcc 0.7200 TestAcc 0.5693 0.7100
epoch 1600 LossPred 0.7963 LossAtt 0.5018 TrainAcc 0.7200 TestAcc 0.5668 0.6950
epoch 1700 LossPred 0.7956 LossAtt 0.4876 TrainAcc 0.7000 TestAcc 0.5681 0.7050
epoch 1800 LossPred 0.7970 LossAtt 0.4971 TrainAcc 0.7000 TestAcc 0.5653 0.7000
epoch 1900 LossPred 0.7993 LossAtt 0.5185 TrainAcc 0.7100 TestAcc 0.5601 0.6950
epoch 2000 LossPred 0.7944 LossAtt 0.5305 TrainAcc 0.7000 TestAcc 0.5458 0.7000
epoch 2100 LossPred 0.7785 LossAtt 0.5035 TrainAcc 0.6900 TestAcc 0.5490 0.6800
epoch 2200 LossPred 0.7628 LossAtt 0.5069 TrainAcc 0.7100 TestAcc 0.5721 0.6850
epoch 2300 LossPred 0.7783 LossAtt 0.4539 TrainAcc 0.7500 TestAcc 0.5808 0.7150
epoch 2400 LossPred 0.7835 LossAtt 0.4880 TrainAcc 0.7300 TestAcc 0.5863 0.7350
epoch 2500 LossPred 0.7403 LossAtt 0.5131 TrainAcc 0.7400 TestAcc 0.5911 0.7250
Optimization Finished!
********** replication  17  **********
epoch   0 LossPred 1.1888 LossAtt 1.0202 TrainAcc 0.5500 TestAcc 0.5453 0.5550
epoch 100 LossPred 0.9034 LossAtt 0.3939 TrainAcc 0.6600 TestAcc 0.5848 0.6600
epoch 200 LossPred 0.8473 LossAtt 0.3792 TrainAcc 0.6600 TestAcc 0.5848 0.6650
epoch 300 LossPred 0.8112 LossAtt 0.3733 TrainAcc 0.7200 TestAcc 0.6356 0.7250
epoch 400 LossPred 0.7935 LossAtt 0.3773 TrainAcc 0.7400 TestAcc 0.6471 0.7300
epoch 500 LossPred 0.7925 LossAtt 0.2787 TrainAcc 0.7400 TestAcc 0.6527 0.7100
epoch 600 LossPred 0.7837 LossAtt 0.2572 TrainAcc 0.7000 TestAcc 0.6396 0.7100
epoch 700 LossPred 0.7312 LossAtt 0.3126 TrainAcc 0.7800 TestAcc 0.6759 0.7600
epoch 800 LossPred 0.7516 LossAtt 0.2819 TrainAcc 0.7300 TestAcc 0.6306 0.7300
epoch 900 LossPred 0.3605 LossAtt 0.2912 TrainAcc 0.8900 TestAcc 0.9012 0.8700
epoch 1000 LossPred 0.2553 LossAtt 0.2909 TrainAcc 0.9100 TestAcc 0.8944 0.9100
epoch 1100 LossPred 0.6416 LossAtt 0.3017 TrainAcc 0.7700 TestAcc 0.7337 0.7650
epoch 1200 LossPred 0.4820 LossAtt 0.3004 TrainAcc 0.8300 TestAcc 0.8088 0.8350
epoch 1300 LossPred 0.5640 LossAtt 0.2785 TrainAcc 0.7900 TestAcc 0.8391 0.7900
epoch 1400 LossPred 0.3071 LossAtt 0.2846 TrainAcc 0.9200 TestAcc 0.8874 0.9000
epoch 1500 LossPred 0.2468 LossAtt 0.2800 TrainAcc 0.9600 TestAcc 0.8996 0.9300
epoch 1600 LossPred 0.2070 LossAtt 0.2894 TrainAcc 0.9700 TestAcc 0.9232 0.9450
epoch 1700 LossPred 0.3627 LossAtt 0.2996 TrainAcc 0.8600 TestAcc 0.8529 0.8550
epoch 1800 LossPred 0.2002 LossAtt 0.2984 TrainAcc 0.9700 TestAcc 0.9322 0.9450
epoch 1900 LossPred 0.1926 LossAtt 0.3045 TrainAcc 0.9500 TestAcc 0.9312 0.9450
epoch 2000 LossPred 0.2214 LossAtt 0.3226 TrainAcc 0.9600 TestAcc 0.9319 0.9300
epoch 2100 LossPred 0.2820 LossAtt 0.3190 TrainAcc 0.9300 TestAcc 0.9169 0.8950
epoch 2200 LossPred 0.1995 LossAtt 0.3130 TrainAcc 0.9800 TestAcc 0.9427 0.9450
epoch 2300 LossPred 0.4204 LossAtt 0.3324 TrainAcc 0.8500 TestAcc 0.8283 0.8450
epoch 2400 LossPred 0.1815 LossAtt 0.3158 TrainAcc 0.9700 TestAcc 0.9304 0.9450
epoch 2500 LossPred 0.3625 LossAtt 0.3208 TrainAcc 0.9000 TestAcc 0.8984 0.8650
Optimization Finished!
********** replication  18  **********
epoch   0 LossPred 1.1189 LossAtt 1.0149 TrainAcc 0.5500 TestAcc 0.4907 0.5050
epoch 100 LossPred 0.8849 LossAtt 0.4718 TrainAcc 0.6600 TestAcc 0.5410 0.6850
epoch 200 LossPred 0.8386 LossAtt 0.3466 TrainAcc 0.6600 TestAcc 0.5410 0.6600
epoch 300 LossPred 0.8263 LossAtt 0.3027 TrainAcc 0.6600 TestAcc 0.5410 0.6650
epoch 400 LossPred 0.8193 LossAtt 0.2401 TrainAcc 0.6600 TestAcc 0.5410 0.6700
epoch 500 LossPred 0.8224 LossAtt 0.2107 TrainAcc 0.6600 TestAcc 0.5851 0.6750
epoch 600 LossPred 0.8217 LossAtt 0.2147 TrainAcc 0.6600 TestAcc 0.5851 0.6750
epoch 700 LossPred 0.8167 LossAtt 0.1981 TrainAcc 0.6600 TestAcc 0.5851 0.6700
epoch 800 LossPred 0.8147 LossAtt 0.2209 TrainAcc 0.6600 TestAcc 0.5851 0.6800
epoch 900 LossPred 0.8215 LossAtt 0.2048 TrainAcc 0.6600 TestAcc 0.5851 0.6600
epoch 1000 LossPred 0.8252 LossAtt 0.1521 TrainAcc 0.6600 TestAcc 0.5851 0.6550
epoch 1100 LossPred 0.8142 LossAtt 0.1162 TrainAcc 0.6600 TestAcc 0.5851 0.6550
epoch 1200 LossPred 0.8026 LossAtt 0.1742 TrainAcc 0.6600 TestAcc 0.5851 0.6550
epoch 1300 LossPred 0.7957 LossAtt 0.2237 TrainAcc 0.6700 TestAcc 0.5773 0.6900
epoch 1400 LossPred 0.7903 LossAtt 0.1983 TrainAcc 0.7100 TestAcc 0.5843 0.6850
epoch 1500 LossPred 0.7846 LossAtt 0.1870 TrainAcc 0.6600 TestAcc 0.5851 0.6700
epoch 1600 LossPred 0.7425 LossAtt 0.2958 TrainAcc 0.7200 TestAcc 0.6527 0.7200
epoch 1700 LossPred 0.8357 LossAtt 0.1985 TrainAcc 0.6600 TestAcc 0.5851 0.6700
epoch 1800 LossPred 0.8246 LossAtt 0.1824 TrainAcc 0.6900 TestAcc 0.6221 0.6900
epoch 1900 LossPred 0.8144 LossAtt 0.1982 TrainAcc 0.6600 TestAcc 0.6406 0.6950
epoch 2000 LossPred 0.8075 LossAtt 0.1871 TrainAcc 0.7200 TestAcc 0.6476 0.7000
epoch 2100 LossPred 0.8053 LossAtt 0.1899 TrainAcc 0.6900 TestAcc 0.6484 0.6850
epoch 2200 LossPred 0.8074 LossAtt 0.1929 TrainAcc 0.6600 TestAcc 0.6406 0.6800
epoch 2300 LossPred 0.8053 LossAtt 0.1943 TrainAcc 0.6600 TestAcc 0.6406 0.6700
epoch 2400 LossPred 0.7849 LossAtt 0.2460 TrainAcc 0.7200 TestAcc 0.6476 0.7200
epoch 2500 LossPred 0.6904 LossAtt 0.3772 TrainAcc 0.7900 TestAcc 0.7262 0.7700
Optimization Finished!
********** replication  19  **********
epoch   0 LossPred 1.0418 LossAtt 0.9986 TrainAcc 0.4500 TestAcc 0.4797 0.4600
epoch 100 LossPred 0.8795 LossAtt 0.4477 TrainAcc 0.6200 TestAcc 0.5293 0.6200
epoch 200 LossPred 0.6248 LossAtt 0.5458 TrainAcc 0.8300 TestAcc 0.7035 0.8300
epoch 300 LossPred 0.5637 LossAtt 0.6105 TrainAcc 0.7900 TestAcc 0.7883 0.7950
epoch 400 LossPred 0.3146 LossAtt 0.5737 TrainAcc 0.9000 TestAcc 0.8216 0.9150
epoch 500 LossPred 0.2101 LossAtt 0.5292 TrainAcc 0.9300 TestAcc 0.8831 0.9500
epoch 600 LossPred 0.1837 LossAtt 0.4866 TrainAcc 0.9800 TestAcc 0.8904 0.9500
epoch 700 LossPred 0.3757 LossAtt 0.4478 TrainAcc 0.8800 TestAcc 0.7913 0.8900
epoch 800 LossPred 0.1687 LossAtt 0.4128 TrainAcc 0.9400 TestAcc 0.8901 0.9600
epoch 900 LossPred 0.3583 LossAtt 0.3759 TrainAcc 0.8600 TestAcc 0.7973 0.8750
epoch 1000 LossPred 0.3336 LossAtt 0.3785 TrainAcc 0.8800 TestAcc 0.8596 0.8700
epoch 1100 LossPred 0.5463 LossAtt 0.3818 TrainAcc 0.8100 TestAcc 0.7588 0.8100
epoch 1200 LossPred 0.1237 LossAtt 0.3804 TrainAcc 0.9700 TestAcc 0.8689 0.9800
epoch 1300 LossPred 0.1773 LossAtt 0.3574 TrainAcc 0.9600 TestAcc 0.8739 0.9550
epoch 1400 LossPred 0.2978 LossAtt 0.3422 TrainAcc 0.9100 TestAcc 0.8579 0.9000
epoch 1500 LossPred 0.2062 LossAtt 0.3204 TrainAcc 0.9200 TestAcc 0.8431 0.9300
epoch 1600 LossPred 0.1800 LossAtt 0.3055 TrainAcc 0.9600 TestAcc 0.8506 0.9500
epoch 1700 LossPred 0.4379 LossAtt 0.3015 TrainAcc 0.8700 TestAcc 0.7823 0.8600
epoch 1800 LossPred 0.1853 LossAtt 0.3162 TrainAcc 0.9400 TestAcc 0.8829 0.9450
epoch 1900 LossPred 0.1672 LossAtt 0.3189 TrainAcc 0.9600 TestAcc 0.8819 0.9500
epoch 2000 LossPred 0.3806 LossAtt 0.3149 TrainAcc 0.8900 TestAcc 0.7995 0.8850
epoch 2100 LossPred 0.2554 LossAtt 0.3318 TrainAcc 0.9200 TestAcc 0.8296 0.9100
epoch 2200 LossPred 0.1786 LossAtt 0.3020 TrainAcc 0.9300 TestAcc 0.8574 0.9400
epoch 2300 LossPred 0.1781 LossAtt 0.3134 TrainAcc 0.9600 TestAcc 0.8729 0.9500
epoch 2400 LossPred 0.2918 LossAtt 0.3345 TrainAcc 0.9300 TestAcc 0.8136 0.9150
epoch 2500 LossPred 0.3301 LossAtt 0.3337 TrainAcc 0.8900 TestAcc 0.8561 0.8950
Optimization Finished!
********** replication  20  **********
epoch   0 LossPred 1.1643 LossAtt 1.0081 TrainAcc 0.5000 TestAcc 0.5008 0.5100
epoch 100 LossPred 0.9530 LossAtt 0.4672 TrainAcc 0.6300 TestAcc 0.6469 0.6300
epoch 200 LossPred 0.8238 LossAtt 0.4226 TrainAcc 0.6600 TestAcc 0.6657 0.6650
epoch 300 LossPred 0.7820 LossAtt 0.3969 TrainAcc 0.6800 TestAcc 0.7140 0.6900
epoch 400 LossPred 0.7554 LossAtt 0.3452 TrainAcc 0.7200 TestAcc 0.7375 0.6950
epoch 500 LossPred 0.4376 LossAtt 0.3430 TrainAcc 0.9100 TestAcc 0.8326 0.8650
epoch 600 LossPred 0.6678 LossAtt 0.3309 TrainAcc 0.7400 TestAcc 0.7653 0.7500
epoch 700 LossPred 0.4620 LossAtt 0.3248 TrainAcc 0.8800 TestAcc 0.7795 0.8350
epoch 800 LossPred 0.4208 LossAtt 0.3262 TrainAcc 0.8800 TestAcc 0.8031 0.8700
epoch 900 LossPred 0.4150 LossAtt 0.3177 TrainAcc 0.9000 TestAcc 0.7888 0.8500
epoch 1000 LossPred 0.4065 LossAtt 0.3122 TrainAcc 0.8900 TestAcc 0.8161 0.8700
epoch 1100 LossPred 0.4497 LossAtt 0.3112 TrainAcc 0.8700 TestAcc 0.8371 0.8450
epoch 1200 LossPred 0.4476 LossAtt 0.3086 TrainAcc 0.8600 TestAcc 0.8336 0.8500
epoch 1300 LossPred 0.3840 LossAtt 0.3038 TrainAcc 0.9100 TestAcc 0.8236 0.8750
epoch 1400 LossPred 0.3881 LossAtt 0.2862 TrainAcc 0.9000 TestAcc 0.8178 0.8750
epoch 1500 LossPred 0.6114 LossAtt 0.3114 TrainAcc 0.7800 TestAcc 0.8051 0.8100
epoch 1600 LossPred 0.4034 LossAtt 0.3124 TrainAcc 0.8900 TestAcc 0.8266 0.8750
epoch 1700 LossPred 0.3803 LossAtt 0.2853 TrainAcc 0.8900 TestAcc 0.8193 0.8800
epoch 1800 LossPred 0.3962 LossAtt 0.2877 TrainAcc 0.8900 TestAcc 0.8256 0.8700
epoch 1900 LossPred 0.4075 LossAtt 0.2756 TrainAcc 0.8800 TestAcc 0.7893 0.8700
epoch 2000 LossPred 0.4330 LossAtt 0.3080 TrainAcc 0.8700 TestAcc 0.8123 0.8700
epoch 2100 LossPred 0.5051 LossAtt 0.3130 TrainAcc 0.8400 TestAcc 0.8006 0.8600
epoch 2200 LossPred 0.4190 LossAtt 0.3063 TrainAcc 0.8600 TestAcc 0.7753 0.8550
epoch 2300 LossPred 0.3492 LossAtt 0.3013 TrainAcc 0.9000 TestAcc 0.8023 0.8750
epoch 2400 LossPred 0.4921 LossAtt 0.3327 TrainAcc 0.8400 TestAcc 0.8021 0.8700
epoch 2500 LossPred 0.4508 LossAtt 0.3115 TrainAcc 0.8700 TestAcc 0.8043 0.8800
Optimization Finished!
********** replication  21  **********
epoch   0 LossPred 0.9566 LossAtt 0.9921 TrainAcc 0.6000 TestAcc 0.4580 0.6050
epoch 100 LossPred 0.8938 LossAtt 0.4522 TrainAcc 0.6200 TestAcc 0.5876 0.6250
epoch 200 LossPred 0.8607 LossAtt 0.4661 TrainAcc 0.6200 TestAcc 0.5338 0.6550
epoch 300 LossPred 0.7560 LossAtt 0.5482 TrainAcc 0.7100 TestAcc 0.6962 0.6850
epoch 400 LossPred 0.4041 LossAtt 0.4646 TrainAcc 0.8700 TestAcc 0.8418 0.8650
epoch 500 LossPred 0.3112 LossAtt 0.4404 TrainAcc 0.8900 TestAcc 0.7933 0.8750
epoch 600 LossPred 0.3242 LossAtt 0.4430 TrainAcc 0.8800 TestAcc 0.8621 0.8800
epoch 700 LossPred 0.3072 LossAtt 0.4459 TrainAcc 0.9000 TestAcc 0.8536 0.8650
epoch 800 LossPred 0.2608 LossAtt 0.4651 TrainAcc 0.9000 TestAcc 0.8579 0.8900
epoch 900 LossPred 0.2577 LossAtt 0.4442 TrainAcc 0.9000 TestAcc 0.8343 0.9000
epoch 1000 LossPred 0.2884 LossAtt 0.4677 TrainAcc 0.8900 TestAcc 0.8176 0.8900
epoch 1100 LossPred 0.1793 LossAtt 0.4515 TrainAcc 0.9300 TestAcc 0.8544 0.8950
epoch 1200 LossPred 0.1718 LossAtt 0.4440 TrainAcc 0.9400 TestAcc 0.8651 0.9000
epoch 1300 LossPred 0.1755 LossAtt 0.4517 TrainAcc 0.9300 TestAcc 0.8706 0.8950
epoch 1400 LossPred 0.2106 LossAtt 0.4344 TrainAcc 0.9200 TestAcc 0.8529 0.9000
epoch 1500 LossPred 0.2147 LossAtt 0.4311 TrainAcc 0.9300 TestAcc 0.8711 0.9000
epoch 1600 LossPred 0.2567 LossAtt 0.4304 TrainAcc 0.9100 TestAcc 0.8759 0.8700
epoch 1700 LossPred 0.3720 LossAtt 0.4115 TrainAcc 0.8800 TestAcc 0.8616 0.8350
epoch 1800 LossPred 0.2403 LossAtt 0.4116 TrainAcc 0.9100 TestAcc 0.8546 0.8850
epoch 1900 LossPred 0.4008 LossAtt 0.4243 TrainAcc 0.8400 TestAcc 0.7968 0.8700
epoch 2000 LossPred 0.2420 LossAtt 0.4012 TrainAcc 0.9100 TestAcc 0.8411 0.8850
epoch 2100 LossPred 0.2609 LossAtt 0.3902 TrainAcc 0.9200 TestAcc 0.8516 0.8750
epoch 2200 LossPred 0.2731 LossAtt 0.3873 TrainAcc 0.9000 TestAcc 0.8534 0.8850
epoch 2300 LossPred 0.3097 LossAtt 0.3958 TrainAcc 0.8900 TestAcc 0.8574 0.8700
epoch 2400 LossPred 0.3516 LossAtt 0.3733 TrainAcc 0.8600 TestAcc 0.8411 0.8850
epoch 2500 LossPred 0.5484 LossAtt 0.3890 TrainAcc 0.8200 TestAcc 0.8211 0.8100
Optimization Finished!
********** replication  22  **********
epoch   0 LossPred 1.4281 LossAtt 1.0206 TrainAcc 0.4200 TestAcc 0.4124 0.4200
epoch 100 LossPred 0.9866 LossAtt 0.3575 TrainAcc 0.5600 TestAcc 0.5956 0.5600
epoch 200 LossPred 0.9596 LossAtt 0.2287 TrainAcc 0.5800 TestAcc 0.5886 0.5800
epoch 300 LossPred 0.9582 LossAtt 0.1791 TrainAcc 0.5800 TestAcc 0.5886 0.5800
epoch 400 LossPred 0.9559 LossAtt 0.1892 TrainAcc 0.5800 TestAcc 0.5886 0.5800
epoch 500 LossPred 0.9533 LossAtt 0.1803 TrainAcc 0.5800 TestAcc 0.5886 0.5800
epoch 600 LossPred 0.9498 LossAtt 0.2049 TrainAcc 0.5800 TestAcc 0.5886 0.5800
epoch 700 LossPred 0.9412 LossAtt 0.2444 TrainAcc 0.6000 TestAcc 0.6414 0.5750
epoch 800 LossPred 0.8522 LossAtt 0.3434 TrainAcc 0.6800 TestAcc 0.7307 0.6550
epoch 900 LossPred 0.4956 LossAtt 0.2935 TrainAcc 0.8700 TestAcc 0.8483 0.8150
epoch 1000 LossPred 0.3770 LossAtt 0.2717 TrainAcc 0.8900 TestAcc 0.8694 0.8400
epoch 1100 LossPred 0.3438 LossAtt 0.2628 TrainAcc 0.8800 TestAcc 0.8694 0.8550
epoch 1200 LossPred 0.3225 LossAtt 0.2717 TrainAcc 0.8900 TestAcc 0.8704 0.8500
epoch 1300 LossPred 0.3129 LossAtt 0.2580 TrainAcc 0.9000 TestAcc 0.8726 0.8500
epoch 1400 LossPred 0.2979 LossAtt 0.2616 TrainAcc 0.9000 TestAcc 0.8874 0.8500
epoch 1500 LossPred 0.2935 LossAtt 0.2611 TrainAcc 0.9000 TestAcc 0.8816 0.8750
epoch 1600 LossPred 0.2739 LossAtt 0.2631 TrainAcc 0.9300 TestAcc 0.8931 0.8700
epoch 1700 LossPred 0.3135 LossAtt 0.2733 TrainAcc 0.9200 TestAcc 0.9267 0.8600
epoch 1800 LossPred 0.6349 LossAtt 0.2548 TrainAcc 0.8000 TestAcc 0.8156 0.8200
epoch 1900 LossPred 0.3518 LossAtt 0.2619 TrainAcc 0.8700 TestAcc 0.8694 0.8750
epoch 2000 LossPred 0.2609 LossAtt 0.2710 TrainAcc 0.9200 TestAcc 0.8989 0.8700
epoch 2100 LossPred 0.2518 LossAtt 0.2753 TrainAcc 0.9200 TestAcc 0.8961 0.8750
epoch 2200 LossPred 0.2577 LossAtt 0.2738 TrainAcc 0.9300 TestAcc 0.9232 0.8650
epoch 2300 LossPred 0.3526 LossAtt 0.2814 TrainAcc 0.8800 TestAcc 0.8674 0.8900
epoch 2400 LossPred 0.2525 LossAtt 0.2783 TrainAcc 0.9200 TestAcc 0.9087 0.8600
epoch 2500 LossPred 0.2462 LossAtt 0.2912 TrainAcc 0.9300 TestAcc 0.9267 0.8550
Optimization Finished!
********** replication  23  **********
epoch   0 LossPred 1.2871 LossAtt 1.0040 TrainAcc 0.4000 TestAcc 0.4264 0.4350
epoch 100 LossPred 1.0006 LossAtt 0.4615 TrainAcc 0.4400 TestAcc 0.4755 0.4300
epoch 200 LossPred 0.9317 LossAtt 0.3765 TrainAcc 0.6500 TestAcc 0.6176 0.6400
epoch 300 LossPred 0.8888 LossAtt 0.3985 TrainAcc 0.6400 TestAcc 0.6296 0.6400
epoch 400 LossPred 0.8570 LossAtt 0.3906 TrainAcc 0.6500 TestAcc 0.6081 0.6500
epoch 500 LossPred 0.8282 LossAtt 0.4225 TrainAcc 0.6500 TestAcc 0.6081 0.6500
epoch 600 LossPred 0.7815 LossAtt 0.3940 TrainAcc 0.7000 TestAcc 0.6156 0.7000
epoch 700 LossPred 0.7481 LossAtt 0.4370 TrainAcc 0.7200 TestAcc 0.6466 0.7000
epoch 800 LossPred 0.9499 LossAtt 0.4836 TrainAcc 0.6600 TestAcc 0.6547 0.6250
epoch 900 LossPred 0.6210 LossAtt 0.4709 TrainAcc 0.7700 TestAcc 0.7795 0.7800
epoch 1000 LossPred 0.6266 LossAtt 0.4827 TrainAcc 0.8000 TestAcc 0.7990 0.7750
epoch 1100 LossPred 0.4729 LossAtt 0.4981 TrainAcc 0.8400 TestAcc 0.8351 0.8400
epoch 1200 LossPred 0.4168 LossAtt 0.5001 TrainAcc 0.8600 TestAcc 0.8386 0.8550
epoch 1300 LossPred 0.3972 LossAtt 0.5062 TrainAcc 0.8900 TestAcc 0.8443 0.8700
epoch 1400 LossPred 0.3856 LossAtt 0.5096 TrainAcc 0.8900 TestAcc 0.8456 0.8700
epoch 1500 LossPred 0.4358 LossAtt 0.5273 TrainAcc 0.8700 TestAcc 0.8248 0.8450
epoch 1600 LossPred 0.5384 LossAtt 0.5257 TrainAcc 0.8300 TestAcc 0.7973 0.8250
epoch 1700 LossPred 0.4566 LossAtt 0.5262 TrainAcc 0.8600 TestAcc 0.8151 0.8500
epoch 1800 LossPred 0.4025 LossAtt 0.4962 TrainAcc 0.8800 TestAcc 0.8331 0.8750
epoch 1900 LossPred 0.4861 LossAtt 0.5160 TrainAcc 0.8500 TestAcc 0.8316 0.8300
epoch 2000 LossPred 0.4049 LossAtt 0.5039 TrainAcc 0.8500 TestAcc 0.8491 0.8350
epoch 2100 LossPred 0.5691 LossAtt 0.5155 TrainAcc 0.8000 TestAcc 0.8046 0.7750
epoch 2200 LossPred 0.3703 LossAtt 0.5228 TrainAcc 0.8800 TestAcc 0.8471 0.8800
epoch 2300 LossPred 0.5484 LossAtt 0.4974 TrainAcc 0.8300 TestAcc 0.8361 0.8250
epoch 2400 LossPred 0.4282 LossAtt 0.5010 TrainAcc 0.8500 TestAcc 0.8606 0.8450
epoch 2500 LossPred 0.2936 LossAtt 0.4977 TrainAcc 0.9200 TestAcc 0.8541 0.9150
Optimization Finished!
********** replication  24  **********
epoch   0 LossPred 0.8830 LossAtt 1.0203 TrainAcc 0.6900 TestAcc 0.5786 0.6700
epoch 100 LossPred 0.8252 LossAtt 0.2296 TrainAcc 0.7100 TestAcc 0.5893 0.7100
epoch 200 LossPred 0.8247 LossAtt 0.1491 TrainAcc 0.7100 TestAcc 0.5893 0.7100
epoch 300 LossPred 0.8228 LossAtt 0.1589 TrainAcc 0.7100 TestAcc 0.5893 0.7100
epoch 400 LossPred 0.8218 LossAtt 0.1331 TrainAcc 0.7100 TestAcc 0.5893 0.7100
epoch 500 LossPred 0.8228 LossAtt 0.1082 TrainAcc 0.7100 TestAcc 0.5893 0.7100
epoch 600 LossPred 0.8233 LossAtt 0.0877 TrainAcc 0.7100 TestAcc 0.5893 0.7100
epoch 700 LossPred 0.8233 LossAtt 0.0793 TrainAcc 0.7100 TestAcc 0.5893 0.7100
epoch 800 LossPred 0.8232 LossAtt 0.0724 TrainAcc 0.7100 TestAcc 0.5893 0.7100
epoch 900 LossPred 0.8232 LossAtt 0.0783 TrainAcc 0.7100 TestAcc 0.5893 0.7100
epoch 1000 LossPred 0.8231 LossAtt 0.0728 TrainAcc 0.7100 TestAcc 0.5893 0.7100
epoch 1100 LossPred 0.8231 LossAtt 0.0682 TrainAcc 0.7100 TestAcc 0.5893 0.7100
epoch 1200 LossPred 0.8230 LossAtt 0.0738 TrainAcc 0.7100 TestAcc 0.5893 0.7100
epoch 1300 LossPred 0.8229 LossAtt 0.0806 TrainAcc 0.7100 TestAcc 0.5893 0.7100
epoch 1400 LossPred 0.8225 LossAtt 0.0956 TrainAcc 0.7100 TestAcc 0.5893 0.7100
epoch 1500 LossPred 0.8074 LossAtt 0.3501 TrainAcc 0.7100 TestAcc 0.5893 0.7100
epoch 1600 LossPred 0.7952 LossAtt 0.3712 TrainAcc 0.7100 TestAcc 0.5893 0.7100
epoch 1700 LossPred 0.7901 LossAtt 0.3604 TrainAcc 0.7100 TestAcc 0.5893 0.7100
epoch 1800 LossPred 0.6603 LossAtt 0.5230 TrainAcc 0.6900 TestAcc 0.6239 0.6950
epoch 1900 LossPred 0.3307 LossAtt 0.4911 TrainAcc 0.9100 TestAcc 0.8451 0.8550
epoch 2000 LossPred 0.4073 LossAtt 0.5000 TrainAcc 0.8700 TestAcc 0.8388 0.8750
epoch 2100 LossPred 0.4499 LossAtt 0.5161 TrainAcc 0.8500 TestAcc 0.8171 0.8500
epoch 2200 LossPred 0.2976 LossAtt 0.4964 TrainAcc 0.9300 TestAcc 0.8541 0.8800
epoch 2300 LossPred 0.6199 LossAtt 0.5012 TrainAcc 0.7900 TestAcc 0.7903 0.8200
epoch 2400 LossPred 0.6349 LossAtt 0.5426 TrainAcc 0.7700 TestAcc 0.7678 0.7850
epoch 2500 LossPred 0.2215 LossAtt 0.5435 TrainAcc 0.9500 TestAcc 0.8739 0.9150
Optimization Finished!
********** replication  25  **********
epoch   0 LossPred 1.2006 LossAtt 1.0275 TrainAcc 0.4600 TestAcc 0.4665 0.4500
epoch 100 LossPred 0.9672 LossAtt 0.3703 TrainAcc 0.6100 TestAcc 0.5723 0.5950
epoch 200 LossPred 0.8943 LossAtt 0.4340 TrainAcc 0.6400 TestAcc 0.5776 0.6350
epoch 300 LossPred 0.8622 LossAtt 0.3808 TrainAcc 0.6700 TestAcc 0.6271 0.6600
epoch 400 LossPred 0.7743 LossAtt 0.4752 TrainAcc 0.6900 TestAcc 0.6797 0.6900
epoch 500 LossPred 0.4044 LossAtt 0.3840 TrainAcc 0.8600 TestAcc 0.8451 0.8300
epoch 600 LossPred 0.4202 LossAtt 0.3803 TrainAcc 0.8600 TestAcc 0.8501 0.8150
epoch 700 LossPred 0.4121 LossAtt 0.4007 TrainAcc 0.8600 TestAcc 0.8524 0.8300
epoch 800 LossPred 0.3791 LossAtt 0.3797 TrainAcc 0.8800 TestAcc 0.8504 0.8200
epoch 900 LossPred 0.3960 LossAtt 0.3972 TrainAcc 0.8700 TestAcc 0.8443 0.8300
epoch 1000 LossPred 0.4710 LossAtt 0.3885 TrainAcc 0.8400 TestAcc 0.8323 0.8000
epoch 1100 LossPred 0.3986 LossAtt 0.3803 TrainAcc 0.8600 TestAcc 0.8483 0.8350
epoch 1200 LossPred 0.3846 LossAtt 0.3614 TrainAcc 0.8700 TestAcc 0.8348 0.8250
epoch 1300 LossPred 0.4405 LossAtt 0.3685 TrainAcc 0.8800 TestAcc 0.8446 0.8250
epoch 1400 LossPred 0.4591 LossAtt 0.3454 TrainAcc 0.8500 TestAcc 0.8343 0.8400
epoch 1500 LossPred 0.3901 LossAtt 0.3354 TrainAcc 0.8600 TestAcc 0.8383 0.8150
epoch 1600 LossPred 0.4161 LossAtt 0.3307 TrainAcc 0.8600 TestAcc 0.8401 0.8150
epoch 1700 LossPred 0.4632 LossAtt 0.3307 TrainAcc 0.8700 TestAcc 0.8296 0.8500
epoch 1800 LossPred 0.4372 LossAtt 0.3075 TrainAcc 0.8400 TestAcc 0.8318 0.8400
epoch 1900 LossPred 0.4502 LossAtt 0.2977 TrainAcc 0.8600 TestAcc 0.8438 0.8050
epoch 2000 LossPred 0.3745 LossAtt 0.2962 TrainAcc 0.8800 TestAcc 0.8471 0.8200
epoch 2100 LossPred 0.4445 LossAtt 0.3160 TrainAcc 0.8300 TestAcc 0.8316 0.8400
epoch 2200 LossPred 0.3907 LossAtt 0.2912 TrainAcc 0.8600 TestAcc 0.8441 0.8500
epoch 2300 LossPred 0.3712 LossAtt 0.2896 TrainAcc 0.8800 TestAcc 0.8448 0.8400
epoch 2400 LossPred 0.3667 LossAtt 0.2989 TrainAcc 0.8900 TestAcc 0.8534 0.8300
epoch 2500 LossPred 0.4316 LossAtt 0.2658 TrainAcc 0.8700 TestAcc 0.8386 0.8450
Optimization Finished!
********** replication  26  **********
epoch   0 LossPred 1.0036 LossAtt 0.9872 TrainAcc 0.5300 TestAcc 0.5288 0.4900
epoch 100 LossPred 0.9624 LossAtt 0.2948 TrainAcc 0.5800 TestAcc 0.6004 0.5800
epoch 200 LossPred 0.9611 LossAtt 0.2527 TrainAcc 0.5800 TestAcc 0.6004 0.5800
epoch 300 LossPred 0.9601 LossAtt 0.1908 TrainAcc 0.5800 TestAcc 0.6004 0.5800
epoch 400 LossPred 0.9592 LossAtt 0.1935 TrainAcc 0.5800 TestAcc 0.6004 0.5800
epoch 500 LossPred 0.7474 LossAtt 0.4914 TrainAcc 0.8000 TestAcc 0.8488 0.7900
epoch 600 LossPred 0.3878 LossAtt 0.4102 TrainAcc 0.9100 TestAcc 0.8413 0.8750
epoch 700 LossPred 0.3691 LossAtt 0.4106 TrainAcc 0.8600 TestAcc 0.8556 0.8350
epoch 800 LossPred 0.5343 LossAtt 0.3647 TrainAcc 0.8100 TestAcc 0.7588 0.8000
epoch 900 LossPred 0.2862 LossAtt 0.3548 TrainAcc 0.9300 TestAcc 0.8856 0.9100
epoch 1000 LossPred 0.2934 LossAtt 0.3501 TrainAcc 0.9100 TestAcc 0.8764 0.9050
epoch 1100 LossPred 0.2794 LossAtt 0.3581 TrainAcc 0.9100 TestAcc 0.8801 0.9100
epoch 1200 LossPred 0.2439 LossAtt 0.3466 TrainAcc 0.9400 TestAcc 0.9029 0.9100
epoch 1300 LossPred 0.2852 LossAtt 0.3533 TrainAcc 0.9100 TestAcc 0.8629 0.8950
epoch 1400 LossPred 0.2405 LossAtt 0.3387 TrainAcc 0.9400 TestAcc 0.8971 0.8950
epoch 1500 LossPred 0.2320 LossAtt 0.3417 TrainAcc 0.9500 TestAcc 0.8976 0.8850
epoch 1600 LossPred 0.2451 LossAtt 0.3383 TrainAcc 0.9400 TestAcc 0.8849 0.9050
epoch 1700 LossPred 0.2278 LossAtt 0.3457 TrainAcc 0.9400 TestAcc 0.9132 0.9050
epoch 1800 LossPred 0.3210 LossAtt 0.3521 TrainAcc 0.9000 TestAcc 0.8594 0.8900
epoch 1900 LossPred 0.2512 LossAtt 0.3317 TrainAcc 0.9300 TestAcc 0.8866 0.8900
epoch 2000 LossPred 0.2147 LossAtt 0.3335 TrainAcc 0.9200 TestAcc 0.8956 0.9050
epoch 2100 LossPred 0.4267 LossAtt 0.3587 TrainAcc 0.8600 TestAcc 0.8046 0.8550
epoch 2200 LossPred 0.2158 LossAtt 0.3510 TrainAcc 0.9400 TestAcc 0.9077 0.9100
epoch 2300 LossPred 0.2151 LossAtt 0.3671 TrainAcc 0.9100 TestAcc 0.8919 0.8950
epoch 2400 LossPred 0.2083 LossAtt 0.3518 TrainAcc 0.9500 TestAcc 0.9467 0.9150
epoch 2500 LossPred 0.2497 LossAtt 0.3682 TrainAcc 0.9000 TestAcc 0.8946 0.9050
Optimization Finished!
********** replication  27  **********
epoch   0 LossPred 0.9974 LossAtt 1.0557 TrainAcc 0.5900 TestAcc 0.5976 0.6050
epoch 100 LossPred 0.9471 LossAtt 0.4581 TrainAcc 0.6200 TestAcc 0.5931 0.5750
epoch 200 LossPred 0.9355 LossAtt 0.4353 TrainAcc 0.6000 TestAcc 0.6181 0.6250
epoch 300 LossPred 0.9219 LossAtt 0.4564 TrainAcc 0.6200 TestAcc 0.6316 0.6150
epoch 400 LossPred 0.8875 LossAtt 0.3997 TrainAcc 0.6300 TestAcc 0.6361 0.6250
epoch 500 LossPred 0.8506 LossAtt 0.4408 TrainAcc 0.6800 TestAcc 0.6684 0.6700
epoch 600 LossPred 0.5396 LossAtt 0.5054 TrainAcc 0.8500 TestAcc 0.8318 0.8250
epoch 700 LossPred 0.6104 LossAtt 0.4770 TrainAcc 0.8100 TestAcc 0.8018 0.8000
epoch 800 LossPred 0.5027 LossAtt 0.4669 TrainAcc 0.8500 TestAcc 0.8076 0.8400
epoch 900 LossPred 0.4652 LossAtt 0.4593 TrainAcc 0.8600 TestAcc 0.8043 0.8350
epoch 1000 LossPred 0.5175 LossAtt 0.4775 TrainAcc 0.8200 TestAcc 0.7963 0.8250
epoch 1100 LossPred 0.4478 LossAtt 0.4666 TrainAcc 0.8600 TestAcc 0.8116 0.8600
epoch 1200 LossPred 0.4940 LossAtt 0.4600 TrainAcc 0.8300 TestAcc 0.8026 0.8200
epoch 1300 LossPred 0.4310 LossAtt 0.4744 TrainAcc 0.8500 TestAcc 0.8191 0.8450
epoch 1400 LossPred 0.6351 LossAtt 0.4652 TrainAcc 0.7600 TestAcc 0.7885 0.7800
epoch 1500 LossPred 0.5672 LossAtt 0.4628 TrainAcc 0.8000 TestAcc 0.7770 0.8000
epoch 1600 LossPred 0.7808 LossAtt 0.4659 TrainAcc 0.7300 TestAcc 0.7407 0.7300
epoch 1700 LossPred 0.5674 LossAtt 0.4565 TrainAcc 0.8100 TestAcc 0.8098 0.8000
epoch 1800 LossPred 0.4781 LossAtt 0.4613 TrainAcc 0.8300 TestAcc 0.8298 0.8300
epoch 1900 LossPred 0.3369 LossAtt 0.4418 TrainAcc 0.8800 TestAcc 0.8476 0.8800
epoch 2000 LossPred 0.3198 LossAtt 0.4528 TrainAcc 0.8900 TestAcc 0.8196 0.8900
epoch 2100 LossPred 0.4186 LossAtt 0.4499 TrainAcc 0.8600 TestAcc 0.8398 0.8400
epoch 2200 LossPred 0.3379 LossAtt 0.4648 TrainAcc 0.9200 TestAcc 0.8226 0.8850
epoch 2300 LossPred 0.3240 LossAtt 0.4534 TrainAcc 0.9000 TestAcc 0.8336 0.9000
epoch 2400 LossPred 0.3425 LossAtt 0.4595 TrainAcc 0.9000 TestAcc 0.8574 0.8750
epoch 2500 LossPred 0.6612 LossAtt 0.4551 TrainAcc 0.7900 TestAcc 0.8111 0.7800
Optimization Finished!
********** replication  28  **********
epoch   0 LossPred 1.2666 LossAtt 0.9949 TrainAcc 0.5500 TestAcc 0.5513 0.5550
epoch 100 LossPred 0.9927 LossAtt 0.5459 TrainAcc 0.5700 TestAcc 0.5976 0.5700
epoch 200 LossPred 0.8995 LossAtt 0.4967 TrainAcc 0.6700 TestAcc 0.5901 0.6700
epoch 300 LossPred 0.8799 LossAtt 0.4654 TrainAcc 0.6700 TestAcc 0.5901 0.6700
epoch 400 LossPred 0.8739 LossAtt 0.4188 TrainAcc 0.6700 TestAcc 0.5901 0.6700
epoch 500 LossPred 0.8705 LossAtt 0.3721 TrainAcc 0.6700 TestAcc 0.5901 0.6700
epoch 600 LossPred 0.8545 LossAtt 0.3445 TrainAcc 0.6700 TestAcc 0.5961 0.6550
epoch 700 LossPred 0.9190 LossAtt 0.3828 TrainAcc 0.6600 TestAcc 0.6687 0.6500
epoch 800 LossPred 0.5953 LossAtt 0.3626 TrainAcc 0.8000 TestAcc 0.7848 0.7700
epoch 900 LossPred 0.5180 LossAtt 0.3724 TrainAcc 0.8200 TestAcc 0.8336 0.8050
epoch 1000 LossPred 0.5039 LossAtt 0.3631 TrainAcc 0.8000 TestAcc 0.8336 0.8150
epoch 1100 LossPred 0.5122 LossAtt 0.3390 TrainAcc 0.7900 TestAcc 0.8126 0.8050
epoch 1200 LossPred 0.5073 LossAtt 0.3333 TrainAcc 0.7900 TestAcc 0.8043 0.7950
epoch 1300 LossPred 0.4604 LossAtt 0.3296 TrainAcc 0.8200 TestAcc 0.8236 0.8100
epoch 1400 LossPred 0.4689 LossAtt 0.3516 TrainAcc 0.8100 TestAcc 0.8113 0.8000
epoch 1500 LossPred 0.5016 LossAtt 0.3262 TrainAcc 0.8200 TestAcc 0.8333 0.8000
epoch 1600 LossPred 0.4438 LossAtt 0.3127 TrainAcc 0.8400 TestAcc 0.8231 0.8050
epoch 1700 LossPred 0.4670 LossAtt 0.3148 TrainAcc 0.8100 TestAcc 0.8116 0.7850
epoch 1800 LossPred 0.5266 LossAtt 0.3489 TrainAcc 0.8200 TestAcc 0.8233 0.8050
epoch 1900 LossPred 0.5103 LossAtt 0.3191 TrainAcc 0.8200 TestAcc 0.8263 0.8150
epoch 2000 LossPred 0.5132 LossAtt 0.3216 TrainAcc 0.8100 TestAcc 0.8101 0.7900
epoch 2100 LossPred 0.4650 LossAtt 0.2922 TrainAcc 0.8400 TestAcc 0.8353 0.7900
epoch 2200 LossPred 0.4583 LossAtt 0.2996 TrainAcc 0.8400 TestAcc 0.8233 0.8150
epoch 2300 LossPred 0.4681 LossAtt 0.3186 TrainAcc 0.8500 TestAcc 0.8381 0.7950
epoch 2400 LossPred 0.4649 LossAtt 0.3027 TrainAcc 0.8100 TestAcc 0.8163 0.8000
epoch 2500 LossPred 0.4664 LossAtt 0.3051 TrainAcc 0.8500 TestAcc 0.8353 0.7950
Optimization Finished!
********** replication  29  **********
epoch   0 LossPred 1.1874 LossAtt 1.0154 TrainAcc 0.5300 TestAcc 0.4562 0.5300
epoch 100 LossPred 0.9937 LossAtt 0.4120 TrainAcc 0.5300 TestAcc 0.5856 0.5300
epoch 200 LossPred 0.9886 LossAtt 0.3517 TrainAcc 0.5300 TestAcc 0.5856 0.5300
epoch 300 LossPred 0.9763 LossAtt 0.3773 TrainAcc 0.5300 TestAcc 0.5931 0.5300
epoch 400 LossPred 0.9440 LossAtt 0.3786 TrainAcc 0.6300 TestAcc 0.6384 0.6300
epoch 500 LossPred 0.5114 LossAtt 0.4483 TrainAcc 0.8300 TestAcc 0.8596 0.8100
epoch 600 LossPred 0.4348 LossAtt 0.4044 TrainAcc 0.8800 TestAcc 0.8051 0.8550
epoch 700 LossPred 0.4291 LossAtt 0.3833 TrainAcc 0.8500 TestAcc 0.7863 0.8600
epoch 800 LossPred 0.3934 LossAtt 0.4099 TrainAcc 0.8900 TestAcc 0.7960 0.8600
epoch 900 LossPred 0.4253 LossAtt 0.3897 TrainAcc 0.8600 TestAcc 0.8326 0.8700
epoch 1000 LossPred 0.4195 LossAtt 0.3876 TrainAcc 0.8500 TestAcc 0.8058 0.8650
epoch 1100 LossPred 0.4116 LossAtt 0.4020 TrainAcc 0.8500 TestAcc 0.7975 0.8500
epoch 1200 LossPred 0.4407 LossAtt 0.3706 TrainAcc 0.8500 TestAcc 0.7913 0.8300
epoch 1300 LossPred 0.4562 LossAtt 0.3638 TrainAcc 0.8500 TestAcc 0.7553 0.8250
epoch 1400 LossPred 0.3753 LossAtt 0.3904 TrainAcc 0.8900 TestAcc 0.7818 0.8350
epoch 1500 LossPred 0.4295 LossAtt 0.4216 TrainAcc 0.8500 TestAcc 0.7913 0.8300
epoch 1600 LossPred 0.4336 LossAtt 0.3950 TrainAcc 0.8600 TestAcc 0.7828 0.8350
epoch 1700 LossPred 0.3899 LossAtt 0.3872 TrainAcc 0.8600 TestAcc 0.7800 0.8350
epoch 1800 LossPred 0.4465 LossAtt 0.4108 TrainAcc 0.8500 TestAcc 0.7553 0.8350
epoch 1900 LossPred 0.4038 LossAtt 0.3861 TrainAcc 0.8500 TestAcc 0.7860 0.8450
epoch 2000 LossPred 0.3858 LossAtt 0.3983 TrainAcc 0.8800 TestAcc 0.7850 0.8450
epoch 2100 LossPred 0.3729 LossAtt 0.4165 TrainAcc 0.8800 TestAcc 0.7890 0.8350
epoch 2200 LossPred 0.3938 LossAtt 0.4041 TrainAcc 0.8600 TestAcc 0.7838 0.8450
epoch 2300 LossPred 0.3442 LossAtt 0.4269 TrainAcc 0.9000 TestAcc 0.7860 0.8350
epoch 2400 LossPred 0.3325 LossAtt 0.4313 TrainAcc 0.8900 TestAcc 0.8016 0.8650
epoch 2500 LossPred 0.3117 LossAtt 0.4005 TrainAcc 0.9200 TestAcc 0.7870 0.8400
Optimization Finished!
********** replication  30  **********
epoch   0 LossPred 1.5003 LossAtt 1.0164 TrainAcc 0.4200 TestAcc 0.4422 0.4100
epoch 100 LossPred 1.0762 LossAtt 0.5029 TrainAcc 0.5400 TestAcc 0.5333 0.5100
epoch 200 LossPred 0.9398 LossAtt 0.4784 TrainAcc 0.5800 TestAcc 0.5270 0.5750
epoch 300 LossPred 0.9062 LossAtt 0.4301 TrainAcc 0.5900 TestAcc 0.5118 0.5900
epoch 400 LossPred 0.8963 LossAtt 0.4156 TrainAcc 0.5900 TestAcc 0.5118 0.5850
epoch 500 LossPred 0.8839 LossAtt 0.4505 TrainAcc 0.6000 TestAcc 0.5408 0.6100
epoch 600 LossPred 0.8689 LossAtt 0.4593 TrainAcc 0.6200 TestAcc 0.5753 0.6200
epoch 700 LossPred 0.8611 LossAtt 0.4446 TrainAcc 0.6300 TestAcc 0.5911 0.6200
epoch 800 LossPred 0.8529 LossAtt 0.4465 TrainAcc 0.6200 TestAcc 0.5951 0.6350
epoch 900 LossPred 0.8393 LossAtt 0.4826 TrainAcc 0.6800 TestAcc 0.5931 0.6600
epoch 1000 LossPred 0.8213 LossAtt 0.5003 TrainAcc 0.6900 TestAcc 0.6254 0.6900
epoch 1100 LossPred 0.7018 LossAtt 0.5498 TrainAcc 0.7300 TestAcc 0.7713 0.7350
epoch 1200 LossPred 0.5456 LossAtt 0.4960 TrainAcc 0.7900 TestAcc 0.7705 0.7700
epoch 1300 LossPred 0.5327 LossAtt 0.5270 TrainAcc 0.8100 TestAcc 0.7713 0.7750
epoch 1400 LossPred 0.8118 LossAtt 0.5354 TrainAcc 0.6500 TestAcc 0.6454 0.6500
epoch 1500 LossPred 0.5274 LossAtt 0.4932 TrainAcc 0.8200 TestAcc 0.7743 0.8000
epoch 1600 LossPred 0.4767 LossAtt 0.5442 TrainAcc 0.8500 TestAcc 0.8013 0.8150
epoch 1700 LossPred 0.6013 LossAtt 0.5259 TrainAcc 0.7800 TestAcc 0.7643 0.7600
epoch 1800 LossPred 0.5200 LossAtt 0.5145 TrainAcc 0.8200 TestAcc 0.7875 0.8050
epoch 1900 LossPred 0.5591 LossAtt 0.5156 TrainAcc 0.7900 TestAcc 0.8123 0.7950
epoch 2000 LossPred 0.4828 LossAtt 0.4896 TrainAcc 0.8300 TestAcc 0.7848 0.7850
epoch 2100 LossPred 0.5701 LossAtt 0.5185 TrainAcc 0.8000 TestAcc 0.7748 0.7750
epoch 2200 LossPred 0.5142 LossAtt 0.5057 TrainAcc 0.8100 TestAcc 0.7860 0.8150
epoch 2300 LossPred 0.4707 LossAtt 0.4918 TrainAcc 0.8400 TestAcc 0.8016 0.8200
epoch 2400 LossPred 0.4716 LossAtt 0.4790 TrainAcc 0.8400 TestAcc 0.8031 0.8050
epoch 2500 LossPred 0.4668 LossAtt 0.4723 TrainAcc 0.8300 TestAcc 0.7878 0.7800
Optimization Finished!
********** replication  31  **********
epoch   0 LossPred 1.2701 LossAtt 1.0073 TrainAcc 0.4800 TestAcc 0.5165 0.4400
epoch 100 LossPred 0.9715 LossAtt 0.4392 TrainAcc 0.5200 TestAcc 0.5546 0.5150
epoch 200 LossPred 0.9159 LossAtt 0.3538 TrainAcc 0.6300 TestAcc 0.5861 0.6300
epoch 300 LossPred 0.7690 LossAtt 0.4207 TrainAcc 0.6400 TestAcc 0.6224 0.6350
epoch 400 LossPred 0.7447 LossAtt 0.4564 TrainAcc 0.6900 TestAcc 0.6767 0.6750
epoch 500 LossPred 1.0955 LossAtt 0.3622 TrainAcc 0.3700 TestAcc 0.4139 0.3750
epoch 600 LossPred 0.8973 LossAtt 0.3234 TrainAcc 0.6300 TestAcc 0.5861 0.6300
epoch 700 LossPred 0.7945 LossAtt 0.3137 TrainAcc 0.6700 TestAcc 0.7012 0.6650
epoch 800 LossPred 0.5693 LossAtt 0.3285 TrainAcc 0.8200 TestAcc 0.8606 0.8200
epoch 900 LossPred 0.5480 LossAtt 0.3338 TrainAcc 0.8100 TestAcc 0.8276 0.8200
epoch 1000 LossPred 1.0310 LossAtt 0.3368 TrainAcc 0.5400 TestAcc 0.5516 0.5600
epoch 1100 LossPred 0.9024 LossAtt 0.3402 TrainAcc 0.5900 TestAcc 0.5488 0.5950
epoch 1200 LossPred 0.8485 LossAtt 0.3613 TrainAcc 0.6300 TestAcc 0.6379 0.6350
epoch 1300 LossPred 0.8934 LossAtt 0.2905 TrainAcc 0.5800 TestAcc 0.5478 0.5850
epoch 1400 LossPred 0.8564 LossAtt 0.2960 TrainAcc 0.6200 TestAcc 0.5686 0.6100
epoch 1500 LossPred 0.8036 LossAtt 0.3072 TrainAcc 0.6300 TestAcc 0.5903 0.6300
epoch 1600 LossPred 0.6159 LossAtt 0.3298 TrainAcc 0.7500 TestAcc 0.7848 0.7700
epoch 1700 LossPred 0.5889 LossAtt 0.3450 TrainAcc 0.8000 TestAcc 0.7770 0.7850
epoch 1800 LossPred 0.8318 LossAtt 0.3212 TrainAcc 0.6600 TestAcc 0.6597 0.6600
epoch 1900 LossPred 0.6412 LossAtt 0.3507 TrainAcc 0.7800 TestAcc 0.7457 0.7800
epoch 2000 LossPred 0.5950 LossAtt 0.3317 TrainAcc 0.7800 TestAcc 0.7978 0.7850
epoch 2100 LossPred 0.9730 LossAtt 0.3264 TrainAcc 0.6700 TestAcc 0.6434 0.6800
epoch 2200 LossPred 0.8127 LossAtt 0.3303 TrainAcc 0.7300 TestAcc 0.6629 0.7100
epoch 2300 LossPred 0.7987 LossAtt 0.3235 TrainAcc 0.7300 TestAcc 0.6779 0.7500
epoch 2400 LossPred 0.7867 LossAtt 0.3159 TrainAcc 0.7300 TestAcc 0.6889 0.7450
epoch 2500 LossPred 0.7808 LossAtt 0.3061 TrainAcc 0.7300 TestAcc 0.6687 0.7350
Optimization Finished!
********** replication  32  **********
epoch   0 LossPred 1.2266 LossAtt 1.0235 TrainAcc 0.4900 TestAcc 0.4429 0.4800
epoch 100 LossPred 1.0003 LossAtt 0.4566 TrainAcc 0.5700 TestAcc 0.5523 0.5750
epoch 200 LossPred 0.9613 LossAtt 0.4405 TrainAcc 0.5800 TestAcc 0.5796 0.5900
epoch 300 LossPred 0.9340 LossAtt 0.5142 TrainAcc 0.6300 TestAcc 0.5956 0.6350
epoch 400 LossPred 0.8811 LossAtt 0.5229 TrainAcc 0.6200 TestAcc 0.6231 0.6500
epoch 500 LossPred 0.3286 LossAtt 0.3886 TrainAcc 0.9000 TestAcc 0.8644 0.8500
epoch 600 LossPred 0.2854 LossAtt 0.3443 TrainAcc 0.9000 TestAcc 0.8691 0.8500
epoch 700 LossPred 0.2784 LossAtt 0.3342 TrainAcc 0.9100 TestAcc 0.8694 0.8600
epoch 800 LossPred 0.2733 LossAtt 0.3274 TrainAcc 0.9000 TestAcc 0.8719 0.8550
epoch 900 LossPred 0.2694 LossAtt 0.3243 TrainAcc 0.9000 TestAcc 0.8749 0.8400
epoch 1000 LossPred 0.2715 LossAtt 0.3074 TrainAcc 0.9000 TestAcc 0.8706 0.8600
epoch 1100 LossPred 0.2741 LossAtt 0.2978 TrainAcc 0.9000 TestAcc 0.8659 0.8500
epoch 1200 LossPred 0.2762 LossAtt 0.3012 TrainAcc 0.9000 TestAcc 0.8721 0.8400
epoch 1300 LossPred 0.2706 LossAtt 0.3066 TrainAcc 0.8900 TestAcc 0.8666 0.8300
epoch 1400 LossPred 0.3109 LossAtt 0.3106 TrainAcc 0.9100 TestAcc 0.8441 0.8700
epoch 1500 LossPred 0.2736 LossAtt 0.2947 TrainAcc 0.9000 TestAcc 0.8701 0.8450
epoch 1600 LossPred 0.2698 LossAtt 0.2896 TrainAcc 0.9000 TestAcc 0.8684 0.8500
epoch 1700 LossPred 0.2664 LossAtt 0.2946 TrainAcc 0.9000 TestAcc 0.8726 0.8550
epoch 1800 LossPred 0.3536 LossAtt 0.3032 TrainAcc 0.8600 TestAcc 0.8516 0.8200
epoch 1900 LossPred 0.2678 LossAtt 0.3027 TrainAcc 0.9100 TestAcc 0.8766 0.8550
epoch 2000 LossPred 0.2683 LossAtt 0.2775 TrainAcc 0.9000 TestAcc 0.8709 0.8450
epoch 2100 LossPred 0.2639 LossAtt 0.2942 TrainAcc 0.9000 TestAcc 0.8744 0.8500
epoch 2200 LossPred 0.2602 LossAtt 0.2891 TrainAcc 0.9000 TestAcc 0.8749 0.8350
epoch 2300 LossPred 0.2639 LossAtt 0.2796 TrainAcc 0.8900 TestAcc 0.8706 0.8400
epoch 2400 LossPred 0.2699 LossAtt 0.2641 TrainAcc 0.9000 TestAcc 0.8756 0.8650
epoch 2500 LossPred 0.2708 LossAtt 0.2678 TrainAcc 0.9100 TestAcc 0.8754 0.8650
Optimization Finished!
********** replication  33  **********
epoch   0 LossPred 1.2227 LossAtt 1.0094 TrainAcc 0.5200 TestAcc 0.5591 0.5350
epoch 100 LossPred 0.9963 LossAtt 0.4810 TrainAcc 0.5700 TestAcc 0.5853 0.5650
epoch 200 LossPred 0.9592 LossAtt 0.4981 TrainAcc 0.5800 TestAcc 0.5526 0.5850
epoch 300 LossPred 0.9403 LossAtt 0.5508 TrainAcc 0.5900 TestAcc 0.5673 0.5900
epoch 400 LossPred 0.8563 LossAtt 0.6065 TrainAcc 0.7200 TestAcc 0.6209 0.7050
epoch 500 LossPred 0.3467 LossAtt 0.6164 TrainAcc 0.9200 TestAcc 0.8549 0.8950
epoch 600 LossPred 0.2530 LossAtt 0.5829 TrainAcc 0.9200 TestAcc 0.8416 0.9000
epoch 700 LossPred 0.2205 LossAtt 0.5474 TrainAcc 0.9400 TestAcc 0.8386 0.9050
epoch 800 LossPred 0.2076 LossAtt 0.5469 TrainAcc 0.9400 TestAcc 0.8466 0.9150
epoch 900 LossPred 0.2075 LossAtt 0.5167 TrainAcc 0.9400 TestAcc 0.8421 0.9200
epoch 1000 LossPred 0.2109 LossAtt 0.4794 TrainAcc 0.9400 TestAcc 0.8559 0.9250
epoch 1100 LossPred 0.2154 LossAtt 0.4801 TrainAcc 0.9300 TestAcc 0.8644 0.9250
epoch 1200 LossPred 0.2404 LossAtt 0.4518 TrainAcc 0.9300 TestAcc 0.8391 0.9000
epoch 1300 LossPred 0.2071 LossAtt 0.4635 TrainAcc 0.9400 TestAcc 0.8363 0.9050
epoch 1400 LossPred 0.1964 LossAtt 0.4421 TrainAcc 0.9400 TestAcc 0.8458 0.9300
epoch 1500 LossPred 0.2086 LossAtt 0.4568 TrainAcc 0.9400 TestAcc 0.8213 0.9150
epoch 1600 LossPred 0.1791 LossAtt 0.4537 TrainAcc 0.9600 TestAcc 0.8486 0.9250
epoch 1700 LossPred 0.1981 LossAtt 0.4426 TrainAcc 0.9500 TestAcc 0.8353 0.9400
epoch 1800 LossPred 0.1795 LossAtt 0.4458 TrainAcc 0.9600 TestAcc 0.8483 0.9350
epoch 1900 LossPred 0.1661 LossAtt 0.4226 TrainAcc 0.9600 TestAcc 0.8381 0.9500
epoch 2000 LossPred 0.1742 LossAtt 0.4363 TrainAcc 0.9600 TestAcc 0.8541 0.9500
epoch 2100 LossPred 0.1643 LossAtt 0.4224 TrainAcc 0.9600 TestAcc 0.8398 0.9500
epoch 2200 LossPred 0.1645 LossAtt 0.4122 TrainAcc 0.9600 TestAcc 0.8283 0.9450
epoch 2300 LossPred 0.1682 LossAtt 0.4136 TrainAcc 0.9600 TestAcc 0.8326 0.9450
epoch 2400 LossPred 0.1695 LossAtt 0.4137 TrainAcc 0.9600 TestAcc 0.8501 0.9550
epoch 2500 LossPred 0.1766 LossAtt 0.4285 TrainAcc 0.9600 TestAcc 0.8313 0.9550
Optimization Finished!
********** replication  34  **********
epoch   0 LossPred 0.9172 LossAtt 1.0032 TrainAcc 0.6200 TestAcc 0.5928 0.6200
epoch 100 LossPred 0.8453 LossAtt 0.3932 TrainAcc 0.6600 TestAcc 0.6416 0.6550
epoch 200 LossPred 0.4842 LossAtt 0.5622 TrainAcc 0.8400 TestAcc 0.8356 0.8300
epoch 300 LossPred 0.5865 LossAtt 0.4440 TrainAcc 0.8000 TestAcc 0.7723 0.8100
epoch 400 LossPred 0.5576 LossAtt 0.4320 TrainAcc 0.8300 TestAcc 0.7755 0.8200
epoch 500 LossPred 0.8347 LossAtt 0.4155 TrainAcc 0.6800 TestAcc 0.6657 0.6900
epoch 600 LossPred 0.3860 LossAtt 0.4248 TrainAcc 0.8600 TestAcc 0.8644 0.8600
epoch 700 LossPred 0.6465 LossAtt 0.4108 TrainAcc 0.7500 TestAcc 0.7122 0.7500
epoch 800 LossPred 0.7731 LossAtt 0.4192 TrainAcc 0.7300 TestAcc 0.6759 0.7250
epoch 900 LossPred 0.4763 LossAtt 0.4080 TrainAcc 0.8400 TestAcc 0.7720 0.8150
epoch 1000 LossPred 0.3838 LossAtt 0.3883 TrainAcc 0.8800 TestAcc 0.8554 0.8350
epoch 1100 LossPred 0.4403 LossAtt 0.3960 TrainAcc 0.8500 TestAcc 0.8318 0.8350
epoch 1200 LossPred 0.5126 LossAtt 0.3800 TrainAcc 0.8300 TestAcc 0.7715 0.8150
epoch 1300 LossPred 0.3455 LossAtt 0.4139 TrainAcc 0.8700 TestAcc 0.8466 0.8650
epoch 1400 LossPred 0.4018 LossAtt 0.3927 TrainAcc 0.8800 TestAcc 0.8313 0.8450
epoch 1500 LossPred 0.3539 LossAtt 0.3891 TrainAcc 0.8800 TestAcc 0.8611 0.8600
epoch 1600 LossPred 0.4277 LossAtt 0.3760 TrainAcc 0.8600 TestAcc 0.8073 0.8400
epoch 1700 LossPred 0.2874 LossAtt 0.4040 TrainAcc 0.9000 TestAcc 0.8886 0.8750
epoch 1800 LossPred 0.4944 LossAtt 0.3880 TrainAcc 0.8200 TestAcc 0.8086 0.8100
epoch 1900 LossPred 0.4164 LossAtt 0.3934 TrainAcc 0.8500 TestAcc 0.8423 0.8400
epoch 2000 LossPred 0.2896 LossAtt 0.3717 TrainAcc 0.9100 TestAcc 0.8741 0.8850
epoch 2100 LossPred 0.3883 LossAtt 0.3621 TrainAcc 0.8600 TestAcc 0.8201 0.8500
epoch 2200 LossPred 0.3911 LossAtt 0.3659 TrainAcc 0.8800 TestAcc 0.8136 0.8600
epoch 2300 LossPred 0.3498 LossAtt 0.3713 TrainAcc 0.8800 TestAcc 0.8303 0.8650
epoch 2400 LossPred 0.2490 LossAtt 0.3836 TrainAcc 0.9200 TestAcc 0.8721 0.9200
epoch 2500 LossPred 0.2464 LossAtt 0.3775 TrainAcc 0.9300 TestAcc 0.8686 0.9150
Optimization Finished!
********** replication  35  **********
epoch   0 LossPred 1.4251 LossAtt 1.0317 TrainAcc 0.4900 TestAcc 0.5025 0.4500
epoch 100 LossPred 1.0429 LossAtt 0.3558 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 200 LossPred 0.9782 LossAtt 0.2876 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 300 LossPred 0.9994 LossAtt 0.1008 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 400 LossPred 1.0163 LossAtt 0.0698 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 500 LossPred 0.9228 LossAtt 0.1434 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 600 LossPred 0.8724 LossAtt 0.1491 TrainAcc 0.6800 TestAcc 0.5833 0.6800
epoch 700 LossPred 0.8684 LossAtt 0.0803 TrainAcc 0.6800 TestAcc 0.5833 0.6800
epoch 800 LossPred 0.9213 LossAtt 0.0519 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 900 LossPred 0.9428 LossAtt 0.0419 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 1000 LossPred 0.9472 LossAtt 0.0485 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 1100 LossPred 0.9448 LossAtt 0.0493 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 1200 LossPred 0.9409 LossAtt 0.0590 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 1300 LossPred 0.9339 LossAtt 0.0594 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 1400 LossPred 0.9271 LossAtt 0.0646 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 1500 LossPred 0.9264 LossAtt 0.0588 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 1600 LossPred 0.9320 LossAtt 0.0395 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 1700 LossPred 0.9290 LossAtt 0.0514 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 1800 LossPred 0.9343 LossAtt 0.0626 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 1900 LossPred 0.9419 LossAtt 0.0953 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 2000 LossPred 0.9728 LossAtt 0.0918 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 2100 LossPred 0.9774 LossAtt 0.0790 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 2200 LossPred 0.9648 LossAtt 0.0500 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 2300 LossPred 0.9472 LossAtt 0.1115 TrainAcc 0.5800 TestAcc 0.5773 0.5800
epoch 2400 LossPred 0.7651 LossAtt 0.3664 TrainAcc 0.7500 TestAcc 0.6474 0.7450
epoch 2500 LossPred 0.8092 LossAtt 0.2701 TrainAcc 0.6800 TestAcc 0.6667 0.6550
Optimization Finished!
********** replication  36  **********
epoch   0 LossPred 1.1542 LossAtt 1.0314 TrainAcc 0.5100 TestAcc 0.5065 0.5150
epoch 100 LossPred 0.8765 LossAtt 0.3672 TrainAcc 0.6900 TestAcc 0.6009 0.6650
epoch 200 LossPred 0.8127 LossAtt 0.3488 TrainAcc 0.6900 TestAcc 0.6009 0.6900
epoch 300 LossPred 0.4938 LossAtt 0.2984 TrainAcc 0.8600 TestAcc 0.7518 0.8350
epoch 400 LossPred 0.4875 LossAtt 0.3166 TrainAcc 0.8300 TestAcc 0.7673 0.8300
epoch 500 LossPred 0.4168 LossAtt 0.2747 TrainAcc 0.8500 TestAcc 0.7765 0.8500
epoch 600 LossPred 0.5023 LossAtt 0.3073 TrainAcc 0.8300 TestAcc 0.7490 0.8200
epoch 700 LossPred 0.3343 LossAtt 0.2611 TrainAcc 0.8700 TestAcc 0.8133 0.8650
epoch 800 LossPred 0.3347 LossAtt 0.2758 TrainAcc 0.8600 TestAcc 0.8083 0.8550
epoch 900 LossPred 0.3293 LossAtt 0.2652 TrainAcc 0.8900 TestAcc 0.8246 0.8550
epoch 1000 LossPred 0.3562 LossAtt 0.2960 TrainAcc 0.8900 TestAcc 0.8228 0.8750
epoch 1100 LossPred 0.6032 LossAtt 0.2998 TrainAcc 0.7700 TestAcc 0.7477 0.8050
epoch 1200 LossPred 0.3279 LossAtt 0.2851 TrainAcc 0.8800 TestAcc 0.8008 0.8500
epoch 1300 LossPred 0.3624 LossAtt 0.2858 TrainAcc 0.8700 TestAcc 0.8128 0.8600
epoch 1400 LossPred 0.3266 LossAtt 0.2992 TrainAcc 0.8600 TestAcc 0.8018 0.8550
epoch 1500 LossPred 0.2895 LossAtt 0.2947 TrainAcc 0.9100 TestAcc 0.8393 0.8750
epoch 1600 LossPred 0.2574 LossAtt 0.3222 TrainAcc 0.9200 TestAcc 0.8463 0.8900
epoch 1700 LossPred 0.2603 LossAtt 0.3103 TrainAcc 0.9200 TestAcc 0.8551 0.8900
epoch 1800 LossPred 0.2344 LossAtt 0.3085 TrainAcc 0.9200 TestAcc 0.8579 0.8800
epoch 1900 LossPred 0.2406 LossAtt 0.3255 TrainAcc 0.9200 TestAcc 0.8596 0.8900
epoch 2000 LossPred 0.2137 LossAtt 0.3031 TrainAcc 0.9400 TestAcc 0.8684 0.8850
epoch 2100 LossPred 0.2105 LossAtt 0.3094 TrainAcc 0.9300 TestAcc 0.8716 0.8900
epoch 2200 LossPred 0.2380 LossAtt 0.2873 TrainAcc 0.9100 TestAcc 0.8559 0.8950
epoch 2300 LossPred 0.2022 LossAtt 0.2997 TrainAcc 0.9400 TestAcc 0.8761 0.9000
epoch 2400 LossPred 0.2390 LossAtt 0.3005 TrainAcc 0.9100 TestAcc 0.8544 0.8950
epoch 2500 LossPred 0.2200 LossAtt 0.2958 TrainAcc 0.9400 TestAcc 0.8564 0.9000
Optimization Finished!
********** replication  37  **********
epoch   0 LossPred 1.1767 LossAtt 1.0040 TrainAcc 0.4400 TestAcc 0.3991 0.4400
epoch 100 LossPred 0.9536 LossAtt 0.4165 TrainAcc 0.5700 TestAcc 0.4975 0.5800
epoch 200 LossPred 0.9433 LossAtt 0.3617 TrainAcc 0.5700 TestAcc 0.4930 0.5700
epoch 300 LossPred 0.9376 LossAtt 0.3689 TrainAcc 0.5700 TestAcc 0.4950 0.5700
epoch 400 LossPred 0.8175 LossAtt 0.3988 TrainAcc 0.7700 TestAcc 0.7445 0.7700
epoch 500 LossPred 0.5406 LossAtt 0.4122 TrainAcc 0.8400 TestAcc 0.8191 0.7900
epoch 600 LossPred 0.3657 LossAtt 0.3830 TrainAcc 0.8800 TestAcc 0.8931 0.8700
epoch 700 LossPred 0.3134 LossAtt 0.3658 TrainAcc 0.9000 TestAcc 0.8906 0.8650
epoch 800 LossPred 0.3119 LossAtt 0.3523 TrainAcc 0.9000 TestAcc 0.8966 0.8750
epoch 900 LossPred 0.3827 LossAtt 0.3514 TrainAcc 0.8500 TestAcc 0.8901 0.8650
epoch 1000 LossPred 0.3325 LossAtt 0.3671 TrainAcc 0.8900 TestAcc 0.8811 0.8700
epoch 1100 LossPred 0.4190 LossAtt 0.3332 TrainAcc 0.8400 TestAcc 0.8864 0.8600
epoch 1200 LossPred 0.2388 LossAtt 0.3487 TrainAcc 0.9100 TestAcc 0.9052 0.8650
epoch 1300 LossPred 0.2387 LossAtt 0.3719 TrainAcc 0.9300 TestAcc 0.9067 0.8650
epoch 1400 LossPred 0.2352 LossAtt 0.3659 TrainAcc 0.9300 TestAcc 0.9129 0.8800
epoch 1500 LossPred 0.2215 LossAtt 0.3819 TrainAcc 0.9200 TestAcc 0.9122 0.8700
epoch 1600 LossPred 0.2192 LossAtt 0.3677 TrainAcc 0.9400 TestAcc 0.9167 0.8850
epoch 1700 LossPred 0.2147 LossAtt 0.3863 TrainAcc 0.9300 TestAcc 0.9167 0.9000
epoch 1800 LossPred 0.2070 LossAtt 0.3878 TrainAcc 0.9300 TestAcc 0.9172 0.8950
epoch 1900 LossPred 0.3118 LossAtt 0.3668 TrainAcc 0.8700 TestAcc 0.9082 0.8850
epoch 2000 LossPred 0.2072 LossAtt 0.3947 TrainAcc 0.9200 TestAcc 0.9154 0.8950
epoch 2100 LossPred 0.1994 LossAtt 0.4044 TrainAcc 0.9500 TestAcc 0.9182 0.8950
epoch 2200 LossPred 0.1939 LossAtt 0.3980 TrainAcc 0.9400 TestAcc 0.9222 0.9000
epoch 2300 LossPred 0.1732 LossAtt 0.3963 TrainAcc 0.9500 TestAcc 0.9277 0.9250
epoch 2400 LossPred 0.2556 LossAtt 0.4113 TrainAcc 0.9000 TestAcc 0.8849 0.8750
epoch 2500 LossPred 0.1787 LossAtt 0.4027 TrainAcc 0.9400 TestAcc 0.9209 0.9050
Optimization Finished!
********** replication  38  **********
epoch   0 LossPred 1.1513 LossAtt 1.0115 TrainAcc 0.5300 TestAcc 0.4552 0.5200
epoch 100 LossPred 0.9945 LossAtt 0.3360 TrainAcc 0.5500 TestAcc 0.5455 0.5500
epoch 200 LossPred 0.9883 LossAtt 0.2993 TrainAcc 0.5500 TestAcc 0.5455 0.5500
epoch 300 LossPred 0.9858 LossAtt 0.2175 TrainAcc 0.5500 TestAcc 0.5455 0.5500
epoch 400 LossPred 0.9777 LossAtt 0.2832 TrainAcc 0.5900 TestAcc 0.5921 0.5500
epoch 500 LossPred 0.6039 LossAtt 0.5741 TrainAcc 0.8200 TestAcc 0.7112 0.8050
epoch 600 LossPred 0.3182 LossAtt 0.5067 TrainAcc 0.9000 TestAcc 0.8141 0.8850
epoch 700 LossPred 0.3142 LossAtt 0.4590 TrainAcc 0.9100 TestAcc 0.8131 0.8950
epoch 800 LossPred 0.3402 LossAtt 0.4313 TrainAcc 0.9000 TestAcc 0.8148 0.8700
epoch 900 LossPred 0.2635 LossAtt 0.4256 TrainAcc 0.9400 TestAcc 0.8128 0.8950
epoch 1000 LossPred 0.2902 LossAtt 0.4121 TrainAcc 0.9200 TestAcc 0.8186 0.8800
epoch 1100 LossPred 0.2862 LossAtt 0.4046 TrainAcc 0.9300 TestAcc 0.8336 0.9200
epoch 1200 LossPred 0.2671 LossAtt 0.3968 TrainAcc 0.9300 TestAcc 0.8388 0.9400
epoch 1300 LossPred 0.2589 LossAtt 0.4113 TrainAcc 0.9000 TestAcc 0.8356 0.9050
epoch 1400 LossPred 0.3368 LossAtt 0.3856 TrainAcc 0.8700 TestAcc 0.8418 0.8800
epoch 1500 LossPred 0.2125 LossAtt 0.3821 TrainAcc 0.9500 TestAcc 0.8571 0.9150
epoch 1600 LossPred 0.2341 LossAtt 0.3644 TrainAcc 0.9200 TestAcc 0.8614 0.9100
epoch 1700 LossPred 0.2486 LossAtt 0.3641 TrainAcc 0.9300 TestAcc 0.8686 0.9150
epoch 1800 LossPred 0.2555 LossAtt 0.3288 TrainAcc 0.9100 TestAcc 0.8666 0.9100
epoch 1900 LossPred 0.1427 LossAtt 0.3615 TrainAcc 0.9600 TestAcc 0.9062 0.9600
epoch 2000 LossPred 0.1687 LossAtt 0.3282 TrainAcc 0.9500 TestAcc 0.9029 0.9450
epoch 2100 LossPred 0.1531 LossAtt 0.3526 TrainAcc 0.9500 TestAcc 0.9089 0.9550
epoch 2200 LossPred 0.1382 LossAtt 0.3373 TrainAcc 0.9500 TestAcc 0.9124 0.9650
epoch 2300 LossPred 0.1027 LossAtt 0.3369 TrainAcc 0.9700 TestAcc 0.9142 0.9650
epoch 2400 LossPred 0.1408 LossAtt 0.3246 TrainAcc 0.9400 TestAcc 0.8916 0.9600
epoch 2500 LossPred 0.1315 LossAtt 0.3455 TrainAcc 0.9600 TestAcc 0.9149 0.9600
Optimization Finished!
********** replication  39  **********
epoch   0 LossPred 1.1421 LossAtt 0.9924 TrainAcc 0.4900 TestAcc 0.5125 0.5150
epoch 100 LossPred 0.9390 LossAtt 0.3720 TrainAcc 0.5900 TestAcc 0.5736 0.5900
epoch 200 LossPred 0.9181 LossAtt 0.3401 TrainAcc 0.6500 TestAcc 0.5901 0.6300
epoch 300 LossPred 0.6947 LossAtt 0.4327 TrainAcc 0.7400 TestAcc 0.7300 0.7550
epoch 400 LossPred 0.9514 LossAtt 0.3851 TrainAcc 0.6000 TestAcc 0.5831 0.6000
epoch 500 LossPred 0.6410 LossAtt 0.4077 TrainAcc 0.7800 TestAcc 0.7445 0.8100
epoch 600 LossPred 0.6330 LossAtt 0.3905 TrainAcc 0.7700 TestAcc 0.7382 0.7750
epoch 700 LossPred 0.8616 LossAtt 0.4022 TrainAcc 0.6300 TestAcc 0.5951 0.6500
epoch 800 LossPred 0.6362 LossAtt 0.3899 TrainAcc 0.7900 TestAcc 0.7392 0.8000
epoch 900 LossPred 0.3941 LossAtt 0.3338 TrainAcc 0.8600 TestAcc 0.8256 0.8700
epoch 1000 LossPred 0.3210 LossAtt 0.3689 TrainAcc 0.9100 TestAcc 0.8744 0.9000
epoch 1100 LossPred 0.2980 LossAtt 0.3489 TrainAcc 0.9100 TestAcc 0.8781 0.8950
epoch 1200 LossPred 0.3091 LossAtt 0.3700 TrainAcc 0.8900 TestAcc 0.8418 0.8750
epoch 1300 LossPred 0.3202 LossAtt 0.3511 TrainAcc 0.9100 TestAcc 0.8594 0.8800
epoch 1400 LossPred 0.3474 LossAtt 0.3497 TrainAcc 0.8900 TestAcc 0.8236 0.8900
epoch 1500 LossPred 0.2847 LossAtt 0.3362 TrainAcc 0.9100 TestAcc 0.8681 0.9050
epoch 1600 LossPred 0.2553 LossAtt 0.3520 TrainAcc 0.9400 TestAcc 0.8724 0.9200
epoch 1700 LossPred 0.2404 LossAtt 0.3487 TrainAcc 0.9200 TestAcc 0.8529 0.9100
epoch 1800 LossPred 0.2138 LossAtt 0.3648 TrainAcc 0.9300 TestAcc 0.8641 0.9300
epoch 1900 LossPred 0.2230 LossAtt 0.3559 TrainAcc 0.9200 TestAcc 0.8791 0.9100
epoch 2000 LossPred 0.2391 LossAtt 0.3756 TrainAcc 0.9400 TestAcc 0.8699 0.9150
epoch 2100 LossPred 0.2004 LossAtt 0.3603 TrainAcc 0.9300 TestAcc 0.8749 0.9250
epoch 2200 LossPred 0.1967 LossAtt 0.3503 TrainAcc 0.9300 TestAcc 0.8729 0.9150
epoch 2300 LossPred 0.1840 LossAtt 0.3531 TrainAcc 0.9300 TestAcc 0.8629 0.9300
epoch 2400 LossPred 0.1945 LossAtt 0.3547 TrainAcc 0.9300 TestAcc 0.8769 0.9050
epoch 2500 LossPred 0.1737 LossAtt 0.3494 TrainAcc 0.9400 TestAcc 0.8676 0.9250
Optimization Finished!
********** replication  40  **********
epoch   0 LossPred 1.1558 LossAtt 1.0207 TrainAcc 0.5900 TestAcc 0.5848 0.5850
epoch 100 LossPred 0.9056 LossAtt 0.4180 TrainAcc 0.5900 TestAcc 0.5898 0.6100
epoch 200 LossPred 0.8869 LossAtt 0.4200 TrainAcc 0.6500 TestAcc 0.6364 0.6400
epoch 300 LossPred 0.8653 LossAtt 0.4422 TrainAcc 0.6300 TestAcc 0.6719 0.6350
epoch 400 LossPred 0.6215 LossAtt 0.3825 TrainAcc 0.7900 TestAcc 0.7795 0.7900
epoch 500 LossPred 0.4617 LossAtt 0.4303 TrainAcc 0.8500 TestAcc 0.7918 0.8300
epoch 600 LossPred 0.3808 LossAtt 0.4111 TrainAcc 0.9000 TestAcc 0.8273 0.8450
epoch 700 LossPred 0.3127 LossAtt 0.3978 TrainAcc 0.9100 TestAcc 0.8226 0.8700
epoch 800 LossPred 0.4089 LossAtt 0.3755 TrainAcc 0.8600 TestAcc 0.8223 0.8500
epoch 900 LossPred 0.9638 LossAtt 0.3086 TrainAcc 0.6300 TestAcc 0.5851 0.6050
epoch 1000 LossPred 0.7674 LossAtt 0.3172 TrainAcc 0.6400 TestAcc 0.6054 0.6300
epoch 1100 LossPred 0.9179 LossAtt 0.3150 TrainAcc 0.5900 TestAcc 0.5833 0.6100
epoch 1200 LossPred 0.7817 LossAtt 0.3156 TrainAcc 0.7100 TestAcc 0.6644 0.6900
epoch 1300 LossPred 0.9226 LossAtt 0.2878 TrainAcc 0.6500 TestAcc 0.6321 0.6500
epoch 1400 LossPred 0.8758 LossAtt 0.3354 TrainAcc 0.6600 TestAcc 0.6376 0.6800
epoch 1500 LossPred 0.8875 LossAtt 0.2907 TrainAcc 0.6500 TestAcc 0.6321 0.6550
epoch 1600 LossPred 0.7390 LossAtt 0.3068 TrainAcc 0.7400 TestAcc 0.7342 0.7650
epoch 1700 LossPred 0.8491 LossAtt 0.2733 TrainAcc 0.6500 TestAcc 0.6246 0.6400
epoch 1800 LossPred 0.3986 LossAtt 0.2834 TrainAcc 0.8900 TestAcc 0.8403 0.8650
epoch 1900 LossPred 0.4374 LossAtt 0.2480 TrainAcc 0.8900 TestAcc 0.8196 0.8600
epoch 2000 LossPred 0.2479 LossAtt 0.2770 TrainAcc 0.9300 TestAcc 0.8478 0.9100
epoch 2100 LossPred 0.1944 LossAtt 0.2960 TrainAcc 0.9500 TestAcc 0.8451 0.8950
epoch 2200 LossPred 0.2625 LossAtt 0.3076 TrainAcc 0.9400 TestAcc 0.8428 0.9150
epoch 2300 LossPred 0.2168 LossAtt 0.2763 TrainAcc 0.9200 TestAcc 0.8531 0.9200
epoch 2400 LossPred 0.2228 LossAtt 0.2729 TrainAcc 0.9300 TestAcc 0.8431 0.9200
epoch 2500 LossPred 0.2297 LossAtt 0.2712 TrainAcc 0.9300 TestAcc 0.8529 0.9200
Optimization Finished!
********** replication  41  **********
epoch   0 LossPred 1.2876 LossAtt 1.0055 TrainAcc 0.4600 TestAcc 0.4237 0.4550
epoch 100 LossPred 0.9949 LossAtt 0.4433 TrainAcc 0.5500 TestAcc 0.5928 0.5500
epoch 200 LossPred 0.9570 LossAtt 0.3772 TrainAcc 0.5800 TestAcc 0.6339 0.5750
epoch 300 LossPred 0.8903 LossAtt 0.4611 TrainAcc 0.6300 TestAcc 0.6924 0.6250
epoch 400 LossPred 0.4317 LossAtt 0.4032 TrainAcc 0.8900 TestAcc 0.8659 0.8750
epoch 500 LossPred 0.4144 LossAtt 0.4224 TrainAcc 0.8500 TestAcc 0.8551 0.8500
epoch 600 LossPred 0.3261 LossAtt 0.3964 TrainAcc 0.8900 TestAcc 0.8701 0.8850
epoch 700 LossPred 0.2749 LossAtt 0.3988 TrainAcc 0.9300 TestAcc 0.8789 0.8750
epoch 800 LossPred 0.3113 LossAtt 0.3885 TrainAcc 0.8800 TestAcc 0.8879 0.8750
epoch 900 LossPred 0.3179 LossAtt 0.3987 TrainAcc 0.9000 TestAcc 0.8649 0.8700
epoch 1000 LossPred 0.3397 LossAtt 0.4057 TrainAcc 0.9000 TestAcc 0.8383 0.8650
epoch 1100 LossPred 0.2547 LossAtt 0.3879 TrainAcc 0.9000 TestAcc 0.8766 0.8900
epoch 1200 LossPred 0.2744 LossAtt 0.4048 TrainAcc 0.9000 TestAcc 0.8899 0.8850
epoch 1300 LossPred 0.2896 LossAtt 0.3880 TrainAcc 0.8900 TestAcc 0.8731 0.8800
epoch 1400 LossPred 0.2561 LossAtt 0.3928 TrainAcc 0.9000 TestAcc 0.8691 0.8950
epoch 1500 LossPred 0.2552 LossAtt 0.4093 TrainAcc 0.9300 TestAcc 0.9042 0.8850
epoch 1600 LossPred 0.2323 LossAtt 0.4039 TrainAcc 0.9300 TestAcc 0.9034 0.8900
epoch 1700 LossPred 0.2407 LossAtt 0.4140 TrainAcc 0.9200 TestAcc 0.8954 0.8900
epoch 1800 LossPred 0.4901 LossAtt 0.3805 TrainAcc 0.8400 TestAcc 0.8048 0.8150
epoch 1900 LossPred 0.2206 LossAtt 0.3910 TrainAcc 0.9600 TestAcc 0.8949 0.8900
epoch 2000 LossPred 0.4326 LossAtt 0.3672 TrainAcc 0.8500 TestAcc 0.8421 0.8350
epoch 2100 LossPred 0.8632 LossAtt 0.4096 TrainAcc 0.7300 TestAcc 0.7290 0.7350
epoch 2200 LossPred 0.2670 LossAtt 0.3943 TrainAcc 0.9000 TestAcc 0.8721 0.8700
epoch 2300 LossPred 0.2437 LossAtt 0.3852 TrainAcc 0.9400 TestAcc 0.8914 0.8700
epoch 2400 LossPred 0.3958 LossAtt 0.3592 TrainAcc 0.8600 TestAcc 0.8614 0.8400
epoch 2500 LossPred 0.2657 LossAtt 0.3687 TrainAcc 0.9100 TestAcc 0.8841 0.8650
Optimization Finished!
********** replication  42  **********
epoch   0 LossPred 1.0244 LossAtt 0.9655 TrainAcc 0.5000 TestAcc 0.4484 0.5000
epoch 100 LossPred 0.8549 LossAtt 0.3874 TrainAcc 0.6600 TestAcc 0.5888 0.6600
epoch 200 LossPred 0.8373 LossAtt 0.3727 TrainAcc 0.6600 TestAcc 0.5888 0.6600
epoch 300 LossPred 0.8285 LossAtt 0.3511 TrainAcc 0.6600 TestAcc 0.5888 0.6600
epoch 400 LossPred 0.7787 LossAtt 0.4847 TrainAcc 0.7600 TestAcc 0.6867 0.7100
epoch 500 LossPred 0.9704 LossAtt 0.5203 TrainAcc 0.6600 TestAcc 0.5953 0.6600
epoch 600 LossPred 0.6144 LossAtt 0.4312 TrainAcc 0.8000 TestAcc 0.7825 0.7850
epoch 700 LossPred 0.6273 LossAtt 0.4079 TrainAcc 0.7700 TestAcc 0.7492 0.7550
epoch 800 LossPred 0.4208 LossAtt 0.4349 TrainAcc 0.8800 TestAcc 0.8111 0.8550
epoch 900 LossPred 0.4075 LossAtt 0.4632 TrainAcc 0.8800 TestAcc 0.8051 0.8550
epoch 1000 LossPred 0.4065 LossAtt 0.4330 TrainAcc 0.8700 TestAcc 0.8151 0.8750
epoch 1100 LossPred 0.3884 LossAtt 0.4597 TrainAcc 0.8800 TestAcc 0.8143 0.8600
epoch 1200 LossPred 0.5221 LossAtt 0.4546 TrainAcc 0.8200 TestAcc 0.7923 0.8400
epoch 1300 LossPred 0.4575 LossAtt 0.4481 TrainAcc 0.8400 TestAcc 0.8073 0.8550
epoch 1400 LossPred 0.3727 LossAtt 0.4573 TrainAcc 0.8700 TestAcc 0.8173 0.8650
epoch 1500 LossPred 0.3763 LossAtt 0.4387 TrainAcc 0.8800 TestAcc 0.8166 0.8550
epoch 1600 LossPred 0.3683 LossAtt 0.4331 TrainAcc 0.8900 TestAcc 0.7958 0.8600
epoch 1700 LossPred 0.3132 LossAtt 0.4156 TrainAcc 0.9000 TestAcc 0.7970 0.8800
epoch 1800 LossPred 0.5996 LossAtt 0.4408 TrainAcc 0.8100 TestAcc 0.7322 0.8150
epoch 1900 LossPred 0.3360 LossAtt 0.4007 TrainAcc 0.9000 TestAcc 0.8126 0.8400
epoch 2000 LossPred 0.4274 LossAtt 0.4262 TrainAcc 0.8700 TestAcc 0.7735 0.8650
epoch 2100 LossPred 0.3412 LossAtt 0.4020 TrainAcc 0.8800 TestAcc 0.8218 0.8500
epoch 2200 LossPred 0.3506 LossAtt 0.3875 TrainAcc 0.8900 TestAcc 0.7790 0.8700
epoch 2300 LossPred 0.3001 LossAtt 0.3784 TrainAcc 0.8900 TestAcc 0.7918 0.8550
epoch 2400 LossPred 0.3412 LossAtt 0.3565 TrainAcc 0.8900 TestAcc 0.7725 0.8500
epoch 2500 LossPred 0.5791 LossAtt 0.3893 TrainAcc 0.8300 TestAcc 0.7227 0.7950
Optimization Finished!
********** replication  43  **********
epoch   0 LossPred 0.9598 LossAtt 1.0332 TrainAcc 0.5900 TestAcc 0.5030 0.5900
epoch 100 LossPred 0.8824 LossAtt 0.5147 TrainAcc 0.6400 TestAcc 0.5901 0.6250
epoch 200 LossPred 0.8367 LossAtt 0.4854 TrainAcc 0.6600 TestAcc 0.6459 0.6450
epoch 300 LossPred 0.3130 LossAtt 0.4775 TrainAcc 0.8900 TestAcc 0.8839 0.8750
epoch 400 LossPred 0.2360 LossAtt 0.4537 TrainAcc 0.9200 TestAcc 0.8959 0.8800
epoch 500 LossPred 0.2229 LossAtt 0.4656 TrainAcc 0.9300 TestAcc 0.9029 0.8750
epoch 600 LossPred 0.3532 LossAtt 0.4374 TrainAcc 0.8700 TestAcc 0.8779 0.8600
epoch 700 LossPred 0.3126 LossAtt 0.4370 TrainAcc 0.9000 TestAcc 0.8984 0.8700
epoch 800 LossPred 0.4876 LossAtt 0.3798 TrainAcc 0.7900 TestAcc 0.8373 0.7950
epoch 900 LossPred 0.3083 LossAtt 0.3839 TrainAcc 0.9000 TestAcc 0.8899 0.8650
epoch 1000 LossPred 0.4378 LossAtt 0.3642 TrainAcc 0.8300 TestAcc 0.8516 0.8200
epoch 1100 LossPred 0.3033 LossAtt 0.3674 TrainAcc 0.9200 TestAcc 0.8891 0.9050
epoch 1200 LossPred 0.2964 LossAtt 0.3841 TrainAcc 0.9100 TestAcc 0.8799 0.8850
epoch 1300 LossPred 0.4922 LossAtt 0.3534 TrainAcc 0.7800 TestAcc 0.8346 0.8100
epoch 1400 LossPred 0.3251 LossAtt 0.3700 TrainAcc 0.8900 TestAcc 0.8874 0.8550
epoch 1500 LossPred 0.4026 LossAtt 0.3771 TrainAcc 0.8600 TestAcc 0.8496 0.8750
epoch 1600 LossPred 0.2735 LossAtt 0.3495 TrainAcc 0.9200 TestAcc 0.8991 0.8750
epoch 1700 LossPred 0.3624 LossAtt 0.3553 TrainAcc 0.8800 TestAcc 0.8779 0.8400
epoch 1800 LossPred 0.3674 LossAtt 0.3693 TrainAcc 0.8800 TestAcc 0.8656 0.8900
epoch 1900 LossPred 0.3965 LossAtt 0.3411 TrainAcc 0.8700 TestAcc 0.8611 0.8500
epoch 2000 LossPred 0.3077 LossAtt 0.3725 TrainAcc 0.9000 TestAcc 0.8851 0.9000
epoch 2100 LossPred 0.2749 LossAtt 0.3464 TrainAcc 0.9200 TestAcc 0.8961 0.8900
epoch 2200 LossPred 0.2895 LossAtt 0.3667 TrainAcc 0.9100 TestAcc 0.8906 0.8950
epoch 2300 LossPred 0.3489 LossAtt 0.3536 TrainAcc 0.9000 TestAcc 0.8734 0.8400
epoch 2400 LossPred 0.6069 LossAtt 0.3903 TrainAcc 0.8100 TestAcc 0.7615 0.8300
epoch 2500 LossPred 0.3011 LossAtt 0.3738 TrainAcc 0.8900 TestAcc 0.8876 0.8550
Optimization Finished!
********** replication  44  **********
epoch   0 LossPred 1.1788 LossAtt 1.0176 TrainAcc 0.5500 TestAcc 0.4882 0.5400
epoch 100 LossPred 0.9774 LossAtt 0.4390 TrainAcc 0.5900 TestAcc 0.5003 0.5900
epoch 200 LossPred 0.9496 LossAtt 0.3733 TrainAcc 0.5900 TestAcc 0.5238 0.5750
epoch 300 LossPred 0.9012 LossAtt 0.3718 TrainAcc 0.6200 TestAcc 0.5413 0.6300
epoch 400 LossPred 0.8607 LossAtt 0.3662 TrainAcc 0.6700 TestAcc 0.5986 0.6600
epoch 500 LossPred 0.8471 LossAtt 0.3774 TrainAcc 0.6600 TestAcc 0.5983 0.6700
epoch 600 LossPred 0.8398 LossAtt 0.3767 TrainAcc 0.6700 TestAcc 0.5961 0.6700
epoch 700 LossPred 0.8339 LossAtt 0.3885 TrainAcc 0.6600 TestAcc 0.5923 0.6650
epoch 800 LossPred 0.8310 LossAtt 0.3798 TrainAcc 0.6600 TestAcc 0.5953 0.6750
epoch 900 LossPred 0.8287 LossAtt 0.3726 TrainAcc 0.6600 TestAcc 0.5908 0.6700
epoch 1000 LossPred 0.8342 LossAtt 0.3616 TrainAcc 0.6600 TestAcc 0.5921 0.6700
epoch 1100 LossPred 0.8237 LossAtt 0.3982 TrainAcc 0.6600 TestAcc 0.5956 0.6700
epoch 1200 LossPred 0.8250 LossAtt 0.4041 TrainAcc 0.6700 TestAcc 0.5913 0.6700
epoch 1300 LossPred 0.8191 LossAtt 0.4266 TrainAcc 0.6700 TestAcc 0.5943 0.6650
epoch 1400 LossPred 0.8160 LossAtt 0.4220 TrainAcc 0.6600 TestAcc 0.5941 0.6700
epoch 1500 LossPred 0.8198 LossAtt 0.4372 TrainAcc 0.6900 TestAcc 0.5853 0.6700
epoch 1600 LossPred 0.8212 LossAtt 0.4374 TrainAcc 0.7100 TestAcc 0.5893 0.6700
epoch 1700 LossPred 0.8038 LossAtt 0.4254 TrainAcc 0.6900 TestAcc 0.5913 0.6800
epoch 1800 LossPred 0.7866 LossAtt 0.4409 TrainAcc 0.7200 TestAcc 0.5963 0.6800
epoch 1900 LossPred 0.7829 LossAtt 0.4443 TrainAcc 0.7100 TestAcc 0.5928 0.6850
epoch 2000 LossPred 0.8038 LossAtt 0.4612 TrainAcc 0.6900 TestAcc 0.5923 0.6900
epoch 2100 LossPred 0.7977 LossAtt 0.4896 TrainAcc 0.7200 TestAcc 0.5891 0.6900
epoch 2200 LossPred 0.7865 LossAtt 0.4520 TrainAcc 0.7300 TestAcc 0.5923 0.6750
epoch 2300 LossPred 0.7873 LossAtt 0.4391 TrainAcc 0.7000 TestAcc 0.5938 0.6800
epoch 2400 LossPred 0.7729 LossAtt 0.4582 TrainAcc 0.7300 TestAcc 0.5901 0.6850
epoch 2500 LossPred 0.8081 LossAtt 0.4636 TrainAcc 0.6800 TestAcc 0.6014 0.6900
Optimization Finished!
********** replication  45  **********
epoch   0 LossPred 1.2944 LossAtt 0.9944 TrainAcc 0.5100 TestAcc 0.4865 0.5050
epoch 100 LossPred 0.9476 LossAtt 0.3662 TrainAcc 0.5800 TestAcc 0.5833 0.5800
epoch 200 LossPred 0.8836 LossAtt 0.2675 TrainAcc 0.6500 TestAcc 0.5996 0.6500
epoch 300 LossPred 0.8743 LossAtt 0.1537 TrainAcc 0.6500 TestAcc 0.5996 0.6500
epoch 400 LossPred 0.8682 LossAtt 0.1963 TrainAcc 0.6500 TestAcc 0.5996 0.6500
epoch 500 LossPred 0.8001 LossAtt 0.4225 TrainAcc 0.7300 TestAcc 0.6697 0.7250
epoch 600 LossPred 0.4237 LossAtt 0.3753 TrainAcc 0.8700 TestAcc 0.8241 0.8600
epoch 700 LossPred 0.3704 LossAtt 0.3672 TrainAcc 0.8800 TestAcc 0.8541 0.8900
epoch 800 LossPred 0.6324 LossAtt 0.3639 TrainAcc 0.7800 TestAcc 0.7157 0.7650
epoch 900 LossPred 0.2818 LossAtt 0.3484 TrainAcc 0.9100 TestAcc 0.8609 0.9150
epoch 1000 LossPred 0.3098 LossAtt 0.3412 TrainAcc 0.8900 TestAcc 0.8564 0.9100
epoch 1100 LossPred 0.5157 LossAtt 0.3380 TrainAcc 0.8100 TestAcc 0.7950 0.8350
epoch 1200 LossPred 0.2666 LossAtt 0.3388 TrainAcc 0.9100 TestAcc 0.8741 0.9150
epoch 1300 LossPred 0.2673 LossAtt 0.3460 TrainAcc 0.9000 TestAcc 0.8814 0.9000
epoch 1400 LossPred 0.3112 LossAtt 0.3340 TrainAcc 0.9000 TestAcc 0.8596 0.9050
epoch 1500 LossPred 0.2169 LossAtt 0.3466 TrainAcc 0.9300 TestAcc 0.8746 0.9000
epoch 1600 LossPred 0.2703 LossAtt 0.3418 TrainAcc 0.8800 TestAcc 0.8861 0.9050
epoch 1700 LossPred 0.2483 LossAtt 0.3258 TrainAcc 0.9100 TestAcc 0.8751 0.9200
epoch 1800 LossPred 0.2255 LossAtt 0.3453 TrainAcc 0.9300 TestAcc 0.8851 0.9150
epoch 1900 LossPred 0.2299 LossAtt 0.3413 TrainAcc 0.9400 TestAcc 0.8989 0.9100
epoch 2000 LossPred 0.3563 LossAtt 0.3342 TrainAcc 0.8700 TestAcc 0.8579 0.8700
epoch 2100 LossPred 0.2890 LossAtt 0.3271 TrainAcc 0.8800 TestAcc 0.8834 0.9000
epoch 2200 LossPred 0.4558 LossAtt 0.3343 TrainAcc 0.8200 TestAcc 0.8363 0.8850
epoch 2300 LossPred 0.2637 LossAtt 0.3462 TrainAcc 0.9200 TestAcc 0.9002 0.8950
epoch 2400 LossPred 0.2143 LossAtt 0.3304 TrainAcc 0.9300 TestAcc 0.8789 0.9050
epoch 2500 LossPred 0.2232 LossAtt 0.3466 TrainAcc 0.9500 TestAcc 0.9014 0.9050
Optimization Finished!
********** replication  46  **********
epoch   0 LossPred 1.0257 LossAtt 1.0340 TrainAcc 0.5500 TestAcc 0.5906 0.5350
epoch 100 LossPred 0.9890 LossAtt 0.2473 TrainAcc 0.5500 TestAcc 0.5916 0.5500
epoch 200 LossPred 0.9895 LossAtt 0.1197 TrainAcc 0.5500 TestAcc 0.5916 0.5500
epoch 300 LossPred 0.9893 LossAtt 0.0904 TrainAcc 0.5500 TestAcc 0.5916 0.5500
epoch 400 LossPred 0.9891 LossAtt 0.0849 TrainAcc 0.5500 TestAcc 0.5916 0.5500
epoch 500 LossPred 0.9890 LossAtt 0.0836 TrainAcc 0.5500 TestAcc 0.5916 0.5500
epoch 600 LossPred 0.9889 LossAtt 0.0792 TrainAcc 0.5500 TestAcc 0.5916 0.5500
epoch 700 LossPred 0.9886 LossAtt 0.0908 TrainAcc 0.5500 TestAcc 0.5916 0.5500
epoch 800 LossPred 0.9890 LossAtt 0.1556 TrainAcc 0.5500 TestAcc 0.5916 0.5500
epoch 900 LossPred 0.9344 LossAtt 0.3477 TrainAcc 0.6200 TestAcc 0.6562 0.6150
epoch 1000 LossPred 0.7553 LossAtt 0.3282 TrainAcc 0.6900 TestAcc 0.7435 0.6800
epoch 1100 LossPred 0.5777 LossAtt 0.3370 TrainAcc 0.8300 TestAcc 0.8048 0.8250
epoch 1200 LossPred 0.8202 LossAtt 0.3050 TrainAcc 0.6800 TestAcc 0.6441 0.6650
epoch 1300 LossPred 0.8114 LossAtt 0.3180 TrainAcc 0.7000 TestAcc 0.6517 0.7050
epoch 1400 LossPred 0.5228 LossAtt 0.3170 TrainAcc 0.8400 TestAcc 0.7853 0.8250
epoch 1500 LossPred 0.4910 LossAtt 0.3289 TrainAcc 0.8400 TestAcc 0.7760 0.8300
epoch 1600 LossPred 0.5330 LossAtt 0.3278 TrainAcc 0.7900 TestAcc 0.7497 0.7950
epoch 1700 LossPred 0.5792 LossAtt 0.3075 TrainAcc 0.7900 TestAcc 0.8063 0.7850
epoch 1800 LossPred 0.4701 LossAtt 0.3002 TrainAcc 0.8600 TestAcc 0.8161 0.8450
epoch 1900 LossPred 0.5213 LossAtt 0.2838 TrainAcc 0.8200 TestAcc 0.7875 0.8150
epoch 2000 LossPred 0.4251 LossAtt 0.2883 TrainAcc 0.8800 TestAcc 0.8038 0.8600
epoch 2100 LossPred 0.7458 LossAtt 0.2757 TrainAcc 0.7500 TestAcc 0.6807 0.7600
epoch 2200 LossPred 0.9955 LossAtt 0.2433 TrainAcc 0.5900 TestAcc 0.5085 0.5750
epoch 2300 LossPred 0.4474 LossAtt 0.2634 TrainAcc 0.8600 TestAcc 0.8021 0.8350
epoch 2400 LossPred 0.4937 LossAtt 0.2455 TrainAcc 0.8400 TestAcc 0.8121 0.8200
epoch 2500 LossPred 0.4533 LossAtt 0.2522 TrainAcc 0.8600 TestAcc 0.8148 0.8400
Optimization Finished!
********** replication  47  **********
epoch   0 LossPred 1.0032 LossAtt 1.0105 TrainAcc 0.6100 TestAcc 0.5125 0.5500
epoch 100 LossPred 0.9507 LossAtt 0.4035 TrainAcc 0.6200 TestAcc 0.5448 0.5900
epoch 200 LossPred 0.9415 LossAtt 0.3323 TrainAcc 0.6200 TestAcc 0.5443 0.6200
epoch 300 LossPred 0.9384 LossAtt 0.3200 TrainAcc 0.6200 TestAcc 0.5443 0.6200
epoch 400 LossPred 0.9366 LossAtt 0.2928 TrainAcc 0.6200 TestAcc 0.5443 0.6200
epoch 500 LossPred 0.9362 LossAtt 0.2551 TrainAcc 0.6200 TestAcc 0.5443 0.6200
epoch 600 LossPred 0.9357 LossAtt 0.2409 TrainAcc 0.6200 TestAcc 0.5443 0.6200
epoch 700 LossPred 0.9360 LossAtt 0.2287 TrainAcc 0.6200 TestAcc 0.5445 0.6200
epoch 800 LossPred 0.9374 LossAtt 0.2323 TrainAcc 0.6200 TestAcc 0.5501 0.6150
epoch 900 LossPred 0.9403 LossAtt 0.2126 TrainAcc 0.6200 TestAcc 0.5506 0.6150
epoch 1000 LossPred 0.9472 LossAtt 0.0940 TrainAcc 0.6100 TestAcc 0.5816 0.6100
epoch 1100 LossPred 0.9468 LossAtt 0.0835 TrainAcc 0.6100 TestAcc 0.5816 0.6100
epoch 1200 LossPred 0.9474 LossAtt 0.0695 TrainAcc 0.6100 TestAcc 0.5816 0.6100
epoch 1300 LossPred 0.9482 LossAtt 0.0641 TrainAcc 0.6100 TestAcc 0.5816 0.6100
epoch 1400 LossPred 0.9485 LossAtt 0.0633 TrainAcc 0.6100 TestAcc 0.5816 0.6100
epoch 1500 LossPred 0.9484 LossAtt 0.0648 TrainAcc 0.6100 TestAcc 0.5816 0.6100
epoch 1600 LossPred 0.9486 LossAtt 0.0353 TrainAcc 0.6100 TestAcc 0.5816 0.6100
epoch 1700 LossPred 0.9490 LossAtt 0.0379 TrainAcc 0.6100 TestAcc 0.5816 0.6100
epoch 1800 LossPred 0.9488 LossAtt 0.0318 TrainAcc 0.6100 TestAcc 0.5816 0.6100
epoch 1900 LossPred 0.9490 LossAtt 0.0238 TrainAcc 0.6100 TestAcc 0.5816 0.6100
epoch 2000 LossPred 0.9490 LossAtt 0.0158 TrainAcc 0.6100 TestAcc 0.5816 0.6100
epoch 2100 LossPred 0.9488 LossAtt 0.0257 TrainAcc 0.6100 TestAcc 0.5816 0.6100
epoch 2200 LossPred 0.9489 LossAtt 0.0192 TrainAcc 0.6100 TestAcc 0.5816 0.6100
epoch 2300 LossPred 0.9492 LossAtt 0.0220 TrainAcc 0.6100 TestAcc 0.5816 0.6100
epoch 2400 LossPred 0.9490 LossAtt 0.0159 TrainAcc 0.6100 TestAcc 0.5816 0.6100
epoch 2500 LossPred 0.9492 LossAtt 0.0164 TrainAcc 0.6100 TestAcc 0.5816 0.6100
Optimization Finished!
********** replication  48  **********
epoch   0 LossPred 1.2605 LossAtt 1.0070 TrainAcc 0.4100 TestAcc 0.4622 0.4350
epoch 100 LossPred 0.9026 LossAtt 0.4820 TrainAcc 0.6300 TestAcc 0.5796 0.6400
epoch 200 LossPred 0.8440 LossAtt 0.4302 TrainAcc 0.6200 TestAcc 0.5926 0.6250
epoch 300 LossPred 0.7925 LossAtt 0.3761 TrainAcc 0.7000 TestAcc 0.6306 0.7250
epoch 400 LossPred 0.4957 LossAtt 0.4261 TrainAcc 0.8600 TestAcc 0.8078 0.8600
epoch 500 LossPred 0.4048 LossAtt 0.3278 TrainAcc 0.8600 TestAcc 0.7955 0.8450
epoch 600 LossPred 0.3809 LossAtt 0.3147 TrainAcc 0.8700 TestAcc 0.7900 0.8550
epoch 700 LossPred 0.3739 LossAtt 0.3299 TrainAcc 0.8700 TestAcc 0.8096 0.8750
epoch 800 LossPred 0.3631 LossAtt 0.3180 TrainAcc 0.8900 TestAcc 0.8036 0.8550
epoch 900 LossPred 0.3498 LossAtt 0.3394 TrainAcc 0.8800 TestAcc 0.8083 0.8800
epoch 1000 LossPred 0.3453 LossAtt 0.3275 TrainAcc 0.8800 TestAcc 0.8098 0.8800
epoch 1100 LossPred 0.3436 LossAtt 0.3232 TrainAcc 0.8900 TestAcc 0.8238 0.8800
epoch 1200 LossPred 0.3498 LossAtt 0.3178 TrainAcc 0.8700 TestAcc 0.8136 0.8700
epoch 1300 LossPred 0.3323 LossAtt 0.3363 TrainAcc 0.8900 TestAcc 0.8188 0.8800
epoch 1400 LossPred 0.3352 LossAtt 0.3261 TrainAcc 0.8900 TestAcc 0.8191 0.8750
epoch 1500 LossPred 0.3346 LossAtt 0.3340 TrainAcc 0.9000 TestAcc 0.8326 0.8700
epoch 1600 LossPred 0.3218 LossAtt 0.3212 TrainAcc 0.9000 TestAcc 0.8291 0.8800
epoch 1700 LossPred 0.3371 LossAtt 0.3131 TrainAcc 0.8900 TestAcc 0.8238 0.8750
epoch 1800 LossPred 0.3248 LossAtt 0.3503 TrainAcc 0.9000 TestAcc 0.8348 0.8850
epoch 1900 LossPred 0.3229 LossAtt 0.3443 TrainAcc 0.8900 TestAcc 0.8356 0.8900
epoch 2000 LossPred 0.3347 LossAtt 0.3530 TrainAcc 0.8800 TestAcc 0.8308 0.8900
epoch 2100 LossPred 0.3274 LossAtt 0.3315 TrainAcc 0.8900 TestAcc 0.8326 0.8950
epoch 2200 LossPred 0.3846 LossAtt 0.3425 TrainAcc 0.8700 TestAcc 0.8141 0.8800
epoch 2300 LossPred 0.3293 LossAtt 0.3533 TrainAcc 0.8700 TestAcc 0.8296 0.8850
epoch 2400 LossPred 0.2833 LossAtt 0.3583 TrainAcc 0.9100 TestAcc 0.8371 0.9050
epoch 2500 LossPred 0.2251 LossAtt 0.3563 TrainAcc 0.9400 TestAcc 0.8689 0.9200
Optimization Finished!
********** replication  49  **********
epoch   0 LossPred 1.1494 LossAtt 1.0155 TrainAcc 0.4200 TestAcc 0.5003 0.4050
epoch 100 LossPred 0.8582 LossAtt 0.4340 TrainAcc 0.6800 TestAcc 0.5878 0.6800
epoch 200 LossPred 0.8371 LossAtt 0.3669 TrainAcc 0.6800 TestAcc 0.5878 0.6800
epoch 300 LossPred 0.8146 LossAtt 0.2640 TrainAcc 0.6800 TestAcc 0.5878 0.7000
epoch 400 LossPred 0.6746 LossAtt 0.3454 TrainAcc 0.7600 TestAcc 0.6969 0.7550
epoch 500 LossPred 0.4200 LossAtt 0.3365 TrainAcc 0.8800 TestAcc 0.8466 0.8600
epoch 600 LossPred 0.4178 LossAtt 0.3329 TrainAcc 0.8700 TestAcc 0.8336 0.8800
epoch 700 LossPred 0.3364 LossAtt 0.3114 TrainAcc 0.9200 TestAcc 0.8546 0.8700
epoch 800 LossPred 0.5106 LossAtt 0.3316 TrainAcc 0.8200 TestAcc 0.7758 0.8250
epoch 900 LossPred 0.4322 LossAtt 0.3074 TrainAcc 0.8400 TestAcc 0.8231 0.8650
epoch 1000 LossPred 0.4132 LossAtt 0.3005 TrainAcc 0.8700 TestAcc 0.8041 0.8250
epoch 1100 LossPred 0.3208 LossAtt 0.3191 TrainAcc 0.9100 TestAcc 0.8526 0.8900
epoch 1200 LossPred 0.3474 LossAtt 0.3026 TrainAcc 0.8700 TestAcc 0.8241 0.8900
epoch 1300 LossPred 0.3256 LossAtt 0.2962 TrainAcc 0.9100 TestAcc 0.8431 0.9000
epoch 1400 LossPred 0.2801 LossAtt 0.2963 TrainAcc 0.9200 TestAcc 0.8559 0.8950
epoch 1500 LossPred 0.2870 LossAtt 0.2789 TrainAcc 0.9100 TestAcc 0.8534 0.8950
epoch 1600 LossPred 0.7880 LossAtt 0.2595 TrainAcc 0.7400 TestAcc 0.7272 0.7350
epoch 1700 LossPred 0.8195 LossAtt 0.2266 TrainAcc 0.7000 TestAcc 0.6924 0.6800
epoch 1800 LossPred 0.5665 LossAtt 0.2944 TrainAcc 0.8000 TestAcc 0.7635 0.8150
epoch 1900 LossPred 0.2919 LossAtt 0.2761 TrainAcc 0.9200 TestAcc 0.8516 0.9100
epoch 2000 LossPred 0.3089 LossAtt 0.2600 TrainAcc 0.9100 TestAcc 0.8549 0.9100
epoch 2100 LossPred 0.3267 LossAtt 0.2610 TrainAcc 0.8900 TestAcc 0.8393 0.8900
epoch 2200 LossPred 0.5409 LossAtt 0.2660 TrainAcc 0.8300 TestAcc 0.7823 0.7950
epoch 2300 LossPred 0.6594 LossAtt 0.2625 TrainAcc 0.7700 TestAcc 0.7407 0.7450
epoch 2400 LossPred 0.3345 LossAtt 0.2827 TrainAcc 0.9100 TestAcc 0.8338 0.8750
epoch 2500 LossPred 0.3076 LossAtt 0.2938 TrainAcc 0.9200 TestAcc 0.8353 0.8950
Optimization Finished!
********** replication  50  **********
epoch   0 LossPred 0.9885 LossAtt 1.0005 TrainAcc 0.5300 TestAcc 0.4900 0.5300
epoch 100 LossPred 0.9466 LossAtt 0.3845 TrainAcc 0.5600 TestAcc 0.5090 0.5650
epoch 200 LossPred 0.9405 LossAtt 0.3277 TrainAcc 0.5700 TestAcc 0.5058 0.5500
epoch 300 LossPred 0.9519 LossAtt 0.2555 TrainAcc 0.5700 TestAcc 0.5781 0.5700
epoch 400 LossPred 0.8542 LossAtt 0.3510 TrainAcc 0.7100 TestAcc 0.6329 0.6900
epoch 500 LossPred 0.1724 LossAtt 0.3480 TrainAcc 0.9400 TestAcc 0.8616 0.9050
epoch 600 LossPred 0.1822 LossAtt 0.3357 TrainAcc 0.9500 TestAcc 0.8476 0.9150
epoch 700 LossPred 0.1400 LossAtt 0.3396 TrainAcc 0.9500 TestAcc 0.8649 0.9100
epoch 800 LossPred 0.1580 LossAtt 0.3327 TrainAcc 0.9500 TestAcc 0.8649 0.9150
epoch 900 LossPred 0.1587 LossAtt 0.3343 TrainAcc 0.9400 TestAcc 0.8649 0.9250
epoch 1000 LossPred 0.1374 LossAtt 0.3258 TrainAcc 0.9600 TestAcc 0.8691 0.9200
epoch 1100 LossPred 0.1621 LossAtt 0.3282 TrainAcc 0.9400 TestAcc 0.8579 0.9200
epoch 1200 LossPred 0.1311 LossAtt 0.3286 TrainAcc 0.9500 TestAcc 0.8664 0.9200
epoch 1300 LossPred 0.1678 LossAtt 0.3182 TrainAcc 0.9500 TestAcc 0.8549 0.9150
epoch 1400 LossPred 0.1553 LossAtt 0.3322 TrainAcc 0.9400 TestAcc 0.8669 0.9250
epoch 1500 LossPred 0.1592 LossAtt 0.3149 TrainAcc 0.9500 TestAcc 0.8686 0.9050
epoch 1600 LossPred 0.1349 LossAtt 0.3135 TrainAcc 0.9600 TestAcc 0.8741 0.9050
epoch 1700 LossPred 0.1292 LossAtt 0.2977 TrainAcc 0.9500 TestAcc 0.8759 0.9250
epoch 1800 LossPred 0.1304 LossAtt 0.2974 TrainAcc 0.9700 TestAcc 0.8646 0.9150
epoch 1900 LossPred 0.1282 LossAtt 0.3015 TrainAcc 0.9600 TestAcc 0.8776 0.9250
epoch 2000 LossPred 0.1288 LossAtt 0.3076 TrainAcc 0.9700 TestAcc 0.8709 0.9300
epoch 2100 LossPred 0.1237 LossAtt 0.2938 TrainAcc 0.9500 TestAcc 0.8801 0.9250
epoch 2200 LossPred 0.1288 LossAtt 0.2892 TrainAcc 0.9600 TestAcc 0.8829 0.9300
epoch 2300 LossPred 0.1229 LossAtt 0.2980 TrainAcc 0.9600 TestAcc 0.8839 0.9300
epoch 2400 LossPred 0.1261 LossAtt 0.2832 TrainAcc 0.9700 TestAcc 0.8826 0.9250
epoch 2500 LossPred 0.1400 LossAtt 0.2824 TrainAcc 0.9400 TestAcc 0.8771 0.9300
Optimization Finished!
********** replication  51  **********
epoch   0 LossPred 1.2608 LossAtt 1.0089 TrainAcc 0.4400 TestAcc 0.4642 0.4350
epoch 100 LossPred 0.9377 LossAtt 0.5374 TrainAcc 0.5800 TestAcc 0.5020 0.5950
epoch 200 LossPred 0.8619 LossAtt 0.5590 TrainAcc 0.6700 TestAcc 0.5358 0.6700
epoch 300 LossPred 0.8245 LossAtt 0.5436 TrainAcc 0.6900 TestAcc 0.5548 0.6800
epoch 400 LossPred 0.8087 LossAtt 0.5170 TrainAcc 0.6900 TestAcc 0.5480 0.6750
epoch 500 LossPred 0.7975 LossAtt 0.4486 TrainAcc 0.6900 TestAcc 0.5433 0.6800
epoch 600 LossPred 0.7890 LossAtt 0.4131 TrainAcc 0.6900 TestAcc 0.5433 0.6850
epoch 700 LossPred 0.7860 LossAtt 0.3725 TrainAcc 0.6900 TestAcc 0.5433 0.6900
epoch 800 LossPred 0.7800 LossAtt 0.3537 TrainAcc 0.6900 TestAcc 0.5433 0.6900
epoch 900 LossPred 0.7727 LossAtt 0.3315 TrainAcc 0.6900 TestAcc 0.5433 0.6900
epoch 1000 LossPred 0.7654 LossAtt 0.2843 TrainAcc 0.6900 TestAcc 0.5433 0.6900
epoch 1100 LossPred 0.7567 LossAtt 0.3282 TrainAcc 0.7200 TestAcc 0.5871 0.7200
epoch 1200 LossPred 0.7317 LossAtt 0.3341 TrainAcc 0.7600 TestAcc 0.6256 0.7400
epoch 1300 LossPred 0.6704 LossAtt 0.4115 TrainAcc 0.7700 TestAcc 0.6877 0.7450
epoch 1400 LossPred 0.5033 LossAtt 0.4724 TrainAcc 0.8200 TestAcc 0.7798 0.8250
epoch 1500 LossPred 0.3680 LossAtt 0.4853 TrainAcc 0.9000 TestAcc 0.7795 0.8750
epoch 1600 LossPred 0.3394 LossAtt 0.5532 TrainAcc 0.9000 TestAcc 0.7640 0.8950
epoch 1700 LossPred 0.4249 LossAtt 0.5810 TrainAcc 0.8500 TestAcc 0.7310 0.8300
epoch 1800 LossPred 0.4370 LossAtt 0.5675 TrainAcc 0.8500 TestAcc 0.7350 0.8450
epoch 1900 LossPred 0.3687 LossAtt 0.5224 TrainAcc 0.8800 TestAcc 0.7823 0.8700
epoch 2000 LossPred 0.3101 LossAtt 0.5536 TrainAcc 0.9000 TestAcc 0.7748 0.8800
epoch 2100 LossPred 0.3014 LossAtt 0.5525 TrainAcc 0.9100 TestAcc 0.7750 0.8700
epoch 2200 LossPred 0.2898 LossAtt 0.5232 TrainAcc 0.9000 TestAcc 0.7820 0.8800
epoch 2300 LossPred 0.3625 LossAtt 0.5278 TrainAcc 0.8800 TestAcc 0.7560 0.8650
epoch 2400 LossPred 0.3233 LossAtt 0.5115 TrainAcc 0.8900 TestAcc 0.7603 0.8700
epoch 2500 LossPred 0.2854 LossAtt 0.5114 TrainAcc 0.9000 TestAcc 0.7648 0.8600
Optimization Finished!
********** replication  52  **********
epoch   0 LossPred 0.9693 LossAtt 1.0173 TrainAcc 0.6200 TestAcc 0.5008 0.5700
epoch 100 LossPred 0.8353 LossAtt 0.4165 TrainAcc 0.6700 TestAcc 0.5876 0.6850
epoch 200 LossPred 0.7806 LossAtt 0.3716 TrainAcc 0.7200 TestAcc 0.5886 0.7200
epoch 300 LossPred 0.5733 LossAtt 0.3644 TrainAcc 0.7900 TestAcc 0.7407 0.8100
epoch 400 LossPred 0.5667 LossAtt 0.3186 TrainAcc 0.7800 TestAcc 0.7825 0.7600
epoch 500 LossPred 0.6298 LossAtt 0.2928 TrainAcc 0.8000 TestAcc 0.8098 0.8250
epoch 600 LossPred 0.4087 LossAtt 0.3051 TrainAcc 0.8600 TestAcc 0.8341 0.8750
epoch 700 LossPred 0.3971 LossAtt 0.2874 TrainAcc 0.8500 TestAcc 0.8473 0.8700
epoch 800 LossPred 0.6041 LossAtt 0.2615 TrainAcc 0.8000 TestAcc 0.8173 0.8100
epoch 900 LossPred 0.3983 LossAtt 0.2698 TrainAcc 0.8600 TestAcc 0.8549 0.8650
epoch 1000 LossPred 0.3326 LossAtt 0.2632 TrainAcc 0.8800 TestAcc 0.8651 0.8900
epoch 1100 LossPred 0.4350 LossAtt 0.2696 TrainAcc 0.8600 TestAcc 0.7988 0.8500
epoch 1200 LossPred 0.3261 LossAtt 0.2828 TrainAcc 0.8900 TestAcc 0.8606 0.8900
epoch 1300 LossPred 0.4695 LossAtt 0.2747 TrainAcc 0.8400 TestAcc 0.7858 0.8250
epoch 1400 LossPred 0.5539 LossAtt 0.2616 TrainAcc 0.8100 TestAcc 0.8226 0.8150
epoch 1500 LossPred 0.6086 LossAtt 0.2836 TrainAcc 0.7600 TestAcc 0.7465 0.7700
epoch 1600 LossPred 0.4038 LossAtt 0.3074 TrainAcc 0.8700 TestAcc 0.8218 0.8750
epoch 1700 LossPred 0.5492 LossAtt 0.3092 TrainAcc 0.8000 TestAcc 0.8088 0.7850
epoch 1800 LossPred 0.5667 LossAtt 0.3220 TrainAcc 0.8000 TestAcc 0.8123 0.8150
epoch 1900 LossPred 0.4565 LossAtt 0.3595 TrainAcc 0.8400 TestAcc 0.8066 0.8550
epoch 2000 LossPred 0.4682 LossAtt 0.3447 TrainAcc 0.8400 TestAcc 0.8313 0.8450
epoch 2100 LossPred 0.4958 LossAtt 0.3617 TrainAcc 0.7900 TestAcc 0.7673 0.7900
epoch 2200 LossPred 0.5093 LossAtt 0.3689 TrainAcc 0.8200 TestAcc 0.8351 0.8300
epoch 2300 LossPred 0.3907 LossAtt 0.3736 TrainAcc 0.8400 TestAcc 0.8433 0.8400
epoch 2400 LossPred 0.5217 LossAtt 0.3327 TrainAcc 0.8100 TestAcc 0.8248 0.8300
epoch 2500 LossPred 0.3658 LossAtt 0.3609 TrainAcc 0.8700 TestAcc 0.8303 0.8700
Optimization Finished!
********** replication  53  **********
epoch   0 LossPred 1.1526 LossAtt 1.0000 TrainAcc 0.4100 TestAcc 0.4617 0.4300
epoch 100 LossPred 0.9253 LossAtt 0.4417 TrainAcc 0.6200 TestAcc 0.5891 0.6200
epoch 200 LossPred 0.9091 LossAtt 0.4042 TrainAcc 0.6200 TestAcc 0.5891 0.6200
epoch 300 LossPred 0.9043 LossAtt 0.3633 TrainAcc 0.6200 TestAcc 0.5891 0.6250
epoch 400 LossPred 0.9022 LossAtt 0.3430 TrainAcc 0.6200 TestAcc 0.5908 0.6450
epoch 500 LossPred 0.9006 LossAtt 0.3299 TrainAcc 0.6200 TestAcc 0.6049 0.6450
epoch 600 LossPred 0.8992 LossAtt 0.3749 TrainAcc 0.6500 TestAcc 0.6271 0.6500
epoch 700 LossPred 0.8930 LossAtt 0.3800 TrainAcc 0.6700 TestAcc 0.5806 0.6600
epoch 800 LossPred 0.8836 LossAtt 0.3591 TrainAcc 0.6700 TestAcc 0.5806 0.6650
epoch 900 LossPred 0.8748 LossAtt 0.3855 TrainAcc 0.6700 TestAcc 0.5878 0.6700
epoch 1000 LossPred 0.8676 LossAtt 0.3806 TrainAcc 0.7000 TestAcc 0.6109 0.6900
epoch 1100 LossPred 0.8484 LossAtt 0.5214 TrainAcc 0.6800 TestAcc 0.6144 0.6800
epoch 1200 LossPred 0.5317 LossAtt 0.5815 TrainAcc 0.8400 TestAcc 0.7540 0.8450
epoch 1300 LossPred 0.2656 LossAtt 0.4854 TrainAcc 0.9000 TestAcc 0.8689 0.8750
epoch 1400 LossPred 0.2188 LossAtt 0.4548 TrainAcc 0.9200 TestAcc 0.8806 0.9050
epoch 1500 LossPred 0.2364 LossAtt 0.4401 TrainAcc 0.9200 TestAcc 0.8606 0.9050
epoch 1600 LossPred 0.2041 LossAtt 0.4589 TrainAcc 0.9200 TestAcc 0.8881 0.9100
epoch 1700 LossPred 0.1802 LossAtt 0.4538 TrainAcc 0.9500 TestAcc 0.8871 0.9150
epoch 1800 LossPred 0.1789 LossAtt 0.4408 TrainAcc 0.9300 TestAcc 0.8899 0.9150
epoch 1900 LossPred 0.2039 LossAtt 0.4179 TrainAcc 0.9400 TestAcc 0.8721 0.9100
epoch 2000 LossPred 0.1652 LossAtt 0.4185 TrainAcc 0.9300 TestAcc 0.8849 0.9450
epoch 2100 LossPred 0.2368 LossAtt 0.4249 TrainAcc 0.9200 TestAcc 0.8629 0.9400
epoch 2200 LossPred 0.1756 LossAtt 0.4109 TrainAcc 0.9400 TestAcc 0.8806 0.9200
epoch 2300 LossPred 0.1840 LossAtt 0.4025 TrainAcc 0.9400 TestAcc 0.8744 0.9200
epoch 2400 LossPred 0.1810 LossAtt 0.3950 TrainAcc 0.9400 TestAcc 0.8629 0.9200
epoch 2500 LossPred 0.2061 LossAtt 0.3946 TrainAcc 0.9300 TestAcc 0.8574 0.9000
Optimization Finished!
********** replication  54  **********
epoch   0 LossPred 1.0363 LossAtt 0.9950 TrainAcc 0.3900 TestAcc 0.4690 0.4000
epoch 100 LossPred 0.8838 LossAtt 0.2403 TrainAcc 0.6500 TestAcc 0.5846 0.6500
epoch 200 LossPred 0.8642 LossAtt 0.1312 TrainAcc 0.6500 TestAcc 0.5846 0.6500
epoch 300 LossPred 0.8511 LossAtt 0.0938 TrainAcc 0.6500 TestAcc 0.5846 0.6500
epoch 400 LossPred 0.8491 LossAtt 0.0619 TrainAcc 0.6500 TestAcc 0.5846 0.6500
epoch 500 LossPred 0.8703 LossAtt 0.0622 TrainAcc 0.6500 TestAcc 0.5846 0.6500
epoch 600 LossPred 0.8866 LossAtt 0.0830 TrainAcc 0.6500 TestAcc 0.5846 0.6500
epoch 700 LossPred 0.8897 LossAtt 0.1009 TrainAcc 0.6500 TestAcc 0.5846 0.6500
epoch 800 LossPred 0.8727 LossAtt 0.1203 TrainAcc 0.6500 TestAcc 0.5846 0.6500
epoch 900 LossPred 0.8471 LossAtt 0.1311 TrainAcc 0.6500 TestAcc 0.5846 0.6500
epoch 1000 LossPred 0.8460 LossAtt 0.1193 TrainAcc 0.6500 TestAcc 0.5846 0.6500
epoch 1100 LossPred 0.8470 LossAtt 0.1051 TrainAcc 0.6500 TestAcc 0.5846 0.6500
epoch 1200 LossPred 0.9166 LossAtt 0.1150 TrainAcc 0.6500 TestAcc 0.5846 0.6500
epoch 1300 LossPred 0.8756 LossAtt 0.1958 TrainAcc 0.6000 TestAcc 0.5375 0.6200
epoch 1400 LossPred 0.8122 LossAtt 0.1975 TrainAcc 0.6500 TestAcc 0.5846 0.6500
epoch 1500 LossPred 0.8054 LossAtt 0.2203 TrainAcc 0.6800 TestAcc 0.6461 0.7000
epoch 1600 LossPred 0.8034 LossAtt 0.2325 TrainAcc 0.6700 TestAcc 0.6334 0.6700
epoch 1700 LossPred 0.8018 LossAtt 0.2520 TrainAcc 0.6700 TestAcc 0.6334 0.6700
epoch 1800 LossPred 0.7991 LossAtt 0.2577 TrainAcc 0.6500 TestAcc 0.5846 0.6500
epoch 1900 LossPred 0.7798 LossAtt 0.2892 TrainAcc 0.6500 TestAcc 0.5733 0.6400
epoch 2000 LossPred 0.7384 LossAtt 0.3176 TrainAcc 0.7600 TestAcc 0.6319 0.7050
epoch 2100 LossPred 0.7293 LossAtt 0.3557 TrainAcc 0.7200 TestAcc 0.6514 0.7150
epoch 2200 LossPred 0.7429 LossAtt 0.3669 TrainAcc 0.7100 TestAcc 0.6401 0.7300
epoch 2300 LossPred 0.7330 LossAtt 0.4716 TrainAcc 0.7300 TestAcc 0.6562 0.6950
epoch 2400 LossPred 0.6380 LossAtt 0.4635 TrainAcc 0.7700 TestAcc 0.7200 0.7700
epoch 2500 LossPred 0.5819 LossAtt 0.4646 TrainAcc 0.7900 TestAcc 0.7360 0.8000
Optimization Finished!
********** replication  55  **********
epoch   0 LossPred 1.0468 LossAtt 1.0008 TrainAcc 0.5100 TestAcc 0.4117 0.5100
epoch 100 LossPred 0.8727 LossAtt 0.3282 TrainAcc 0.6700 TestAcc 0.5663 0.6650
epoch 200 LossPred 0.8913 LossAtt 0.1945 TrainAcc 0.6800 TestAcc 0.5490 0.6800
epoch 300 LossPred 0.8423 LossAtt 0.1829 TrainAcc 0.6800 TestAcc 0.5490 0.6800
epoch 400 LossPred 0.8123 LossAtt 0.1971 TrainAcc 0.6800 TestAcc 0.5490 0.6800
epoch 500 LossPred 0.7957 LossAtt 0.2032 TrainAcc 0.6800 TestAcc 0.5490 0.6850
epoch 600 LossPred 0.4471 LossAtt 0.4663 TrainAcc 0.8400 TestAcc 0.8403 0.8450
epoch 700 LossPred 0.3832 LossAtt 0.4176 TrainAcc 0.8800 TestAcc 0.8831 0.8900
epoch 800 LossPred 0.2424 LossAtt 0.4441 TrainAcc 0.9200 TestAcc 0.8751 0.9150
epoch 900 LossPred 0.2597 LossAtt 0.4311 TrainAcc 0.9200 TestAcc 0.8984 0.9150
epoch 1000 LossPred 0.2537 LossAtt 0.4408 TrainAcc 0.9200 TestAcc 0.8726 0.9050
epoch 1100 LossPred 0.2562 LossAtt 0.4448 TrainAcc 0.9100 TestAcc 0.8949 0.9150
epoch 1200 LossPred 0.2951 LossAtt 0.4570 TrainAcc 0.8900 TestAcc 0.8431 0.8750
epoch 1300 LossPred 0.3233 LossAtt 0.4226 TrainAcc 0.9100 TestAcc 0.8994 0.8800
epoch 1400 LossPred 0.3107 LossAtt 0.4606 TrainAcc 0.9000 TestAcc 0.8358 0.8600
epoch 1500 LossPred 0.2193 LossAtt 0.4412 TrainAcc 0.9200 TestAcc 0.8821 0.9350
epoch 1600 LossPred 0.3494 LossAtt 0.4748 TrainAcc 0.8700 TestAcc 0.8368 0.8800
epoch 1700 LossPred 0.3361 LossAtt 0.4318 TrainAcc 0.9000 TestAcc 0.8946 0.8800
epoch 1800 LossPred 0.2666 LossAtt 0.4349 TrainAcc 0.9200 TestAcc 0.8879 0.9200
epoch 1900 LossPred 0.2348 LossAtt 0.4393 TrainAcc 0.9300 TestAcc 0.9004 0.9300
epoch 2000 LossPred 0.2378 LossAtt 0.4597 TrainAcc 0.9000 TestAcc 0.8701 0.9100
epoch 2100 LossPred 0.2346 LossAtt 0.4403 TrainAcc 0.9200 TestAcc 0.8616 0.9150
epoch 2200 LossPred 0.2214 LossAtt 0.4493 TrainAcc 0.9200 TestAcc 0.8911 0.9350
epoch 2300 LossPred 0.3206 LossAtt 0.4177 TrainAcc 0.9100 TestAcc 0.8971 0.8850
epoch 2400 LossPred 0.2136 LossAtt 0.4483 TrainAcc 0.9300 TestAcc 0.8726 0.9200
epoch 2500 LossPred 0.2525 LossAtt 0.4572 TrainAcc 0.9100 TestAcc 0.8584 0.9100
Optimization Finished!
********** replication  56  **********
epoch   0 LossPred 1.0591 LossAtt 1.0111 TrainAcc 0.5800 TestAcc 0.5340 0.5400
epoch 100 LossPred 0.9428 LossAtt 0.3023 TrainAcc 0.6200 TestAcc 0.5938 0.6200
epoch 200 LossPred 0.9362 LossAtt 0.2320 TrainAcc 0.6200 TestAcc 0.5938 0.6200
epoch 300 LossPred 0.9336 LossAtt 0.2143 TrainAcc 0.6200 TestAcc 0.5938 0.6200
epoch 400 LossPred 0.9220 LossAtt 0.2074 TrainAcc 0.6200 TestAcc 0.5938 0.6200
epoch 500 LossPred 0.9121 LossAtt 0.1756 TrainAcc 0.6200 TestAcc 0.5938 0.6200
epoch 600 LossPred 0.9037 LossAtt 0.1517 TrainAcc 0.6200 TestAcc 0.5938 0.6200
epoch 700 LossPred 0.9069 LossAtt 0.1722 TrainAcc 0.6200 TestAcc 0.5938 0.6200
epoch 800 LossPred 0.9064 LossAtt 0.1744 TrainAcc 0.6200 TestAcc 0.5938 0.6200
epoch 900 LossPred 0.8916 LossAtt 0.1464 TrainAcc 0.6400 TestAcc 0.5611 0.6400
epoch 1000 LossPred 0.8784 LossAtt 0.1452 TrainAcc 0.6400 TestAcc 0.5611 0.6250
epoch 1100 LossPred 0.8398 LossAtt 0.5027 TrainAcc 0.7000 TestAcc 0.5811 0.6850
epoch 1200 LossPred 0.7997 LossAtt 0.5355 TrainAcc 0.6900 TestAcc 0.6116 0.6800
epoch 1300 LossPred 0.6767 LossAtt 0.6152 TrainAcc 0.7600 TestAcc 0.6637 0.7450
epoch 1400 LossPred 0.2565 LossAtt 0.5289 TrainAcc 0.9100 TestAcc 0.8569 0.9050
epoch 1500 LossPred 0.1151 LossAtt 0.5273 TrainAcc 0.9600 TestAcc 0.8686 0.9700
epoch 1600 LossPred 0.1796 LossAtt 0.5429 TrainAcc 0.9400 TestAcc 0.8423 0.9400
epoch 1700 LossPred 0.1047 LossAtt 0.5649 TrainAcc 0.9600 TestAcc 0.8799 0.9550
epoch 1800 LossPred 0.0987 LossAtt 0.5430 TrainAcc 0.9700 TestAcc 0.8906 0.9450
epoch 1900 LossPred 0.1018 LossAtt 0.5485 TrainAcc 0.9800 TestAcc 0.8886 0.9650
epoch 2000 LossPred 0.1108 LossAtt 0.5280 TrainAcc 0.9700 TestAcc 0.8584 0.9650
epoch 2100 LossPred 0.0802 LossAtt 0.5484 TrainAcc 0.9700 TestAcc 0.9007 0.9700
epoch 2200 LossPred 0.0786 LossAtt 0.5245 TrainAcc 0.9700 TestAcc 0.8839 0.9750
epoch 2300 LossPred 0.1108 LossAtt 0.4906 TrainAcc 0.9600 TestAcc 0.8689 0.9500
epoch 2400 LossPred 0.0693 LossAtt 0.4946 TrainAcc 0.9900 TestAcc 0.8934 0.9800
epoch 2500 LossPred 0.0707 LossAtt 0.5008 TrainAcc 0.9700 TestAcc 0.8864 0.9800
Optimization Finished!
********** replication  57  **********
epoch   0 LossPred 1.0368 LossAtt 1.0224 TrainAcc 0.5100 TestAcc 0.5551 0.5100
epoch 100 LossPred 0.9488 LossAtt 0.3297 TrainAcc 0.5800 TestAcc 0.5868 0.5800
epoch 200 LossPred 0.9344 LossAtt 0.3225 TrainAcc 0.5800 TestAcc 0.5868 0.5750
epoch 300 LossPred 0.4000 LossAtt 0.4399 TrainAcc 0.9100 TestAcc 0.8629 0.8650
epoch 400 LossPred 0.2582 LossAtt 0.4110 TrainAcc 0.9200 TestAcc 0.8599 0.9100
epoch 500 LossPred 0.1886 LossAtt 0.4057 TrainAcc 0.9600 TestAcc 0.8896 0.9200
epoch 600 LossPred 0.2058 LossAtt 0.3977 TrainAcc 0.9200 TestAcc 0.8611 0.9100
epoch 700 LossPred 0.1620 LossAtt 0.3650 TrainAcc 0.9900 TestAcc 0.9182 0.9300
epoch 800 LossPred 0.1507 LossAtt 0.2980 TrainAcc 0.9700 TestAcc 0.9147 0.9800
epoch 900 LossPred 0.4362 LossAtt 0.2816 TrainAcc 0.8500 TestAcc 0.8296 0.8450
epoch 1000 LossPred 0.5015 LossAtt 0.2573 TrainAcc 0.8500 TestAcc 0.8311 0.8400
epoch 1100 LossPred 0.1177 LossAtt 0.2463 TrainAcc 0.9900 TestAcc 0.9302 0.9850
epoch 1200 LossPred 0.1423 LossAtt 0.2351 TrainAcc 0.9800 TestAcc 0.9032 0.9700
epoch 1300 LossPred 0.1089 LossAtt 0.2372 TrainAcc 0.9900 TestAcc 0.9277 0.9900
epoch 1400 LossPred 0.1199 LossAtt 0.2274 TrainAcc 0.9900 TestAcc 0.9159 0.9850
epoch 1500 LossPred 0.3231 LossAtt 0.2250 TrainAcc 0.9000 TestAcc 0.8218 0.9000
epoch 1600 LossPred 0.3262 LossAtt 0.2179 TrainAcc 0.8900 TestAcc 0.8216 0.8950
epoch 1700 LossPred 0.1006 LossAtt 0.2234 TrainAcc 0.9900 TestAcc 0.9162 0.9900
epoch 1800 LossPred 0.3625 LossAtt 0.2113 TrainAcc 0.8700 TestAcc 0.8131 0.8700
epoch 1900 LossPred 0.1010 LossAtt 0.2302 TrainAcc 0.9900 TestAcc 0.9167 0.9900
epoch 2000 LossPred 0.1241 LossAtt 0.2383 TrainAcc 0.9700 TestAcc 0.8874 0.9650
epoch 2100 LossPred 0.0933 LossAtt 0.2041 TrainAcc 0.9900 TestAcc 0.9159 0.9900
epoch 2200 LossPred 0.1323 LossAtt 0.2095 TrainAcc 0.9500 TestAcc 0.8764 0.9500
epoch 2300 LossPred 0.5167 LossAtt 0.2219 TrainAcc 0.8700 TestAcc 0.7673 0.8650
epoch 2400 LossPred 0.0980 LossAtt 0.2130 TrainAcc 0.9900 TestAcc 0.9017 0.9800
epoch 2500 LossPred 0.1030 LossAtt 0.2341 TrainAcc 0.9500 TestAcc 0.8954 0.9600
Optimization Finished!
********** replication  58  **********
epoch   0 LossPred 1.0551 LossAtt 0.9923 TrainAcc 0.5400 TestAcc 0.5428 0.5500
epoch 100 LossPred 0.8668 LossAtt 0.4148 TrainAcc 0.6500 TestAcc 0.5856 0.6350
epoch 200 LossPred 0.8346 LossAtt 0.4119 TrainAcc 0.6500 TestAcc 0.5856 0.6500
epoch 300 LossPred 0.8532 LossAtt 0.4475 TrainAcc 0.6000 TestAcc 0.6572 0.6150
epoch 400 LossPred 0.8571 LossAtt 0.4087 TrainAcc 0.5700 TestAcc 0.5603 0.5600
epoch 500 LossPred 0.9511 LossAtt 0.2804 TrainAcc 0.6500 TestAcc 0.5856 0.6500
epoch 600 LossPred 0.9118 LossAtt 0.2411 TrainAcc 0.6500 TestAcc 0.5856 0.6500
epoch 700 LossPred 0.8926 LossAtt 0.2297 TrainAcc 0.6500 TestAcc 0.5856 0.6500
epoch 800 LossPred 0.8863 LossAtt 0.2179 TrainAcc 0.6500 TestAcc 0.5856 0.6500
epoch 900 LossPred 0.8908 LossAtt 0.2072 TrainAcc 0.6500 TestAcc 0.5856 0.6500
epoch 1000 LossPred 0.8792 LossAtt 0.1935 TrainAcc 0.6500 TestAcc 0.5856 0.6500
epoch 1100 LossPred 0.8821 LossAtt 0.1638 TrainAcc 0.6500 TestAcc 0.5856 0.6500
epoch 1200 LossPred 0.8840 LossAtt 0.1639 TrainAcc 0.6500 TestAcc 0.5856 0.6500
epoch 1300 LossPred 0.8831 LossAtt 0.1653 TrainAcc 0.6500 TestAcc 0.5856 0.6500
epoch 1400 LossPred 0.8819 LossAtt 0.1528 TrainAcc 0.6500 TestAcc 0.5856 0.6500
epoch 1500 LossPred 0.8809 LossAtt 0.1531 TrainAcc 0.6500 TestAcc 0.5856 0.6500
epoch 1600 LossPred 0.8796 LossAtt 0.1606 TrainAcc 0.6500 TestAcc 0.5856 0.6500
epoch 1700 LossPred 0.8808 LossAtt 0.1692 TrainAcc 0.6500 TestAcc 0.5856 0.6500
epoch 1800 LossPred 0.8823 LossAtt 0.1610 TrainAcc 0.6500 TestAcc 0.5856 0.6500
epoch 1900 LossPred 0.8809 LossAtt 0.1492 TrainAcc 0.6500 TestAcc 0.5856 0.6500
epoch 2000 LossPred 0.8798 LossAtt 0.1366 TrainAcc 0.6500 TestAcc 0.5856 0.6500
epoch 2100 LossPred 0.8799 LossAtt 0.1439 TrainAcc 0.6500 TestAcc 0.5856 0.6500
epoch 2200 LossPred 0.8796 LossAtt 0.1421 TrainAcc 0.6500 TestAcc 0.5856 0.6500
epoch 2300 LossPred 0.8789 LossAtt 0.1535 TrainAcc 0.6500 TestAcc 0.5856 0.6500
epoch 2400 LossPred 0.8783 LossAtt 0.1402 TrainAcc 0.6500 TestAcc 0.5856 0.6500
epoch 2500 LossPred 0.8773 LossAtt 0.1446 TrainAcc 0.6500 TestAcc 0.5856 0.6500
Optimization Finished!
********** replication  59  **********
epoch   0 LossPred 1.0340 LossAtt 1.0022 TrainAcc 0.5900 TestAcc 0.5193 0.5700
epoch 100 LossPred 0.9018 LossAtt 0.3660 TrainAcc 0.6200 TestAcc 0.5813 0.6200
epoch 200 LossPred 0.8956 LossAtt 0.2897 TrainAcc 0.6200 TestAcc 0.5813 0.6200
epoch 300 LossPred 0.8929 LossAtt 0.2683 TrainAcc 0.6200 TestAcc 0.5813 0.6200
epoch 400 LossPred 0.8896 LossAtt 0.2639 TrainAcc 0.6200 TestAcc 0.5813 0.6200
epoch 500 LossPred 0.8842 LossAtt 0.2765 TrainAcc 0.6200 TestAcc 0.5813 0.6200
epoch 600 LossPred 0.8903 LossAtt 0.2162 TrainAcc 0.6200 TestAcc 0.5813 0.6200
epoch 700 LossPred 0.8826 LossAtt 0.3398 TrainAcc 0.6200 TestAcc 0.5813 0.6200
epoch 800 LossPred 0.3855 LossAtt 0.4256 TrainAcc 0.8800 TestAcc 0.8171 0.8550
epoch 900 LossPred 0.3316 LossAtt 0.3593 TrainAcc 0.8700 TestAcc 0.8776 0.8650
epoch 1000 LossPred 0.5471 LossAtt 0.3536 TrainAcc 0.8300 TestAcc 0.7910 0.8150
epoch 1100 LossPred 0.6034 LossAtt 0.3312 TrainAcc 0.7700 TestAcc 0.8241 0.7700
epoch 1200 LossPred 0.6698 LossAtt 0.3293 TrainAcc 0.7600 TestAcc 0.7858 0.7450
epoch 1300 LossPred 0.4646 LossAtt 0.3205 TrainAcc 0.8500 TestAcc 0.8358 0.8150
epoch 1400 LossPred 0.3803 LossAtt 0.3190 TrainAcc 0.8600 TestAcc 0.8361 0.8550
epoch 1500 LossPred 0.3337 LossAtt 0.3066 TrainAcc 0.8900 TestAcc 0.8579 0.8350
epoch 1600 LossPred 0.3643 LossAtt 0.3055 TrainAcc 0.9000 TestAcc 0.8403 0.8750
epoch 1700 LossPred 0.3016 LossAtt 0.3010 TrainAcc 0.9000 TestAcc 0.8661 0.8550
epoch 1800 LossPred 0.3314 LossAtt 0.2851 TrainAcc 0.8900 TestAcc 0.8448 0.8800
epoch 1900 LossPred 0.3595 LossAtt 0.2842 TrainAcc 0.8800 TestAcc 0.8599 0.8450
epoch 2000 LossPred 0.3390 LossAtt 0.2862 TrainAcc 0.9000 TestAcc 0.8293 0.8700
epoch 2100 LossPred 0.3809 LossAtt 0.2927 TrainAcc 0.8900 TestAcc 0.8381 0.8700
epoch 2200 LossPred 0.5859 LossAtt 0.2748 TrainAcc 0.8100 TestAcc 0.7573 0.7800
epoch 2300 LossPred 0.4525 LossAtt 0.2670 TrainAcc 0.8500 TestAcc 0.8088 0.8250
epoch 2400 LossPred 0.3567 LossAtt 0.2779 TrainAcc 0.8900 TestAcc 0.8514 0.8600
epoch 2500 LossPred 0.3167 LossAtt 0.2765 TrainAcc 0.8900 TestAcc 0.8684 0.8400
Optimization Finished!
********** replication  60  **********
epoch   0 LossPred 1.0058 LossAtt 0.9809 TrainAcc 0.4800 TestAcc 0.5776 0.4650
epoch 100 LossPred 0.8724 LossAtt 0.4778 TrainAcc 0.6600 TestAcc 0.5873 0.6600
epoch 200 LossPred 0.8093 LossAtt 0.5169 TrainAcc 0.7000 TestAcc 0.6219 0.6900
epoch 300 LossPred 0.5275 LossAtt 0.5185 TrainAcc 0.8300 TestAcc 0.8473 0.8100
epoch 400 LossPred 0.3424 LossAtt 0.5140 TrainAcc 0.9000 TestAcc 0.8921 0.8700
epoch 500 LossPred 0.5400 LossAtt 0.5197 TrainAcc 0.8000 TestAcc 0.7828 0.8150
epoch 600 LossPred 0.3050 LossAtt 0.5376 TrainAcc 0.8900 TestAcc 0.8989 0.8700
epoch 700 LossPred 0.2967 LossAtt 0.5327 TrainAcc 0.9000 TestAcc 0.8946 0.8700
epoch 800 LossPred 0.2898 LossAtt 0.5218 TrainAcc 0.9200 TestAcc 0.8956 0.8700
epoch 900 LossPred 0.5193 LossAtt 0.5258 TrainAcc 0.8300 TestAcc 0.7940 0.8350
epoch 1000 LossPred 0.5098 LossAtt 0.4946 TrainAcc 0.8400 TestAcc 0.7970 0.8250
epoch 1100 LossPred 0.2626 LossAtt 0.4995 TrainAcc 0.9000 TestAcc 0.8959 0.8900
epoch 1200 LossPred 0.2420 LossAtt 0.4895 TrainAcc 0.9100 TestAcc 0.9069 0.8850
epoch 1300 LossPred 0.3030 LossAtt 0.4646 TrainAcc 0.9000 TestAcc 0.8749 0.8750
epoch 1400 LossPred 0.2923 LossAtt 0.4756 TrainAcc 0.8900 TestAcc 0.8759 0.8700
epoch 1500 LossPred 0.2564 LossAtt 0.4919 TrainAcc 0.9100 TestAcc 0.8846 0.8850
epoch 1600 LossPred 0.2378 LossAtt 0.4673 TrainAcc 0.9400 TestAcc 0.9047 0.8750
epoch 1700 LossPred 0.4143 LossAtt 0.4774 TrainAcc 0.8400 TestAcc 0.8448 0.8200
epoch 1800 LossPred 0.3359 LossAtt 0.4569 TrainAcc 0.8600 TestAcc 0.8581 0.8600
epoch 1900 LossPred 0.3149 LossAtt 0.4511 TrainAcc 0.8800 TestAcc 0.8606 0.8550
epoch 2000 LossPred 0.2167 LossAtt 0.4638 TrainAcc 0.9100 TestAcc 0.9017 0.8850
epoch 2100 LossPred 0.3462 LossAtt 0.4601 TrainAcc 0.8700 TestAcc 0.8654 0.8250
epoch 2200 LossPred 0.2506 LossAtt 0.4829 TrainAcc 0.9300 TestAcc 0.8931 0.8700
epoch 2300 LossPred 0.2386 LossAtt 0.4547 TrainAcc 0.9200 TestAcc 0.8849 0.8750
epoch 2400 LossPred 0.2835 LossAtt 0.4534 TrainAcc 0.9000 TestAcc 0.8656 0.8700
epoch 2500 LossPred 0.2374 LossAtt 0.4488 TrainAcc 0.9400 TestAcc 0.8966 0.8750
Optimization Finished!
********** replication  61  **********
epoch   0 LossPred 1.1016 LossAtt 1.0133 TrainAcc 0.4700 TestAcc 0.4882 0.4550
epoch 100 LossPred 0.9569 LossAtt 0.4272 TrainAcc 0.6000 TestAcc 0.5225 0.6000
epoch 200 LossPred 0.9372 LossAtt 0.4329 TrainAcc 0.6100 TestAcc 0.5118 0.6000
epoch 300 LossPred 0.9233 LossAtt 0.4151 TrainAcc 0.6300 TestAcc 0.4727 0.6100
epoch 400 LossPred 0.8927 LossAtt 0.4610 TrainAcc 0.6600 TestAcc 0.4832 0.6350
epoch 500 LossPred 0.8642 LossAtt 0.5023 TrainAcc 0.6700 TestAcc 0.4877 0.6450
epoch 600 LossPred 0.8468 LossAtt 0.5108 TrainAcc 0.7000 TestAcc 0.4865 0.6600
epoch 700 LossPred 0.8305 LossAtt 0.5045 TrainAcc 0.7000 TestAcc 0.4825 0.6700
epoch 800 LossPred 0.8116 LossAtt 0.4924 TrainAcc 0.6900 TestAcc 0.4752 0.6650
epoch 900 LossPred 0.7926 LossAtt 0.4955 TrainAcc 0.7100 TestAcc 0.4762 0.6800
epoch 1000 LossPred 0.7831 LossAtt 0.4544 TrainAcc 0.7100 TestAcc 0.4725 0.7000
epoch 1100 LossPred 0.7664 LossAtt 0.4434 TrainAcc 0.7100 TestAcc 0.4717 0.6850
epoch 1200 LossPred 0.7630 LossAtt 0.4233 TrainAcc 0.7000 TestAcc 0.4735 0.6900
epoch 1300 LossPred 0.7594 LossAtt 0.4287 TrainAcc 0.6900 TestAcc 0.4770 0.6850
epoch 1400 LossPred 0.7659 LossAtt 0.4413 TrainAcc 0.6900 TestAcc 0.4757 0.6850
epoch 1500 LossPred 0.7470 LossAtt 0.3976 TrainAcc 0.7000 TestAcc 0.4840 0.6850
epoch 1600 LossPred 0.7620 LossAtt 0.4228 TrainAcc 0.7000 TestAcc 0.4825 0.6800
epoch 1700 LossPred 0.7474 LossAtt 0.4051 TrainAcc 0.6900 TestAcc 0.4832 0.6650
epoch 1800 LossPred 0.7588 LossAtt 0.4209 TrainAcc 0.6900 TestAcc 0.4875 0.6800
epoch 1900 LossPred 0.7473 LossAtt 0.4095 TrainAcc 0.7000 TestAcc 0.4847 0.6650
epoch 2000 LossPred 0.7736 LossAtt 0.4165 TrainAcc 0.6700 TestAcc 0.4845 0.6550
epoch 2100 LossPred 0.7671 LossAtt 0.3954 TrainAcc 0.6800 TestAcc 0.4830 0.6850
epoch 2200 LossPred 0.7474 LossAtt 0.4011 TrainAcc 0.7200 TestAcc 0.4820 0.6650
epoch 2300 LossPred 0.7672 LossAtt 0.4140 TrainAcc 0.7000 TestAcc 0.4932 0.6800
epoch 2400 LossPred 0.7296 LossAtt 0.3947 TrainAcc 0.7400 TestAcc 0.4872 0.7050
epoch 2500 LossPred 0.7210 LossAtt 0.3944 TrainAcc 0.7300 TestAcc 0.4842 0.6850
Optimization Finished!
********** replication  62  **********
epoch   0 LossPred 1.1509 LossAtt 1.0249 TrainAcc 0.4300 TestAcc 0.4545 0.4450
epoch 100 LossPred 0.8896 LossAtt 0.4000 TrainAcc 0.6500 TestAcc 0.5971 0.6500
epoch 200 LossPred 0.8836 LossAtt 0.3224 TrainAcc 0.6500 TestAcc 0.5971 0.6500
epoch 300 LossPred 0.8969 LossAtt 0.2559 TrainAcc 0.6500 TestAcc 0.5971 0.6500
epoch 400 LossPred 0.8946 LossAtt 0.2368 TrainAcc 0.6500 TestAcc 0.5971 0.6500
epoch 500 LossPred 0.8898 LossAtt 0.2015 TrainAcc 0.6500 TestAcc 0.5971 0.6500
epoch 600 LossPred 0.8766 LossAtt 0.2013 TrainAcc 0.6500 TestAcc 0.5971 0.6500
epoch 700 LossPred 0.8604 LossAtt 0.2487 TrainAcc 0.6500 TestAcc 0.5971 0.6500
epoch 800 LossPred 0.7781 LossAtt 0.4880 TrainAcc 0.7300 TestAcc 0.6324 0.7300
epoch 900 LossPred 1.0162 LossAtt 0.4301 TrainAcc 0.6700 TestAcc 0.6194 0.6550
epoch 1000 LossPred 0.7633 LossAtt 0.4161 TrainAcc 0.7400 TestAcc 0.6331 0.7400
epoch 1100 LossPred 0.7303 LossAtt 0.3823 TrainAcc 0.7700 TestAcc 0.6504 0.7600
epoch 1200 LossPred 0.4596 LossAtt 0.3923 TrainAcc 0.8300 TestAcc 0.8263 0.8500
epoch 1300 LossPred 0.5032 LossAtt 0.4094 TrainAcc 0.8100 TestAcc 0.7573 0.8150
epoch 1400 LossPred 0.3327 LossAtt 0.4174 TrainAcc 0.8900 TestAcc 0.8171 0.8800
epoch 1500 LossPred 0.2142 LossAtt 0.3958 TrainAcc 0.9500 TestAcc 0.8841 0.9500
epoch 1600 LossPred 0.2561 LossAtt 0.3926 TrainAcc 0.9200 TestAcc 0.8221 0.9050
epoch 1700 LossPred 0.1450 LossAtt 0.3977 TrainAcc 0.9600 TestAcc 0.9042 0.9450
epoch 1800 LossPred 0.1067 LossAtt 0.3833 TrainAcc 0.9600 TestAcc 0.9232 0.9700
epoch 1900 LossPred 0.1160 LossAtt 0.3795 TrainAcc 0.9800 TestAcc 0.9189 0.9750
epoch 2000 LossPred 0.1108 LossAtt 0.3723 TrainAcc 0.9500 TestAcc 0.9364 0.9650
epoch 2100 LossPred 0.0952 LossAtt 0.3924 TrainAcc 0.9800 TestAcc 0.9174 0.9800
epoch 2200 LossPred 0.1272 LossAtt 0.3834 TrainAcc 0.9800 TestAcc 0.9069 0.9600
epoch 2300 LossPred 0.2555 LossAtt 0.3893 TrainAcc 0.8900 TestAcc 0.8383 0.8950
epoch 2400 LossPred 0.1224 LossAtt 0.3805 TrainAcc 0.9500 TestAcc 0.9199 0.9550
epoch 2500 LossPred 0.2048 LossAtt 0.3863 TrainAcc 0.9100 TestAcc 0.8576 0.9150
Optimization Finished!
********** replication  63  **********
epoch   0 LossPred 0.9880 LossAtt 1.0106 TrainAcc 0.5100 TestAcc 0.5300 0.5250
epoch 100 LossPred 0.9169 LossAtt 0.4160 TrainAcc 0.6500 TestAcc 0.5133 0.6500
epoch 200 LossPred 0.8917 LossAtt 0.3773 TrainAcc 0.6500 TestAcc 0.5120 0.6600
epoch 300 LossPred 0.8862 LossAtt 0.3900 TrainAcc 0.6500 TestAcc 0.5150 0.6500
epoch 400 LossPred 0.8848 LossAtt 0.4324 TrainAcc 0.6500 TestAcc 0.5355 0.6350
epoch 500 LossPred 0.8802 LossAtt 0.4001 TrainAcc 0.6500 TestAcc 0.5355 0.6400
epoch 600 LossPred 0.8758 LossAtt 0.3902 TrainAcc 0.6500 TestAcc 0.5355 0.6350
epoch 700 LossPred 0.8695 LossAtt 0.3920 TrainAcc 0.6500 TestAcc 0.5355 0.6250
epoch 800 LossPred 0.9050 LossAtt 0.5126 TrainAcc 0.6300 TestAcc 0.5663 0.6300
epoch 900 LossPred 0.7676 LossAtt 0.5058 TrainAcc 0.7200 TestAcc 0.6036 0.7250
epoch 1000 LossPred 0.5937 LossAtt 0.4801 TrainAcc 0.8000 TestAcc 0.7558 0.7750
epoch 1100 LossPred 0.4401 LossAtt 0.4841 TrainAcc 0.8600 TestAcc 0.7758 0.8400
epoch 1200 LossPred 0.4202 LossAtt 0.4331 TrainAcc 0.8800 TestAcc 0.7825 0.8600
epoch 1300 LossPred 0.4325 LossAtt 0.4276 TrainAcc 0.8700 TestAcc 0.7973 0.8500
epoch 1400 LossPred 0.5394 LossAtt 0.4171 TrainAcc 0.8300 TestAcc 0.7923 0.8250
epoch 1500 LossPred 0.5768 LossAtt 0.3868 TrainAcc 0.8200 TestAcc 0.8281 0.8100
epoch 1600 LossPred 0.6077 LossAtt 0.4080 TrainAcc 0.8000 TestAcc 0.8006 0.8150
epoch 1700 LossPred 0.6640 LossAtt 0.3716 TrainAcc 0.7700 TestAcc 0.7635 0.7800
epoch 1800 LossPred 0.9385 LossAtt 0.3139 TrainAcc 0.6400 TestAcc 0.6789 0.6350
epoch 1900 LossPred 0.6733 LossAtt 0.3521 TrainAcc 0.7800 TestAcc 0.7975 0.7850
epoch 2000 LossPred 0.6128 LossAtt 0.3362 TrainAcc 0.7800 TestAcc 0.8173 0.8150
epoch 2100 LossPred 0.9302 LossAtt 0.3643 TrainAcc 0.6300 TestAcc 0.6461 0.6450
epoch 2200 LossPred 0.6233 LossAtt 0.3199 TrainAcc 0.7800 TestAcc 0.8221 0.8200
epoch 2300 LossPred 0.6185 LossAtt 0.3214 TrainAcc 0.7900 TestAcc 0.8136 0.7850
epoch 2400 LossPred 0.5990 LossAtt 0.3124 TrainAcc 0.7800 TestAcc 0.8291 0.8100
epoch 2500 LossPred 0.8513 LossAtt 0.3264 TrainAcc 0.6700 TestAcc 0.6874 0.6650
Optimization Finished!
********** replication  64  **********
epoch   0 LossPred 1.0636 LossAtt 0.9976 TrainAcc 0.5800 TestAcc 0.5213 0.5800
epoch 100 LossPred 0.9281 LossAtt 0.4544 TrainAcc 0.6000 TestAcc 0.5843 0.6000
epoch 200 LossPred 0.9173 LossAtt 0.3780 TrainAcc 0.6000 TestAcc 0.5843 0.6000
epoch 300 LossPred 0.9099 LossAtt 0.3493 TrainAcc 0.6000 TestAcc 0.5843 0.6000
epoch 400 LossPred 0.9059 LossAtt 0.2959 TrainAcc 0.6400 TestAcc 0.5833 0.5950
epoch 500 LossPred 0.9042 LossAtt 0.2674 TrainAcc 0.6000 TestAcc 0.5843 0.6000
epoch 600 LossPred 0.9023 LossAtt 0.3062 TrainAcc 0.6000 TestAcc 0.5843 0.6100
epoch 700 LossPred 0.8683 LossAtt 0.4116 TrainAcc 0.6700 TestAcc 0.6522 0.6600
epoch 800 LossPred 0.4853 LossAtt 0.4214 TrainAcc 0.8400 TestAcc 0.8701 0.8350
epoch 900 LossPred 0.2720 LossAtt 0.4263 TrainAcc 0.9300 TestAcc 0.9017 0.9050
epoch 1000 LossPred 0.2204 LossAtt 0.4366 TrainAcc 0.9200 TestAcc 0.9064 0.9150
epoch 1100 LossPred 0.2008 LossAtt 0.4191 TrainAcc 0.9400 TestAcc 0.9242 0.9300
epoch 1200 LossPred 0.1948 LossAtt 0.3725 TrainAcc 0.9300 TestAcc 0.9154 0.9050
epoch 1300 LossPred 0.1985 LossAtt 0.3712 TrainAcc 0.9300 TestAcc 0.9047 0.9200
epoch 1400 LossPred 0.1919 LossAtt 0.3777 TrainAcc 0.9400 TestAcc 0.9124 0.9300
epoch 1500 LossPred 0.2226 LossAtt 0.3549 TrainAcc 0.9100 TestAcc 0.8916 0.9150
epoch 1600 LossPred 0.1958 LossAtt 0.3659 TrainAcc 0.9300 TestAcc 0.9012 0.9200
epoch 1700 LossPred 0.1919 LossAtt 0.3764 TrainAcc 0.9300 TestAcc 0.8991 0.9250
epoch 1800 LossPred 0.1843 LossAtt 0.3705 TrainAcc 0.9400 TestAcc 0.9079 0.9200
epoch 1900 LossPred 0.1910 LossAtt 0.3657 TrainAcc 0.9400 TestAcc 0.9024 0.9200
epoch 2000 LossPred 0.1824 LossAtt 0.3786 TrainAcc 0.9400 TestAcc 0.9094 0.9200
epoch 2100 LossPred 0.1848 LossAtt 0.3825 TrainAcc 0.9400 TestAcc 0.9117 0.9350
epoch 2200 LossPred 0.1977 LossAtt 0.3810 TrainAcc 0.9100 TestAcc 0.8996 0.9150
epoch 2300 LossPred 0.1938 LossAtt 0.3756 TrainAcc 0.9300 TestAcc 0.9067 0.9100
epoch 2400 LossPred 0.1992 LossAtt 0.3661 TrainAcc 0.9400 TestAcc 0.8991 0.9050
epoch 2500 LossPred 0.3191 LossAtt 0.3847 TrainAcc 0.9000 TestAcc 0.8393 0.9000
Optimization Finished!
********** replication  65  **********
epoch   0 LossPred 1.2819 LossAtt 1.0023 TrainAcc 0.3700 TestAcc 0.4855 0.3900
epoch 100 LossPred 0.8940 LossAtt 0.4635 TrainAcc 0.6500 TestAcc 0.5648 0.6450
epoch 200 LossPred 0.8342 LossAtt 0.3919 TrainAcc 0.6600 TestAcc 0.5320 0.6650
epoch 300 LossPred 0.8155 LossAtt 0.3958 TrainAcc 0.6600 TestAcc 0.5320 0.6850
epoch 400 LossPred 0.7989 LossAtt 0.4337 TrainAcc 0.6800 TestAcc 0.5751 0.6850
epoch 500 LossPred 0.7810 LossAtt 0.4323 TrainAcc 0.6800 TestAcc 0.5783 0.6900
epoch 600 LossPred 0.7709 LossAtt 0.4143 TrainAcc 0.6900 TestAcc 0.5818 0.7050
epoch 700 LossPred 0.7651 LossAtt 0.4141 TrainAcc 0.6800 TestAcc 0.5898 0.7000
epoch 800 LossPred 0.7599 LossAtt 0.3828 TrainAcc 0.7000 TestAcc 0.5876 0.7050
epoch 900 LossPred 0.7568 LossAtt 0.3458 TrainAcc 0.7000 TestAcc 0.5848 0.6950
epoch 1000 LossPred 0.7570 LossAtt 0.3093 TrainAcc 0.6900 TestAcc 0.5793 0.6950
epoch 1100 LossPred 0.7724 LossAtt 0.2994 TrainAcc 0.6900 TestAcc 0.5886 0.7000
epoch 1200 LossPred 0.7733 LossAtt 0.2931 TrainAcc 0.6900 TestAcc 0.6001 0.6850
epoch 1300 LossPred 0.7658 LossAtt 0.2665 TrainAcc 0.6900 TestAcc 0.5956 0.6950
epoch 1400 LossPred 0.7566 LossAtt 0.3103 TrainAcc 0.6900 TestAcc 0.6036 0.6750
epoch 1500 LossPred 0.7477 LossAtt 0.3249 TrainAcc 0.6900 TestAcc 0.5946 0.6750
epoch 1600 LossPred 0.7391 LossAtt 0.3023 TrainAcc 0.7000 TestAcc 0.5976 0.7050
epoch 1700 LossPred 0.7368 LossAtt 0.3744 TrainAcc 0.7000 TestAcc 0.5856 0.6900
epoch 1800 LossPred 0.7326 LossAtt 0.3619 TrainAcc 0.7000 TestAcc 0.5788 0.6850
epoch 1900 LossPred 0.7145 LossAtt 0.3641 TrainAcc 0.7000 TestAcc 0.5938 0.7000
epoch 2000 LossPred 0.7108 LossAtt 0.4134 TrainAcc 0.7500 TestAcc 0.6034 0.6950
epoch 2100 LossPred 0.7051 LossAtt 0.3886 TrainAcc 0.7500 TestAcc 0.6099 0.7150
epoch 2200 LossPred 0.6979 LossAtt 0.4071 TrainAcc 0.7300 TestAcc 0.6044 0.7100
epoch 2300 LossPred 0.6948 LossAtt 0.4190 TrainAcc 0.7300 TestAcc 0.6174 0.7150
epoch 2400 LossPred 0.6872 LossAtt 0.4152 TrainAcc 0.7100 TestAcc 0.6091 0.7100
epoch 2500 LossPred 0.6838 LossAtt 0.4464 TrainAcc 0.7200 TestAcc 0.6139 0.7250
Optimization Finished!
********** replication  66  **********
epoch   0 LossPred 1.1368 LossAtt 1.0079 TrainAcc 0.4600 TestAcc 0.4094 0.4550
epoch 100 LossPred 0.9664 LossAtt 0.3353 TrainAcc 0.5500 TestAcc 0.5851 0.5500
epoch 200 LossPred 0.9313 LossAtt 0.2612 TrainAcc 0.5800 TestAcc 0.6284 0.5800
epoch 300 LossPred 0.3966 LossAtt 0.3646 TrainAcc 0.8900 TestAcc 0.8471 0.8450
epoch 400 LossPred 0.5673 LossAtt 0.3351 TrainAcc 0.8100 TestAcc 0.7793 0.8100
epoch 500 LossPred 0.4189 LossAtt 0.3422 TrainAcc 0.8400 TestAcc 0.8346 0.8450
epoch 600 LossPred 0.4902 LossAtt 0.3150 TrainAcc 0.8600 TestAcc 0.8178 0.8400
epoch 700 LossPred 0.3413 LossAtt 0.3572 TrainAcc 0.8900 TestAcc 0.8478 0.8400
epoch 800 LossPred 0.3396 LossAtt 0.3604 TrainAcc 0.9000 TestAcc 0.8471 0.8450
epoch 900 LossPred 0.4895 LossAtt 0.3186 TrainAcc 0.8600 TestAcc 0.8181 0.8300
epoch 1000 LossPred 0.4450 LossAtt 0.3478 TrainAcc 0.8600 TestAcc 0.8233 0.8400
epoch 1100 LossPred 0.4128 LossAtt 0.3470 TrainAcc 0.8700 TestAcc 0.8263 0.8450
epoch 1200 LossPred 0.5111 LossAtt 0.3204 TrainAcc 0.8500 TestAcc 0.7988 0.8400
epoch 1300 LossPred 0.6227 LossAtt 0.3158 TrainAcc 0.7900 TestAcc 0.7462 0.7850
epoch 1400 LossPred 0.3754 LossAtt 0.3232 TrainAcc 0.8700 TestAcc 0.8271 0.8550
epoch 1500 LossPred 0.4661 LossAtt 0.3163 TrainAcc 0.8500 TestAcc 0.8108 0.8500
epoch 1600 LossPred 0.4173 LossAtt 0.3667 TrainAcc 0.8500 TestAcc 0.8371 0.8200
epoch 1700 LossPred 0.3283 LossAtt 0.3560 TrainAcc 0.8900 TestAcc 0.8371 0.8550
epoch 1800 LossPred 0.3088 LossAtt 0.3716 TrainAcc 0.9000 TestAcc 0.8361 0.8600
epoch 1900 LossPred 0.3484 LossAtt 0.3503 TrainAcc 0.8700 TestAcc 0.8371 0.8550
epoch 2000 LossPred 0.3118 LossAtt 0.3693 TrainAcc 0.8900 TestAcc 0.8411 0.8650
epoch 2100 LossPred 0.3048 LossAtt 0.3708 TrainAcc 0.8800 TestAcc 0.8461 0.8800
epoch 2200 LossPred 0.2944 LossAtt 0.3642 TrainAcc 0.9000 TestAcc 0.8376 0.8900
epoch 2300 LossPred 0.3884 LossAtt 0.3588 TrainAcc 0.8800 TestAcc 0.8236 0.8500
epoch 2400 LossPred 0.2850 LossAtt 0.3567 TrainAcc 0.9100 TestAcc 0.8481 0.8950
epoch 2500 LossPred 0.3341 LossAtt 0.3859 TrainAcc 0.8800 TestAcc 0.8473 0.8500
Optimization Finished!
********** replication  67  **********
epoch   0 LossPred 0.9633 LossAtt 1.0121 TrainAcc 0.5400 TestAcc 0.5380 0.5450
epoch 100 LossPred 0.8839 LossAtt 0.3319 TrainAcc 0.6200 TestAcc 0.5833 0.6200
epoch 200 LossPred 0.8696 LossAtt 0.3241 TrainAcc 0.6600 TestAcc 0.6089 0.6550
epoch 300 LossPred 0.8580 LossAtt 0.3246 TrainAcc 0.6900 TestAcc 0.6299 0.6900
epoch 400 LossPred 0.8349 LossAtt 0.2490 TrainAcc 0.6900 TestAcc 0.6299 0.6900
epoch 500 LossPred 0.8078 LossAtt 0.2346 TrainAcc 0.6800 TestAcc 0.6319 0.7200
epoch 600 LossPred 0.7814 LossAtt 0.2494 TrainAcc 0.6800 TestAcc 0.6386 0.7200
epoch 700 LossPred 0.7893 LossAtt 0.2228 TrainAcc 0.6800 TestAcc 0.6386 0.7100
epoch 800 LossPred 0.8516 LossAtt 0.2152 TrainAcc 0.7100 TestAcc 0.6254 0.7100
epoch 900 LossPred 0.8548 LossAtt 0.2174 TrainAcc 0.7000 TestAcc 0.6211 0.6800
epoch 1000 LossPred 0.8520 LossAtt 0.2137 TrainAcc 0.6900 TestAcc 0.6196 0.6950
epoch 1100 LossPred 0.8595 LossAtt 0.1689 TrainAcc 0.7100 TestAcc 0.6186 0.6900
epoch 1200 LossPred 0.8670 LossAtt 0.1397 TrainAcc 0.7100 TestAcc 0.6254 0.6850
epoch 1300 LossPred 0.8621 LossAtt 0.1574 TrainAcc 0.7100 TestAcc 0.6254 0.6750
epoch 1400 LossPred 0.8599 LossAtt 0.1333 TrainAcc 0.6900 TestAcc 0.6196 0.6750
epoch 1500 LossPred 0.8510 LossAtt 0.1573 TrainAcc 0.7300 TestAcc 0.6186 0.6950
epoch 1600 LossPred 0.8324 LossAtt 0.1730 TrainAcc 0.7400 TestAcc 0.6251 0.7200
epoch 1700 LossPred 0.8677 LossAtt 0.2363 TrainAcc 0.6900 TestAcc 0.6299 0.7050
epoch 1800 LossPred 0.8669 LossAtt 0.2136 TrainAcc 0.6900 TestAcc 0.6299 0.6650
epoch 1900 LossPred 0.8653 LossAtt 0.1519 TrainAcc 0.6900 TestAcc 0.6299 0.6550
epoch 2000 LossPred 0.8675 LossAtt 0.1152 TrainAcc 0.6900 TestAcc 0.6299 0.6450
epoch 2100 LossPred 0.8684 LossAtt 0.1087 TrainAcc 0.6900 TestAcc 0.6299 0.6300
epoch 2200 LossPred 0.8679 LossAtt 0.1008 TrainAcc 0.6900 TestAcc 0.6299 0.6350
epoch 2300 LossPred 0.8667 LossAtt 0.1136 TrainAcc 0.6900 TestAcc 0.6299 0.6650
epoch 2400 LossPred 0.8682 LossAtt 0.1711 TrainAcc 0.6200 TestAcc 0.5833 0.6300
epoch 2500 LossPred 0.8687 LossAtt 0.2059 TrainAcc 0.6200 TestAcc 0.5833 0.6250
Optimization Finished!
********** replication  68  **********
epoch   0 LossPred 1.0188 LossAtt 0.9898 TrainAcc 0.5800 TestAcc 0.5771 0.5750
epoch 100 LossPred 0.8885 LossAtt 0.4753 TrainAcc 0.7200 TestAcc 0.6386 0.7100
epoch 200 LossPred 0.8025 LossAtt 0.4887 TrainAcc 0.7300 TestAcc 0.6524 0.7100
epoch 300 LossPred 0.7205 LossAtt 0.4377 TrainAcc 0.7200 TestAcc 0.6579 0.7250
epoch 400 LossPred 0.6881 LossAtt 0.4264 TrainAcc 0.7400 TestAcc 0.6707 0.7350
epoch 500 LossPred 0.6704 LossAtt 0.4084 TrainAcc 0.7300 TestAcc 0.6847 0.7300
epoch 600 LossPred 0.5670 LossAtt 0.3191 TrainAcc 0.8200 TestAcc 0.7750 0.8050
epoch 700 LossPred 0.4944 LossAtt 0.2779 TrainAcc 0.8100 TestAcc 0.7650 0.7950
epoch 800 LossPred 0.4751 LossAtt 0.2905 TrainAcc 0.8300 TestAcc 0.8046 0.8500
epoch 900 LossPred 0.4717 LossAtt 0.2845 TrainAcc 0.8400 TestAcc 0.7990 0.8300
epoch 1000 LossPred 0.4297 LossAtt 0.3128 TrainAcc 0.8400 TestAcc 0.7920 0.8400
epoch 1100 LossPred 0.4211 LossAtt 0.3058 TrainAcc 0.8600 TestAcc 0.8198 0.8550
epoch 1200 LossPred 0.4268 LossAtt 0.3116 TrainAcc 0.8500 TestAcc 0.7828 0.8350
epoch 1300 LossPred 0.4455 LossAtt 0.3189 TrainAcc 0.8300 TestAcc 0.7978 0.8350
epoch 1400 LossPred 0.4107 LossAtt 0.3237 TrainAcc 0.8500 TestAcc 0.7870 0.8450
epoch 1500 LossPred 0.4493 LossAtt 0.3342 TrainAcc 0.8400 TestAcc 0.8153 0.8550
epoch 1600 LossPred 0.4042 LossAtt 0.3269 TrainAcc 0.8500 TestAcc 0.7850 0.8450
epoch 1700 LossPred 0.3940 LossAtt 0.3211 TrainAcc 0.8500 TestAcc 0.8003 0.8500
epoch 1800 LossPred 0.4086 LossAtt 0.3071 TrainAcc 0.8500 TestAcc 0.8023 0.8450
epoch 1900 LossPred 0.4135 LossAtt 0.2959 TrainAcc 0.8400 TestAcc 0.7818 0.8300
epoch 2000 LossPred 0.4068 LossAtt 0.3115 TrainAcc 0.8500 TestAcc 0.8083 0.8450
epoch 2100 LossPred 0.4027 LossAtt 0.2964 TrainAcc 0.8400 TestAcc 0.7753 0.8300
epoch 2200 LossPred 0.3979 LossAtt 0.2819 TrainAcc 0.8500 TestAcc 0.7855 0.8400
epoch 2300 LossPred 0.3958 LossAtt 0.2967 TrainAcc 0.8500 TestAcc 0.7963 0.8450
epoch 2400 LossPred 0.4034 LossAtt 0.2834 TrainAcc 0.8500 TestAcc 0.7938 0.8450
epoch 2500 LossPred 0.3896 LossAtt 0.2832 TrainAcc 0.8500 TestAcc 0.7928 0.8450
Optimization Finished!
********** replication  69  **********
epoch   0 LossPred 1.2024 LossAtt 1.0358 TrainAcc 0.5400 TestAcc 0.4932 0.5300
epoch 100 LossPred 1.0086 LossAtt 0.5268 TrainAcc 0.5600 TestAcc 0.4865 0.5450
epoch 200 LossPred 0.9581 LossAtt 0.4877 TrainAcc 0.5600 TestAcc 0.5015 0.5400
epoch 300 LossPred 0.9410 LossAtt 0.3847 TrainAcc 0.5600 TestAcc 0.5591 0.5400
epoch 400 LossPred 0.9550 LossAtt 0.4006 TrainAcc 0.5500 TestAcc 0.5856 0.5500
epoch 500 LossPred 0.9610 LossAtt 0.4299 TrainAcc 0.5500 TestAcc 0.4970 0.5300
epoch 600 LossPred 0.9512 LossAtt 0.4125 TrainAcc 0.5600 TestAcc 0.4877 0.5700
epoch 700 LossPred 0.9323 LossAtt 0.3849 TrainAcc 0.5900 TestAcc 0.5290 0.5850
epoch 800 LossPred 0.9179 LossAtt 0.3811 TrainAcc 0.6000 TestAcc 0.5048 0.5850
epoch 900 LossPred 0.9154 LossAtt 0.3882 TrainAcc 0.6000 TestAcc 0.5203 0.5850
epoch 1000 LossPred 0.9150 LossAtt 0.4449 TrainAcc 0.5800 TestAcc 0.5168 0.5850
epoch 1100 LossPred 0.9226 LossAtt 0.4889 TrainAcc 0.5800 TestAcc 0.4955 0.5800
epoch 1200 LossPred 0.8919 LossAtt 0.4862 TrainAcc 0.6000 TestAcc 0.4907 0.5950
epoch 1300 LossPred 0.8567 LossAtt 0.4613 TrainAcc 0.5900 TestAcc 0.4835 0.5900
epoch 1400 LossPred 0.8670 LossAtt 0.4243 TrainAcc 0.5700 TestAcc 0.4852 0.5650
epoch 1500 LossPred 0.8404 LossAtt 0.4436 TrainAcc 0.5900 TestAcc 0.4960 0.5900
epoch 1600 LossPred 0.8336 LossAtt 0.4377 TrainAcc 0.6000 TestAcc 0.5125 0.6000
epoch 1700 LossPred 0.8395 LossAtt 0.4443 TrainAcc 0.6200 TestAcc 0.5178 0.6000
epoch 1800 LossPred 0.8414 LossAtt 0.4331 TrainAcc 0.6100 TestAcc 0.5265 0.6050
epoch 1900 LossPred 0.8500 LossAtt 0.4385 TrainAcc 0.6600 TestAcc 0.5521 0.6000
epoch 2000 LossPred 0.8294 LossAtt 0.4545 TrainAcc 0.6700 TestAcc 0.5536 0.6000
epoch 2100 LossPred 0.8182 LossAtt 0.4110 TrainAcc 0.6500 TestAcc 0.5538 0.6050
epoch 2200 LossPred 0.8330 LossAtt 0.4153 TrainAcc 0.6500 TestAcc 0.5641 0.6050
epoch 2300 LossPred 0.8276 LossAtt 0.4212 TrainAcc 0.6600 TestAcc 0.5616 0.6150
epoch 2400 LossPred 0.8153 LossAtt 0.4196 TrainAcc 0.6600 TestAcc 0.5478 0.6150
epoch 2500 LossPred 0.8347 LossAtt 0.4180 TrainAcc 0.6700 TestAcc 0.5493 0.6350
Optimization Finished!
********** replication  70  **********
epoch   0 LossPred 1.2076 LossAtt 1.0202 TrainAcc 0.5200 TestAcc 0.5020 0.5000
epoch 100 LossPred 0.9478 LossAtt 0.5530 TrainAcc 0.5600 TestAcc 0.5190 0.5650
epoch 200 LossPred 0.8967 LossAtt 0.5664 TrainAcc 0.5900 TestAcc 0.5300 0.5900
epoch 300 LossPred 0.8407 LossAtt 0.5925 TrainAcc 0.6300 TestAcc 0.5508 0.6350
epoch 400 LossPred 0.8181 LossAtt 0.5706 TrainAcc 0.6500 TestAcc 0.5508 0.6450
epoch 500 LossPred 0.7928 LossAtt 0.5864 TrainAcc 0.7000 TestAcc 0.5526 0.6400
epoch 600 LossPred 0.7859 LossAtt 0.5846 TrainAcc 0.7300 TestAcc 0.5528 0.6850
epoch 700 LossPred 0.8093 LossAtt 0.5318 TrainAcc 0.7000 TestAcc 0.5583 0.6650
epoch 800 LossPred 0.7918 LossAtt 0.4796 TrainAcc 0.7100 TestAcc 0.5566 0.6800
epoch 900 LossPred 0.7680 LossAtt 0.4722 TrainAcc 0.7300 TestAcc 0.5576 0.7100
epoch 1000 LossPred 0.7692 LossAtt 0.4599 TrainAcc 0.7300 TestAcc 0.5648 0.7250
epoch 1100 LossPred 0.7672 LossAtt 0.4369 TrainAcc 0.7200 TestAcc 0.5711 0.7250
epoch 1200 LossPred 0.7828 LossAtt 0.4564 TrainAcc 0.7100 TestAcc 0.5653 0.7250
epoch 1300 LossPred 0.7925 LossAtt 0.4356 TrainAcc 0.7000 TestAcc 0.5686 0.7100
epoch 1400 LossPred 0.7825 LossAtt 0.4047 TrainAcc 0.7200 TestAcc 0.5706 0.7100
epoch 1500 LossPred 0.7819 LossAtt 0.3764 TrainAcc 0.7200 TestAcc 0.5701 0.7050
epoch 1600 LossPred 0.7931 LossAtt 0.3887 TrainAcc 0.7000 TestAcc 0.5678 0.7050
epoch 1700 LossPred 0.7853 LossAtt 0.3802 TrainAcc 0.7100 TestAcc 0.5703 0.7100
epoch 1800 LossPred 0.7890 LossAtt 0.3646 TrainAcc 0.7000 TestAcc 0.5666 0.7100
epoch 1900 LossPred 0.7877 LossAtt 0.3536 TrainAcc 0.7000 TestAcc 0.5716 0.7100
epoch 2000 LossPred 0.7876 LossAtt 0.3824 TrainAcc 0.7000 TestAcc 0.5723 0.7100
epoch 2100 LossPred 0.8104 LossAtt 0.3671 TrainAcc 0.6900 TestAcc 0.5653 0.7050
epoch 2200 LossPred 0.7977 LossAtt 0.3692 TrainAcc 0.7000 TestAcc 0.5786 0.7050
epoch 2300 LossPred 0.8115 LossAtt 0.3604 TrainAcc 0.7000 TestAcc 0.5743 0.7000
epoch 2400 LossPred 0.7950 LossAtt 0.3448 TrainAcc 0.7000 TestAcc 0.5798 0.7050
epoch 2500 LossPred 0.7950 LossAtt 0.3492 TrainAcc 0.7000 TestAcc 0.5788 0.7050
Optimization Finished!
********** replication  71  **********
epoch   0 LossPred 0.9364 LossAtt 1.0009 TrainAcc 0.6100 TestAcc 0.5183 0.6150
epoch 100 LossPred 0.8434 LossAtt 0.4553 TrainAcc 0.6900 TestAcc 0.5883 0.6900
epoch 200 LossPred 0.8285 LossAtt 0.4958 TrainAcc 0.6900 TestAcc 0.5883 0.6900
epoch 300 LossPred 0.8105 LossAtt 0.4719 TrainAcc 0.6900 TestAcc 0.5883 0.6900
epoch 400 LossPred 0.7949 LossAtt 0.4579 TrainAcc 0.6900 TestAcc 0.5883 0.6900
epoch 500 LossPred 0.7495 LossAtt 0.5180 TrainAcc 0.7100 TestAcc 0.6279 0.6950
epoch 600 LossPred 0.5906 LossAtt 0.5431 TrainAcc 0.8000 TestAcc 0.8016 0.7600
epoch 700 LossPred 0.5067 LossAtt 0.5020 TrainAcc 0.8100 TestAcc 0.8306 0.8300
epoch 800 LossPred 0.4685 LossAtt 0.4394 TrainAcc 0.8500 TestAcc 0.8448 0.8350
epoch 900 LossPred 0.3868 LossAtt 0.4200 TrainAcc 0.8600 TestAcc 0.8313 0.8450
epoch 1000 LossPred 0.3525 LossAtt 0.3737 TrainAcc 0.8600 TestAcc 0.8426 0.8600
epoch 1100 LossPred 0.3877 LossAtt 0.3700 TrainAcc 0.8600 TestAcc 0.8524 0.8700
epoch 1200 LossPred 0.3567 LossAtt 0.3552 TrainAcc 0.8700 TestAcc 0.8421 0.8850
epoch 1300 LossPred 0.3547 LossAtt 0.3504 TrainAcc 0.8800 TestAcc 0.8408 0.8850
epoch 1400 LossPred 0.3384 LossAtt 0.3517 TrainAcc 0.8700 TestAcc 0.8531 0.8600
epoch 1500 LossPred 0.3272 LossAtt 0.3566 TrainAcc 0.8800 TestAcc 0.8509 0.8700
epoch 1600 LossPred 0.3263 LossAtt 0.3642 TrainAcc 0.9000 TestAcc 0.8476 0.9000
epoch 1700 LossPred 0.3329 LossAtt 0.3518 TrainAcc 0.9000 TestAcc 0.8501 0.9000
epoch 1800 LossPred 0.3718 LossAtt 0.3763 TrainAcc 0.8500 TestAcc 0.8551 0.8550
epoch 1900 LossPred 0.5145 LossAtt 0.3599 TrainAcc 0.8100 TestAcc 0.7638 0.8100
epoch 2000 LossPred 0.3237 LossAtt 0.3714 TrainAcc 0.9000 TestAcc 0.8679 0.8750
epoch 2100 LossPred 0.3174 LossAtt 0.3558 TrainAcc 0.9100 TestAcc 0.8609 0.9000
epoch 2200 LossPred 0.3888 LossAtt 0.3670 TrainAcc 0.8500 TestAcc 0.8211 0.8450
epoch 2300 LossPred 0.3338 LossAtt 0.4126 TrainAcc 0.8600 TestAcc 0.8551 0.8700
epoch 2400 LossPred 0.4585 LossAtt 0.3869 TrainAcc 0.8400 TestAcc 0.8131 0.8350
epoch 2500 LossPred 0.3433 LossAtt 0.3799 TrainAcc 0.8600 TestAcc 0.8521 0.8750
Optimization Finished!
********** replication  72  **********
epoch   0 LossPred 1.0517 LossAtt 0.9863 TrainAcc 0.5400 TestAcc 0.5098 0.5300
epoch 100 LossPred 0.9263 LossAtt 0.3925 TrainAcc 0.6000 TestAcc 0.5893 0.6000
epoch 200 LossPred 0.9134 LossAtt 0.2865 TrainAcc 0.6000 TestAcc 0.5893 0.5900
epoch 300 LossPred 0.9055 LossAtt 0.3196 TrainAcc 0.6000 TestAcc 0.5893 0.5950
epoch 400 LossPred 0.8970 LossAtt 0.3453 TrainAcc 0.6000 TestAcc 0.6014 0.6000
epoch 500 LossPred 0.8550 LossAtt 0.4359 TrainAcc 0.6600 TestAcc 0.6264 0.6550
epoch 600 LossPred 0.8354 LossAtt 0.3827 TrainAcc 0.6700 TestAcc 0.6401 0.6800
epoch 700 LossPred 0.4953 LossAtt 0.4445 TrainAcc 0.8300 TestAcc 0.8496 0.8200
epoch 800 LossPred 0.4303 LossAtt 0.4512 TrainAcc 0.8500 TestAcc 0.8731 0.8450
epoch 900 LossPred 0.4027 LossAtt 0.4366 TrainAcc 0.9100 TestAcc 0.8774 0.8200
epoch 1000 LossPred 0.3680 LossAtt 0.4189 TrainAcc 0.8700 TestAcc 0.8851 0.8450
epoch 1100 LossPred 0.4702 LossAtt 0.4152 TrainAcc 0.8200 TestAcc 0.8376 0.7800
epoch 1200 LossPred 0.3976 LossAtt 0.4147 TrainAcc 0.8900 TestAcc 0.8559 0.8050
epoch 1300 LossPred 0.3799 LossAtt 0.4141 TrainAcc 0.9000 TestAcc 0.8746 0.8200
epoch 1400 LossPred 0.4563 LossAtt 0.3935 TrainAcc 0.8300 TestAcc 0.8321 0.8000
epoch 1500 LossPred 0.3549 LossAtt 0.4195 TrainAcc 0.9000 TestAcc 0.8761 0.8650
epoch 1600 LossPred 0.4996 LossAtt 0.3987 TrainAcc 0.8400 TestAcc 0.8511 0.8300
epoch 1700 LossPred 0.4477 LossAtt 0.4129 TrainAcc 0.8300 TestAcc 0.8521 0.8550
epoch 1800 LossPred 0.3817 LossAtt 0.4036 TrainAcc 0.8600 TestAcc 0.8614 0.8300
epoch 1900 LossPred 0.5005 LossAtt 0.4098 TrainAcc 0.8300 TestAcc 0.8448 0.8200
epoch 2000 LossPred 0.3736 LossAtt 0.4014 TrainAcc 0.8800 TestAcc 0.8661 0.8350
epoch 2100 LossPred 0.4265 LossAtt 0.4091 TrainAcc 0.8500 TestAcc 0.8586 0.8600
epoch 2200 LossPred 0.3366 LossAtt 0.3880 TrainAcc 0.9200 TestAcc 0.8614 0.8350
epoch 2300 LossPred 0.3334 LossAtt 0.3947 TrainAcc 0.9000 TestAcc 0.8816 0.9050
epoch 2400 LossPred 0.3240 LossAtt 0.3867 TrainAcc 0.9100 TestAcc 0.8821 0.8900
epoch 2500 LossPred 0.3120 LossAtt 0.3878 TrainAcc 0.9200 TestAcc 0.8609 0.8700
Optimization Finished!
********** replication  73  **********
epoch   0 LossPred 1.0844 LossAtt 1.0067 TrainAcc 0.5200 TestAcc 0.5325 0.5400
epoch 100 LossPred 0.9879 LossAtt 0.2662 TrainAcc 0.5600 TestAcc 0.5843 0.5600
epoch 200 LossPred 0.9839 LossAtt 0.1715 TrainAcc 0.5600 TestAcc 0.5843 0.5600
epoch 300 LossPred 0.9607 LossAtt 0.2883 TrainAcc 0.5900 TestAcc 0.5586 0.5750
epoch 400 LossPred 0.9501 LossAtt 0.3784 TrainAcc 0.5900 TestAcc 0.5671 0.5750
epoch 500 LossPred 0.4593 LossAtt 0.5447 TrainAcc 0.9100 TestAcc 0.8629 0.8750
epoch 600 LossPred 0.3523 LossAtt 0.4996 TrainAcc 0.9100 TestAcc 0.8656 0.8850
epoch 700 LossPred 0.3161 LossAtt 0.4851 TrainAcc 0.9200 TestAcc 0.8704 0.8850
epoch 800 LossPred 0.2916 LossAtt 0.4736 TrainAcc 0.9100 TestAcc 0.8759 0.8850
epoch 900 LossPred 0.2744 LossAtt 0.4844 TrainAcc 0.9100 TestAcc 0.8801 0.8850
epoch 1000 LossPred 0.3060 LossAtt 0.4761 TrainAcc 0.9100 TestAcc 0.8636 0.8850
epoch 1100 LossPred 0.2662 LossAtt 0.4911 TrainAcc 0.9200 TestAcc 0.8776 0.9050
epoch 1200 LossPred 0.3575 LossAtt 0.4958 TrainAcc 0.8800 TestAcc 0.8564 0.8750
epoch 1300 LossPred 0.2413 LossAtt 0.5197 TrainAcc 0.9200 TestAcc 0.8986 0.9150
epoch 1400 LossPred 0.2541 LossAtt 0.4979 TrainAcc 0.9000 TestAcc 0.8844 0.9000
epoch 1500 LossPred 0.2507 LossAtt 0.4861 TrainAcc 0.9100 TestAcc 0.9024 0.8950
epoch 1600 LossPred 0.2087 LossAtt 0.5064 TrainAcc 0.9300 TestAcc 0.9037 0.8900
epoch 1700 LossPred 0.2428 LossAtt 0.4983 TrainAcc 0.9000 TestAcc 0.9067 0.9000
epoch 1800 LossPred 0.2264 LossAtt 0.5200 TrainAcc 0.9200 TestAcc 0.9012 0.9050
epoch 1900 LossPred 0.2377 LossAtt 0.4998 TrainAcc 0.9100 TestAcc 0.9014 0.9050
epoch 2000 LossPred 0.2079 LossAtt 0.5019 TrainAcc 0.9300 TestAcc 0.8856 0.8950
epoch 2100 LossPred 0.1524 LossAtt 0.5144 TrainAcc 0.9700 TestAcc 0.8996 0.9150
epoch 2200 LossPred 0.3144 LossAtt 0.5354 TrainAcc 0.8700 TestAcc 0.8799 0.8850
epoch 2300 LossPred 0.3180 LossAtt 0.5029 TrainAcc 0.8800 TestAcc 0.8811 0.8950
epoch 2400 LossPred 0.1430 LossAtt 0.4975 TrainAcc 0.9600 TestAcc 0.8989 0.9150
epoch 2500 LossPred 0.1205 LossAtt 0.5093 TrainAcc 0.9700 TestAcc 0.9074 0.9300
Optimization Finished!
********** replication  74  **********
epoch   0 LossPred 1.1023 LossAtt 0.9909 TrainAcc 0.4200 TestAcc 0.4757 0.4500
epoch 100 LossPred 0.8982 LossAtt 0.4043 TrainAcc 0.6300 TestAcc 0.5883 0.6300
epoch 200 LossPred 0.8837 LossAtt 0.3550 TrainAcc 0.6600 TestAcc 0.5475 0.6400
epoch 300 LossPred 0.8820 LossAtt 0.3130 TrainAcc 0.6600 TestAcc 0.5475 0.6600
epoch 400 LossPred 0.8802 LossAtt 0.3602 TrainAcc 0.6600 TestAcc 0.5475 0.6600
epoch 500 LossPred 0.8754 LossAtt 0.3836 TrainAcc 0.6600 TestAcc 0.5475 0.6600
epoch 600 LossPred 0.8671 LossAtt 0.4117 TrainAcc 0.6500 TestAcc 0.5671 0.6450
epoch 700 LossPred 0.7470 LossAtt 0.4277 TrainAcc 0.7400 TestAcc 0.7062 0.7350
epoch 800 LossPred 0.4476 LossAtt 0.4329 TrainAcc 0.8600 TestAcc 0.8211 0.8300
epoch 900 LossPred 0.4264 LossAtt 0.4317 TrainAcc 0.8600 TestAcc 0.8396 0.8550
epoch 1000 LossPred 0.4210 LossAtt 0.3945 TrainAcc 0.8600 TestAcc 0.8378 0.8550
epoch 1100 LossPred 0.3877 LossAtt 0.4112 TrainAcc 0.8700 TestAcc 0.8046 0.8700
epoch 1200 LossPred 0.3861 LossAtt 0.4261 TrainAcc 0.8900 TestAcc 0.8188 0.8150
epoch 1300 LossPred 0.4107 LossAtt 0.4278 TrainAcc 0.8800 TestAcc 0.8201 0.7900
epoch 1400 LossPred 0.3713 LossAtt 0.4069 TrainAcc 0.8700 TestAcc 0.8273 0.8300
epoch 1500 LossPred 0.3623 LossAtt 0.3677 TrainAcc 0.8800 TestAcc 0.8161 0.8550
epoch 1600 LossPred 0.3252 LossAtt 0.3776 TrainAcc 0.8900 TestAcc 0.8193 0.8400
epoch 1700 LossPred 0.4485 LossAtt 0.3876 TrainAcc 0.8400 TestAcc 0.8233 0.7800
epoch 1800 LossPred 0.3277 LossAtt 0.3804 TrainAcc 0.9200 TestAcc 0.8318 0.8650
epoch 1900 LossPred 0.3337 LossAtt 0.3581 TrainAcc 0.9100 TestAcc 0.8093 0.8700
epoch 2000 LossPred 0.3108 LossAtt 0.3642 TrainAcc 0.9100 TestAcc 0.8213 0.8700
epoch 2100 LossPred 0.3241 LossAtt 0.3491 TrainAcc 0.9100 TestAcc 0.8261 0.8700
epoch 2200 LossPred 0.3061 LossAtt 0.3556 TrainAcc 0.9200 TestAcc 0.8291 0.8650
epoch 2300 LossPred 0.3586 LossAtt 0.3294 TrainAcc 0.8900 TestAcc 0.7908 0.8550
epoch 2400 LossPred 0.3095 LossAtt 0.3508 TrainAcc 0.9000 TestAcc 0.8278 0.8450
epoch 2500 LossPred 0.3075 LossAtt 0.3322 TrainAcc 0.9000 TestAcc 0.8288 0.8550
Optimization Finished!
********** replication  75  **********
epoch   0 LossPred 1.2288 LossAtt 1.0104 TrainAcc 0.5800 TestAcc 0.5706 0.5450
epoch 100 LossPred 0.9903 LossAtt 0.4043 TrainAcc 0.6100 TestAcc 0.5325 0.6050
epoch 200 LossPred 0.9476 LossAtt 0.3750 TrainAcc 0.6400 TestAcc 0.5428 0.6100
epoch 300 LossPred 0.9176 LossAtt 0.3402 TrainAcc 0.6100 TestAcc 0.5325 0.6100
epoch 400 LossPred 0.8937 LossAtt 0.3422 TrainAcc 0.6100 TestAcc 0.5325 0.6100
epoch 500 LossPred 0.8783 LossAtt 0.3129 TrainAcc 0.6100 TestAcc 0.5956 0.6200
epoch 600 LossPred 0.8756 LossAtt 0.3433 TrainAcc 0.6000 TestAcc 0.6029 0.6250
epoch 700 LossPred 0.8820 LossAtt 0.4819 TrainAcc 0.5900 TestAcc 0.6066 0.5950
epoch 800 LossPred 0.8305 LossAtt 0.5186 TrainAcc 0.6900 TestAcc 0.6221 0.6650
epoch 900 LossPred 0.7844 LossAtt 0.6160 TrainAcc 0.7100 TestAcc 0.6299 0.6900
epoch 1000 LossPred 0.5871 LossAtt 0.7198 TrainAcc 0.8100 TestAcc 0.7185 0.7950
epoch 1100 LossPred 0.4584 LossAtt 0.7028 TrainAcc 0.8600 TestAcc 0.8136 0.8400
epoch 1200 LossPred 0.3966 LossAtt 0.6801 TrainAcc 0.8600 TestAcc 0.8331 0.8350
epoch 1300 LossPred 0.3757 LossAtt 0.6086 TrainAcc 0.8500 TestAcc 0.8584 0.8800
epoch 1400 LossPred 0.2443 LossAtt 0.6016 TrainAcc 0.9400 TestAcc 0.8974 0.9350
epoch 1500 LossPred 0.2969 LossAtt 0.5881 TrainAcc 0.9100 TestAcc 0.8831 0.9100
epoch 1600 LossPred 0.3406 LossAtt 0.5867 TrainAcc 0.8600 TestAcc 0.8551 0.8600
epoch 1700 LossPred 0.2475 LossAtt 0.5686 TrainAcc 0.9100 TestAcc 0.8929 0.9050
epoch 1800 LossPred 0.2256 LossAtt 0.5446 TrainAcc 0.9100 TestAcc 0.8959 0.9100
epoch 1900 LossPred 0.2956 LossAtt 0.5523 TrainAcc 0.8800 TestAcc 0.8774 0.8800
epoch 2000 LossPred 0.4156 LossAtt 0.5267 TrainAcc 0.8600 TestAcc 0.8726 0.8700
epoch 2100 LossPred 0.1841 LossAtt 0.5399 TrainAcc 0.9500 TestAcc 0.9052 0.9300
epoch 2200 LossPred 0.2195 LossAtt 0.5425 TrainAcc 0.9400 TestAcc 0.9024 0.9300
epoch 2300 LossPred 0.2491 LossAtt 0.5437 TrainAcc 0.9000 TestAcc 0.8981 0.8950
epoch 2400 LossPred 0.2476 LossAtt 0.5142 TrainAcc 0.9000 TestAcc 0.9084 0.9050
epoch 2500 LossPred 0.1622 LossAtt 0.5255 TrainAcc 0.9300 TestAcc 0.9142 0.9500
Optimization Finished!
********** replication  76  **********
epoch   0 LossPred 1.2238 LossAtt 0.9650 TrainAcc 0.5200 TestAcc 0.4880 0.5150
epoch 100 LossPred 0.9823 LossAtt 0.4810 TrainAcc 0.5700 TestAcc 0.6224 0.5600
epoch 200 LossPred 0.9519 LossAtt 0.4031 TrainAcc 0.5800 TestAcc 0.5876 0.5500
epoch 300 LossPred 0.9199 LossAtt 0.4699 TrainAcc 0.5900 TestAcc 0.5813 0.5950
epoch 400 LossPred 0.8329 LossAtt 0.5071 TrainAcc 0.7000 TestAcc 0.5418 0.6600
epoch 500 LossPred 0.7874 LossAtt 0.5666 TrainAcc 0.7200 TestAcc 0.5638 0.6850
epoch 600 LossPred 0.7562 LossAtt 0.5426 TrainAcc 0.7300 TestAcc 0.5561 0.6700
epoch 700 LossPred 0.7480 LossAtt 0.5317 TrainAcc 0.7200 TestAcc 0.5538 0.6700
epoch 800 LossPred 0.7406 LossAtt 0.5436 TrainAcc 0.7200 TestAcc 0.5443 0.6850
epoch 900 LossPred 0.7525 LossAtt 0.5189 TrainAcc 0.7100 TestAcc 0.5435 0.6850
epoch 1000 LossPred 0.7404 LossAtt 0.5169 TrainAcc 0.7100 TestAcc 0.5420 0.6900
epoch 1100 LossPred 0.7604 LossAtt 0.5211 TrainAcc 0.7100 TestAcc 0.5378 0.6850
epoch 1200 LossPred 0.7686 LossAtt 0.5183 TrainAcc 0.7100 TestAcc 0.5310 0.6900
epoch 1300 LossPred 0.7470 LossAtt 0.5225 TrainAcc 0.7100 TestAcc 0.5378 0.6600
epoch 1400 LossPred 0.7480 LossAtt 0.5111 TrainAcc 0.7000 TestAcc 0.5425 0.6650
epoch 1500 LossPred 0.7484 LossAtt 0.5148 TrainAcc 0.7000 TestAcc 0.5438 0.6550
epoch 1600 LossPred 0.7368 LossAtt 0.5150 TrainAcc 0.7100 TestAcc 0.5430 0.6650
epoch 1700 LossPred 0.7315 LossAtt 0.5207 TrainAcc 0.7100 TestAcc 0.5425 0.6600
epoch 1800 LossPred 0.7352 LossAtt 0.5152 TrainAcc 0.6900 TestAcc 0.5380 0.6650
epoch 1900 LossPred 0.7238 LossAtt 0.4980 TrainAcc 0.7100 TestAcc 0.5370 0.6650
epoch 2000 LossPred 0.7215 LossAtt 0.5191 TrainAcc 0.7200 TestAcc 0.5388 0.6850
epoch 2100 LossPred 0.7241 LossAtt 0.4984 TrainAcc 0.7300 TestAcc 0.5400 0.6700
epoch 2200 LossPred 0.7475 LossAtt 0.4807 TrainAcc 0.7000 TestAcc 0.5340 0.6850
epoch 2300 LossPred 0.7268 LossAtt 0.4950 TrainAcc 0.6900 TestAcc 0.5355 0.7150
epoch 2400 LossPred 0.7251 LossAtt 0.4932 TrainAcc 0.6900 TestAcc 0.5385 0.6950
epoch 2500 LossPred 0.7331 LossAtt 0.5012 TrainAcc 0.6800 TestAcc 0.5423 0.6950
Optimization Finished!
********** replication  77  **********
epoch   0 LossPred 1.0454 LossAtt 0.9963 TrainAcc 0.5100 TestAcc 0.5055 0.5250
epoch 100 LossPred 0.8862 LossAtt 0.4515 TrainAcc 0.6000 TestAcc 0.5896 0.6500
epoch 200 LossPred 0.8757 LossAtt 0.4353 TrainAcc 0.6900 TestAcc 0.6346 0.6900
epoch 300 LossPred 0.8616 LossAtt 0.4822 TrainAcc 0.6900 TestAcc 0.6346 0.6900
epoch 400 LossPred 0.8057 LossAtt 0.4725 TrainAcc 0.6900 TestAcc 0.6346 0.6900
epoch 500 LossPred 0.4958 LossAtt 0.4803 TrainAcc 0.8200 TestAcc 0.8336 0.8050
epoch 600 LossPred 0.3345 LossAtt 0.5203 TrainAcc 0.8800 TestAcc 0.8516 0.8800
epoch 700 LossPred 0.2727 LossAtt 0.4709 TrainAcc 0.9000 TestAcc 0.8846 0.8850
epoch 800 LossPred 0.2652 LossAtt 0.4525 TrainAcc 0.9100 TestAcc 0.8856 0.8900
epoch 900 LossPred 0.2761 LossAtt 0.4556 TrainAcc 0.8900 TestAcc 0.8826 0.8700
epoch 1000 LossPred 0.2939 LossAtt 0.4558 TrainAcc 0.8800 TestAcc 0.8729 0.8700
epoch 1100 LossPred 0.3424 LossAtt 0.4624 TrainAcc 0.8800 TestAcc 0.8493 0.8700
epoch 1200 LossPred 0.2466 LossAtt 0.4532 TrainAcc 0.9100 TestAcc 0.8854 0.8900
epoch 1300 LossPred 0.2215 LossAtt 0.4303 TrainAcc 0.9400 TestAcc 0.8931 0.8700
epoch 1400 LossPred 0.2321 LossAtt 0.4383 TrainAcc 0.9300 TestAcc 0.8869 0.8900
epoch 1500 LossPred 0.2984 LossAtt 0.3863 TrainAcc 0.8900 TestAcc 0.8606 0.8950
epoch 1600 LossPred 0.2328 LossAtt 0.4252 TrainAcc 0.9100 TestAcc 0.8894 0.9050
epoch 1700 LossPred 0.2554 LossAtt 0.4412 TrainAcc 0.8800 TestAcc 0.8881 0.8800
epoch 1800 LossPred 0.2720 LossAtt 0.4252 TrainAcc 0.8900 TestAcc 0.8749 0.8850
epoch 1900 LossPred 0.2307 LossAtt 0.4143 TrainAcc 0.8900 TestAcc 0.8951 0.8950
epoch 2000 LossPred 0.2094 LossAtt 0.4286 TrainAcc 0.9100 TestAcc 0.8921 0.8700
epoch 2100 LossPred 0.2005 LossAtt 0.4217 TrainAcc 0.9300 TestAcc 0.9002 0.9050
epoch 2200 LossPred 0.2079 LossAtt 0.4141 TrainAcc 0.9200 TestAcc 0.8921 0.9200
epoch 2300 LossPred 0.1931 LossAtt 0.4047 TrainAcc 0.9200 TestAcc 0.9027 0.9100
epoch 2400 LossPred 0.1870 LossAtt 0.4001 TrainAcc 0.9200 TestAcc 0.9004 0.8700
epoch 2500 LossPred 0.1831 LossAtt 0.4199 TrainAcc 0.9100 TestAcc 0.9037 0.8800
Optimization Finished!
********** replication  78  **********
epoch   0 LossPred 1.1875 LossAtt 0.9855 TrainAcc 0.4100 TestAcc 0.4815 0.4050
epoch 100 LossPred 0.9504 LossAtt 0.4137 TrainAcc 0.5500 TestAcc 0.5663 0.5550
epoch 200 LossPred 0.9227 LossAtt 0.3664 TrainAcc 0.6200 TestAcc 0.5911 0.6200
epoch 300 LossPred 0.8939 LossAtt 0.3603 TrainAcc 0.6200 TestAcc 0.5911 0.6200
epoch 400 LossPred 0.6562 LossAtt 0.3257 TrainAcc 0.7900 TestAcc 0.7678 0.7700
epoch 500 LossPred 0.8949 LossAtt 0.3205 TrainAcc 0.7100 TestAcc 0.7125 0.7100
epoch 600 LossPred 0.7523 LossAtt 0.3101 TrainAcc 0.7500 TestAcc 0.7545 0.7650
epoch 700 LossPred 0.8770 LossAtt 0.2949 TrainAcc 0.6700 TestAcc 0.6609 0.6700
epoch 800 LossPred 0.8199 LossAtt 0.2851 TrainAcc 0.7000 TestAcc 0.6934 0.6900
epoch 900 LossPred 0.8167 LossAtt 0.3002 TrainAcc 0.7100 TestAcc 0.7305 0.7400
epoch 1000 LossPred 0.8146 LossAtt 0.2958 TrainAcc 0.7100 TestAcc 0.7295 0.7400
epoch 1100 LossPred 0.8151 LossAtt 0.2644 TrainAcc 0.7000 TestAcc 0.7282 0.7400
epoch 1200 LossPred 0.7619 LossAtt 0.2766 TrainAcc 0.7400 TestAcc 0.7520 0.7600
epoch 1300 LossPred 0.7036 LossAtt 0.2869 TrainAcc 0.7600 TestAcc 0.7195 0.7400
epoch 1400 LossPred 0.6376 LossAtt 0.2713 TrainAcc 0.7900 TestAcc 0.7523 0.7800
epoch 1500 LossPred 0.7033 LossAtt 0.2831 TrainAcc 0.7400 TestAcc 0.7230 0.7600
epoch 1600 LossPred 0.6986 LossAtt 0.2781 TrainAcc 0.7400 TestAcc 0.7230 0.7500
epoch 1700 LossPred 0.6729 LossAtt 0.2876 TrainAcc 0.7500 TestAcc 0.7230 0.7450
epoch 1800 LossPred 0.6153 LossAtt 0.2987 TrainAcc 0.7800 TestAcc 0.7753 0.7800
epoch 1900 LossPred 0.6749 LossAtt 0.2821 TrainAcc 0.7400 TestAcc 0.7235 0.7450
epoch 2000 LossPred 0.7125 LossAtt 0.2819 TrainAcc 0.7300 TestAcc 0.7430 0.7650
epoch 2100 LossPred 0.6729 LossAtt 0.2906 TrainAcc 0.7700 TestAcc 0.7718 0.7600
epoch 2200 LossPred 0.7280 LossAtt 0.2792 TrainAcc 0.7500 TestAcc 0.7585 0.7550
epoch 2300 LossPred 0.7612 LossAtt 0.2858 TrainAcc 0.7400 TestAcc 0.7305 0.7300
epoch 2400 LossPred 0.7246 LossAtt 0.2666 TrainAcc 0.7500 TestAcc 0.7608 0.7500
epoch 2500 LossPred 0.7330 LossAtt 0.2847 TrainAcc 0.7500 TestAcc 0.7410 0.7200
Optimization Finished!
********** replication  79  **********
epoch   0 LossPred 1.1673 LossAtt 1.0272 TrainAcc 0.4200 TestAcc 0.4482 0.4500
epoch 100 LossPred 0.9485 LossAtt 0.3663 TrainAcc 0.5900 TestAcc 0.5816 0.5900
epoch 200 LossPred 0.9332 LossAtt 0.3530 TrainAcc 0.6000 TestAcc 0.6091 0.6000
epoch 300 LossPred 0.9173 LossAtt 0.3110 TrainAcc 0.6000 TestAcc 0.6159 0.6100
epoch 400 LossPred 0.9042 LossAtt 0.3426 TrainAcc 0.6000 TestAcc 0.5963 0.6000
epoch 500 LossPred 0.8917 LossAtt 0.3500 TrainAcc 0.6400 TestAcc 0.6001 0.6000
epoch 600 LossPred 0.8771 LossAtt 0.3869 TrainAcc 0.6400 TestAcc 0.6029 0.6500
epoch 700 LossPred 0.8519 LossAtt 0.3584 TrainAcc 0.6900 TestAcc 0.6219 0.6700
epoch 800 LossPred 0.8361 LossAtt 0.3586 TrainAcc 0.6900 TestAcc 0.6226 0.6750
epoch 900 LossPred 0.8255 LossAtt 0.3452 TrainAcc 0.7000 TestAcc 0.5798 0.6800
epoch 1000 LossPred 0.8222 LossAtt 0.3437 TrainAcc 0.7100 TestAcc 0.5791 0.6750
epoch 1100 LossPred 0.8026 LossAtt 0.3752 TrainAcc 0.7200 TestAcc 0.5816 0.7050
epoch 1200 LossPred 0.7920 LossAtt 0.3908 TrainAcc 0.7000 TestAcc 0.5911 0.6900
epoch 1300 LossPred 0.7722 LossAtt 0.4075 TrainAcc 0.6900 TestAcc 0.6006 0.7150
epoch 1400 LossPred 0.7735 LossAtt 0.3852 TrainAcc 0.6900 TestAcc 0.6114 0.7150
epoch 1500 LossPred 0.7611 LossAtt 0.4046 TrainAcc 0.6800 TestAcc 0.6174 0.7200
epoch 1600 LossPred 0.7530 LossAtt 0.3906 TrainAcc 0.7000 TestAcc 0.6199 0.7150
epoch 1700 LossPred 0.7687 LossAtt 0.4260 TrainAcc 0.7000 TestAcc 0.6419 0.6950
epoch 1800 LossPred 0.8259 LossAtt 0.4248 TrainAcc 0.6600 TestAcc 0.6414 0.6650
epoch 1900 LossPred 0.7512 LossAtt 0.4561 TrainAcc 0.7200 TestAcc 0.6374 0.7100
epoch 2000 LossPred 0.4831 LossAtt 0.4482 TrainAcc 0.8300 TestAcc 0.7923 0.8200
epoch 2100 LossPred 0.5785 LossAtt 0.4153 TrainAcc 0.7900 TestAcc 0.7753 0.7800
epoch 2200 LossPred 0.3826 LossAtt 0.4054 TrainAcc 0.8700 TestAcc 0.8433 0.8300
epoch 2300 LossPred 0.3543 LossAtt 0.4344 TrainAcc 0.8600 TestAcc 0.8504 0.8400
epoch 2400 LossPred 0.3492 LossAtt 0.4150 TrainAcc 0.8800 TestAcc 0.8624 0.8400
epoch 2500 LossPred 0.4488 LossAtt 0.4515 TrainAcc 0.8400 TestAcc 0.8338 0.7700
Optimization Finished!
********** replication  80  **********
epoch   0 LossPred 1.1056 LossAtt 1.0129 TrainAcc 0.4700 TestAcc 0.5053 0.4850
epoch 100 LossPred 0.9248 LossAtt 0.4693 TrainAcc 0.5900 TestAcc 0.5996 0.5900
epoch 200 LossPred 0.8924 LossAtt 0.4149 TrainAcc 0.6200 TestAcc 0.5758 0.6300
epoch 300 LossPred 0.8829 LossAtt 0.3476 TrainAcc 0.6200 TestAcc 0.5758 0.6350
epoch 400 LossPred 0.8788 LossAtt 0.2667 TrainAcc 0.6200 TestAcc 0.5758 0.6300
epoch 500 LossPred 0.8768 LossAtt 0.2188 TrainAcc 0.6200 TestAcc 0.5758 0.6200
epoch 600 LossPred 0.8761 LossAtt 0.1876 TrainAcc 0.6200 TestAcc 0.5758 0.6200
epoch 700 LossPred 0.8763 LossAtt 0.1914 TrainAcc 0.6200 TestAcc 0.5468 0.6400
epoch 800 LossPred 0.8809 LossAtt 0.2141 TrainAcc 0.6200 TestAcc 0.5468 0.6200
epoch 900 LossPred 0.8797 LossAtt 0.2314 TrainAcc 0.6200 TestAcc 0.5468 0.6200
epoch 1000 LossPred 0.8733 LossAtt 0.2686 TrainAcc 0.6200 TestAcc 0.5468 0.6200
epoch 1100 LossPred 0.8639 LossAtt 0.3122 TrainAcc 0.6300 TestAcc 0.5608 0.6550
epoch 1200 LossPred 0.7766 LossAtt 0.4222 TrainAcc 0.6900 TestAcc 0.6869 0.7100
epoch 1300 LossPred 0.7549 LossAtt 0.4467 TrainAcc 0.7400 TestAcc 0.7132 0.7350
epoch 1400 LossPred 0.7143 LossAtt 0.4959 TrainAcc 0.7300 TestAcc 0.7798 0.7150
epoch 1500 LossPred 0.4307 LossAtt 0.4509 TrainAcc 0.8600 TestAcc 0.8231 0.8800
epoch 1600 LossPred 0.3461 LossAtt 0.4683 TrainAcc 0.9000 TestAcc 0.8323 0.8600
epoch 1700 LossPred 0.3635 LossAtt 0.4444 TrainAcc 0.8900 TestAcc 0.8311 0.8700
epoch 1800 LossPred 0.3451 LossAtt 0.4245 TrainAcc 0.8900 TestAcc 0.8378 0.8600
epoch 1900 LossPred 0.3096 LossAtt 0.4152 TrainAcc 0.9100 TestAcc 0.8408 0.9000
epoch 2000 LossPred 0.5482 LossAtt 0.4081 TrainAcc 0.7900 TestAcc 0.8071 0.7700
epoch 2100 LossPred 0.3577 LossAtt 0.4044 TrainAcc 0.8600 TestAcc 0.8358 0.8400
epoch 2200 LossPred 0.2602 LossAtt 0.3964 TrainAcc 0.9200 TestAcc 0.8606 0.9000
epoch 2300 LossPred 0.3492 LossAtt 0.4195 TrainAcc 0.8700 TestAcc 0.8348 0.8750
epoch 2400 LossPred 0.5489 LossAtt 0.3856 TrainAcc 0.8200 TestAcc 0.8343 0.7750
epoch 2500 LossPred 0.3419 LossAtt 0.3959 TrainAcc 0.8500 TestAcc 0.8534 0.8750
Optimization Finished!
********** replication  81  **********
epoch   0 LossPred 0.9698 LossAtt 1.0063 TrainAcc 0.6600 TestAcc 0.5561 0.5900
epoch 100 LossPred 0.8393 LossAtt 0.3661 TrainAcc 0.6700 TestAcc 0.5908 0.6700
epoch 200 LossPred 0.8238 LossAtt 0.3024 TrainAcc 0.6700 TestAcc 0.5908 0.6700
epoch 300 LossPred 0.8165 LossAtt 0.2412 TrainAcc 0.6700 TestAcc 0.5908 0.6700
epoch 400 LossPred 0.8079 LossAtt 0.2238 TrainAcc 0.6700 TestAcc 0.5908 0.6700
epoch 500 LossPred 0.7980 LossAtt 0.2247 TrainAcc 0.6700 TestAcc 0.5908 0.6700
epoch 600 LossPred 0.7914 LossAtt 0.2696 TrainAcc 0.6700 TestAcc 0.5908 0.6700
epoch 700 LossPred 0.6948 LossAtt 0.4494 TrainAcc 0.7500 TestAcc 0.6927 0.7350
epoch 800 LossPred 0.9222 LossAtt 0.3956 TrainAcc 0.6700 TestAcc 0.5951 0.6700
epoch 900 LossPred 0.5887 LossAtt 0.3616 TrainAcc 0.8000 TestAcc 0.7132 0.8200
epoch 1000 LossPred 0.3816 LossAtt 0.3526 TrainAcc 0.9000 TestAcc 0.8196 0.8750
epoch 1100 LossPred 0.3503 LossAtt 0.3320 TrainAcc 0.9000 TestAcc 0.8071 0.8950
epoch 1200 LossPred 0.5791 LossAtt 0.3148 TrainAcc 0.8000 TestAcc 0.7285 0.8250
epoch 1300 LossPred 0.3400 LossAtt 0.2936 TrainAcc 0.9000 TestAcc 0.8066 0.8850
epoch 1400 LossPred 0.3480 LossAtt 0.3014 TrainAcc 0.8800 TestAcc 0.7980 0.8900
epoch 1500 LossPred 0.3792 LossAtt 0.2770 TrainAcc 0.8800 TestAcc 0.7933 0.8800
epoch 1600 LossPred 0.5915 LossAtt 0.2812 TrainAcc 0.8300 TestAcc 0.7487 0.8300
epoch 1700 LossPred 0.4794 LossAtt 0.2717 TrainAcc 0.8400 TestAcc 0.7840 0.8400
epoch 1800 LossPred 0.3437 LossAtt 0.2680 TrainAcc 0.8900 TestAcc 0.7905 0.8850
epoch 1900 LossPred 0.3078 LossAtt 0.2517 TrainAcc 0.9100 TestAcc 0.7773 0.8700
epoch 2000 LossPred 0.5992 LossAtt 0.2489 TrainAcc 0.8200 TestAcc 0.7578 0.8150
epoch 2100 LossPred 0.8483 LossAtt 0.2618 TrainAcc 0.7500 TestAcc 0.6859 0.7600
epoch 2200 LossPred 0.4273 LossAtt 0.2331 TrainAcc 0.8700 TestAcc 0.7725 0.8650
epoch 2300 LossPred 0.3901 LossAtt 0.2410 TrainAcc 0.8800 TestAcc 0.7803 0.8700
epoch 2400 LossPred 0.4076 LossAtt 0.2276 TrainAcc 0.8700 TestAcc 0.7820 0.8800
epoch 2500 LossPred 0.3354 LossAtt 0.2454 TrainAcc 0.9000 TestAcc 0.7855 0.8800
Optimization Finished!
********** replication  82  **********
epoch   0 LossPred 1.2137 LossAtt 0.9955 TrainAcc 0.4600 TestAcc 0.4094 0.4600
epoch 100 LossPred 0.9647 LossAtt 0.2617 TrainAcc 0.6300 TestAcc 0.6161 0.5600
epoch 200 LossPred 0.9594 LossAtt 0.1782 TrainAcc 0.5800 TestAcc 0.5881 0.5800
epoch 300 LossPred 0.9350 LossAtt 0.2188 TrainAcc 0.6300 TestAcc 0.6286 0.6400
epoch 400 LossPred 0.4080 LossAtt 0.2959 TrainAcc 0.9000 TestAcc 0.9064 0.8850
epoch 500 LossPred 0.4697 LossAtt 0.3068 TrainAcc 0.8600 TestAcc 0.8383 0.8300
epoch 600 LossPred 0.5056 LossAtt 0.3697 TrainAcc 0.8400 TestAcc 0.8008 0.7800
epoch 700 LossPred 0.9854 LossAtt 0.3451 TrainAcc 0.6500 TestAcc 0.6624 0.6500
epoch 800 LossPred 0.3874 LossAtt 0.3325 TrainAcc 0.8700 TestAcc 0.8576 0.8850
epoch 900 LossPred 0.8183 LossAtt 0.3302 TrainAcc 0.6900 TestAcc 0.7145 0.7050
epoch 1000 LossPred 0.9659 LossAtt 0.2889 TrainAcc 0.6600 TestAcc 0.6849 0.6500
epoch 1100 LossPred 0.6925 LossAtt 0.3004 TrainAcc 0.7500 TestAcc 0.6984 0.7100
epoch 1200 LossPred 0.5686 LossAtt 0.2976 TrainAcc 0.8200 TestAcc 0.7282 0.7850
epoch 1300 LossPred 0.3931 LossAtt 0.2955 TrainAcc 0.9000 TestAcc 0.8298 0.8900
epoch 1400 LossPred 0.4443 LossAtt 0.2775 TrainAcc 0.8500 TestAcc 0.7913 0.8250
epoch 1500 LossPred 0.3270 LossAtt 0.2841 TrainAcc 0.8800 TestAcc 0.8866 0.8900
epoch 1600 LossPred 0.3224 LossAtt 0.2830 TrainAcc 0.8900 TestAcc 0.8856 0.8900
epoch 1700 LossPred 0.2920 LossAtt 0.2729 TrainAcc 0.9100 TestAcc 0.8859 0.8900
epoch 1800 LossPred 0.2913 LossAtt 0.2713 TrainAcc 0.9100 TestAcc 0.8859 0.8900
epoch 1900 LossPred 0.3476 LossAtt 0.2719 TrainAcc 0.8800 TestAcc 0.8594 0.8700
epoch 2000 LossPred 0.2890 LossAtt 0.2647 TrainAcc 0.9200 TestAcc 0.8834 0.9050
epoch 2100 LossPred 0.7693 LossAtt 0.2451 TrainAcc 0.6700 TestAcc 0.6924 0.6750
epoch 2200 LossPred 0.9867 LossAtt 0.2471 TrainAcc 0.6400 TestAcc 0.7085 0.6450
epoch 2300 LossPred 0.5605 LossAtt 0.2697 TrainAcc 0.8400 TestAcc 0.7395 0.8300
epoch 2400 LossPred 0.7864 LossAtt 0.2392 TrainAcc 0.7000 TestAcc 0.7137 0.6850
epoch 2500 LossPred 0.3960 LossAtt 0.2713 TrainAcc 0.8700 TestAcc 0.8421 0.8800
Optimization Finished!
********** replication  83  **********
epoch   0 LossPred 1.0365 LossAtt 0.9991 TrainAcc 0.6100 TestAcc 0.5568 0.5800
epoch 100 LossPred 0.8382 LossAtt 0.4245 TrainAcc 0.7100 TestAcc 0.5991 0.7150
epoch 200 LossPred 0.8115 LossAtt 0.4136 TrainAcc 0.7100 TestAcc 0.5858 0.7050
epoch 300 LossPred 0.7598 LossAtt 0.4028 TrainAcc 0.7500 TestAcc 0.5983 0.7550
epoch 400 LossPred 0.7149 LossAtt 0.4343 TrainAcc 0.7500 TestAcc 0.6171 0.7600
epoch 500 LossPred 0.6373 LossAtt 0.4571 TrainAcc 0.7900 TestAcc 0.6104 0.7700
epoch 600 LossPred 0.6008 LossAtt 0.4797 TrainAcc 0.7900 TestAcc 0.6374 0.8050
epoch 700 LossPred 0.5534 LossAtt 0.5397 TrainAcc 0.8300 TestAcc 0.6864 0.8050
epoch 800 LossPred 0.5178 LossAtt 0.5688 TrainAcc 0.7600 TestAcc 0.7525 0.7750
epoch 900 LossPred 0.4112 LossAtt 0.5330 TrainAcc 0.8400 TestAcc 0.8066 0.8450
epoch 1000 LossPred 0.4319 LossAtt 0.5302 TrainAcc 0.8500 TestAcc 0.8403 0.8450
epoch 1100 LossPred 0.2128 LossAtt 0.5332 TrainAcc 0.9200 TestAcc 0.8771 0.9250
epoch 1200 LossPred 0.1622 LossAtt 0.5300 TrainAcc 0.9500 TestAcc 0.8819 0.9450
epoch 1300 LossPred 0.1914 LossAtt 0.5273 TrainAcc 0.9400 TestAcc 0.8751 0.9400
epoch 1400 LossPred 0.2756 LossAtt 0.5219 TrainAcc 0.9000 TestAcc 0.8589 0.9000
epoch 1500 LossPred 0.1857 LossAtt 0.5259 TrainAcc 0.9300 TestAcc 0.8894 0.9300
epoch 1600 LossPred 0.1962 LossAtt 0.5200 TrainAcc 0.9400 TestAcc 0.8836 0.9400
epoch 1700 LossPred 0.1297 LossAtt 0.5160 TrainAcc 0.9500 TestAcc 0.8934 0.9600
epoch 1800 LossPred 0.2369 LossAtt 0.5560 TrainAcc 0.9200 TestAcc 0.8526 0.9300
epoch 1900 LossPred 0.3083 LossAtt 0.5506 TrainAcc 0.8800 TestAcc 0.8624 0.8800
epoch 2000 LossPred 0.1316 LossAtt 0.5669 TrainAcc 0.9600 TestAcc 0.8986 0.9550
epoch 2100 LossPred 0.1904 LossAtt 0.5514 TrainAcc 0.9400 TestAcc 0.8829 0.9250
epoch 2200 LossPred 0.2645 LossAtt 0.5539 TrainAcc 0.9000 TestAcc 0.8681 0.9050
epoch 2300 LossPred 0.3272 LossAtt 0.5218 TrainAcc 0.8800 TestAcc 0.8486 0.8850
epoch 2400 LossPred 0.2199 LossAtt 0.5573 TrainAcc 0.9200 TestAcc 0.8711 0.9100
epoch 2500 LossPred 0.2733 LossAtt 0.5370 TrainAcc 0.9100 TestAcc 0.8594 0.8900
Optimization Finished!
********** replication  84  **********
epoch   0 LossPred 1.0737 LossAtt 1.0200 TrainAcc 0.5000 TestAcc 0.4797 0.4950
epoch 100 LossPred 0.9525 LossAtt 0.3787 TrainAcc 0.5500 TestAcc 0.5493 0.5500
epoch 200 LossPred 0.9072 LossAtt 0.3514 TrainAcc 0.6700 TestAcc 0.6264 0.6600
epoch 300 LossPred 0.5190 LossAtt 0.3751 TrainAcc 0.8300 TestAcc 0.8476 0.8300
epoch 400 LossPred 0.4481 LossAtt 0.3891 TrainAcc 0.8600 TestAcc 0.8501 0.8200
epoch 500 LossPred 0.4550 LossAtt 0.3755 TrainAcc 0.8400 TestAcc 0.8519 0.8400
epoch 600 LossPred 0.4092 LossAtt 0.3562 TrainAcc 0.8800 TestAcc 0.8691 0.8600
epoch 700 LossPred 0.3879 LossAtt 0.3622 TrainAcc 0.8900 TestAcc 0.8711 0.8650
epoch 800 LossPred 0.3859 LossAtt 0.3679 TrainAcc 0.8800 TestAcc 0.8701 0.8750
epoch 900 LossPred 0.3871 LossAtt 0.3547 TrainAcc 0.8800 TestAcc 0.8684 0.8500
epoch 1000 LossPred 0.3843 LossAtt 0.3424 TrainAcc 0.8900 TestAcc 0.8744 0.8700
epoch 1100 LossPred 0.3684 LossAtt 0.3571 TrainAcc 0.8800 TestAcc 0.8809 0.8550
epoch 1200 LossPred 0.5201 LossAtt 0.3477 TrainAcc 0.8300 TestAcc 0.8451 0.8350
epoch 1300 LossPred 0.4647 LossAtt 0.3308 TrainAcc 0.8500 TestAcc 0.8741 0.8600
epoch 1400 LossPred 0.4182 LossAtt 0.3332 TrainAcc 0.8600 TestAcc 0.8629 0.8100
epoch 1500 LossPred 0.4998 LossAtt 0.3287 TrainAcc 0.8400 TestAcc 0.8576 0.8500
epoch 1600 LossPred 0.3607 LossAtt 0.3447 TrainAcc 0.8900 TestAcc 0.8824 0.8600
epoch 1700 LossPred 0.4905 LossAtt 0.3456 TrainAcc 0.8300 TestAcc 0.8361 0.8550
epoch 1800 LossPred 0.4840 LossAtt 0.3335 TrainAcc 0.8400 TestAcc 0.8621 0.8700
epoch 1900 LossPred 0.4537 LossAtt 0.3233 TrainAcc 0.8500 TestAcc 0.8681 0.8700
epoch 2000 LossPred 0.3665 LossAtt 0.3399 TrainAcc 0.8800 TestAcc 0.8846 0.8750
epoch 2100 LossPred 0.3785 LossAtt 0.3206 TrainAcc 0.8700 TestAcc 0.8821 0.8350
epoch 2200 LossPred 0.4742 LossAtt 0.3274 TrainAcc 0.8300 TestAcc 0.8428 0.8550
epoch 2300 LossPred 0.3489 LossAtt 0.3248 TrainAcc 0.8800 TestAcc 0.8896 0.8300
epoch 2400 LossPred 0.3492 LossAtt 0.3273 TrainAcc 0.8800 TestAcc 0.8866 0.8850
epoch 2500 LossPred 0.3579 LossAtt 0.3221 TrainAcc 0.8800 TestAcc 0.8994 0.8600
Optimization Finished!
********** replication  85  **********
epoch   0 LossPred 1.1005 LossAtt 1.0660 TrainAcc 0.5100 TestAcc 0.5093 0.4850
epoch 100 LossPred 0.9848 LossAtt 0.3187 TrainAcc 0.5600 TestAcc 0.5876 0.5600
epoch 200 LossPred 0.9841 LossAtt 0.2171 TrainAcc 0.5600 TestAcc 0.5876 0.5600
epoch 300 LossPred 0.9842 LossAtt 0.2278 TrainAcc 0.5600 TestAcc 0.5876 0.5600
epoch 400 LossPred 0.9803 LossAtt 0.2432 TrainAcc 0.5600 TestAcc 0.5876 0.5600
epoch 500 LossPred 0.9704 LossAtt 0.3231 TrainAcc 0.5600 TestAcc 0.5876 0.5600
epoch 600 LossPred 0.9469 LossAtt 0.3403 TrainAcc 0.6100 TestAcc 0.6281 0.6200
epoch 700 LossPred 0.8896 LossAtt 0.3461 TrainAcc 0.7000 TestAcc 0.6466 0.6050
epoch 800 LossPred 0.8475 LossAtt 0.4150 TrainAcc 0.6700 TestAcc 0.6552 0.6500
epoch 900 LossPred 0.7470 LossAtt 0.3637 TrainAcc 0.7500 TestAcc 0.7352 0.7500
epoch 1000 LossPred 1.3049 LossAtt 0.2838 TrainAcc 0.5600 TestAcc 0.5946 0.5650
epoch 1100 LossPred 1.0751 LossAtt 0.2785 TrainAcc 0.5600 TestAcc 0.5876 0.5600
epoch 1200 LossPred 0.9826 LossAtt 0.3437 TrainAcc 0.6300 TestAcc 0.6091 0.6200
epoch 1300 LossPred 0.4315 LossAtt 0.3270 TrainAcc 0.8600 TestAcc 0.8604 0.8750
epoch 1400 LossPred 0.3735 LossAtt 0.3419 TrainAcc 0.8900 TestAcc 0.8511 0.8750
epoch 1500 LossPred 0.3582 LossAtt 0.3588 TrainAcc 0.8900 TestAcc 0.8233 0.8800
epoch 1600 LossPred 0.3567 LossAtt 0.3627 TrainAcc 0.8800 TestAcc 0.8238 0.8750
epoch 1700 LossPred 0.4510 LossAtt 0.3694 TrainAcc 0.8700 TestAcc 0.8033 0.8650
epoch 1800 LossPred 0.3497 LossAtt 0.3887 TrainAcc 0.8900 TestAcc 0.8253 0.8900
epoch 1900 LossPred 0.3799 LossAtt 0.3644 TrainAcc 0.9000 TestAcc 0.8151 0.8800
epoch 2000 LossPred 0.4397 LossAtt 0.3833 TrainAcc 0.8700 TestAcc 0.7973 0.8500
epoch 2100 LossPred 0.4686 LossAtt 0.3812 TrainAcc 0.8200 TestAcc 0.8086 0.8700
epoch 2200 LossPred 0.4074 LossAtt 0.3797 TrainAcc 0.8800 TestAcc 0.8143 0.8850
epoch 2300 LossPred 0.5636 LossAtt 0.3716 TrainAcc 0.7800 TestAcc 0.7958 0.7700
epoch 2400 LossPred 0.4257 LossAtt 0.3643 TrainAcc 0.8400 TestAcc 0.8093 0.8650
epoch 2500 LossPred 0.3718 LossAtt 0.3777 TrainAcc 0.8800 TestAcc 0.8378 0.8900
Optimization Finished!
********** replication  86  **********
epoch   0 LossPred 1.1015 LossAtt 1.0206 TrainAcc 0.3900 TestAcc 0.4164 0.4000
epoch 100 LossPred 0.9336 LossAtt 0.4350 TrainAcc 0.6300 TestAcc 0.6346 0.6300
epoch 200 LossPred 0.8692 LossAtt 0.4367 TrainAcc 0.6500 TestAcc 0.6557 0.6200
epoch 300 LossPred 0.4079 LossAtt 0.4705 TrainAcc 0.9100 TestAcc 0.8751 0.8950
epoch 400 LossPred 0.3132 LossAtt 0.3904 TrainAcc 0.9100 TestAcc 0.8796 0.9150
epoch 500 LossPred 0.3153 LossAtt 0.3888 TrainAcc 0.9100 TestAcc 0.8809 0.9100
epoch 600 LossPred 0.2500 LossAtt 0.3608 TrainAcc 0.9400 TestAcc 0.8859 0.9250
epoch 700 LossPred 0.3698 LossAtt 0.3503 TrainAcc 0.8700 TestAcc 0.8496 0.8750
epoch 800 LossPred 0.2784 LossAtt 0.3670 TrainAcc 0.9200 TestAcc 0.8749 0.9100
epoch 900 LossPred 0.4286 LossAtt 0.3972 TrainAcc 0.8500 TestAcc 0.8559 0.8350
epoch 1000 LossPred 0.3479 LossAtt 0.3962 TrainAcc 0.8700 TestAcc 0.8596 0.8700
epoch 1100 LossPred 0.2569 LossAtt 0.3953 TrainAcc 0.9300 TestAcc 0.8881 0.9150
epoch 1200 LossPred 0.5587 LossAtt 0.3910 TrainAcc 0.8100 TestAcc 0.7853 0.8050
epoch 1300 LossPred 0.2421 LossAtt 0.3780 TrainAcc 0.9300 TestAcc 0.8891 0.9100
epoch 1400 LossPred 0.2348 LossAtt 0.3843 TrainAcc 0.9300 TestAcc 0.8934 0.9200
epoch 1500 LossPred 0.3572 LossAtt 0.3894 TrainAcc 0.8800 TestAcc 0.8529 0.8600
epoch 1600 LossPred 0.3919 LossAtt 0.3994 TrainAcc 0.8500 TestAcc 0.8333 0.8550
epoch 1700 LossPred 0.4904 LossAtt 0.3869 TrainAcc 0.8300 TestAcc 0.8586 0.8350
epoch 1800 LossPred 0.3143 LossAtt 0.3927 TrainAcc 0.9100 TestAcc 0.8656 0.8900
epoch 1900 LossPred 0.2275 LossAtt 0.3645 TrainAcc 0.9300 TestAcc 0.8894 0.9200
epoch 2000 LossPred 0.2604 LossAtt 0.3671 TrainAcc 0.9000 TestAcc 0.8774 0.9050
epoch 2100 LossPred 0.1975 LossAtt 0.3581 TrainAcc 0.9400 TestAcc 0.8909 0.9150
epoch 2200 LossPred 0.1989 LossAtt 0.3441 TrainAcc 0.9200 TestAcc 0.8881 0.9250
epoch 2300 LossPred 0.1889 LossAtt 0.3554 TrainAcc 0.9400 TestAcc 0.8959 0.9250
epoch 2400 LossPred 0.1857 LossAtt 0.3535 TrainAcc 0.9300 TestAcc 0.8919 0.9250
epoch 2500 LossPred 0.3004 LossAtt 0.3625 TrainAcc 0.9000 TestAcc 0.8814 0.8900
Optimization Finished!
********** replication  87  **********
epoch   0 LossPred 0.9844 LossAtt 1.0320 TrainAcc 0.6200 TestAcc 0.5183 0.6100
epoch 100 LossPred 0.8929 LossAtt 0.4237 TrainAcc 0.6400 TestAcc 0.5603 0.6200
epoch 200 LossPred 0.8579 LossAtt 0.4054 TrainAcc 0.6300 TestAcc 0.5448 0.6150
epoch 300 LossPred 0.8174 LossAtt 0.3976 TrainAcc 0.7000 TestAcc 0.5480 0.6750
epoch 400 LossPred 0.8127 LossAtt 0.4088 TrainAcc 0.6700 TestAcc 0.5608 0.6650
epoch 500 LossPred 0.8152 LossAtt 0.3879 TrainAcc 0.7200 TestAcc 0.5253 0.6850
epoch 600 LossPred 0.7845 LossAtt 0.3934 TrainAcc 0.7200 TestAcc 0.5395 0.7100
epoch 700 LossPred 0.7786 LossAtt 0.3804 TrainAcc 0.7200 TestAcc 0.5408 0.7000
epoch 800 LossPred 0.7768 LossAtt 0.4003 TrainAcc 0.7200 TestAcc 0.5470 0.7050
epoch 900 LossPred 0.7766 LossAtt 0.3965 TrainAcc 0.7100 TestAcc 0.5420 0.7100
epoch 1000 LossPred 0.7611 LossAtt 0.4495 TrainAcc 0.7200 TestAcc 0.5478 0.7150
epoch 1100 LossPred 0.4119 LossAtt 0.5861 TrainAcc 0.8600 TestAcc 0.8161 0.8050
epoch 1200 LossPred 0.4262 LossAtt 0.5598 TrainAcc 0.8700 TestAcc 0.7988 0.8450
epoch 1300 LossPred 0.2685 LossAtt 0.5946 TrainAcc 0.9100 TestAcc 0.8451 0.8300
epoch 1400 LossPred 0.2911 LossAtt 0.6003 TrainAcc 0.8800 TestAcc 0.8559 0.8600
epoch 1500 LossPred 0.2766 LossAtt 0.6033 TrainAcc 0.8900 TestAcc 0.8278 0.8150
epoch 1600 LossPred 0.3504 LossAtt 0.6075 TrainAcc 0.8700 TestAcc 0.8166 0.7950
epoch 1700 LossPred 0.3238 LossAtt 0.5798 TrainAcc 0.9000 TestAcc 0.8456 0.8400
epoch 1800 LossPred 0.2914 LossAtt 0.5746 TrainAcc 0.8900 TestAcc 0.8328 0.8350
epoch 1900 LossPred 0.2452 LossAtt 0.5699 TrainAcc 0.9100 TestAcc 0.8321 0.8350
epoch 2000 LossPred 0.2645 LossAtt 0.5554 TrainAcc 0.9200 TestAcc 0.8248 0.8450
epoch 2100 LossPred 0.2904 LossAtt 0.5234 TrainAcc 0.8900 TestAcc 0.8471 0.8650
epoch 2200 LossPred 0.2949 LossAtt 0.5461 TrainAcc 0.9000 TestAcc 0.8586 0.8550
epoch 2300 LossPred 0.2190 LossAtt 0.5090 TrainAcc 0.9200 TestAcc 0.8496 0.8700
epoch 2400 LossPred 0.2447 LossAtt 0.5392 TrainAcc 0.9200 TestAcc 0.8589 0.8600
epoch 2500 LossPred 0.2642 LossAtt 0.5269 TrainAcc 0.8800 TestAcc 0.8408 0.8700
Optimization Finished!
********** replication  88  **********
epoch   0 LossPred 1.1446 LossAtt 1.0117 TrainAcc 0.5100 TestAcc 0.4272 0.4900
epoch 100 LossPred 0.9525 LossAtt 0.4661 TrainAcc 0.5700 TestAcc 0.4910 0.5600
epoch 200 LossPred 0.9247 LossAtt 0.4420 TrainAcc 0.5700 TestAcc 0.4910 0.5700
epoch 300 LossPred 0.9018 LossAtt 0.4393 TrainAcc 0.5800 TestAcc 0.5090 0.5850
epoch 400 LossPred 0.4638 LossAtt 0.3934 TrainAcc 0.8600 TestAcc 0.7442 0.8100
epoch 500 LossPred 0.4193 LossAtt 0.3551 TrainAcc 0.8700 TestAcc 0.7523 0.8100
epoch 600 LossPred 0.4558 LossAtt 0.3134 TrainAcc 0.8600 TestAcc 0.7382 0.8600
epoch 700 LossPred 0.3786 LossAtt 0.3081 TrainAcc 0.9000 TestAcc 0.7838 0.8650
epoch 800 LossPred 0.3709 LossAtt 0.2985 TrainAcc 0.9100 TestAcc 0.7788 0.8700
epoch 900 LossPred 0.3718 LossAtt 0.3126 TrainAcc 0.8800 TestAcc 0.7743 0.8650
epoch 1000 LossPred 0.3581 LossAtt 0.3101 TrainAcc 0.9100 TestAcc 0.7875 0.8700
epoch 1100 LossPred 0.3373 LossAtt 0.2777 TrainAcc 0.9000 TestAcc 0.8138 0.8800
epoch 1200 LossPred 0.3208 LossAtt 0.2864 TrainAcc 0.9100 TestAcc 0.8211 0.8750
epoch 1300 LossPred 0.3497 LossAtt 0.3030 TrainAcc 0.9000 TestAcc 0.7870 0.8900
epoch 1400 LossPred 0.3113 LossAtt 0.2950 TrainAcc 0.9100 TestAcc 0.8201 0.8850
epoch 1500 LossPred 0.3613 LossAtt 0.2915 TrainAcc 0.8900 TestAcc 0.8463 0.8850
epoch 1600 LossPred 0.3143 LossAtt 0.3039 TrainAcc 0.9100 TestAcc 0.8268 0.8850
epoch 1700 LossPred 0.3126 LossAtt 0.2794 TrainAcc 0.9000 TestAcc 0.8278 0.8800
epoch 1800 LossPred 0.3122 LossAtt 0.2928 TrainAcc 0.9000 TestAcc 0.8203 0.8700
epoch 1900 LossPred 0.3285 LossAtt 0.3146 TrainAcc 0.9100 TestAcc 0.8378 0.8750
epoch 2000 LossPred 0.3116 LossAtt 0.3060 TrainAcc 0.9200 TestAcc 0.8361 0.8850
epoch 2100 LossPred 0.3411 LossAtt 0.3194 TrainAcc 0.9000 TestAcc 0.8308 0.8700
epoch 2200 LossPred 0.2998 LossAtt 0.3193 TrainAcc 0.9100 TestAcc 0.8251 0.8800
epoch 2300 LossPred 0.3073 LossAtt 0.3001 TrainAcc 0.9100 TestAcc 0.8306 0.8850
epoch 2400 LossPred 0.4028 LossAtt 0.3025 TrainAcc 0.8700 TestAcc 0.8336 0.8450
epoch 2500 LossPred 0.3064 LossAtt 0.3181 TrainAcc 0.9100 TestAcc 0.8308 0.8800
Optimization Finished!
********** replication  89  **********
epoch   0 LossPred 0.9658 LossAtt 0.9972 TrainAcc 0.5700 TestAcc 0.5741 0.5650
epoch 100 LossPred 0.8040 LossAtt 0.5141 TrainAcc 0.7200 TestAcc 0.6329 0.7150
epoch 200 LossPred 0.6644 LossAtt 0.5303 TrainAcc 0.7500 TestAcc 0.6909 0.7500
epoch 300 LossPred 0.5323 LossAtt 0.4775 TrainAcc 0.8300 TestAcc 0.7938 0.8200
epoch 400 LossPred 0.3596 LossAtt 0.4252 TrainAcc 0.9300 TestAcc 0.8634 0.9300
epoch 500 LossPred 0.5780 LossAtt 0.4315 TrainAcc 0.7500 TestAcc 0.7600 0.7850
epoch 600 LossPred 0.3035 LossAtt 0.4298 TrainAcc 0.9400 TestAcc 0.8554 0.9400
epoch 700 LossPred 0.3814 LossAtt 0.4306 TrainAcc 0.8500 TestAcc 0.8431 0.8600
epoch 800 LossPred 0.6434 LossAtt 0.4165 TrainAcc 0.7400 TestAcc 0.7045 0.7550
epoch 900 LossPred 0.7041 LossAtt 0.4072 TrainAcc 0.7000 TestAcc 0.7012 0.7050
epoch 1000 LossPred 0.8179 LossAtt 0.4050 TrainAcc 0.6700 TestAcc 0.6489 0.6700
epoch 1100 LossPred 0.5291 LossAtt 0.3763 TrainAcc 0.7900 TestAcc 0.7603 0.8000
epoch 1200 LossPred 0.5618 LossAtt 0.3622 TrainAcc 0.7600 TestAcc 0.7553 0.7650
epoch 1300 LossPred 0.5282 LossAtt 0.3421 TrainAcc 0.8000 TestAcc 0.7560 0.8050
epoch 1400 LossPred 0.2973 LossAtt 0.3533 TrainAcc 0.9300 TestAcc 0.8413 0.9250
epoch 1500 LossPred 0.3095 LossAtt 0.3571 TrainAcc 0.9200 TestAcc 0.8431 0.9200
epoch 1600 LossPred 0.2978 LossAtt 0.3407 TrainAcc 0.9200 TestAcc 0.8343 0.9150
epoch 1700 LossPred 0.3329 LossAtt 0.3618 TrainAcc 0.8600 TestAcc 0.8463 0.8750
epoch 1800 LossPred 0.2494 LossAtt 0.3532 TrainAcc 0.9500 TestAcc 0.8466 0.9350
epoch 1900 LossPred 0.3466 LossAtt 0.3396 TrainAcc 0.8800 TestAcc 0.8038 0.8950
epoch 2000 LossPred 0.2812 LossAtt 0.3461 TrainAcc 0.9200 TestAcc 0.8551 0.9200
epoch 2100 LossPred 0.3555 LossAtt 0.3481 TrainAcc 0.8700 TestAcc 0.7945 0.8750
epoch 2200 LossPred 0.2710 LossAtt 0.3301 TrainAcc 0.9100 TestAcc 0.8323 0.9250
epoch 2300 LossPred 0.3593 LossAtt 0.3477 TrainAcc 0.9000 TestAcc 0.8061 0.8900
epoch 2400 LossPred 0.6512 LossAtt 0.3382 TrainAcc 0.7100 TestAcc 0.7060 0.7250
epoch 2500 LossPred 0.5302 LossAtt 0.3535 TrainAcc 0.8100 TestAcc 0.7420 0.8150
Optimization Finished!
********** replication  90  **********
epoch   0 LossPred 1.2728 LossAtt 1.0034 TrainAcc 0.4500 TestAcc 0.4892 0.4550
epoch 100 LossPred 0.9729 LossAtt 0.2450 TrainAcc 0.6100 TestAcc 0.5751 0.6100
epoch 200 LossPred 0.8762 LossAtt 0.3513 TrainAcc 0.6100 TestAcc 0.5751 0.6100
epoch 300 LossPred 0.7989 LossAtt 0.4046 TrainAcc 0.7400 TestAcc 0.6389 0.7150
epoch 400 LossPred 0.4856 LossAtt 0.3779 TrainAcc 0.8500 TestAcc 0.8511 0.8150
epoch 500 LossPred 0.4145 LossAtt 0.3629 TrainAcc 0.8700 TestAcc 0.8541 0.8350
epoch 600 LossPred 0.3581 LossAtt 0.3869 TrainAcc 0.8900 TestAcc 0.8684 0.8800
epoch 700 LossPred 0.3602 LossAtt 0.3957 TrainAcc 0.8800 TestAcc 0.8629 0.8900
epoch 800 LossPred 0.2642 LossAtt 0.4066 TrainAcc 0.9300 TestAcc 0.8819 0.8800
epoch 900 LossPred 0.2117 LossAtt 0.4238 TrainAcc 0.9400 TestAcc 0.8936 0.9050
epoch 1000 LossPred 0.2191 LossAtt 0.4241 TrainAcc 0.9300 TestAcc 0.8754 0.8700
epoch 1100 LossPred 0.1472 LossAtt 0.4185 TrainAcc 0.9600 TestAcc 0.8991 0.9100
epoch 1200 LossPred 0.1302 LossAtt 0.4183 TrainAcc 0.9600 TestAcc 0.8966 0.9250
epoch 1300 LossPred 0.2385 LossAtt 0.4170 TrainAcc 0.9400 TestAcc 0.8594 0.9350
epoch 1400 LossPred 0.1502 LossAtt 0.4229 TrainAcc 0.9700 TestAcc 0.8874 0.9400
epoch 1500 LossPred 0.2087 LossAtt 0.4051 TrainAcc 0.9400 TestAcc 0.8516 0.9250
epoch 1600 LossPred 0.1969 LossAtt 0.4396 TrainAcc 0.9500 TestAcc 0.8696 0.9350
epoch 1700 LossPred 0.1265 LossAtt 0.4224 TrainAcc 0.9600 TestAcc 0.8851 0.9200
epoch 1800 LossPred 0.2149 LossAtt 0.3985 TrainAcc 0.9400 TestAcc 0.8541 0.9150
epoch 1900 LossPred 0.1299 LossAtt 0.3904 TrainAcc 0.9700 TestAcc 0.8889 0.9300
epoch 2000 LossPred 0.1141 LossAtt 0.4019 TrainAcc 0.9700 TestAcc 0.8941 0.9300
epoch 2100 LossPred 0.1736 LossAtt 0.4110 TrainAcc 0.9400 TestAcc 0.8849 0.9050
epoch 2200 LossPred 0.1453 LossAtt 0.3720 TrainAcc 0.9500 TestAcc 0.8884 0.9150
epoch 2300 LossPred 0.1566 LossAtt 0.3814 TrainAcc 0.9400 TestAcc 0.8816 0.9300
epoch 2400 LossPred 0.1565 LossAtt 0.3953 TrainAcc 0.9500 TestAcc 0.8854 0.9100
epoch 2500 LossPred 0.1365 LossAtt 0.3760 TrainAcc 0.9600 TestAcc 0.8851 0.9450
Optimization Finished!
********** replication  91  **********
epoch   0 LossPred 0.9453 LossAtt 0.9866 TrainAcc 0.5300 TestAcc 0.5638 0.5400
epoch 100 LossPred 0.8564 LossAtt 0.4080 TrainAcc 0.6700 TestAcc 0.6286 0.6550
epoch 200 LossPred 0.8535 LossAtt 0.3296 TrainAcc 0.6700 TestAcc 0.6286 0.6600
epoch 300 LossPred 0.8214 LossAtt 0.3413 TrainAcc 0.6800 TestAcc 0.6431 0.6800
epoch 400 LossPred 0.4021 LossAtt 0.3535 TrainAcc 0.8500 TestAcc 0.8433 0.8400
epoch 500 LossPred 0.3834 LossAtt 0.3261 TrainAcc 0.8400 TestAcc 0.8501 0.8500
epoch 600 LossPred 0.3976 LossAtt 0.3115 TrainAcc 0.8400 TestAcc 0.8468 0.8500
epoch 700 LossPred 0.3735 LossAtt 0.3162 TrainAcc 0.8800 TestAcc 0.8268 0.8300
epoch 800 LossPred 0.4915 LossAtt 0.2805 TrainAcc 0.8100 TestAcc 0.7900 0.8200
epoch 900 LossPred 0.4053 LossAtt 0.3171 TrainAcc 0.8700 TestAcc 0.8426 0.8650
epoch 1000 LossPred 0.4206 LossAtt 0.3376 TrainAcc 0.8700 TestAcc 0.8421 0.8450
epoch 1100 LossPred 0.5067 LossAtt 0.2555 TrainAcc 0.8100 TestAcc 0.7670 0.8050
epoch 1200 LossPred 0.5810 LossAtt 0.3029 TrainAcc 0.7900 TestAcc 0.8176 0.7850
epoch 1300 LossPred 0.3740 LossAtt 0.3047 TrainAcc 0.8800 TestAcc 0.8451 0.8400
epoch 1400 LossPred 0.4562 LossAtt 0.2990 TrainAcc 0.8200 TestAcc 0.7928 0.8100
epoch 1500 LossPred 0.3789 LossAtt 0.2986 TrainAcc 0.8600 TestAcc 0.8201 0.8300
epoch 1600 LossPred 0.4142 LossAtt 0.3375 TrainAcc 0.8300 TestAcc 0.8223 0.8450
epoch 1700 LossPred 0.3823 LossAtt 0.3056 TrainAcc 0.8700 TestAcc 0.8321 0.8450
epoch 1800 LossPred 0.4905 LossAtt 0.2801 TrainAcc 0.8300 TestAcc 0.7895 0.8200
epoch 1900 LossPred 0.4902 LossAtt 0.2628 TrainAcc 0.8200 TestAcc 0.7880 0.8100
epoch 2000 LossPred 1.1080 LossAtt 0.2683 TrainAcc 0.6500 TestAcc 0.6759 0.6650
epoch 2100 LossPred 0.5547 LossAtt 0.2775 TrainAcc 0.8200 TestAcc 0.7720 0.7950
epoch 2200 LossPred 0.5274 LossAtt 0.2693 TrainAcc 0.8100 TestAcc 0.7578 0.7800
epoch 2300 LossPred 0.5675 LossAtt 0.2505 TrainAcc 0.7800 TestAcc 0.7300 0.7750
epoch 2400 LossPred 0.5582 LossAtt 0.2473 TrainAcc 0.7800 TestAcc 0.7297 0.7700
epoch 2500 LossPred 0.5102 LossAtt 0.2973 TrainAcc 0.8300 TestAcc 0.7895 0.8000
Optimization Finished!
********** replication  92  **********
epoch   0 LossPred 1.3237 LossAtt 1.0014 TrainAcc 0.4500 TestAcc 0.4645 0.4400
epoch 100 LossPred 1.0210 LossAtt 0.4502 TrainAcc 0.5300 TestAcc 0.5398 0.5250
epoch 200 LossPred 0.9460 LossAtt 0.3460 TrainAcc 0.6800 TestAcc 0.6266 0.6350
epoch 300 LossPred 0.8753 LossAtt 0.4110 TrainAcc 0.7300 TestAcc 0.6724 0.7050
epoch 400 LossPred 0.5249 LossAtt 0.4703 TrainAcc 0.8500 TestAcc 0.7895 0.8450
epoch 500 LossPred 0.3661 LossAtt 0.4499 TrainAcc 0.9200 TestAcc 0.8173 0.8900
epoch 600 LossPred 0.4372 LossAtt 0.4334 TrainAcc 0.8800 TestAcc 0.7635 0.8450
epoch 700 LossPred 0.3517 LossAtt 0.4264 TrainAcc 0.9100 TestAcc 0.8346 0.8800
epoch 800 LossPred 0.3163 LossAtt 0.4448 TrainAcc 0.9100 TestAcc 0.8363 0.8800
epoch 900 LossPred 0.2603 LossAtt 0.4064 TrainAcc 0.9200 TestAcc 0.8433 0.9200
epoch 1000 LossPred 0.3378 LossAtt 0.4233 TrainAcc 0.9000 TestAcc 0.8323 0.8750
epoch 1100 LossPred 0.2572 LossAtt 0.3983 TrainAcc 0.9300 TestAcc 0.8466 0.9150
epoch 1200 LossPred 0.2565 LossAtt 0.4067 TrainAcc 0.9300 TestAcc 0.8208 0.9000
epoch 1300 LossPred 0.2113 LossAtt 0.3936 TrainAcc 0.9400 TestAcc 0.8348 0.9150
epoch 1400 LossPred 0.2155 LossAtt 0.4015 TrainAcc 0.9300 TestAcc 0.8258 0.9100
epoch 1500 LossPred 0.4006 LossAtt 0.4100 TrainAcc 0.8700 TestAcc 0.7588 0.8300
epoch 1600 LossPred 0.2406 LossAtt 0.4027 TrainAcc 0.9200 TestAcc 0.8408 0.9100
epoch 1700 LossPred 0.2085 LossAtt 0.4045 TrainAcc 0.9400 TestAcc 0.8383 0.9000
epoch 1800 LossPred 0.1827 LossAtt 0.3905 TrainAcc 0.9500 TestAcc 0.8328 0.9200
epoch 1900 LossPred 0.2513 LossAtt 0.4243 TrainAcc 0.9200 TestAcc 0.8148 0.9000
epoch 2000 LossPred 0.2005 LossAtt 0.4005 TrainAcc 0.9300 TestAcc 0.8298 0.9100
epoch 2100 LossPred 0.2053 LossAtt 0.4027 TrainAcc 0.9400 TestAcc 0.8196 0.9100
epoch 2200 LossPred 0.1686 LossAtt 0.3977 TrainAcc 0.9500 TestAcc 0.8316 0.9400
epoch 2300 LossPred 0.2028 LossAtt 0.3986 TrainAcc 0.9300 TestAcc 0.8176 0.9100
epoch 2400 LossPred 0.1704 LossAtt 0.4146 TrainAcc 0.9500 TestAcc 0.8201 0.9200
epoch 2500 LossPred 0.1633 LossAtt 0.4157 TrainAcc 0.9600 TestAcc 0.8271 0.9150
Optimization Finished!
********** replication  93  **********
epoch   0 LossPred 1.0672 LossAtt 1.0290 TrainAcc 0.5700 TestAcc 0.5078 0.5800
epoch 100 LossPred 0.8110 LossAtt 0.2970 TrainAcc 0.6800 TestAcc 0.5946 0.6600
epoch 200 LossPred 0.7820 LossAtt 0.2018 TrainAcc 0.6800 TestAcc 0.5946 0.6700
epoch 300 LossPred 0.7453 LossAtt 0.3145 TrainAcc 0.7400 TestAcc 0.6269 0.7500
epoch 400 LossPred 0.4605 LossAtt 0.3847 TrainAcc 0.8600 TestAcc 0.8148 0.8450
epoch 500 LossPred 0.3993 LossAtt 0.3478 TrainAcc 0.8900 TestAcc 0.8421 0.8750
epoch 600 LossPred 0.3717 LossAtt 0.3444 TrainAcc 0.8400 TestAcc 0.8589 0.8550
epoch 700 LossPred 0.3554 LossAtt 0.3511 TrainAcc 0.8500 TestAcc 0.8684 0.8800
epoch 800 LossPred 0.3850 LossAtt 0.3486 TrainAcc 0.8400 TestAcc 0.8428 0.8500
epoch 900 LossPred 0.3136 LossAtt 0.3555 TrainAcc 0.8600 TestAcc 0.8654 0.8550
epoch 1000 LossPred 0.3178 LossAtt 0.3430 TrainAcc 0.8500 TestAcc 0.8579 0.8800
epoch 1100 LossPred 0.4159 LossAtt 0.3360 TrainAcc 0.8500 TestAcc 0.8363 0.8500
epoch 1200 LossPred 0.2975 LossAtt 0.3382 TrainAcc 0.9100 TestAcc 0.8749 0.8700
epoch 1300 LossPred 0.3338 LossAtt 0.3425 TrainAcc 0.8600 TestAcc 0.8606 0.8700
epoch 1400 LossPred 0.2826 LossAtt 0.3211 TrainAcc 0.8900 TestAcc 0.8731 0.8800
epoch 1500 LossPred 0.2918 LossAtt 0.3299 TrainAcc 0.8800 TestAcc 0.8701 0.8950
epoch 1600 LossPred 0.2734 LossAtt 0.3281 TrainAcc 0.9100 TestAcc 0.8724 0.8800
epoch 1700 LossPred 0.2630 LossAtt 0.3237 TrainAcc 0.9000 TestAcc 0.8799 0.8800
epoch 1800 LossPred 0.2650 LossAtt 0.3209 TrainAcc 0.8800 TestAcc 0.8776 0.8900
epoch 1900 LossPred 0.3658 LossAtt 0.3122 TrainAcc 0.8800 TestAcc 0.8661 0.8750
epoch 2000 LossPred 0.3808 LossAtt 0.3217 TrainAcc 0.8400 TestAcc 0.8398 0.8500
epoch 2100 LossPred 0.2807 LossAtt 0.2993 TrainAcc 0.8700 TestAcc 0.8776 0.8800
epoch 2200 LossPred 0.3049 LossAtt 0.2912 TrainAcc 0.8900 TestAcc 0.8819 0.8750
epoch 2300 LossPred 0.2434 LossAtt 0.2940 TrainAcc 0.9100 TestAcc 0.8864 0.9050
epoch 2400 LossPred 0.2620 LossAtt 0.2845 TrainAcc 0.9000 TestAcc 0.8886 0.8900
epoch 2500 LossPred 0.2875 LossAtt 0.2933 TrainAcc 0.8900 TestAcc 0.8774 0.8650
Optimization Finished!
********** replication  94  **********
epoch   0 LossPred 1.1338 LossAtt 0.9833 TrainAcc 0.3500 TestAcc 0.4049 0.3600
epoch 100 LossPred 0.9379 LossAtt 0.4077 TrainAcc 0.6500 TestAcc 0.5838 0.6500
epoch 200 LossPred 0.8697 LossAtt 0.3975 TrainAcc 0.6500 TestAcc 0.5838 0.6450
epoch 300 LossPred 0.8259 LossAtt 0.3463 TrainAcc 0.6800 TestAcc 0.6414 0.6750
epoch 400 LossPred 0.7942 LossAtt 0.3386 TrainAcc 0.7000 TestAcc 0.6554 0.6950
epoch 500 LossPred 0.5519 LossAtt 0.4235 TrainAcc 0.7800 TestAcc 0.8056 0.8000
epoch 600 LossPred 0.4592 LossAtt 0.4584 TrainAcc 0.8500 TestAcc 0.8571 0.8600
epoch 700 LossPred 0.4270 LossAtt 0.4296 TrainAcc 0.8700 TestAcc 0.8556 0.8800
epoch 800 LossPred 0.4016 LossAtt 0.4339 TrainAcc 0.8400 TestAcc 0.7633 0.8150
epoch 900 LossPred 0.4196 LossAtt 0.4381 TrainAcc 0.8500 TestAcc 0.8591 0.8400
epoch 1000 LossPred 0.3767 LossAtt 0.4210 TrainAcc 0.8800 TestAcc 0.8136 0.8500
epoch 1100 LossPred 0.3301 LossAtt 0.4173 TrainAcc 0.9000 TestAcc 0.8734 0.8800
epoch 1200 LossPred 0.3682 LossAtt 0.4075 TrainAcc 0.8600 TestAcc 0.7663 0.8300
epoch 1300 LossPred 0.3990 LossAtt 0.3809 TrainAcc 0.8400 TestAcc 0.7660 0.8300
epoch 1400 LossPred 0.5852 LossAtt 0.3888 TrainAcc 0.7300 TestAcc 0.7087 0.7750
epoch 1500 LossPred 0.2974 LossAtt 0.3942 TrainAcc 0.8800 TestAcc 0.8188 0.8650
epoch 1600 LossPred 0.2780 LossAtt 0.3925 TrainAcc 0.9200 TestAcc 0.8699 0.8900
epoch 1700 LossPred 0.4425 LossAtt 0.4036 TrainAcc 0.8300 TestAcc 0.7738 0.8350
epoch 1800 LossPred 0.2409 LossAtt 0.4079 TrainAcc 0.9400 TestAcc 0.8554 0.8800
epoch 1900 LossPred 0.5494 LossAtt 0.3924 TrainAcc 0.8500 TestAcc 0.8181 0.8350
epoch 2000 LossPred 0.3224 LossAtt 0.3617 TrainAcc 0.8800 TestAcc 0.8293 0.8650
epoch 2100 LossPred 0.2659 LossAtt 0.3799 TrainAcc 0.9200 TestAcc 0.8594 0.8950
epoch 2200 LossPred 0.3127 LossAtt 0.3822 TrainAcc 0.9100 TestAcc 0.8504 0.8900
epoch 2300 LossPred 0.3735 LossAtt 0.3746 TrainAcc 0.8900 TestAcc 0.8549 0.8750
epoch 2400 LossPred 0.3355 LossAtt 0.3847 TrainAcc 0.8700 TestAcc 0.8203 0.8500
epoch 2500 LossPred 0.3510 LossAtt 0.3770 TrainAcc 0.9000 TestAcc 0.8629 0.8850
Optimization Finished!
********** replication  95  **********
epoch   0 LossPred 1.1572 LossAtt 0.9877 TrainAcc 0.4800 TestAcc 0.4755 0.4700
epoch 100 LossPred 0.9062 LossAtt 0.3471 TrainAcc 0.6200 TestAcc 0.5896 0.6200
epoch 200 LossPred 0.8706 LossAtt 0.3058 TrainAcc 0.6200 TestAcc 0.5896 0.6200
epoch 300 LossPred 0.7568 LossAtt 0.4544 TrainAcc 0.7200 TestAcc 0.6629 0.7300
epoch 400 LossPred 0.3665 LossAtt 0.4281 TrainAcc 0.9100 TestAcc 0.8293 0.8900
epoch 500 LossPred 0.3588 LossAtt 0.4151 TrainAcc 0.9000 TestAcc 0.8644 0.8500
epoch 600 LossPred 0.4059 LossAtt 0.3863 TrainAcc 0.8600 TestAcc 0.8594 0.8350
epoch 700 LossPred 0.3312 LossAtt 0.3703 TrainAcc 0.8900 TestAcc 0.8744 0.8600
epoch 800 LossPred 0.3394 LossAtt 0.3650 TrainAcc 0.8800 TestAcc 0.8448 0.8500
epoch 900 LossPred 0.3111 LossAtt 0.3814 TrainAcc 0.8900 TestAcc 0.8501 0.8600
epoch 1000 LossPred 0.3020 LossAtt 0.3587 TrainAcc 0.9200 TestAcc 0.8408 0.8800
epoch 1100 LossPred 0.3100 LossAtt 0.3667 TrainAcc 0.8900 TestAcc 0.8739 0.8600
epoch 1200 LossPred 0.3585 LossAtt 0.3474 TrainAcc 0.8700 TestAcc 0.7840 0.8700
epoch 1300 LossPred 0.2990 LossAtt 0.3511 TrainAcc 0.8900 TestAcc 0.8701 0.8700
epoch 1400 LossPred 0.3113 LossAtt 0.3407 TrainAcc 0.8700 TestAcc 0.8746 0.8600
epoch 1500 LossPred 0.3274 LossAtt 0.3341 TrainAcc 0.8700 TestAcc 0.8651 0.8550
epoch 1600 LossPred 0.3232 LossAtt 0.3182 TrainAcc 0.8700 TestAcc 0.8561 0.8550
epoch 1700 LossPred 0.5457 LossAtt 0.3076 TrainAcc 0.8200 TestAcc 0.7145 0.8250
epoch 1800 LossPred 0.3558 LossAtt 0.3279 TrainAcc 0.8900 TestAcc 0.7818 0.8750
epoch 1900 LossPred 0.4591 LossAtt 0.3395 TrainAcc 0.8400 TestAcc 0.8393 0.8250
epoch 2000 LossPred 0.3689 LossAtt 0.3213 TrainAcc 0.8600 TestAcc 0.7758 0.8700
epoch 2100 LossPred 0.3637 LossAtt 0.3149 TrainAcc 0.8800 TestAcc 0.8243 0.8500
epoch 2200 LossPred 0.3708 LossAtt 0.3002 TrainAcc 0.8800 TestAcc 0.7763 0.8650
epoch 2300 LossPred 0.3679 LossAtt 0.3321 TrainAcc 0.8700 TestAcc 0.8146 0.8700
epoch 2400 LossPred 0.3161 LossAtt 0.3402 TrainAcc 0.8900 TestAcc 0.8106 0.8850
epoch 2500 LossPred 0.3363 LossAtt 0.3602 TrainAcc 0.8900 TestAcc 0.8143 0.8650
Optimization Finished!
********** replication  96  **********
epoch   0 LossPred 1.0978 LossAtt 0.9981 TrainAcc 0.4800 TestAcc 0.4182 0.4800
epoch 100 LossPred 0.9235 LossAtt 0.5266 TrainAcc 0.6500 TestAcc 0.5425 0.6500
epoch 200 LossPred 0.8705 LossAtt 0.5305 TrainAcc 0.6500 TestAcc 0.5425 0.6650
epoch 300 LossPred 0.8334 LossAtt 0.5770 TrainAcc 0.6800 TestAcc 0.5508 0.6750
epoch 400 LossPred 0.8101 LossAtt 0.5802 TrainAcc 0.6900 TestAcc 0.5613 0.6850
epoch 500 LossPred 0.5879 LossAtt 0.5932 TrainAcc 0.8000 TestAcc 0.7533 0.7750
epoch 600 LossPred 0.4659 LossAtt 0.6810 TrainAcc 0.8500 TestAcc 0.7985 0.8300
epoch 700 LossPred 0.3085 LossAtt 0.6414 TrainAcc 0.9100 TestAcc 0.8386 0.8800
epoch 800 LossPred 0.2394 LossAtt 0.5493 TrainAcc 0.9300 TestAcc 0.8699 0.9250
epoch 900 LossPred 0.3087 LossAtt 0.5739 TrainAcc 0.9200 TestAcc 0.8521 0.8950
epoch 1000 LossPred 0.1434 LossAtt 0.5390 TrainAcc 0.9400 TestAcc 0.8731 0.9300
epoch 1100 LossPred 0.1353 LossAtt 0.5661 TrainAcc 0.9600 TestAcc 0.8781 0.9600
epoch 1200 LossPred 0.2294 LossAtt 0.5929 TrainAcc 0.9400 TestAcc 0.8729 0.9200
epoch 1300 LossPred 0.1479 LossAtt 0.5918 TrainAcc 0.9700 TestAcc 0.8851 0.9500
epoch 1400 LossPred 0.4025 LossAtt 0.6504 TrainAcc 0.8500 TestAcc 0.7735 0.8400
epoch 1500 LossPred 0.1331 LossAtt 0.5878 TrainAcc 0.9600 TestAcc 0.8311 0.9550
epoch 1600 LossPred 0.0969 LossAtt 0.6069 TrainAcc 0.9700 TestAcc 0.8714 0.9650
epoch 1700 LossPred 0.0978 LossAtt 0.6184 TrainAcc 0.9600 TestAcc 0.8804 0.9650
epoch 1800 LossPred 0.0891 LossAtt 0.5949 TrainAcc 0.9700 TestAcc 0.8634 0.9650
epoch 1900 LossPred 0.1186 LossAtt 0.5950 TrainAcc 0.9600 TestAcc 0.8253 0.9400
epoch 2000 LossPred 0.0828 LossAtt 0.5820 TrainAcc 0.9700 TestAcc 0.8721 0.9650
epoch 2100 LossPred 0.4245 LossAtt 0.5628 TrainAcc 0.8800 TestAcc 0.7923 0.8650
epoch 2200 LossPred 0.4223 LossAtt 0.5789 TrainAcc 0.8900 TestAcc 0.7858 0.8650
epoch 2300 LossPred 0.1716 LossAtt 0.5891 TrainAcc 0.9400 TestAcc 0.8196 0.9450
epoch 2400 LossPred 0.0965 LossAtt 0.5950 TrainAcc 0.9600 TestAcc 0.8441 0.9550
epoch 2500 LossPred 0.2633 LossAtt 0.5964 TrainAcc 0.9000 TestAcc 0.8639 0.9100
Optimization Finished!
********** replication  97  **********
epoch   0 LossPred 1.0273 LossAtt 0.9957 TrainAcc 0.5300 TestAcc 0.5065 0.5350
epoch 100 LossPred 0.9628 LossAtt 0.3732 TrainAcc 0.5900 TestAcc 0.5898 0.5900
epoch 200 LossPred 0.9534 LossAtt 0.3424 TrainAcc 0.5800 TestAcc 0.5898 0.5800
epoch 300 LossPred 0.9512 LossAtt 0.3664 TrainAcc 0.6100 TestAcc 0.5711 0.6050
epoch 400 LossPred 0.9490 LossAtt 0.3741 TrainAcc 0.6100 TestAcc 0.5711 0.6050
epoch 500 LossPred 0.9416 LossAtt 0.3183 TrainAcc 0.6100 TestAcc 0.5711 0.6100
epoch 600 LossPred 0.9279 LossAtt 0.2954 TrainAcc 0.6100 TestAcc 0.5711 0.6250
epoch 700 LossPred 0.9160 LossAtt 0.2581 TrainAcc 0.6200 TestAcc 0.5761 0.6050
epoch 800 LossPred 0.9109 LossAtt 0.3889 TrainAcc 0.6200 TestAcc 0.5823 0.6100
epoch 900 LossPred 0.8891 LossAtt 0.4450 TrainAcc 0.7000 TestAcc 0.5683 0.6550
epoch 1000 LossPred 0.8239 LossAtt 0.4025 TrainAcc 0.6900 TestAcc 0.5435 0.6800
epoch 1100 LossPred 0.7912 LossAtt 0.3760 TrainAcc 0.6900 TestAcc 0.5120 0.6750
epoch 1200 LossPred 0.7712 LossAtt 0.3848 TrainAcc 0.7000 TestAcc 0.4937 0.6600
epoch 1300 LossPred 0.7515 LossAtt 0.4254 TrainAcc 0.7000 TestAcc 0.5133 0.6850
epoch 1400 LossPred 0.7457 LossAtt 0.4211 TrainAcc 0.7000 TestAcc 0.5178 0.7050
epoch 1500 LossPred 0.7429 LossAtt 0.4477 TrainAcc 0.7200 TestAcc 0.5183 0.6850
epoch 1600 LossPred 0.7832 LossAtt 0.4860 TrainAcc 0.7200 TestAcc 0.5243 0.6600
epoch 1700 LossPred 0.7532 LossAtt 0.4783 TrainAcc 0.7400 TestAcc 0.5080 0.6800
epoch 1800 LossPred 0.7325 LossAtt 0.4709 TrainAcc 0.7500 TestAcc 0.5185 0.6750
epoch 1900 LossPred 0.7122 LossAtt 0.4536 TrainAcc 0.7300 TestAcc 0.5168 0.6750
epoch 2000 LossPred 0.7001 LossAtt 0.4481 TrainAcc 0.7600 TestAcc 0.5295 0.6900
epoch 2100 LossPred 0.6944 LossAtt 0.4316 TrainAcc 0.7800 TestAcc 0.5460 0.6900
epoch 2200 LossPred 0.6859 LossAtt 0.4454 TrainAcc 0.7700 TestAcc 0.5393 0.6950
epoch 2300 LossPred 0.6987 LossAtt 0.4684 TrainAcc 0.7700 TestAcc 0.5340 0.6800
epoch 2400 LossPred 0.6894 LossAtt 0.4162 TrainAcc 0.7800 TestAcc 0.5511 0.6850
epoch 2500 LossPred 0.6860 LossAtt 0.4227 TrainAcc 0.7400 TestAcc 0.5455 0.6950
Optimization Finished!
********** replication  98  **********
epoch   0 LossPred 1.2570 LossAtt 1.0025 TrainAcc 0.3700 TestAcc 0.4505 0.4000
epoch 100 LossPred 0.9312 LossAtt 0.4187 TrainAcc 0.6600 TestAcc 0.5948 0.6600
epoch 200 LossPred 0.8935 LossAtt 0.3864 TrainAcc 0.6600 TestAcc 0.5948 0.6600
epoch 300 LossPred 0.8808 LossAtt 0.3122 TrainAcc 0.6600 TestAcc 0.5948 0.6600
epoch 400 LossPred 0.8738 LossAtt 0.2901 TrainAcc 0.6600 TestAcc 0.5948 0.6600
epoch 500 LossPred 0.8643 LossAtt 0.2948 TrainAcc 0.6600 TestAcc 0.5948 0.6600
epoch 600 LossPred 0.7693 LossAtt 0.3215 TrainAcc 0.7200 TestAcc 0.6917 0.7250
epoch 700 LossPred 0.5766 LossAtt 0.2253 TrainAcc 0.7900 TestAcc 0.8118 0.7700
epoch 800 LossPred 0.8637 LossAtt 0.2423 TrainAcc 0.6800 TestAcc 0.6714 0.6750
epoch 900 LossPred 0.8888 LossAtt 0.2439 TrainAcc 0.6300 TestAcc 0.6607 0.6600
epoch 1000 LossPred 0.9048 LossAtt 0.2126 TrainAcc 0.6600 TestAcc 0.5966 0.6650
epoch 1100 LossPred 0.8804 LossAtt 0.2168 TrainAcc 0.6600 TestAcc 0.5953 0.6600
epoch 1200 LossPred 0.8765 LossAtt 0.2277 TrainAcc 0.6600 TestAcc 0.5961 0.6600
epoch 1300 LossPred 0.8736 LossAtt 0.2253 TrainAcc 0.6600 TestAcc 0.5961 0.6650
epoch 1400 LossPred 0.8713 LossAtt 0.2308 TrainAcc 0.6600 TestAcc 0.5978 0.6650
epoch 1500 LossPred 0.8684 LossAtt 0.2435 TrainAcc 0.6600 TestAcc 0.5983 0.6650
epoch 1600 LossPred 0.8654 LossAtt 0.2397 TrainAcc 0.6600 TestAcc 0.5976 0.6650
epoch 1700 LossPred 0.8627 LossAtt 0.2303 TrainAcc 0.6600 TestAcc 0.5978 0.6650
epoch 1800 LossPred 0.8608 LossAtt 0.2241 TrainAcc 0.6500 TestAcc 0.6141 0.6600
epoch 1900 LossPred 0.8581 LossAtt 0.2323 TrainAcc 0.6400 TestAcc 0.6286 0.6550
epoch 2000 LossPred 0.8559 LossAtt 0.2290 TrainAcc 0.6600 TestAcc 0.6346 0.6550
epoch 2100 LossPred 0.8545 LossAtt 0.2465 TrainAcc 0.6600 TestAcc 0.6354 0.6500
epoch 2200 LossPred 0.8420 LossAtt 0.2533 TrainAcc 0.6700 TestAcc 0.6371 0.6600
epoch 2300 LossPred 0.8203 LossAtt 0.2984 TrainAcc 0.6800 TestAcc 0.6557 0.6650
epoch 2400 LossPred 0.4287 LossAtt 0.3415 TrainAcc 0.8300 TestAcc 0.8514 0.8400
epoch 2500 LossPred 0.4082 LossAtt 0.3548 TrainAcc 0.8400 TestAcc 0.8609 0.8500
Optimization Finished!
********** replication  99  **********
epoch   0 LossPred 1.0829 LossAtt 1.0157 TrainAcc 0.4800 TestAcc 0.4667 0.5050
epoch 100 LossPred 0.9096 LossAtt 0.3016 TrainAcc 0.6600 TestAcc 0.6524 0.6400
epoch 200 LossPred 0.8256 LossAtt 0.3674 TrainAcc 0.7000 TestAcc 0.6862 0.6900
epoch 300 LossPred 0.8250 LossAtt 0.4236 TrainAcc 0.6300 TestAcc 0.6527 0.6550
epoch 400 LossPred 0.5993 LossAtt 0.3652 TrainAcc 0.7800 TestAcc 0.7775 0.7650
epoch 500 LossPred 0.7735 LossAtt 0.4070 TrainAcc 0.6800 TestAcc 0.6777 0.7000
epoch 600 LossPred 0.5618 LossAtt 0.3891 TrainAcc 0.7600 TestAcc 0.7425 0.7600
epoch 700 LossPred 0.4321 LossAtt 0.3786 TrainAcc 0.8800 TestAcc 0.8506 0.8000
epoch 800 LossPred 0.4055 LossAtt 0.3847 TrainAcc 0.8600 TestAcc 0.8356 0.8200
epoch 900 LossPred 0.5043 LossAtt 0.3878 TrainAcc 0.8200 TestAcc 0.8066 0.7750
epoch 1000 LossPred 0.4921 LossAtt 0.3624 TrainAcc 0.8000 TestAcc 0.8383 0.8000
epoch 1100 LossPred 0.6083 LossAtt 0.3374 TrainAcc 0.7900 TestAcc 0.7623 0.7700
epoch 1200 LossPred 0.7073 LossAtt 0.3215 TrainAcc 0.7200 TestAcc 0.7245 0.7450
epoch 1300 LossPred 1.1542 LossAtt 0.3565 TrainAcc 0.5900 TestAcc 0.5733 0.5650
epoch 1400 LossPred 0.8357 LossAtt 0.3277 TrainAcc 0.6900 TestAcc 0.6754 0.6850
epoch 1500 LossPred 0.8421 LossAtt 0.3596 TrainAcc 0.6600 TestAcc 0.6669 0.6450
epoch 1600 LossPred 0.5203 LossAtt 0.3444 TrainAcc 0.8200 TestAcc 0.8231 0.8150
epoch 1700 LossPred 1.1541 LossAtt 0.3339 TrainAcc 0.6000 TestAcc 0.6081 0.5950
epoch 1800 LossPred 0.4100 LossAtt 0.3713 TrainAcc 0.8500 TestAcc 0.8483 0.8500
epoch 1900 LossPred 0.6563 LossAtt 0.3492 TrainAcc 0.7500 TestAcc 0.7357 0.7450
epoch 2000 LossPred 0.5656 LossAtt 0.3589 TrainAcc 0.7900 TestAcc 0.7768 0.7900
epoch 2100 LossPred 0.5779 LossAtt 0.3716 TrainAcc 0.7900 TestAcc 0.7733 0.7950
epoch 2200 LossPred 0.5871 LossAtt 0.3829 TrainAcc 0.8000 TestAcc 0.7928 0.7800
epoch 2300 LossPred 0.4271 LossAtt 0.3540 TrainAcc 0.8400 TestAcc 0.8266 0.8400
epoch 2400 LossPred 0.4339 LossAtt 0.3805 TrainAcc 0.8600 TestAcc 0.8341 0.8600
epoch 2500 LossPred 0.4648 LossAtt 0.3618 TrainAcc 0.8300 TestAcc 0.8193 0.8350
Optimization Finished!
********************************************************************
Namespace(arch='tanh', batch_size=256, display_epoch=100, input_noise_level=0.15, latent_attractor_space=True, loss_switch_frequency=0, lrate_attractor=0.002, lrate_prediction=0.002, lrate_wt_penalty=0.0, n_attractor_hidden=10, n_attractor_steps=5, n_hidden=5, n_replications=100, noise_level=0.5, report_best_train_performance=True, seq_len=20, task='majority', train_attr_weights_on_prediction=False, training_epochs=2500)
********************************************************************
mean train accuracy 0.89109993
indiv runs  [0.93, 0.92, 0.94, 0.9, 0.93, 0.92, 0.97, 0.93, 0.62, 0.95, 0.88, 0.91, 0.95, 0.9, 0.67, 0.91, 0.75, 0.98, 0.79, 0.98, 0.91, 0.94, 0.93, 0.92, 0.95, 0.89, 0.95, 0.92, 0.85, 0.92, 0.85, 0.82, 0.91, 0.96, 0.93, 0.75, 0.94, 0.95, 0.97, 0.94, 0.95, 0.96, 0.9, 0.93, 0.73, 0.95, 0.88, 0.62, 0.94, 0.92, 0.97, 0.91, 0.89, 0.95, 0.79, 0.93, 0.99, 0.99, 0.65, 0.9, 0.94, 0.74, 0.98, 0.88, 0.94, 0.75, 0.91, 0.74, 0.86, 0.67, 0.73, 0.91, 0.92, 0.97, 0.92, 0.95, 0.73, 0.94, 0.79, 0.88, 0.92, 0.91, 0.92, 0.96, 0.89, 0.9, 0.94, 0.92, 0.92, 0.95, 0.97, 0.88, 0.96, 0.91, 0.94, 0.92, 0.97, 0.78, 0.84, 0.88]
mean epoch nan
indiv epochs  []
test1 accuracy mean  0.8188364  median  0.8568569
test2 accuracy mean  0.85675  median  0.88
test1 indiv runs  [0.8901401, 0.8583584, 0.8751251, 0.8488488, 0.9346847, 0.8928929, 0.8828829, 0.8183183, 0.5885886, 0.8681181, 0.8373373, 0.8613614, 0.8468468, 0.8245746, 0.5437938, 0.9051552, 0.5808308, 0.9426927, 0.7262262, 0.8903904, 0.8325826, 0.8651151, 0.8931431, 0.8541041, 0.8738739, 0.8533534, 0.8976476, 0.8225726, 0.8380881, 0.787037, 0.8013013, 0.8606106, 0.8693694, 0.8485986, 0.8686186, 0.6473974, 0.8683684, 0.9181682, 0.9141642, 0.8723724, 0.8450951, 0.8948949, 0.797047, 0.9029029, 0.5923423, 0.9014014, 0.8038038, 0.5447948, 0.8688689, 0.8546046, 0.8646146, 0.775025, 0.8606106, 0.8871371, 0.735986, 0.9004004, 0.8933934, 0.9181682, 0.5855856, 0.8403403, 0.9046547, 0.48723724, 0.9189189, 0.7825325, 0.9241742, 0.6033534, 0.8480981, 0.6251251, 0.8198198, 0.5535536, 0.5528028, 0.8608609, 0.8613614, 0.8996496, 0.8318318, 0.9051552, 0.5560561, 0.8931431, 0.7677678, 0.8623624, 0.8606106, 0.7772773, 0.8833834, 0.8986486, 0.8711211, 0.8150651, 0.8858859, 0.8248248, 0.8360861, 0.8465966, 0.8873874, 0.8268268, 0.8270771, 0.8748749, 0.8553554, 0.8408408, 0.8851351, 0.546046, 0.8608609, 0.8506006]
test2 indiv runs  [0.875, 0.885, 0.875, 0.885, 0.89, 0.89, 0.92, 0.91, 0.62, 0.955, 0.85, 0.91, 0.895, 0.88, 0.64, 0.91, 0.715, 0.945, 0.77, 0.95, 0.865, 0.9, 0.87, 0.915, 0.915, 0.83, 0.885, 0.885, 0.795, 0.84, 0.815, 0.82, 0.86, 0.925, 0.915, 0.745, 0.885, 0.895, 0.965, 0.92, 0.895, 0.89, 0.88, 0.875, 0.675, 0.905, 0.86, 0.59, 0.92, 0.87, 0.915, 0.87, 0.89, 0.915, 0.8, 0.93, 0.98, 0.93, 0.635, 0.875, 0.875, 0.705, 0.975, 0.86, 0.93, 0.695, 0.895, 0.72, 0.855, 0.6, 0.685, 0.9, 0.835, 0.915, 0.865, 0.93, 0.67, 0.87, 0.77, 0.84, 0.9, 0.87, 0.905, 0.955, 0.865, 0.88, 0.925, 0.845, 0.885, 0.935, 0.94, 0.83, 0.915, 0.87, 0.88, 0.88, 0.95, 0.69, 0.85, 0.8]
