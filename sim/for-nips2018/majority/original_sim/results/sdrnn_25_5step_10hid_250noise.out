Namespace(arch='tanh', batch_size=256, display_epoch=100, input_noise_level=0.15, latent_attractor_space=True, loss_switch_frequency=0, lrate_attractor=0.002, lrate_prediction=0.002, lrate_wt_penalty=0.0, n_attractor_hidden=20, n_attractor_steps=5, n_hidden=10, n_replications=100, noise_level=0.25, report_best_train_performance=True, seq_len=25, task='majority', train_attr_weights_on_prediction=False, training_epochs=2500)
TRAINING ON 100 EXAMPLES, TESTING ON 3996
********** replication  0  **********
epoch   0 LossPred 1.1430 LossAtt 1.0221 TrainAcc 0.5100 TestAcc 0.5403 0.5050
epoch 100 LossPred 0.9014 LossAtt 0.3311 TrainAcc 0.6400 TestAcc 0.5658 0.6200
epoch 200 LossPred 0.8344 LossAtt 0.3306 TrainAcc 0.6900 TestAcc 0.5511 0.6600
epoch 300 LossPred 0.5723 LossAtt 0.4478 TrainAcc 0.8200 TestAcc 0.7825 0.8000
epoch 400 LossPred 0.4582 LossAtt 0.3800 TrainAcc 0.8500 TestAcc 0.7963 0.7950
epoch 500 LossPred 0.3844 LossAtt 0.3634 TrainAcc 0.9000 TestAcc 0.8073 0.8200
epoch 600 LossPred 0.3577 LossAtt 0.3540 TrainAcc 0.8800 TestAcc 0.7963 0.8400
epoch 700 LossPred 0.2884 LossAtt 0.3654 TrainAcc 0.9200 TestAcc 0.7903 0.8400
epoch 800 LossPred 0.2853 LossAtt 0.3592 TrainAcc 0.9200 TestAcc 0.8211 0.8400
epoch 900 LossPred 0.2764 LossAtt 0.3780 TrainAcc 0.9300 TestAcc 0.8116 0.8400
epoch 1000 LossPred 0.2721 LossAtt 0.3971 TrainAcc 0.9100 TestAcc 0.8308 0.8600
epoch 1100 LossPred 0.2269 LossAtt 0.3790 TrainAcc 0.9400 TestAcc 0.8246 0.8800
epoch 1200 LossPred 0.2211 LossAtt 0.3768 TrainAcc 0.9400 TestAcc 0.8378 0.8950
epoch 1300 LossPred 0.3085 LossAtt 0.3700 TrainAcc 0.8900 TestAcc 0.8308 0.8550
epoch 1400 LossPred 0.2173 LossAtt 0.3594 TrainAcc 0.9500 TestAcc 0.8406 0.9150
epoch 1500 LossPred 0.2079 LossAtt 0.3592 TrainAcc 0.9500 TestAcc 0.8366 0.9100
epoch 1600 LossPred 0.2452 LossAtt 0.3684 TrainAcc 0.9300 TestAcc 0.8233 0.8850
epoch 1700 LossPred 0.2340 LossAtt 0.3752 TrainAcc 0.9200 TestAcc 0.8426 0.9300
epoch 1800 LossPred 0.2253 LossAtt 0.3874 TrainAcc 0.9300 TestAcc 0.8288 0.9050
epoch 1900 LossPred 0.1892 LossAtt 0.3903 TrainAcc 0.9500 TestAcc 0.8461 0.9250
epoch 2000 LossPred 0.3356 LossAtt 0.3819 TrainAcc 0.8600 TestAcc 0.8253 0.8600
epoch 2100 LossPred 0.2348 LossAtt 0.3761 TrainAcc 0.9200 TestAcc 0.8408 0.8700
epoch 2200 LossPred 0.1379 LossAtt 0.3745 TrainAcc 0.9700 TestAcc 0.8509 0.9450
epoch 2300 LossPred 0.1986 LossAtt 0.3690 TrainAcc 0.9400 TestAcc 0.8478 0.9050
epoch 2400 LossPred 0.1364 LossAtt 0.3546 TrainAcc 0.9700 TestAcc 0.8456 0.9200
epoch 2500 LossPred 0.1128 LossAtt 0.3531 TrainAcc 0.9700 TestAcc 0.8586 0.9600
Optimization Finished!
********** replication  1  **********
epoch   0 LossPred 1.0399 LossAtt 1.0425 TrainAcc 0.5100 TestAcc 0.4737 0.5300
epoch 100 LossPred 0.8712 LossAtt 0.4008 TrainAcc 0.6700 TestAcc 0.6036 0.6700
epoch 200 LossPred 0.4919 LossAtt 0.4347 TrainAcc 0.8500 TestAcc 0.7530 0.8400
epoch 300 LossPred 0.4138 LossAtt 0.4155 TrainAcc 0.8700 TestAcc 0.8063 0.8500
epoch 400 LossPred 0.3896 LossAtt 0.4092 TrainAcc 0.8800 TestAcc 0.8136 0.8550
epoch 500 LossPred 0.2977 LossAtt 0.4033 TrainAcc 0.9100 TestAcc 0.8493 0.8800
epoch 600 LossPred 0.2528 LossAtt 0.4054 TrainAcc 0.9200 TestAcc 0.8168 0.9000
epoch 700 LossPred 0.2005 LossAtt 0.4005 TrainAcc 0.9200 TestAcc 0.8506 0.9250
epoch 800 LossPred 0.1277 LossAtt 0.4075 TrainAcc 0.9700 TestAcc 0.8341 0.9200
epoch 900 LossPred 0.1160 LossAtt 0.3952 TrainAcc 0.9800 TestAcc 0.8481 0.9200
epoch 1000 LossPred 0.1503 LossAtt 0.3834 TrainAcc 0.9600 TestAcc 0.8586 0.9150
epoch 1100 LossPred 0.1140 LossAtt 0.3758 TrainAcc 0.9700 TestAcc 0.8544 0.9200
epoch 1200 LossPred 0.1083 LossAtt 0.3702 TrainAcc 0.9800 TestAcc 0.8569 0.9150
epoch 1300 LossPred 0.0968 LossAtt 0.3706 TrainAcc 0.9800 TestAcc 0.8471 0.9200
epoch 1400 LossPred 0.0981 LossAtt 0.3594 TrainAcc 0.9800 TestAcc 0.8471 0.9250
epoch 1500 LossPred 0.4686 LossAtt 0.3743 TrainAcc 0.8400 TestAcc 0.8341 0.8250
epoch 1600 LossPred 0.1345 LossAtt 0.3685 TrainAcc 0.9600 TestAcc 0.8353 0.9100
epoch 1700 LossPred 0.1395 LossAtt 0.3727 TrainAcc 0.9500 TestAcc 0.8624 0.9250
epoch 1800 LossPred 0.0971 LossAtt 0.3554 TrainAcc 0.9700 TestAcc 0.8529 0.9400
epoch 1900 LossPred 0.0921 LossAtt 0.3560 TrainAcc 0.9800 TestAcc 0.8519 0.9250
epoch 2000 LossPred 0.0881 LossAtt 0.3554 TrainAcc 0.9800 TestAcc 0.8506 0.9350
epoch 2100 LossPred 0.0980 LossAtt 0.3496 TrainAcc 0.9800 TestAcc 0.8501 0.9250
epoch 2200 LossPred 0.1346 LossAtt 0.3423 TrainAcc 0.9600 TestAcc 0.8343 0.9300
epoch 2300 LossPred 0.0990 LossAtt 0.3447 TrainAcc 0.9800 TestAcc 0.8446 0.9300
epoch 2400 LossPred 0.1448 LossAtt 0.3301 TrainAcc 0.9500 TestAcc 0.8589 0.9100
epoch 2500 LossPred 0.0801 LossAtt 0.3460 TrainAcc 0.9800 TestAcc 0.8614 0.9450
Optimization Finished!
********** replication  2  **********
epoch   0 LossPred 1.0429 LossAtt 1.0154 TrainAcc 0.4200 TestAcc 0.4432 0.4150
epoch 100 LossPred 0.9058 LossAtt 0.3019 TrainAcc 0.6500 TestAcc 0.5833 0.6450
epoch 200 LossPred 0.7518 LossAtt 0.3964 TrainAcc 0.7000 TestAcc 0.7127 0.7300
epoch 300 LossPred 0.4770 LossAtt 0.3585 TrainAcc 0.8200 TestAcc 0.8031 0.8300
epoch 400 LossPred 0.4982 LossAtt 0.3235 TrainAcc 0.7900 TestAcc 0.8073 0.8350
epoch 500 LossPred 0.2976 LossAtt 0.3448 TrainAcc 0.9000 TestAcc 0.8639 0.8850
epoch 600 LossPred 0.2148 LossAtt 0.3286 TrainAcc 0.9400 TestAcc 0.8826 0.9300
epoch 700 LossPred 0.1594 LossAtt 0.3345 TrainAcc 0.9600 TestAcc 0.8849 0.9250
epoch 800 LossPred 0.1607 LossAtt 0.3302 TrainAcc 0.9500 TestAcc 0.8831 0.9350
epoch 900 LossPred 0.2435 LossAtt 0.3264 TrainAcc 0.9300 TestAcc 0.8779 0.9250
epoch 1000 LossPred 0.1223 LossAtt 0.3166 TrainAcc 0.9800 TestAcc 0.8771 0.9450
epoch 1100 LossPred 0.1574 LossAtt 0.3121 TrainAcc 0.9500 TestAcc 0.8851 0.9550
epoch 1200 LossPred 0.1509 LossAtt 0.3080 TrainAcc 0.9500 TestAcc 0.8846 0.9500
epoch 1300 LossPred 0.1061 LossAtt 0.3037 TrainAcc 0.9700 TestAcc 0.8844 0.9550
epoch 1400 LossPred 0.1112 LossAtt 0.2990 TrainAcc 0.9800 TestAcc 0.8824 0.9500
epoch 1500 LossPred 0.3956 LossAtt 0.3160 TrainAcc 0.8600 TestAcc 0.8216 0.8650
epoch 1600 LossPred 0.1486 LossAtt 0.3054 TrainAcc 0.9500 TestAcc 0.8781 0.9450
epoch 1700 LossPred 0.1223 LossAtt 0.3095 TrainAcc 0.9600 TestAcc 0.8954 0.9550
epoch 1800 LossPred 0.1161 LossAtt 0.3043 TrainAcc 0.9800 TestAcc 0.8946 0.9650
epoch 1900 LossPred 0.0897 LossAtt 0.3091 TrainAcc 0.9800 TestAcc 0.9037 0.9650
epoch 2000 LossPred 0.1458 LossAtt 0.3134 TrainAcc 0.9600 TestAcc 0.8889 0.9500
epoch 2100 LossPred 0.0826 LossAtt 0.3107 TrainAcc 0.9800 TestAcc 0.8904 0.9750
epoch 2200 LossPred 0.0701 LossAtt 0.3180 TrainAcc 0.9800 TestAcc 0.9029 0.9800
epoch 2300 LossPred 0.0550 LossAtt 0.3235 TrainAcc 0.9900 TestAcc 0.9002 0.9800
epoch 2400 LossPred 0.0530 LossAtt 0.3221 TrainAcc 0.9900 TestAcc 0.8894 0.9750
epoch 2500 LossPred 0.0477 LossAtt 0.3154 TrainAcc 0.9900 TestAcc 0.8866 0.9800
Optimization Finished!
********** replication  3  **********
epoch   0 LossPred 0.9983 LossAtt 1.0512 TrainAcc 0.4600 TestAcc 0.4980 0.4700
epoch 100 LossPred 0.8440 LossAtt 0.4147 TrainAcc 0.6500 TestAcc 0.5901 0.6650
epoch 200 LossPred 0.2480 LossAtt 0.4557 TrainAcc 0.9200 TestAcc 0.8601 0.9000
epoch 300 LossPred 0.1963 LossAtt 0.4139 TrainAcc 0.9500 TestAcc 0.8616 0.9250
epoch 400 LossPred 0.1710 LossAtt 0.4153 TrainAcc 0.9500 TestAcc 0.8729 0.9100
epoch 500 LossPred 0.1454 LossAtt 0.4196 TrainAcc 0.9700 TestAcc 0.8841 0.9450
epoch 600 LossPred 0.1270 LossAtt 0.4066 TrainAcc 0.9800 TestAcc 0.8899 0.9650
epoch 700 LossPred 0.1033 LossAtt 0.4095 TrainAcc 0.9800 TestAcc 0.8991 0.9700
epoch 800 LossPred 0.0951 LossAtt 0.3853 TrainAcc 0.9800 TestAcc 0.9057 0.9700
epoch 900 LossPred 0.0696 LossAtt 0.3878 TrainAcc 0.9800 TestAcc 0.9089 0.9550
epoch 1000 LossPred 0.1327 LossAtt 0.3931 TrainAcc 0.9500 TestAcc 0.8769 0.9250
epoch 1100 LossPred 0.0534 LossAtt 0.3922 TrainAcc 0.9800 TestAcc 0.9124 0.9600
epoch 1200 LossPred 0.1012 LossAtt 0.3967 TrainAcc 0.9800 TestAcc 0.8874 0.9450
epoch 1300 LossPred 0.0446 LossAtt 0.4079 TrainAcc 1.0000 TestAcc 0.8989 0.9700
Optimization Finished!
********** replication  4  **********
epoch   0 LossPred 0.9818 LossAtt 1.0252 TrainAcc 0.5400 TestAcc 0.4810 0.5350
epoch 100 LossPred 0.8576 LossAtt 0.4516 TrainAcc 0.6400 TestAcc 0.5543 0.6350
epoch 200 LossPred 0.7692 LossAtt 0.4800 TrainAcc 0.6500 TestAcc 0.5578 0.6650
epoch 300 LossPred 0.6696 LossAtt 0.5012 TrainAcc 0.7000 TestAcc 0.5598 0.7150
epoch 400 LossPred 0.5962 LossAtt 0.4999 TrainAcc 0.7300 TestAcc 0.5498 0.7150
epoch 500 LossPred 0.5488 LossAtt 0.5214 TrainAcc 0.7600 TestAcc 0.5656 0.7550
epoch 600 LossPred 0.4825 LossAtt 0.5390 TrainAcc 0.8300 TestAcc 0.5748 0.7650
epoch 700 LossPred 0.4255 LossAtt 0.5511 TrainAcc 0.8600 TestAcc 0.5681 0.7600
epoch 800 LossPred 0.3895 LossAtt 0.5591 TrainAcc 0.8600 TestAcc 0.5738 0.7800
epoch 900 LossPred 0.3630 LossAtt 0.5456 TrainAcc 0.9000 TestAcc 0.5803 0.7950
epoch 1000 LossPred 0.3550 LossAtt 0.5415 TrainAcc 0.8800 TestAcc 0.5813 0.7650
epoch 1100 LossPred 0.3090 LossAtt 0.5434 TrainAcc 0.9000 TestAcc 0.5906 0.8050
epoch 1200 LossPred 0.2725 LossAtt 0.5393 TrainAcc 0.9300 TestAcc 0.5916 0.8000
epoch 1300 LossPred 0.2807 LossAtt 0.5529 TrainAcc 0.9300 TestAcc 0.5858 0.7850
epoch 1400 LossPred 0.2581 LossAtt 0.5382 TrainAcc 0.9100 TestAcc 0.5896 0.8150
epoch 1500 LossPred 0.2753 LossAtt 0.5251 TrainAcc 0.9300 TestAcc 0.5866 0.7900
epoch 1600 LossPred 0.2241 LossAtt 0.5409 TrainAcc 0.9500 TestAcc 0.5856 0.7900
epoch 1700 LossPred 0.2437 LossAtt 0.5300 TrainAcc 0.9300 TestAcc 0.5926 0.8050
epoch 1800 LossPred 0.2060 LossAtt 0.5244 TrainAcc 0.9500 TestAcc 0.5918 0.7900
epoch 1900 LossPred 0.2187 LossAtt 0.5109 TrainAcc 0.9400 TestAcc 0.5928 0.7900
epoch 2000 LossPred 0.2115 LossAtt 0.5295 TrainAcc 0.9400 TestAcc 0.5968 0.7850
epoch 2100 LossPred 0.2078 LossAtt 0.5215 TrainAcc 0.9500 TestAcc 0.5868 0.7750
epoch 2200 LossPred 0.1862 LossAtt 0.5192 TrainAcc 0.9500 TestAcc 0.5951 0.7850
epoch 2300 LossPred 0.1782 LossAtt 0.5244 TrainAcc 0.9400 TestAcc 0.5898 0.7850
epoch 2400 LossPred 0.2113 LossAtt 0.5148 TrainAcc 0.9500 TestAcc 0.5933 0.8100
epoch 2500 LossPred 0.2135 LossAtt 0.5233 TrainAcc 0.9600 TestAcc 0.5921 0.8000
Optimization Finished!
********** replication  5  **********
epoch   0 LossPred 0.9965 LossAtt 1.0165 TrainAcc 0.5600 TestAcc 0.4577 0.5450
epoch 100 LossPred 0.8121 LossAtt 0.3617 TrainAcc 0.6900 TestAcc 0.5033 0.6900
epoch 200 LossPred 0.6652 LossAtt 0.3909 TrainAcc 0.7600 TestAcc 0.6346 0.7300
epoch 300 LossPred 0.2702 LossAtt 0.3717 TrainAcc 0.9300 TestAcc 0.8011 0.8800
epoch 400 LossPred 0.3191 LossAtt 0.3602 TrainAcc 0.9000 TestAcc 0.8236 0.8500
epoch 500 LossPred 0.3092 LossAtt 0.3626 TrainAcc 0.8700 TestAcc 0.8271 0.8300
epoch 600 LossPred 0.1882 LossAtt 0.3473 TrainAcc 0.9500 TestAcc 0.8211 0.8750
epoch 700 LossPred 0.1633 LossAtt 0.3356 TrainAcc 0.9400 TestAcc 0.8231 0.8750
epoch 800 LossPred 0.1614 LossAtt 0.3104 TrainAcc 0.9400 TestAcc 0.8281 0.8800
epoch 900 LossPred 0.2313 LossAtt 0.3036 TrainAcc 0.9200 TestAcc 0.8351 0.8750
epoch 1000 LossPred 0.2325 LossAtt 0.2802 TrainAcc 0.9300 TestAcc 0.8406 0.8850
epoch 1100 LossPred 0.1804 LossAtt 0.2742 TrainAcc 0.9300 TestAcc 0.8396 0.8850
epoch 1200 LossPred 0.1496 LossAtt 0.2772 TrainAcc 0.9500 TestAcc 0.8358 0.9000
epoch 1300 LossPred 0.1971 LossAtt 0.2751 TrainAcc 0.9200 TestAcc 0.8406 0.8900
epoch 1400 LossPred 0.1952 LossAtt 0.2568 TrainAcc 0.9500 TestAcc 0.8056 0.9100
epoch 1500 LossPred 0.1835 LossAtt 0.2695 TrainAcc 0.9400 TestAcc 0.8256 0.9100
epoch 1600 LossPred 0.1743 LossAtt 0.2712 TrainAcc 0.9400 TestAcc 0.8298 0.9150
epoch 1700 LossPred 0.1626 LossAtt 0.2759 TrainAcc 0.9400 TestAcc 0.8298 0.9250
epoch 1800 LossPred 0.1364 LossAtt 0.2601 TrainAcc 0.9400 TestAcc 0.8303 0.9150
epoch 1900 LossPred 0.1335 LossAtt 0.2730 TrainAcc 0.9500 TestAcc 0.8378 0.9250
epoch 2000 LossPred 0.1232 LossAtt 0.2636 TrainAcc 0.9600 TestAcc 0.8446 0.9200
epoch 2100 LossPred 0.2010 LossAtt 0.2811 TrainAcc 0.9300 TestAcc 0.8496 0.9100
epoch 2200 LossPred 0.1326 LossAtt 0.2831 TrainAcc 0.9600 TestAcc 0.8506 0.9150
epoch 2300 LossPred 0.1206 LossAtt 0.2829 TrainAcc 0.9600 TestAcc 0.8411 0.9200
epoch 2400 LossPred 0.1170 LossAtt 0.2829 TrainAcc 0.9700 TestAcc 0.8453 0.9250
epoch 2500 LossPred 0.1055 LossAtt 0.2942 TrainAcc 0.9600 TestAcc 0.8544 0.9300
Optimization Finished!
********** replication  6  **********
epoch   0 LossPred 1.0281 LossAtt 1.0158 TrainAcc 0.5400 TestAcc 0.5025 0.5900
epoch 100 LossPred 0.9043 LossAtt 0.2797 TrainAcc 0.6400 TestAcc 0.5716 0.6350
epoch 200 LossPred 0.8178 LossAtt 0.3575 TrainAcc 0.7000 TestAcc 0.5636 0.6850
epoch 300 LossPred 0.7696 LossAtt 0.3483 TrainAcc 0.7200 TestAcc 0.5723 0.7150
epoch 400 LossPred 0.7535 LossAtt 0.3332 TrainAcc 0.7200 TestAcc 0.5736 0.7100
epoch 500 LossPred 0.7349 LossAtt 0.3611 TrainAcc 0.7500 TestAcc 0.5761 0.7050
epoch 600 LossPred 0.7338 LossAtt 0.3454 TrainAcc 0.7400 TestAcc 0.5751 0.7150
epoch 700 LossPred 0.7260 LossAtt 0.3459 TrainAcc 0.7600 TestAcc 0.5728 0.7200
epoch 800 LossPred 0.7210 LossAtt 0.3464 TrainAcc 0.7600 TestAcc 0.5713 0.7250
epoch 900 LossPred 0.7081 LossAtt 0.3492 TrainAcc 0.7500 TestAcc 0.5731 0.7250
epoch 1000 LossPred 0.7008 LossAtt 0.3285 TrainAcc 0.7600 TestAcc 0.5753 0.7150
epoch 1100 LossPred 0.6930 LossAtt 0.3303 TrainAcc 0.7700 TestAcc 0.5763 0.7150
epoch 1200 LossPred 0.6928 LossAtt 0.3134 TrainAcc 0.7700 TestAcc 0.5763 0.7100
epoch 1300 LossPred 0.6960 LossAtt 0.3158 TrainAcc 0.7700 TestAcc 0.5766 0.7100
epoch 1400 LossPred 0.6969 LossAtt 0.2879 TrainAcc 0.7700 TestAcc 0.5741 0.7150
epoch 1500 LossPred 0.6907 LossAtt 0.3168 TrainAcc 0.7500 TestAcc 0.5753 0.7150
epoch 1600 LossPred 0.6734 LossAtt 0.2954 TrainAcc 0.7700 TestAcc 0.5741 0.7150
epoch 1700 LossPred 0.6710 LossAtt 0.2957 TrainAcc 0.7700 TestAcc 0.5741 0.7150
epoch 1800 LossPred 0.6696 LossAtt 0.2837 TrainAcc 0.7700 TestAcc 0.5756 0.7150
epoch 1900 LossPred 0.6656 LossAtt 0.3009 TrainAcc 0.7700 TestAcc 0.5771 0.7200
epoch 2000 LossPred 0.6655 LossAtt 0.2945 TrainAcc 0.7700 TestAcc 0.5778 0.7300
epoch 2100 LossPred 0.6634 LossAtt 0.2867 TrainAcc 0.7700 TestAcc 0.5738 0.7150
epoch 2200 LossPred 0.6747 LossAtt 0.2936 TrainAcc 0.7700 TestAcc 0.5713 0.7350
epoch 2300 LossPred 0.6642 LossAtt 0.2980 TrainAcc 0.7700 TestAcc 0.5721 0.7400
epoch 2400 LossPred 0.6642 LossAtt 0.2957 TrainAcc 0.7700 TestAcc 0.5708 0.7400
epoch 2500 LossPred 0.6598 LossAtt 0.3002 TrainAcc 0.7700 TestAcc 0.5733 0.7400
Optimization Finished!
********** replication  7  **********
epoch   0 LossPred 1.0165 LossAtt 1.0312 TrainAcc 0.5600 TestAcc 0.5288 0.5800
epoch 100 LossPred 0.9096 LossAtt 0.3788 TrainAcc 0.6100 TestAcc 0.5763 0.6250
epoch 200 LossPred 0.5210 LossAtt 0.3926 TrainAcc 0.8200 TestAcc 0.8046 0.7950
epoch 300 LossPred 0.4773 LossAtt 0.3707 TrainAcc 0.8500 TestAcc 0.7670 0.8100
epoch 400 LossPred 0.4043 LossAtt 0.4013 TrainAcc 0.8800 TestAcc 0.8056 0.8250
epoch 500 LossPred 0.3978 LossAtt 0.3923 TrainAcc 0.8900 TestAcc 0.8098 0.8350
epoch 600 LossPred 0.3987 LossAtt 0.4145 TrainAcc 0.8900 TestAcc 0.7995 0.8250
epoch 700 LossPred 0.3973 LossAtt 0.4037 TrainAcc 0.9000 TestAcc 0.8073 0.8450
epoch 800 LossPred 0.3777 LossAtt 0.4101 TrainAcc 0.9000 TestAcc 0.7915 0.8450
epoch 900 LossPred 0.3852 LossAtt 0.4224 TrainAcc 0.9000 TestAcc 0.7790 0.8500
epoch 1000 LossPred 0.3703 LossAtt 0.4309 TrainAcc 0.9000 TestAcc 0.7940 0.8500
epoch 1100 LossPred 0.3627 LossAtt 0.4205 TrainAcc 0.9000 TestAcc 0.7973 0.8300
epoch 1200 LossPred 0.3205 LossAtt 0.4345 TrainAcc 0.9000 TestAcc 0.7740 0.8250
epoch 1300 LossPred 0.3245 LossAtt 0.4229 TrainAcc 0.9100 TestAcc 0.7888 0.8550
epoch 1400 LossPred 0.2908 LossAtt 0.4330 TrainAcc 0.9200 TestAcc 0.7900 0.8800
epoch 1500 LossPred 0.2798 LossAtt 0.4203 TrainAcc 0.9200 TestAcc 0.7865 0.8700
epoch 1600 LossPred 0.2701 LossAtt 0.4249 TrainAcc 0.9200 TestAcc 0.7868 0.8800
epoch 1700 LossPred 0.2618 LossAtt 0.4222 TrainAcc 0.9300 TestAcc 0.7985 0.8950
epoch 1800 LossPred 0.2584 LossAtt 0.4120 TrainAcc 0.9300 TestAcc 0.7915 0.9000
epoch 1900 LossPred 0.2500 LossAtt 0.4215 TrainAcc 0.9300 TestAcc 0.7930 0.9000
epoch 2000 LossPred 0.2461 LossAtt 0.4122 TrainAcc 0.9300 TestAcc 0.7985 0.8900
epoch 2100 LossPred 0.2399 LossAtt 0.4175 TrainAcc 0.9300 TestAcc 0.7908 0.9000
epoch 2200 LossPred 0.2339 LossAtt 0.4276 TrainAcc 0.9300 TestAcc 0.7880 0.8900
epoch 2300 LossPred 0.2296 LossAtt 0.4064 TrainAcc 0.9300 TestAcc 0.7863 0.9050
epoch 2400 LossPred 0.2209 LossAtt 0.4202 TrainAcc 0.9300 TestAcc 0.7920 0.8900
epoch 2500 LossPred 0.2110 LossAtt 0.4131 TrainAcc 0.9300 TestAcc 0.7900 0.8850
Optimization Finished!
********** replication  8  **********
epoch   0 LossPred 1.2129 LossAtt 1.0442 TrainAcc 0.4200 TestAcc 0.4409 0.4400
epoch 100 LossPred 0.9251 LossAtt 0.4205 TrainAcc 0.6400 TestAcc 0.5443 0.6100
epoch 200 LossPred 0.6010 LossAtt 0.5415 TrainAcc 0.8000 TestAcc 0.7540 0.8150
epoch 300 LossPred 0.2971 LossAtt 0.4843 TrainAcc 0.9400 TestAcc 0.8786 0.8700
epoch 400 LossPred 0.2080 LossAtt 0.4765 TrainAcc 0.9500 TestAcc 0.8754 0.9000
epoch 500 LossPred 0.1286 LossAtt 0.4787 TrainAcc 0.9700 TestAcc 0.8624 0.9050
epoch 600 LossPred 0.0968 LossAtt 0.4717 TrainAcc 0.9900 TestAcc 0.8614 0.8750
epoch 700 LossPred 0.0680 LossAtt 0.4929 TrainAcc 1.0000 TestAcc 0.8529 0.9000
Optimization Finished!
********** replication  9  **********
epoch   0 LossPred 0.9473 LossAtt 1.0419 TrainAcc 0.5600 TestAcc 0.5000 0.5850
epoch 100 LossPred 0.8236 LossAtt 0.4310 TrainAcc 0.6500 TestAcc 0.5806 0.6400
epoch 200 LossPred 0.7590 LossAtt 0.4547 TrainAcc 0.6900 TestAcc 0.5986 0.6900
epoch 300 LossPred 0.1836 LossAtt 0.5088 TrainAcc 0.9500 TestAcc 0.8586 0.9250
epoch 400 LossPred 0.1332 LossAtt 0.5146 TrainAcc 0.9600 TestAcc 0.8561 0.9300
epoch 500 LossPred 0.0865 LossAtt 0.5077 TrainAcc 0.9800 TestAcc 0.8621 0.9450
epoch 600 LossPred 0.1698 LossAtt 0.5102 TrainAcc 0.9500 TestAcc 0.8541 0.9100
epoch 700 LossPred 0.0681 LossAtt 0.5026 TrainAcc 0.9800 TestAcc 0.8639 0.9350
epoch 800 LossPred 0.0533 LossAtt 0.4889 TrainAcc 0.9900 TestAcc 0.8586 0.9250
epoch 900 LossPred 0.0508 LossAtt 0.4795 TrainAcc 0.9900 TestAcc 0.8609 0.9200
epoch 1000 LossPred 0.0424 LossAtt 0.4637 TrainAcc 0.9900 TestAcc 0.8619 0.9250
epoch 1100 LossPred 0.0319 LossAtt 0.4608 TrainAcc 0.9900 TestAcc 0.8534 0.9250
epoch 1200 LossPred 0.0458 LossAtt 0.4730 TrainAcc 0.9900 TestAcc 0.8579 0.9300
epoch 1300 LossPred 0.0212 LossAtt 0.4606 TrainAcc 1.0000 TestAcc 0.8569 0.9250
Optimization Finished!
********** replication  10  **********
epoch   0 LossPred 0.9526 LossAtt 1.0212 TrainAcc 0.5700 TestAcc 0.5440 0.5750
epoch 100 LossPred 0.8097 LossAtt 0.3648 TrainAcc 0.7000 TestAcc 0.5946 0.7050
epoch 200 LossPred 0.3735 LossAtt 0.3385 TrainAcc 0.8800 TestAcc 0.8308 0.8800
epoch 300 LossPred 0.3208 LossAtt 0.3079 TrainAcc 0.8900 TestAcc 0.8456 0.8500
epoch 400 LossPred 0.4164 LossAtt 0.3084 TrainAcc 0.8600 TestAcc 0.8131 0.7900
epoch 500 LossPred 0.3948 LossAtt 0.2977 TrainAcc 0.8600 TestAcc 0.8223 0.8200
epoch 600 LossPred 0.2659 LossAtt 0.2871 TrainAcc 0.8900 TestAcc 0.8666 0.8950
epoch 700 LossPred 0.2312 LossAtt 0.2834 TrainAcc 0.9300 TestAcc 0.8876 0.9100
epoch 800 LossPred 0.2114 LossAtt 0.2765 TrainAcc 0.9500 TestAcc 0.8869 0.9300
epoch 900 LossPred 0.1768 LossAtt 0.2750 TrainAcc 0.9500 TestAcc 0.8969 0.9150
epoch 1000 LossPred 0.1901 LossAtt 0.2694 TrainAcc 0.9500 TestAcc 0.8889 0.9250
epoch 1100 LossPred 0.1546 LossAtt 0.2603 TrainAcc 0.9700 TestAcc 0.9004 0.9300
epoch 1200 LossPred 0.1790 LossAtt 0.2667 TrainAcc 0.9500 TestAcc 0.8879 0.9300
epoch 1300 LossPred 0.2146 LossAtt 0.2717 TrainAcc 0.9300 TestAcc 0.8894 0.8700
epoch 1400 LossPred 0.1640 LossAtt 0.2632 TrainAcc 0.9600 TestAcc 0.8886 0.9250
epoch 1500 LossPred 0.2322 LossAtt 0.2806 TrainAcc 0.9300 TestAcc 0.8749 0.8700
epoch 1600 LossPred 0.2052 LossAtt 0.2629 TrainAcc 0.9400 TestAcc 0.8799 0.9050
epoch 1700 LossPred 0.2379 LossAtt 0.2716 TrainAcc 0.9300 TestAcc 0.8746 0.8800
epoch 1800 LossPred 0.4440 LossAtt 0.2845 TrainAcc 0.8500 TestAcc 0.8128 0.8400
epoch 1900 LossPred 0.2417 LossAtt 0.2705 TrainAcc 0.9300 TestAcc 0.8644 0.8800
epoch 2000 LossPred 0.2514 LossAtt 0.2676 TrainAcc 0.9200 TestAcc 0.8566 0.8900
epoch 2100 LossPred 0.3784 LossAtt 0.2737 TrainAcc 0.8600 TestAcc 0.8178 0.8850
epoch 2200 LossPred 0.2797 LossAtt 0.2724 TrainAcc 0.9200 TestAcc 0.8483 0.8600
epoch 2300 LossPred 0.2055 LossAtt 0.2705 TrainAcc 0.9500 TestAcc 0.8654 0.9050
epoch 2400 LossPred 0.2131 LossAtt 0.2756 TrainAcc 0.9400 TestAcc 0.8644 0.8850
epoch 2500 LossPred 0.2761 LossAtt 0.2754 TrainAcc 0.9000 TestAcc 0.8476 0.9250
Optimization Finished!
********** replication  11  **********
epoch   0 LossPred 1.1671 LossAtt 1.0087 TrainAcc 0.4700 TestAcc 0.4965 0.4700
epoch 100 LossPred 0.9765 LossAtt 0.3114 TrainAcc 0.5500 TestAcc 0.5886 0.5500
epoch 200 LossPred 0.9574 LossAtt 0.2820 TrainAcc 0.5800 TestAcc 0.5393 0.5700
epoch 300 LossPred 0.9462 LossAtt 0.3111 TrainAcc 0.6000 TestAcc 0.5343 0.5600
epoch 400 LossPred 0.9264 LossAtt 0.3695 TrainAcc 0.6000 TestAcc 0.5155 0.5900
epoch 500 LossPred 0.8716 LossAtt 0.3462 TrainAcc 0.6000 TestAcc 0.5145 0.5800
epoch 600 LossPred 0.8526 LossAtt 0.3399 TrainAcc 0.6500 TestAcc 0.5158 0.6150
epoch 700 LossPred 0.8301 LossAtt 0.3750 TrainAcc 0.6700 TestAcc 0.5050 0.6250
epoch 800 LossPred 0.8146 LossAtt 0.3776 TrainAcc 0.6600 TestAcc 0.4965 0.6300
epoch 900 LossPred 0.7899 LossAtt 0.3883 TrainAcc 0.6800 TestAcc 0.4915 0.6250
epoch 1000 LossPred 0.7536 LossAtt 0.4040 TrainAcc 0.6700 TestAcc 0.4970 0.6500
epoch 1100 LossPred 0.7341 LossAtt 0.3850 TrainAcc 0.6800 TestAcc 0.4967 0.6650
epoch 1200 LossPred 0.7234 LossAtt 0.4010 TrainAcc 0.7100 TestAcc 0.4952 0.6650
epoch 1300 LossPred 0.7112 LossAtt 0.3834 TrainAcc 0.6800 TestAcc 0.4900 0.6550
epoch 1400 LossPred 0.6764 LossAtt 0.3930 TrainAcc 0.7100 TestAcc 0.4947 0.7000
epoch 1500 LossPred 0.6476 LossAtt 0.3814 TrainAcc 0.7200 TestAcc 0.4945 0.6650
epoch 1600 LossPred 0.6253 LossAtt 0.3960 TrainAcc 0.7600 TestAcc 0.5053 0.6950
epoch 1700 LossPred 0.6104 LossAtt 0.4047 TrainAcc 0.7900 TestAcc 0.5075 0.7200
epoch 1800 LossPred 0.5885 LossAtt 0.4080 TrainAcc 0.8200 TestAcc 0.5075 0.7200
epoch 1900 LossPred 0.6384 LossAtt 0.4267 TrainAcc 0.7500 TestAcc 0.5088 0.6900
epoch 2000 LossPred 0.5649 LossAtt 0.4137 TrainAcc 0.7600 TestAcc 0.5158 0.6900
epoch 2100 LossPred 0.5906 LossAtt 0.4055 TrainAcc 0.7600 TestAcc 0.5178 0.7100
epoch 2200 LossPred 0.6103 LossAtt 0.4074 TrainAcc 0.8000 TestAcc 0.5050 0.7200
epoch 2300 LossPred 0.5736 LossAtt 0.4065 TrainAcc 0.7800 TestAcc 0.5195 0.7300
epoch 2400 LossPred 0.5209 LossAtt 0.3948 TrainAcc 0.8300 TestAcc 0.5105 0.7300
epoch 2500 LossPred 0.5491 LossAtt 0.4015 TrainAcc 0.8000 TestAcc 0.5103 0.7250
Optimization Finished!
********** replication  12  **********
epoch   0 LossPred 1.0498 LossAtt 1.0313 TrainAcc 0.4200 TestAcc 0.4565 0.4300
epoch 100 LossPred 0.8313 LossAtt 0.4129 TrainAcc 0.6700 TestAcc 0.6346 0.6850
epoch 200 LossPred 0.3509 LossAtt 0.3658 TrainAcc 0.9000 TestAcc 0.8436 0.8400
epoch 300 LossPred 0.2908 LossAtt 0.3472 TrainAcc 0.9100 TestAcc 0.8408 0.8450
epoch 400 LossPred 0.3501 LossAtt 0.3172 TrainAcc 0.8900 TestAcc 0.8306 0.8600
epoch 500 LossPred 0.2277 LossAtt 0.3029 TrainAcc 0.9300 TestAcc 0.8436 0.8500
epoch 600 LossPred 0.2286 LossAtt 0.2965 TrainAcc 0.9300 TestAcc 0.8403 0.8500
epoch 700 LossPred 0.2353 LossAtt 0.2859 TrainAcc 0.9300 TestAcc 0.8411 0.8550
epoch 800 LossPred 0.2221 LossAtt 0.2817 TrainAcc 0.9300 TestAcc 0.8418 0.8600
epoch 900 LossPred 0.2433 LossAtt 0.2754 TrainAcc 0.9200 TestAcc 0.8338 0.8700
epoch 1000 LossPred 0.2202 LossAtt 0.2780 TrainAcc 0.9300 TestAcc 0.8378 0.8650
epoch 1100 LossPred 0.2479 LossAtt 0.3027 TrainAcc 0.9200 TestAcc 0.8188 0.8800
epoch 1200 LossPred 0.2153 LossAtt 0.2975 TrainAcc 0.9400 TestAcc 0.8223 0.8450
epoch 1300 LossPred 0.2147 LossAtt 0.3234 TrainAcc 0.9400 TestAcc 0.8056 0.8650
epoch 1400 LossPred 0.1780 LossAtt 0.3161 TrainAcc 0.9500 TestAcc 0.8083 0.8900
epoch 1500 LossPred 0.1830 LossAtt 0.3018 TrainAcc 0.9500 TestAcc 0.8073 0.8800
epoch 1600 LossPred 0.1599 LossAtt 0.3129 TrainAcc 0.9600 TestAcc 0.8138 0.8950
epoch 1700 LossPred 0.1581 LossAtt 0.3139 TrainAcc 0.9600 TestAcc 0.8148 0.8750
epoch 1800 LossPred 0.1547 LossAtt 0.3280 TrainAcc 0.9600 TestAcc 0.8206 0.8900
epoch 1900 LossPred 0.1590 LossAtt 0.3078 TrainAcc 0.9600 TestAcc 0.8151 0.8750
epoch 2000 LossPred 0.1503 LossAtt 0.3086 TrainAcc 0.9600 TestAcc 0.8118 0.9000
epoch 2100 LossPred 0.1531 LossAtt 0.3208 TrainAcc 0.9600 TestAcc 0.8088 0.8800
epoch 2200 LossPred 0.1457 LossAtt 0.3145 TrainAcc 0.9600 TestAcc 0.8121 0.8900
epoch 2300 LossPred 0.1437 LossAtt 0.3122 TrainAcc 0.9600 TestAcc 0.8123 0.9100
epoch 2400 LossPred 0.1838 LossAtt 0.3386 TrainAcc 0.9500 TestAcc 0.8111 0.9050
epoch 2500 LossPred 0.1435 LossAtt 0.3218 TrainAcc 0.9700 TestAcc 0.8146 0.9000
Optimization Finished!
********** replication  13  **********
epoch   0 LossPred 1.2139 LossAtt 1.0385 TrainAcc 0.4200 TestAcc 0.4414 0.4200
epoch 100 LossPred 0.9072 LossAtt 0.3921 TrainAcc 0.6300 TestAcc 0.5763 0.6350
epoch 200 LossPred 0.6080 LossAtt 0.4452 TrainAcc 0.8200 TestAcc 0.8123 0.7800
epoch 300 LossPred 0.3970 LossAtt 0.4321 TrainAcc 0.8800 TestAcc 0.8606 0.8550
epoch 400 LossPred 0.4024 LossAtt 0.4493 TrainAcc 0.8700 TestAcc 0.8629 0.8650
epoch 500 LossPred 0.2842 LossAtt 0.4632 TrainAcc 0.8900 TestAcc 0.8829 0.8950
epoch 600 LossPred 0.2314 LossAtt 0.4722 TrainAcc 0.9600 TestAcc 0.8664 0.9100
epoch 700 LossPred 0.2322 LossAtt 0.4836 TrainAcc 0.9600 TestAcc 0.8431 0.9000
epoch 800 LossPred 0.1596 LossAtt 0.4722 TrainAcc 0.9500 TestAcc 0.8764 0.9250
epoch 900 LossPred 0.1853 LossAtt 0.4776 TrainAcc 0.9400 TestAcc 0.8826 0.9150
epoch 1000 LossPred 0.1349 LossAtt 0.4721 TrainAcc 0.9700 TestAcc 0.8769 0.9400
epoch 1100 LossPred 0.1559 LossAtt 0.4615 TrainAcc 0.9600 TestAcc 0.8764 0.9300
epoch 1200 LossPred 0.1171 LossAtt 0.4585 TrainAcc 0.9800 TestAcc 0.8599 0.9250
epoch 1300 LossPred 0.1198 LossAtt 0.4466 TrainAcc 0.9800 TestAcc 0.8561 0.9300
epoch 1400 LossPred 0.0960 LossAtt 0.4412 TrainAcc 0.9800 TestAcc 0.8571 0.9400
epoch 1500 LossPred 0.0883 LossAtt 0.4281 TrainAcc 0.9800 TestAcc 0.8631 0.9350
epoch 1600 LossPred 0.0862 LossAtt 0.4201 TrainAcc 0.9800 TestAcc 0.8571 0.9400
epoch 1700 LossPred 0.0919 LossAtt 0.4219 TrainAcc 0.9800 TestAcc 0.8746 0.9450
epoch 1800 LossPred 0.0694 LossAtt 0.4274 TrainAcc 0.9800 TestAcc 0.8536 0.9550
epoch 1900 LossPred 0.0689 LossAtt 0.4242 TrainAcc 0.9800 TestAcc 0.8511 0.9400
epoch 2000 LossPred 0.0643 LossAtt 0.4323 TrainAcc 0.9900 TestAcc 0.8496 0.9400
epoch 2100 LossPred 0.0572 LossAtt 0.4311 TrainAcc 0.9900 TestAcc 0.8606 0.9500
epoch 2200 LossPred 0.0565 LossAtt 0.4051 TrainAcc 0.9900 TestAcc 0.8519 0.9550
epoch 2300 LossPred 0.0624 LossAtt 0.4162 TrainAcc 0.9900 TestAcc 0.8639 0.9550
epoch 2400 LossPred 0.0548 LossAtt 0.4080 TrainAcc 0.9900 TestAcc 0.8579 0.9400
epoch 2500 LossPred 0.0488 LossAtt 0.4202 TrainAcc 0.9900 TestAcc 0.8564 0.9550
Optimization Finished!
********** replication  14  **********
epoch   0 LossPred 1.0911 LossAtt 1.0185 TrainAcc 0.4300 TestAcc 0.4640 0.4600
epoch 100 LossPred 0.8530 LossAtt 0.3663 TrainAcc 0.6800 TestAcc 0.6034 0.6650
epoch 200 LossPred 0.7965 LossAtt 0.3374 TrainAcc 0.6800 TestAcc 0.7095 0.6950
epoch 300 LossPred 0.5848 LossAtt 0.2806 TrainAcc 0.8400 TestAcc 0.7640 0.7900
epoch 400 LossPred 0.4004 LossAtt 0.2524 TrainAcc 0.8900 TestAcc 0.8263 0.8400
epoch 500 LossPred 0.4414 LossAtt 0.2521 TrainAcc 0.8700 TestAcc 0.8118 0.8250
epoch 600 LossPred 0.3532 LossAtt 0.2256 TrainAcc 0.8800 TestAcc 0.8258 0.8550
epoch 700 LossPred 0.3510 LossAtt 0.2249 TrainAcc 0.8800 TestAcc 0.8168 0.8550
epoch 800 LossPred 0.3759 LossAtt 0.2147 TrainAcc 0.8900 TestAcc 0.8146 0.8450
epoch 900 LossPred 0.3844 LossAtt 0.2219 TrainAcc 0.8800 TestAcc 0.8106 0.8450
epoch 1000 LossPred 0.4149 LossAtt 0.2143 TrainAcc 0.8600 TestAcc 0.7993 0.8300
epoch 1100 LossPred 0.3753 LossAtt 0.2221 TrainAcc 0.8800 TestAcc 0.7865 0.8000
epoch 1200 LossPred 0.3486 LossAtt 0.2068 TrainAcc 0.9000 TestAcc 0.7868 0.8400
epoch 1300 LossPred 0.4174 LossAtt 0.2089 TrainAcc 0.8500 TestAcc 0.7958 0.8500
epoch 1400 LossPred 0.3396 LossAtt 0.1862 TrainAcc 0.8900 TestAcc 0.7903 0.8300
epoch 1500 LossPred 0.5190 LossAtt 0.1925 TrainAcc 0.8300 TestAcc 0.7768 0.8050
epoch 1600 LossPred 0.5977 LossAtt 0.2327 TrainAcc 0.7900 TestAcc 0.7578 0.7800
epoch 1700 LossPred 0.3621 LossAtt 0.2058 TrainAcc 0.8900 TestAcc 0.7913 0.8250
epoch 1800 LossPred 0.6990 LossAtt 0.2254 TrainAcc 0.7500 TestAcc 0.7295 0.7300
epoch 1900 LossPred 0.4387 LossAtt 0.2064 TrainAcc 0.8700 TestAcc 0.7763 0.8200
epoch 2000 LossPred 1.0235 LossAtt 0.2658 TrainAcc 0.6500 TestAcc 0.6539 0.6350
epoch 2100 LossPred 0.7714 LossAtt 0.2304 TrainAcc 0.6700 TestAcc 0.6872 0.6750
epoch 2200 LossPred 0.4671 LossAtt 0.2101 TrainAcc 0.8700 TestAcc 0.7840 0.8200
epoch 2300 LossPred 0.3401 LossAtt 0.2147 TrainAcc 0.9000 TestAcc 0.8103 0.8450
epoch 2400 LossPred 0.3516 LossAtt 0.2041 TrainAcc 0.8900 TestAcc 0.7955 0.8250
epoch 2500 LossPred 0.3521 LossAtt 0.1919 TrainAcc 0.8900 TestAcc 0.7928 0.8400
Optimization Finished!
********** replication  15  **********
epoch   0 LossPred 1.0699 LossAtt 1.0304 TrainAcc 0.5700 TestAcc 0.5758 0.5450
epoch 100 LossPred 0.9011 LossAtt 0.2559 TrainAcc 0.6300 TestAcc 0.5826 0.6300
epoch 200 LossPred 0.7944 LossAtt 0.2630 TrainAcc 0.7100 TestAcc 0.6569 0.7150
epoch 300 LossPred 0.4117 LossAtt 0.2638 TrainAcc 0.8600 TestAcc 0.7973 0.8600
epoch 400 LossPred 0.4146 LossAtt 0.2397 TrainAcc 0.8400 TestAcc 0.8136 0.8450
epoch 500 LossPred 0.3573 LossAtt 0.2267 TrainAcc 0.8900 TestAcc 0.8091 0.8400
epoch 600 LossPred 0.3330 LossAtt 0.2227 TrainAcc 0.8900 TestAcc 0.8321 0.8800
epoch 700 LossPred 0.3425 LossAtt 0.2226 TrainAcc 0.8900 TestAcc 0.8261 0.8650
epoch 800 LossPred 0.3659 LossAtt 0.2270 TrainAcc 0.8600 TestAcc 0.7910 0.8050
epoch 900 LossPred 0.3333 LossAtt 0.2077 TrainAcc 0.9000 TestAcc 0.8108 0.8550
epoch 1000 LossPred 0.3207 LossAtt 0.2180 TrainAcc 0.9100 TestAcc 0.8321 0.8850
epoch 1100 LossPred 0.3276 LossAtt 0.2101 TrainAcc 0.9000 TestAcc 0.8166 0.8600
epoch 1200 LossPred 0.4448 LossAtt 0.2024 TrainAcc 0.8400 TestAcc 0.7680 0.7900
epoch 1300 LossPred 0.2443 LossAtt 0.2075 TrainAcc 0.9400 TestAcc 0.8286 0.8950
epoch 1400 LossPred 0.4386 LossAtt 0.2083 TrainAcc 0.8600 TestAcc 0.7855 0.8400
epoch 1500 LossPred 0.2914 LossAtt 0.2011 TrainAcc 0.9100 TestAcc 0.8331 0.9050
epoch 1600 LossPred 0.7740 LossAtt 0.1975 TrainAcc 0.7300 TestAcc 0.7698 0.8050
epoch 1700 LossPred 0.2730 LossAtt 0.1953 TrainAcc 0.9100 TestAcc 0.8271 0.8700
epoch 1800 LossPred 0.3473 LossAtt 0.1984 TrainAcc 0.8700 TestAcc 0.8058 0.8250
epoch 1900 LossPred 0.2651 LossAtt 0.2129 TrainAcc 0.9200 TestAcc 0.8353 0.8700
epoch 2000 LossPred 0.2980 LossAtt 0.2276 TrainAcc 0.9100 TestAcc 0.8336 0.8700
epoch 2100 LossPred 0.2981 LossAtt 0.2329 TrainAcc 0.9200 TestAcc 0.8393 0.8750
epoch 2200 LossPred 0.4603 LossAtt 0.2303 TrainAcc 0.8400 TestAcc 0.7695 0.8150
epoch 2300 LossPred 0.5087 LossAtt 0.2498 TrainAcc 0.8200 TestAcc 0.8253 0.8250
epoch 2400 LossPred 0.3093 LossAtt 0.2370 TrainAcc 0.8900 TestAcc 0.8118 0.8600
epoch 2500 LossPred 0.5574 LossAtt 0.2474 TrainAcc 0.8100 TestAcc 0.8256 0.8250
Optimization Finished!
********** replication  16  **********
epoch   0 LossPred 1.0348 LossAtt 0.9871 TrainAcc 0.5900 TestAcc 0.5045 0.5900
epoch 100 LossPred 0.9117 LossAtt 0.3432 TrainAcc 0.6200 TestAcc 0.5833 0.6100
epoch 200 LossPred 0.8908 LossAtt 0.2857 TrainAcc 0.6400 TestAcc 0.6064 0.6750
epoch 300 LossPred 0.3623 LossAtt 0.3897 TrainAcc 0.9000 TestAcc 0.8026 0.8850
epoch 400 LossPred 0.3411 LossAtt 0.3683 TrainAcc 0.9100 TestAcc 0.8096 0.9000
epoch 500 LossPred 0.3702 LossAtt 0.3502 TrainAcc 0.8800 TestAcc 0.8103 0.8750
epoch 600 LossPred 0.4111 LossAtt 0.3307 TrainAcc 0.8700 TestAcc 0.8048 0.8450
epoch 700 LossPred 0.3086 LossAtt 0.3331 TrainAcc 0.9200 TestAcc 0.8333 0.8900
epoch 800 LossPred 0.3200 LossAtt 0.3195 TrainAcc 0.9100 TestAcc 0.8261 0.8800
epoch 900 LossPred 0.3027 LossAtt 0.3167 TrainAcc 0.9200 TestAcc 0.8388 0.8800
epoch 1000 LossPred 0.3095 LossAtt 0.3136 TrainAcc 0.9100 TestAcc 0.8381 0.8550
epoch 1100 LossPred 0.2864 LossAtt 0.3056 TrainAcc 0.9200 TestAcc 0.8441 0.8650
epoch 1200 LossPred 0.2452 LossAtt 0.3123 TrainAcc 0.9300 TestAcc 0.8569 0.8850
epoch 1300 LossPred 0.2901 LossAtt 0.3034 TrainAcc 0.9400 TestAcc 0.8584 0.8650
epoch 1400 LossPred 0.2537 LossAtt 0.3077 TrainAcc 0.9100 TestAcc 0.8529 0.8800
epoch 1500 LossPred 0.2228 LossAtt 0.3013 TrainAcc 0.9300 TestAcc 0.8521 0.9000
epoch 1600 LossPred 0.2049 LossAtt 0.3082 TrainAcc 0.9500 TestAcc 0.8756 0.8850
epoch 1700 LossPred 0.1812 LossAtt 0.2976 TrainAcc 0.9400 TestAcc 0.8629 0.9050
epoch 1800 LossPred 0.1436 LossAtt 0.2921 TrainAcc 0.9600 TestAcc 0.8784 0.9250
epoch 1900 LossPred 0.1614 LossAtt 0.2830 TrainAcc 0.9500 TestAcc 0.8666 0.9200
epoch 2000 LossPred 0.1372 LossAtt 0.3051 TrainAcc 0.9600 TestAcc 0.8696 0.9300
epoch 2100 LossPred 0.1268 LossAtt 0.2883 TrainAcc 0.9700 TestAcc 0.8751 0.9350
epoch 2200 LossPred 0.1388 LossAtt 0.2817 TrainAcc 0.9700 TestAcc 0.8834 0.9400
epoch 2300 LossPred 0.1392 LossAtt 0.2825 TrainAcc 0.9700 TestAcc 0.8836 0.9500
epoch 2400 LossPred 0.1117 LossAtt 0.2739 TrainAcc 0.9700 TestAcc 0.8759 0.9450
epoch 2500 LossPred 0.1695 LossAtt 0.2809 TrainAcc 0.9500 TestAcc 0.8531 0.9300
Optimization Finished!
********** replication  17  **********
epoch   0 LossPred 1.0136 LossAtt 1.0317 TrainAcc 0.5300 TestAcc 0.4710 0.5200
epoch 100 LossPred 0.9655 LossAtt 0.3737 TrainAcc 0.5600 TestAcc 0.4700 0.5350
epoch 200 LossPred 0.8727 LossAtt 0.4137 TrainAcc 0.6400 TestAcc 0.5516 0.6050
epoch 300 LossPred 0.4395 LossAtt 0.3818 TrainAcc 0.9000 TestAcc 0.8121 0.8600
epoch 400 LossPred 0.3691 LossAtt 0.3802 TrainAcc 0.9100 TestAcc 0.8323 0.8950
epoch 500 LossPred 0.3221 LossAtt 0.3669 TrainAcc 0.9100 TestAcc 0.8416 0.8850
epoch 600 LossPred 0.2612 LossAtt 0.4083 TrainAcc 0.9300 TestAcc 0.8576 0.9050
epoch 700 LossPred 0.1933 LossAtt 0.4264 TrainAcc 0.9600 TestAcc 0.8654 0.9250
epoch 800 LossPred 0.1547 LossAtt 0.4276 TrainAcc 0.9500 TestAcc 0.8504 0.9050
epoch 900 LossPred 0.1148 LossAtt 0.4284 TrainAcc 0.9800 TestAcc 0.8619 0.9400
epoch 1000 LossPred 0.1033 LossAtt 0.4382 TrainAcc 0.9800 TestAcc 0.8624 0.9400
epoch 1100 LossPred 0.1091 LossAtt 0.4260 TrainAcc 0.9800 TestAcc 0.8636 0.9350
epoch 1200 LossPred 0.0904 LossAtt 0.4270 TrainAcc 0.9800 TestAcc 0.8671 0.9400
epoch 1300 LossPred 0.0785 LossAtt 0.4158 TrainAcc 0.9800 TestAcc 0.8641 0.9400
epoch 1400 LossPred 0.1348 LossAtt 0.4170 TrainAcc 0.9600 TestAcc 0.8591 0.9200
epoch 1500 LossPred 0.1005 LossAtt 0.3956 TrainAcc 0.9800 TestAcc 0.8616 0.9250
epoch 1600 LossPred 0.0850 LossAtt 0.3993 TrainAcc 0.9800 TestAcc 0.8594 0.9600
epoch 1700 LossPred 0.1115 LossAtt 0.3880 TrainAcc 0.9700 TestAcc 0.8551 0.9450
epoch 1800 LossPred 0.1598 LossAtt 0.3973 TrainAcc 0.9600 TestAcc 0.8418 0.9350
epoch 1900 LossPred 0.0689 LossAtt 0.3920 TrainAcc 0.9800 TestAcc 0.8576 0.9500
epoch 2000 LossPred 0.0658 LossAtt 0.3756 TrainAcc 0.9900 TestAcc 0.8596 0.9550
epoch 2100 LossPred 0.1184 LossAtt 0.3834 TrainAcc 0.9700 TestAcc 0.8674 0.9600
epoch 2200 LossPred 0.0862 LossAtt 0.3715 TrainAcc 0.9800 TestAcc 0.8561 0.9650
epoch 2300 LossPred 0.0677 LossAtt 0.3809 TrainAcc 0.9800 TestAcc 0.8566 0.9600
epoch 2400 LossPred 0.0654 LossAtt 0.3805 TrainAcc 0.9900 TestAcc 0.8579 0.9700
epoch 2500 LossPred 0.0612 LossAtt 0.3799 TrainAcc 0.9900 TestAcc 0.8531 0.9550
Optimization Finished!
********** replication  18  **********
epoch   0 LossPred 1.0095 LossAtt 1.0435 TrainAcc 0.4800 TestAcc 0.4762 0.4900
epoch 100 LossPred 0.8276 LossAtt 0.3353 TrainAcc 0.6600 TestAcc 0.6376 0.6750
epoch 200 LossPred 0.5236 LossAtt 0.2915 TrainAcc 0.8200 TestAcc 0.8118 0.8000
epoch 300 LossPred 0.4795 LossAtt 0.2758 TrainAcc 0.8500 TestAcc 0.8133 0.7900
epoch 400 LossPred 0.4620 LossAtt 0.2529 TrainAcc 0.8500 TestAcc 0.8246 0.8050
epoch 500 LossPred 0.4688 LossAtt 0.2683 TrainAcc 0.8400 TestAcc 0.8181 0.7900
epoch 600 LossPred 0.3769 LossAtt 0.2748 TrainAcc 0.8800 TestAcc 0.7945 0.8150
epoch 700 LossPred 0.6488 LossAtt 0.2887 TrainAcc 0.7800 TestAcc 0.7322 0.7550
epoch 800 LossPred 0.3672 LossAtt 0.2771 TrainAcc 0.8700 TestAcc 0.8233 0.8400
epoch 900 LossPred 0.4411 LossAtt 0.2835 TrainAcc 0.8400 TestAcc 0.8273 0.8150
epoch 1000 LossPred 0.3734 LossAtt 0.2742 TrainAcc 0.8800 TestAcc 0.8148 0.8550
epoch 1100 LossPred 0.3790 LossAtt 0.2737 TrainAcc 0.8700 TestAcc 0.8141 0.8400
epoch 1200 LossPred 0.4734 LossAtt 0.2604 TrainAcc 0.8400 TestAcc 0.8048 0.8200
epoch 1300 LossPred 0.3459 LossAtt 0.2603 TrainAcc 0.8800 TestAcc 0.8153 0.8450
epoch 1400 LossPred 0.3080 LossAtt 0.2495 TrainAcc 0.9000 TestAcc 0.7983 0.8400
epoch 1500 LossPred 0.3671 LossAtt 0.2492 TrainAcc 0.9000 TestAcc 0.7913 0.8600
epoch 1600 LossPred 0.2977 LossAtt 0.2407 TrainAcc 0.9200 TestAcc 0.7820 0.8700
epoch 1700 LossPred 0.4090 LossAtt 0.2536 TrainAcc 0.8800 TestAcc 0.7948 0.8450
epoch 1800 LossPred 0.3173 LossAtt 0.2416 TrainAcc 0.9100 TestAcc 0.7930 0.8500
epoch 1900 LossPred 0.3097 LossAtt 0.2286 TrainAcc 0.9100 TestAcc 0.7855 0.8550
epoch 2000 LossPred 0.4845 LossAtt 0.2417 TrainAcc 0.8400 TestAcc 0.7700 0.7750
epoch 2100 LossPred 0.4218 LossAtt 0.2464 TrainAcc 0.8600 TestAcc 0.7890 0.8050
epoch 2200 LossPred 0.4236 LossAtt 0.2695 TrainAcc 0.8700 TestAcc 0.7865 0.8250
epoch 2300 LossPred 0.3129 LossAtt 0.2675 TrainAcc 0.9200 TestAcc 0.8001 0.8350
epoch 2400 LossPred 0.3586 LossAtt 0.2595 TrainAcc 0.9100 TestAcc 0.7823 0.8550
epoch 2500 LossPred 0.3096 LossAtt 0.2697 TrainAcc 0.9200 TestAcc 0.7888 0.8500
Optimization Finished!
********** replication  19  **********
epoch   0 LossPred 1.0221 LossAtt 1.0309 TrainAcc 0.4900 TestAcc 0.5018 0.5250
epoch 100 LossPred 0.9033 LossAtt 0.3654 TrainAcc 0.6000 TestAcc 0.6006 0.6200
epoch 200 LossPred 0.5087 LossAtt 0.3670 TrainAcc 0.8200 TestAcc 0.8393 0.8100
epoch 300 LossPred 0.4139 LossAtt 0.3587 TrainAcc 0.8600 TestAcc 0.8584 0.8250
epoch 400 LossPred 0.5084 LossAtt 0.3474 TrainAcc 0.8400 TestAcc 0.8081 0.8050
epoch 500 LossPred 0.3944 LossAtt 0.3477 TrainAcc 0.8700 TestAcc 0.8403 0.8250
epoch 600 LossPred 0.3499 LossAtt 0.3624 TrainAcc 0.8800 TestAcc 0.8786 0.8250
epoch 700 LossPred 0.2049 LossAtt 0.3594 TrainAcc 0.9300 TestAcc 0.8981 0.8750
epoch 800 LossPred 0.2102 LossAtt 0.3642 TrainAcc 0.9200 TestAcc 0.8969 0.8750
epoch 900 LossPred 0.2141 LossAtt 0.3614 TrainAcc 0.9400 TestAcc 0.9224 0.8600
epoch 1000 LossPred 0.2487 LossAtt 0.3544 TrainAcc 0.9000 TestAcc 0.8764 0.8600
epoch 1100 LossPred 0.2814 LossAtt 0.3588 TrainAcc 0.9000 TestAcc 0.8631 0.8650
epoch 1200 LossPred 0.1547 LossAtt 0.3561 TrainAcc 0.9400 TestAcc 0.9244 0.9100
epoch 1300 LossPred 0.1568 LossAtt 0.3569 TrainAcc 0.9500 TestAcc 0.9254 0.9050
epoch 1400 LossPred 0.1515 LossAtt 0.3431 TrainAcc 0.9600 TestAcc 0.9304 0.9100
epoch 1500 LossPred 0.1598 LossAtt 0.3394 TrainAcc 0.9400 TestAcc 0.9097 0.9100
epoch 1600 LossPred 0.1821 LossAtt 0.3201 TrainAcc 0.9400 TestAcc 0.8946 0.9000
epoch 1700 LossPred 0.1527 LossAtt 0.3376 TrainAcc 0.9300 TestAcc 0.9119 0.9000
epoch 1800 LossPred 0.1737 LossAtt 0.3205 TrainAcc 0.9500 TestAcc 0.9002 0.9050
epoch 1900 LossPred 0.1672 LossAtt 0.3207 TrainAcc 0.9300 TestAcc 0.9022 0.9050
epoch 2000 LossPred 0.1498 LossAtt 0.3186 TrainAcc 0.9500 TestAcc 0.9104 0.8950
epoch 2100 LossPred 0.1602 LossAtt 0.3084 TrainAcc 0.9400 TestAcc 0.9002 0.8950
epoch 2200 LossPred 0.1701 LossAtt 0.3049 TrainAcc 0.9400 TestAcc 0.8959 0.8950
epoch 2300 LossPred 0.1643 LossAtt 0.3125 TrainAcc 0.9400 TestAcc 0.9027 0.9000
epoch 2400 LossPred 0.1612 LossAtt 0.2998 TrainAcc 0.9400 TestAcc 0.9127 0.9000
epoch 2500 LossPred 0.2973 LossAtt 0.3091 TrainAcc 0.9000 TestAcc 0.8934 0.8800
Optimization Finished!
********** replication  20  **********
epoch   0 LossPred 0.8808 LossAtt 1.0483 TrainAcc 0.7000 TestAcc 0.5876 0.6850
epoch 100 LossPred 0.7292 LossAtt 0.4503 TrainAcc 0.7400 TestAcc 0.6034 0.7100
epoch 200 LossPred 0.6814 LossAtt 0.3962 TrainAcc 0.7600 TestAcc 0.5921 0.7450
epoch 300 LossPred 0.6573 LossAtt 0.4061 TrainAcc 0.7800 TestAcc 0.5981 0.7300
epoch 400 LossPred 0.6389 LossAtt 0.3991 TrainAcc 0.7800 TestAcc 0.5948 0.7550
epoch 500 LossPred 0.6301 LossAtt 0.3596 TrainAcc 0.7800 TestAcc 0.5973 0.7650
epoch 600 LossPred 0.6099 LossAtt 0.3743 TrainAcc 0.7900 TestAcc 0.5928 0.7650
epoch 700 LossPred 0.5622 LossAtt 0.4068 TrainAcc 0.8400 TestAcc 0.5986 0.8000
epoch 800 LossPred 0.5112 LossAtt 0.4763 TrainAcc 0.8400 TestAcc 0.5856 0.8050
epoch 900 LossPred 0.4083 LossAtt 0.5134 TrainAcc 0.9000 TestAcc 0.5891 0.8300
epoch 1000 LossPred 0.3227 LossAtt 0.5166 TrainAcc 0.9200 TestAcc 0.5846 0.8100
epoch 1100 LossPred 0.2648 LossAtt 0.4930 TrainAcc 0.9300 TestAcc 0.5831 0.8400
epoch 1200 LossPred 0.2480 LossAtt 0.5061 TrainAcc 0.9400 TestAcc 0.5821 0.8350
epoch 1300 LossPred 0.2368 LossAtt 0.5042 TrainAcc 0.9500 TestAcc 0.5801 0.8450
epoch 1400 LossPred 0.2273 LossAtt 0.4811 TrainAcc 0.9500 TestAcc 0.5816 0.8500
epoch 1500 LossPred 0.2324 LossAtt 0.4793 TrainAcc 0.9400 TestAcc 0.5811 0.8550
epoch 1600 LossPred 0.2068 LossAtt 0.4662 TrainAcc 0.9500 TestAcc 0.5821 0.8550
epoch 1700 LossPred 0.2068 LossAtt 0.4914 TrainAcc 0.9500 TestAcc 0.5841 0.8800
epoch 1800 LossPred 0.1999 LossAtt 0.4827 TrainAcc 0.9500 TestAcc 0.5791 0.8650
epoch 1900 LossPred 0.2002 LossAtt 0.4683 TrainAcc 0.9500 TestAcc 0.5783 0.8350
epoch 2000 LossPred 0.2349 LossAtt 0.4678 TrainAcc 0.9300 TestAcc 0.5883 0.8650
epoch 2100 LossPred 0.1976 LossAtt 0.4719 TrainAcc 0.9500 TestAcc 0.5826 0.8350
epoch 2200 LossPred 0.1846 LossAtt 0.4703 TrainAcc 0.9600 TestAcc 0.5786 0.8500
epoch 2300 LossPred 0.1816 LossAtt 0.4721 TrainAcc 0.9600 TestAcc 0.5801 0.8450
epoch 2400 LossPred 0.1855 LossAtt 0.4782 TrainAcc 0.9600 TestAcc 0.5781 0.8500
epoch 2500 LossPred 0.1773 LossAtt 0.4702 TrainAcc 0.9600 TestAcc 0.5758 0.8650
Optimization Finished!
********** replication  21  **********
epoch   0 LossPred 0.9615 LossAtt 1.0311 TrainAcc 0.6000 TestAcc 0.5098 0.5950
epoch 100 LossPred 0.7901 LossAtt 0.3858 TrainAcc 0.7100 TestAcc 0.6216 0.7100
epoch 200 LossPred 0.5301 LossAtt 0.5134 TrainAcc 0.8200 TestAcc 0.7170 0.7950
epoch 300 LossPred 0.4217 LossAtt 0.5360 TrainAcc 0.8600 TestAcc 0.7497 0.8300
epoch 400 LossPred 0.3452 LossAtt 0.5229 TrainAcc 0.9000 TestAcc 0.7718 0.8500
epoch 500 LossPred 0.2768 LossAtt 0.5230 TrainAcc 0.9200 TestAcc 0.7758 0.8600
epoch 600 LossPred 0.3223 LossAtt 0.5231 TrainAcc 0.8900 TestAcc 0.7575 0.8350
epoch 700 LossPred 0.2230 LossAtt 0.5017 TrainAcc 0.9400 TestAcc 0.7800 0.8500
epoch 800 LossPred 0.2139 LossAtt 0.5086 TrainAcc 0.9300 TestAcc 0.7765 0.8450
epoch 900 LossPred 0.1986 LossAtt 0.5122 TrainAcc 0.9500 TestAcc 0.7675 0.8500
epoch 1000 LossPred 0.1882 LossAtt 0.4821 TrainAcc 0.9600 TestAcc 0.7683 0.8700
epoch 1100 LossPred 0.1848 LossAtt 0.5010 TrainAcc 0.9600 TestAcc 0.7615 0.8600
epoch 1200 LossPred 0.1776 LossAtt 0.5017 TrainAcc 0.9600 TestAcc 0.7675 0.8500
epoch 1300 LossPred 0.1724 LossAtt 0.4900 TrainAcc 0.9600 TestAcc 0.7680 0.8650
epoch 1400 LossPred 0.1719 LossAtt 0.4847 TrainAcc 0.9600 TestAcc 0.7715 0.8600
epoch 1500 LossPred 0.1708 LossAtt 0.4803 TrainAcc 0.9600 TestAcc 0.7715 0.8800
epoch 1600 LossPred 0.1652 LossAtt 0.4764 TrainAcc 0.9600 TestAcc 0.7693 0.8900
epoch 1700 LossPred 0.1597 LossAtt 0.4585 TrainAcc 0.9600 TestAcc 0.7685 0.8800
epoch 1800 LossPred 0.1513 LossAtt 0.4489 TrainAcc 0.9600 TestAcc 0.7595 0.9050
epoch 1900 LossPred 0.1477 LossAtt 0.4382 TrainAcc 0.9600 TestAcc 0.7635 0.8950
epoch 2000 LossPred 0.1454 LossAtt 0.4414 TrainAcc 0.9600 TestAcc 0.7560 0.9000
epoch 2100 LossPred 0.1383 LossAtt 0.4370 TrainAcc 0.9600 TestAcc 0.7570 0.9050
epoch 2200 LossPred 0.1320 LossAtt 0.4148 TrainAcc 0.9700 TestAcc 0.7563 0.9050
epoch 2300 LossPred 0.1278 LossAtt 0.4171 TrainAcc 0.9700 TestAcc 0.7545 0.9100
epoch 2400 LossPred 0.1290 LossAtt 0.4362 TrainAcc 0.9700 TestAcc 0.7565 0.9150
epoch 2500 LossPred 0.1630 LossAtt 0.4224 TrainAcc 0.9600 TestAcc 0.7663 0.9000
Optimization Finished!
********** replication  22  **********
epoch   0 LossPred 1.0855 LossAtt 1.0053 TrainAcc 0.5000 TestAcc 0.5405 0.5000
epoch 100 LossPred 0.8959 LossAtt 0.3355 TrainAcc 0.6600 TestAcc 0.6044 0.6550
epoch 200 LossPred 0.3819 LossAtt 0.4204 TrainAcc 0.8900 TestAcc 0.8529 0.8650
epoch 300 LossPred 0.3046 LossAtt 0.4044 TrainAcc 0.9300 TestAcc 0.8453 0.8800
epoch 400 LossPred 0.2816 LossAtt 0.3928 TrainAcc 0.9300 TestAcc 0.8368 0.8800
epoch 500 LossPred 0.2821 LossAtt 0.3779 TrainAcc 0.9300 TestAcc 0.8318 0.8900
epoch 600 LossPred 0.2993 LossAtt 0.3827 TrainAcc 0.9100 TestAcc 0.8213 0.9000
epoch 700 LossPred 0.3229 LossAtt 0.3861 TrainAcc 0.9100 TestAcc 0.8401 0.8700
epoch 800 LossPred 0.2451 LossAtt 0.3775 TrainAcc 0.9200 TestAcc 0.8328 0.8850
epoch 900 LossPred 0.2091 LossAtt 0.3845 TrainAcc 0.9400 TestAcc 0.8301 0.8850
epoch 1000 LossPred 0.2170 LossAtt 0.3793 TrainAcc 0.9400 TestAcc 0.8311 0.8850
epoch 1100 LossPred 0.2588 LossAtt 0.3680 TrainAcc 0.9200 TestAcc 0.7905 0.8950
epoch 1200 LossPred 0.2111 LossAtt 0.3702 TrainAcc 0.9400 TestAcc 0.8111 0.8900
epoch 1300 LossPred 0.1915 LossAtt 0.3676 TrainAcc 0.9500 TestAcc 0.8273 0.8800
epoch 1400 LossPred 0.2653 LossAtt 0.3729 TrainAcc 0.9100 TestAcc 0.8241 0.8750
epoch 1500 LossPred 0.2286 LossAtt 0.3786 TrainAcc 0.9400 TestAcc 0.8098 0.8950
epoch 1600 LossPred 0.2756 LossAtt 0.3791 TrainAcc 0.9100 TestAcc 0.7928 0.8950
epoch 1700 LossPred 0.2539 LossAtt 0.3843 TrainAcc 0.9200 TestAcc 0.7975 0.8850
epoch 1800 LossPred 0.1825 LossAtt 0.3685 TrainAcc 0.9500 TestAcc 0.8331 0.8700
epoch 1900 LossPred 0.1773 LossAtt 0.3729 TrainAcc 0.9500 TestAcc 0.8158 0.8750
epoch 2000 LossPred 0.2434 LossAtt 0.3810 TrainAcc 0.9200 TestAcc 0.7918 0.8900
epoch 2100 LossPred 0.2334 LossAtt 0.3833 TrainAcc 0.9300 TestAcc 0.8301 0.8800
epoch 2200 LossPred 0.1951 LossAtt 0.3811 TrainAcc 0.9400 TestAcc 0.8161 0.8700
epoch 2300 LossPred 0.1533 LossAtt 0.3794 TrainAcc 0.9600 TestAcc 0.8268 0.8800
epoch 2400 LossPred 0.1718 LossAtt 0.3802 TrainAcc 0.9500 TestAcc 0.8286 0.8900
epoch 2500 LossPred 0.1589 LossAtt 0.3542 TrainAcc 0.9600 TestAcc 0.8263 0.8900
Optimization Finished!
********** replication  23  **********
epoch   0 LossPred 1.0381 LossAtt 1.0255 TrainAcc 0.5500 TestAcc 0.5403 0.5400
epoch 100 LossPred 0.9259 LossAtt 0.2758 TrainAcc 0.6200 TestAcc 0.5340 0.6150
epoch 200 LossPred 0.8329 LossAtt 0.3757 TrainAcc 0.6700 TestAcc 0.5395 0.6500
epoch 300 LossPred 0.4164 LossAtt 0.5164 TrainAcc 0.8600 TestAcc 0.8769 0.8100
epoch 400 LossPred 0.2490 LossAtt 0.4611 TrainAcc 0.9300 TestAcc 0.8751 0.8900
epoch 500 LossPred 0.1924 LossAtt 0.4770 TrainAcc 0.9400 TestAcc 0.8751 0.9000
epoch 600 LossPred 0.1432 LossAtt 0.4760 TrainAcc 0.9700 TestAcc 0.8659 0.8950
epoch 700 LossPred 0.1241 LossAtt 0.4687 TrainAcc 0.9700 TestAcc 0.8631 0.9150
epoch 800 LossPred 0.1852 LossAtt 0.4473 TrainAcc 0.9400 TestAcc 0.8483 0.9300
epoch 900 LossPred 0.1034 LossAtt 0.4664 TrainAcc 0.9800 TestAcc 0.8539 0.9350
epoch 1000 LossPred 0.1222 LossAtt 0.4571 TrainAcc 0.9700 TestAcc 0.8551 0.9200
epoch 1100 LossPred 0.1035 LossAtt 0.4453 TrainAcc 0.9600 TestAcc 0.8488 0.9300
epoch 1200 LossPred 0.2933 LossAtt 0.4651 TrainAcc 0.9000 TestAcc 0.8448 0.8750
epoch 1300 LossPred 0.0926 LossAtt 0.4589 TrainAcc 0.9700 TestAcc 0.8488 0.9500
epoch 1400 LossPred 0.0518 LossAtt 0.4634 TrainAcc 1.0000 TestAcc 0.8546 0.9500
Optimization Finished!
********** replication  24  **********
epoch   0 LossPred 1.0555 LossAtt 1.0196 TrainAcc 0.5000 TestAcc 0.5501 0.5000
epoch 100 LossPred 0.9275 LossAtt 0.2548 TrainAcc 0.6300 TestAcc 0.5551 0.6250
epoch 200 LossPred 0.9123 LossAtt 0.2939 TrainAcc 0.6300 TestAcc 0.5551 0.6300
epoch 300 LossPred 0.8803 LossAtt 0.3577 TrainAcc 0.6300 TestAcc 0.5856 0.6300
epoch 400 LossPred 0.4606 LossAtt 0.4648 TrainAcc 0.8900 TestAcc 0.8113 0.8350
epoch 500 LossPred 0.2087 LossAtt 0.4674 TrainAcc 0.9400 TestAcc 0.8488 0.9000
epoch 600 LossPred 0.1500 LossAtt 0.4615 TrainAcc 0.9700 TestAcc 0.8539 0.9400
epoch 700 LossPred 0.1319 LossAtt 0.4464 TrainAcc 0.9700 TestAcc 0.8511 0.9350
epoch 800 LossPred 0.1168 LossAtt 0.4264 TrainAcc 0.9700 TestAcc 0.8531 0.9600
epoch 900 LossPred 0.0884 LossAtt 0.4223 TrainAcc 0.9900 TestAcc 0.8654 0.9600
epoch 1000 LossPred 0.1031 LossAtt 0.4095 TrainAcc 0.9700 TestAcc 0.8596 0.9800
epoch 1100 LossPred 0.0818 LossAtt 0.3956 TrainAcc 0.9900 TestAcc 0.8666 0.9650
epoch 1200 LossPred 0.0681 LossAtt 0.3987 TrainAcc 0.9900 TestAcc 0.8646 0.9800
epoch 1300 LossPred 0.0607 LossAtt 0.3947 TrainAcc 0.9900 TestAcc 0.8646 0.9800
epoch 1400 LossPred 0.0607 LossAtt 0.4025 TrainAcc 0.9800 TestAcc 0.8666 0.9750
epoch 1500 LossPred 0.0638 LossAtt 0.3963 TrainAcc 0.9900 TestAcc 0.8624 0.9800
epoch 1600 LossPred 0.0549 LossAtt 0.3870 TrainAcc 0.9900 TestAcc 0.8616 0.9700
epoch 1700 LossPred 0.0760 LossAtt 0.3959 TrainAcc 0.9700 TestAcc 0.8641 0.9700
epoch 1800 LossPred 0.0438 LossAtt 0.4019 TrainAcc 0.9900 TestAcc 0.8616 0.9850
epoch 1900 LossPred 0.0382 LossAtt 0.3893 TrainAcc 0.9900 TestAcc 0.8586 1.0000
epoch 2000 LossPred 0.0401 LossAtt 0.3956 TrainAcc 0.9900 TestAcc 0.8541 0.9900
epoch 2100 LossPred 0.0369 LossAtt 0.3991 TrainAcc 0.9900 TestAcc 0.8519 0.9950
epoch 2200 LossPred 0.0373 LossAtt 0.3898 TrainAcc 0.9900 TestAcc 0.8431 0.9900
epoch 2300 LossPred 0.0734 LossAtt 0.3929 TrainAcc 0.9800 TestAcc 0.8296 0.9750
epoch 2400 LossPred 0.0275 LossAtt 0.4015 TrainAcc 0.9900 TestAcc 0.8283 0.9900
epoch 2500 LossPred 0.0218 LossAtt 0.4053 TrainAcc 1.0000 TestAcc 0.8331 0.9900
Optimization Finished!
********** replication  25  **********
epoch   0 LossPred 1.0498 LossAtt 1.0315 TrainAcc 0.4400 TestAcc 0.4932 0.4400
epoch 100 LossPred 0.9573 LossAtt 0.2868 TrainAcc 0.6100 TestAcc 0.5548 0.6150
epoch 200 LossPred 0.9342 LossAtt 0.2709 TrainAcc 0.6000 TestAcc 0.5475 0.5800
epoch 300 LossPred 0.9068 LossAtt 0.3029 TrainAcc 0.6000 TestAcc 0.5438 0.5850
epoch 400 LossPred 0.8801 LossAtt 0.3043 TrainAcc 0.6500 TestAcc 0.5300 0.6250
epoch 500 LossPred 0.8736 LossAtt 0.2857 TrainAcc 0.6500 TestAcc 0.5333 0.6150
epoch 600 LossPred 0.8712 LossAtt 0.2550 TrainAcc 0.6500 TestAcc 0.5343 0.6250
epoch 700 LossPred 0.8790 LossAtt 0.3140 TrainAcc 0.6100 TestAcc 0.5360 0.5950
epoch 800 LossPred 0.8449 LossAtt 0.2996 TrainAcc 0.6700 TestAcc 0.5338 0.6200
epoch 900 LossPred 0.8369 LossAtt 0.2959 TrainAcc 0.6900 TestAcc 0.5220 0.6400
epoch 1000 LossPred 0.8124 LossAtt 0.3079 TrainAcc 0.7200 TestAcc 0.5220 0.6950
epoch 1100 LossPred 0.8000 LossAtt 0.3076 TrainAcc 0.7000 TestAcc 0.5060 0.6700
epoch 1200 LossPred 0.7843 LossAtt 0.3105 TrainAcc 0.7100 TestAcc 0.5140 0.6850
epoch 1300 LossPred 0.7510 LossAtt 0.3874 TrainAcc 0.7400 TestAcc 0.5185 0.7150
epoch 1400 LossPred 0.6771 LossAtt 0.4504 TrainAcc 0.7800 TestAcc 0.5325 0.7200
epoch 1500 LossPred 0.5941 LossAtt 0.4537 TrainAcc 0.8200 TestAcc 0.5385 0.7600
epoch 1600 LossPred 0.5385 LossAtt 0.4469 TrainAcc 0.8300 TestAcc 0.5420 0.7500
epoch 1700 LossPred 0.5108 LossAtt 0.4335 TrainAcc 0.8400 TestAcc 0.5423 0.7450
epoch 1800 LossPred 0.4920 LossAtt 0.4319 TrainAcc 0.8600 TestAcc 0.5478 0.7450
epoch 1900 LossPred 0.4675 LossAtt 0.4202 TrainAcc 0.8700 TestAcc 0.5415 0.7500
epoch 2000 LossPred 0.4508 LossAtt 0.4304 TrainAcc 0.8700 TestAcc 0.5430 0.7500
epoch 2100 LossPred 0.4249 LossAtt 0.4431 TrainAcc 0.8700 TestAcc 0.5440 0.7500
epoch 2200 LossPred 0.3865 LossAtt 0.4558 TrainAcc 0.9100 TestAcc 0.5433 0.7300
epoch 2300 LossPred 0.3680 LossAtt 0.4432 TrainAcc 0.9000 TestAcc 0.5395 0.7500
epoch 2400 LossPred 0.3441 LossAtt 0.4374 TrainAcc 0.9200 TestAcc 0.5400 0.7700
epoch 2500 LossPred 0.3453 LossAtt 0.4460 TrainAcc 0.9200 TestAcc 0.5383 0.7500
Optimization Finished!
********** replication  26  **********
epoch   0 LossPred 0.9980 LossAtt 1.0196 TrainAcc 0.5100 TestAcc 0.4660 0.4950
epoch 100 LossPred 0.8460 LossAtt 0.3791 TrainAcc 0.6700 TestAcc 0.5971 0.6650
epoch 200 LossPred 0.7916 LossAtt 0.3876 TrainAcc 0.7000 TestAcc 0.5661 0.6850
epoch 300 LossPred 0.7062 LossAtt 0.4377 TrainAcc 0.7500 TestAcc 0.5661 0.7400
epoch 400 LossPred 0.5760 LossAtt 0.4610 TrainAcc 0.7800 TestAcc 0.5523 0.7750
epoch 500 LossPred 0.5063 LossAtt 0.4463 TrainAcc 0.8400 TestAcc 0.5568 0.8150
epoch 600 LossPred 0.4851 LossAtt 0.4348 TrainAcc 0.8400 TestAcc 0.5661 0.7850
epoch 700 LossPred 0.4617 LossAtt 0.4361 TrainAcc 0.8400 TestAcc 0.5591 0.7850
epoch 800 LossPred 0.4423 LossAtt 0.4434 TrainAcc 0.8400 TestAcc 0.5661 0.7900
epoch 900 LossPred 0.4525 LossAtt 0.4600 TrainAcc 0.8400 TestAcc 0.5706 0.7850
epoch 1000 LossPred 0.4153 LossAtt 0.4535 TrainAcc 0.8500 TestAcc 0.5656 0.8050
epoch 1100 LossPred 0.3888 LossAtt 0.4464 TrainAcc 0.8600 TestAcc 0.5636 0.7800
epoch 1200 LossPred 0.4564 LossAtt 0.4651 TrainAcc 0.8300 TestAcc 0.5638 0.7950
epoch 1300 LossPred 0.3812 LossAtt 0.4284 TrainAcc 0.8500 TestAcc 0.5621 0.7950
epoch 1400 LossPred 0.4132 LossAtt 0.4419 TrainAcc 0.8500 TestAcc 0.5593 0.8000
epoch 1500 LossPred 0.3900 LossAtt 0.4495 TrainAcc 0.8800 TestAcc 0.5636 0.7900
epoch 1600 LossPred 0.3843 LossAtt 0.4438 TrainAcc 0.8700 TestAcc 0.5663 0.7900
epoch 1700 LossPred 0.6951 LossAtt 0.4818 TrainAcc 0.7300 TestAcc 0.5693 0.7600
epoch 1800 LossPred 0.4683 LossAtt 0.4416 TrainAcc 0.8300 TestAcc 0.5673 0.7800
epoch 1900 LossPred 0.4417 LossAtt 0.4410 TrainAcc 0.8300 TestAcc 0.5731 0.8050
epoch 2000 LossPred 0.4370 LossAtt 0.4154 TrainAcc 0.8200 TestAcc 0.5783 0.8050
epoch 2100 LossPred 0.3822 LossAtt 0.4264 TrainAcc 0.8600 TestAcc 0.5786 0.8200
epoch 2200 LossPred 0.4387 LossAtt 0.4404 TrainAcc 0.8400 TestAcc 0.5753 0.7850
epoch 2300 LossPred 0.4058 LossAtt 0.4221 TrainAcc 0.8800 TestAcc 0.5721 0.8050
epoch 2400 LossPred 0.4303 LossAtt 0.4293 TrainAcc 0.8500 TestAcc 0.5743 0.8000
epoch 2500 LossPred 0.4582 LossAtt 0.4090 TrainAcc 0.8700 TestAcc 0.5475 0.7950
Optimization Finished!
********** replication  27  **********
epoch   0 LossPred 1.1805 LossAtt 1.0200 TrainAcc 0.4000 TestAcc 0.4369 0.3950
epoch 100 LossPred 0.9599 LossAtt 0.2835 TrainAcc 0.5800 TestAcc 0.5270 0.5850
epoch 200 LossPred 0.9448 LossAtt 0.2842 TrainAcc 0.6200 TestAcc 0.5536 0.6450
epoch 300 LossPred 0.8853 LossAtt 0.3990 TrainAcc 0.6600 TestAcc 0.5596 0.6650
epoch 400 LossPred 0.4539 LossAtt 0.4782 TrainAcc 0.8600 TestAcc 0.8068 0.8250
epoch 500 LossPred 0.2823 LossAtt 0.4580 TrainAcc 0.9100 TestAcc 0.8186 0.8550
epoch 600 LossPred 0.2212 LossAtt 0.4519 TrainAcc 0.9300 TestAcc 0.8256 0.8900
epoch 700 LossPred 0.1902 LossAtt 0.4381 TrainAcc 0.9300 TestAcc 0.8333 0.9050
epoch 800 LossPred 0.1620 LossAtt 0.4401 TrainAcc 0.9600 TestAcc 0.8363 0.9200
epoch 900 LossPred 0.1478 LossAtt 0.4320 TrainAcc 0.9600 TestAcc 0.8408 0.9300
epoch 1000 LossPred 0.1456 LossAtt 0.4420 TrainAcc 0.9500 TestAcc 0.8451 0.9300
epoch 1100 LossPred 0.1271 LossAtt 0.4301 TrainAcc 0.9600 TestAcc 0.8416 0.9450
epoch 1200 LossPred 0.1182 LossAtt 0.4305 TrainAcc 0.9600 TestAcc 0.8426 0.9450
epoch 1300 LossPred 0.1163 LossAtt 0.4413 TrainAcc 0.9500 TestAcc 0.8471 0.9500
epoch 1400 LossPred 0.1057 LossAtt 0.4264 TrainAcc 0.9600 TestAcc 0.8448 0.9500
epoch 1500 LossPred 0.1097 LossAtt 0.4277 TrainAcc 0.9500 TestAcc 0.8481 0.9600
epoch 1600 LossPred 0.0918 LossAtt 0.4230 TrainAcc 0.9600 TestAcc 0.8483 0.9650
epoch 1700 LossPred 0.0931 LossAtt 0.4171 TrainAcc 0.9500 TestAcc 0.8448 0.9650
epoch 1800 LossPred 0.0793 LossAtt 0.4272 TrainAcc 0.9700 TestAcc 0.8486 0.9600
epoch 1900 LossPred 0.0787 LossAtt 0.4115 TrainAcc 0.9800 TestAcc 0.8534 0.9550
epoch 2000 LossPred 0.0724 LossAtt 0.4037 TrainAcc 0.9700 TestAcc 0.8451 0.9650
epoch 2100 LossPred 0.0855 LossAtt 0.4028 TrainAcc 0.9800 TestAcc 0.8446 0.9600
epoch 2200 LossPred 0.0601 LossAtt 0.4013 TrainAcc 0.9800 TestAcc 0.8448 0.9650
epoch 2300 LossPred 0.0556 LossAtt 0.4133 TrainAcc 0.9700 TestAcc 0.8461 0.9750
epoch 2400 LossPred 0.0879 LossAtt 0.4024 TrainAcc 0.9700 TestAcc 0.8341 0.9450
epoch 2500 LossPred 0.0626 LossAtt 0.4036 TrainAcc 0.9800 TestAcc 0.8351 0.9600
Optimization Finished!
********** replication  28  **********
epoch   0 LossPred 1.1954 LossAtt 1.0185 TrainAcc 0.4400 TestAcc 0.4224 0.4750
epoch 100 LossPred 0.8769 LossAtt 0.3920 TrainAcc 0.6400 TestAcc 0.5831 0.6500
epoch 200 LossPred 0.4976 LossAtt 0.4290 TrainAcc 0.8800 TestAcc 0.8151 0.8400
epoch 300 LossPred 0.3010 LossAtt 0.4194 TrainAcc 0.9100 TestAcc 0.8634 0.8600
epoch 400 LossPred 0.3938 LossAtt 0.4057 TrainAcc 0.8700 TestAcc 0.8166 0.8400
epoch 500 LossPred 0.2598 LossAtt 0.3981 TrainAcc 0.9100 TestAcc 0.8689 0.8900
epoch 600 LossPred 0.2612 LossAtt 0.3889 TrainAcc 0.9100 TestAcc 0.8651 0.8900
epoch 700 LossPred 0.1963 LossAtt 0.3881 TrainAcc 0.9400 TestAcc 0.8869 0.8900
epoch 800 LossPred 0.1960 LossAtt 0.3437 TrainAcc 0.9300 TestAcc 0.8861 0.9250
epoch 900 LossPred 0.1915 LossAtt 0.3450 TrainAcc 0.9400 TestAcc 0.8809 0.9250
epoch 1000 LossPred 0.1456 LossAtt 0.3515 TrainAcc 0.9700 TestAcc 0.8919 0.9700
epoch 1100 LossPred 0.1633 LossAtt 0.3408 TrainAcc 0.9400 TestAcc 0.8894 0.9250
epoch 1200 LossPred 0.1317 LossAtt 0.3445 TrainAcc 0.9700 TestAcc 0.8954 0.9700
epoch 1300 LossPred 0.2360 LossAtt 0.3469 TrainAcc 0.9100 TestAcc 0.8819 0.9150
epoch 1400 LossPred 0.1200 LossAtt 0.3433 TrainAcc 0.9700 TestAcc 0.8991 0.9650
epoch 1500 LossPred 0.1090 LossAtt 0.3280 TrainAcc 0.9700 TestAcc 0.8996 0.9650
epoch 1600 LossPred 0.1730 LossAtt 0.3420 TrainAcc 0.9500 TestAcc 0.8906 0.9450
epoch 1700 LossPred 0.1120 LossAtt 0.3298 TrainAcc 0.9700 TestAcc 0.9044 0.9600
epoch 1800 LossPred 0.1717 LossAtt 0.3214 TrainAcc 0.9300 TestAcc 0.8866 0.9400
epoch 1900 LossPred 0.1278 LossAtt 0.3224 TrainAcc 0.9600 TestAcc 0.9042 0.9700
epoch 2000 LossPred 0.1199 LossAtt 0.3313 TrainAcc 0.9500 TestAcc 0.9044 0.9500
epoch 2100 LossPred 0.1135 LossAtt 0.3232 TrainAcc 0.9600 TestAcc 0.9034 0.9700
epoch 2200 LossPred 0.0963 LossAtt 0.3147 TrainAcc 0.9800 TestAcc 0.9027 0.9750
epoch 2300 LossPred 0.1119 LossAtt 0.3037 TrainAcc 0.9600 TestAcc 0.9012 0.9700
epoch 2400 LossPred 0.1149 LossAtt 0.3187 TrainAcc 0.9700 TestAcc 0.9062 0.9700
epoch 2500 LossPred 0.1004 LossAtt 0.3121 TrainAcc 0.9800 TestAcc 0.9072 0.9800
Optimization Finished!
********** replication  29  **********
epoch   0 LossPred 1.0350 LossAtt 1.0529 TrainAcc 0.4100 TestAcc 0.5005 0.4100
epoch 100 LossPred 0.9155 LossAtt 0.3790 TrainAcc 0.6100 TestAcc 0.5223 0.6300
epoch 200 LossPred 0.7214 LossAtt 0.3702 TrainAcc 0.7400 TestAcc 0.7603 0.7200
epoch 300 LossPred 0.5289 LossAtt 0.3330 TrainAcc 0.8000 TestAcc 0.8386 0.7600
epoch 400 LossPred 0.5588 LossAtt 0.3336 TrainAcc 0.7700 TestAcc 0.8078 0.7450
epoch 500 LossPred 0.5857 LossAtt 0.3201 TrainAcc 0.7700 TestAcc 0.8186 0.7150
epoch 600 LossPred 0.6739 LossAtt 0.3114 TrainAcc 0.7500 TestAcc 0.7805 0.7550
epoch 700 LossPred 0.5007 LossAtt 0.3082 TrainAcc 0.8100 TestAcc 0.8403 0.7850
epoch 800 LossPred 0.5586 LossAtt 0.3140 TrainAcc 0.7600 TestAcc 0.8251 0.7300
epoch 900 LossPred 0.4467 LossAtt 0.3076 TrainAcc 0.8300 TestAcc 0.8591 0.7950
epoch 1000 LossPred 0.4516 LossAtt 0.3068 TrainAcc 0.8500 TestAcc 0.8586 0.8100
epoch 1100 LossPred 0.5826 LossAtt 0.3068 TrainAcc 0.7700 TestAcc 0.8161 0.7600
epoch 1200 LossPred 0.3930 LossAtt 0.3085 TrainAcc 0.8800 TestAcc 0.8639 0.7950
epoch 1300 LossPred 0.6828 LossAtt 0.3190 TrainAcc 0.7500 TestAcc 0.8036 0.7150
epoch 1400 LossPred 0.5410 LossAtt 0.3229 TrainAcc 0.8100 TestAcc 0.7940 0.7750
epoch 1500 LossPred 0.5560 LossAtt 0.3404 TrainAcc 0.7900 TestAcc 0.8123 0.7500
epoch 1600 LossPred 0.6719 LossAtt 0.3183 TrainAcc 0.7800 TestAcc 0.7688 0.7650
epoch 1700 LossPred 0.4749 LossAtt 0.3208 TrainAcc 0.8200 TestAcc 0.8193 0.8000
epoch 1800 LossPred 0.4296 LossAtt 0.3169 TrainAcc 0.8400 TestAcc 0.8526 0.7850
epoch 1900 LossPred 0.4295 LossAtt 0.3244 TrainAcc 0.8400 TestAcc 0.8569 0.8200
epoch 2000 LossPred 0.4855 LossAtt 0.3390 TrainAcc 0.8300 TestAcc 0.8606 0.8000
epoch 2100 LossPred 0.5980 LossAtt 0.3471 TrainAcc 0.7600 TestAcc 0.8138 0.7600
epoch 2200 LossPred 0.4778 LossAtt 0.3444 TrainAcc 0.8000 TestAcc 0.8356 0.7800
epoch 2300 LossPred 0.4988 LossAtt 0.3547 TrainAcc 0.8200 TestAcc 0.8268 0.7950
epoch 2400 LossPred 0.4781 LossAtt 0.3690 TrainAcc 0.8100 TestAcc 0.8549 0.8100
epoch 2500 LossPred 0.3880 LossAtt 0.3738 TrainAcc 0.8600 TestAcc 0.8534 0.7900
Optimization Finished!
********** replication  30  **********
epoch   0 LossPred 1.0500 LossAtt 1.0462 TrainAcc 0.4800 TestAcc 0.4122 0.5000
epoch 100 LossPred 0.9081 LossAtt 0.3308 TrainAcc 0.6400 TestAcc 0.5863 0.6500
epoch 200 LossPred 0.4918 LossAtt 0.3478 TrainAcc 0.8600 TestAcc 0.8356 0.8200
epoch 300 LossPred 0.4312 LossAtt 0.3319 TrainAcc 0.8400 TestAcc 0.8383 0.8200
epoch 400 LossPred 0.3358 LossAtt 0.2993 TrainAcc 0.8900 TestAcc 0.8531 0.8200
epoch 500 LossPred 0.2241 LossAtt 0.3154 TrainAcc 0.9500 TestAcc 0.8724 0.8250
epoch 600 LossPred 0.3627 LossAtt 0.3319 TrainAcc 0.9000 TestAcc 0.8473 0.8100
epoch 700 LossPred 0.3301 LossAtt 0.3279 TrainAcc 0.8900 TestAcc 0.8461 0.8550
epoch 800 LossPred 0.1649 LossAtt 0.3166 TrainAcc 0.9500 TestAcc 0.8884 0.8750
epoch 900 LossPred 0.1481 LossAtt 0.2955 TrainAcc 0.9600 TestAcc 0.8964 0.8800
epoch 1000 LossPred 0.2381 LossAtt 0.2864 TrainAcc 0.9300 TestAcc 0.8574 0.8450
epoch 1100 LossPred 0.4390 LossAtt 0.3001 TrainAcc 0.8600 TestAcc 0.8326 0.7900
epoch 1200 LossPred 0.1708 LossAtt 0.2986 TrainAcc 0.9500 TestAcc 0.8949 0.9000
epoch 1300 LossPred 0.7533 LossAtt 0.2734 TrainAcc 0.7800 TestAcc 0.7217 0.7550
epoch 1400 LossPred 0.5699 LossAtt 0.2636 TrainAcc 0.7800 TestAcc 0.7790 0.7850
epoch 1500 LossPred 0.2562 LossAtt 0.2738 TrainAcc 0.9100 TestAcc 0.8731 0.8700
epoch 1600 LossPred 0.3000 LossAtt 0.2832 TrainAcc 0.9200 TestAcc 0.8486 0.8650
epoch 1700 LossPred 0.2487 LossAtt 0.2698 TrainAcc 0.9100 TestAcc 0.8676 0.9050
epoch 1800 LossPred 0.2287 LossAtt 0.2802 TrainAcc 0.9300 TestAcc 0.8534 0.8550
epoch 1900 LossPred 0.2688 LossAtt 0.2797 TrainAcc 0.9200 TestAcc 0.8781 0.8700
epoch 2000 LossPred 0.4505 LossAtt 0.2750 TrainAcc 0.8500 TestAcc 0.8223 0.8200
epoch 2100 LossPred 0.3254 LossAtt 0.2875 TrainAcc 0.8800 TestAcc 0.8516 0.8400
epoch 2200 LossPred 0.1739 LossAtt 0.2788 TrainAcc 0.9500 TestAcc 0.8799 0.9100
epoch 2300 LossPred 0.2196 LossAtt 0.2742 TrainAcc 0.9400 TestAcc 0.8664 0.9200
epoch 2400 LossPred 0.1594 LossAtt 0.2561 TrainAcc 0.9300 TestAcc 0.8814 0.9050
epoch 2500 LossPred 0.3271 LossAtt 0.2533 TrainAcc 0.9000 TestAcc 0.8664 0.8500
Optimization Finished!
********** replication  31  **********
epoch   0 LossPred 1.1762 LossAtt 1.0139 TrainAcc 0.4300 TestAcc 0.4279 0.4750
epoch 100 LossPred 0.9144 LossAtt 0.3725 TrainAcc 0.6200 TestAcc 0.5733 0.6400
epoch 200 LossPred 0.5968 LossAtt 0.4324 TrainAcc 0.8200 TestAcc 0.7863 0.8350
epoch 300 LossPred 0.4457 LossAtt 0.3810 TrainAcc 0.8600 TestAcc 0.7975 0.8250
epoch 400 LossPred 0.3330 LossAtt 0.3692 TrainAcc 0.9200 TestAcc 0.8306 0.8600
epoch 500 LossPred 0.4425 LossAtt 0.3632 TrainAcc 0.8700 TestAcc 0.8001 0.8150
epoch 600 LossPred 0.3041 LossAtt 0.3443 TrainAcc 0.9100 TestAcc 0.8301 0.8450
epoch 700 LossPred 0.3755 LossAtt 0.3418 TrainAcc 0.8900 TestAcc 0.8078 0.8600
epoch 800 LossPred 0.3548 LossAtt 0.3423 TrainAcc 0.8900 TestAcc 0.8416 0.8450
epoch 900 LossPred 0.3594 LossAtt 0.3313 TrainAcc 0.8800 TestAcc 0.7963 0.8300
epoch 1000 LossPred 0.2942 LossAtt 0.3382 TrainAcc 0.9000 TestAcc 0.8336 0.8600
epoch 1100 LossPred 0.3100 LossAtt 0.3455 TrainAcc 0.9100 TestAcc 0.8411 0.8500
epoch 1200 LossPred 0.2973 LossAtt 0.3362 TrainAcc 0.9100 TestAcc 0.8306 0.8500
epoch 1300 LossPred 0.2869 LossAtt 0.3342 TrainAcc 0.9100 TestAcc 0.8251 0.8400
epoch 1400 LossPred 0.3362 LossAtt 0.3339 TrainAcc 0.8900 TestAcc 0.8641 0.8450
epoch 1500 LossPred 0.3270 LossAtt 0.3386 TrainAcc 0.9000 TestAcc 0.8243 0.8550
epoch 1600 LossPred 0.2700 LossAtt 0.3370 TrainAcc 0.9300 TestAcc 0.8654 0.8650
epoch 1700 LossPred 0.3299 LossAtt 0.3295 TrainAcc 0.8900 TestAcc 0.8248 0.8400
epoch 1800 LossPred 0.2718 LossAtt 0.3236 TrainAcc 0.9200 TestAcc 0.8786 0.8500
epoch 1900 LossPred 0.4178 LossAtt 0.3380 TrainAcc 0.8600 TestAcc 0.8509 0.8150
epoch 2000 LossPred 0.2484 LossAtt 0.3389 TrainAcc 0.9200 TestAcc 0.8739 0.8650
epoch 2100 LossPred 0.2817 LossAtt 0.3745 TrainAcc 0.9200 TestAcc 0.8493 0.8600
epoch 2200 LossPred 0.3000 LossAtt 0.3576 TrainAcc 0.9100 TestAcc 0.8561 0.8750
epoch 2300 LossPred 0.0782 LossAtt 0.3695 TrainAcc 0.9900 TestAcc 0.8879 0.9150
epoch 2400 LossPred 0.0784 LossAtt 0.3771 TrainAcc 0.9700 TestAcc 0.8989 0.9350
epoch 2500 LossPred 0.0493 LossAtt 0.3754 TrainAcc 0.9900 TestAcc 0.8914 0.9200
Optimization Finished!
********** replication  32  **********
epoch   0 LossPred 0.9804 LossAtt 0.9978 TrainAcc 0.5800 TestAcc 0.5280 0.5650
epoch 100 LossPred 0.9013 LossAtt 0.3198 TrainAcc 0.6400 TestAcc 0.5693 0.6350
epoch 200 LossPred 0.7585 LossAtt 0.4899 TrainAcc 0.7200 TestAcc 0.6351 0.7200
epoch 300 LossPred 0.4147 LossAtt 0.4765 TrainAcc 0.8700 TestAcc 0.7925 0.8500
epoch 400 LossPred 0.2905 LossAtt 0.4240 TrainAcc 0.9000 TestAcc 0.8524 0.8750
epoch 500 LossPred 0.2337 LossAtt 0.3917 TrainAcc 0.9300 TestAcc 0.8591 0.8800
epoch 600 LossPred 0.2430 LossAtt 0.3880 TrainAcc 0.9200 TestAcc 0.8781 0.8850
epoch 700 LossPred 0.1803 LossAtt 0.3721 TrainAcc 0.9400 TestAcc 0.8696 0.8750
epoch 800 LossPred 0.2967 LossAtt 0.3822 TrainAcc 0.9000 TestAcc 0.8481 0.8850
epoch 900 LossPred 0.1916 LossAtt 0.3542 TrainAcc 0.9400 TestAcc 0.8621 0.8800
epoch 1000 LossPred 0.2395 LossAtt 0.3505 TrainAcc 0.9100 TestAcc 0.8614 0.8950
epoch 1100 LossPred 0.1907 LossAtt 0.3403 TrainAcc 0.9400 TestAcc 0.8646 0.9000
epoch 1200 LossPred 0.1713 LossAtt 0.3491 TrainAcc 0.9500 TestAcc 0.8651 0.9150
epoch 1300 LossPred 0.1597 LossAtt 0.3420 TrainAcc 0.9500 TestAcc 0.8616 0.9000
epoch 1400 LossPred 0.2754 LossAtt 0.3506 TrainAcc 0.9200 TestAcc 0.8388 0.8950
epoch 1500 LossPred 0.1827 LossAtt 0.3433 TrainAcc 0.9500 TestAcc 0.8629 0.9200
epoch 1600 LossPred 0.1529 LossAtt 0.3461 TrainAcc 0.9500 TestAcc 0.8636 0.9150
epoch 1700 LossPred 0.1985 LossAtt 0.3315 TrainAcc 0.9200 TestAcc 0.8619 0.8950
epoch 1800 LossPred 0.2133 LossAtt 0.3435 TrainAcc 0.9200 TestAcc 0.8611 0.8750
epoch 1900 LossPred 0.1319 LossAtt 0.3473 TrainAcc 0.9700 TestAcc 0.8589 0.9000
epoch 2000 LossPred 0.1459 LossAtt 0.3410 TrainAcc 0.9500 TestAcc 0.8441 0.9000
epoch 2100 LossPred 0.1363 LossAtt 0.3558 TrainAcc 0.9600 TestAcc 0.8408 0.9100
epoch 2200 LossPred 0.1875 LossAtt 0.3547 TrainAcc 0.9500 TestAcc 0.8358 0.9050
epoch 2300 LossPred 0.1243 LossAtt 0.3746 TrainAcc 0.9700 TestAcc 0.8393 0.9000
epoch 2400 LossPred 0.1336 LossAtt 0.3872 TrainAcc 0.9600 TestAcc 0.8361 0.9100
epoch 2500 LossPred 0.1381 LossAtt 0.3800 TrainAcc 0.9600 TestAcc 0.8466 0.9000
Optimization Finished!
********** replication  33  **********
epoch   0 LossPred 1.0178 LossAtt 1.0335 TrainAcc 0.4800 TestAcc 0.4617 0.4700
epoch 100 LossPred 0.8872 LossAtt 0.4198 TrainAcc 0.6400 TestAcc 0.6121 0.6000
epoch 200 LossPred 0.2610 LossAtt 0.4550 TrainAcc 0.9400 TestAcc 0.8686 0.9100
epoch 300 LossPred 0.2098 LossAtt 0.4746 TrainAcc 0.9500 TestAcc 0.8699 0.9150
epoch 400 LossPred 0.2285 LossAtt 0.4800 TrainAcc 0.9300 TestAcc 0.8851 0.9150
epoch 500 LossPred 0.1613 LossAtt 0.4469 TrainAcc 0.9500 TestAcc 0.8856 0.9150
epoch 600 LossPred 0.1390 LossAtt 0.4213 TrainAcc 0.9600 TestAcc 0.8969 0.9400
epoch 700 LossPred 0.1748 LossAtt 0.4047 TrainAcc 0.9400 TestAcc 0.8929 0.9500
epoch 800 LossPred 0.2003 LossAtt 0.3951 TrainAcc 0.9200 TestAcc 0.8926 0.9350
epoch 900 LossPred 0.1338 LossAtt 0.3676 TrainAcc 0.9500 TestAcc 0.9019 0.9550
epoch 1000 LossPred 0.1222 LossAtt 0.3597 TrainAcc 0.9700 TestAcc 0.8854 0.9450
epoch 1100 LossPred 0.1609 LossAtt 0.3589 TrainAcc 0.9500 TestAcc 0.8559 0.9100
epoch 1200 LossPred 0.1039 LossAtt 0.3539 TrainAcc 0.9900 TestAcc 0.8851 0.9450
epoch 1300 LossPred 0.1020 LossAtt 0.3390 TrainAcc 0.9700 TestAcc 0.9072 0.9650
epoch 1400 LossPred 0.0831 LossAtt 0.3422 TrainAcc 0.9900 TestAcc 0.9004 0.9500
epoch 1500 LossPred 0.1154 LossAtt 0.3481 TrainAcc 0.9700 TestAcc 0.8981 0.9600
epoch 1600 LossPred 0.0748 LossAtt 0.3300 TrainAcc 0.9800 TestAcc 0.9089 0.9850
epoch 1700 LossPred 0.0711 LossAtt 0.3152 TrainAcc 0.9900 TestAcc 0.8934 0.9650
epoch 1800 LossPred 0.0653 LossAtt 0.3087 TrainAcc 0.9900 TestAcc 0.8994 0.9750
epoch 1900 LossPred 0.0547 LossAtt 0.3014 TrainAcc 0.9900 TestAcc 0.9117 0.9800
epoch 2000 LossPred 0.1355 LossAtt 0.3138 TrainAcc 0.9400 TestAcc 0.8851 0.9450
epoch 2100 LossPred 0.0604 LossAtt 0.2929 TrainAcc 0.9900 TestAcc 0.8966 0.9700
epoch 2200 LossPred 0.0477 LossAtt 0.2936 TrainAcc 0.9900 TestAcc 0.9099 0.9800
epoch 2300 LossPred 0.0477 LossAtt 0.2933 TrainAcc 0.9900 TestAcc 0.9057 0.9900
epoch 2400 LossPred 0.0761 LossAtt 0.3052 TrainAcc 0.9800 TestAcc 0.8921 0.9600
epoch 2500 LossPred 0.0471 LossAtt 0.2854 TrainAcc 0.9900 TestAcc 0.9007 0.9800
Optimization Finished!
********** replication  34  **********
epoch   0 LossPred 1.1176 LossAtt 1.0528 TrainAcc 0.4700 TestAcc 0.5423 0.4500
epoch 100 LossPred 0.9080 LossAtt 0.3505 TrainAcc 0.6300 TestAcc 0.4612 0.6200
epoch 200 LossPred 0.8935 LossAtt 0.2912 TrainAcc 0.6300 TestAcc 0.4600 0.6300
epoch 300 LossPred 0.8878 LossAtt 0.2662 TrainAcc 0.6300 TestAcc 0.4600 0.6300
epoch 400 LossPred 0.8823 LossAtt 0.2635 TrainAcc 0.6300 TestAcc 0.4600 0.6350
epoch 500 LossPred 0.8579 LossAtt 0.2964 TrainAcc 0.6400 TestAcc 0.4520 0.6400
epoch 600 LossPred 0.8281 LossAtt 0.2697 TrainAcc 0.6700 TestAcc 0.4397 0.6400
epoch 700 LossPred 0.8068 LossAtt 0.3070 TrainAcc 0.6800 TestAcc 0.4452 0.6500
epoch 800 LossPred 0.7947 LossAtt 0.3506 TrainAcc 0.7000 TestAcc 0.4494 0.6700
epoch 900 LossPred 0.7766 LossAtt 0.4011 TrainAcc 0.7100 TestAcc 0.4547 0.6600
epoch 1000 LossPred 0.7705 LossAtt 0.4224 TrainAcc 0.6900 TestAcc 0.5045 0.6650
epoch 1100 LossPred 0.7524 LossAtt 0.3707 TrainAcc 0.7300 TestAcc 0.5293 0.6850
epoch 1200 LossPred 0.7425 LossAtt 0.3278 TrainAcc 0.7400 TestAcc 0.5250 0.6950
epoch 1300 LossPred 0.7299 LossAtt 0.3411 TrainAcc 0.7500 TestAcc 0.5330 0.6950
epoch 1400 LossPred 0.7207 LossAtt 0.3652 TrainAcc 0.7600 TestAcc 0.5368 0.6950
epoch 1500 LossPred 0.7094 LossAtt 0.3770 TrainAcc 0.7500 TestAcc 0.5363 0.6900
epoch 1600 LossPred 0.6811 LossAtt 0.3673 TrainAcc 0.7500 TestAcc 0.5385 0.6700
epoch 1700 LossPred 0.6897 LossAtt 0.4045 TrainAcc 0.7400 TestAcc 0.5335 0.7050
epoch 1800 LossPred 0.6501 LossAtt 0.3967 TrainAcc 0.7700 TestAcc 0.5343 0.6850
epoch 1900 LossPred 0.7056 LossAtt 0.4125 TrainAcc 0.7700 TestAcc 0.5315 0.7300
epoch 2000 LossPred 0.6949 LossAtt 0.3963 TrainAcc 0.7600 TestAcc 0.5418 0.6900
epoch 2100 LossPred 0.6410 LossAtt 0.3789 TrainAcc 0.7800 TestAcc 0.5373 0.7150
epoch 2200 LossPred 0.6361 LossAtt 0.3798 TrainAcc 0.7900 TestAcc 0.5340 0.6950
epoch 2300 LossPred 0.6373 LossAtt 0.3425 TrainAcc 0.7900 TestAcc 0.5360 0.6950
epoch 2400 LossPred 0.6323 LossAtt 0.3433 TrainAcc 0.7800 TestAcc 0.5320 0.6950
epoch 2500 LossPred 0.6349 LossAtt 0.3500 TrainAcc 0.8000 TestAcc 0.5313 0.6900
Optimization Finished!
********** replication  35  **********
epoch   0 LossPred 0.9740 LossAtt 1.0273 TrainAcc 0.6200 TestAcc 0.5493 0.6000
epoch 100 LossPred 0.8850 LossAtt 0.3552 TrainAcc 0.6600 TestAcc 0.5971 0.6600
epoch 200 LossPred 0.8208 LossAtt 0.3333 TrainAcc 0.6800 TestAcc 0.6074 0.6850
epoch 300 LossPred 0.7776 LossAtt 0.3626 TrainAcc 0.6900 TestAcc 0.5873 0.6800
epoch 400 LossPred 0.7352 LossAtt 0.4085 TrainAcc 0.7200 TestAcc 0.5913 0.7050
epoch 500 LossPred 0.6307 LossAtt 0.4840 TrainAcc 0.7500 TestAcc 0.5688 0.6950
epoch 600 LossPred 0.5135 LossAtt 0.4769 TrainAcc 0.8400 TestAcc 0.5521 0.7100
epoch 700 LossPred 0.4549 LossAtt 0.4422 TrainAcc 0.8800 TestAcc 0.5686 0.7450
epoch 800 LossPred 0.4202 LossAtt 0.4433 TrainAcc 0.8900 TestAcc 0.5683 0.7350
epoch 900 LossPred 0.3951 LossAtt 0.4447 TrainAcc 0.8800 TestAcc 0.5691 0.7350
epoch 1000 LossPred 0.3745 LossAtt 0.4284 TrainAcc 0.8600 TestAcc 0.5691 0.7350
epoch 1100 LossPred 0.3646 LossAtt 0.4285 TrainAcc 0.8800 TestAcc 0.5623 0.7750
epoch 1200 LossPred 0.3334 LossAtt 0.4142 TrainAcc 0.9100 TestAcc 0.5703 0.7550
epoch 1300 LossPred 0.3288 LossAtt 0.4235 TrainAcc 0.9200 TestAcc 0.5663 0.7500
epoch 1400 LossPred 0.3148 LossAtt 0.4084 TrainAcc 0.9200 TestAcc 0.5736 0.7650
epoch 1500 LossPred 0.3039 LossAtt 0.4076 TrainAcc 0.9100 TestAcc 0.5723 0.7550
epoch 1600 LossPred 0.3312 LossAtt 0.4157 TrainAcc 0.9000 TestAcc 0.5656 0.7550
epoch 1700 LossPred 0.3132 LossAtt 0.4314 TrainAcc 0.9100 TestAcc 0.5523 0.7300
epoch 1800 LossPred 0.3022 LossAtt 0.4225 TrainAcc 0.9100 TestAcc 0.5643 0.7650
epoch 1900 LossPred 0.2944 LossAtt 0.4071 TrainAcc 0.9100 TestAcc 0.5633 0.7650
epoch 2000 LossPred 0.2870 LossAtt 0.4058 TrainAcc 0.9100 TestAcc 0.5651 0.7500
epoch 2100 LossPred 0.2855 LossAtt 0.4012 TrainAcc 0.9100 TestAcc 0.5658 0.7550
epoch 2200 LossPred 0.2771 LossAtt 0.4118 TrainAcc 0.9100 TestAcc 0.5623 0.7450
epoch 2300 LossPred 0.2787 LossAtt 0.4009 TrainAcc 0.9100 TestAcc 0.5653 0.7400
epoch 2400 LossPred 0.2613 LossAtt 0.4023 TrainAcc 0.9200 TestAcc 0.5606 0.7550
epoch 2500 LossPred 0.2562 LossAtt 0.3961 TrainAcc 0.9200 TestAcc 0.5593 0.7300
Optimization Finished!
********** replication  36  **********
epoch   0 LossPred 0.9208 LossAtt 1.0624 TrainAcc 0.5300 TestAcc 0.4897 0.5450
epoch 100 LossPred 0.8374 LossAtt 0.3245 TrainAcc 0.6800 TestAcc 0.5928 0.6700
epoch 200 LossPred 0.8182 LossAtt 0.2901 TrainAcc 0.6800 TestAcc 0.5928 0.6800
epoch 300 LossPred 0.6156 LossAtt 0.4242 TrainAcc 0.7900 TestAcc 0.7245 0.8100
epoch 400 LossPred 0.3980 LossAtt 0.3593 TrainAcc 0.8700 TestAcc 0.8361 0.8550
epoch 500 LossPred 0.3459 LossAtt 0.3592 TrainAcc 0.8700 TestAcc 0.8353 0.8650
epoch 600 LossPred 0.3005 LossAtt 0.3412 TrainAcc 0.9000 TestAcc 0.8166 0.8700
epoch 700 LossPred 0.2782 LossAtt 0.3470 TrainAcc 0.9000 TestAcc 0.8291 0.8750
epoch 800 LossPred 0.2207 LossAtt 0.3599 TrainAcc 0.9400 TestAcc 0.8486 0.8750
epoch 900 LossPred 0.1185 LossAtt 0.3382 TrainAcc 0.9700 TestAcc 0.8756 0.9400
epoch 1000 LossPred 0.1046 LossAtt 0.3317 TrainAcc 0.9900 TestAcc 0.8699 0.9450
epoch 1100 LossPred 0.1395 LossAtt 0.3322 TrainAcc 0.9700 TestAcc 0.8789 0.8900
epoch 1200 LossPred 0.0725 LossAtt 0.3212 TrainAcc 0.9900 TestAcc 0.8701 0.9550
epoch 1300 LossPred 0.1191 LossAtt 0.3134 TrainAcc 0.9600 TestAcc 0.8621 0.9300
epoch 1400 LossPred 0.0794 LossAtt 0.3059 TrainAcc 0.9800 TestAcc 0.8779 0.9500
epoch 1500 LossPred 0.0727 LossAtt 0.3118 TrainAcc 0.9800 TestAcc 0.8719 0.9550
epoch 1600 LossPred 0.0582 LossAtt 0.3007 TrainAcc 0.9900 TestAcc 0.8786 0.9600
epoch 1700 LossPred 0.0792 LossAtt 0.2944 TrainAcc 0.9800 TestAcc 0.8559 0.9350
epoch 1800 LossPred 0.2412 LossAtt 0.2887 TrainAcc 0.9300 TestAcc 0.8531 0.8950
epoch 1900 LossPred 0.0861 LossAtt 0.2958 TrainAcc 0.9600 TestAcc 0.8719 0.9350
epoch 2000 LossPred 0.0665 LossAtt 0.2846 TrainAcc 0.9900 TestAcc 0.8781 0.9500
epoch 2100 LossPred 0.0604 LossAtt 0.2828 TrainAcc 0.9900 TestAcc 0.8694 0.9650
epoch 2200 LossPred 0.0660 LossAtt 0.2717 TrainAcc 0.9900 TestAcc 0.8756 0.9550
epoch 2300 LossPred 0.3213 LossAtt 0.2774 TrainAcc 0.9000 TestAcc 0.8301 0.8950
epoch 2400 LossPred 0.0928 LossAtt 0.2686 TrainAcc 0.9700 TestAcc 0.8669 0.9450
epoch 2500 LossPred 0.0577 LossAtt 0.2770 TrainAcc 0.9900 TestAcc 0.8764 0.9700
Optimization Finished!
********** replication  37  **********
epoch   0 LossPred 0.9774 LossAtt 1.0468 TrainAcc 0.5200 TestAcc 0.5405 0.5250
epoch 100 LossPred 0.7948 LossAtt 0.4113 TrainAcc 0.6600 TestAcc 0.6214 0.6600
epoch 200 LossPred 0.3204 LossAtt 0.4576 TrainAcc 0.8900 TestAcc 0.8549 0.8800
epoch 300 LossPred 0.3886 LossAtt 0.4414 TrainAcc 0.8500 TestAcc 0.8413 0.8350
epoch 400 LossPred 0.2817 LossAtt 0.4385 TrainAcc 0.9200 TestAcc 0.8258 0.8950
epoch 500 LossPred 0.1850 LossAtt 0.4246 TrainAcc 0.9500 TestAcc 0.8371 0.9050
epoch 600 LossPred 0.2020 LossAtt 0.4313 TrainAcc 0.9300 TestAcc 0.8336 0.9000
epoch 700 LossPred 0.1437 LossAtt 0.4253 TrainAcc 0.9600 TestAcc 0.8428 0.9150
epoch 800 LossPred 0.1850 LossAtt 0.4209 TrainAcc 0.9400 TestAcc 0.8391 0.8950
epoch 900 LossPred 0.1097 LossAtt 0.4122 TrainAcc 0.9700 TestAcc 0.8353 0.9150
epoch 1000 LossPred 0.1764 LossAtt 0.3928 TrainAcc 0.9400 TestAcc 0.8171 0.8900
epoch 1100 LossPred 0.1076 LossAtt 0.3851 TrainAcc 0.9700 TestAcc 0.8351 0.9250
epoch 1200 LossPred 0.0950 LossAtt 0.3814 TrainAcc 0.9600 TestAcc 0.8346 0.9300
epoch 1300 LossPred 0.1136 LossAtt 0.3903 TrainAcc 0.9500 TestAcc 0.8381 0.9150
epoch 1400 LossPred 0.1436 LossAtt 0.3755 TrainAcc 0.9500 TestAcc 0.8133 0.8900
epoch 1500 LossPred 0.0712 LossAtt 0.3648 TrainAcc 0.9800 TestAcc 0.8228 0.9200
epoch 1600 LossPred 0.0666 LossAtt 0.3474 TrainAcc 0.9700 TestAcc 0.8336 0.9400
epoch 1700 LossPred 0.0558 LossAtt 0.3683 TrainAcc 0.9800 TestAcc 0.8303 0.9200
epoch 1800 LossPred 0.1896 LossAtt 0.3670 TrainAcc 0.9300 TestAcc 0.8418 0.9000
epoch 1900 LossPred 0.1256 LossAtt 0.3622 TrainAcc 0.9500 TestAcc 0.8233 0.8950
epoch 2000 LossPred 0.0530 LossAtt 0.3514 TrainAcc 0.9800 TestAcc 0.8263 0.9200
epoch 2100 LossPred 0.0520 LossAtt 0.3457 TrainAcc 0.9900 TestAcc 0.8306 0.9200
epoch 2200 LossPred 0.1539 LossAtt 0.3497 TrainAcc 0.9400 TestAcc 0.8343 0.9050
epoch 2300 LossPred 0.1166 LossAtt 0.3486 TrainAcc 0.9500 TestAcc 0.8296 0.9000
epoch 2400 LossPred 0.0987 LossAtt 0.3453 TrainAcc 0.9700 TestAcc 0.8326 0.9000
epoch 2500 LossPred 0.0543 LossAtt 0.3475 TrainAcc 0.9900 TestAcc 0.8271 0.9100
Optimization Finished!
********** replication  38  **********
epoch   0 LossPred 1.0059 LossAtt 1.0289 TrainAcc 0.5700 TestAcc 0.5521 0.5650
epoch 100 LossPred 0.9326 LossAtt 0.2363 TrainAcc 0.6100 TestAcc 0.5843 0.6100
epoch 200 LossPred 0.9317 LossAtt 0.1458 TrainAcc 0.6100 TestAcc 0.5843 0.6100
epoch 300 LossPred 0.9290 LossAtt 0.1804 TrainAcc 0.6100 TestAcc 0.5843 0.6050
epoch 400 LossPred 0.8512 LossAtt 0.4284 TrainAcc 0.5900 TestAcc 0.5556 0.6100
epoch 500 LossPred 0.3002 LossAtt 0.4125 TrainAcc 0.8900 TestAcc 0.8531 0.9100
epoch 600 LossPred 0.2180 LossAtt 0.3741 TrainAcc 0.9500 TestAcc 0.8386 0.9000
epoch 700 LossPred 0.2018 LossAtt 0.3652 TrainAcc 0.9500 TestAcc 0.8396 0.9050
epoch 800 LossPred 0.1680 LossAtt 0.3465 TrainAcc 0.9500 TestAcc 0.8586 0.9350
epoch 900 LossPred 0.1712 LossAtt 0.3504 TrainAcc 0.9500 TestAcc 0.8516 0.9300
epoch 1000 LossPred 0.1419 LossAtt 0.3419 TrainAcc 0.9700 TestAcc 0.8719 0.9350
epoch 1100 LossPred 0.1828 LossAtt 0.3340 TrainAcc 0.9600 TestAcc 0.8796 0.9400
epoch 1200 LossPred 0.1305 LossAtt 0.3354 TrainAcc 0.9700 TestAcc 0.8746 0.9450
epoch 1300 LossPred 0.1369 LossAtt 0.3444 TrainAcc 0.9700 TestAcc 0.8736 0.9600
epoch 1400 LossPred 0.1631 LossAtt 0.3456 TrainAcc 0.9600 TestAcc 0.8754 0.9350
epoch 1500 LossPred 0.1251 LossAtt 0.3338 TrainAcc 0.9700 TestAcc 0.8626 0.9550
epoch 1600 LossPred 0.1180 LossAtt 0.3331 TrainAcc 0.9800 TestAcc 0.8641 0.9650
epoch 1700 LossPred 0.1162 LossAtt 0.3367 TrainAcc 0.9700 TestAcc 0.8601 0.9550
epoch 1800 LossPred 0.1231 LossAtt 0.3311 TrainAcc 0.9700 TestAcc 0.8544 0.9650
epoch 1900 LossPred 0.1252 LossAtt 0.3349 TrainAcc 0.9700 TestAcc 0.8616 0.9700
epoch 2000 LossPred 0.1086 LossAtt 0.3351 TrainAcc 0.9800 TestAcc 0.8559 0.9550
epoch 2100 LossPred 0.1629 LossAtt 0.3288 TrainAcc 0.9600 TestAcc 0.8371 0.9450
epoch 2200 LossPred 0.1029 LossAtt 0.3256 TrainAcc 0.9800 TestAcc 0.8511 0.9650
epoch 2300 LossPred 0.1017 LossAtt 0.3283 TrainAcc 0.9800 TestAcc 0.8504 0.9650
epoch 2400 LossPred 0.3725 LossAtt 0.3208 TrainAcc 0.9100 TestAcc 0.8534 0.9000
epoch 2500 LossPred 0.1055 LossAtt 0.3286 TrainAcc 0.9700 TestAcc 0.8368 0.9600
Optimization Finished!
********** replication  39  **********
epoch   0 LossPred 1.0148 LossAtt 1.0156 TrainAcc 0.5200 TestAcc 0.4780 0.5300
epoch 100 LossPred 0.8898 LossAtt 0.3779 TrainAcc 0.6400 TestAcc 0.5791 0.6150
epoch 200 LossPred 0.5814 LossAtt 0.4593 TrainAcc 0.7900 TestAcc 0.7533 0.7750
epoch 300 LossPred 0.3727 LossAtt 0.4566 TrainAcc 0.9000 TestAcc 0.8091 0.8600
epoch 400 LossPred 0.3167 LossAtt 0.4493 TrainAcc 0.8800 TestAcc 0.8033 0.8650
epoch 500 LossPred 0.2520 LossAtt 0.4316 TrainAcc 0.9200 TestAcc 0.8113 0.8800
epoch 600 LossPred 0.2401 LossAtt 0.4449 TrainAcc 0.9200 TestAcc 0.8126 0.8700
epoch 700 LossPred 0.1829 LossAtt 0.4367 TrainAcc 0.9500 TestAcc 0.8343 0.8850
epoch 800 LossPred 0.1907 LossAtt 0.4211 TrainAcc 0.9500 TestAcc 0.8238 0.8850
epoch 900 LossPred 0.1692 LossAtt 0.4118 TrainAcc 0.9600 TestAcc 0.8311 0.8850
epoch 1000 LossPred 0.1476 LossAtt 0.4274 TrainAcc 0.9700 TestAcc 0.8433 0.8700
epoch 1100 LossPred 0.1928 LossAtt 0.4099 TrainAcc 0.9600 TestAcc 0.8271 0.8900
epoch 1200 LossPred 0.1312 LossAtt 0.4103 TrainAcc 0.9800 TestAcc 0.8463 0.8900
epoch 1300 LossPred 0.2583 LossAtt 0.4077 TrainAcc 0.9100 TestAcc 0.8368 0.8600
epoch 1400 LossPred 0.4837 LossAtt 0.3884 TrainAcc 0.8500 TestAcc 0.7758 0.8450
epoch 1500 LossPred 0.1515 LossAtt 0.3568 TrainAcc 0.9700 TestAcc 0.8326 0.9200
epoch 1600 LossPred 0.1351 LossAtt 0.3358 TrainAcc 0.9700 TestAcc 0.8401 0.9350
epoch 1700 LossPred 0.1298 LossAtt 0.3258 TrainAcc 0.9800 TestAcc 0.8438 0.9400
epoch 1800 LossPred 0.1405 LossAtt 0.3288 TrainAcc 0.9700 TestAcc 0.8433 0.9450
epoch 1900 LossPred 0.1206 LossAtt 0.3212 TrainAcc 0.9700 TestAcc 0.8293 0.9500
epoch 2000 LossPred 0.1319 LossAtt 0.3119 TrainAcc 0.9600 TestAcc 0.8408 0.9350
epoch 2100 LossPred 0.1792 LossAtt 0.3236 TrainAcc 0.9500 TestAcc 0.8428 0.9050
epoch 2200 LossPred 0.1252 LossAtt 0.3171 TrainAcc 0.9800 TestAcc 0.8353 0.9600
epoch 2300 LossPred 0.1215 LossAtt 0.3118 TrainAcc 0.9700 TestAcc 0.8266 0.9600
epoch 2400 LossPred 0.1126 LossAtt 0.3095 TrainAcc 0.9800 TestAcc 0.8326 0.9500
epoch 2500 LossPred 0.2774 LossAtt 0.3016 TrainAcc 0.9200 TestAcc 0.8076 0.8950
Optimization Finished!
********** replication  40  **********
epoch   0 LossPred 1.2781 LossAtt 1.0047 TrainAcc 0.5100 TestAcc 0.4987 0.4800
epoch 100 LossPred 0.8348 LossAtt 0.3910 TrainAcc 0.7100 TestAcc 0.5951 0.7150
epoch 200 LossPred 0.6384 LossAtt 0.4460 TrainAcc 0.7900 TestAcc 0.7643 0.7950
epoch 300 LossPred 0.4893 LossAtt 0.4343 TrainAcc 0.8200 TestAcc 0.7983 0.8350
epoch 400 LossPred 0.4000 LossAtt 0.4349 TrainAcc 0.8800 TestAcc 0.8143 0.8600
epoch 500 LossPred 0.4682 LossAtt 0.4285 TrainAcc 0.8500 TestAcc 0.7985 0.8350
epoch 600 LossPred 0.3138 LossAtt 0.4182 TrainAcc 0.9200 TestAcc 0.8248 0.8800
epoch 700 LossPred 0.3284 LossAtt 0.4109 TrainAcc 0.9100 TestAcc 0.8223 0.8800
epoch 800 LossPred 0.2977 LossAtt 0.4211 TrainAcc 0.9100 TestAcc 0.8238 0.8850
epoch 900 LossPred 0.2807 LossAtt 0.4043 TrainAcc 0.9200 TestAcc 0.8223 0.8850
epoch 1000 LossPred 0.2638 LossAtt 0.3981 TrainAcc 0.9100 TestAcc 0.8353 0.8700
epoch 1100 LossPred 0.2350 LossAtt 0.3865 TrainAcc 0.9300 TestAcc 0.8361 0.8750
epoch 1200 LossPred 0.2654 LossAtt 0.3866 TrainAcc 0.9200 TestAcc 0.8383 0.8750
epoch 1300 LossPred 0.2853 LossAtt 0.3844 TrainAcc 0.9000 TestAcc 0.8256 0.8500
epoch 1400 LossPred 0.2120 LossAtt 0.3719 TrainAcc 0.9400 TestAcc 0.8306 0.8700
epoch 1500 LossPred 0.2343 LossAtt 0.3798 TrainAcc 0.9200 TestAcc 0.8346 0.8850
epoch 1600 LossPred 0.1686 LossAtt 0.3868 TrainAcc 0.9500 TestAcc 0.8318 0.8700
epoch 1700 LossPred 0.1786 LossAtt 0.3644 TrainAcc 0.9500 TestAcc 0.8281 0.8700
epoch 1800 LossPred 0.1713 LossAtt 0.3860 TrainAcc 0.9600 TestAcc 0.8288 0.8500
epoch 1900 LossPred 0.2913 LossAtt 0.3662 TrainAcc 0.8900 TestAcc 0.8141 0.8550
epoch 2000 LossPred 0.1366 LossAtt 0.3836 TrainAcc 0.9700 TestAcc 0.8343 0.8750
epoch 2100 LossPred 0.2039 LossAtt 0.3866 TrainAcc 0.9300 TestAcc 0.8311 0.8800
epoch 2200 LossPred 0.1525 LossAtt 0.3890 TrainAcc 0.9700 TestAcc 0.8353 0.8950
epoch 2300 LossPred 0.1806 LossAtt 0.3829 TrainAcc 0.9500 TestAcc 0.8301 0.8800
epoch 2400 LossPred 0.1137 LossAtt 0.3844 TrainAcc 0.9700 TestAcc 0.8406 0.8700
epoch 2500 LossPred 0.1137 LossAtt 0.3766 TrainAcc 0.9800 TestAcc 0.8388 0.8800
Optimization Finished!
********** replication  41  **********
epoch   0 LossPred 1.0401 LossAtt 1.0086 TrainAcc 0.4400 TestAcc 0.4772 0.4400
epoch 100 LossPred 0.9684 LossAtt 0.3443 TrainAcc 0.5700 TestAcc 0.5758 0.5700
epoch 200 LossPred 0.9368 LossAtt 0.3717 TrainAcc 0.6200 TestAcc 0.5415 0.6250
epoch 300 LossPred 0.8900 LossAtt 0.4201 TrainAcc 0.6600 TestAcc 0.5465 0.6650
epoch 400 LossPred 0.7607 LossAtt 0.4918 TrainAcc 0.7000 TestAcc 0.5611 0.7050
epoch 500 LossPred 0.6296 LossAtt 0.5228 TrainAcc 0.7800 TestAcc 0.5468 0.7050
epoch 600 LossPred 0.5495 LossAtt 0.5240 TrainAcc 0.8100 TestAcc 0.5488 0.7250
epoch 700 LossPred 0.5511 LossAtt 0.5143 TrainAcc 0.7700 TestAcc 0.5483 0.7200
epoch 800 LossPred 0.5094 LossAtt 0.5144 TrainAcc 0.8100 TestAcc 0.5340 0.7200
epoch 900 LossPred 0.4840 LossAtt 0.5118 TrainAcc 0.8500 TestAcc 0.5368 0.7300
epoch 1000 LossPred 0.5058 LossAtt 0.5219 TrainAcc 0.8200 TestAcc 0.5358 0.7350
epoch 1100 LossPred 0.4449 LossAtt 0.4975 TrainAcc 0.8500 TestAcc 0.5305 0.7350
epoch 1200 LossPred 0.4543 LossAtt 0.4872 TrainAcc 0.8400 TestAcc 0.5335 0.7200
epoch 1300 LossPred 0.4642 LossAtt 0.4925 TrainAcc 0.8500 TestAcc 0.5265 0.7250
epoch 1400 LossPred 0.4821 LossAtt 0.4798 TrainAcc 0.8200 TestAcc 0.5298 0.7400
epoch 1500 LossPred 0.5568 LossAtt 0.4596 TrainAcc 0.7900 TestAcc 0.5303 0.7100
epoch 1600 LossPred 0.4547 LossAtt 0.4633 TrainAcc 0.8500 TestAcc 0.5283 0.7250
epoch 1700 LossPred 0.4727 LossAtt 0.4762 TrainAcc 0.8500 TestAcc 0.5353 0.7200
epoch 1800 LossPred 0.4596 LossAtt 0.4473 TrainAcc 0.8600 TestAcc 0.5280 0.7150
epoch 1900 LossPred 0.4026 LossAtt 0.4524 TrainAcc 0.8600 TestAcc 0.5383 0.7250
epoch 2000 LossPred 0.4048 LossAtt 0.4497 TrainAcc 0.8900 TestAcc 0.5340 0.7150
epoch 2100 LossPred 0.3951 LossAtt 0.4386 TrainAcc 0.8600 TestAcc 0.5320 0.6950
epoch 2200 LossPred 0.4176 LossAtt 0.4396 TrainAcc 0.8700 TestAcc 0.5363 0.7200
epoch 2300 LossPred 0.4312 LossAtt 0.4268 TrainAcc 0.8800 TestAcc 0.5365 0.7100
epoch 2400 LossPred 0.4354 LossAtt 0.4102 TrainAcc 0.8600 TestAcc 0.5360 0.7100
epoch 2500 LossPred 0.3716 LossAtt 0.4222 TrainAcc 0.8700 TestAcc 0.5323 0.7350
Optimization Finished!
********** replication  42  **********
epoch   0 LossPred 1.0713 LossAtt 1.0215 TrainAcc 0.3900 TestAcc 0.4394 0.4150
epoch 100 LossPred 0.9046 LossAtt 0.3399 TrainAcc 0.6400 TestAcc 0.5811 0.6300
epoch 200 LossPred 0.8751 LossAtt 0.3412 TrainAcc 0.6700 TestAcc 0.5996 0.6800
epoch 300 LossPred 0.3623 LossAtt 0.3998 TrainAcc 0.9200 TestAcc 0.8483 0.8500
epoch 400 LossPred 0.2122 LossAtt 0.3893 TrainAcc 0.9600 TestAcc 0.8746 0.8900
epoch 500 LossPred 0.1557 LossAtt 0.3747 TrainAcc 0.9700 TestAcc 0.8839 0.8950
epoch 600 LossPred 0.1354 LossAtt 0.3715 TrainAcc 0.9700 TestAcc 0.8796 0.9100
epoch 700 LossPred 0.1182 LossAtt 0.3531 TrainAcc 0.9700 TestAcc 0.8864 0.9250
epoch 800 LossPred 0.1488 LossAtt 0.3450 TrainAcc 0.9600 TestAcc 0.8844 0.9050
epoch 900 LossPred 0.1130 LossAtt 0.3399 TrainAcc 0.9800 TestAcc 0.8771 0.9250
epoch 1000 LossPred 0.2002 LossAtt 0.3396 TrainAcc 0.9300 TestAcc 0.8749 0.8700
epoch 1100 LossPred 0.2022 LossAtt 0.3286 TrainAcc 0.9300 TestAcc 0.8751 0.8700
epoch 1200 LossPred 0.1205 LossAtt 0.3312 TrainAcc 0.9600 TestAcc 0.8839 0.9050
epoch 1300 LossPred 0.1175 LossAtt 0.3272 TrainAcc 0.9700 TestAcc 0.8834 0.9050
epoch 1400 LossPred 0.1527 LossAtt 0.3269 TrainAcc 0.9300 TestAcc 0.8839 0.8900
epoch 1500 LossPred 0.1340 LossAtt 0.3174 TrainAcc 0.9600 TestAcc 0.8806 0.8950
epoch 1600 LossPred 0.1213 LossAtt 0.3250 TrainAcc 0.9500 TestAcc 0.8756 0.9300
epoch 1700 LossPred 0.0929 LossAtt 0.3202 TrainAcc 0.9700 TestAcc 0.8841 0.9300
epoch 1800 LossPred 0.0901 LossAtt 0.3021 TrainAcc 0.9700 TestAcc 0.8829 0.9200
epoch 1900 LossPred 0.1317 LossAtt 0.3319 TrainAcc 0.9500 TestAcc 0.8731 0.9250
epoch 2000 LossPred 0.0874 LossAtt 0.3040 TrainAcc 0.9800 TestAcc 0.8869 0.9300
epoch 2100 LossPred 0.0890 LossAtt 0.3127 TrainAcc 0.9800 TestAcc 0.8839 0.9250
epoch 2200 LossPred 0.1395 LossAtt 0.3251 TrainAcc 0.9600 TestAcc 0.8846 0.9000
epoch 2300 LossPred 0.2037 LossAtt 0.3014 TrainAcc 0.9200 TestAcc 0.8776 0.8500
epoch 2400 LossPred 0.1069 LossAtt 0.3017 TrainAcc 0.9600 TestAcc 0.8776 0.9250
epoch 2500 LossPred 0.1801 LossAtt 0.2963 TrainAcc 0.9300 TestAcc 0.8794 0.8800
Optimization Finished!
********** replication  43  **********
epoch   0 LossPred 1.1645 LossAtt 1.0430 TrainAcc 0.3800 TestAcc 0.4149 0.3800
epoch 100 LossPred 0.9260 LossAtt 0.2886 TrainAcc 0.6300 TestAcc 0.5868 0.6400
epoch 200 LossPred 0.9193 LossAtt 0.2629 TrainAcc 0.6300 TestAcc 0.5868 0.6300
epoch 300 LossPred 0.9156 LossAtt 0.2630 TrainAcc 0.6300 TestAcc 0.5868 0.6350
epoch 400 LossPred 0.8826 LossAtt 0.3468 TrainAcc 0.6500 TestAcc 0.6101 0.6500
epoch 500 LossPred 0.6215 LossAtt 0.3884 TrainAcc 0.7700 TestAcc 0.8016 0.7900
epoch 600 LossPred 0.5141 LossAtt 0.3533 TrainAcc 0.8300 TestAcc 0.8371 0.8100
epoch 700 LossPred 0.4800 LossAtt 0.3302 TrainAcc 0.8400 TestAcc 0.8288 0.8150
epoch 800 LossPred 0.4151 LossAtt 0.3112 TrainAcc 0.8500 TestAcc 0.8486 0.8300
epoch 900 LossPred 0.4004 LossAtt 0.2946 TrainAcc 0.8800 TestAcc 0.8566 0.8400
epoch 1000 LossPred 0.4119 LossAtt 0.2843 TrainAcc 0.8500 TestAcc 0.8626 0.8400
epoch 1100 LossPred 0.3389 LossAtt 0.2632 TrainAcc 0.8600 TestAcc 0.8864 0.8750
epoch 1200 LossPred 0.2644 LossAtt 0.2655 TrainAcc 0.9200 TestAcc 0.9069 0.9000
epoch 1300 LossPred 0.2361 LossAtt 0.2606 TrainAcc 0.9400 TestAcc 0.9452 0.9150
epoch 1400 LossPred 0.6138 LossAtt 0.2442 TrainAcc 0.8000 TestAcc 0.7500 0.7600
epoch 1500 LossPred 0.3138 LossAtt 0.2498 TrainAcc 0.8700 TestAcc 0.8554 0.8800
epoch 1600 LossPred 0.2427 LossAtt 0.2508 TrainAcc 0.9100 TestAcc 0.9107 0.8950
epoch 1700 LossPred 0.4648 LossAtt 0.2390 TrainAcc 0.8400 TestAcc 0.8026 0.8350
epoch 1800 LossPred 0.2104 LossAtt 0.2280 TrainAcc 0.9200 TestAcc 0.9157 0.9100
epoch 1900 LossPred 0.5874 LossAtt 0.2341 TrainAcc 0.8200 TestAcc 0.7578 0.7700
epoch 2000 LossPred 0.1758 LossAtt 0.2187 TrainAcc 0.9500 TestAcc 0.9254 0.9250
epoch 2100 LossPred 0.3584 LossAtt 0.2226 TrainAcc 0.8500 TestAcc 0.8483 0.8650
epoch 2200 LossPred 0.2138 LossAtt 0.2248 TrainAcc 0.8900 TestAcc 0.9024 0.9150
epoch 2300 LossPred 0.1541 LossAtt 0.2309 TrainAcc 0.9600 TestAcc 0.9477 0.9000
epoch 2400 LossPred 0.2292 LossAtt 0.2241 TrainAcc 0.9100 TestAcc 0.9112 0.9150
epoch 2500 LossPred 0.3638 LossAtt 0.2346 TrainAcc 0.8800 TestAcc 0.8604 0.8650
Optimization Finished!
********** replication  44  **********
epoch   0 LossPred 1.2596 LossAtt 1.0034 TrainAcc 0.4000 TestAcc 0.4214 0.3850
epoch 100 LossPred 0.9298 LossAtt 0.3579 TrainAcc 0.6200 TestAcc 0.5028 0.6200
epoch 200 LossPred 0.9130 LossAtt 0.3155 TrainAcc 0.6200 TestAcc 0.5083 0.6350
epoch 300 LossPred 0.8978 LossAtt 0.3040 TrainAcc 0.6400 TestAcc 0.5345 0.6300
epoch 400 LossPred 0.8897 LossAtt 0.3445 TrainAcc 0.6500 TestAcc 0.5425 0.6550
epoch 500 LossPred 0.8739 LossAtt 0.3436 TrainAcc 0.6600 TestAcc 0.5513 0.6650
epoch 600 LossPred 0.8596 LossAtt 0.3392 TrainAcc 0.6500 TestAcc 0.5723 0.6600
epoch 700 LossPred 0.8170 LossAtt 0.4354 TrainAcc 0.6800 TestAcc 0.6254 0.6750
epoch 800 LossPred 0.7205 LossAtt 0.5015 TrainAcc 0.7300 TestAcc 0.6489 0.7050
epoch 900 LossPred 0.6634 LossAtt 0.4718 TrainAcc 0.7700 TestAcc 0.6369 0.7500
epoch 1000 LossPred 0.5585 LossAtt 0.4723 TrainAcc 0.8000 TestAcc 0.6932 0.7650
epoch 1100 LossPred 0.5390 LossAtt 0.4694 TrainAcc 0.8100 TestAcc 0.7405 0.7700
epoch 1200 LossPred 0.4143 LossAtt 0.4756 TrainAcc 0.8400 TestAcc 0.7653 0.8050
epoch 1300 LossPred 0.3676 LossAtt 0.4791 TrainAcc 0.8700 TestAcc 0.7835 0.8400
epoch 1400 LossPred 0.3325 LossAtt 0.4701 TrainAcc 0.8800 TestAcc 0.7680 0.8350
epoch 1500 LossPred 0.2924 LossAtt 0.4643 TrainAcc 0.9200 TestAcc 0.7848 0.8550
epoch 1600 LossPred 0.3577 LossAtt 0.4620 TrainAcc 0.8900 TestAcc 0.7760 0.8200
epoch 1700 LossPred 0.2781 LossAtt 0.4838 TrainAcc 0.9400 TestAcc 0.7848 0.8600
epoch 1800 LossPred 0.2627 LossAtt 0.4809 TrainAcc 0.9400 TestAcc 0.7808 0.8750
epoch 1900 LossPred 0.2539 LossAtt 0.4687 TrainAcc 0.9400 TestAcc 0.7838 0.8700
epoch 2000 LossPred 0.2602 LossAtt 0.4694 TrainAcc 0.9400 TestAcc 0.7830 0.8400
epoch 2100 LossPred 0.2665 LossAtt 0.4520 TrainAcc 0.9300 TestAcc 0.7825 0.8650
epoch 2200 LossPred 0.2396 LossAtt 0.4523 TrainAcc 0.9400 TestAcc 0.7925 0.8550
epoch 2300 LossPred 0.2386 LossAtt 0.4592 TrainAcc 0.9400 TestAcc 0.7870 0.8750
epoch 2400 LossPred 0.2654 LossAtt 0.4337 TrainAcc 0.9200 TestAcc 0.8018 0.9000
epoch 2500 LossPred 0.2318 LossAtt 0.4529 TrainAcc 0.9400 TestAcc 0.7923 0.8750
Optimization Finished!
********** replication  45  **********
epoch   0 LossPred 1.0218 LossAtt 1.0499 TrainAcc 0.5700 TestAcc 0.4725 0.5450
epoch 100 LossPred 0.8071 LossAtt 0.3320 TrainAcc 0.6400 TestAcc 0.5923 0.6400
epoch 200 LossPred 0.3643 LossAtt 0.3975 TrainAcc 0.8900 TestAcc 0.8358 0.8850
epoch 300 LossPred 0.2808 LossAtt 0.3755 TrainAcc 0.9100 TestAcc 0.8569 0.8900
epoch 400 LossPred 0.2655 LossAtt 0.3798 TrainAcc 0.9100 TestAcc 0.8619 0.8900
epoch 500 LossPred 0.2245 LossAtt 0.3637 TrainAcc 0.9100 TestAcc 0.8493 0.8900
epoch 600 LossPred 0.2158 LossAtt 0.3554 TrainAcc 0.9400 TestAcc 0.8534 0.9000
epoch 700 LossPred 0.2039 LossAtt 0.3510 TrainAcc 0.9500 TestAcc 0.8529 0.8900
epoch 800 LossPred 0.1903 LossAtt 0.3496 TrainAcc 0.9500 TestAcc 0.8559 0.8800
epoch 900 LossPred 0.1943 LossAtt 0.3485 TrainAcc 0.9400 TestAcc 0.8501 0.8850
epoch 1000 LossPred 0.1648 LossAtt 0.3407 TrainAcc 0.9500 TestAcc 0.8541 0.9050
epoch 1100 LossPred 0.1466 LossAtt 0.3255 TrainAcc 0.9500 TestAcc 0.8539 0.9100
epoch 1200 LossPred 0.1766 LossAtt 0.3202 TrainAcc 0.9500 TestAcc 0.8396 0.9000
epoch 1300 LossPred 0.3897 LossAtt 0.3402 TrainAcc 0.8500 TestAcc 0.8118 0.8500
epoch 1400 LossPred 0.1806 LossAtt 0.3332 TrainAcc 0.9500 TestAcc 0.8403 0.9000
epoch 1500 LossPred 0.2116 LossAtt 0.3177 TrainAcc 0.9400 TestAcc 0.8386 0.8950
epoch 1600 LossPred 0.1895 LossAtt 0.3229 TrainAcc 0.9500 TestAcc 0.8266 0.8900
epoch 1700 LossPred 0.3008 LossAtt 0.3203 TrainAcc 0.8900 TestAcc 0.8096 0.8700
epoch 1800 LossPred 0.1655 LossAtt 0.3289 TrainAcc 0.9500 TestAcc 0.8453 0.9000
epoch 1900 LossPred 0.1891 LossAtt 0.2960 TrainAcc 0.9300 TestAcc 0.8423 0.9050
epoch 2000 LossPred 0.1272 LossAtt 0.3105 TrainAcc 0.9600 TestAcc 0.8659 0.9150
epoch 2100 LossPred 0.0994 LossAtt 0.2977 TrainAcc 0.9700 TestAcc 0.8666 0.9200
epoch 2200 LossPred 0.1465 LossAtt 0.3115 TrainAcc 0.9300 TestAcc 0.8584 0.9150
epoch 2300 LossPred 0.1882 LossAtt 0.2877 TrainAcc 0.9200 TestAcc 0.8366 0.9000
epoch 2400 LossPred 0.2062 LossAtt 0.2999 TrainAcc 0.9400 TestAcc 0.8383 0.8950
epoch 2500 LossPred 0.2206 LossAtt 0.2938 TrainAcc 0.9200 TestAcc 0.8128 0.8900
Optimization Finished!
********** replication  46  **********
epoch   0 LossPred 1.2535 LossAtt 1.0180 TrainAcc 0.4700 TestAcc 0.4507 0.4400
epoch 100 LossPred 0.9448 LossAtt 0.3173 TrainAcc 0.6200 TestAcc 0.5478 0.6300
epoch 200 LossPred 0.9235 LossAtt 0.3038 TrainAcc 0.6300 TestAcc 0.5483 0.6250
epoch 300 LossPred 0.8659 LossAtt 0.4021 TrainAcc 0.6400 TestAcc 0.5973 0.6300
epoch 400 LossPred 0.5239 LossAtt 0.4096 TrainAcc 0.8300 TestAcc 0.7688 0.8200
epoch 500 LossPred 0.4270 LossAtt 0.4045 TrainAcc 0.8600 TestAcc 0.7898 0.8550
epoch 600 LossPred 0.3440 LossAtt 0.4052 TrainAcc 0.9000 TestAcc 0.8341 0.8650
epoch 700 LossPred 0.3212 LossAtt 0.4024 TrainAcc 0.9100 TestAcc 0.8311 0.8700
epoch 800 LossPred 0.3344 LossAtt 0.3786 TrainAcc 0.8800 TestAcc 0.8549 0.8900
epoch 900 LossPred 0.3022 LossAtt 0.3763 TrainAcc 0.9200 TestAcc 0.8599 0.8650
epoch 1000 LossPred 0.2789 LossAtt 0.3585 TrainAcc 0.9000 TestAcc 0.8684 0.8900
epoch 1100 LossPred 0.2656 LossAtt 0.3671 TrainAcc 0.9100 TestAcc 0.8719 0.8850
epoch 1200 LossPred 0.2278 LossAtt 0.3576 TrainAcc 0.9300 TestAcc 0.8916 0.9000
epoch 1300 LossPred 0.2166 LossAtt 0.3467 TrainAcc 0.9400 TestAcc 0.8879 0.9000
epoch 1400 LossPred 0.2155 LossAtt 0.3415 TrainAcc 0.9300 TestAcc 0.8979 0.9200
epoch 1500 LossPred 0.1971 LossAtt 0.3493 TrainAcc 0.9300 TestAcc 0.9092 0.9300
epoch 1600 LossPred 0.2139 LossAtt 0.3539 TrainAcc 0.9300 TestAcc 0.9094 0.9150
epoch 1700 LossPred 0.2278 LossAtt 0.3518 TrainAcc 0.9300 TestAcc 0.8956 0.9000
epoch 1800 LossPred 0.2072 LossAtt 0.3481 TrainAcc 0.9200 TestAcc 0.9127 0.9200
epoch 1900 LossPred 0.1710 LossAtt 0.3301 TrainAcc 0.9500 TestAcc 0.9244 0.9350
epoch 2000 LossPred 0.1664 LossAtt 0.3388 TrainAcc 0.9600 TestAcc 0.9212 0.9250
epoch 2100 LossPred 0.1490 LossAtt 0.3405 TrainAcc 0.9700 TestAcc 0.9299 0.9300
epoch 2200 LossPred 0.1742 LossAtt 0.3399 TrainAcc 0.9500 TestAcc 0.9212 0.9250
epoch 2300 LossPred 0.1795 LossAtt 0.3394 TrainAcc 0.9400 TestAcc 0.9184 0.9250
epoch 2400 LossPred 0.1458 LossAtt 0.3373 TrainAcc 0.9600 TestAcc 0.9357 0.9350
epoch 2500 LossPred 0.1355 LossAtt 0.3450 TrainAcc 0.9600 TestAcc 0.9339 0.9300
Optimization Finished!
********** replication  47  **********
epoch   0 LossPred 1.0994 LossAtt 1.0398 TrainAcc 0.5700 TestAcc 0.4697 0.5500
epoch 100 LossPred 0.9630 LossAtt 0.4190 TrainAcc 0.6000 TestAcc 0.5255 0.5900
epoch 200 LossPred 0.8823 LossAtt 0.4505 TrainAcc 0.6500 TestAcc 0.5188 0.6350
epoch 300 LossPred 0.7940 LossAtt 0.4841 TrainAcc 0.7200 TestAcc 0.5208 0.6550
epoch 400 LossPred 0.7466 LossAtt 0.4764 TrainAcc 0.7700 TestAcc 0.5240 0.6700
epoch 500 LossPred 0.6958 LossAtt 0.4954 TrainAcc 0.8100 TestAcc 0.5398 0.7050
epoch 600 LossPred 0.6669 LossAtt 0.5104 TrainAcc 0.8000 TestAcc 0.5448 0.7000
epoch 700 LossPred 0.6511 LossAtt 0.5161 TrainAcc 0.7800 TestAcc 0.5433 0.7000
epoch 800 LossPred 0.6422 LossAtt 0.5250 TrainAcc 0.8000 TestAcc 0.5463 0.7100
epoch 900 LossPred 0.5986 LossAtt 0.5372 TrainAcc 0.8200 TestAcc 0.5470 0.7100
epoch 1000 LossPred 0.5653 LossAtt 0.5385 TrainAcc 0.8300 TestAcc 0.5536 0.7300
epoch 1100 LossPred 0.5266 LossAtt 0.5420 TrainAcc 0.8300 TestAcc 0.5546 0.7300
epoch 1200 LossPred 0.4883 LossAtt 0.5428 TrainAcc 0.8500 TestAcc 0.5445 0.7300
epoch 1300 LossPred 0.4233 LossAtt 0.5689 TrainAcc 0.8700 TestAcc 0.5513 0.7450
epoch 1400 LossPred 0.3612 LossAtt 0.5556 TrainAcc 0.9100 TestAcc 0.5506 0.7700
epoch 1500 LossPred 0.4386 LossAtt 0.5746 TrainAcc 0.8700 TestAcc 0.5395 0.7150
epoch 1600 LossPred 0.3406 LossAtt 0.5534 TrainAcc 0.9100 TestAcc 0.5395 0.7300
epoch 1700 LossPred 0.3417 LossAtt 0.5500 TrainAcc 0.9000 TestAcc 0.5400 0.7500
epoch 1800 LossPred 0.3028 LossAtt 0.5425 TrainAcc 0.9200 TestAcc 0.5383 0.7400
epoch 1900 LossPred 0.2836 LossAtt 0.5245 TrainAcc 0.9200 TestAcc 0.5355 0.7500
epoch 2000 LossPred 0.2629 LossAtt 0.5469 TrainAcc 0.9200 TestAcc 0.5303 0.7600
epoch 2100 LossPred 0.2514 LossAtt 0.5590 TrainAcc 0.9300 TestAcc 0.5248 0.7700
epoch 2200 LossPred 0.2320 LossAtt 0.5466 TrainAcc 0.9500 TestAcc 0.5233 0.7600
epoch 2300 LossPred 0.2701 LossAtt 0.5220 TrainAcc 0.9400 TestAcc 0.5288 0.7800
epoch 2400 LossPred 0.2185 LossAtt 0.5277 TrainAcc 0.9400 TestAcc 0.5255 0.7900
epoch 2500 LossPred 0.2161 LossAtt 0.5286 TrainAcc 0.9600 TestAcc 0.5265 0.7900
Optimization Finished!
********** replication  48  **********
epoch   0 LossPred 0.8850 LossAtt 1.0183 TrainAcc 0.6800 TestAcc 0.5548 0.6600
epoch 100 LossPred 0.4084 LossAtt 0.3739 TrainAcc 0.8600 TestAcc 0.8146 0.8400
epoch 200 LossPred 0.3325 LossAtt 0.3223 TrainAcc 0.8900 TestAcc 0.8218 0.8750
epoch 300 LossPred 0.3107 LossAtt 0.3141 TrainAcc 0.9200 TestAcc 0.8176 0.8800
epoch 400 LossPred 0.2382 LossAtt 0.2989 TrainAcc 0.9400 TestAcc 0.8386 0.8800
epoch 500 LossPred 0.2644 LossAtt 0.3093 TrainAcc 0.9200 TestAcc 0.8153 0.8750
epoch 600 LossPred 0.1814 LossAtt 0.3126 TrainAcc 0.9300 TestAcc 0.8146 0.8950
epoch 700 LossPred 0.1722 LossAtt 0.3070 TrainAcc 0.9400 TestAcc 0.8168 0.8950
epoch 800 LossPred 0.2770 LossAtt 0.3176 TrainAcc 0.9100 TestAcc 0.8413 0.8800
epoch 900 LossPred 0.2310 LossAtt 0.3235 TrainAcc 0.9100 TestAcc 0.8023 0.8800
epoch 1000 LossPred 0.1945 LossAtt 0.3307 TrainAcc 0.9100 TestAcc 0.8246 0.9000
epoch 1100 LossPred 0.3959 LossAtt 0.3276 TrainAcc 0.8500 TestAcc 0.8111 0.8550
epoch 1200 LossPred 0.1594 LossAtt 0.3362 TrainAcc 0.9500 TestAcc 0.8151 0.9150
epoch 1300 LossPred 0.1969 LossAtt 0.3203 TrainAcc 0.9200 TestAcc 0.7803 0.9000
epoch 1400 LossPred 0.2858 LossAtt 0.3314 TrainAcc 0.9000 TestAcc 0.7578 0.8950
epoch 1500 LossPred 0.3487 LossAtt 0.3166 TrainAcc 0.8800 TestAcc 0.7442 0.8400
epoch 1600 LossPred 0.1344 LossAtt 0.3155 TrainAcc 0.9700 TestAcc 0.7985 0.9250
epoch 1700 LossPred 0.1406 LossAtt 0.3227 TrainAcc 0.9600 TestAcc 0.8093 0.9300
epoch 1800 LossPred 0.1260 LossAtt 0.3142 TrainAcc 0.9600 TestAcc 0.7925 0.9300
epoch 1900 LossPred 0.1204 LossAtt 0.3112 TrainAcc 0.9800 TestAcc 0.7968 0.9250
epoch 2000 LossPred 0.1134 LossAtt 0.3102 TrainAcc 0.9700 TestAcc 0.7863 0.9200
epoch 2100 LossPred 0.1133 LossAtt 0.3122 TrainAcc 0.9700 TestAcc 0.7970 0.9250
epoch 2200 LossPred 0.1007 LossAtt 0.3061 TrainAcc 0.9700 TestAcc 0.7958 0.9400
epoch 2300 LossPred 0.1660 LossAtt 0.3014 TrainAcc 0.9400 TestAcc 0.7905 0.9100
epoch 2400 LossPred 0.1852 LossAtt 0.3077 TrainAcc 0.9400 TestAcc 0.7990 0.9350
epoch 2500 LossPred 0.1009 LossAtt 0.2935 TrainAcc 0.9700 TestAcc 0.7750 0.9350
Optimization Finished!
********** replication  49  **********
epoch   0 LossPred 1.0058 LossAtt 1.0117 TrainAcc 0.5300 TestAcc 0.5485 0.5300
epoch 100 LossPred 0.8987 LossAtt 0.3536 TrainAcc 0.6500 TestAcc 0.5626 0.6500
epoch 200 LossPred 0.8873 LossAtt 0.3290 TrainAcc 0.6600 TestAcc 0.5676 0.6550
epoch 300 LossPred 0.5070 LossAtt 0.3895 TrainAcc 0.8400 TestAcc 0.8188 0.8450
epoch 400 LossPred 0.9631 LossAtt 0.3854 TrainAcc 0.6800 TestAcc 0.6747 0.6750
epoch 500 LossPred 0.3914 LossAtt 0.3456 TrainAcc 0.8700 TestAcc 0.8338 0.8700
epoch 600 LossPred 0.3058 LossAtt 0.3438 TrainAcc 0.9200 TestAcc 0.8288 0.8950
epoch 700 LossPred 0.4768 LossAtt 0.3397 TrainAcc 0.8200 TestAcc 0.8081 0.8300
epoch 800 LossPred 0.3617 LossAtt 0.3500 TrainAcc 0.8900 TestAcc 0.8071 0.9000
epoch 900 LossPred 0.2854 LossAtt 0.3376 TrainAcc 0.9100 TestAcc 0.8133 0.8850
epoch 1000 LossPred 0.2747 LossAtt 0.3366 TrainAcc 0.9100 TestAcc 0.8221 0.9300
epoch 1100 LossPred 0.5456 LossAtt 0.3344 TrainAcc 0.8500 TestAcc 0.8021 0.8350
epoch 1200 LossPred 0.2751 LossAtt 0.3302 TrainAcc 0.9200 TestAcc 0.8041 0.9000
epoch 1300 LossPred 0.2143 LossAtt 0.3191 TrainAcc 0.9300 TestAcc 0.8233 0.9100
epoch 1400 LossPred 0.2113 LossAtt 0.3067 TrainAcc 0.9500 TestAcc 0.8176 0.9150
epoch 1500 LossPred 0.2070 LossAtt 0.3171 TrainAcc 0.9500 TestAcc 0.8193 0.9200
epoch 1600 LossPred 0.2030 LossAtt 0.3099 TrainAcc 0.9400 TestAcc 0.8256 0.9400
epoch 1700 LossPred 0.2445 LossAtt 0.3129 TrainAcc 0.9200 TestAcc 0.8316 0.9250
epoch 1800 LossPred 0.2028 LossAtt 0.3119 TrainAcc 0.9400 TestAcc 0.8361 0.9450
epoch 1900 LossPred 0.2304 LossAtt 0.2978 TrainAcc 0.9300 TestAcc 0.8391 0.9300
epoch 2000 LossPred 0.2062 LossAtt 0.3210 TrainAcc 0.9300 TestAcc 0.8363 0.9400
epoch 2100 LossPred 0.2178 LossAtt 0.3312 TrainAcc 0.9200 TestAcc 0.8326 0.9250
epoch 2200 LossPred 0.1765 LossAtt 0.3328 TrainAcc 0.9400 TestAcc 0.8281 0.9500
epoch 2300 LossPred 0.1877 LossAtt 0.3278 TrainAcc 0.9400 TestAcc 0.8303 0.9450
epoch 2400 LossPred 0.2503 LossAtt 0.3330 TrainAcc 0.9000 TestAcc 0.8353 0.9400
epoch 2500 LossPred 0.2166 LossAtt 0.3321 TrainAcc 0.9400 TestAcc 0.8308 0.9350
Optimization Finished!
********** replication  50  **********
epoch   0 LossPred 1.2249 LossAtt 1.0826 TrainAcc 0.4500 TestAcc 0.4765 0.4900
epoch 100 LossPred 0.8818 LossAtt 0.4165 TrainAcc 0.6800 TestAcc 0.5756 0.6500
epoch 200 LossPred 0.8122 LossAtt 0.4181 TrainAcc 0.7000 TestAcc 0.5841 0.6900
epoch 300 LossPred 0.3701 LossAtt 0.4661 TrainAcc 0.9100 TestAcc 0.7823 0.8950
epoch 400 LossPred 0.2769 LossAtt 0.4654 TrainAcc 0.9400 TestAcc 0.7888 0.9050
epoch 500 LossPred 0.2223 LossAtt 0.4561 TrainAcc 0.9500 TestAcc 0.8036 0.8950
epoch 600 LossPred 0.2336 LossAtt 0.4411 TrainAcc 0.9400 TestAcc 0.7828 0.9150
epoch 700 LossPred 0.1806 LossAtt 0.4180 TrainAcc 0.9600 TestAcc 0.8038 0.9350
epoch 800 LossPred 0.1403 LossAtt 0.4066 TrainAcc 0.9600 TestAcc 0.8038 0.9050
epoch 900 LossPred 0.1340 LossAtt 0.3988 TrainAcc 0.9600 TestAcc 0.8021 0.9150
epoch 1000 LossPred 0.1348 LossAtt 0.3998 TrainAcc 0.9700 TestAcc 0.7993 0.9150
epoch 1100 LossPred 0.1372 LossAtt 0.4008 TrainAcc 0.9600 TestAcc 0.7965 0.9250
epoch 1200 LossPred 0.1160 LossAtt 0.4094 TrainAcc 0.9700 TestAcc 0.7958 0.9350
epoch 1300 LossPred 0.1116 LossAtt 0.3861 TrainAcc 0.9700 TestAcc 0.7913 0.9400
epoch 1400 LossPred 0.1113 LossAtt 0.3876 TrainAcc 0.9700 TestAcc 0.7870 0.9400
epoch 1500 LossPred 0.1001 LossAtt 0.3956 TrainAcc 0.9700 TestAcc 0.7885 0.9350
epoch 1600 LossPred 0.1000 LossAtt 0.3932 TrainAcc 0.9700 TestAcc 0.7805 0.9350
epoch 1700 LossPred 0.1039 LossAtt 0.3928 TrainAcc 0.9700 TestAcc 0.7805 0.9500
epoch 1800 LossPred 0.0898 LossAtt 0.3891 TrainAcc 0.9700 TestAcc 0.7840 0.9350
epoch 1900 LossPred 0.0922 LossAtt 0.3918 TrainAcc 0.9700 TestAcc 0.7860 0.9500
epoch 2000 LossPred 0.0874 LossAtt 0.3780 TrainAcc 0.9800 TestAcc 0.7805 0.9450
epoch 2100 LossPred 0.0909 LossAtt 0.3802 TrainAcc 0.9700 TestAcc 0.7860 0.9350
epoch 2200 LossPred 0.0922 LossAtt 0.3737 TrainAcc 0.9800 TestAcc 0.7780 0.9450
epoch 2300 LossPred 0.0850 LossAtt 0.3754 TrainAcc 0.9800 TestAcc 0.7808 0.9400
epoch 2400 LossPred 0.0878 LossAtt 0.3716 TrainAcc 0.9800 TestAcc 0.7788 0.9450
epoch 2500 LossPred 0.0837 LossAtt 0.3593 TrainAcc 0.9800 TestAcc 0.7750 0.9500
Optimization Finished!
********** replication  51  **********
epoch   0 LossPred 1.1611 LossAtt 1.0112 TrainAcc 0.5300 TestAcc 0.4767 0.5150
epoch 100 LossPred 0.9251 LossAtt 0.3666 TrainAcc 0.6400 TestAcc 0.5606 0.6400
epoch 200 LossPred 0.5764 LossAtt 0.4912 TrainAcc 0.8000 TestAcc 0.8048 0.8150
epoch 300 LossPred 0.3974 LossAtt 0.4747 TrainAcc 0.8600 TestAcc 0.8313 0.8600
epoch 400 LossPred 0.3131 LossAtt 0.4679 TrainAcc 0.9100 TestAcc 0.8028 0.8850
epoch 500 LossPred 0.2591 LossAtt 0.4851 TrainAcc 0.9200 TestAcc 0.8108 0.9050
epoch 600 LossPred 0.2320 LossAtt 0.4807 TrainAcc 0.9400 TestAcc 0.8106 0.9100
epoch 700 LossPred 0.2217 LossAtt 0.4738 TrainAcc 0.9400 TestAcc 0.8146 0.9100
epoch 800 LossPred 0.2138 LossAtt 0.4573 TrainAcc 0.9400 TestAcc 0.8231 0.9150
epoch 900 LossPred 0.2008 LossAtt 0.4573 TrainAcc 0.9500 TestAcc 0.8218 0.9150
epoch 1000 LossPred 0.1930 LossAtt 0.4310 TrainAcc 0.9500 TestAcc 0.8221 0.9200
epoch 1100 LossPred 0.1862 LossAtt 0.4400 TrainAcc 0.9600 TestAcc 0.8253 0.9100
epoch 1200 LossPred 0.1794 LossAtt 0.4313 TrainAcc 0.9600 TestAcc 0.8191 0.9200
epoch 1300 LossPred 0.1794 LossAtt 0.4215 TrainAcc 0.9600 TestAcc 0.8276 0.9000
epoch 1400 LossPred 0.2184 LossAtt 0.4205 TrainAcc 0.9600 TestAcc 0.8341 0.8950
epoch 1500 LossPred 0.1730 LossAtt 0.4187 TrainAcc 0.9700 TestAcc 0.8183 0.9300
epoch 1600 LossPred 0.1580 LossAtt 0.4149 TrainAcc 0.9700 TestAcc 0.8286 0.9200
epoch 1700 LossPred 0.1482 LossAtt 0.4148 TrainAcc 0.9700 TestAcc 0.8216 0.9350
epoch 1800 LossPred 0.1558 LossAtt 0.3900 TrainAcc 0.9600 TestAcc 0.8083 0.9250
epoch 1900 LossPred 0.1422 LossAtt 0.3920 TrainAcc 0.9700 TestAcc 0.8156 0.9300
epoch 2000 LossPred 0.1386 LossAtt 0.3880 TrainAcc 0.9700 TestAcc 0.8226 0.9350
epoch 2100 LossPred 0.1391 LossAtt 0.3924 TrainAcc 0.9700 TestAcc 0.8228 0.9400
epoch 2200 LossPred 0.1338 LossAtt 0.3899 TrainAcc 0.9700 TestAcc 0.8171 0.9400
epoch 2300 LossPred 0.1377 LossAtt 0.3744 TrainAcc 0.9700 TestAcc 0.8096 0.9200
epoch 2400 LossPred 0.1356 LossAtt 0.3751 TrainAcc 0.9700 TestAcc 0.8258 0.9400
epoch 2500 LossPred 0.3420 LossAtt 0.3794 TrainAcc 0.8900 TestAcc 0.7868 0.8900
Optimization Finished!
********** replication  52  **********
epoch   0 LossPred 0.9773 LossAtt 1.0265 TrainAcc 0.5900 TestAcc 0.5761 0.6050
epoch 100 LossPred 0.7511 LossAtt 0.4158 TrainAcc 0.7400 TestAcc 0.5633 0.7300
epoch 200 LossPred 0.2698 LossAtt 0.4300 TrainAcc 0.9500 TestAcc 0.8041 0.8750
epoch 300 LossPred 0.1165 LossAtt 0.4172 TrainAcc 0.9700 TestAcc 0.8529 0.9200
epoch 400 LossPred 0.1266 LossAtt 0.4122 TrainAcc 0.9600 TestAcc 0.8443 0.9050
epoch 500 LossPred 0.0817 LossAtt 0.4111 TrainAcc 0.9700 TestAcc 0.8551 0.9250
epoch 600 LossPred 0.0616 LossAtt 0.4091 TrainAcc 0.9900 TestAcc 0.8529 0.9150
epoch 700 LossPred 0.0960 LossAtt 0.4010 TrainAcc 0.9700 TestAcc 0.8526 0.9200
epoch 800 LossPred 0.0519 LossAtt 0.3873 TrainAcc 0.9900 TestAcc 0.8519 0.9400
epoch 900 LossPred 0.0564 LossAtt 0.4071 TrainAcc 0.9900 TestAcc 0.8441 0.9250
epoch 1000 LossPred 0.0526 LossAtt 0.3965 TrainAcc 0.9900 TestAcc 0.8516 0.9400
epoch 1100 LossPred 0.0470 LossAtt 0.3845 TrainAcc 0.9900 TestAcc 0.8476 0.9300
epoch 1200 LossPred 0.0448 LossAtt 0.3752 TrainAcc 0.9900 TestAcc 0.8546 0.9300
epoch 1300 LossPred 0.0458 LossAtt 0.3756 TrainAcc 0.9900 TestAcc 0.8561 0.9250
epoch 1400 LossPred 0.0429 LossAtt 0.3751 TrainAcc 0.9900 TestAcc 0.8526 0.9400
epoch 1500 LossPred 0.0458 LossAtt 0.3841 TrainAcc 0.9900 TestAcc 0.8549 0.9250
epoch 1600 LossPred 0.0406 LossAtt 0.3630 TrainAcc 0.9900 TestAcc 0.8536 0.9200
epoch 1700 LossPred 0.0759 LossAtt 0.3617 TrainAcc 0.9800 TestAcc 0.8391 0.9300
epoch 1800 LossPred 0.0407 LossAtt 0.3798 TrainAcc 0.9900 TestAcc 0.8514 0.9500
epoch 1900 LossPred 0.0397 LossAtt 0.3725 TrainAcc 0.9900 TestAcc 0.8514 0.9400
epoch 2000 LossPred 0.0413 LossAtt 0.3769 TrainAcc 0.9900 TestAcc 0.8456 0.9350
epoch 2100 LossPred 0.0321 LossAtt 0.3579 TrainAcc 0.9900 TestAcc 0.8621 0.9350
epoch 2200 LossPred 0.0285 LossAtt 0.3688 TrainAcc 0.9900 TestAcc 0.8634 0.9300
epoch 2300 LossPred 0.0276 LossAtt 0.3832 TrainAcc 0.9900 TestAcc 0.8626 0.9350
epoch 2400 LossPred 0.0249 LossAtt 0.3816 TrainAcc 0.9900 TestAcc 0.8586 0.9200
epoch 2500 LossPred 0.0515 LossAtt 0.3855 TrainAcc 0.9800 TestAcc 0.8554 0.9150
Optimization Finished!
********** replication  53  **********
epoch   0 LossPred 1.3188 LossAtt 1.0308 TrainAcc 0.3800 TestAcc 0.4662 0.4000
epoch 100 LossPred 0.9363 LossAtt 0.3612 TrainAcc 0.6000 TestAcc 0.5818 0.5900
epoch 200 LossPred 0.8774 LossAtt 0.3068 TrainAcc 0.6200 TestAcc 0.5681 0.6150
epoch 300 LossPred 0.6203 LossAtt 0.4479 TrainAcc 0.8100 TestAcc 0.7675 0.7900
epoch 400 LossPred 0.3644 LossAtt 0.4010 TrainAcc 0.8800 TestAcc 0.8486 0.8600
epoch 500 LossPred 0.3039 LossAtt 0.3752 TrainAcc 0.9000 TestAcc 0.8448 0.9000
epoch 600 LossPred 0.2787 LossAtt 0.3720 TrainAcc 0.9200 TestAcc 0.8509 0.8900
epoch 700 LossPred 0.2690 LossAtt 0.3724 TrainAcc 0.9300 TestAcc 0.8338 0.9200
epoch 800 LossPred 0.2473 LossAtt 0.3645 TrainAcc 0.9100 TestAcc 0.8509 0.9100
epoch 900 LossPred 0.2324 LossAtt 0.3693 TrainAcc 0.9100 TestAcc 0.8544 0.9200
epoch 1000 LossPred 0.2110 LossAtt 0.3585 TrainAcc 0.9300 TestAcc 0.8526 0.9250
epoch 1100 LossPred 0.2105 LossAtt 0.3598 TrainAcc 0.9400 TestAcc 0.8486 0.9350
epoch 1200 LossPred 0.2657 LossAtt 0.3549 TrainAcc 0.9200 TestAcc 0.8241 0.9200
epoch 1300 LossPred 0.1907 LossAtt 0.3748 TrainAcc 0.9500 TestAcc 0.8529 0.9300
epoch 1400 LossPred 0.1704 LossAtt 0.3624 TrainAcc 0.9600 TestAcc 0.8589 0.9500
epoch 1500 LossPred 0.1960 LossAtt 0.3579 TrainAcc 0.9500 TestAcc 0.8376 0.9600
epoch 1600 LossPred 0.1631 LossAtt 0.3496 TrainAcc 0.9600 TestAcc 0.8514 0.9600
epoch 1700 LossPred 0.1422 LossAtt 0.3443 TrainAcc 0.9700 TestAcc 0.8581 0.9550
epoch 1800 LossPred 0.1498 LossAtt 0.3507 TrainAcc 0.9600 TestAcc 0.8486 0.9700
epoch 1900 LossPred 0.1324 LossAtt 0.3511 TrainAcc 0.9700 TestAcc 0.8599 0.9450
epoch 2000 LossPred 0.1256 LossAtt 0.3591 TrainAcc 0.9800 TestAcc 0.8566 0.9350
epoch 2100 LossPred 0.1206 LossAtt 0.3402 TrainAcc 0.9800 TestAcc 0.8604 0.9400
epoch 2200 LossPred 0.1192 LossAtt 0.3408 TrainAcc 0.9800 TestAcc 0.8509 0.9700
epoch 2300 LossPred 0.1173 LossAtt 0.3332 TrainAcc 0.9700 TestAcc 0.8691 0.9400
epoch 2400 LossPred 0.1118 LossAtt 0.3468 TrainAcc 0.9800 TestAcc 0.8624 0.9550
epoch 2500 LossPred 0.1316 LossAtt 0.3404 TrainAcc 0.9700 TestAcc 0.8421 0.9750
Optimization Finished!
********** replication  54  **********
epoch   0 LossPred 0.9583 LossAtt 1.0370 TrainAcc 0.5800 TestAcc 0.5796 0.5950
epoch 100 LossPred 0.8066 LossAtt 0.4533 TrainAcc 0.7000 TestAcc 0.6161 0.7050
epoch 200 LossPred 0.1149 LossAtt 0.4819 TrainAcc 0.9900 TestAcc 0.8706 0.9650
epoch 300 LossPred 0.0641 LossAtt 0.4692 TrainAcc 0.9900 TestAcc 0.8869 0.9700
epoch 400 LossPred 0.0404 LossAtt 0.4603 TrainAcc 0.9900 TestAcc 0.8766 0.9700
epoch 500 LossPred 0.0275 LossAtt 0.4566 TrainAcc 1.0000 TestAcc 0.8776 0.9750
Optimization Finished!
********** replication  55  **********
epoch   0 LossPred 1.0875 LossAtt 1.0228 TrainAcc 0.4600 TestAcc 0.5023 0.4800
epoch 100 LossPred 0.9713 LossAtt 0.3507 TrainAcc 0.6100 TestAcc 0.5746 0.6100
epoch 200 LossPred 0.8479 LossAtt 0.4007 TrainAcc 0.6600 TestAcc 0.6451 0.6600
epoch 300 LossPred 0.4847 LossAtt 0.3606 TrainAcc 0.8600 TestAcc 0.8383 0.8350
epoch 400 LossPred 0.5908 LossAtt 0.3704 TrainAcc 0.8100 TestAcc 0.7710 0.8050
epoch 500 LossPred 0.2519 LossAtt 0.3818 TrainAcc 0.9300 TestAcc 0.8406 0.8800
epoch 600 LossPred 0.2117 LossAtt 0.3692 TrainAcc 0.9400 TestAcc 0.8388 0.8850
epoch 700 LossPred 0.1839 LossAtt 0.3701 TrainAcc 0.9600 TestAcc 0.8441 0.8800
epoch 800 LossPred 0.2621 LossAtt 0.3590 TrainAcc 0.9300 TestAcc 0.8471 0.8650
epoch 900 LossPred 0.1745 LossAtt 0.3729 TrainAcc 0.9600 TestAcc 0.8516 0.8850
epoch 1000 LossPred 0.2046 LossAtt 0.3473 TrainAcc 0.9400 TestAcc 0.8441 0.8900
epoch 1100 LossPred 0.2249 LossAtt 0.3527 TrainAcc 0.9200 TestAcc 0.8471 0.8750
epoch 1200 LossPred 0.1935 LossAtt 0.3568 TrainAcc 0.9500 TestAcc 0.8371 0.9050
epoch 1300 LossPred 0.1944 LossAtt 0.3541 TrainAcc 0.9400 TestAcc 0.8391 0.8850
epoch 1400 LossPred 0.1675 LossAtt 0.3615 TrainAcc 0.9600 TestAcc 0.8413 0.8900
epoch 1500 LossPred 0.1589 LossAtt 0.3583 TrainAcc 0.9600 TestAcc 0.8428 0.9050
epoch 1600 LossPred 0.2395 LossAtt 0.3518 TrainAcc 0.9300 TestAcc 0.8383 0.8850
epoch 1700 LossPred 0.1579 LossAtt 0.3390 TrainAcc 0.9600 TestAcc 0.8466 0.9000
epoch 1800 LossPred 0.5204 LossAtt 0.3289 TrainAcc 0.8500 TestAcc 0.8178 0.8250
epoch 1900 LossPred 0.1587 LossAtt 0.3390 TrainAcc 0.9600 TestAcc 0.8413 0.9000
epoch 2000 LossPred 0.1686 LossAtt 0.3260 TrainAcc 0.9500 TestAcc 0.8473 0.9050
epoch 2100 LossPred 0.1586 LossAtt 0.3255 TrainAcc 0.9600 TestAcc 0.8458 0.9250
epoch 2200 LossPred 0.2438 LossAtt 0.3175 TrainAcc 0.9200 TestAcc 0.8436 0.8950
epoch 2300 LossPred 0.3150 LossAtt 0.3213 TrainAcc 0.9000 TestAcc 0.8381 0.8750
epoch 2400 LossPred 0.1603 LossAtt 0.3110 TrainAcc 0.9600 TestAcc 0.8436 0.9300
epoch 2500 LossPred 0.1628 LossAtt 0.3138 TrainAcc 0.9600 TestAcc 0.8438 0.9100
Optimization Finished!
********** replication  56  **********
epoch   0 LossPred 1.0457 LossAtt 1.0333 TrainAcc 0.4600 TestAcc 0.5503 0.4600
epoch 100 LossPred 0.9828 LossAtt 0.3334 TrainAcc 0.5600 TestAcc 0.4907 0.5600
epoch 200 LossPred 0.9361 LossAtt 0.4316 TrainAcc 0.6100 TestAcc 0.4677 0.6100
epoch 300 LossPred 0.8971 LossAtt 0.4016 TrainAcc 0.6200 TestAcc 0.4925 0.6150
epoch 400 LossPred 0.8457 LossAtt 0.4442 TrainAcc 0.6500 TestAcc 0.5220 0.6600
epoch 500 LossPred 0.6937 LossAtt 0.4941 TrainAcc 0.7300 TestAcc 0.5163 0.6950
epoch 600 LossPred 0.5665 LossAtt 0.5219 TrainAcc 0.8200 TestAcc 0.5390 0.7100
epoch 700 LossPred 0.5045 LossAtt 0.5268 TrainAcc 0.8300 TestAcc 0.5435 0.7300
epoch 800 LossPred 0.4440 LossAtt 0.5457 TrainAcc 0.8900 TestAcc 0.5463 0.7750
epoch 900 LossPred 0.4636 LossAtt 0.5633 TrainAcc 0.8700 TestAcc 0.5861 0.7600
epoch 1000 LossPred 0.4081 LossAtt 0.5288 TrainAcc 0.8800 TestAcc 0.5511 0.7750
epoch 1100 LossPred 0.3149 LossAtt 0.5106 TrainAcc 0.9200 TestAcc 0.5823 0.7750
epoch 1200 LossPred 0.3362 LossAtt 0.5094 TrainAcc 0.9000 TestAcc 0.5973 0.7750
epoch 1300 LossPred 0.3924 LossAtt 0.5078 TrainAcc 0.8600 TestAcc 0.5698 0.7700
epoch 1400 LossPred 0.3147 LossAtt 0.5360 TrainAcc 0.9000 TestAcc 0.5966 0.8000
epoch 1500 LossPred 0.2689 LossAtt 0.5148 TrainAcc 0.9400 TestAcc 0.5981 0.8150
epoch 1600 LossPred 0.3106 LossAtt 0.5298 TrainAcc 0.9000 TestAcc 0.6009 0.8000
epoch 1700 LossPred 0.2375 LossAtt 0.5130 TrainAcc 0.9400 TestAcc 0.5968 0.7850
epoch 1800 LossPred 0.2458 LossAtt 0.5096 TrainAcc 0.9400 TestAcc 0.6036 0.7900
epoch 1900 LossPred 0.2551 LossAtt 0.5154 TrainAcc 0.9400 TestAcc 0.5996 0.8100
epoch 2000 LossPred 0.2555 LossAtt 0.5210 TrainAcc 0.9200 TestAcc 0.5951 0.7800
epoch 2100 LossPred 0.2201 LossAtt 0.5072 TrainAcc 0.9400 TestAcc 0.5906 0.7650
epoch 2200 LossPred 0.2548 LossAtt 0.5219 TrainAcc 0.9300 TestAcc 0.5911 0.7800
epoch 2300 LossPred 0.2491 LossAtt 0.5099 TrainAcc 0.9200 TestAcc 0.5898 0.7950
epoch 2400 LossPred 0.2379 LossAtt 0.5035 TrainAcc 0.9200 TestAcc 0.6089 0.8100
epoch 2500 LossPred 0.2044 LossAtt 0.4924 TrainAcc 0.9400 TestAcc 0.6036 0.7850
Optimization Finished!
********** replication  57  **********
epoch   0 LossPred 1.1177 LossAtt 1.0795 TrainAcc 0.5200 TestAcc 0.4357 0.5150
epoch 100 LossPred 0.8988 LossAtt 0.4370 TrainAcc 0.6300 TestAcc 0.4865 0.6600
epoch 200 LossPred 0.5867 LossAtt 0.5022 TrainAcc 0.8000 TestAcc 0.7167 0.7850
epoch 300 LossPred 0.3834 LossAtt 0.5200 TrainAcc 0.8900 TestAcc 0.7583 0.8600
epoch 400 LossPred 0.2320 LossAtt 0.5020 TrainAcc 0.9500 TestAcc 0.7615 0.8900
epoch 500 LossPred 0.2471 LossAtt 0.5000 TrainAcc 0.9300 TestAcc 0.7518 0.8900
epoch 600 LossPred 0.1541 LossAtt 0.4874 TrainAcc 0.9600 TestAcc 0.7683 0.9000
epoch 700 LossPred 0.1373 LossAtt 0.4908 TrainAcc 0.9700 TestAcc 0.7620 0.9050
epoch 800 LossPred 0.1237 LossAtt 0.4759 TrainAcc 0.9700 TestAcc 0.7618 0.9100
epoch 900 LossPred 0.1195 LossAtt 0.4552 TrainAcc 0.9700 TestAcc 0.7555 0.9300
epoch 1000 LossPred 0.1148 LossAtt 0.4415 TrainAcc 0.9700 TestAcc 0.7618 0.9400
epoch 1100 LossPred 0.1062 LossAtt 0.4466 TrainAcc 0.9800 TestAcc 0.7643 0.9500
epoch 1200 LossPred 0.1065 LossAtt 0.4323 TrainAcc 0.9800 TestAcc 0.7603 0.9350
epoch 1300 LossPred 0.1440 LossAtt 0.4200 TrainAcc 0.9600 TestAcc 0.7397 0.8900
epoch 1400 LossPred 0.4132 LossAtt 0.4400 TrainAcc 0.8800 TestAcc 0.7583 0.8400
epoch 1500 LossPred 0.1208 LossAtt 0.4240 TrainAcc 0.9700 TestAcc 0.7442 0.9400
epoch 1600 LossPred 0.0878 LossAtt 0.4341 TrainAcc 0.9800 TestAcc 0.7540 0.9500
epoch 1700 LossPred 0.0781 LossAtt 0.4150 TrainAcc 0.9800 TestAcc 0.7462 0.9500
epoch 1800 LossPred 0.0758 LossAtt 0.4176 TrainAcc 0.9800 TestAcc 0.7490 0.9600
epoch 1900 LossPred 0.0704 LossAtt 0.4148 TrainAcc 0.9800 TestAcc 0.7452 0.9450
epoch 2000 LossPred 0.1100 LossAtt 0.4183 TrainAcc 0.9700 TestAcc 0.7382 0.9300
epoch 2100 LossPred 0.0631 LossAtt 0.4033 TrainAcc 0.9800 TestAcc 0.7395 0.9400
epoch 2200 LossPred 0.0597 LossAtt 0.4081 TrainAcc 0.9800 TestAcc 0.7377 0.9500
epoch 2300 LossPred 0.0790 LossAtt 0.4259 TrainAcc 0.9800 TestAcc 0.7435 0.9450
epoch 2400 LossPred 0.0562 LossAtt 0.4141 TrainAcc 0.9800 TestAcc 0.7300 0.9400
epoch 2500 LossPred 0.0952 LossAtt 0.4039 TrainAcc 0.9700 TestAcc 0.7347 0.9150
Optimization Finished!
********** replication  58  **********
epoch   0 LossPred 0.9775 LossAtt 1.0350 TrainAcc 0.6000 TestAcc 0.5523 0.6000
epoch 100 LossPred 0.8644 LossAtt 0.3928 TrainAcc 0.6400 TestAcc 0.5786 0.6150
epoch 200 LossPred 0.4269 LossAtt 0.4030 TrainAcc 0.8200 TestAcc 0.8081 0.8400
epoch 300 LossPred 0.3344 LossAtt 0.3766 TrainAcc 0.8900 TestAcc 0.8053 0.8850
epoch 400 LossPred 0.3120 LossAtt 0.3558 TrainAcc 0.8900 TestAcc 0.8123 0.8800
epoch 500 LossPred 0.3150 LossAtt 0.3480 TrainAcc 0.8700 TestAcc 0.8056 0.8750
epoch 600 LossPred 0.2512 LossAtt 0.3383 TrainAcc 0.9100 TestAcc 0.8261 0.8900
epoch 700 LossPred 0.2874 LossAtt 0.3433 TrainAcc 0.8800 TestAcc 0.8086 0.8800
epoch 800 LossPred 0.2301 LossAtt 0.3345 TrainAcc 0.9000 TestAcc 0.8281 0.8850
epoch 900 LossPred 0.2725 LossAtt 0.3357 TrainAcc 0.9000 TestAcc 0.8158 0.8750
epoch 1000 LossPred 0.2043 LossAtt 0.3288 TrainAcc 0.9400 TestAcc 0.8316 0.8800
epoch 1100 LossPred 0.2280 LossAtt 0.3315 TrainAcc 0.9300 TestAcc 0.8301 0.8700
epoch 1200 LossPred 0.2135 LossAtt 0.3355 TrainAcc 0.9300 TestAcc 0.8253 0.8900
epoch 1300 LossPred 0.1999 LossAtt 0.3296 TrainAcc 0.9500 TestAcc 0.8341 0.8650
epoch 1400 LossPred 0.1910 LossAtt 0.3223 TrainAcc 0.9500 TestAcc 0.8261 0.8900
epoch 1500 LossPred 0.1934 LossAtt 0.3258 TrainAcc 0.9400 TestAcc 0.8226 0.9000
epoch 1600 LossPred 0.1969 LossAtt 0.3303 TrainAcc 0.9500 TestAcc 0.8241 0.8850
epoch 1700 LossPred 0.1841 LossAtt 0.3121 TrainAcc 0.9500 TestAcc 0.8141 0.8950
epoch 1800 LossPred 0.2084 LossAtt 0.3098 TrainAcc 0.9300 TestAcc 0.8038 0.8900
epoch 1900 LossPred 0.1905 LossAtt 0.3155 TrainAcc 0.9400 TestAcc 0.8148 0.8800
epoch 2000 LossPred 0.1767 LossAtt 0.3053 TrainAcc 0.9500 TestAcc 0.8163 0.9050
epoch 2100 LossPred 0.2073 LossAtt 0.3083 TrainAcc 0.9400 TestAcc 0.8003 0.9000
epoch 2200 LossPred 0.1711 LossAtt 0.3053 TrainAcc 0.9600 TestAcc 0.8111 0.9000
epoch 2300 LossPred 0.1664 LossAtt 0.3093 TrainAcc 0.9700 TestAcc 0.8153 0.8950
epoch 2400 LossPred 0.1741 LossAtt 0.3026 TrainAcc 0.9600 TestAcc 0.8146 0.8900
epoch 2500 LossPred 0.1635 LossAtt 0.3001 TrainAcc 0.9700 TestAcc 0.8126 0.8900
Optimization Finished!
********** replication  59  **********
epoch   0 LossPred 1.2099 LossAtt 1.0346 TrainAcc 0.4700 TestAcc 0.4620 0.4600
epoch 100 LossPred 0.9376 LossAtt 0.3385 TrainAcc 0.6300 TestAcc 0.5953 0.6200
epoch 200 LossPred 0.5965 LossAtt 0.3697 TrainAcc 0.8200 TestAcc 0.7975 0.8400
epoch 300 LossPred 0.3669 LossAtt 0.3323 TrainAcc 0.8800 TestAcc 0.8566 0.8850
epoch 400 LossPred 0.3272 LossAtt 0.3523 TrainAcc 0.8700 TestAcc 0.8541 0.8850
epoch 500 LossPred 0.2219 LossAtt 0.3661 TrainAcc 0.9300 TestAcc 0.8764 0.8900
epoch 600 LossPred 0.2025 LossAtt 0.3368 TrainAcc 0.9400 TestAcc 0.8786 0.9000
epoch 700 LossPred 0.1343 LossAtt 0.3415 TrainAcc 0.9700 TestAcc 0.8961 0.9150
epoch 800 LossPred 0.1691 LossAtt 0.3163 TrainAcc 0.9600 TestAcc 0.8876 0.8950
epoch 900 LossPred 0.1685 LossAtt 0.3315 TrainAcc 0.9500 TestAcc 0.8931 0.8950
epoch 1000 LossPred 0.0660 LossAtt 0.3086 TrainAcc 0.9900 TestAcc 0.9154 0.9550
epoch 1100 LossPred 0.0464 LossAtt 0.3055 TrainAcc 0.9900 TestAcc 0.9154 0.9500
epoch 1200 LossPred 0.0797 LossAtt 0.3100 TrainAcc 0.9900 TestAcc 0.9044 0.9500
epoch 1300 LossPred 0.0441 LossAtt 0.3037 TrainAcc 1.0000 TestAcc 0.9049 0.9500
Optimization Finished!
********** replication  60  **********
epoch   0 LossPred 0.9746 LossAtt 1.0287 TrainAcc 0.5700 TestAcc 0.5681 0.5900
epoch 100 LossPred 0.8973 LossAtt 0.4001 TrainAcc 0.6700 TestAcc 0.5110 0.6500
epoch 200 LossPred 0.7135 LossAtt 0.5030 TrainAcc 0.7300 TestAcc 0.5280 0.7300
epoch 300 LossPred 0.5976 LossAtt 0.5283 TrainAcc 0.8100 TestAcc 0.5385 0.7750
epoch 400 LossPred 0.5119 LossAtt 0.5272 TrainAcc 0.8300 TestAcc 0.5443 0.7850
epoch 500 LossPred 0.4489 LossAtt 0.5531 TrainAcc 0.8600 TestAcc 0.5388 0.7900
epoch 600 LossPred 0.3908 LossAtt 0.5258 TrainAcc 0.8900 TestAcc 0.5418 0.7900
epoch 700 LossPred 0.3620 LossAtt 0.5035 TrainAcc 0.9000 TestAcc 0.5385 0.8050
epoch 800 LossPred 0.3347 LossAtt 0.5243 TrainAcc 0.9100 TestAcc 0.5420 0.8050
epoch 900 LossPred 0.3160 LossAtt 0.4971 TrainAcc 0.9200 TestAcc 0.5345 0.8250
epoch 1000 LossPred 0.3076 LossAtt 0.5048 TrainAcc 0.9200 TestAcc 0.5333 0.8300
epoch 1100 LossPred 0.2750 LossAtt 0.4943 TrainAcc 0.9500 TestAcc 0.5348 0.8350
epoch 1200 LossPred 0.2546 LossAtt 0.5016 TrainAcc 0.9500 TestAcc 0.5278 0.8300
epoch 1300 LossPred 0.2557 LossAtt 0.5056 TrainAcc 0.9400 TestAcc 0.5290 0.8250
epoch 1400 LossPred 0.2176 LossAtt 0.5022 TrainAcc 0.9500 TestAcc 0.5313 0.8450
epoch 1500 LossPred 0.1964 LossAtt 0.5093 TrainAcc 0.9500 TestAcc 0.5345 0.8150
epoch 1600 LossPred 0.1784 LossAtt 0.4969 TrainAcc 0.9700 TestAcc 0.5430 0.8150
epoch 1700 LossPred 0.1774 LossAtt 0.5091 TrainAcc 0.9700 TestAcc 0.5448 0.8000
epoch 1800 LossPred 0.1671 LossAtt 0.4952 TrainAcc 0.9700 TestAcc 0.5443 0.7800
epoch 1900 LossPred 0.1599 LossAtt 0.5233 TrainAcc 0.9600 TestAcc 0.5405 0.7950
epoch 2000 LossPred 0.1383 LossAtt 0.5167 TrainAcc 0.9700 TestAcc 0.5490 0.8150
epoch 2100 LossPred 0.1274 LossAtt 0.5211 TrainAcc 0.9700 TestAcc 0.5403 0.8600
epoch 2200 LossPred 0.1225 LossAtt 0.5019 TrainAcc 0.9800 TestAcc 0.5501 0.8200
epoch 2300 LossPred 0.1178 LossAtt 0.5106 TrainAcc 0.9800 TestAcc 0.5526 0.8350
epoch 2400 LossPred 0.1092 LossAtt 0.5052 TrainAcc 0.9800 TestAcc 0.5498 0.8600
epoch 2500 LossPred 0.1046 LossAtt 0.5019 TrainAcc 0.9800 TestAcc 0.5495 0.8500
Optimization Finished!
********** replication  61  **********
epoch   0 LossPred 1.0057 LossAtt 1.0158 TrainAcc 0.4800 TestAcc 0.4942 0.4700
epoch 100 LossPred 0.7349 LossAtt 0.4027 TrainAcc 0.7300 TestAcc 0.7417 0.7500
epoch 200 LossPred 0.2452 LossAtt 0.3243 TrainAcc 0.9400 TestAcc 0.8769 0.9000
epoch 300 LossPred 0.2596 LossAtt 0.3167 TrainAcc 0.9400 TestAcc 0.8631 0.8800
epoch 400 LossPred 0.2790 LossAtt 0.3003 TrainAcc 0.9200 TestAcc 0.8729 0.8650
epoch 500 LossPred 0.2683 LossAtt 0.2812 TrainAcc 0.9300 TestAcc 0.8756 0.8850
epoch 600 LossPred 0.4204 LossAtt 0.2861 TrainAcc 0.8500 TestAcc 0.8071 0.8350
epoch 700 LossPred 0.2962 LossAtt 0.2715 TrainAcc 0.9200 TestAcc 0.8541 0.8750
epoch 800 LossPred 0.3680 LossAtt 0.2638 TrainAcc 0.8800 TestAcc 0.8656 0.8800
epoch 900 LossPred 0.4629 LossAtt 0.2894 TrainAcc 0.8500 TestAcc 0.8373 0.8650
epoch 1000 LossPred 0.3262 LossAtt 0.2919 TrainAcc 0.9000 TestAcc 0.8321 0.8850
epoch 1100 LossPred 0.6924 LossAtt 0.3028 TrainAcc 0.7700 TestAcc 0.7475 0.7900
epoch 1200 LossPred 0.2677 LossAtt 0.2999 TrainAcc 0.9200 TestAcc 0.8589 0.9000
epoch 1300 LossPred 0.2602 LossAtt 0.2826 TrainAcc 0.9200 TestAcc 0.8664 0.9150
epoch 1400 LossPred 0.4106 LossAtt 0.2777 TrainAcc 0.8800 TestAcc 0.8293 0.8600
epoch 1500 LossPred 0.2904 LossAtt 0.2712 TrainAcc 0.9300 TestAcc 0.8321 0.8950
epoch 1600 LossPred 0.2081 LossAtt 0.2677 TrainAcc 0.9500 TestAcc 0.8606 0.8950
epoch 1700 LossPred 0.2818 LossAtt 0.2615 TrainAcc 0.9300 TestAcc 0.8306 0.9000
epoch 1800 LossPred 0.3845 LossAtt 0.2587 TrainAcc 0.8800 TestAcc 0.8188 0.8900
epoch 1900 LossPred 0.1972 LossAtt 0.2677 TrainAcc 0.9500 TestAcc 0.8531 0.9100
epoch 2000 LossPred 0.4612 LossAtt 0.2682 TrainAcc 0.8700 TestAcc 0.8228 0.8450
epoch 2100 LossPred 0.4302 LossAtt 0.2645 TrainAcc 0.8800 TestAcc 0.8066 0.8600
epoch 2200 LossPred 0.4795 LossAtt 0.2851 TrainAcc 0.8500 TestAcc 0.8168 0.8550
epoch 2300 LossPred 0.3043 LossAtt 0.2811 TrainAcc 0.9000 TestAcc 0.8526 0.9050
epoch 2400 LossPred 0.5851 LossAtt 0.3020 TrainAcc 0.8300 TestAcc 0.7843 0.8350
epoch 2500 LossPred 0.1982 LossAtt 0.3083 TrainAcc 0.9400 TestAcc 0.8398 0.9150
Optimization Finished!
********** replication  62  **********
epoch   0 LossPred 1.2571 LossAtt 1.0241 TrainAcc 0.4300 TestAcc 0.4770 0.4300
epoch 100 LossPred 0.8452 LossAtt 0.3406 TrainAcc 0.7200 TestAcc 0.6181 0.7100
epoch 200 LossPred 0.8601 LossAtt 0.3575 TrainAcc 0.6400 TestAcc 0.6642 0.6650
epoch 300 LossPred 0.6754 LossAtt 0.3132 TrainAcc 0.7900 TestAcc 0.7785 0.7600
epoch 400 LossPred 0.5706 LossAtt 0.2934 TrainAcc 0.8100 TestAcc 0.8126 0.7950
epoch 500 LossPred 0.5181 LossAtt 0.2919 TrainAcc 0.8000 TestAcc 0.8163 0.7950
epoch 600 LossPred 0.5855 LossAtt 0.2735 TrainAcc 0.7700 TestAcc 0.7908 0.7650
epoch 700 LossPred 0.4922 LossAtt 0.2630 TrainAcc 0.8000 TestAcc 0.8081 0.8050
epoch 800 LossPred 0.5389 LossAtt 0.2785 TrainAcc 0.8100 TestAcc 0.8203 0.8000
epoch 900 LossPred 0.4576 LossAtt 0.2763 TrainAcc 0.8200 TestAcc 0.8196 0.8250
epoch 1000 LossPred 0.5324 LossAtt 0.2787 TrainAcc 0.8100 TestAcc 0.7650 0.8000
epoch 1100 LossPred 0.4957 LossAtt 0.2696 TrainAcc 0.8100 TestAcc 0.7758 0.8050
epoch 1200 LossPred 0.4416 LossAtt 0.2778 TrainAcc 0.8300 TestAcc 0.8148 0.8050
epoch 1300 LossPred 0.3866 LossAtt 0.3085 TrainAcc 0.8600 TestAcc 0.8136 0.8100
epoch 1400 LossPred 0.4122 LossAtt 0.3030 TrainAcc 0.8400 TestAcc 0.8046 0.8250
epoch 1500 LossPred 0.3737 LossAtt 0.3133 TrainAcc 0.8600 TestAcc 0.8151 0.8300
epoch 1600 LossPred 0.3354 LossAtt 0.3183 TrainAcc 0.8900 TestAcc 0.8271 0.8300
epoch 1700 LossPred 0.4012 LossAtt 0.3171 TrainAcc 0.8500 TestAcc 0.8126 0.8300
epoch 1800 LossPred 0.3696 LossAtt 0.3132 TrainAcc 0.8600 TestAcc 0.8318 0.8200
epoch 1900 LossPred 0.3649 LossAtt 0.3159 TrainAcc 0.8600 TestAcc 0.8376 0.8400
epoch 2000 LossPred 0.3352 LossAtt 0.3083 TrainAcc 0.8700 TestAcc 0.8288 0.8400
epoch 2100 LossPred 0.3129 LossAtt 0.2910 TrainAcc 0.8900 TestAcc 0.8198 0.8400
epoch 2200 LossPred 0.5771 LossAtt 0.2976 TrainAcc 0.8100 TestAcc 0.7863 0.7750
epoch 2300 LossPred 0.3553 LossAtt 0.3029 TrainAcc 0.8700 TestAcc 0.8171 0.8450
epoch 2400 LossPred 0.4694 LossAtt 0.2914 TrainAcc 0.8300 TestAcc 0.7975 0.8050
epoch 2500 LossPred 0.3569 LossAtt 0.3162 TrainAcc 0.8600 TestAcc 0.7878 0.8450
Optimization Finished!
********** replication  63  **********
epoch   0 LossPred 1.0150 LossAtt 1.0129 TrainAcc 0.5400 TestAcc 0.5405 0.5500
epoch 100 LossPred 0.9497 LossAtt 0.2354 TrainAcc 0.6100 TestAcc 0.5821 0.6100
epoch 200 LossPred 0.9476 LossAtt 0.2062 TrainAcc 0.6100 TestAcc 0.5821 0.6100
epoch 300 LossPred 0.8859 LossAtt 0.3546 TrainAcc 0.6400 TestAcc 0.5410 0.6500
epoch 400 LossPred 0.7942 LossAtt 0.3276 TrainAcc 0.7100 TestAcc 0.5328 0.6900
epoch 500 LossPred 0.7287 LossAtt 0.3705 TrainAcc 0.7700 TestAcc 0.5368 0.7350
epoch 600 LossPred 0.6592 LossAtt 0.4117 TrainAcc 0.7700 TestAcc 0.5310 0.7700
epoch 700 LossPred 0.5982 LossAtt 0.4646 TrainAcc 0.8200 TestAcc 0.5355 0.7650
epoch 800 LossPred 0.5204 LossAtt 0.4835 TrainAcc 0.8300 TestAcc 0.5400 0.7400
epoch 900 LossPred 0.4811 LossAtt 0.5055 TrainAcc 0.8400 TestAcc 0.5353 0.7500
epoch 1000 LossPred 0.4407 LossAtt 0.5104 TrainAcc 0.8500 TestAcc 0.5358 0.7550
epoch 1100 LossPred 0.3873 LossAtt 0.5060 TrainAcc 0.8600 TestAcc 0.5365 0.7650
epoch 1200 LossPred 0.3473 LossAtt 0.4953 TrainAcc 0.8800 TestAcc 0.5348 0.7550
epoch 1300 LossPred 0.3215 LossAtt 0.5080 TrainAcc 0.9000 TestAcc 0.5408 0.7650
epoch 1400 LossPred 0.3030 LossAtt 0.5269 TrainAcc 0.9100 TestAcc 0.5345 0.7700
epoch 1500 LossPred 0.3248 LossAtt 0.4892 TrainAcc 0.8900 TestAcc 0.5343 0.7600
epoch 1600 LossPred 0.3778 LossAtt 0.4968 TrainAcc 0.8600 TestAcc 0.5278 0.7200
epoch 1700 LossPred 0.2702 LossAtt 0.4993 TrainAcc 0.9100 TestAcc 0.5280 0.7500
epoch 1800 LossPred 0.2681 LossAtt 0.4936 TrainAcc 0.9300 TestAcc 0.5213 0.7900
epoch 1900 LossPred 0.2595 LossAtt 0.4844 TrainAcc 0.9200 TestAcc 0.5250 0.7550
epoch 2000 LossPred 0.2605 LossAtt 0.4757 TrainAcc 0.9100 TestAcc 0.5245 0.7450
epoch 2100 LossPred 0.2531 LossAtt 0.4782 TrainAcc 0.9300 TestAcc 0.5208 0.7600
epoch 2200 LossPred 0.2118 LossAtt 0.4860 TrainAcc 0.9400 TestAcc 0.5160 0.7650
epoch 2300 LossPred 0.2219 LossAtt 0.4706 TrainAcc 0.9500 TestAcc 0.5113 0.7850
epoch 2400 LossPred 0.2028 LossAtt 0.4669 TrainAcc 0.9500 TestAcc 0.5133 0.7800
epoch 2500 LossPred 0.2013 LossAtt 0.4519 TrainAcc 0.9500 TestAcc 0.5148 0.7550
Optimization Finished!
********** replication  64  **********
epoch   0 LossPred 1.0255 LossAtt 1.0329 TrainAcc 0.5000 TestAcc 0.4727 0.4900
epoch 100 LossPred 0.8687 LossAtt 0.3455 TrainAcc 0.6700 TestAcc 0.6439 0.6700
epoch 200 LossPred 0.4194 LossAtt 0.3793 TrainAcc 0.8800 TestAcc 0.8676 0.8700
epoch 300 LossPred 0.3755 LossAtt 0.3774 TrainAcc 0.8900 TestAcc 0.8746 0.8800
epoch 400 LossPred 0.2968 LossAtt 0.3808 TrainAcc 0.9100 TestAcc 0.8841 0.8850
epoch 500 LossPred 0.2032 LossAtt 0.3583 TrainAcc 0.9500 TestAcc 0.9037 0.9300
epoch 600 LossPred 0.1835 LossAtt 0.3407 TrainAcc 0.9600 TestAcc 0.9074 0.9150
epoch 700 LossPred 0.1763 LossAtt 0.3353 TrainAcc 0.9500 TestAcc 0.9082 0.9200
epoch 800 LossPred 0.2155 LossAtt 0.3247 TrainAcc 0.9200 TestAcc 0.8924 0.9200
epoch 900 LossPred 0.1613 LossAtt 0.3161 TrainAcc 0.9600 TestAcc 0.9139 0.9400
epoch 1000 LossPred 0.1423 LossAtt 0.3118 TrainAcc 0.9600 TestAcc 0.9144 0.9300
epoch 1100 LossPred 0.1852 LossAtt 0.3117 TrainAcc 0.9300 TestAcc 0.9142 0.9000
epoch 1200 LossPred 0.2654 LossAtt 0.3044 TrainAcc 0.9000 TestAcc 0.9014 0.8800
epoch 1300 LossPred 0.1500 LossAtt 0.3068 TrainAcc 0.9600 TestAcc 0.9209 0.9000
epoch 1400 LossPred 0.2147 LossAtt 0.2912 TrainAcc 0.9400 TestAcc 0.9099 0.8900
epoch 1500 LossPred 0.1643 LossAtt 0.2996 TrainAcc 0.9500 TestAcc 0.9079 0.9050
epoch 1600 LossPred 0.1738 LossAtt 0.2928 TrainAcc 0.9400 TestAcc 0.9079 0.9150
epoch 1700 LossPred 0.2219 LossAtt 0.3044 TrainAcc 0.9300 TestAcc 0.8889 0.9200
epoch 1800 LossPred 0.1714 LossAtt 0.3018 TrainAcc 0.9400 TestAcc 0.9032 0.9150
epoch 1900 LossPred 0.2855 LossAtt 0.3039 TrainAcc 0.9100 TestAcc 0.8649 0.9000
epoch 2000 LossPred 0.1757 LossAtt 0.3033 TrainAcc 0.9600 TestAcc 0.9099 0.9100
epoch 2100 LossPred 0.1845 LossAtt 0.2914 TrainAcc 0.9500 TestAcc 0.9077 0.9250
epoch 2200 LossPred 0.1783 LossAtt 0.2813 TrainAcc 0.9600 TestAcc 0.9184 0.8700
epoch 2300 LossPred 0.1732 LossAtt 0.2771 TrainAcc 0.9600 TestAcc 0.9234 0.8800
epoch 2400 LossPred 0.1759 LossAtt 0.2819 TrainAcc 0.9600 TestAcc 0.9124 0.9250
epoch 2500 LossPred 0.3480 LossAtt 0.2904 TrainAcc 0.8900 TestAcc 0.8288 0.9000
Optimization Finished!
********** replication  65  **********
epoch   0 LossPred 0.9630 LossAtt 1.0172 TrainAcc 0.5800 TestAcc 0.5671 0.5800
epoch 100 LossPred 0.9208 LossAtt 0.3334 TrainAcc 0.6300 TestAcc 0.5883 0.6250
epoch 200 LossPred 0.5467 LossAtt 0.4921 TrainAcc 0.8300 TestAcc 0.7550 0.7900
epoch 300 LossPred 0.2965 LossAtt 0.4366 TrainAcc 0.9000 TestAcc 0.7988 0.8700
epoch 400 LossPred 0.1892 LossAtt 0.4515 TrainAcc 0.9300 TestAcc 0.8268 0.8850
epoch 500 LossPred 0.1271 LossAtt 0.4412 TrainAcc 0.9600 TestAcc 0.8171 0.8800
epoch 600 LossPred 0.1208 LossAtt 0.4223 TrainAcc 0.9600 TestAcc 0.8236 0.8800
epoch 700 LossPred 0.1067 LossAtt 0.4300 TrainAcc 0.9700 TestAcc 0.8323 0.9000
epoch 800 LossPred 0.0726 LossAtt 0.4358 TrainAcc 0.9800 TestAcc 0.8206 0.8850
epoch 900 LossPred 0.0721 LossAtt 0.4305 TrainAcc 0.9800 TestAcc 0.8273 0.8950
epoch 1000 LossPred 0.0705 LossAtt 0.4249 TrainAcc 0.9800 TestAcc 0.8376 0.8900
epoch 1100 LossPred 0.0986 LossAtt 0.4245 TrainAcc 0.9800 TestAcc 0.8363 0.9050
epoch 1200 LossPred 0.0564 LossAtt 0.4067 TrainAcc 0.9900 TestAcc 0.8366 0.9050
epoch 1300 LossPred 0.0512 LossAtt 0.4032 TrainAcc 0.9900 TestAcc 0.8273 0.9100
epoch 1400 LossPred 0.0497 LossAtt 0.4004 TrainAcc 0.9900 TestAcc 0.8338 0.9100
epoch 1500 LossPred 0.1072 LossAtt 0.3848 TrainAcc 0.9700 TestAcc 0.8251 0.9150
epoch 1600 LossPred 0.0999 LossAtt 0.3824 TrainAcc 0.9600 TestAcc 0.8356 0.9200
epoch 1700 LossPred 0.0521 LossAtt 0.3779 TrainAcc 0.9900 TestAcc 0.8263 0.9200
epoch 1800 LossPred 0.0520 LossAtt 0.3691 TrainAcc 0.9900 TestAcc 0.8351 0.8950
epoch 1900 LossPred 0.0655 LossAtt 0.3584 TrainAcc 0.9800 TestAcc 0.8051 0.9150
epoch 2000 LossPred 0.0595 LossAtt 0.3641 TrainAcc 0.9900 TestAcc 0.8331 0.9100
epoch 2100 LossPred 0.0570 LossAtt 0.3518 TrainAcc 0.9800 TestAcc 0.8176 0.9050
epoch 2200 LossPred 0.0469 LossAtt 0.3399 TrainAcc 0.9900 TestAcc 0.8336 0.9050
epoch 2300 LossPred 0.0504 LossAtt 0.3373 TrainAcc 0.9900 TestAcc 0.8363 0.9050
epoch 2400 LossPred 0.0452 LossAtt 0.3505 TrainAcc 0.9900 TestAcc 0.8271 0.9050
epoch 2500 LossPred 0.2610 LossAtt 0.3428 TrainAcc 0.9300 TestAcc 0.7848 0.9050
Optimization Finished!
********** replication  66  **********
epoch   0 LossPred 1.0374 LossAtt 1.0553 TrainAcc 0.5300 TestAcc 0.5478 0.5250
epoch 100 LossPred 0.9093 LossAtt 0.3268 TrainAcc 0.6100 TestAcc 0.5926 0.6150
epoch 200 LossPred 0.3211 LossAtt 0.4024 TrainAcc 0.8700 TestAcc 0.8576 0.9150
epoch 300 LossPred 0.1609 LossAtt 0.3646 TrainAcc 0.9400 TestAcc 0.8746 0.9250
epoch 400 LossPred 0.1279 LossAtt 0.3525 TrainAcc 0.9600 TestAcc 0.8826 0.9350
epoch 500 LossPred 0.1143 LossAtt 0.3407 TrainAcc 0.9500 TestAcc 0.8841 0.9300
epoch 600 LossPred 0.1083 LossAtt 0.3129 TrainAcc 0.9500 TestAcc 0.8881 0.9350
epoch 700 LossPred 0.1344 LossAtt 0.2982 TrainAcc 0.9400 TestAcc 0.8816 0.9300
epoch 800 LossPred 0.1067 LossAtt 0.2650 TrainAcc 0.9500 TestAcc 0.8891 0.9400
epoch 900 LossPred 0.1710 LossAtt 0.2592 TrainAcc 0.9200 TestAcc 0.8869 0.9350
epoch 1000 LossPred 0.3820 LossAtt 0.2446 TrainAcc 0.8800 TestAcc 0.8436 0.8850
epoch 1100 LossPred 0.1071 LossAtt 0.2350 TrainAcc 0.9700 TestAcc 0.8944 0.9500
epoch 1200 LossPred 0.1374 LossAtt 0.2372 TrainAcc 0.9400 TestAcc 0.8981 0.9500
epoch 1300 LossPred 0.1382 LossAtt 0.2400 TrainAcc 0.9300 TestAcc 0.8789 0.9250
epoch 1400 LossPred 0.1116 LossAtt 0.2268 TrainAcc 0.9800 TestAcc 0.8889 0.9500
epoch 1500 LossPred 0.1016 LossAtt 0.2165 TrainAcc 0.9900 TestAcc 0.8934 0.9600
epoch 1600 LossPred 0.1310 LossAtt 0.2202 TrainAcc 0.9800 TestAcc 0.8884 0.9400
epoch 1700 LossPred 0.0849 LossAtt 0.2214 TrainAcc 0.9600 TestAcc 0.8904 0.9400
epoch 1800 LossPred 0.0713 LossAtt 0.2232 TrainAcc 0.9900 TestAcc 0.8936 0.9600
epoch 1900 LossPred 0.0890 LossAtt 0.2116 TrainAcc 0.9800 TestAcc 0.8846 0.9400
epoch 2000 LossPred 0.0669 LossAtt 0.2143 TrainAcc 0.9900 TestAcc 0.8946 0.9600
epoch 2100 LossPred 0.1179 LossAtt 0.2097 TrainAcc 0.9500 TestAcc 0.8934 0.9400
epoch 2200 LossPred 0.0775 LossAtt 0.2156 TrainAcc 0.9700 TestAcc 0.8879 0.9300
epoch 2300 LossPred 0.0722 LossAtt 0.2088 TrainAcc 0.9700 TestAcc 0.8891 0.9550
epoch 2400 LossPred 0.0883 LossAtt 0.2202 TrainAcc 0.9800 TestAcc 0.8921 0.9650
epoch 2500 LossPred 0.0765 LossAtt 0.2176 TrainAcc 0.9800 TestAcc 0.8866 0.9350
Optimization Finished!
********** replication  67  **********
epoch   0 LossPred 1.0818 LossAtt 1.0189 TrainAcc 0.4800 TestAcc 0.4522 0.4500
epoch 100 LossPred 0.9624 LossAtt 0.2586 TrainAcc 0.5800 TestAcc 0.5841 0.5800
epoch 200 LossPred 0.9630 LossAtt 0.1606 TrainAcc 0.5800 TestAcc 0.5841 0.5800
epoch 300 LossPred 0.9621 LossAtt 0.1186 TrainAcc 0.5800 TestAcc 0.5841 0.5800
epoch 400 LossPred 0.9599 LossAtt 0.1308 TrainAcc 0.5800 TestAcc 0.5841 0.5850
epoch 500 LossPred 0.7058 LossAtt 0.4155 TrainAcc 0.7700 TestAcc 0.7960 0.7500
epoch 600 LossPred 0.5071 LossAtt 0.3976 TrainAcc 0.8400 TestAcc 0.8103 0.8100
epoch 700 LossPred 0.5344 LossAtt 0.3870 TrainAcc 0.8300 TestAcc 0.8183 0.8050
epoch 800 LossPred 0.4710 LossAtt 0.3935 TrainAcc 0.8400 TestAcc 0.8406 0.8300
epoch 900 LossPred 0.2846 LossAtt 0.3745 TrainAcc 0.9100 TestAcc 0.8781 0.8650
epoch 1000 LossPred 0.2130 LossAtt 0.3504 TrainAcc 0.9500 TestAcc 0.8829 0.9000
epoch 1100 LossPred 0.2017 LossAtt 0.3432 TrainAcc 0.9500 TestAcc 0.8806 0.9050
epoch 1200 LossPred 0.1779 LossAtt 0.3202 TrainAcc 0.9600 TestAcc 0.8886 0.9050
epoch 1300 LossPred 0.1872 LossAtt 0.3172 TrainAcc 0.9600 TestAcc 0.8829 0.9150
epoch 1400 LossPred 0.1746 LossAtt 0.2902 TrainAcc 0.9600 TestAcc 0.8921 0.9200
epoch 1500 LossPred 0.2234 LossAtt 0.2831 TrainAcc 0.9200 TestAcc 0.8759 0.9200
epoch 1600 LossPred 0.2366 LossAtt 0.2794 TrainAcc 0.9200 TestAcc 0.8916 0.9150
epoch 1700 LossPred 0.2928 LossAtt 0.2735 TrainAcc 0.9000 TestAcc 0.8589 0.8950
epoch 1800 LossPred 0.1463 LossAtt 0.2582 TrainAcc 0.9700 TestAcc 0.8954 0.9350
epoch 1900 LossPred 0.1773 LossAtt 0.2547 TrainAcc 0.9600 TestAcc 0.8924 0.9350
epoch 2000 LossPred 0.2419 LossAtt 0.2408 TrainAcc 0.9200 TestAcc 0.8914 0.9250
epoch 2100 LossPred 0.1912 LossAtt 0.2378 TrainAcc 0.9300 TestAcc 0.8964 0.9400
epoch 2200 LossPred 0.1362 LossAtt 0.2257 TrainAcc 0.9700 TestAcc 0.8964 0.9400
epoch 2300 LossPred 0.1437 LossAtt 0.2195 TrainAcc 0.9700 TestAcc 0.8931 0.9400
epoch 2400 LossPred 0.1462 LossAtt 0.2186 TrainAcc 0.9600 TestAcc 0.8934 0.9350
epoch 2500 LossPred 0.1541 LossAtt 0.2102 TrainAcc 0.9800 TestAcc 0.8899 0.9300
Optimization Finished!
********** replication  68  **********
epoch   0 LossPred 0.9453 LossAtt 1.0290 TrainAcc 0.6000 TestAcc 0.5631 0.6000
epoch 100 LossPred 0.8486 LossAtt 0.4197 TrainAcc 0.6400 TestAcc 0.6079 0.6650
epoch 200 LossPred 0.4077 LossAtt 0.3853 TrainAcc 0.8600 TestAcc 0.7870 0.8500
epoch 300 LossPred 0.3105 LossAtt 0.3669 TrainAcc 0.9100 TestAcc 0.7983 0.8650
epoch 400 LossPred 0.3027 LossAtt 0.3643 TrainAcc 0.9100 TestAcc 0.8021 0.8600
epoch 500 LossPred 0.2866 LossAtt 0.3694 TrainAcc 0.9200 TestAcc 0.8098 0.8700
epoch 600 LossPred 0.2851 LossAtt 0.3777 TrainAcc 0.9100 TestAcc 0.8138 0.8600
epoch 700 LossPred 0.3147 LossAtt 0.3674 TrainAcc 0.9000 TestAcc 0.8151 0.8700
epoch 800 LossPred 0.3205 LossAtt 0.3694 TrainAcc 0.9000 TestAcc 0.8158 0.8700
epoch 900 LossPred 0.2564 LossAtt 0.3791 TrainAcc 0.9100 TestAcc 0.8328 0.8900
epoch 1000 LossPred 0.3781 LossAtt 0.3681 TrainAcc 0.8700 TestAcc 0.8176 0.8450
epoch 1100 LossPred 0.2440 LossAtt 0.3553 TrainAcc 0.9200 TestAcc 0.8408 0.9050
epoch 1200 LossPred 0.2500 LossAtt 0.3390 TrainAcc 0.9400 TestAcc 0.8418 0.9100
epoch 1300 LossPred 0.2566 LossAtt 0.3347 TrainAcc 0.9200 TestAcc 0.8248 0.8950
epoch 1400 LossPred 0.2744 LossAtt 0.3175 TrainAcc 0.9300 TestAcc 0.8431 0.9150
epoch 1500 LossPred 0.2292 LossAtt 0.3152 TrainAcc 0.9300 TestAcc 0.8403 0.9200
epoch 1600 LossPred 0.2291 LossAtt 0.3083 TrainAcc 0.9200 TestAcc 0.8403 0.9050
epoch 1700 LossPred 0.2226 LossAtt 0.3154 TrainAcc 0.9200 TestAcc 0.8438 0.9150
epoch 1800 LossPred 0.2323 LossAtt 0.3065 TrainAcc 0.9200 TestAcc 0.8363 0.9050
epoch 1900 LossPred 0.2207 LossAtt 0.2978 TrainAcc 0.9200 TestAcc 0.8383 0.9100
epoch 2000 LossPred 0.2103 LossAtt 0.2989 TrainAcc 0.9400 TestAcc 0.8544 0.9250
epoch 2100 LossPred 0.3042 LossAtt 0.3107 TrainAcc 0.8800 TestAcc 0.8233 0.8650
epoch 2200 LossPred 0.2340 LossAtt 0.3087 TrainAcc 0.9200 TestAcc 0.8549 0.8900
epoch 2300 LossPred 0.1944 LossAtt 0.2868 TrainAcc 0.9300 TestAcc 0.8516 0.9200
epoch 2400 LossPred 0.2513 LossAtt 0.3076 TrainAcc 0.9200 TestAcc 0.8423 0.9050
epoch 2500 LossPred 0.1850 LossAtt 0.2993 TrainAcc 0.9300 TestAcc 0.8584 0.9300
Optimization Finished!
********** replication  69  **********
epoch   0 LossPred 1.0048 LossAtt 1.0141 TrainAcc 0.5300 TestAcc 0.4830 0.5250
epoch 100 LossPred 0.8969 LossAtt 0.4289 TrainAcc 0.6200 TestAcc 0.5756 0.6100
epoch 200 LossPred 0.8574 LossAtt 0.4021 TrainAcc 0.6400 TestAcc 0.5776 0.6250
epoch 300 LossPred 0.7709 LossAtt 0.4918 TrainAcc 0.7000 TestAcc 0.5806 0.6750
epoch 400 LossPred 0.6838 LossAtt 0.5533 TrainAcc 0.7300 TestAcc 0.5908 0.7150
epoch 500 LossPred 0.6706 LossAtt 0.5721 TrainAcc 0.7400 TestAcc 0.6069 0.6950
epoch 600 LossPred 0.5580 LossAtt 0.5604 TrainAcc 0.8200 TestAcc 0.6446 0.7900
epoch 700 LossPred 0.4436 LossAtt 0.5571 TrainAcc 0.8700 TestAcc 0.6737 0.8050
epoch 800 LossPred 0.4044 LossAtt 0.5512 TrainAcc 0.8800 TestAcc 0.6892 0.7750
epoch 900 LossPred 0.3951 LossAtt 0.5464 TrainAcc 0.8700 TestAcc 0.6852 0.7950
epoch 1000 LossPred 0.3948 LossAtt 0.5158 TrainAcc 0.8700 TestAcc 0.6742 0.8050
epoch 1100 LossPred 0.3791 LossAtt 0.5126 TrainAcc 0.8900 TestAcc 0.6787 0.8200
epoch 1200 LossPred 0.3757 LossAtt 0.4942 TrainAcc 0.8900 TestAcc 0.6909 0.8350
epoch 1300 LossPred 0.3458 LossAtt 0.4949 TrainAcc 0.9000 TestAcc 0.6929 0.8400
epoch 1400 LossPred 0.3535 LossAtt 0.4892 TrainAcc 0.9100 TestAcc 0.7045 0.8150
epoch 1500 LossPred 0.3345 LossAtt 0.4963 TrainAcc 0.9100 TestAcc 0.7060 0.8450
epoch 1600 LossPred 0.3305 LossAtt 0.4861 TrainAcc 0.9000 TestAcc 0.7037 0.8650
epoch 1700 LossPred 0.2573 LossAtt 0.4990 TrainAcc 0.9300 TestAcc 0.7222 0.8800
epoch 1800 LossPred 0.2848 LossAtt 0.4898 TrainAcc 0.9200 TestAcc 0.7277 0.8850
epoch 1900 LossPred 0.2644 LossAtt 0.4794 TrainAcc 0.9400 TestAcc 0.7197 0.8700
epoch 2000 LossPred 0.2618 LossAtt 0.4896 TrainAcc 0.9400 TestAcc 0.7320 0.8800
epoch 2100 LossPred 0.3220 LossAtt 0.5124 TrainAcc 0.8800 TestAcc 0.7222 0.8750
epoch 2200 LossPred 0.1963 LossAtt 0.5166 TrainAcc 0.9500 TestAcc 0.7477 0.9100
epoch 2300 LossPred 0.3114 LossAtt 0.5105 TrainAcc 0.9200 TestAcc 0.7490 0.8500
epoch 2400 LossPred 0.1695 LossAtt 0.4919 TrainAcc 0.9500 TestAcc 0.7583 0.9300
epoch 2500 LossPred 0.1679 LossAtt 0.5010 TrainAcc 0.9500 TestAcc 0.7485 0.9200
Optimization Finished!
********** replication  70  **********
epoch   0 LossPred 1.0668 LossAtt 1.0154 TrainAcc 0.4900 TestAcc 0.4505 0.4500
epoch 100 LossPred 0.9386 LossAtt 0.3733 TrainAcc 0.5900 TestAcc 0.5563 0.5750
epoch 200 LossPred 0.8744 LossAtt 0.4787 TrainAcc 0.6500 TestAcc 0.5851 0.6450
epoch 300 LossPred 0.5052 LossAtt 0.5343 TrainAcc 0.8400 TestAcc 0.8041 0.8000
epoch 400 LossPred 0.1980 LossAtt 0.5316 TrainAcc 0.9400 TestAcc 0.8348 0.9000
epoch 500 LossPred 0.1841 LossAtt 0.5067 TrainAcc 0.9500 TestAcc 0.8296 0.9200
epoch 600 LossPred 0.0977 LossAtt 0.5062 TrainAcc 0.9700 TestAcc 0.8341 0.9150
epoch 700 LossPred 0.0713 LossAtt 0.4907 TrainAcc 0.9900 TestAcc 0.8416 0.9200
epoch 800 LossPred 0.0555 LossAtt 0.4684 TrainAcc 0.9900 TestAcc 0.8471 0.9200
epoch 900 LossPred 0.0483 LossAtt 0.4522 TrainAcc 0.9900 TestAcc 0.8509 0.9350
epoch 1000 LossPred 0.0875 LossAtt 0.4521 TrainAcc 0.9800 TestAcc 0.8569 0.9250
epoch 1100 LossPred 0.0379 LossAtt 0.4322 TrainAcc 1.0000 TestAcc 0.8536 0.9200
Optimization Finished!
********** replication  71  **********
epoch   0 LossPred 1.0070 LossAtt 1.0024 TrainAcc 0.5000 TestAcc 0.5223 0.5100
epoch 100 LossPred 0.9130 LossAtt 0.2776 TrainAcc 0.6400 TestAcc 0.5818 0.6400
epoch 200 LossPred 0.8021 LossAtt 0.3764 TrainAcc 0.7000 TestAcc 0.6249 0.6900
epoch 300 LossPred 0.5564 LossAtt 0.3759 TrainAcc 0.8100 TestAcc 0.7563 0.7850
epoch 400 LossPred 0.4100 LossAtt 0.3341 TrainAcc 0.8600 TestAcc 0.8216 0.8200
epoch 500 LossPred 0.4025 LossAtt 0.3305 TrainAcc 0.8600 TestAcc 0.8216 0.8250
epoch 600 LossPred 0.3680 LossAtt 0.3106 TrainAcc 0.8600 TestAcc 0.8398 0.8450
epoch 700 LossPred 0.3452 LossAtt 0.3008 TrainAcc 0.8800 TestAcc 0.8551 0.8300
epoch 800 LossPred 0.3478 LossAtt 0.3022 TrainAcc 0.8800 TestAcc 0.8328 0.8500
epoch 900 LossPred 0.3034 LossAtt 0.2959 TrainAcc 0.8900 TestAcc 0.8476 0.8650
epoch 1000 LossPred 0.2910 LossAtt 0.2994 TrainAcc 0.8800 TestAcc 0.8656 0.8650
epoch 1100 LossPred 0.2872 LossAtt 0.2898 TrainAcc 0.9000 TestAcc 0.8644 0.8650
epoch 1200 LossPred 0.3465 LossAtt 0.2905 TrainAcc 0.8600 TestAcc 0.8318 0.8650
epoch 1300 LossPred 0.2459 LossAtt 0.2901 TrainAcc 0.9300 TestAcc 0.8769 0.9000
epoch 1400 LossPred 0.2407 LossAtt 0.2839 TrainAcc 0.9200 TestAcc 0.8721 0.9000
epoch 1500 LossPred 0.2196 LossAtt 0.2814 TrainAcc 0.9300 TestAcc 0.8764 0.9100
epoch 1600 LossPred 0.2163 LossAtt 0.2864 TrainAcc 0.9200 TestAcc 0.8694 0.9000
epoch 1700 LossPred 0.2083 LossAtt 0.2822 TrainAcc 0.9400 TestAcc 0.8799 0.9200
epoch 1800 LossPred 0.2077 LossAtt 0.2832 TrainAcc 0.9300 TestAcc 0.8749 0.9100
epoch 1900 LossPred 0.2307 LossAtt 0.2942 TrainAcc 0.9300 TestAcc 0.8901 0.8950
epoch 2000 LossPred 0.2367 LossAtt 0.2965 TrainAcc 0.9200 TestAcc 0.8944 0.9100
epoch 2100 LossPred 0.1882 LossAtt 0.2801 TrainAcc 0.9500 TestAcc 0.8994 0.9250
epoch 2200 LossPred 0.2307 LossAtt 0.2923 TrainAcc 0.9200 TestAcc 0.8644 0.9200
epoch 2300 LossPred 0.1873 LossAtt 0.2723 TrainAcc 0.9500 TestAcc 0.8969 0.9450
epoch 2400 LossPred 0.3319 LossAtt 0.2913 TrainAcc 0.8700 TestAcc 0.8914 0.8800
epoch 2500 LossPred 0.1541 LossAtt 0.2798 TrainAcc 0.9700 TestAcc 0.9179 0.9350
Optimization Finished!
********** replication  72  **********
epoch   0 LossPred 1.1392 LossAtt 1.0457 TrainAcc 0.4100 TestAcc 0.4339 0.4350
epoch 100 LossPred 0.9472 LossAtt 0.3316 TrainAcc 0.5900 TestAcc 0.5641 0.5750
epoch 200 LossPred 0.6579 LossAtt 0.3620 TrainAcc 0.8000 TestAcc 0.7633 0.8350
epoch 300 LossPred 0.4560 LossAtt 0.3193 TrainAcc 0.8300 TestAcc 0.8156 0.8200
epoch 400 LossPred 0.3608 LossAtt 0.2926 TrainAcc 0.8900 TestAcc 0.8293 0.8200
epoch 500 LossPred 0.3593 LossAtt 0.3067 TrainAcc 0.8800 TestAcc 0.8218 0.8350
epoch 600 LossPred 0.4512 LossAtt 0.2995 TrainAcc 0.8600 TestAcc 0.8186 0.8100
epoch 700 LossPred 0.3349 LossAtt 0.2965 TrainAcc 0.9000 TestAcc 0.8346 0.8550
epoch 800 LossPred 0.2269 LossAtt 0.3017 TrainAcc 0.9400 TestAcc 0.8453 0.8700
epoch 900 LossPred 0.2645 LossAtt 0.3066 TrainAcc 0.9300 TestAcc 0.8408 0.8550
epoch 1000 LossPred 0.2472 LossAtt 0.2997 TrainAcc 0.9200 TestAcc 0.8366 0.8650
epoch 1100 LossPred 0.3046 LossAtt 0.2955 TrainAcc 0.9000 TestAcc 0.8348 0.8600
epoch 1200 LossPred 0.2112 LossAtt 0.3030 TrainAcc 0.9400 TestAcc 0.8321 0.8450
epoch 1300 LossPred 0.1770 LossAtt 0.2884 TrainAcc 0.9500 TestAcc 0.8398 0.8550
epoch 1400 LossPred 0.1777 LossAtt 0.2880 TrainAcc 0.9600 TestAcc 0.8461 0.8700
epoch 1500 LossPred 0.1923 LossAtt 0.2911 TrainAcc 0.9600 TestAcc 0.8381 0.8600
epoch 1600 LossPred 0.1840 LossAtt 0.2776 TrainAcc 0.9600 TestAcc 0.8406 0.8750
epoch 1700 LossPred 0.2131 LossAtt 0.2793 TrainAcc 0.9400 TestAcc 0.8506 0.8750
epoch 1800 LossPred 0.2020 LossAtt 0.2711 TrainAcc 0.9400 TestAcc 0.8443 0.8650
epoch 1900 LossPred 0.2402 LossAtt 0.2776 TrainAcc 0.9400 TestAcc 0.8413 0.8800
epoch 2000 LossPred 0.1965 LossAtt 0.2592 TrainAcc 0.9500 TestAcc 0.8483 0.8800
epoch 2100 LossPred 0.2730 LossAtt 0.2671 TrainAcc 0.9200 TestAcc 0.8443 0.8800
epoch 2200 LossPred 0.2489 LossAtt 0.2691 TrainAcc 0.9200 TestAcc 0.8463 0.8750
epoch 2300 LossPred 0.2756 LossAtt 0.2470 TrainAcc 0.9300 TestAcc 0.8328 0.8650
epoch 2400 LossPred 0.1573 LossAtt 0.2444 TrainAcc 0.9700 TestAcc 0.8451 0.8700
epoch 2500 LossPred 0.1987 LossAtt 0.2637 TrainAcc 0.9400 TestAcc 0.8478 0.8750
Optimization Finished!
********** replication  73  **********
epoch   0 LossPred 0.9949 LossAtt 1.0498 TrainAcc 0.5500 TestAcc 0.5918 0.5350
epoch 100 LossPred 0.9404 LossAtt 0.3079 TrainAcc 0.6100 TestAcc 0.5305 0.6100
epoch 200 LossPred 0.9082 LossAtt 0.3454 TrainAcc 0.6400 TestAcc 0.6534 0.6650
epoch 300 LossPred 0.3914 LossAtt 0.3460 TrainAcc 0.9000 TestAcc 0.8391 0.8700
epoch 400 LossPred 0.9930 LossAtt 0.3034 TrainAcc 0.6900 TestAcc 0.6824 0.6950
epoch 500 LossPred 0.3126 LossAtt 0.3204 TrainAcc 0.9100 TestAcc 0.8403 0.8700
epoch 600 LossPred 0.3323 LossAtt 0.2972 TrainAcc 0.9000 TestAcc 0.8403 0.8900
epoch 700 LossPred 0.3297 LossAtt 0.2838 TrainAcc 0.8800 TestAcc 0.8433 0.8600
epoch 800 LossPred 0.3349 LossAtt 0.2757 TrainAcc 0.9100 TestAcc 0.8358 0.8800
epoch 900 LossPred 0.3642 LossAtt 0.2636 TrainAcc 0.9000 TestAcc 0.8333 0.8750
epoch 1000 LossPred 0.2644 LossAtt 0.2610 TrainAcc 0.9200 TestAcc 0.8443 0.8800
epoch 1100 LossPred 0.4339 LossAtt 0.2603 TrainAcc 0.8700 TestAcc 0.8253 0.8800
epoch 1200 LossPred 0.2868 LossAtt 0.2570 TrainAcc 0.9200 TestAcc 0.8291 0.8950
epoch 1300 LossPred 0.2186 LossAtt 0.2459 TrainAcc 0.9400 TestAcc 0.8423 0.9150
epoch 1400 LossPred 0.2323 LossAtt 0.2535 TrainAcc 0.9400 TestAcc 0.8373 0.9000
epoch 1500 LossPred 0.2622 LossAtt 0.2498 TrainAcc 0.9300 TestAcc 0.8448 0.9150
epoch 1600 LossPred 0.2854 LossAtt 0.2499 TrainAcc 0.9100 TestAcc 0.8178 0.8900
epoch 1700 LossPred 0.3009 LossAtt 0.2508 TrainAcc 0.9100 TestAcc 0.8158 0.8950
epoch 1800 LossPred 0.1533 LossAtt 0.2554 TrainAcc 0.9600 TestAcc 0.8391 0.9400
epoch 1900 LossPred 0.1416 LossAtt 0.2440 TrainAcc 0.9700 TestAcc 0.8448 0.9300
epoch 2000 LossPred 0.1406 LossAtt 0.2401 TrainAcc 0.9700 TestAcc 0.8401 0.9350
epoch 2100 LossPred 0.3637 LossAtt 0.2365 TrainAcc 0.8900 TestAcc 0.8378 0.8900
epoch 2200 LossPred 0.1420 LossAtt 0.2298 TrainAcc 0.9700 TestAcc 0.8421 0.9400
epoch 2300 LossPred 0.1418 LossAtt 0.2163 TrainAcc 0.9700 TestAcc 0.8341 0.9550
epoch 2400 LossPred 0.1383 LossAtt 0.2301 TrainAcc 0.9700 TestAcc 0.8383 0.9400
epoch 2500 LossPred 0.1374 LossAtt 0.2214 TrainAcc 0.9600 TestAcc 0.8504 0.9400
Optimization Finished!
********** replication  74  **********
epoch   0 LossPred 1.0679 LossAtt 1.0686 TrainAcc 0.5300 TestAcc 0.5511 0.5400
epoch 100 LossPred 0.8568 LossAtt 0.3994 TrainAcc 0.6900 TestAcc 0.6346 0.6550
epoch 200 LossPred 0.3425 LossAtt 0.3898 TrainAcc 0.9000 TestAcc 0.8561 0.8550
epoch 300 LossPred 0.3060 LossAtt 0.3598 TrainAcc 0.9100 TestAcc 0.8401 0.8800
epoch 400 LossPred 0.3194 LossAtt 0.3682 TrainAcc 0.9000 TestAcc 0.8744 0.8800
epoch 500 LossPred 0.2705 LossAtt 0.3913 TrainAcc 0.9100 TestAcc 0.8711 0.8950
epoch 600 LossPred 0.2215 LossAtt 0.4172 TrainAcc 0.9300 TestAcc 0.8556 0.8700
epoch 700 LossPred 0.2810 LossAtt 0.4190 TrainAcc 0.9000 TestAcc 0.8831 0.9000
epoch 800 LossPred 0.1748 LossAtt 0.4117 TrainAcc 0.9600 TestAcc 0.8846 0.9050
epoch 900 LossPred 0.1646 LossAtt 0.4054 TrainAcc 0.9500 TestAcc 0.8791 0.9050
epoch 1000 LossPred 0.3456 LossAtt 0.3722 TrainAcc 0.8600 TestAcc 0.8398 0.8650
epoch 1100 LossPred 0.1893 LossAtt 0.3837 TrainAcc 0.9300 TestAcc 0.8936 0.9100
epoch 1200 LossPred 0.3009 LossAtt 0.3660 TrainAcc 0.9000 TestAcc 0.8696 0.9050
epoch 1300 LossPred 0.2884 LossAtt 0.3622 TrainAcc 0.9000 TestAcc 0.8754 0.9050
epoch 1400 LossPred 0.2495 LossAtt 0.3735 TrainAcc 0.9000 TestAcc 0.8493 0.8850
epoch 1500 LossPred 0.1696 LossAtt 0.3565 TrainAcc 0.9300 TestAcc 0.8631 0.9100
epoch 1600 LossPred 0.2182 LossAtt 0.3569 TrainAcc 0.9000 TestAcc 0.9034 0.9200
epoch 1700 LossPred 0.1269 LossAtt 0.3572 TrainAcc 0.9500 TestAcc 0.8999 0.9350
epoch 1800 LossPred 0.1148 LossAtt 0.3467 TrainAcc 0.9600 TestAcc 0.8989 0.9350
epoch 1900 LossPred 0.1215 LossAtt 0.3487 TrainAcc 0.9600 TestAcc 0.9032 0.9400
epoch 2000 LossPred 0.1155 LossAtt 0.3449 TrainAcc 0.9700 TestAcc 0.8716 0.9350
epoch 2100 LossPred 0.3629 LossAtt 0.3491 TrainAcc 0.9000 TestAcc 0.8376 0.8850
epoch 2200 LossPred 0.1373 LossAtt 0.3428 TrainAcc 0.9600 TestAcc 0.9122 0.9350
epoch 2300 LossPred 0.1260 LossAtt 0.3370 TrainAcc 0.9600 TestAcc 0.9134 0.9450
epoch 2400 LossPred 0.0911 LossAtt 0.3364 TrainAcc 0.9800 TestAcc 0.8901 0.9350
epoch 2500 LossPred 0.0855 LossAtt 0.3309 TrainAcc 0.9800 TestAcc 0.8876 0.9400
Optimization Finished!
********** replication  75  **********
epoch   0 LossPred 0.9894 LossAtt 1.0511 TrainAcc 0.5600 TestAcc 0.5223 0.5750
epoch 100 LossPred 0.8370 LossAtt 0.3761 TrainAcc 0.6800 TestAcc 0.5050 0.6600
epoch 200 LossPred 0.7124 LossAtt 0.4951 TrainAcc 0.7400 TestAcc 0.5420 0.7150
epoch 300 LossPred 0.5934 LossAtt 0.5542 TrainAcc 0.7500 TestAcc 0.5661 0.7550
epoch 400 LossPred 0.3416 LossAtt 0.5792 TrainAcc 0.8800 TestAcc 0.7730 0.8200
epoch 500 LossPred 0.1799 LossAtt 0.5828 TrainAcc 0.9400 TestAcc 0.7740 0.9150
epoch 600 LossPred 0.1163 LossAtt 0.5717 TrainAcc 0.9700 TestAcc 0.7750 0.9050
epoch 700 LossPred 0.0855 LossAtt 0.5816 TrainAcc 0.9800 TestAcc 0.7798 0.9200
epoch 800 LossPred 0.0745 LossAtt 0.5659 TrainAcc 0.9800 TestAcc 0.7788 0.9250
epoch 900 LossPred 0.0669 LossAtt 0.5494 TrainAcc 0.9800 TestAcc 0.7683 0.9350
epoch 1000 LossPred 0.0780 LossAtt 0.5652 TrainAcc 0.9900 TestAcc 0.7470 0.9100
epoch 1100 LossPred 0.0504 LossAtt 0.5426 TrainAcc 0.9900 TestAcc 0.7553 0.9450
epoch 1200 LossPred 0.0494 LossAtt 0.5261 TrainAcc 0.9900 TestAcc 0.7645 0.9100
epoch 1300 LossPred 0.0401 LossAtt 0.5477 TrainAcc 0.9900 TestAcc 0.7578 0.9500
epoch 1400 LossPred 0.0286 LossAtt 0.5322 TrainAcc 0.9900 TestAcc 0.7610 0.9500
epoch 1500 LossPred 0.0185 LossAtt 0.5270 TrainAcc 1.0000 TestAcc 0.7580 0.9600
Optimization Finished!
********** replication  76  **********
epoch   0 LossPred 1.0943 LossAtt 1.0962 TrainAcc 0.5200 TestAcc 0.4492 0.5600
epoch 100 LossPred 0.9175 LossAtt 0.4092 TrainAcc 0.6500 TestAcc 0.5238 0.6500
epoch 200 LossPred 0.7793 LossAtt 0.4743 TrainAcc 0.7300 TestAcc 0.6009 0.7150
epoch 300 LossPred 0.3625 LossAtt 0.3698 TrainAcc 0.9100 TestAcc 0.8501 0.8550
epoch 400 LossPred 0.2754 LossAtt 0.3768 TrainAcc 0.9300 TestAcc 0.8801 0.9000
epoch 500 LossPred 0.2184 LossAtt 0.3620 TrainAcc 0.9200 TestAcc 0.8826 0.9000
epoch 600 LossPred 0.1653 LossAtt 0.3718 TrainAcc 0.9500 TestAcc 0.8896 0.9100
epoch 700 LossPred 0.1335 LossAtt 0.3773 TrainAcc 0.9700 TestAcc 0.9067 0.9250
epoch 800 LossPred 0.1603 LossAtt 0.3596 TrainAcc 0.9500 TestAcc 0.8794 0.9200
epoch 900 LossPred 0.1116 LossAtt 0.3611 TrainAcc 0.9700 TestAcc 0.9012 0.9350
epoch 1000 LossPred 0.0921 LossAtt 0.3448 TrainAcc 0.9700 TestAcc 0.9132 0.9450
epoch 1100 LossPred 0.0788 LossAtt 0.3438 TrainAcc 0.9800 TestAcc 0.9057 0.9400
epoch 1200 LossPred 0.3094 LossAtt 0.3557 TrainAcc 0.9100 TestAcc 0.8321 0.9050
epoch 1300 LossPred 0.0803 LossAtt 0.3588 TrainAcc 0.9900 TestAcc 0.8906 0.9500
epoch 1400 LossPred 0.0925 LossAtt 0.3528 TrainAcc 0.9900 TestAcc 0.8876 0.9450
epoch 1500 LossPred 0.0590 LossAtt 0.3421 TrainAcc 0.9900 TestAcc 0.9009 0.9500
epoch 1600 LossPred 0.0486 LossAtt 0.3364 TrainAcc 1.0000 TestAcc 0.9164 0.9650
Optimization Finished!
********** replication  77  **********
epoch   0 LossPred 1.0300 LossAtt 1.0349 TrainAcc 0.4800 TestAcc 0.4910 0.4800
epoch 100 LossPred 0.9418 LossAtt 0.2969 TrainAcc 0.5800 TestAcc 0.5776 0.5750
epoch 200 LossPred 0.8842 LossAtt 0.3117 TrainAcc 0.6500 TestAcc 0.5901 0.6600
epoch 300 LossPred 0.7986 LossAtt 0.4052 TrainAcc 0.6700 TestAcc 0.6281 0.6500
epoch 400 LossPred 0.4820 LossAtt 0.4467 TrainAcc 0.8100 TestAcc 0.8226 0.8000
epoch 500 LossPred 0.2616 LossAtt 0.4399 TrainAcc 0.9200 TestAcc 0.8396 0.8500
epoch 600 LossPred 0.1782 LossAtt 0.4234 TrainAcc 0.9500 TestAcc 0.8509 0.8900
epoch 700 LossPred 0.1377 LossAtt 0.4205 TrainAcc 0.9700 TestAcc 0.8601 0.9050
epoch 800 LossPred 0.1582 LossAtt 0.4282 TrainAcc 0.9400 TestAcc 0.8576 0.8900
epoch 900 LossPred 0.0951 LossAtt 0.4190 TrainAcc 0.9700 TestAcc 0.8666 0.9100
epoch 1000 LossPred 0.1056 LossAtt 0.4223 TrainAcc 0.9800 TestAcc 0.8666 0.9100
epoch 1100 LossPred 0.0702 LossAtt 0.4310 TrainAcc 0.9900 TestAcc 0.8739 0.9400
epoch 1200 LossPred 0.0967 LossAtt 0.4293 TrainAcc 0.9800 TestAcc 0.8794 0.9100
epoch 1300 LossPred 0.0526 LossAtt 0.4196 TrainAcc 0.9900 TestAcc 0.8726 0.9400
epoch 1400 LossPred 0.0437 LossAtt 0.4195 TrainAcc 1.0000 TestAcc 0.8769 0.9200
Optimization Finished!
********** replication  78  **********
epoch   0 LossPred 1.1393 LossAtt 1.0108 TrainAcc 0.5500 TestAcc 0.5168 0.5400
epoch 100 LossPred 0.9507 LossAtt 0.3904 TrainAcc 0.6100 TestAcc 0.5218 0.5800
epoch 200 LossPred 0.8973 LossAtt 0.4108 TrainAcc 0.6100 TestAcc 0.5400 0.6000
epoch 300 LossPred 0.8329 LossAtt 0.4660 TrainAcc 0.6700 TestAcc 0.5360 0.6700
epoch 400 LossPred 0.7990 LossAtt 0.4561 TrainAcc 0.6900 TestAcc 0.5478 0.6550
epoch 500 LossPred 0.7728 LossAtt 0.4139 TrainAcc 0.7200 TestAcc 0.5708 0.7000
epoch 600 LossPred 0.7253 LossAtt 0.4618 TrainAcc 0.7400 TestAcc 0.5876 0.7250
epoch 700 LossPred 0.6691 LossAtt 0.4598 TrainAcc 0.7600 TestAcc 0.6269 0.7400
epoch 800 LossPred 0.5699 LossAtt 0.5030 TrainAcc 0.8200 TestAcc 0.7035 0.7800
epoch 900 LossPred 0.3626 LossAtt 0.5050 TrainAcc 0.8800 TestAcc 0.8031 0.8600
epoch 1000 LossPred 0.2615 LossAtt 0.4921 TrainAcc 0.9200 TestAcc 0.8141 0.8900
epoch 1100 LossPred 0.2280 LossAtt 0.4810 TrainAcc 0.9300 TestAcc 0.8081 0.9150
epoch 1200 LossPred 0.2302 LossAtt 0.4768 TrainAcc 0.9200 TestAcc 0.8186 0.9100
epoch 1300 LossPred 0.2592 LossAtt 0.4804 TrainAcc 0.9300 TestAcc 0.7948 0.9000
epoch 1400 LossPred 0.2407 LossAtt 0.4599 TrainAcc 0.9200 TestAcc 0.8066 0.9200
epoch 1500 LossPred 0.1737 LossAtt 0.4546 TrainAcc 0.9500 TestAcc 0.8071 0.9100
epoch 1600 LossPred 0.1661 LossAtt 0.4556 TrainAcc 0.9700 TestAcc 0.8121 0.9100
epoch 1700 LossPred 0.2475 LossAtt 0.4631 TrainAcc 0.9200 TestAcc 0.8176 0.8750
epoch 1800 LossPred 0.2197 LossAtt 0.4633 TrainAcc 0.9500 TestAcc 0.8133 0.9000
epoch 1900 LossPred 0.1860 LossAtt 0.4774 TrainAcc 0.9600 TestAcc 0.8083 0.9350
epoch 2000 LossPred 0.3373 LossAtt 0.4648 TrainAcc 0.8900 TestAcc 0.7883 0.9100
epoch 2100 LossPred 0.1207 LossAtt 0.4524 TrainAcc 0.9700 TestAcc 0.8138 0.9500
epoch 2200 LossPred 0.1176 LossAtt 0.4639 TrainAcc 0.9800 TestAcc 0.8101 0.9100
epoch 2300 LossPred 0.1187 LossAtt 0.4608 TrainAcc 0.9800 TestAcc 0.8001 0.9050
epoch 2400 LossPred 0.1071 LossAtt 0.4618 TrainAcc 0.9800 TestAcc 0.8171 0.9250
epoch 2500 LossPred 0.1032 LossAtt 0.4640 TrainAcc 0.9800 TestAcc 0.8131 0.9550
Optimization Finished!
********** replication  79  **********
epoch   0 LossPred 1.2408 LossAtt 1.0317 TrainAcc 0.4200 TestAcc 0.4219 0.4050
epoch 100 LossPred 0.9270 LossAtt 0.4300 TrainAcc 0.6000 TestAcc 0.5506 0.5700
epoch 200 LossPred 0.8207 LossAtt 0.4584 TrainAcc 0.7000 TestAcc 0.5583 0.7000
epoch 300 LossPred 0.5323 LossAtt 0.5530 TrainAcc 0.8000 TestAcc 0.7022 0.7650
epoch 400 LossPred 0.3521 LossAtt 0.5364 TrainAcc 0.9000 TestAcc 0.7457 0.8450
epoch 500 LossPred 0.3097 LossAtt 0.5276 TrainAcc 0.9000 TestAcc 0.7543 0.8400
epoch 600 LossPred 0.2712 LossAtt 0.5280 TrainAcc 0.9200 TestAcc 0.7623 0.8550
epoch 700 LossPred 0.3308 LossAtt 0.5336 TrainAcc 0.8800 TestAcc 0.7618 0.8450
epoch 800 LossPred 0.2392 LossAtt 0.5069 TrainAcc 0.9300 TestAcc 0.7623 0.8600
epoch 900 LossPred 0.2294 LossAtt 0.5034 TrainAcc 0.9400 TestAcc 0.7585 0.8600
epoch 1000 LossPred 0.2201 LossAtt 0.5077 TrainAcc 0.9400 TestAcc 0.7593 0.8700
epoch 1100 LossPred 0.2657 LossAtt 0.4877 TrainAcc 0.9100 TestAcc 0.7593 0.8600
epoch 1200 LossPred 0.2078 LossAtt 0.5009 TrainAcc 0.9400 TestAcc 0.7550 0.8650
epoch 1300 LossPred 0.1988 LossAtt 0.4902 TrainAcc 0.9400 TestAcc 0.7555 0.8700
epoch 1400 LossPred 0.1885 LossAtt 0.5002 TrainAcc 0.9500 TestAcc 0.7530 0.8650
epoch 1500 LossPred 0.1882 LossAtt 0.4970 TrainAcc 0.9500 TestAcc 0.7515 0.8750
epoch 1600 LossPred 0.1747 LossAtt 0.4843 TrainAcc 0.9500 TestAcc 0.7535 0.8700
epoch 1700 LossPred 0.1734 LossAtt 0.4852 TrainAcc 0.9600 TestAcc 0.7492 0.8650
epoch 1800 LossPred 0.1606 LossAtt 0.4883 TrainAcc 0.9600 TestAcc 0.7513 0.8750
epoch 1900 LossPred 0.1652 LossAtt 0.4847 TrainAcc 0.9600 TestAcc 0.7487 0.8850
epoch 2000 LossPred 0.1501 LossAtt 0.4984 TrainAcc 0.9600 TestAcc 0.7480 0.8800
epoch 2100 LossPred 0.2432 LossAtt 0.4789 TrainAcc 0.9300 TestAcc 0.7347 0.8500
epoch 2200 LossPred 0.1373 LossAtt 0.4708 TrainAcc 0.9700 TestAcc 0.7500 0.8650
epoch 2300 LossPred 0.1405 LossAtt 0.4881 TrainAcc 0.9700 TestAcc 0.7495 0.8750
epoch 2400 LossPred 0.1319 LossAtt 0.4853 TrainAcc 0.9700 TestAcc 0.7495 0.8800
epoch 2500 LossPred 0.1359 LossAtt 0.4847 TrainAcc 0.9700 TestAcc 0.7500 0.8700
Optimization Finished!
********** replication  80  **********
epoch   0 LossPred 1.1205 LossAtt 1.0400 TrainAcc 0.5400 TestAcc 0.4222 0.5450
epoch 100 LossPred 0.9021 LossAtt 0.3260 TrainAcc 0.5900 TestAcc 0.4464 0.6100
epoch 200 LossPred 0.8630 LossAtt 0.3193 TrainAcc 0.6600 TestAcc 0.5058 0.6650
epoch 300 LossPred 0.7807 LossAtt 0.3002 TrainAcc 0.6900 TestAcc 0.5155 0.6850
epoch 400 LossPred 0.7472 LossAtt 0.3574 TrainAcc 0.7300 TestAcc 0.5150 0.7100
epoch 500 LossPred 0.7315 LossAtt 0.3547 TrainAcc 0.7300 TestAcc 0.5090 0.7050
epoch 600 LossPred 0.7151 LossAtt 0.3472 TrainAcc 0.7500 TestAcc 0.5175 0.7050
epoch 700 LossPred 0.7018 LossAtt 0.3417 TrainAcc 0.7400 TestAcc 0.5180 0.7150
epoch 800 LossPred 0.6928 LossAtt 0.3561 TrainAcc 0.7400 TestAcc 0.5180 0.7250
epoch 900 LossPred 0.6865 LossAtt 0.3541 TrainAcc 0.7500 TestAcc 0.5243 0.7400
epoch 1000 LossPred 0.6845 LossAtt 0.3659 TrainAcc 0.7400 TestAcc 0.5173 0.7300
epoch 1100 LossPred 0.6737 LossAtt 0.3649 TrainAcc 0.7300 TestAcc 0.5215 0.7450
epoch 1200 LossPred 0.6625 LossAtt 0.3508 TrainAcc 0.7400 TestAcc 0.5223 0.7350
epoch 1300 LossPred 0.6618 LossAtt 0.3600 TrainAcc 0.7700 TestAcc 0.5323 0.7250
epoch 1400 LossPred 0.6569 LossAtt 0.3716 TrainAcc 0.7800 TestAcc 0.5283 0.7350
epoch 1500 LossPred 0.6628 LossAtt 0.3619 TrainAcc 0.7500 TestAcc 0.5223 0.7250
epoch 1600 LossPred 0.6479 LossAtt 0.3795 TrainAcc 0.7500 TestAcc 0.5238 0.7300
epoch 1700 LossPred 0.6401 LossAtt 0.3646 TrainAcc 0.7800 TestAcc 0.5285 0.7300
epoch 1800 LossPred 0.6401 LossAtt 0.3604 TrainAcc 0.7800 TestAcc 0.5295 0.7200
epoch 1900 LossPred 0.6492 LossAtt 0.3653 TrainAcc 0.7700 TestAcc 0.5275 0.7050
epoch 2000 LossPred 0.6388 LossAtt 0.3577 TrainAcc 0.7700 TestAcc 0.5270 0.7450
epoch 2100 LossPred 0.6265 LossAtt 0.3798 TrainAcc 0.7800 TestAcc 0.5175 0.7150
epoch 2200 LossPred 0.6032 LossAtt 0.3726 TrainAcc 0.7700 TestAcc 0.5173 0.7150
epoch 2300 LossPred 0.5825 LossAtt 0.3498 TrainAcc 0.7900 TestAcc 0.5083 0.7150
epoch 2400 LossPred 0.6111 LossAtt 0.3575 TrainAcc 0.7800 TestAcc 0.5115 0.7300
epoch 2500 LossPred 0.5877 LossAtt 0.3751 TrainAcc 0.8000 TestAcc 0.5150 0.7500
Optimization Finished!
********** replication  81  **********
epoch   0 LossPred 0.9859 LossAtt 1.0387 TrainAcc 0.5500 TestAcc 0.5010 0.5500
epoch 100 LossPred 0.9357 LossAtt 0.3842 TrainAcc 0.6000 TestAcc 0.5746 0.6050
epoch 200 LossPred 0.5457 LossAtt 0.5354 TrainAcc 0.8200 TestAcc 0.7690 0.8350
epoch 300 LossPred 0.3949 LossAtt 0.4514 TrainAcc 0.8800 TestAcc 0.8123 0.8750
epoch 400 LossPred 0.3307 LossAtt 0.4295 TrainAcc 0.9100 TestAcc 0.8248 0.8850
epoch 500 LossPred 0.2778 LossAtt 0.4161 TrainAcc 0.9200 TestAcc 0.8146 0.8500
epoch 600 LossPred 0.2779 LossAtt 0.3995 TrainAcc 0.9200 TestAcc 0.8131 0.8600
epoch 700 LossPred 0.2233 LossAtt 0.3898 TrainAcc 0.9300 TestAcc 0.8266 0.8750
epoch 800 LossPred 0.2099 LossAtt 0.3747 TrainAcc 0.9400 TestAcc 0.8468 0.8950
epoch 900 LossPred 0.2061 LossAtt 0.3514 TrainAcc 0.9500 TestAcc 0.8406 0.9000
epoch 1000 LossPred 0.2203 LossAtt 0.3256 TrainAcc 0.9200 TestAcc 0.8406 0.9000
epoch 1100 LossPred 0.2209 LossAtt 0.3252 TrainAcc 0.9300 TestAcc 0.8761 0.8850
epoch 1200 LossPred 0.1789 LossAtt 0.2997 TrainAcc 0.9500 TestAcc 0.8739 0.8950
epoch 1300 LossPred 0.2607 LossAtt 0.3116 TrainAcc 0.8900 TestAcc 0.8756 0.8700
epoch 1400 LossPred 0.1727 LossAtt 0.2933 TrainAcc 0.9400 TestAcc 0.8754 0.8950
epoch 1500 LossPred 0.1622 LossAtt 0.3058 TrainAcc 0.9500 TestAcc 0.8829 0.9200
epoch 1600 LossPred 0.2066 LossAtt 0.3227 TrainAcc 0.9100 TestAcc 0.8596 0.8650
epoch 1700 LossPred 0.1285 LossAtt 0.3168 TrainAcc 0.9400 TestAcc 0.8924 0.9050
epoch 1800 LossPred 0.2152 LossAtt 0.3277 TrainAcc 0.9100 TestAcc 0.8604 0.8650
epoch 1900 LossPred 0.2451 LossAtt 0.3326 TrainAcc 0.8900 TestAcc 0.8476 0.8750
epoch 2000 LossPred 0.0810 LossAtt 0.3377 TrainAcc 0.9800 TestAcc 0.8971 0.9350
epoch 2100 LossPred 0.2735 LossAtt 0.3430 TrainAcc 0.9000 TestAcc 0.8914 0.8900
epoch 2200 LossPred 0.1267 LossAtt 0.3506 TrainAcc 0.9700 TestAcc 0.8799 0.9050
epoch 2300 LossPred 0.1086 LossAtt 0.3495 TrainAcc 0.9600 TestAcc 0.8794 0.9100
epoch 2400 LossPred 0.0415 LossAtt 0.3714 TrainAcc 0.9900 TestAcc 0.9032 0.9450
epoch 2500 LossPred 0.0963 LossAtt 0.3484 TrainAcc 0.9600 TestAcc 0.8771 0.9100
Optimization Finished!
********** replication  82  **********
epoch   0 LossPred 0.9715 LossAtt 1.0300 TrainAcc 0.5400 TestAcc 0.5458 0.5100
epoch 100 LossPred 0.8203 LossAtt 0.3033 TrainAcc 0.6800 TestAcc 0.5918 0.6850
epoch 200 LossPred 0.3142 LossAtt 0.3206 TrainAcc 0.9000 TestAcc 0.8376 0.8300
epoch 300 LossPred 0.2801 LossAtt 0.3023 TrainAcc 0.9000 TestAcc 0.8436 0.8500
epoch 400 LossPred 0.2958 LossAtt 0.2973 TrainAcc 0.8900 TestAcc 0.8428 0.8400
epoch 500 LossPred 0.4802 LossAtt 0.2823 TrainAcc 0.8200 TestAcc 0.8063 0.8250
epoch 600 LossPred 0.3126 LossAtt 0.2506 TrainAcc 0.8900 TestAcc 0.8408 0.8450
epoch 700 LossPred 0.3529 LossAtt 0.2412 TrainAcc 0.8700 TestAcc 0.8346 0.8450
epoch 800 LossPred 0.4907 LossAtt 0.2265 TrainAcc 0.8200 TestAcc 0.8186 0.8150
epoch 900 LossPred 0.2613 LossAtt 0.2230 TrainAcc 0.9100 TestAcc 0.8506 0.8500
epoch 1000 LossPred 0.2447 LossAtt 0.2238 TrainAcc 0.9100 TestAcc 0.8514 0.8650
epoch 1100 LossPred 0.2589 LossAtt 0.2237 TrainAcc 0.9300 TestAcc 0.8509 0.8450
epoch 1200 LossPred 0.2354 LossAtt 0.2126 TrainAcc 0.9100 TestAcc 0.8509 0.8700
epoch 1300 LossPred 0.2899 LossAtt 0.2171 TrainAcc 0.8800 TestAcc 0.8423 0.8500
epoch 1400 LossPred 0.3904 LossAtt 0.2421 TrainAcc 0.8700 TestAcc 0.8281 0.8250
epoch 1500 LossPred 0.4612 LossAtt 0.2521 TrainAcc 0.8400 TestAcc 0.8091 0.8100
epoch 1600 LossPred 0.2850 LossAtt 0.2326 TrainAcc 0.9200 TestAcc 0.8371 0.8850
epoch 1700 LossPred 0.2859 LossAtt 0.2419 TrainAcc 0.9100 TestAcc 0.8569 0.8600
epoch 1800 LossPred 0.3060 LossAtt 0.2391 TrainAcc 0.9100 TestAcc 0.8316 0.8850
epoch 1900 LossPred 0.2447 LossAtt 0.2340 TrainAcc 0.9200 TestAcc 0.8576 0.8900
epoch 2000 LossPred 0.2920 LossAtt 0.2444 TrainAcc 0.8900 TestAcc 0.8554 0.8700
epoch 2100 LossPred 0.2811 LossAtt 0.2352 TrainAcc 0.9100 TestAcc 0.8366 0.9000
epoch 2200 LossPred 0.3399 LossAtt 0.2267 TrainAcc 0.9000 TestAcc 0.8258 0.8950
epoch 2300 LossPred 0.3536 LossAtt 0.2253 TrainAcc 0.8900 TestAcc 0.8271 0.9000
epoch 2400 LossPred 0.2769 LossAtt 0.2195 TrainAcc 0.9100 TestAcc 0.8521 0.8800
epoch 2500 LossPred 0.2414 LossAtt 0.2063 TrainAcc 0.9300 TestAcc 0.8526 0.8900
Optimization Finished!
********** replication  83  **********
epoch   0 LossPred 1.0435 LossAtt 1.0433 TrainAcc 0.4600 TestAcc 0.4404 0.4750
epoch 100 LossPred 0.8354 LossAtt 0.4057 TrainAcc 0.6900 TestAcc 0.5891 0.7000
epoch 200 LossPred 0.5452 LossAtt 0.3989 TrainAcc 0.8100 TestAcc 0.7653 0.7800
epoch 300 LossPred 0.4703 LossAtt 0.3684 TrainAcc 0.8500 TestAcc 0.7725 0.7900
epoch 400 LossPred 0.3869 LossAtt 0.3497 TrainAcc 0.8800 TestAcc 0.7928 0.7900
epoch 500 LossPred 0.5086 LossAtt 0.3632 TrainAcc 0.8200 TestAcc 0.7623 0.7750
epoch 600 LossPred 0.3748 LossAtt 0.3650 TrainAcc 0.8800 TestAcc 0.8078 0.8050
epoch 700 LossPred 0.3697 LossAtt 0.3856 TrainAcc 0.8900 TestAcc 0.8111 0.8400
epoch 800 LossPred 0.3613 LossAtt 0.3823 TrainAcc 0.8900 TestAcc 0.8256 0.8250
epoch 900 LossPred 0.2831 LossAtt 0.4057 TrainAcc 0.9000 TestAcc 0.8621 0.8650
epoch 1000 LossPred 0.2540 LossAtt 0.4164 TrainAcc 0.9200 TestAcc 0.8779 0.8750
epoch 1100 LossPred 0.2408 LossAtt 0.4154 TrainAcc 0.9100 TestAcc 0.8929 0.9100
epoch 1200 LossPred 0.1120 LossAtt 0.4107 TrainAcc 0.9800 TestAcc 0.9017 0.9300
epoch 1300 LossPred 0.0729 LossAtt 0.4228 TrainAcc 0.9900 TestAcc 0.9087 0.9200
epoch 1400 LossPred 0.3061 LossAtt 0.4259 TrainAcc 0.9100 TestAcc 0.8764 0.9100
epoch 1500 LossPred 0.0503 LossAtt 0.4145 TrainAcc 0.9900 TestAcc 0.9092 0.9400
epoch 1600 LossPred 0.1072 LossAtt 0.4374 TrainAcc 0.9800 TestAcc 0.8956 0.9300
epoch 1700 LossPred 0.0356 LossAtt 0.4351 TrainAcc 0.9900 TestAcc 0.9044 0.9500
epoch 1800 LossPred 0.1440 LossAtt 0.4285 TrainAcc 0.9600 TestAcc 0.8589 0.9200
epoch 1900 LossPred 0.0469 LossAtt 0.4369 TrainAcc 0.9900 TestAcc 0.8956 0.9550
epoch 2000 LossPred 0.0497 LossAtt 0.4369 TrainAcc 0.9900 TestAcc 0.9202 0.9750
epoch 2100 LossPred 0.0490 LossAtt 0.4249 TrainAcc 0.9900 TestAcc 0.8811 0.9500
epoch 2200 LossPred 0.0217 LossAtt 0.4243 TrainAcc 1.0000 TestAcc 0.9162 0.9800
Optimization Finished!
********** replication  84  **********
epoch   0 LossPred 1.1560 LossAtt 1.0379 TrainAcc 0.5000 TestAcc 0.4622 0.5200
epoch 100 LossPred 0.9189 LossAtt 0.4098 TrainAcc 0.6200 TestAcc 0.5646 0.6350
epoch 200 LossPred 0.8802 LossAtt 0.4238 TrainAcc 0.6400 TestAcc 0.5976 0.6400
epoch 300 LossPred 0.5463 LossAtt 0.3554 TrainAcc 0.8200 TestAcc 0.7813 0.7600
epoch 400 LossPred 0.4971 LossAtt 0.3230 TrainAcc 0.8600 TestAcc 0.8136 0.8150
epoch 500 LossPred 0.3741 LossAtt 0.3395 TrainAcc 0.8700 TestAcc 0.8316 0.8000
epoch 600 LossPred 0.3302 LossAtt 0.3409 TrainAcc 0.9000 TestAcc 0.8371 0.8500
epoch 700 LossPred 0.3144 LossAtt 0.3337 TrainAcc 0.9100 TestAcc 0.8481 0.8500
epoch 800 LossPred 0.2545 LossAtt 0.3251 TrainAcc 0.9200 TestAcc 0.8539 0.8550
epoch 900 LossPred 0.2314 LossAtt 0.3245 TrainAcc 0.9300 TestAcc 0.8521 0.8550
epoch 1000 LossPred 0.2348 LossAtt 0.3107 TrainAcc 0.9200 TestAcc 0.8478 0.8550
epoch 1100 LossPred 0.2274 LossAtt 0.3213 TrainAcc 0.9300 TestAcc 0.8478 0.8650
epoch 1200 LossPred 0.2188 LossAtt 0.3266 TrainAcc 0.9400 TestAcc 0.8511 0.8700
epoch 1300 LossPred 0.2184 LossAtt 0.3161 TrainAcc 0.9400 TestAcc 0.8501 0.8550
epoch 1400 LossPred 0.1984 LossAtt 0.3044 TrainAcc 0.9500 TestAcc 0.8493 0.8750
epoch 1500 LossPred 0.1958 LossAtt 0.3036 TrainAcc 0.9500 TestAcc 0.8546 0.8600
epoch 1600 LossPred 0.1900 LossAtt 0.3109 TrainAcc 0.9400 TestAcc 0.8586 0.8650
epoch 1700 LossPred 0.1883 LossAtt 0.3140 TrainAcc 0.9500 TestAcc 0.8589 0.8750
epoch 1800 LossPred 0.1939 LossAtt 0.2955 TrainAcc 0.9600 TestAcc 0.8504 0.8600
epoch 1900 LossPred 0.2383 LossAtt 0.2985 TrainAcc 0.9200 TestAcc 0.8634 0.8900
epoch 2000 LossPred 0.1890 LossAtt 0.2884 TrainAcc 0.9600 TestAcc 0.8631 0.8750
epoch 2100 LossPred 0.1784 LossAtt 0.2904 TrainAcc 0.9500 TestAcc 0.8634 0.8850
epoch 2200 LossPred 0.1762 LossAtt 0.2993 TrainAcc 0.9600 TestAcc 0.8556 0.9000
epoch 2300 LossPred 0.1715 LossAtt 0.2909 TrainAcc 0.9600 TestAcc 0.8604 0.8900
epoch 2400 LossPred 0.1709 LossAtt 0.2873 TrainAcc 0.9600 TestAcc 0.8596 0.9000
epoch 2500 LossPred 0.1620 LossAtt 0.3071 TrainAcc 0.9500 TestAcc 0.8791 0.9250
Optimization Finished!
********** replication  85  **********
epoch   0 LossPred 1.0430 LossAtt 1.0233 TrainAcc 0.4600 TestAcc 0.4977 0.4500
epoch 100 LossPred 0.8886 LossAtt 0.4480 TrainAcc 0.6200 TestAcc 0.5793 0.6100
epoch 200 LossPred 0.5228 LossAtt 0.4903 TrainAcc 0.8400 TestAcc 0.7768 0.8250
epoch 300 LossPred 0.3913 LossAtt 0.4705 TrainAcc 0.9000 TestAcc 0.7938 0.8600
epoch 400 LossPred 0.3394 LossAtt 0.4773 TrainAcc 0.9000 TestAcc 0.8058 0.8600
epoch 500 LossPred 0.3178 LossAtt 0.4800 TrainAcc 0.9000 TestAcc 0.8076 0.8650
epoch 600 LossPred 0.2876 LossAtt 0.4760 TrainAcc 0.9400 TestAcc 0.8108 0.8800
epoch 700 LossPred 0.2730 LossAtt 0.4857 TrainAcc 0.9400 TestAcc 0.8116 0.8750
epoch 800 LossPred 0.2557 LossAtt 0.4791 TrainAcc 0.9300 TestAcc 0.8113 0.8750
epoch 900 LossPred 0.2584 LossAtt 0.4707 TrainAcc 0.9300 TestAcc 0.8148 0.8700
epoch 1000 LossPred 0.2017 LossAtt 0.4847 TrainAcc 0.9500 TestAcc 0.8256 0.8900
epoch 1100 LossPred 0.1693 LossAtt 0.4818 TrainAcc 0.9600 TestAcc 0.8291 0.9050
epoch 1200 LossPred 0.1530 LossAtt 0.4684 TrainAcc 0.9600 TestAcc 0.8291 0.9150
epoch 1300 LossPred 0.1346 LossAtt 0.4588 TrainAcc 0.9600 TestAcc 0.8261 0.9300
epoch 1400 LossPred 0.1971 LossAtt 0.4553 TrainAcc 0.9500 TestAcc 0.8306 0.9100
epoch 1500 LossPred 0.1061 LossAtt 0.4677 TrainAcc 0.9700 TestAcc 0.8293 0.9300
epoch 1600 LossPred 0.1761 LossAtt 0.4505 TrainAcc 0.9500 TestAcc 0.8361 0.9150
epoch 1700 LossPred 0.1088 LossAtt 0.4559 TrainAcc 0.9700 TestAcc 0.8173 0.9100
epoch 1800 LossPred 0.0742 LossAtt 0.4540 TrainAcc 0.9800 TestAcc 0.8216 0.9250
epoch 1900 LossPred 0.0690 LossAtt 0.4373 TrainAcc 0.9900 TestAcc 0.8256 0.9250
epoch 2000 LossPred 0.0600 LossAtt 0.4396 TrainAcc 0.9900 TestAcc 0.8163 0.9200
epoch 2100 LossPred 0.1110 LossAtt 0.4319 TrainAcc 0.9800 TestAcc 0.8108 0.9350
epoch 2200 LossPred 0.0617 LossAtt 0.4300 TrainAcc 0.9900 TestAcc 0.8126 0.9250
epoch 2300 LossPred 0.1029 LossAtt 0.4456 TrainAcc 0.9800 TestAcc 0.8143 0.9100
epoch 2400 LossPred 0.0539 LossAtt 0.4277 TrainAcc 0.9900 TestAcc 0.8101 0.9150
epoch 2500 LossPred 0.0526 LossAtt 0.4319 TrainAcc 0.9900 TestAcc 0.8063 0.9250
Optimization Finished!
********** replication  86  **********
epoch   0 LossPred 1.0422 LossAtt 1.0151 TrainAcc 0.4500 TestAcc 0.4920 0.4450
epoch 100 LossPred 0.8262 LossAtt 0.3403 TrainAcc 0.6700 TestAcc 0.5781 0.6650
epoch 200 LossPred 0.6072 LossAtt 0.3501 TrainAcc 0.7800 TestAcc 0.7608 0.7800
epoch 300 LossPred 0.3993 LossAtt 0.3374 TrainAcc 0.8800 TestAcc 0.8176 0.8450
epoch 400 LossPred 0.3891 LossAtt 0.3446 TrainAcc 0.8600 TestAcc 0.8231 0.8550
epoch 500 LossPred 0.3759 LossAtt 0.3671 TrainAcc 0.8800 TestAcc 0.8171 0.8300
epoch 600 LossPred 0.3665 LossAtt 0.3700 TrainAcc 0.8700 TestAcc 0.8043 0.8450
epoch 700 LossPred 0.4693 LossAtt 0.3759 TrainAcc 0.8200 TestAcc 0.8111 0.8250
epoch 800 LossPred 0.3338 LossAtt 0.3700 TrainAcc 0.8800 TestAcc 0.8148 0.8450
epoch 900 LossPred 0.3435 LossAtt 0.3650 TrainAcc 0.8800 TestAcc 0.7988 0.8550
epoch 1000 LossPred 0.3257 LossAtt 0.3494 TrainAcc 0.9000 TestAcc 0.8273 0.8500
epoch 1100 LossPred 0.3357 LossAtt 0.3517 TrainAcc 0.8900 TestAcc 0.8431 0.8800
epoch 1200 LossPred 0.3999 LossAtt 0.3537 TrainAcc 0.8700 TestAcc 0.8006 0.8300
epoch 1300 LossPred 0.3564 LossAtt 0.3453 TrainAcc 0.8900 TestAcc 0.8078 0.8650
epoch 1400 LossPred 0.3759 LossAtt 0.3352 TrainAcc 0.8900 TestAcc 0.8056 0.8400
epoch 1500 LossPred 0.3430 LossAtt 0.3239 TrainAcc 0.9000 TestAcc 0.8111 0.8650
epoch 1600 LossPred 0.2932 LossAtt 0.3305 TrainAcc 0.9100 TestAcc 0.8346 0.8900
epoch 1700 LossPred 0.2903 LossAtt 0.3249 TrainAcc 0.9200 TestAcc 0.8358 0.8900
epoch 1800 LossPred 0.4821 LossAtt 0.3222 TrainAcc 0.8300 TestAcc 0.7728 0.8000
epoch 1900 LossPred 0.3201 LossAtt 0.3267 TrainAcc 0.8900 TestAcc 0.8148 0.8800
epoch 2000 LossPred 0.3073 LossAtt 0.3199 TrainAcc 0.9000 TestAcc 0.8266 0.8850
epoch 2100 LossPred 0.3195 LossAtt 0.3103 TrainAcc 0.9000 TestAcc 0.8128 0.8850
epoch 2200 LossPred 0.3289 LossAtt 0.3121 TrainAcc 0.8900 TestAcc 0.8053 0.8850
epoch 2300 LossPred 0.2845 LossAtt 0.3190 TrainAcc 0.9100 TestAcc 0.8293 0.8900
epoch 2400 LossPred 0.3631 LossAtt 0.3173 TrainAcc 0.8800 TestAcc 0.8043 0.8550
epoch 2500 LossPred 0.3177 LossAtt 0.3132 TrainAcc 0.9000 TestAcc 0.8381 0.8900
Optimization Finished!
********** replication  87  **********
epoch   0 LossPred 1.1449 LossAtt 1.0497 TrainAcc 0.4300 TestAcc 0.4795 0.4350
epoch 100 LossPred 0.9197 LossAtt 0.3624 TrainAcc 0.6200 TestAcc 0.5628 0.6050
epoch 200 LossPred 0.9086 LossAtt 0.3333 TrainAcc 0.6500 TestAcc 0.5683 0.6500
epoch 300 LossPred 0.8948 LossAtt 0.3239 TrainAcc 0.6500 TestAcc 0.5683 0.6550
epoch 400 LossPred 0.7825 LossAtt 0.4514 TrainAcc 0.7200 TestAcc 0.5558 0.6750
epoch 500 LossPred 0.5577 LossAtt 0.4791 TrainAcc 0.8200 TestAcc 0.5916 0.7450
epoch 600 LossPred 0.4581 LossAtt 0.4630 TrainAcc 0.8600 TestAcc 0.5896 0.7700
epoch 700 LossPred 0.4288 LossAtt 0.4616 TrainAcc 0.8500 TestAcc 0.5821 0.7800
epoch 800 LossPred 0.3587 LossAtt 0.4418 TrainAcc 0.8700 TestAcc 0.5816 0.8000
epoch 900 LossPred 0.3385 LossAtt 0.4562 TrainAcc 0.9000 TestAcc 0.5806 0.8000
epoch 1000 LossPred 0.3451 LossAtt 0.4412 TrainAcc 0.8800 TestAcc 0.5823 0.8000
epoch 1100 LossPred 0.2946 LossAtt 0.4705 TrainAcc 0.9100 TestAcc 0.5808 0.7950
epoch 1200 LossPred 0.2682 LossAtt 0.4714 TrainAcc 0.9100 TestAcc 0.5798 0.7950
epoch 1300 LossPred 0.2638 LossAtt 0.4732 TrainAcc 0.9200 TestAcc 0.5768 0.8150
epoch 1400 LossPred 0.2412 LossAtt 0.4495 TrainAcc 0.9300 TestAcc 0.5743 0.8350
epoch 1500 LossPred 0.2350 LossAtt 0.4474 TrainAcc 0.9300 TestAcc 0.5726 0.8050
epoch 1600 LossPred 0.2300 LossAtt 0.4560 TrainAcc 0.9300 TestAcc 0.5728 0.8000
epoch 1700 LossPred 0.2179 LossAtt 0.4451 TrainAcc 0.9400 TestAcc 0.5701 0.8050
epoch 1800 LossPred 0.2130 LossAtt 0.4286 TrainAcc 0.9400 TestAcc 0.5708 0.8100
epoch 1900 LossPred 0.2011 LossAtt 0.4255 TrainAcc 0.9400 TestAcc 0.5741 0.8000
epoch 2000 LossPred 0.1960 LossAtt 0.4349 TrainAcc 0.9400 TestAcc 0.5753 0.8300
epoch 2100 LossPred 0.1984 LossAtt 0.4212 TrainAcc 0.9400 TestAcc 0.5748 0.8100
epoch 2200 LossPred 0.1915 LossAtt 0.4137 TrainAcc 0.9400 TestAcc 0.5751 0.8150
epoch 2300 LossPred 0.1870 LossAtt 0.4194 TrainAcc 0.9400 TestAcc 0.5733 0.8150
epoch 2400 LossPred 0.2112 LossAtt 0.4052 TrainAcc 0.9300 TestAcc 0.5671 0.8450
epoch 2500 LossPred 0.1904 LossAtt 0.3988 TrainAcc 0.9400 TestAcc 0.5706 0.8500
Optimization Finished!
********** replication  88  **********
epoch   0 LossPred 1.0824 LossAtt 1.0139 TrainAcc 0.4100 TestAcc 0.4377 0.4100
epoch 100 LossPred 0.9353 LossAtt 0.2984 TrainAcc 0.6200 TestAcc 0.5686 0.6200
epoch 200 LossPred 0.9042 LossAtt 0.2380 TrainAcc 0.6800 TestAcc 0.5458 0.6700
epoch 300 LossPred 0.8860 LossAtt 0.2489 TrainAcc 0.6700 TestAcc 0.5210 0.6650
epoch 400 LossPred 0.8725 LossAtt 0.3071 TrainAcc 0.6700 TestAcc 0.5155 0.6700
epoch 500 LossPred 0.8443 LossAtt 0.3829 TrainAcc 0.6700 TestAcc 0.5280 0.6850
epoch 600 LossPred 0.7737 LossAtt 0.4052 TrainAcc 0.7100 TestAcc 0.5255 0.7050
epoch 700 LossPred 0.7100 LossAtt 0.4431 TrainAcc 0.7500 TestAcc 0.5145 0.6900
epoch 800 LossPred 0.6273 LossAtt 0.4712 TrainAcc 0.7900 TestAcc 0.5020 0.6950
epoch 900 LossPred 0.6038 LossAtt 0.4704 TrainAcc 0.7900 TestAcc 0.5033 0.7150
epoch 1000 LossPred 0.5637 LossAtt 0.4640 TrainAcc 0.8000 TestAcc 0.5128 0.7350
epoch 1100 LossPred 0.5214 LossAtt 0.4652 TrainAcc 0.8400 TestAcc 0.5135 0.7400
epoch 1200 LossPred 0.5318 LossAtt 0.4335 TrainAcc 0.8100 TestAcc 0.5223 0.7250
epoch 1300 LossPred 0.4942 LossAtt 0.4518 TrainAcc 0.8400 TestAcc 0.5200 0.7250
epoch 1400 LossPred 0.4722 LossAtt 0.4732 TrainAcc 0.8600 TestAcc 0.5213 0.6950
epoch 1500 LossPred 0.4507 LossAtt 0.4547 TrainAcc 0.8400 TestAcc 0.5260 0.7150
epoch 1600 LossPred 0.4313 LossAtt 0.4585 TrainAcc 0.8600 TestAcc 0.5270 0.7100
epoch 1700 LossPred 0.3844 LossAtt 0.4575 TrainAcc 0.9000 TestAcc 0.5315 0.7400
epoch 1800 LossPred 0.4760 LossAtt 0.4623 TrainAcc 0.8800 TestAcc 0.5300 0.7400
epoch 1900 LossPred 0.4605 LossAtt 0.4406 TrainAcc 0.8500 TestAcc 0.5378 0.7300
epoch 2000 LossPred 0.3576 LossAtt 0.4483 TrainAcc 0.9100 TestAcc 0.5355 0.7400
epoch 2100 LossPred 0.4293 LossAtt 0.4397 TrainAcc 0.8800 TestAcc 0.5323 0.7200
epoch 2200 LossPred 0.4119 LossAtt 0.4154 TrainAcc 0.8700 TestAcc 0.5373 0.7300
epoch 2300 LossPred 0.4531 LossAtt 0.4087 TrainAcc 0.8600 TestAcc 0.5358 0.7350
epoch 2400 LossPred 0.3958 LossAtt 0.4155 TrainAcc 0.8900 TestAcc 0.5373 0.7550
epoch 2500 LossPred 0.5433 LossAtt 0.4230 TrainAcc 0.8100 TestAcc 0.5288 0.7100
Optimization Finished!
********** replication  89  **********
epoch   0 LossPred 1.0380 LossAtt 1.0179 TrainAcc 0.4400 TestAcc 0.4324 0.4400
epoch 100 LossPred 0.9574 LossAtt 0.2851 TrainAcc 0.5700 TestAcc 0.4992 0.5900
epoch 200 LossPred 0.9407 LossAtt 0.2249 TrainAcc 0.5900 TestAcc 0.5108 0.6000
epoch 300 LossPred 0.9313 LossAtt 0.2460 TrainAcc 0.6000 TestAcc 0.5248 0.6100
epoch 400 LossPred 0.9198 LossAtt 0.2548 TrainAcc 0.6100 TestAcc 0.5553 0.6450
epoch 500 LossPred 0.9097 LossAtt 0.2456 TrainAcc 0.6200 TestAcc 0.5435 0.6100
epoch 600 LossPred 0.8538 LossAtt 0.3923 TrainAcc 0.6700 TestAcc 0.5501 0.6700
epoch 700 LossPred 0.5667 LossAtt 0.4680 TrainAcc 0.7800 TestAcc 0.7720 0.8050
epoch 800 LossPred 0.4089 LossAtt 0.4413 TrainAcc 0.8200 TestAcc 0.8186 0.8700
epoch 900 LossPred 0.3675 LossAtt 0.4197 TrainAcc 0.8800 TestAcc 0.8233 0.8700
epoch 1000 LossPred 0.3370 LossAtt 0.4027 TrainAcc 0.9000 TestAcc 0.8166 0.8850
epoch 1100 LossPred 0.3387 LossAtt 0.3963 TrainAcc 0.8900 TestAcc 0.8198 0.8750
epoch 1200 LossPred 0.3246 LossAtt 0.3886 TrainAcc 0.9000 TestAcc 0.8268 0.8650
epoch 1300 LossPred 0.4103 LossAtt 0.3658 TrainAcc 0.8500 TestAcc 0.7960 0.8500
epoch 1400 LossPred 0.2794 LossAtt 0.3765 TrainAcc 0.9000 TestAcc 0.8126 0.8850
epoch 1500 LossPred 0.2751 LossAtt 0.3680 TrainAcc 0.9200 TestAcc 0.8166 0.8850
epoch 1600 LossPred 0.2683 LossAtt 0.3909 TrainAcc 0.8900 TestAcc 0.8108 0.8850
epoch 1700 LossPred 0.2980 LossAtt 0.3703 TrainAcc 0.8900 TestAcc 0.8076 0.8800
epoch 1800 LossPred 0.2321 LossAtt 0.3801 TrainAcc 0.9200 TestAcc 0.8221 0.8900
epoch 1900 LossPred 0.2538 LossAtt 0.3719 TrainAcc 0.9000 TestAcc 0.8211 0.9000
epoch 2000 LossPred 0.2356 LossAtt 0.3864 TrainAcc 0.9100 TestAcc 0.8176 0.8900
epoch 2100 LossPred 0.2833 LossAtt 0.3831 TrainAcc 0.9000 TestAcc 0.8178 0.8850
epoch 2200 LossPred 0.2344 LossAtt 0.3821 TrainAcc 0.9200 TestAcc 0.8191 0.8950
epoch 2300 LossPred 0.2220 LossAtt 0.3846 TrainAcc 0.9100 TestAcc 0.8241 0.9050
epoch 2400 LossPred 0.2545 LossAtt 0.3726 TrainAcc 0.8900 TestAcc 0.8173 0.9000
epoch 2500 LossPred 0.2381 LossAtt 0.3703 TrainAcc 0.9100 TestAcc 0.8216 0.9000
Optimization Finished!
********** replication  90  **********
epoch   0 LossPred 1.0571 LossAtt 1.0374 TrainAcc 0.4400 TestAcc 0.5531 0.4500
epoch 100 LossPred 0.9143 LossAtt 0.3358 TrainAcc 0.6400 TestAcc 0.5175 0.6300
epoch 200 LossPred 0.8968 LossAtt 0.2952 TrainAcc 0.6400 TestAcc 0.5781 0.6400
epoch 300 LossPred 0.8723 LossAtt 0.3177 TrainAcc 0.6700 TestAcc 0.5533 0.6600
epoch 400 LossPred 0.8364 LossAtt 0.3756 TrainAcc 0.6900 TestAcc 0.5448 0.6900
epoch 500 LossPred 0.3044 LossAtt 0.5189 TrainAcc 0.9500 TestAcc 0.8514 0.9100
epoch 600 LossPred 0.2192 LossAtt 0.4824 TrainAcc 0.9600 TestAcc 0.7963 0.9450
epoch 700 LossPred 0.1406 LossAtt 0.4488 TrainAcc 0.9700 TestAcc 0.8363 0.9600
epoch 800 LossPred 0.1297 LossAtt 0.4334 TrainAcc 0.9700 TestAcc 0.8438 0.9400
epoch 900 LossPred 0.1600 LossAtt 0.4440 TrainAcc 0.9500 TestAcc 0.7868 0.9250
epoch 1000 LossPred 0.1106 LossAtt 0.4270 TrainAcc 0.9700 TestAcc 0.8268 0.9450
epoch 1100 LossPred 0.1024 LossAtt 0.4301 TrainAcc 0.9800 TestAcc 0.8401 0.9400
epoch 1200 LossPred 0.1001 LossAtt 0.4338 TrainAcc 0.9800 TestAcc 0.8371 0.9250
epoch 1300 LossPred 0.1144 LossAtt 0.4300 TrainAcc 0.9700 TestAcc 0.8303 0.9400
epoch 1400 LossPred 0.2652 LossAtt 0.4296 TrainAcc 0.9000 TestAcc 0.7593 0.9150
epoch 1500 LossPred 0.1675 LossAtt 0.4546 TrainAcc 0.9500 TestAcc 0.8498 0.9000
epoch 1600 LossPred 0.1180 LossAtt 0.4523 TrainAcc 0.9700 TestAcc 0.7983 0.9250
epoch 1700 LossPred 0.0738 LossAtt 0.4577 TrainAcc 0.9800 TestAcc 0.8504 0.9100
epoch 1800 LossPred 0.0789 LossAtt 0.4553 TrainAcc 0.9700 TestAcc 0.8383 0.9200
epoch 1900 LossPred 0.1083 LossAtt 0.4419 TrainAcc 0.9700 TestAcc 0.8008 0.9300
epoch 2000 LossPred 0.0866 LossAtt 0.4684 TrainAcc 0.9700 TestAcc 0.8378 0.9350
epoch 2100 LossPred 0.0710 LossAtt 0.4702 TrainAcc 0.9800 TestAcc 0.8273 0.9450
epoch 2200 LossPred 0.0686 LossAtt 0.4567 TrainAcc 0.9800 TestAcc 0.8288 0.9450
epoch 2300 LossPred 0.0783 LossAtt 0.4648 TrainAcc 0.9700 TestAcc 0.8166 0.9500
epoch 2400 LossPred 0.0580 LossAtt 0.4664 TrainAcc 0.9800 TestAcc 0.8341 0.9500
epoch 2500 LossPred 0.0698 LossAtt 0.4640 TrainAcc 0.9900 TestAcc 0.8213 0.9600
Optimization Finished!
********** replication  91  **********
epoch   0 LossPred 1.0111 LossAtt 1.0854 TrainAcc 0.4900 TestAcc 0.4995 0.5250
epoch 100 LossPred 0.9015 LossAtt 0.4300 TrainAcc 0.6200 TestAcc 0.5768 0.5900
epoch 200 LossPred 0.5168 LossAtt 0.4358 TrainAcc 0.8100 TestAcc 0.8246 0.8250
epoch 300 LossPred 0.2911 LossAtt 0.4124 TrainAcc 0.9100 TestAcc 0.8346 0.8600
epoch 400 LossPred 0.2631 LossAtt 0.3806 TrainAcc 0.9000 TestAcc 0.8363 0.8600
epoch 500 LossPred 0.2368 LossAtt 0.3619 TrainAcc 0.9400 TestAcc 0.8496 0.8650
epoch 600 LossPred 0.2651 LossAtt 0.3624 TrainAcc 0.9000 TestAcc 0.8443 0.8550
epoch 700 LossPred 0.2371 LossAtt 0.3558 TrainAcc 0.9500 TestAcc 0.8298 0.8700
epoch 800 LossPred 0.2610 LossAtt 0.3535 TrainAcc 0.9300 TestAcc 0.8361 0.8700
epoch 900 LossPred 0.2307 LossAtt 0.3530 TrainAcc 0.9400 TestAcc 0.8326 0.8750
epoch 1000 LossPred 0.2667 LossAtt 0.3294 TrainAcc 0.9300 TestAcc 0.8323 0.8800
epoch 1100 LossPred 0.2241 LossAtt 0.3379 TrainAcc 0.9400 TestAcc 0.8248 0.8950
epoch 1200 LossPred 0.2350 LossAtt 0.3190 TrainAcc 0.9400 TestAcc 0.8549 0.8850
epoch 1300 LossPred 0.2334 LossAtt 0.3109 TrainAcc 0.9300 TestAcc 0.8441 0.8850
epoch 1400 LossPred 0.3202 LossAtt 0.3154 TrainAcc 0.9200 TestAcc 0.8288 0.8800
epoch 1500 LossPred 0.2218 LossAtt 0.2983 TrainAcc 0.9400 TestAcc 0.8488 0.8950
epoch 1600 LossPred 0.2266 LossAtt 0.3019 TrainAcc 0.9500 TestAcc 0.8231 0.8950
epoch 1700 LossPred 0.3704 LossAtt 0.2958 TrainAcc 0.8800 TestAcc 0.8441 0.8550
epoch 1800 LossPred 0.3630 LossAtt 0.3007 TrainAcc 0.8900 TestAcc 0.8376 0.8950
epoch 1900 LossPred 0.2286 LossAtt 0.2973 TrainAcc 0.9500 TestAcc 0.8268 0.9100
epoch 2000 LossPred 0.3454 LossAtt 0.3031 TrainAcc 0.8900 TestAcc 0.8316 0.8850
epoch 2100 LossPred 0.2533 LossAtt 0.3107 TrainAcc 0.9300 TestAcc 0.8268 0.8850
epoch 2200 LossPred 0.2291 LossAtt 0.2984 TrainAcc 0.9400 TestAcc 0.8286 0.8900
epoch 2300 LossPred 0.2318 LossAtt 0.2964 TrainAcc 0.9300 TestAcc 0.8258 0.8800
epoch 2400 LossPred 0.2246 LossAtt 0.3136 TrainAcc 0.9400 TestAcc 0.8191 0.8800
epoch 2500 LossPred 0.2385 LossAtt 0.3151 TrainAcc 0.9400 TestAcc 0.8341 0.8800
Optimization Finished!
********** replication  92  **********
epoch   0 LossPred 1.0426 LossAtt 1.0409 TrainAcc 0.5500 TestAcc 0.5440 0.5650
epoch 100 LossPred 0.9441 LossAtt 0.2914 TrainAcc 0.6100 TestAcc 0.5906 0.6200
epoch 200 LossPred 0.9343 LossAtt 0.2884 TrainAcc 0.6200 TestAcc 0.5626 0.6300
epoch 300 LossPred 0.8888 LossAtt 0.3460 TrainAcc 0.6400 TestAcc 0.5420 0.6500
epoch 400 LossPred 0.8558 LossAtt 0.3411 TrainAcc 0.6700 TestAcc 0.5483 0.6550
epoch 500 LossPred 0.8182 LossAtt 0.3780 TrainAcc 0.6800 TestAcc 0.5538 0.6450
epoch 600 LossPred 0.7821 LossAtt 0.3454 TrainAcc 0.7000 TestAcc 0.5458 0.6700
epoch 700 LossPred 0.7364 LossAtt 0.3696 TrainAcc 0.7200 TestAcc 0.5521 0.6850
epoch 800 LossPred 0.7059 LossAtt 0.4063 TrainAcc 0.7300 TestAcc 0.5470 0.6950
epoch 900 LossPred 0.6781 LossAtt 0.3923 TrainAcc 0.7400 TestAcc 0.5465 0.7150
epoch 1000 LossPred 0.6477 LossAtt 0.4257 TrainAcc 0.8100 TestAcc 0.5591 0.7700
epoch 1100 LossPred 0.6122 LossAtt 0.4353 TrainAcc 0.8200 TestAcc 0.5656 0.7800
epoch 1200 LossPred 0.5901 LossAtt 0.4509 TrainAcc 0.8400 TestAcc 0.5488 0.7850
epoch 1300 LossPred 0.5366 LossAtt 0.4748 TrainAcc 0.8500 TestAcc 0.5506 0.7600
epoch 1400 LossPred 0.5112 LossAtt 0.4991 TrainAcc 0.8500 TestAcc 0.5355 0.7500
epoch 1500 LossPred 0.4447 LossAtt 0.4821 TrainAcc 0.8600 TestAcc 0.5403 0.7700
epoch 1600 LossPred 0.4306 LossAtt 0.4613 TrainAcc 0.8800 TestAcc 0.5415 0.7750
epoch 1700 LossPred 0.5273 LossAtt 0.4729 TrainAcc 0.8400 TestAcc 0.5428 0.7700
epoch 1800 LossPred 0.3809 LossAtt 0.4708 TrainAcc 0.8900 TestAcc 0.5458 0.7850
epoch 1900 LossPred 0.3731 LossAtt 0.4715 TrainAcc 0.9000 TestAcc 0.5410 0.7800
epoch 2000 LossPred 0.3536 LossAtt 0.4565 TrainAcc 0.9000 TestAcc 0.5458 0.7800
epoch 2100 LossPred 0.3429 LossAtt 0.4635 TrainAcc 0.9000 TestAcc 0.5413 0.7700
epoch 2200 LossPred 0.3440 LossAtt 0.4519 TrainAcc 0.9000 TestAcc 0.5410 0.8100
epoch 2300 LossPred 0.3281 LossAtt 0.4616 TrainAcc 0.9200 TestAcc 0.5350 0.7950
epoch 2400 LossPred 0.3189 LossAtt 0.4288 TrainAcc 0.9100 TestAcc 0.5393 0.8200
epoch 2500 LossPred 0.3229 LossAtt 0.4619 TrainAcc 0.9100 TestAcc 0.5400 0.7950
Optimization Finished!
********** replication  93  **********
epoch   0 LossPred 1.1433 LossAtt 1.0137 TrainAcc 0.4700 TestAcc 0.4695 0.4700
epoch 100 LossPred 0.9165 LossAtt 0.3761 TrainAcc 0.6300 TestAcc 0.5523 0.6300
epoch 200 LossPred 0.5373 LossAtt 0.3997 TrainAcc 0.8400 TestAcc 0.8058 0.8000
epoch 300 LossPred 0.4738 LossAtt 0.3758 TrainAcc 0.8400 TestAcc 0.8311 0.8250
epoch 400 LossPred 0.4548 LossAtt 0.3729 TrainAcc 0.8500 TestAcc 0.8043 0.8050
epoch 500 LossPred 0.3837 LossAtt 0.3507 TrainAcc 0.8700 TestAcc 0.8361 0.8550
epoch 600 LossPred 0.3976 LossAtt 0.3417 TrainAcc 0.8600 TestAcc 0.8488 0.8550
epoch 700 LossPred 0.4183 LossAtt 0.3210 TrainAcc 0.8600 TestAcc 0.7970 0.8250
epoch 800 LossPred 0.3524 LossAtt 0.3128 TrainAcc 0.8900 TestAcc 0.8478 0.8800
epoch 900 LossPred 0.5400 LossAtt 0.3174 TrainAcc 0.8400 TestAcc 0.8096 0.8100
epoch 1000 LossPred 0.4204 LossAtt 0.3185 TrainAcc 0.8500 TestAcc 0.8493 0.8500
epoch 1100 LossPred 0.3622 LossAtt 0.2981 TrainAcc 0.8700 TestAcc 0.8526 0.8650
epoch 1200 LossPred 0.3785 LossAtt 0.3147 TrainAcc 0.8600 TestAcc 0.8436 0.8550
epoch 1300 LossPred 0.3271 LossAtt 0.3180 TrainAcc 0.8700 TestAcc 0.8478 0.8750
epoch 1400 LossPred 0.2872 LossAtt 0.3226 TrainAcc 0.9100 TestAcc 0.8741 0.9050
epoch 1500 LossPred 0.2738 LossAtt 0.3230 TrainAcc 0.8900 TestAcc 0.8851 0.9000
epoch 1600 LossPred 0.3039 LossAtt 0.3186 TrainAcc 0.8900 TestAcc 0.8671 0.8650
epoch 1700 LossPred 0.2910 LossAtt 0.3051 TrainAcc 0.9200 TestAcc 0.8729 0.9100
epoch 1800 LossPred 0.2482 LossAtt 0.3026 TrainAcc 0.9100 TestAcc 0.8784 0.9050
epoch 1900 LossPred 0.3336 LossAtt 0.2962 TrainAcc 0.8900 TestAcc 0.8591 0.8400
epoch 2000 LossPred 0.2352 LossAtt 0.2830 TrainAcc 0.9000 TestAcc 0.8846 0.9100
epoch 2100 LossPred 0.2300 LossAtt 0.2749 TrainAcc 0.9000 TestAcc 0.8879 0.9350
epoch 2200 LossPred 0.1655 LossAtt 0.2660 TrainAcc 0.9500 TestAcc 0.9014 0.9450
epoch 2300 LossPred 0.1767 LossAtt 0.2622 TrainAcc 0.9600 TestAcc 0.9009 0.9350
epoch 2400 LossPred 0.1655 LossAtt 0.2648 TrainAcc 0.9400 TestAcc 0.9027 0.9350
epoch 2500 LossPred 0.4056 LossAtt 0.2619 TrainAcc 0.8500 TestAcc 0.8301 0.8550
Optimization Finished!
********** replication  94  **********
epoch   0 LossPred 1.3495 LossAtt 1.0213 TrainAcc 0.4200 TestAcc 0.4607 0.4000
epoch 100 LossPred 0.9248 LossAtt 0.3590 TrainAcc 0.6600 TestAcc 0.5786 0.6600
epoch 200 LossPred 0.8444 LossAtt 0.3090 TrainAcc 0.6700 TestAcc 0.6129 0.6600
epoch 300 LossPred 0.5615 LossAtt 0.3435 TrainAcc 0.8300 TestAcc 0.8243 0.8500
epoch 400 LossPred 0.4275 LossAtt 0.3940 TrainAcc 0.8800 TestAcc 0.8373 0.8450
epoch 500 LossPred 0.3132 LossAtt 0.4100 TrainAcc 0.9000 TestAcc 0.8468 0.8800
epoch 600 LossPred 0.2582 LossAtt 0.4164 TrainAcc 0.9400 TestAcc 0.8378 0.8900
epoch 700 LossPred 0.2370 LossAtt 0.4181 TrainAcc 0.9300 TestAcc 0.8263 0.8800
epoch 800 LossPred 0.2724 LossAtt 0.4185 TrainAcc 0.8900 TestAcc 0.8163 0.8750
epoch 900 LossPred 0.2269 LossAtt 0.4059 TrainAcc 0.9300 TestAcc 0.8493 0.8800
epoch 1000 LossPred 0.2031 LossAtt 0.4052 TrainAcc 0.9300 TestAcc 0.8386 0.8850
epoch 1100 LossPred 0.3214 LossAtt 0.4051 TrainAcc 0.9000 TestAcc 0.8021 0.8700
epoch 1200 LossPred 0.2077 LossAtt 0.4001 TrainAcc 0.9300 TestAcc 0.8218 0.8900
epoch 1300 LossPred 0.2367 LossAtt 0.4129 TrainAcc 0.9100 TestAcc 0.8196 0.8900
epoch 1400 LossPred 0.1514 LossAtt 0.3908 TrainAcc 0.9500 TestAcc 0.8426 0.9050
epoch 1500 LossPred 0.1715 LossAtt 0.4067 TrainAcc 0.9300 TestAcc 0.8423 0.8950
epoch 1600 LossPred 0.2799 LossAtt 0.3871 TrainAcc 0.9000 TestAcc 0.8458 0.8850
epoch 1700 LossPred 0.1537 LossAtt 0.3905 TrainAcc 0.9300 TestAcc 0.8286 0.8850
epoch 1800 LossPred 0.1311 LossAtt 0.3969 TrainAcc 0.9700 TestAcc 0.8271 0.9300
epoch 1900 LossPred 0.1218 LossAtt 0.4043 TrainAcc 0.9700 TestAcc 0.8293 0.9350
epoch 2000 LossPred 0.1915 LossAtt 0.3952 TrainAcc 0.9500 TestAcc 0.8156 0.9100
epoch 2100 LossPred 0.1718 LossAtt 0.3886 TrainAcc 0.9500 TestAcc 0.8421 0.9000
epoch 2200 LossPred 0.1128 LossAtt 0.4036 TrainAcc 0.9800 TestAcc 0.8431 0.9150
epoch 2300 LossPred 0.1004 LossAtt 0.3968 TrainAcc 0.9800 TestAcc 0.8423 0.9150
epoch 2400 LossPred 0.0871 LossAtt 0.4051 TrainAcc 0.9800 TestAcc 0.8311 0.9400
epoch 2500 LossPred 0.0863 LossAtt 0.3933 TrainAcc 0.9800 TestAcc 0.8341 0.9300
Optimization Finished!
********** replication  95  **********
epoch   0 LossPred 0.9996 LossAtt 1.0597 TrainAcc 0.5500 TestAcc 0.5005 0.5450
epoch 100 LossPred 0.9124 LossAtt 0.3144 TrainAcc 0.6400 TestAcc 0.5433 0.6150
epoch 200 LossPred 0.8524 LossAtt 0.3182 TrainAcc 0.6300 TestAcc 0.5701 0.6050
epoch 300 LossPred 0.6058 LossAtt 0.4439 TrainAcc 0.7500 TestAcc 0.7457 0.7900
epoch 400 LossPred 0.4633 LossAtt 0.4147 TrainAcc 0.8400 TestAcc 0.7905 0.8650
epoch 500 LossPred 0.3151 LossAtt 0.4196 TrainAcc 0.8900 TestAcc 0.8381 0.9000
epoch 600 LossPred 0.2674 LossAtt 0.4241 TrainAcc 0.9100 TestAcc 0.8403 0.9100
epoch 700 LossPred 0.2295 LossAtt 0.4108 TrainAcc 0.9200 TestAcc 0.8398 0.9200
epoch 800 LossPred 0.2421 LossAtt 0.4148 TrainAcc 0.9200 TestAcc 0.8363 0.9100
epoch 900 LossPred 0.1887 LossAtt 0.4071 TrainAcc 0.9500 TestAcc 0.8383 0.9200
epoch 1000 LossPred 0.2112 LossAtt 0.3801 TrainAcc 0.9300 TestAcc 0.8323 0.9150
epoch 1100 LossPred 0.1710 LossAtt 0.3869 TrainAcc 0.9300 TestAcc 0.8398 0.9200
epoch 1200 LossPred 0.1187 LossAtt 0.3771 TrainAcc 0.9600 TestAcc 0.8458 0.9250
epoch 1300 LossPred 0.1128 LossAtt 0.3906 TrainAcc 0.9700 TestAcc 0.8468 0.9150
epoch 1400 LossPred 0.1338 LossAtt 0.3678 TrainAcc 0.9400 TestAcc 0.8498 0.9450
epoch 1500 LossPred 0.1187 LossAtt 0.3514 TrainAcc 0.9600 TestAcc 0.8526 0.9450
epoch 1600 LossPred 0.0927 LossAtt 0.3390 TrainAcc 0.9800 TestAcc 0.8549 0.9400
epoch 1700 LossPred 0.0841 LossAtt 0.3436 TrainAcc 0.9800 TestAcc 0.8601 0.9450
epoch 1800 LossPred 0.1288 LossAtt 0.3293 TrainAcc 0.9400 TestAcc 0.8631 0.9350
epoch 1900 LossPred 0.0699 LossAtt 0.3213 TrainAcc 0.9800 TestAcc 0.8646 0.9450
epoch 2000 LossPred 0.0824 LossAtt 0.3220 TrainAcc 0.9900 TestAcc 0.8609 0.9400
epoch 2100 LossPred 0.1154 LossAtt 0.3119 TrainAcc 0.9600 TestAcc 0.8524 0.9300
epoch 2200 LossPred 0.0707 LossAtt 0.3107 TrainAcc 0.9800 TestAcc 0.8629 0.9500
epoch 2300 LossPred 0.0618 LossAtt 0.3005 TrainAcc 0.9800 TestAcc 0.8641 0.9700
epoch 2400 LossPred 0.0632 LossAtt 0.2926 TrainAcc 0.9900 TestAcc 0.8596 0.9550
epoch 2500 LossPred 0.0650 LossAtt 0.2895 TrainAcc 0.9800 TestAcc 0.8724 0.9750
Optimization Finished!
********** replication  96  **********
epoch   0 LossPred 1.1690 LossAtt 1.0167 TrainAcc 0.3900 TestAcc 0.4622 0.3700
epoch 100 LossPred 0.8520 LossAtt 0.3780 TrainAcc 0.6500 TestAcc 0.5793 0.6550
epoch 200 LossPred 0.4436 LossAtt 0.3823 TrainAcc 0.8700 TestAcc 0.7925 0.8450
epoch 300 LossPred 0.3392 LossAtt 0.3510 TrainAcc 0.9100 TestAcc 0.8146 0.8550
epoch 400 LossPred 0.3053 LossAtt 0.3147 TrainAcc 0.9400 TestAcc 0.8306 0.8550
epoch 500 LossPred 0.2898 LossAtt 0.3081 TrainAcc 0.9300 TestAcc 0.8323 0.8500
epoch 600 LossPred 0.2804 LossAtt 0.3116 TrainAcc 0.9500 TestAcc 0.8286 0.8400
epoch 700 LossPred 0.2721 LossAtt 0.2914 TrainAcc 0.9300 TestAcc 0.8176 0.8400
epoch 800 LossPred 0.3745 LossAtt 0.3097 TrainAcc 0.8800 TestAcc 0.7883 0.8200
epoch 900 LossPred 0.3273 LossAtt 0.3016 TrainAcc 0.9000 TestAcc 0.8223 0.8300
epoch 1000 LossPred 0.3477 LossAtt 0.3096 TrainAcc 0.8800 TestAcc 0.8326 0.8200
epoch 1100 LossPred 0.2426 LossAtt 0.2898 TrainAcc 0.9100 TestAcc 0.8096 0.8250
epoch 1200 LossPred 0.2891 LossAtt 0.2893 TrainAcc 0.9100 TestAcc 0.7848 0.8250
epoch 1300 LossPred 0.7842 LossAtt 0.3179 TrainAcc 0.7400 TestAcc 0.6857 0.7500
epoch 1400 LossPred 0.3175 LossAtt 0.2968 TrainAcc 0.9000 TestAcc 0.8178 0.8300
epoch 1500 LossPred 0.3036 LossAtt 0.2849 TrainAcc 0.9000 TestAcc 0.7975 0.8500
epoch 1600 LossPred 0.2963 LossAtt 0.2737 TrainAcc 0.9100 TestAcc 0.7898 0.8400
epoch 1700 LossPred 0.2948 LossAtt 0.2611 TrainAcc 0.9000 TestAcc 0.7865 0.8200
epoch 1800 LossPred 0.2675 LossAtt 0.2798 TrainAcc 0.9200 TestAcc 0.7925 0.8200
epoch 1900 LossPred 0.2585 LossAtt 0.2909 TrainAcc 0.9200 TestAcc 0.7948 0.8150
epoch 2000 LossPred 0.2381 LossAtt 0.3017 TrainAcc 0.9400 TestAcc 0.7865 0.8250
epoch 2100 LossPred 0.2471 LossAtt 0.3144 TrainAcc 0.9200 TestAcc 0.7940 0.8400
epoch 2200 LossPred 0.2186 LossAtt 0.3079 TrainAcc 0.9300 TestAcc 0.7990 0.8300
epoch 2300 LossPred 0.2083 LossAtt 0.2995 TrainAcc 0.9500 TestAcc 0.7985 0.8300
epoch 2400 LossPred 0.2424 LossAtt 0.2991 TrainAcc 0.9200 TestAcc 0.8026 0.8350
epoch 2500 LossPred 0.2373 LossAtt 0.2956 TrainAcc 0.9400 TestAcc 0.7983 0.8450
Optimization Finished!
********** replication  97  **********
epoch   0 LossPred 1.0275 LossAtt 1.0522 TrainAcc 0.4400 TestAcc 0.4207 0.4450
epoch 100 LossPred 0.9479 LossAtt 0.3361 TrainAcc 0.5800 TestAcc 0.6221 0.5650
epoch 200 LossPred 1.1228 LossAtt 0.3864 TrainAcc 0.5800 TestAcc 0.6096 0.6250
epoch 300 LossPred 0.4027 LossAtt 0.3344 TrainAcc 0.8700 TestAcc 0.8018 0.8250
epoch 400 LossPred 0.3503 LossAtt 0.3129 TrainAcc 0.8900 TestAcc 0.8371 0.8850
epoch 500 LossPred 0.3171 LossAtt 0.3237 TrainAcc 0.9100 TestAcc 0.8336 0.8900
epoch 600 LossPred 0.2972 LossAtt 0.3041 TrainAcc 0.9200 TestAcc 0.8398 0.8850
epoch 700 LossPred 0.2765 LossAtt 0.3067 TrainAcc 0.9200 TestAcc 0.8433 0.8800
epoch 800 LossPred 0.2764 LossAtt 0.3107 TrainAcc 0.9100 TestAcc 0.8328 0.8950
epoch 900 LossPred 0.2140 LossAtt 0.3298 TrainAcc 0.9400 TestAcc 0.8353 0.8850
epoch 1000 LossPred 0.2041 LossAtt 0.3208 TrainAcc 0.9500 TestAcc 0.8396 0.8950
epoch 1100 LossPred 0.1908 LossAtt 0.3212 TrainAcc 0.9500 TestAcc 0.8383 0.8950
epoch 1200 LossPred 0.2251 LossAtt 0.3220 TrainAcc 0.9200 TestAcc 0.8358 0.8900
epoch 1300 LossPred 0.2825 LossAtt 0.3220 TrainAcc 0.9200 TestAcc 0.8243 0.8850
epoch 1400 LossPred 0.1770 LossAtt 0.3192 TrainAcc 0.9400 TestAcc 0.8398 0.8900
epoch 1500 LossPred 0.1782 LossAtt 0.3116 TrainAcc 0.9400 TestAcc 0.8381 0.8950
epoch 1600 LossPred 0.1663 LossAtt 0.3050 TrainAcc 0.9400 TestAcc 0.8351 0.8900
epoch 1700 LossPred 0.1741 LossAtt 0.2972 TrainAcc 0.9600 TestAcc 0.8348 0.8850
epoch 1800 LossPred 0.1732 LossAtt 0.2923 TrainAcc 0.9400 TestAcc 0.8323 0.8900
epoch 1900 LossPred 0.1622 LossAtt 0.2966 TrainAcc 0.9600 TestAcc 0.8321 0.8850
epoch 2000 LossPred 0.1780 LossAtt 0.2894 TrainAcc 0.9300 TestAcc 0.8328 0.8850
epoch 2100 LossPred 0.1676 LossAtt 0.2929 TrainAcc 0.9500 TestAcc 0.8291 0.8800
epoch 2200 LossPred 0.1584 LossAtt 0.3017 TrainAcc 0.9500 TestAcc 0.8283 0.8750
epoch 2300 LossPred 0.2558 LossAtt 0.2908 TrainAcc 0.9200 TestAcc 0.8153 0.8650
epoch 2400 LossPred 0.3742 LossAtt 0.2895 TrainAcc 0.8800 TestAcc 0.7933 0.8350
epoch 2500 LossPred 0.1966 LossAtt 0.2839 TrainAcc 0.9400 TestAcc 0.8223 0.8900
Optimization Finished!
********** replication  98  **********
epoch   0 LossPred 1.0532 LossAtt 1.0547 TrainAcc 0.5600 TestAcc 0.5853 0.5400
epoch 100 LossPred 0.9230 LossAtt 0.2552 TrainAcc 0.6100 TestAcc 0.5831 0.6100
epoch 200 LossPred 0.9100 LossAtt 0.1935 TrainAcc 0.5500 TestAcc 0.5763 0.5600
epoch 300 LossPred 0.9026 LossAtt 0.1973 TrainAcc 0.6300 TestAcc 0.5623 0.6250
epoch 400 LossPred 0.8967 LossAtt 0.2090 TrainAcc 0.6100 TestAcc 0.4860 0.6100
epoch 500 LossPred 0.8910 LossAtt 0.2219 TrainAcc 0.6100 TestAcc 0.4860 0.6000
epoch 600 LossPred 0.8861 LossAtt 0.2435 TrainAcc 0.6100 TestAcc 0.4855 0.6100
epoch 700 LossPred 0.8800 LossAtt 0.2586 TrainAcc 0.6100 TestAcc 0.4857 0.6000
epoch 800 LossPred 0.8808 LossAtt 0.2717 TrainAcc 0.6300 TestAcc 0.5653 0.5800
epoch 900 LossPred 0.8609 LossAtt 0.2904 TrainAcc 0.6500 TestAcc 0.5718 0.6100
epoch 1000 LossPred 0.8431 LossAtt 0.2491 TrainAcc 0.6500 TestAcc 0.5696 0.6450
epoch 1100 LossPred 0.8223 LossAtt 0.2874 TrainAcc 0.6600 TestAcc 0.5751 0.6200
epoch 1200 LossPred 0.8022 LossAtt 0.2943 TrainAcc 0.6700 TestAcc 0.5733 0.6550
epoch 1300 LossPred 0.8116 LossAtt 0.3044 TrainAcc 0.6900 TestAcc 0.5998 0.6450
epoch 1400 LossPred 0.7494 LossAtt 0.3281 TrainAcc 0.7000 TestAcc 0.5726 0.6700
epoch 1500 LossPred 0.7323 LossAtt 0.3517 TrainAcc 0.7000 TestAcc 0.5656 0.6600
epoch 1600 LossPred 0.7186 LossAtt 0.3376 TrainAcc 0.7100 TestAcc 0.5691 0.6500
epoch 1700 LossPred 0.7031 LossAtt 0.3560 TrainAcc 0.7100 TestAcc 0.5703 0.6900
epoch 1800 LossPred 0.7104 LossAtt 0.3849 TrainAcc 0.7000 TestAcc 0.5733 0.7050
epoch 1900 LossPred 0.6534 LossAtt 0.3726 TrainAcc 0.7600 TestAcc 0.5746 0.7100
epoch 2000 LossPred 0.6230 LossAtt 0.3785 TrainAcc 0.7900 TestAcc 0.5888 0.7350
epoch 2100 LossPred 0.6372 LossAtt 0.3703 TrainAcc 0.7600 TestAcc 0.5913 0.7250
epoch 2200 LossPred 0.6105 LossAtt 0.3608 TrainAcc 0.7800 TestAcc 0.5891 0.7500
epoch 2300 LossPred 0.6642 LossAtt 0.3704 TrainAcc 0.7500 TestAcc 0.5861 0.7350
epoch 2400 LossPred 0.5983 LossAtt 0.3568 TrainAcc 0.7900 TestAcc 0.5848 0.7600
epoch 2500 LossPred 0.5886 LossAtt 0.3594 TrainAcc 0.8200 TestAcc 0.5756 0.7550
Optimization Finished!
********** replication  99  **********
epoch   0 LossPred 1.0462 LossAtt 1.0090 TrainAcc 0.5300 TestAcc 0.5198 0.5250
epoch 100 LossPred 0.9457 LossAtt 0.3222 TrainAcc 0.5900 TestAcc 0.5428 0.5900
epoch 200 LossPred 0.9369 LossAtt 0.2722 TrainAcc 0.6000 TestAcc 0.5495 0.6150
epoch 300 LossPred 0.8849 LossAtt 0.3446 TrainAcc 0.6700 TestAcc 0.6061 0.6550
epoch 400 LossPred 0.3480 LossAtt 0.3286 TrainAcc 0.8900 TestAcc 0.8336 0.8750
epoch 500 LossPred 0.4731 LossAtt 0.3269 TrainAcc 0.8500 TestAcc 0.7955 0.8250
epoch 600 LossPred 0.3334 LossAtt 0.3304 TrainAcc 0.9000 TestAcc 0.8023 0.8500
epoch 700 LossPred 0.5084 LossAtt 0.3453 TrainAcc 0.8500 TestAcc 0.7980 0.8000
epoch 800 LossPred 0.3613 LossAtt 0.3397 TrainAcc 0.8800 TestAcc 0.8206 0.8650
epoch 900 LossPred 0.2782 LossAtt 0.3184 TrainAcc 0.9200 TestAcc 0.8363 0.8900
epoch 1000 LossPred 0.2866 LossAtt 0.3290 TrainAcc 0.9200 TestAcc 0.8358 0.8700
epoch 1100 LossPred 0.4357 LossAtt 0.3228 TrainAcc 0.8500 TestAcc 0.8168 0.8700
epoch 1200 LossPred 0.2703 LossAtt 0.3134 TrainAcc 0.9200 TestAcc 0.8336 0.8850
epoch 1300 LossPred 0.2650 LossAtt 0.3135 TrainAcc 0.9200 TestAcc 0.8361 0.8950
epoch 1400 LossPred 0.2653 LossAtt 0.3193 TrainAcc 0.9300 TestAcc 0.8208 0.8900
epoch 1500 LossPred 0.2548 LossAtt 0.3045 TrainAcc 0.9200 TestAcc 0.8346 0.8950
epoch 1600 LossPred 0.2454 LossAtt 0.3043 TrainAcc 0.9300 TestAcc 0.8316 0.8750
epoch 1700 LossPred 0.2287 LossAtt 0.2923 TrainAcc 0.9400 TestAcc 0.8231 0.8950
epoch 1800 LossPred 0.2253 LossAtt 0.2931 TrainAcc 0.9300 TestAcc 0.8266 0.8850
epoch 1900 LossPred 0.2393 LossAtt 0.3002 TrainAcc 0.9300 TestAcc 0.8308 0.9000
epoch 2000 LossPred 0.2572 LossAtt 0.2939 TrainAcc 0.9200 TestAcc 0.8291 0.8850
epoch 2100 LossPred 0.4459 LossAtt 0.3019 TrainAcc 0.8400 TestAcc 0.7845 0.8300
epoch 2200 LossPred 0.2319 LossAtt 0.2795 TrainAcc 0.9300 TestAcc 0.8266 0.8950
epoch 2300 LossPred 0.2224 LossAtt 0.2699 TrainAcc 0.9400 TestAcc 0.8321 0.8900
epoch 2400 LossPred 0.5974 LossAtt 0.2932 TrainAcc 0.7700 TestAcc 0.7362 0.7800
epoch 2500 LossPred 0.2310 LossAtt 0.2807 TrainAcc 0.9300 TestAcc 0.8273 0.9000
Optimization Finished!
********************************************************************
Namespace(arch='tanh', batch_size=256, display_epoch=100, input_noise_level=0.15, latent_attractor_space=True, loss_switch_frequency=0, lrate_attractor=0.002, lrate_prediction=0.002, lrate_wt_penalty=0.0, n_attractor_hidden=20, n_attractor_steps=5, n_hidden=10, n_replications=100, noise_level=0.25, report_best_train_performance=True, seq_len=25, task='majority', train_attr_weights_on_prediction=False, training_epochs=2500)
********************************************************************
mean train accuracy 0.95699996
indiv runs  [0.97, 0.98, 0.99, 1.0, 0.96, 0.97, 0.77, 0.93, 1.0, 1.0, 0.97, 0.83, 0.97, 0.99, 0.9, 0.94, 0.97, 0.99, 0.92, 0.96, 0.96, 0.97, 0.96, 1.0, 1.0, 0.92, 0.88, 0.98, 0.98, 0.88, 0.96, 0.99, 0.97, 0.99, 0.8, 0.92, 0.99, 0.99, 0.98, 0.98, 0.98, 0.89, 0.98, 0.96, 0.94, 0.97, 0.97, 0.96, 0.98, 0.95, 0.98, 0.97, 0.99, 0.98, 1.0, 0.96, 0.94, 0.98, 0.97, 1.0, 0.98, 0.95, 0.89, 0.95, 0.96, 0.99, 0.99, 0.98, 0.94, 0.95, 1.0, 0.97, 0.97, 0.97, 0.98, 1.0, 1.0, 1.0, 0.98, 0.97, 0.8, 0.99, 0.93, 1.0, 0.96, 0.99, 0.92, 0.94, 0.91, 0.92, 0.99, 0.95, 0.92, 0.96, 0.98, 0.99, 0.95, 0.96, 0.82, 0.94]
mean epoch 1401.0
indiv epochs  [1301, 701, 1301, 1401, 2501, 501, 1301, 1101, 1501, 1601, 1401, 2201]
test1 accuracy mean  0.79600847  median  0.8424674
test2 accuracy mean  0.88975  median  0.91
test1 indiv runs  [0.8508509, 0.8480981, 0.9001502, 0.8988989, 0.5920921, 0.8453453, 0.5763263, 0.7985485, 0.8528529, 0.8568569, 0.9004004, 0.5105105, 0.8145646, 0.8495996, 0.7867868, 0.8285786, 0.8751251, 0.8596096, 0.782032, 0.9304304, 0.5785786, 0.7562563, 0.8268268, 0.8546046, 0.8330831, 0.54004, 0.5635636, 0.8533534, 0.9026527, 0.8638639, 0.8963964, 0.8878879, 0.8588589, 0.8851351, 0.5312813, 0.5663163, 0.8698699, 0.8305806, 0.8641141, 0.8463463, 0.8388388, 0.534034, 0.8771271, 0.9476977, 0.7847848, 0.8666166, 0.9299299, 0.5265265, 0.7967968, 0.8175676, 0.7805305, 0.8183183, 0.8528529, 0.8566066, 0.8776276, 0.8440941, 0.5980981, 0.7642643, 0.8153153, 0.9049049, 0.5500501, 0.8606106, 0.8270771, 0.5112613, 0.9074074, 0.8365866, 0.8933934, 0.8898899, 0.8418418, 0.7477477, 0.8536036, 0.9179179, 0.8450951, 0.8448448, 0.8901401, 0.758008, 0.9164164, 0.8768769, 0.8100601, 0.75, 0.515015, 0.9031532, 0.8508509, 0.9161662, 0.8503504, 0.8255756, 0.8358358, 0.5700701, 0.5355355, 0.8165666, 0.8213213, 0.8298298, 0.535035, 0.9009009, 0.8430931, 0.8608609, 0.8285786, 0.8348348, 0.5755756, 0.8230731]
test2 indiv runs  [0.945, 0.92, 0.98, 0.97, 0.8, 0.925, 0.715, 0.895, 0.9, 0.925, 0.93, 0.73, 0.9, 0.94, 0.84, 0.895, 0.935, 0.955, 0.87, 0.91, 0.85, 0.905, 0.88, 0.95, 0.99, 0.77, 0.79, 0.955, 0.975, 0.795, 0.88, 0.915, 0.9, 0.945, 0.69, 0.75, 0.945, 0.92, 0.965, 0.89, 0.88, 0.715, 0.925, 0.9, 0.86, 0.92, 0.93, 0.79, 0.925, 0.915, 0.945, 0.93, 0.915, 0.935, 0.975, 0.88, 0.815, 0.95, 0.895, 0.95, 0.82, 0.895, 0.83, 0.785, 0.915, 0.905, 0.96, 0.93, 0.91, 0.91, 0.92, 0.935, 0.87, 0.93, 0.935, 0.96, 0.965, 0.92, 0.91, 0.865, 0.75, 0.945, 0.845, 0.98, 0.86, 0.925, 0.89, 0.805, 0.74, 0.885, 0.96, 0.87, 0.795, 0.935, 0.915, 0.94, 0.84, 0.885, 0.755, 0.895]
