Namespace(arch='tanh', batch_size=256, display_epoch=100, input_noise_level=0.15, latent_attractor_space=True, loss_switch_frequency=0, lrate_attractor=0.002, lrate_prediction=0.002, lrate_wt_penalty=0.0, n_attractor_hidden=10, n_attractor_steps=15, n_hidden=5, n_replications=100, noise_level=0.5, report_best_train_performance=True, seq_len=15, task='majority', train_attr_weights_on_prediction=False, training_epochs=2500)
TRAINING ON 100 EXAMPLES, TESTING ON 3996
********** replication  0  **********
epoch   0 LossPred 1.0637 LossAtt 1.0365 TrainAcc 0.5100 TestAcc 0.5305 0.5000
epoch 100 LossPred 0.9529 LossAtt 0.4429 TrainAcc 0.6100 TestAcc 0.5403 0.5950
epoch 200 LossPred 0.9407 LossAtt 0.3651 TrainAcc 0.6100 TestAcc 0.5403 0.6200
epoch 300 LossPred 0.9325 LossAtt 0.3016 TrainAcc 0.6100 TestAcc 0.5403 0.6300
epoch 400 LossPred 0.9002 LossAtt 0.3379 TrainAcc 0.6400 TestAcc 0.5931 0.6250
epoch 500 LossPred 0.5592 LossAtt 0.3781 TrainAcc 0.8100 TestAcc 0.8356 0.7950
epoch 600 LossPred 0.3585 LossAtt 0.4075 TrainAcc 0.8900 TestAcc 0.8724 0.8800
epoch 700 LossPred 0.3539 LossAtt 0.4365 TrainAcc 0.8700 TestAcc 0.8774 0.8700
epoch 800 LossPred 0.3550 LossAtt 0.4426 TrainAcc 0.8600 TestAcc 0.8779 0.8700
epoch 900 LossPred 0.3203 LossAtt 0.4379 TrainAcc 0.8900 TestAcc 0.8711 0.8850
epoch 1000 LossPred 0.2517 LossAtt 0.3956 TrainAcc 0.9200 TestAcc 0.9252 0.8850
epoch 1100 LossPred 0.2302 LossAtt 0.3794 TrainAcc 0.9400 TestAcc 0.9272 0.9100
epoch 1200 LossPred 0.1770 LossAtt 0.3825 TrainAcc 0.9800 TestAcc 0.9585 0.9350
epoch 1300 LossPred 0.2049 LossAtt 0.3887 TrainAcc 0.9100 TestAcc 0.9282 0.8950
epoch 1400 LossPred 0.1319 LossAtt 0.3671 TrainAcc 0.9800 TestAcc 0.9675 0.9250
epoch 1500 LossPred 0.1024 LossAtt 0.3698 TrainAcc 0.9900 TestAcc 0.9755 0.9350
epoch 1600 LossPred 0.1071 LossAtt 0.3752 TrainAcc 0.9600 TestAcc 0.9682 0.9300
epoch 1700 LossPred 0.0918 LossAtt 0.3770 TrainAcc 0.9900 TestAcc 0.9767 0.9400
epoch 1800 LossPred 0.0858 LossAtt 0.3824 TrainAcc 0.9900 TestAcc 0.9762 0.9400
epoch 1900 LossPred 0.1267 LossAtt 0.3641 TrainAcc 0.9600 TestAcc 0.9587 0.9450
epoch 2000 LossPred 0.0832 LossAtt 0.3624 TrainAcc 0.9900 TestAcc 0.9757 0.9250
epoch 2100 LossPred 0.1136 LossAtt 0.3321 TrainAcc 0.9900 TestAcc 0.9720 0.9100
epoch 2200 LossPred 0.3187 LossAtt 0.3341 TrainAcc 0.8900 TestAcc 0.9107 0.8850
epoch 2300 LossPred 0.0905 LossAtt 0.3442 TrainAcc 0.9800 TestAcc 0.9682 0.9600
epoch 2400 LossPred 0.0943 LossAtt 0.3616 TrainAcc 0.9700 TestAcc 0.9667 0.9550
epoch 2500 LossPred 0.1641 LossAtt 0.3687 TrainAcc 0.9500 TestAcc 0.9367 0.9200
Optimization Finished!
********** replication  1  **********
epoch   0 LossPred 1.4913 LossAtt 1.0037 TrainAcc 0.3800 TestAcc 0.4474 0.3800
epoch 100 LossPred 1.0795 LossAtt 0.2868 TrainAcc 0.4300 TestAcc 0.4907 0.4200
epoch 200 LossPred 0.8780 LossAtt 0.2293 TrainAcc 0.7100 TestAcc 0.6074 0.7100
epoch 300 LossPred 0.8400 LossAtt 0.1599 TrainAcc 0.7100 TestAcc 0.6074 0.7100
epoch 400 LossPred 0.8611 LossAtt 0.1146 TrainAcc 0.7100 TestAcc 0.6074 0.7100
epoch 500 LossPred 0.8273 LossAtt 0.1747 TrainAcc 0.7100 TestAcc 0.6074 0.7100
epoch 600 LossPred 0.8045 LossAtt 0.2381 TrainAcc 0.7100 TestAcc 0.6074 0.6750
epoch 700 LossPred 0.7845 LossAtt 0.2793 TrainAcc 0.7200 TestAcc 0.6674 0.6900
epoch 800 LossPred 0.4922 LossAtt 0.3951 TrainAcc 0.8200 TestAcc 0.8216 0.8150
epoch 900 LossPred 0.4416 LossAtt 0.3860 TrainAcc 0.8400 TestAcc 0.8581 0.8350
epoch 1000 LossPred 0.3612 LossAtt 0.3642 TrainAcc 0.8800 TestAcc 0.8659 0.8750
epoch 1100 LossPred 0.3480 LossAtt 0.3625 TrainAcc 0.8800 TestAcc 0.8751 0.8600
epoch 1200 LossPred 0.3100 LossAtt 0.3477 TrainAcc 0.9000 TestAcc 0.8726 0.8950
epoch 1300 LossPred 0.3230 LossAtt 0.3230 TrainAcc 0.8700 TestAcc 0.8649 0.8800
epoch 1400 LossPred 0.2709 LossAtt 0.3235 TrainAcc 0.9100 TestAcc 0.8739 0.8900
epoch 1500 LossPred 0.2563 LossAtt 0.3019 TrainAcc 0.9100 TestAcc 0.8734 0.9000
epoch 1600 LossPred 0.2398 LossAtt 0.2892 TrainAcc 0.9200 TestAcc 0.8899 0.8900
epoch 1700 LossPred 0.2301 LossAtt 0.3065 TrainAcc 0.9000 TestAcc 0.8869 0.8950
epoch 1800 LossPred 0.2248 LossAtt 0.3040 TrainAcc 0.9100 TestAcc 0.8991 0.8900
epoch 1900 LossPred 0.2144 LossAtt 0.3182 TrainAcc 0.9200 TestAcc 0.9044 0.8900
epoch 2000 LossPred 0.1826 LossAtt 0.3198 TrainAcc 0.9400 TestAcc 0.9087 0.9050
epoch 2100 LossPred 0.1815 LossAtt 0.3267 TrainAcc 0.9400 TestAcc 0.9079 0.9000
epoch 2200 LossPred 0.1857 LossAtt 0.3287 TrainAcc 0.9400 TestAcc 0.9137 0.9000
epoch 2300 LossPred 0.2225 LossAtt 0.3281 TrainAcc 0.9400 TestAcc 0.9174 0.8850
epoch 2400 LossPred 0.1951 LossAtt 0.3082 TrainAcc 0.9300 TestAcc 0.9119 0.8800
epoch 2500 LossPred 0.1735 LossAtt 0.3219 TrainAcc 0.9300 TestAcc 0.9502 0.8900
Optimization Finished!
********** replication  2  **********
epoch   0 LossPred 1.1972 LossAtt 1.0251 TrainAcc 0.4000 TestAcc 0.3951 0.4100
epoch 100 LossPred 0.9916 LossAtt 0.3241 TrainAcc 0.5500 TestAcc 0.4957 0.5500
epoch 200 LossPred 0.9667 LossAtt 0.2406 TrainAcc 0.6000 TestAcc 0.6049 0.5900
epoch 300 LossPred 0.9625 LossAtt 0.2318 TrainAcc 0.6000 TestAcc 0.6049 0.6000
epoch 400 LossPred 0.9598 LossAtt 0.2794 TrainAcc 0.6000 TestAcc 0.6049 0.6000
epoch 500 LossPred 0.9576 LossAtt 0.3513 TrainAcc 0.6000 TestAcc 0.6049 0.6000
epoch 600 LossPred 0.9752 LossAtt 0.3044 TrainAcc 0.5500 TestAcc 0.5240 0.5500
epoch 700 LossPred 0.9814 LossAtt 0.1744 TrainAcc 0.5500 TestAcc 0.4957 0.5500
epoch 800 LossPred 0.9790 LossAtt 0.1126 TrainAcc 0.5500 TestAcc 0.4957 0.5500
epoch 900 LossPred 0.9853 LossAtt 0.0419 TrainAcc 0.5500 TestAcc 0.4957 0.5500
epoch 1000 LossPred 0.9894 LossAtt 0.0311 TrainAcc 0.5500 TestAcc 0.4957 0.5500
epoch 1100 LossPred 0.9901 LossAtt 0.0348 TrainAcc 0.5500 TestAcc 0.4957 0.5500
epoch 1200 LossPred 0.9904 LossAtt 0.0236 TrainAcc 0.5500 TestAcc 0.4957 0.5500
epoch 1300 LossPred 0.9902 LossAtt 0.0209 TrainAcc 0.5500 TestAcc 0.4957 0.5500
epoch 1400 LossPred 0.9903 LossAtt 0.0222 TrainAcc 0.5500 TestAcc 0.4957 0.5500
epoch 1500 LossPred 0.9904 LossAtt 0.0141 TrainAcc 0.5500 TestAcc 0.4957 0.5500
epoch 1600 LossPred 0.9903 LossAtt 0.0156 TrainAcc 0.5500 TestAcc 0.4957 0.5500
epoch 1700 LossPred 0.9902 LossAtt 0.0527 TrainAcc 0.5500 TestAcc 0.4957 0.5500
epoch 1800 LossPred 0.9902 LossAtt 0.0084 TrainAcc 0.5500 TestAcc 0.4957 0.5500
epoch 1900 LossPred 0.9902 LossAtt 0.0071 TrainAcc 0.5500 TestAcc 0.4957 0.5500
epoch 2000 LossPred 0.9901 LossAtt 0.0076 TrainAcc 0.5500 TestAcc 0.4957 0.5500
epoch 2100 LossPred 0.9900 LossAtt 0.0083 TrainAcc 0.5500 TestAcc 0.4957 0.5500
epoch 2200 LossPred 0.9900 LossAtt 0.0087 TrainAcc 0.5500 TestAcc 0.4957 0.5500
epoch 2300 LossPred 0.9900 LossAtt 0.0072 TrainAcc 0.5500 TestAcc 0.4957 0.5500
epoch 2400 LossPred 0.9899 LossAtt 0.0062 TrainAcc 0.5500 TestAcc 0.4957 0.5500
epoch 2500 LossPred 0.9899 LossAtt 0.0066 TrainAcc 0.5500 TestAcc 0.4957 0.5500
Optimization Finished!
********** replication  3  **********
epoch   0 LossPred 1.1285 LossAtt 1.0155 TrainAcc 0.3800 TestAcc 0.3999 0.4250
epoch 100 LossPred 0.9834 LossAtt 0.2317 TrainAcc 0.6100 TestAcc 0.6036 0.6100
epoch 200 LossPred 0.9333 LossAtt 0.1871 TrainAcc 0.6100 TestAcc 0.6036 0.6200
epoch 300 LossPred 0.8417 LossAtt 0.2928 TrainAcc 0.6900 TestAcc 0.6271 0.7050
epoch 400 LossPred 0.2991 LossAtt 0.3083 TrainAcc 0.9400 TestAcc 0.9037 0.9150
epoch 500 LossPred 0.1927 LossAtt 0.3255 TrainAcc 0.9400 TestAcc 0.9129 0.9150
epoch 600 LossPred 0.1960 LossAtt 0.3433 TrainAcc 0.9400 TestAcc 0.9044 0.8950
epoch 700 LossPred 0.1560 LossAtt 0.3275 TrainAcc 0.9700 TestAcc 0.9189 0.9250
epoch 800 LossPred 0.1960 LossAtt 0.3206 TrainAcc 0.9300 TestAcc 0.9059 0.9300
epoch 900 LossPred 0.0970 LossAtt 0.3348 TrainAcc 0.9800 TestAcc 0.9229 0.9400
epoch 1000 LossPred 0.2692 LossAtt 0.3532 TrainAcc 0.8900 TestAcc 0.8644 0.8650
epoch 1100 LossPred 0.1588 LossAtt 0.3193 TrainAcc 0.9400 TestAcc 0.9134 0.9500
epoch 1200 LossPred 0.1179 LossAtt 0.3556 TrainAcc 0.9600 TestAcc 0.9292 0.9350
epoch 1300 LossPred 0.0910 LossAtt 0.3067 TrainAcc 0.9700 TestAcc 0.9264 0.9400
epoch 1400 LossPred 0.1562 LossAtt 0.3382 TrainAcc 0.9300 TestAcc 0.9299 0.9550
epoch 1500 LossPred 0.0953 LossAtt 0.3301 TrainAcc 0.9700 TestAcc 0.9129 0.9350
epoch 1600 LossPred 0.1382 LossAtt 0.3482 TrainAcc 0.9600 TestAcc 0.9124 0.9150
epoch 1700 LossPred 0.1364 LossAtt 0.3205 TrainAcc 0.9500 TestAcc 0.9264 0.9450
epoch 1800 LossPred 0.2236 LossAtt 0.3194 TrainAcc 0.9200 TestAcc 0.9132 0.9400
epoch 1900 LossPred 0.1905 LossAtt 0.3238 TrainAcc 0.9300 TestAcc 0.8854 0.9150
epoch 2000 LossPred 0.1723 LossAtt 0.3318 TrainAcc 0.9400 TestAcc 0.8899 0.9200
epoch 2100 LossPred 0.0712 LossAtt 0.3214 TrainAcc 0.9900 TestAcc 0.9402 0.9600
epoch 2200 LossPred 0.0582 LossAtt 0.3070 TrainAcc 0.9800 TestAcc 0.9467 0.9500
epoch 2300 LossPred 0.1895 LossAtt 0.3497 TrainAcc 0.9300 TestAcc 0.8986 0.9000
epoch 2400 LossPred 0.1319 LossAtt 0.3178 TrainAcc 0.9600 TestAcc 0.9272 0.9550
epoch 2500 LossPred 0.1228 LossAtt 0.3350 TrainAcc 0.9600 TestAcc 0.9062 0.9350
Optimization Finished!
********** replication  4  **********
epoch   0 LossPred 1.1347 LossAtt 1.0057 TrainAcc 0.5600 TestAcc 0.4274 0.5550
epoch 100 LossPred 0.9876 LossAtt 0.4421 TrainAcc 0.5900 TestAcc 0.5175 0.5800
epoch 200 LossPred 1.0119 LossAtt 0.1911 TrainAcc 0.5300 TestAcc 0.4084 0.5550
epoch 300 LossPred 0.9882 LossAtt 0.1442 TrainAcc 0.5900 TestAcc 0.5175 0.5900
epoch 400 LossPred 0.9766 LossAtt 0.1385 TrainAcc 0.5900 TestAcc 0.5175 0.5900
epoch 500 LossPred 0.9723 LossAtt 0.1418 TrainAcc 0.5900 TestAcc 0.5175 0.5900
epoch 600 LossPred 0.9705 LossAtt 0.1012 TrainAcc 0.5900 TestAcc 0.5175 0.5900
epoch 700 LossPred 0.9697 LossAtt 0.1085 TrainAcc 0.5900 TestAcc 0.5175 0.5900
epoch 800 LossPred 0.9690 LossAtt 0.0725 TrainAcc 0.5900 TestAcc 0.5175 0.5900
epoch 900 LossPred 0.9686 LossAtt 0.0708 TrainAcc 0.5900 TestAcc 0.5175 0.5900
epoch 1000 LossPred 0.9684 LossAtt 0.1325 TrainAcc 0.5900 TestAcc 0.5175 0.5900
epoch 1100 LossPred 0.9682 LossAtt 0.0682 TrainAcc 0.5900 TestAcc 0.5175 0.5900
epoch 1200 LossPred 0.9682 LossAtt 0.0421 TrainAcc 0.5900 TestAcc 0.5175 0.5900
epoch 1300 LossPred 0.9681 LossAtt 0.0941 TrainAcc 0.5900 TestAcc 0.5175 0.5900
epoch 1400 LossPred 0.9680 LossAtt 0.0472 TrainAcc 0.5900 TestAcc 0.5175 0.5900
epoch 1500 LossPred 0.9680 LossAtt 0.0477 TrainAcc 0.5900 TestAcc 0.5175 0.5900
epoch 1600 LossPred 0.9680 LossAtt 0.0482 TrainAcc 0.5900 TestAcc 0.5175 0.5900
epoch 1700 LossPred 0.9680 LossAtt 0.0595 TrainAcc 0.5900 TestAcc 0.5175 0.5900
epoch 1800 LossPred 0.9679 LossAtt 0.0477 TrainAcc 0.5900 TestAcc 0.5175 0.5900
epoch 1900 LossPred 0.9679 LossAtt 0.0278 TrainAcc 0.5900 TestAcc 0.5175 0.5900
epoch 2000 LossPred 0.9678 LossAtt 0.0317 TrainAcc 0.5900 TestAcc 0.5175 0.5900
epoch 2100 LossPred 0.9678 LossAtt 0.0289 TrainAcc 0.5900 TestAcc 0.5175 0.5900
epoch 2200 LossPred 0.9678 LossAtt 0.0174 TrainAcc 0.5900 TestAcc 0.5175 0.5900
epoch 2300 LossPred 0.9678 LossAtt 0.0197 TrainAcc 0.5900 TestAcc 0.5175 0.5900
epoch 2400 LossPred 0.9678 LossAtt 0.0245 TrainAcc 0.5900 TestAcc 0.5175 0.5900
epoch 2500 LossPred 0.9678 LossAtt 0.0192 TrainAcc 0.5900 TestAcc 0.5175 0.5900
Optimization Finished!
********** replication  5  **********
epoch   0 LossPred 1.1030 LossAtt 1.0056 TrainAcc 0.5300 TestAcc 0.5661 0.5400
epoch 100 LossPred 0.9573 LossAtt 0.4048 TrainAcc 0.5700 TestAcc 0.6094 0.5700
epoch 200 LossPred 0.9118 LossAtt 0.4149 TrainAcc 0.6400 TestAcc 0.6301 0.6550
epoch 300 LossPred 0.3544 LossAtt 0.4677 TrainAcc 0.9300 TestAcc 0.8861 0.8850
epoch 400 LossPred 0.2367 LossAtt 0.4476 TrainAcc 0.9400 TestAcc 0.8996 0.9200
epoch 500 LossPred 0.1685 LossAtt 0.4648 TrainAcc 0.9800 TestAcc 0.9082 0.9450
epoch 600 LossPred 0.1312 LossAtt 0.4762 TrainAcc 0.9800 TestAcc 0.9299 0.9500
epoch 700 LossPred 0.1004 LossAtt 0.4542 TrainAcc 0.9800 TestAcc 0.9204 0.9600
epoch 800 LossPred 0.0904 LossAtt 0.4534 TrainAcc 0.9800 TestAcc 0.9182 0.9550
epoch 900 LossPred 0.0892 LossAtt 0.4622 TrainAcc 0.9800 TestAcc 0.9019 0.9600
epoch 1000 LossPred 0.0721 LossAtt 0.4699 TrainAcc 0.9800 TestAcc 0.9074 0.9650
epoch 1100 LossPred 0.0821 LossAtt 0.4599 TrainAcc 0.9800 TestAcc 0.9144 0.9450
epoch 1200 LossPred 0.0891 LossAtt 0.4219 TrainAcc 0.9700 TestAcc 0.9039 0.9600
epoch 1300 LossPred 0.0912 LossAtt 0.4020 TrainAcc 0.9800 TestAcc 0.8979 0.9700
epoch 1400 LossPred 0.0739 LossAtt 0.4278 TrainAcc 0.9800 TestAcc 0.9087 0.9600
epoch 1500 LossPred 0.0747 LossAtt 0.4203 TrainAcc 0.9800 TestAcc 0.9109 0.9600
epoch 1600 LossPred 0.0653 LossAtt 0.4273 TrainAcc 0.9800 TestAcc 0.9149 0.9600
epoch 1700 LossPred 0.0539 LossAtt 0.4319 TrainAcc 0.9800 TestAcc 0.9184 0.9500
epoch 1800 LossPred 0.0776 LossAtt 0.4354 TrainAcc 0.9800 TestAcc 0.9024 0.9550
epoch 1900 LossPred 0.0506 LossAtt 0.4609 TrainAcc 0.9800 TestAcc 0.9172 0.9550
epoch 2000 LossPred 0.0465 LossAtt 0.4280 TrainAcc 0.9900 TestAcc 0.9192 0.9650
epoch 2100 LossPred 0.0788 LossAtt 0.4096 TrainAcc 0.9700 TestAcc 0.9117 0.9400
epoch 2200 LossPred 0.0511 LossAtt 0.4168 TrainAcc 0.9900 TestAcc 0.9209 0.9550
epoch 2300 LossPred 0.0439 LossAtt 0.4310 TrainAcc 0.9900 TestAcc 0.9217 0.9600
epoch 2400 LossPred 0.0429 LossAtt 0.4265 TrainAcc 0.9900 TestAcc 0.9262 0.9700
epoch 2500 LossPred 0.0623 LossAtt 0.4172 TrainAcc 0.9700 TestAcc 0.9127 0.9550
Optimization Finished!
********** replication  6  **********
epoch   0 LossPred 0.9754 LossAtt 1.0126 TrainAcc 0.5300 TestAcc 0.4657 0.5300
epoch 100 LossPred 0.9052 LossAtt 0.4700 TrainAcc 0.6300 TestAcc 0.5796 0.6050
epoch 200 LossPred 0.8046 LossAtt 0.4617 TrainAcc 0.7000 TestAcc 0.6329 0.7100
epoch 300 LossPred 0.3214 LossAtt 0.4802 TrainAcc 0.9200 TestAcc 0.9007 0.8600
epoch 400 LossPred 0.2547 LossAtt 0.4771 TrainAcc 0.9300 TestAcc 0.9287 0.8400
epoch 500 LossPred 0.2620 LossAtt 0.4820 TrainAcc 0.8900 TestAcc 0.9022 0.8500
epoch 600 LossPred 0.4099 LossAtt 0.4602 TrainAcc 0.8500 TestAcc 0.8881 0.8650
epoch 700 LossPred 0.5516 LossAtt 0.4104 TrainAcc 0.8300 TestAcc 0.7893 0.8050
epoch 800 LossPred 0.3239 LossAtt 0.3778 TrainAcc 0.9100 TestAcc 0.9097 0.9050
epoch 900 LossPred 0.4540 LossAtt 0.3660 TrainAcc 0.8500 TestAcc 0.8676 0.8300
epoch 1000 LossPred 0.3475 LossAtt 0.3719 TrainAcc 0.8900 TestAcc 0.8448 0.8900
epoch 1100 LossPred 0.4391 LossAtt 0.3603 TrainAcc 0.8500 TestAcc 0.8088 0.8500
epoch 1200 LossPred 0.2980 LossAtt 0.3763 TrainAcc 0.9200 TestAcc 0.8991 0.9050
epoch 1300 LossPred 0.3142 LossAtt 0.3989 TrainAcc 0.8800 TestAcc 0.9112 0.8450
epoch 1400 LossPred 0.2886 LossAtt 0.4109 TrainAcc 0.9100 TestAcc 0.8796 0.9100
epoch 1500 LossPred 0.2662 LossAtt 0.3936 TrainAcc 0.9200 TestAcc 0.9009 0.9100
epoch 1600 LossPred 0.2223 LossAtt 0.3949 TrainAcc 0.9200 TestAcc 0.9292 0.8750
epoch 1700 LossPred 0.2200 LossAtt 0.3867 TrainAcc 0.9400 TestAcc 0.9442 0.8950
epoch 1800 LossPred 0.2001 LossAtt 0.3924 TrainAcc 0.9400 TestAcc 0.9585 0.9200
epoch 1900 LossPred 0.2661 LossAtt 0.3821 TrainAcc 0.8800 TestAcc 0.9074 0.8600
epoch 2000 LossPred 0.2463 LossAtt 0.4036 TrainAcc 0.9000 TestAcc 0.9102 0.8650
epoch 2100 LossPred 0.1858 LossAtt 0.4112 TrainAcc 0.9300 TestAcc 0.9349 0.9050
epoch 2200 LossPred 0.1631 LossAtt 0.4144 TrainAcc 0.9700 TestAcc 0.9667 0.9250
epoch 2300 LossPred 0.1583 LossAtt 0.3946 TrainAcc 0.9600 TestAcc 0.9580 0.9100
epoch 2400 LossPred 0.1834 LossAtt 0.4125 TrainAcc 0.9400 TestAcc 0.9267 0.9250
epoch 2500 LossPred 0.1425 LossAtt 0.4066 TrainAcc 0.9600 TestAcc 0.9607 0.9150
Optimization Finished!
********** replication  7  **********
epoch   0 LossPred 0.9747 LossAtt 1.0082 TrainAcc 0.6300 TestAcc 0.5831 0.5850
epoch 100 LossPred 0.8382 LossAtt 0.4599 TrainAcc 0.6700 TestAcc 0.6114 0.6650
epoch 200 LossPred 0.5843 LossAtt 0.3911 TrainAcc 0.7900 TestAcc 0.6882 0.7850
epoch 300 LossPred 0.3243 LossAtt 0.3910 TrainAcc 0.9200 TestAcc 0.8253 0.9200
epoch 400 LossPred 0.3061 LossAtt 0.2976 TrainAcc 0.9100 TestAcc 0.8458 0.9250
epoch 500 LossPred 0.2709 LossAtt 0.3097 TrainAcc 0.9200 TestAcc 0.8443 0.9250
epoch 600 LossPred 0.2768 LossAtt 0.3028 TrainAcc 0.9100 TestAcc 0.8651 0.9150
epoch 700 LossPred 0.3583 LossAtt 0.2774 TrainAcc 0.9000 TestAcc 0.8331 0.8900
epoch 800 LossPred 0.7900 LossAtt 0.2457 TrainAcc 0.7300 TestAcc 0.7077 0.7500
epoch 900 LossPred 0.4898 LossAtt 0.2706 TrainAcc 0.8500 TestAcc 0.7848 0.8200
epoch 1000 LossPred 0.2940 LossAtt 0.2476 TrainAcc 0.9100 TestAcc 0.8296 0.9300
epoch 1100 LossPred 0.2642 LossAtt 0.2609 TrainAcc 0.9200 TestAcc 0.8366 0.9200
epoch 1200 LossPred 0.2913 LossAtt 0.2589 TrainAcc 0.9000 TestAcc 0.8506 0.9200
epoch 1300 LossPred 0.2737 LossAtt 0.2638 TrainAcc 0.9200 TestAcc 0.8346 0.9200
epoch 1400 LossPred 0.3098 LossAtt 0.2602 TrainAcc 0.9100 TestAcc 0.8386 0.9150
epoch 1500 LossPred 0.3538 LossAtt 0.2658 TrainAcc 0.8700 TestAcc 0.8436 0.9000
epoch 1600 LossPred 0.4234 LossAtt 0.2488 TrainAcc 0.8600 TestAcc 0.8141 0.8500
epoch 1700 LossPred 0.3930 LossAtt 0.2705 TrainAcc 0.8700 TestAcc 0.8661 0.8900
epoch 1800 LossPred 0.2620 LossAtt 0.2703 TrainAcc 0.9200 TestAcc 0.8363 0.9250
epoch 1900 LossPred 0.3089 LossAtt 0.2900 TrainAcc 0.9000 TestAcc 0.8276 0.9250
epoch 2000 LossPred 0.2596 LossAtt 0.2695 TrainAcc 0.9200 TestAcc 0.8288 0.9250
epoch 2100 LossPred 0.2634 LossAtt 0.2644 TrainAcc 0.9300 TestAcc 0.8398 0.9250
epoch 2200 LossPred 0.2930 LossAtt 0.2640 TrainAcc 0.9100 TestAcc 0.8301 0.9050
epoch 2300 LossPred 0.4015 LossAtt 0.2393 TrainAcc 0.8700 TestAcc 0.8076 0.8600
epoch 2400 LossPred 0.2854 LossAtt 0.2736 TrainAcc 0.9100 TestAcc 0.8263 0.9150
epoch 2500 LossPred 0.3453 LossAtt 0.2729 TrainAcc 0.8800 TestAcc 0.8333 0.9000
Optimization Finished!
********** replication  8  **********
epoch   0 LossPred 1.0838 LossAtt 1.0241 TrainAcc 0.5700 TestAcc 0.5048 0.5700
epoch 100 LossPred 0.9481 LossAtt 0.4223 TrainAcc 0.5700 TestAcc 0.5048 0.5700
epoch 200 LossPred 0.9043 LossAtt 0.3993 TrainAcc 0.6400 TestAcc 0.6026 0.6450
epoch 300 LossPred 0.7886 LossAtt 0.4313 TrainAcc 0.7100 TestAcc 0.6759 0.7100
epoch 400 LossPred 0.4145 LossAtt 0.3904 TrainAcc 0.8600 TestAcc 0.8779 0.8500
epoch 500 LossPred 0.3483 LossAtt 0.3592 TrainAcc 0.8800 TestAcc 0.8991 0.8850
epoch 600 LossPred 0.3083 LossAtt 0.3517 TrainAcc 0.8900 TestAcc 0.9109 0.8750
epoch 700 LossPred 0.4262 LossAtt 0.3252 TrainAcc 0.8300 TestAcc 0.8626 0.8500
epoch 800 LossPred 0.4451 LossAtt 0.3327 TrainAcc 0.8300 TestAcc 0.8423 0.8400
epoch 900 LossPred 0.3957 LossAtt 0.3452 TrainAcc 0.8600 TestAcc 0.8764 0.8550
epoch 1000 LossPred 0.2853 LossAtt 0.3451 TrainAcc 0.9200 TestAcc 0.9094 0.8950
epoch 1100 LossPred 0.5182 LossAtt 0.3432 TrainAcc 0.8200 TestAcc 0.7968 0.8200
epoch 1200 LossPred 0.4245 LossAtt 0.3582 TrainAcc 0.8400 TestAcc 0.8481 0.8400
epoch 1300 LossPred 0.3649 LossAtt 0.3633 TrainAcc 0.8500 TestAcc 0.8701 0.8600
epoch 1400 LossPred 0.2684 LossAtt 0.3521 TrainAcc 0.9000 TestAcc 0.9094 0.8800
epoch 1500 LossPred 0.3910 LossAtt 0.3367 TrainAcc 0.8600 TestAcc 0.8589 0.8500
epoch 1600 LossPred 0.2833 LossAtt 0.3477 TrainAcc 0.8800 TestAcc 0.8969 0.8950
epoch 1700 LossPred 0.2413 LossAtt 0.3309 TrainAcc 0.9200 TestAcc 0.9167 0.9200
epoch 1800 LossPred 0.2323 LossAtt 0.3436 TrainAcc 0.9200 TestAcc 0.9182 0.9300
epoch 1900 LossPred 0.4182 LossAtt 0.3327 TrainAcc 0.8600 TestAcc 0.8501 0.8550
epoch 2000 LossPred 0.2581 LossAtt 0.3186 TrainAcc 0.9100 TestAcc 0.9092 0.9100
epoch 2100 LossPred 0.2517 LossAtt 0.3322 TrainAcc 0.9300 TestAcc 0.9119 0.9250
epoch 2200 LossPred 0.2557 LossAtt 0.3243 TrainAcc 0.9200 TestAcc 0.9134 0.9200
epoch 2300 LossPred 0.4377 LossAtt 0.3352 TrainAcc 0.8400 TestAcc 0.8626 0.8150
epoch 2400 LossPred 0.2969 LossAtt 0.3156 TrainAcc 0.8700 TestAcc 0.8936 0.8900
epoch 2500 LossPred 0.3458 LossAtt 0.3107 TrainAcc 0.8700 TestAcc 0.8791 0.8700
Optimization Finished!
********** replication  9  **********
epoch   0 LossPred 1.0379 LossAtt 1.0027 TrainAcc 0.5100 TestAcc 0.5556 0.5000
epoch 100 LossPred 0.9640 LossAtt 0.3248 TrainAcc 0.5900 TestAcc 0.5938 0.5900
epoch 200 LossPred 0.9620 LossAtt 0.2151 TrainAcc 0.5900 TestAcc 0.5938 0.5900
epoch 300 LossPred 0.9581 LossAtt 0.2358 TrainAcc 0.5900 TestAcc 0.5938 0.5900
epoch 400 LossPred 0.5829 LossAtt 0.4440 TrainAcc 0.8200 TestAcc 0.7613 0.8250
epoch 500 LossPred 0.4458 LossAtt 0.3983 TrainAcc 0.8400 TestAcc 0.8841 0.8400
epoch 600 LossPred 0.3917 LossAtt 0.4339 TrainAcc 0.8700 TestAcc 0.8781 0.8800
epoch 700 LossPred 0.3470 LossAtt 0.4391 TrainAcc 0.8900 TestAcc 0.9062 0.8700
epoch 800 LossPred 0.3514 LossAtt 0.4632 TrainAcc 0.9000 TestAcc 0.8576 0.8700
epoch 900 LossPred 0.3966 LossAtt 0.4754 TrainAcc 0.8900 TestAcc 0.8624 0.8650
epoch 1000 LossPred 0.2524 LossAtt 0.4837 TrainAcc 0.9300 TestAcc 0.8816 0.9350
epoch 1100 LossPred 1.0207 LossAtt 0.4587 TrainAcc 0.6600 TestAcc 0.6669 0.6900
epoch 1200 LossPred 0.6421 LossAtt 0.4223 TrainAcc 0.7800 TestAcc 0.8101 0.7900
epoch 1300 LossPred 0.8213 LossAtt 0.4296 TrainAcc 0.7200 TestAcc 0.7505 0.7300
epoch 1400 LossPred 0.4880 LossAtt 0.4104 TrainAcc 0.8300 TestAcc 0.8476 0.8350
epoch 1500 LossPred 0.6719 LossAtt 0.4134 TrainAcc 0.7600 TestAcc 0.8016 0.7700
epoch 1600 LossPred 0.4158 LossAtt 0.4467 TrainAcc 0.8600 TestAcc 0.8584 0.8600
epoch 1700 LossPred 0.4778 LossAtt 0.4243 TrainAcc 0.8300 TestAcc 0.8396 0.8450
epoch 1800 LossPred 0.6384 LossAtt 0.4165 TrainAcc 0.7700 TestAcc 0.7613 0.7600
epoch 1900 LossPred 0.3639 LossAtt 0.4241 TrainAcc 0.8800 TestAcc 0.8619 0.8950
epoch 2000 LossPred 0.5711 LossAtt 0.4583 TrainAcc 0.8000 TestAcc 0.7913 0.7950
epoch 2100 LossPred 0.4125 LossAtt 0.4542 TrainAcc 0.8700 TestAcc 0.8423 0.8650
epoch 2200 LossPred 0.2161 LossAtt 0.4773 TrainAcc 0.9400 TestAcc 0.8771 0.9250
epoch 2300 LossPred 0.1615 LossAtt 0.4669 TrainAcc 0.9800 TestAcc 0.8609 0.9700
epoch 2400 LossPred 0.1454 LossAtt 0.4776 TrainAcc 0.9700 TestAcc 0.8601 0.9700
epoch 2500 LossPred 0.1634 LossAtt 0.4614 TrainAcc 0.9600 TestAcc 0.8784 0.9650
Optimization Finished!
********** replication  10  **********
epoch   0 LossPred 0.8321 LossAtt 1.0476 TrainAcc 0.7000 TestAcc 0.6069 0.6950
epoch 100 LossPred 0.7294 LossAtt 0.5033 TrainAcc 0.7200 TestAcc 0.6479 0.7200
epoch 200 LossPred 0.3567 LossAtt 0.5957 TrainAcc 0.9200 TestAcc 0.8303 0.9100
epoch 300 LossPred 0.6184 LossAtt 0.5822 TrainAcc 0.7600 TestAcc 0.6769 0.7900
epoch 400 LossPred 0.5716 LossAtt 0.5257 TrainAcc 0.8000 TestAcc 0.7195 0.8100
epoch 500 LossPred 0.5042 LossAtt 0.5157 TrainAcc 0.8200 TestAcc 0.7400 0.8300
epoch 600 LossPred 0.3104 LossAtt 0.5238 TrainAcc 0.9100 TestAcc 0.8216 0.9000
epoch 700 LossPred 0.1929 LossAtt 0.5068 TrainAcc 0.9500 TestAcc 0.8844 0.9400
epoch 800 LossPred 0.1568 LossAtt 0.4911 TrainAcc 0.9600 TestAcc 0.8911 0.9350
epoch 900 LossPred 0.1771 LossAtt 0.4868 TrainAcc 0.9400 TestAcc 0.8794 0.9300
epoch 1000 LossPred 0.1477 LossAtt 0.4911 TrainAcc 0.9500 TestAcc 0.9079 0.9600
epoch 1100 LossPred 0.1696 LossAtt 0.4794 TrainAcc 0.9600 TestAcc 0.9122 0.9500
epoch 1200 LossPred 0.1375 LossAtt 0.4969 TrainAcc 0.9600 TestAcc 0.9004 0.9550
epoch 1300 LossPred 0.1457 LossAtt 0.4639 TrainAcc 0.9600 TestAcc 0.8934 0.9400
epoch 1400 LossPred 0.1450 LossAtt 0.4671 TrainAcc 0.9600 TestAcc 0.9102 0.9600
epoch 1500 LossPred 0.1677 LossAtt 0.4589 TrainAcc 0.9700 TestAcc 0.9247 0.9500
epoch 1600 LossPred 0.3090 LossAtt 0.4462 TrainAcc 0.8700 TestAcc 0.8306 0.8800
epoch 1700 LossPred 0.1593 LossAtt 0.4755 TrainAcc 0.9500 TestAcc 0.9089 0.9600
epoch 1800 LossPred 0.1483 LossAtt 0.4637 TrainAcc 0.9600 TestAcc 0.8979 0.9400
epoch 1900 LossPred 0.1429 LossAtt 0.4625 TrainAcc 0.9700 TestAcc 0.9169 0.9450
epoch 2000 LossPred 0.2494 LossAtt 0.4699 TrainAcc 0.9100 TestAcc 0.8609 0.9050
epoch 2100 LossPred 0.1397 LossAtt 0.4550 TrainAcc 0.9600 TestAcc 0.9147 0.9550
epoch 2200 LossPred 0.2404 LossAtt 0.4631 TrainAcc 0.9100 TestAcc 0.9077 0.9250
epoch 2300 LossPred 0.1388 LossAtt 0.4505 TrainAcc 0.9700 TestAcc 0.9234 0.9400
epoch 2400 LossPred 0.1673 LossAtt 0.4468 TrainAcc 0.9500 TestAcc 0.9222 0.9550
epoch 2500 LossPred 0.1478 LossAtt 0.4497 TrainAcc 0.9500 TestAcc 0.9154 0.9500
Optimization Finished!
********** replication  11  **********
epoch   0 LossPred 1.4150 LossAtt 1.0070 TrainAcc 0.4400 TestAcc 0.5073 0.4500
epoch 100 LossPred 0.9078 LossAtt 0.5051 TrainAcc 0.5600 TestAcc 0.5130 0.6200
epoch 200 LossPred 0.7479 LossAtt 0.3793 TrainAcc 0.7600 TestAcc 0.6081 0.7600
epoch 300 LossPred 0.7262 LossAtt 0.4167 TrainAcc 0.7600 TestAcc 0.6081 0.7600
epoch 400 LossPred 0.7342 LossAtt 0.4007 TrainAcc 0.7600 TestAcc 0.6081 0.7600
epoch 500 LossPred 0.7240 LossAtt 0.4158 TrainAcc 0.7600 TestAcc 0.6081 0.7600
epoch 600 LossPred 0.6903 LossAtt 0.4385 TrainAcc 0.7700 TestAcc 0.6266 0.7600
epoch 700 LossPred 0.3599 LossAtt 0.5569 TrainAcc 0.9100 TestAcc 0.8774 0.9250
epoch 800 LossPred 0.2697 LossAtt 0.5074 TrainAcc 0.9300 TestAcc 0.8659 0.9100
epoch 900 LossPred 0.2616 LossAtt 0.4806 TrainAcc 0.9300 TestAcc 0.8509 0.9000
epoch 1000 LossPred 0.1866 LossAtt 0.4614 TrainAcc 0.9600 TestAcc 0.8771 0.9250
epoch 1100 LossPred 0.1640 LossAtt 0.4428 TrainAcc 0.9600 TestAcc 0.8839 0.9250
epoch 1200 LossPred 0.1597 LossAtt 0.4209 TrainAcc 0.9500 TestAcc 0.8831 0.9250
epoch 1300 LossPred 0.1519 LossAtt 0.4147 TrainAcc 0.9600 TestAcc 0.8856 0.9300
epoch 1400 LossPred 0.1432 LossAtt 0.4250 TrainAcc 0.9700 TestAcc 0.8859 0.9350
epoch 1500 LossPred 0.1470 LossAtt 0.4058 TrainAcc 0.9600 TestAcc 0.8824 0.9250
epoch 1600 LossPred 0.1424 LossAtt 0.3939 TrainAcc 0.9700 TestAcc 0.8849 0.9400
epoch 1700 LossPred 0.1415 LossAtt 0.4436 TrainAcc 0.9700 TestAcc 0.8769 0.9300
epoch 1800 LossPred 0.7037 LossAtt 0.4334 TrainAcc 0.7900 TestAcc 0.7022 0.7700
epoch 1900 LossPred 0.2112 LossAtt 0.4416 TrainAcc 0.9400 TestAcc 0.8426 0.9200
epoch 2000 LossPred 0.1460 LossAtt 0.4119 TrainAcc 0.9700 TestAcc 0.8816 0.9400
epoch 2100 LossPred 0.1359 LossAtt 0.4512 TrainAcc 0.9700 TestAcc 0.8701 0.9350
epoch 2200 LossPred 0.1369 LossAtt 0.4218 TrainAcc 0.9700 TestAcc 0.8736 0.9550
epoch 2300 LossPred 0.1431 LossAtt 0.4180 TrainAcc 0.9700 TestAcc 0.8756 0.9350
epoch 2400 LossPred 0.2213 LossAtt 0.4164 TrainAcc 0.9300 TestAcc 0.8353 0.9100
epoch 2500 LossPred 0.1336 LossAtt 0.4056 TrainAcc 0.9700 TestAcc 0.8491 0.9400
Optimization Finished!
********** replication  12  **********
epoch   0 LossPred 1.0763 LossAtt 1.0112 TrainAcc 0.6400 TestAcc 0.5495 0.6150
epoch 100 LossPred 0.9212 LossAtt 0.5349 TrainAcc 0.6500 TestAcc 0.5538 0.6350
epoch 200 LossPred 0.9022 LossAtt 0.5431 TrainAcc 0.6500 TestAcc 0.5641 0.6300
epoch 300 LossPred 0.8853 LossAtt 0.5943 TrainAcc 0.6300 TestAcc 0.5618 0.6250
epoch 400 LossPred 0.8660 LossAtt 0.5587 TrainAcc 0.6500 TestAcc 0.5631 0.6150
epoch 500 LossPred 0.8531 LossAtt 0.5579 TrainAcc 0.6800 TestAcc 0.5618 0.6400
epoch 600 LossPred 0.8420 LossAtt 0.5482 TrainAcc 0.6900 TestAcc 0.5553 0.6350
epoch 700 LossPred 0.8227 LossAtt 0.5564 TrainAcc 0.6900 TestAcc 0.5548 0.6450
epoch 800 LossPred 0.7765 LossAtt 0.5656 TrainAcc 0.7300 TestAcc 0.5601 0.6600
epoch 900 LossPred 0.6833 LossAtt 0.5876 TrainAcc 0.7400 TestAcc 0.5931 0.7000
epoch 1000 LossPred 0.6182 LossAtt 0.5763 TrainAcc 0.7900 TestAcc 0.6081 0.7100
epoch 1100 LossPred 0.5940 LossAtt 0.5580 TrainAcc 0.8000 TestAcc 0.6141 0.6900
epoch 1200 LossPred 0.5998 LossAtt 0.5533 TrainAcc 0.7900 TestAcc 0.6119 0.7050
epoch 1300 LossPred 0.5482 LossAtt 0.5448 TrainAcc 0.8000 TestAcc 0.6204 0.7300
epoch 1400 LossPred 0.5369 LossAtt 0.5492 TrainAcc 0.8000 TestAcc 0.6189 0.7150
epoch 1500 LossPred 0.5274 LossAtt 0.5561 TrainAcc 0.8100 TestAcc 0.6204 0.7250
epoch 1600 LossPred 0.5232 LossAtt 0.5192 TrainAcc 0.8000 TestAcc 0.6229 0.7300
epoch 1700 LossPred 0.5137 LossAtt 0.5104 TrainAcc 0.8100 TestAcc 0.6266 0.7100
epoch 1800 LossPred 0.5147 LossAtt 0.5047 TrainAcc 0.8100 TestAcc 0.6216 0.7100
epoch 1900 LossPred 0.5060 LossAtt 0.5194 TrainAcc 0.8000 TestAcc 0.6264 0.7400
epoch 2000 LossPred 0.5395 LossAtt 0.5047 TrainAcc 0.8100 TestAcc 0.6259 0.7150
epoch 2100 LossPred 0.5043 LossAtt 0.4912 TrainAcc 0.8100 TestAcc 0.6281 0.7100
epoch 2200 LossPred 0.5045 LossAtt 0.4981 TrainAcc 0.8000 TestAcc 0.6221 0.7250
epoch 2300 LossPred 0.5101 LossAtt 0.5002 TrainAcc 0.8100 TestAcc 0.6226 0.7400
epoch 2400 LossPred 0.5130 LossAtt 0.4955 TrainAcc 0.8100 TestAcc 0.6224 0.7350
epoch 2500 LossPred 0.5057 LossAtt 0.4929 TrainAcc 0.8200 TestAcc 0.6271 0.7550
Optimization Finished!
********** replication  13  **********
epoch   0 LossPred 1.0544 LossAtt 1.0282 TrainAcc 0.5100 TestAcc 0.5621 0.5050
epoch 100 LossPred 0.9130 LossAtt 0.4188 TrainAcc 0.5700 TestAcc 0.5871 0.5550
epoch 200 LossPred 0.9071 LossAtt 0.3873 TrainAcc 0.5700 TestAcc 0.5868 0.5700
epoch 300 LossPred 0.9021 LossAtt 0.3978 TrainAcc 0.6100 TestAcc 0.5571 0.5800
epoch 400 LossPred 0.8946 LossAtt 0.4208 TrainAcc 0.6100 TestAcc 0.5063 0.5950
epoch 500 LossPred 0.8927 LossAtt 0.4130 TrainAcc 0.6000 TestAcc 0.5185 0.6100
epoch 600 LossPred 0.6981 LossAtt 0.5288 TrainAcc 0.7700 TestAcc 0.7573 0.7600
epoch 700 LossPred 0.3548 LossAtt 0.4706 TrainAcc 0.8700 TestAcc 0.8126 0.8550
epoch 800 LossPred 0.3078 LossAtt 0.4277 TrainAcc 0.8900 TestAcc 0.8428 0.8900
epoch 900 LossPred 0.2906 LossAtt 0.4267 TrainAcc 0.8900 TestAcc 0.8438 0.9000
epoch 1000 LossPred 0.2992 LossAtt 0.4281 TrainAcc 0.9100 TestAcc 0.8664 0.8950
epoch 1100 LossPred 0.2892 LossAtt 0.4509 TrainAcc 0.9100 TestAcc 0.8601 0.8850
epoch 1200 LossPred 0.2623 LossAtt 0.4515 TrainAcc 0.9100 TestAcc 0.8651 0.8950
epoch 1300 LossPred 0.2152 LossAtt 0.4859 TrainAcc 0.9200 TestAcc 0.8721 0.9150
epoch 1400 LossPred 0.1952 LossAtt 0.5026 TrainAcc 0.9400 TestAcc 0.8751 0.9200
epoch 1500 LossPred 0.1718 LossAtt 0.5300 TrainAcc 0.9300 TestAcc 0.8729 0.9400
epoch 1600 LossPred 0.1561 LossAtt 0.5095 TrainAcc 0.9300 TestAcc 0.8651 0.9450
epoch 1700 LossPred 0.1636 LossAtt 0.5090 TrainAcc 0.9500 TestAcc 0.8786 0.9500
epoch 1800 LossPred 0.1556 LossAtt 0.4731 TrainAcc 0.9500 TestAcc 0.8721 0.9450
epoch 1900 LossPred 0.1471 LossAtt 0.5056 TrainAcc 0.9400 TestAcc 0.8671 0.9500
epoch 2000 LossPred 0.1738 LossAtt 0.5154 TrainAcc 0.9300 TestAcc 0.8696 0.9150
epoch 2100 LossPred 0.1636 LossAtt 0.4740 TrainAcc 0.9500 TestAcc 0.8666 0.9350
epoch 2200 LossPred 0.1778 LossAtt 0.4873 TrainAcc 0.9400 TestAcc 0.8786 0.9400
epoch 2300 LossPred 0.1647 LossAtt 0.5043 TrainAcc 0.9500 TestAcc 0.8609 0.9400
epoch 2400 LossPred 0.1416 LossAtt 0.4806 TrainAcc 0.9500 TestAcc 0.8754 0.9400
epoch 2500 LossPred 0.1383 LossAtt 0.4615 TrainAcc 0.9400 TestAcc 0.8781 0.9400
Optimization Finished!
********** replication  14  **********
epoch   0 LossPred 1.0782 LossAtt 1.0267 TrainAcc 0.5500 TestAcc 0.5193 0.5400
epoch 100 LossPred 0.9206 LossAtt 0.4167 TrainAcc 0.6300 TestAcc 0.5991 0.6200
epoch 200 LossPred 0.9138 LossAtt 0.3218 TrainAcc 0.6300 TestAcc 0.5991 0.6350
epoch 300 LossPred 0.9132 LossAtt 0.2965 TrainAcc 0.6300 TestAcc 0.5991 0.6300
epoch 400 LossPred 0.9116 LossAtt 0.3126 TrainAcc 0.6300 TestAcc 0.5991 0.6300
epoch 500 LossPred 0.9056 LossAtt 0.3353 TrainAcc 0.6300 TestAcc 0.5991 0.6300
epoch 600 LossPred 0.8786 LossAtt 0.3575 TrainAcc 0.6500 TestAcc 0.6354 0.6400
epoch 700 LossPred 0.5849 LossAtt 0.5033 TrainAcc 0.8200 TestAcc 0.8128 0.8200
epoch 800 LossPred 0.3322 LossAtt 0.4430 TrainAcc 0.8300 TestAcc 0.8659 0.8650
epoch 900 LossPred 0.2075 LossAtt 0.4318 TrainAcc 0.9500 TestAcc 0.9222 0.9050
epoch 1000 LossPred 0.1945 LossAtt 0.4049 TrainAcc 0.9200 TestAcc 0.9269 0.8850
epoch 1100 LossPred 0.2117 LossAtt 0.3803 TrainAcc 0.9500 TestAcc 0.9494 0.9000
epoch 1200 LossPred 0.1760 LossAtt 0.3462 TrainAcc 0.9400 TestAcc 0.9322 0.9200
epoch 1300 LossPred 0.2139 LossAtt 0.3661 TrainAcc 0.9300 TestAcc 0.9174 0.9050
epoch 1400 LossPred 0.1560 LossAtt 0.3383 TrainAcc 0.9600 TestAcc 0.9374 0.9250
epoch 1500 LossPred 0.1742 LossAtt 0.3514 TrainAcc 0.9200 TestAcc 0.9199 0.9150
epoch 1600 LossPred 0.1506 LossAtt 0.3536 TrainAcc 0.9600 TestAcc 0.9407 0.9250
epoch 1700 LossPred 0.1833 LossAtt 0.3483 TrainAcc 0.9300 TestAcc 0.9109 0.9050
epoch 1800 LossPred 0.1951 LossAtt 0.3569 TrainAcc 0.9300 TestAcc 0.8941 0.9100
epoch 1900 LossPred 0.2720 LossAtt 0.3827 TrainAcc 0.9000 TestAcc 0.9067 0.8800
epoch 2000 LossPred 0.1413 LossAtt 0.3699 TrainAcc 0.9800 TestAcc 0.9417 0.9050
epoch 2100 LossPred 0.1849 LossAtt 0.3491 TrainAcc 0.9300 TestAcc 0.8904 0.8950
epoch 2200 LossPred 0.1598 LossAtt 0.3470 TrainAcc 0.9600 TestAcc 0.9317 0.8900
epoch 2300 LossPred 0.1398 LossAtt 0.3464 TrainAcc 0.9700 TestAcc 0.9224 0.9100
epoch 2400 LossPred 0.1321 LossAtt 0.3739 TrainAcc 0.9800 TestAcc 0.9169 0.9050
epoch 2500 LossPred 0.1958 LossAtt 0.3651 TrainAcc 0.9300 TestAcc 0.9082 0.8950
Optimization Finished!
********** replication  15  **********
epoch   0 LossPred 0.9870 LossAtt 1.0494 TrainAcc 0.5400 TestAcc 0.5738 0.5650
epoch 100 LossPred 0.9056 LossAtt 0.4279 TrainAcc 0.6100 TestAcc 0.6066 0.6200
epoch 200 LossPred 0.7401 LossAtt 0.4470 TrainAcc 0.7600 TestAcc 0.6724 0.7500
epoch 300 LossPred 0.3543 LossAtt 0.4166 TrainAcc 0.8700 TestAcc 0.8951 0.8550
epoch 400 LossPred 0.3277 LossAtt 0.4065 TrainAcc 0.8800 TestAcc 0.8519 0.8900
epoch 500 LossPred 0.1687 LossAtt 0.3704 TrainAcc 0.9600 TestAcc 0.9314 0.9300
epoch 600 LossPred 0.1373 LossAtt 0.3998 TrainAcc 0.9700 TestAcc 0.9457 0.9450
epoch 700 LossPred 0.1327 LossAtt 0.3986 TrainAcc 0.9700 TestAcc 0.9525 0.9250
epoch 800 LossPred 0.1175 LossAtt 0.4000 TrainAcc 0.9700 TestAcc 0.9510 0.9450
epoch 900 LossPred 0.1220 LossAtt 0.3859 TrainAcc 0.9700 TestAcc 0.9577 0.9350
epoch 1000 LossPred 0.1180 LossAtt 0.4007 TrainAcc 0.9700 TestAcc 0.9600 0.9300
epoch 1100 LossPred 0.1034 LossAtt 0.3996 TrainAcc 0.9800 TestAcc 0.9612 0.9550
epoch 1200 LossPred 0.0973 LossAtt 0.3970 TrainAcc 0.9800 TestAcc 0.9597 0.9550
epoch 1300 LossPred 0.1004 LossAtt 0.3793 TrainAcc 0.9700 TestAcc 0.9552 0.9500
epoch 1400 LossPred 0.1103 LossAtt 0.4054 TrainAcc 0.9800 TestAcc 0.9605 0.9150
epoch 1500 LossPred 0.0943 LossAtt 0.4071 TrainAcc 0.9800 TestAcc 0.9665 0.9400
epoch 1600 LossPred 0.0875 LossAtt 0.3800 TrainAcc 0.9800 TestAcc 0.9650 0.9600
epoch 1700 LossPred 0.0895 LossAtt 0.3872 TrainAcc 0.9800 TestAcc 0.9637 0.9250
epoch 1800 LossPred 0.0827 LossAtt 0.3928 TrainAcc 0.9800 TestAcc 0.9550 0.9500
epoch 1900 LossPred 0.0771 LossAtt 0.3768 TrainAcc 0.9800 TestAcc 0.9585 0.9500
epoch 2000 LossPred 0.0729 LossAtt 0.3721 TrainAcc 0.9800 TestAcc 0.9597 0.9500
epoch 2100 LossPred 0.0738 LossAtt 0.3743 TrainAcc 0.9800 TestAcc 0.9577 0.9550
epoch 2200 LossPred 0.0729 LossAtt 0.3809 TrainAcc 0.9800 TestAcc 0.9605 0.9350
epoch 2300 LossPred 0.0704 LossAtt 0.3779 TrainAcc 0.9800 TestAcc 0.9565 0.9600
epoch 2400 LossPred 0.1274 LossAtt 0.3766 TrainAcc 0.9800 TestAcc 0.9645 0.9150
epoch 2500 LossPred 0.3674 LossAtt 0.3872 TrainAcc 0.8400 TestAcc 0.8836 0.8600
Optimization Finished!
********** replication  16  **********
epoch   0 LossPred 1.0214 LossAtt 1.0033 TrainAcc 0.5700 TestAcc 0.5400 0.5650
epoch 100 LossPred 0.9221 LossAtt 0.4495 TrainAcc 0.6000 TestAcc 0.6031 0.5950
epoch 200 LossPred 0.9202 LossAtt 0.2783 TrainAcc 0.6100 TestAcc 0.5993 0.6100
epoch 300 LossPred 0.9009 LossAtt 0.3538 TrainAcc 0.5700 TestAcc 0.6021 0.5750
epoch 400 LossPred 0.8809 LossAtt 0.3293 TrainAcc 0.6300 TestAcc 0.6401 0.6200
epoch 500 LossPred 0.8778 LossAtt 0.3009 TrainAcc 0.6400 TestAcc 0.6116 0.6500
epoch 600 LossPred 0.8771 LossAtt 0.2701 TrainAcc 0.6500 TestAcc 0.6444 0.6350
epoch 700 LossPred 0.8776 LossAtt 0.2366 TrainAcc 0.6300 TestAcc 0.6401 0.6300
epoch 800 LossPred 0.8794 LossAtt 0.1920 TrainAcc 0.6300 TestAcc 0.6401 0.6350
epoch 900 LossPred 0.8867 LossAtt 0.1524 TrainAcc 0.6300 TestAcc 0.6154 0.6300
epoch 1000 LossPred 0.9008 LossAtt 0.1727 TrainAcc 0.6300 TestAcc 0.6154 0.6300
epoch 1100 LossPred 0.8967 LossAtt 0.1676 TrainAcc 0.6400 TestAcc 0.6309 0.6400
epoch 1200 LossPred 0.9084 LossAtt 0.1837 TrainAcc 0.6500 TestAcc 0.6196 0.6450
epoch 1300 LossPred 0.8999 LossAtt 0.1557 TrainAcc 0.6400 TestAcc 0.6036 0.6200
epoch 1400 LossPred 0.8921 LossAtt 0.1450 TrainAcc 0.6200 TestAcc 0.5628 0.6400
epoch 1500 LossPred 0.8908 LossAtt 0.1808 TrainAcc 0.6200 TestAcc 0.5626 0.6500
epoch 1600 LossPred 0.8780 LossAtt 0.1697 TrainAcc 0.6400 TestAcc 0.5868 0.6100
epoch 1700 LossPred 0.8788 LossAtt 0.1479 TrainAcc 0.6400 TestAcc 0.5868 0.6150
epoch 1800 LossPred 0.8800 LossAtt 0.0738 TrainAcc 0.6400 TestAcc 0.5868 0.6250
epoch 1900 LossPred 0.8822 LossAtt 0.1188 TrainAcc 0.6400 TestAcc 0.5868 0.6400
epoch 2000 LossPred 0.8768 LossAtt 0.1996 TrainAcc 0.6700 TestAcc 0.5866 0.6550
epoch 2100 LossPred 0.8657 LossAtt 0.2560 TrainAcc 0.6800 TestAcc 0.5841 0.6800
epoch 2200 LossPred 0.8487 LossAtt 0.4625 TrainAcc 0.7300 TestAcc 0.6144 0.6900
epoch 2300 LossPred 0.5043 LossAtt 0.6348 TrainAcc 0.8100 TestAcc 0.8306 0.8000
epoch 2400 LossPred 0.2822 LossAtt 0.4236 TrainAcc 0.9200 TestAcc 0.8361 0.8300
epoch 2500 LossPred 0.1192 LossAtt 0.4002 TrainAcc 0.9500 TestAcc 0.9192 0.9150
Optimization Finished!
********** replication  17  **********
epoch   0 LossPred 1.1877 LossAtt 1.0175 TrainAcc 0.5600 TestAcc 0.5786 0.5250
epoch 100 LossPred 0.9804 LossAtt 0.4481 TrainAcc 0.5800 TestAcc 0.6049 0.5800
epoch 200 LossPred 0.9365 LossAtt 0.5323 TrainAcc 0.6200 TestAcc 0.6049 0.6100
epoch 300 LossPred 0.9183 LossAtt 0.5170 TrainAcc 0.6500 TestAcc 0.6074 0.6350
epoch 400 LossPred 0.8944 LossAtt 0.5365 TrainAcc 0.6600 TestAcc 0.6099 0.6550
epoch 500 LossPred 0.8671 LossAtt 0.5106 TrainAcc 0.6500 TestAcc 0.6011 0.6450
epoch 600 LossPred 0.8499 LossAtt 0.5193 TrainAcc 0.6600 TestAcc 0.5973 0.6650
epoch 700 LossPred 0.8325 LossAtt 0.5176 TrainAcc 0.6600 TestAcc 0.5993 0.6650
epoch 800 LossPred 0.8079 LossAtt 0.5795 TrainAcc 0.6700 TestAcc 0.5948 0.6650
epoch 900 LossPred 0.7854 LossAtt 0.5856 TrainAcc 0.6400 TestAcc 0.6151 0.6450
epoch 1000 LossPred 0.7674 LossAtt 0.5777 TrainAcc 0.6700 TestAcc 0.6344 0.6550
epoch 1100 LossPred 0.6746 LossAtt 0.5883 TrainAcc 0.7500 TestAcc 0.6957 0.7200
epoch 1200 LossPred 0.6415 LossAtt 0.5513 TrainAcc 0.7500 TestAcc 0.7112 0.7450
epoch 1300 LossPred 0.6031 LossAtt 0.5461 TrainAcc 0.8000 TestAcc 0.6989 0.7550
epoch 1400 LossPred 0.7060 LossAtt 0.5670 TrainAcc 0.7500 TestAcc 0.7035 0.7500
epoch 1500 LossPred 0.6041 LossAtt 0.5835 TrainAcc 0.7900 TestAcc 0.7095 0.7450
epoch 1600 LossPred 0.5917 LossAtt 0.5495 TrainAcc 0.7800 TestAcc 0.7205 0.7450
epoch 1700 LossPred 0.5674 LossAtt 0.5547 TrainAcc 0.8000 TestAcc 0.7257 0.7650
epoch 1800 LossPred 0.6022 LossAtt 0.5443 TrainAcc 0.7900 TestAcc 0.7643 0.7650
epoch 1900 LossPred 0.5374 LossAtt 0.5234 TrainAcc 0.8200 TestAcc 0.7382 0.7800
epoch 2000 LossPred 0.5532 LossAtt 0.5583 TrainAcc 0.8100 TestAcc 0.7325 0.7750
epoch 2100 LossPred 0.5438 LossAtt 0.5267 TrainAcc 0.8000 TestAcc 0.7580 0.7900
epoch 2200 LossPred 0.5215 LossAtt 0.5401 TrainAcc 0.8200 TestAcc 0.7485 0.8000
epoch 2300 LossPred 0.5165 LossAtt 0.5517 TrainAcc 0.8400 TestAcc 0.7508 0.7850
epoch 2400 LossPred 0.5040 LossAtt 0.5338 TrainAcc 0.8400 TestAcc 0.7427 0.8000
epoch 2500 LossPred 0.5233 LossAtt 0.5265 TrainAcc 0.8300 TestAcc 0.7457 0.7900
Optimization Finished!
********** replication  18  **********
epoch   0 LossPred 1.2176 LossAtt 1.0167 TrainAcc 0.5000 TestAcc 0.5465 0.5050
epoch 100 LossPred 0.9548 LossAtt 0.4768 TrainAcc 0.6000 TestAcc 0.6139 0.6000
epoch 200 LossPred 0.9235 LossAtt 0.3984 TrainAcc 0.6300 TestAcc 0.6051 0.6200
epoch 300 LossPred 0.9075 LossAtt 0.4064 TrainAcc 0.6300 TestAcc 0.6051 0.6300
epoch 400 LossPred 0.8949 LossAtt 0.3018 TrainAcc 0.6300 TestAcc 0.6051 0.6300
epoch 500 LossPred 0.8835 LossAtt 0.3322 TrainAcc 0.6600 TestAcc 0.6329 0.6550
epoch 600 LossPred 0.8565 LossAtt 0.2996 TrainAcc 0.6600 TestAcc 0.6607 0.6650
epoch 700 LossPred 0.4255 LossAtt 0.3998 TrainAcc 0.8500 TestAcc 0.8371 0.8600
epoch 800 LossPred 0.2186 LossAtt 0.4048 TrainAcc 0.9500 TestAcc 0.8989 0.9400
epoch 900 LossPred 0.1290 LossAtt 0.4455 TrainAcc 0.9900 TestAcc 0.9307 0.9600
epoch 1000 LossPred 0.1312 LossAtt 0.4364 TrainAcc 0.9800 TestAcc 0.9287 0.9750
epoch 1100 LossPred 0.0910 LossAtt 0.4441 TrainAcc 0.9900 TestAcc 0.9432 0.9900
epoch 1200 LossPred 0.0715 LossAtt 0.4347 TrainAcc 0.9900 TestAcc 0.9472 0.9850
epoch 1300 LossPred 0.0640 LossAtt 0.4549 TrainAcc 0.9900 TestAcc 0.9505 0.9900
epoch 1400 LossPred 0.1716 LossAtt 0.4170 TrainAcc 0.9200 TestAcc 0.9127 0.9150
epoch 1500 LossPred 0.1147 LossAtt 0.4457 TrainAcc 0.9600 TestAcc 0.9279 0.9650
epoch 1600 LossPred 0.1510 LossAtt 0.4292 TrainAcc 0.9400 TestAcc 0.9174 0.9350
epoch 1700 LossPred 0.0461 LossAtt 0.4276 TrainAcc 1.0000 TestAcc 0.9605 0.9950
Optimization Finished!
********** replication  19  **********
epoch   0 LossPred 0.9473 LossAtt 1.0001 TrainAcc 0.6000 TestAcc 0.5561 0.6050
epoch 100 LossPred 0.8042 LossAtt 0.4701 TrainAcc 0.6800 TestAcc 0.6612 0.7000
epoch 200 LossPred 0.6003 LossAtt 0.5531 TrainAcc 0.8100 TestAcc 0.7135 0.7950
epoch 300 LossPred 0.3472 LossAtt 0.5405 TrainAcc 0.9100 TestAcc 0.9109 0.8800
epoch 400 LossPred 0.2407 LossAtt 0.5446 TrainAcc 0.9500 TestAcc 0.9017 0.9000
epoch 500 LossPred 0.2405 LossAtt 0.5255 TrainAcc 0.9200 TestAcc 0.8609 0.9250
epoch 600 LossPred 0.2616 LossAtt 0.5042 TrainAcc 0.9000 TestAcc 0.8398 0.9100
epoch 700 LossPred 0.1884 LossAtt 0.4538 TrainAcc 0.9500 TestAcc 0.8904 0.9350
epoch 800 LossPred 0.1757 LossAtt 0.4504 TrainAcc 0.9700 TestAcc 0.9209 0.9500
epoch 900 LossPred 0.1870 LossAtt 0.4331 TrainAcc 0.9600 TestAcc 0.9267 0.9450
epoch 1000 LossPred 0.1988 LossAtt 0.4114 TrainAcc 0.9300 TestAcc 0.8799 0.9300
epoch 1100 LossPred 0.1660 LossAtt 0.4242 TrainAcc 0.9500 TestAcc 0.9004 0.9350
epoch 1200 LossPred 0.2496 LossAtt 0.4109 TrainAcc 0.9100 TestAcc 0.8514 0.9150
epoch 1300 LossPred 0.1678 LossAtt 0.4167 TrainAcc 0.9600 TestAcc 0.8941 0.9350
epoch 1400 LossPred 0.1551 LossAtt 0.4062 TrainAcc 0.9700 TestAcc 0.9229 0.9550
epoch 1500 LossPred 0.1528 LossAtt 0.4225 TrainAcc 0.9700 TestAcc 0.9237 0.9550
epoch 1600 LossPred 0.1728 LossAtt 0.4125 TrainAcc 0.9600 TestAcc 0.9237 0.9350
epoch 1700 LossPred 0.2019 LossAtt 0.4220 TrainAcc 0.9400 TestAcc 0.8661 0.9300
epoch 1800 LossPred 0.1921 LossAtt 0.4458 TrainAcc 0.9400 TestAcc 0.9119 0.9200
epoch 1900 LossPred 0.2193 LossAtt 0.4499 TrainAcc 0.9200 TestAcc 0.8614 0.9150
epoch 2000 LossPred 0.1380 LossAtt 0.4251 TrainAcc 0.9400 TestAcc 0.8879 0.9350
epoch 2100 LossPred 0.1519 LossAtt 0.4246 TrainAcc 0.9600 TestAcc 0.9049 0.9450
epoch 2200 LossPred 0.1318 LossAtt 0.4201 TrainAcc 0.9700 TestAcc 0.8799 0.9450
epoch 2300 LossPred 0.1042 LossAtt 0.3963 TrainAcc 0.9700 TestAcc 0.9079 0.9500
epoch 2400 LossPred 0.1004 LossAtt 0.4503 TrainAcc 0.9700 TestAcc 0.9022 0.9500
epoch 2500 LossPred 0.1228 LossAtt 0.4167 TrainAcc 0.9500 TestAcc 0.8914 0.9400
Optimization Finished!
********** replication  20  **********
epoch   0 LossPred 1.0272 LossAtt 1.0104 TrainAcc 0.5500 TestAcc 0.5518 0.5500
epoch 100 LossPred 0.8571 LossAtt 0.5000 TrainAcc 0.6800 TestAcc 0.6697 0.6650
epoch 200 LossPred 0.5891 LossAtt 0.4462 TrainAcc 0.7900 TestAcc 0.7743 0.7900
epoch 300 LossPred 0.7809 LossAtt 0.3890 TrainAcc 0.6700 TestAcc 0.6762 0.6600
epoch 400 LossPred 0.6379 LossAtt 0.4306 TrainAcc 0.7800 TestAcc 0.7400 0.7750
epoch 500 LossPred 0.5974 LossAtt 0.4171 TrainAcc 0.7700 TestAcc 0.7297 0.7600
epoch 600 LossPred 0.4902 LossAtt 0.4415 TrainAcc 0.8500 TestAcc 0.8358 0.8050
epoch 700 LossPred 0.5443 LossAtt 0.4357 TrainAcc 0.7800 TestAcc 0.7623 0.8000
epoch 800 LossPred 0.3856 LossAtt 0.4021 TrainAcc 0.8500 TestAcc 0.8413 0.8600
epoch 900 LossPred 0.3598 LossAtt 0.4057 TrainAcc 0.9000 TestAcc 0.8599 0.8350
epoch 1000 LossPred 0.3245 LossAtt 0.3920 TrainAcc 0.9100 TestAcc 0.8826 0.8500
epoch 1100 LossPred 0.3395 LossAtt 0.4255 TrainAcc 0.8600 TestAcc 0.8639 0.8750
epoch 1200 LossPred 0.2387 LossAtt 0.4458 TrainAcc 0.9500 TestAcc 0.9024 0.9050
epoch 1300 LossPred 0.2542 LossAtt 0.4072 TrainAcc 0.9500 TestAcc 0.9117 0.9050
epoch 1400 LossPred 0.2113 LossAtt 0.4242 TrainAcc 0.9500 TestAcc 0.9019 0.9200
epoch 1500 LossPred 0.2071 LossAtt 0.4158 TrainAcc 0.9500 TestAcc 0.8986 0.9150
epoch 1600 LossPred 0.1944 LossAtt 0.4316 TrainAcc 0.9500 TestAcc 0.9007 0.9250
epoch 1700 LossPred 0.1941 LossAtt 0.4217 TrainAcc 0.9500 TestAcc 0.8889 0.9250
epoch 1800 LossPred 0.2038 LossAtt 0.4374 TrainAcc 0.9600 TestAcc 0.8994 0.9100
epoch 1900 LossPred 0.2076 LossAtt 0.4246 TrainAcc 0.9500 TestAcc 0.9144 0.9100
epoch 2000 LossPred 0.2729 LossAtt 0.4211 TrainAcc 0.8800 TestAcc 0.8521 0.8800
epoch 2100 LossPred 0.2420 LossAtt 0.4112 TrainAcc 0.9200 TestAcc 0.8949 0.9150
epoch 2200 LossPred 0.1760 LossAtt 0.4092 TrainAcc 0.9500 TestAcc 0.8984 0.9250
epoch 2300 LossPred 0.1917 LossAtt 0.3996 TrainAcc 0.9500 TestAcc 0.9019 0.9250
epoch 2400 LossPred 0.1759 LossAtt 0.4178 TrainAcc 0.9600 TestAcc 0.8999 0.9150
epoch 2500 LossPred 0.1933 LossAtt 0.4131 TrainAcc 0.9500 TestAcc 0.8934 0.9200
Optimization Finished!
********** replication  21  **********
epoch   0 LossPred 0.9868 LossAtt 0.9913 TrainAcc 0.4800 TestAcc 0.5195 0.5000
epoch 100 LossPred 0.8496 LossAtt 0.4181 TrainAcc 0.6800 TestAcc 0.6061 0.6800
epoch 200 LossPred 0.8143 LossAtt 0.4049 TrainAcc 0.7200 TestAcc 0.6371 0.6950
epoch 300 LossPred 0.7714 LossAtt 0.4534 TrainAcc 0.7100 TestAcc 0.6489 0.7000
epoch 400 LossPred 0.5534 LossAtt 0.4453 TrainAcc 0.8300 TestAcc 0.7665 0.8100
epoch 500 LossPred 0.3809 LossAtt 0.4571 TrainAcc 0.8800 TestAcc 0.8786 0.8600
epoch 600 LossPred 0.2810 LossAtt 0.4263 TrainAcc 0.9200 TestAcc 0.8909 0.8500
epoch 700 LossPred 0.2735 LossAtt 0.4032 TrainAcc 0.9100 TestAcc 0.8874 0.8550
epoch 800 LossPred 0.2750 LossAtt 0.4015 TrainAcc 0.8900 TestAcc 0.9012 0.8800
epoch 900 LossPred 0.2696 LossAtt 0.3883 TrainAcc 0.9200 TestAcc 0.8821 0.8550
epoch 1000 LossPred 0.2169 LossAtt 0.3767 TrainAcc 0.9400 TestAcc 0.9127 0.8900
epoch 1100 LossPred 0.2107 LossAtt 0.3467 TrainAcc 0.9400 TestAcc 0.9044 0.8950
epoch 1200 LossPred 0.2867 LossAtt 0.3716 TrainAcc 0.9100 TestAcc 0.8956 0.8950
epoch 1300 LossPred 0.1775 LossAtt 0.3480 TrainAcc 0.9700 TestAcc 0.9412 0.9150
epoch 1400 LossPred 0.3791 LossAtt 0.3294 TrainAcc 0.8500 TestAcc 0.8378 0.8650
epoch 1500 LossPred 0.1462 LossAtt 0.3238 TrainAcc 0.9500 TestAcc 0.9252 0.9050
epoch 1600 LossPred 0.1515 LossAtt 0.3220 TrainAcc 0.9700 TestAcc 0.9294 0.9250
epoch 1700 LossPred 0.3086 LossAtt 0.3337 TrainAcc 0.8700 TestAcc 0.8999 0.8850
epoch 1800 LossPred 0.1422 LossAtt 0.2966 TrainAcc 0.9600 TestAcc 0.9222 0.9200
epoch 1900 LossPred 0.2301 LossAtt 0.3084 TrainAcc 0.8900 TestAcc 0.8819 0.8750
epoch 2000 LossPred 0.1254 LossAtt 0.3119 TrainAcc 0.9700 TestAcc 0.9527 0.9200
epoch 2100 LossPred 0.2301 LossAtt 0.3065 TrainAcc 0.8800 TestAcc 0.8744 0.8800
epoch 2200 LossPred 0.1616 LossAtt 0.3088 TrainAcc 0.9500 TestAcc 0.9157 0.9000
epoch 2300 LossPred 0.2802 LossAtt 0.2973 TrainAcc 0.8800 TestAcc 0.8631 0.8750
epoch 2400 LossPred 0.3016 LossAtt 0.2833 TrainAcc 0.8800 TestAcc 0.8634 0.8750
epoch 2500 LossPred 0.1761 LossAtt 0.2900 TrainAcc 0.9500 TestAcc 0.9302 0.9050
Optimization Finished!
********** replication  22  **********
epoch   0 LossPred 1.2165 LossAtt 1.0221 TrainAcc 0.5100 TestAcc 0.4985 0.5200
epoch 100 LossPred 0.9335 LossAtt 0.3953 TrainAcc 0.6100 TestAcc 0.6021 0.6150
epoch 200 LossPred 0.9093 LossAtt 0.3726 TrainAcc 0.6400 TestAcc 0.6026 0.6500
epoch 300 LossPred 0.7560 LossAtt 0.3205 TrainAcc 0.7300 TestAcc 0.7167 0.7250
epoch 400 LossPred 0.4028 LossAtt 0.2901 TrainAcc 0.8800 TestAcc 0.8926 0.8550
epoch 500 LossPred 0.2940 LossAtt 0.2723 TrainAcc 0.9200 TestAcc 0.9214 0.8900
epoch 600 LossPred 0.1374 LossAtt 0.2933 TrainAcc 0.9600 TestAcc 0.9357 0.9300
epoch 700 LossPred 0.0814 LossAtt 0.2874 TrainAcc 0.9800 TestAcc 0.9582 0.9650
epoch 800 LossPred 0.0846 LossAtt 0.2764 TrainAcc 0.9900 TestAcc 0.9652 0.9350
epoch 900 LossPred 0.5681 LossAtt 0.2570 TrainAcc 0.8300 TestAcc 0.7953 0.7900
epoch 1000 LossPred 0.3065 LossAtt 0.2732 TrainAcc 0.9200 TestAcc 0.8759 0.8950
epoch 1100 LossPred 0.3344 LossAtt 0.2360 TrainAcc 0.9000 TestAcc 0.8929 0.8950
epoch 1200 LossPred 0.1036 LossAtt 0.2679 TrainAcc 0.9700 TestAcc 0.9565 0.9500
epoch 1300 LossPred 0.1844 LossAtt 0.2668 TrainAcc 0.9300 TestAcc 0.9304 0.9050
epoch 1400 LossPred 0.1919 LossAtt 0.2618 TrainAcc 0.9200 TestAcc 0.9267 0.9050
epoch 1500 LossPred 0.1694 LossAtt 0.2748 TrainAcc 0.9300 TestAcc 0.9119 0.9250
epoch 1600 LossPred 0.3148 LossAtt 0.2593 TrainAcc 0.8900 TestAcc 0.8931 0.8900
epoch 1700 LossPred 0.0964 LossAtt 0.2593 TrainAcc 0.9700 TestAcc 0.9269 0.9500
epoch 1800 LossPred 0.0979 LossAtt 0.2625 TrainAcc 0.9800 TestAcc 0.9462 0.9650
epoch 1900 LossPred 0.0750 LossAtt 0.2612 TrainAcc 0.9800 TestAcc 0.9334 0.9800
epoch 2000 LossPred 0.3591 LossAtt 0.2676 TrainAcc 0.8700 TestAcc 0.8816 0.8700
epoch 2100 LossPred 0.1099 LossAtt 0.2537 TrainAcc 0.9800 TestAcc 0.9122 0.9700
epoch 2200 LossPred 0.0700 LossAtt 0.2454 TrainAcc 0.9800 TestAcc 0.9582 0.9700
epoch 2300 LossPred 0.0939 LossAtt 0.2508 TrainAcc 0.9700 TestAcc 0.9535 0.9500
epoch 2400 LossPred 0.2475 LossAtt 0.2622 TrainAcc 0.9100 TestAcc 0.9177 0.8950
epoch 2500 LossPred 0.2170 LossAtt 0.2477 TrainAcc 0.9300 TestAcc 0.9284 0.9300
Optimization Finished!
********** replication  23  **********
epoch   0 LossPred 1.1836 LossAtt 0.9996 TrainAcc 0.4600 TestAcc 0.4132 0.5050
epoch 100 LossPred 0.9625 LossAtt 0.5221 TrainAcc 0.5900 TestAcc 0.5460 0.6000
epoch 200 LossPred 0.9126 LossAtt 0.5363 TrainAcc 0.6200 TestAcc 0.5636 0.6100
epoch 300 LossPred 0.8899 LossAtt 0.4496 TrainAcc 0.6200 TestAcc 0.5636 0.6400
epoch 400 LossPred 0.8648 LossAtt 0.3844 TrainAcc 0.6700 TestAcc 0.5938 0.6600
epoch 500 LossPred 0.8356 LossAtt 0.4130 TrainAcc 0.6500 TestAcc 0.5973 0.6400
epoch 600 LossPred 0.4370 LossAtt 0.5485 TrainAcc 0.8800 TestAcc 0.8226 0.8750
epoch 700 LossPred 0.2440 LossAtt 0.5630 TrainAcc 0.9400 TestAcc 0.8599 0.9250
epoch 800 LossPred 0.1950 LossAtt 0.5339 TrainAcc 0.9400 TestAcc 0.8629 0.9300
epoch 900 LossPred 0.1714 LossAtt 0.5511 TrainAcc 0.9300 TestAcc 0.8591 0.9250
epoch 1000 LossPred 0.1875 LossAtt 0.5219 TrainAcc 0.9100 TestAcc 0.8554 0.9000
epoch 1100 LossPred 0.1799 LossAtt 0.5047 TrainAcc 0.9400 TestAcc 0.8574 0.9200
epoch 1200 LossPred 0.1501 LossAtt 0.5276 TrainAcc 0.9400 TestAcc 0.8704 0.9250
epoch 1300 LossPred 0.1362 LossAtt 0.5322 TrainAcc 0.9500 TestAcc 0.8709 0.9400
epoch 1400 LossPred 0.2010 LossAtt 0.5527 TrainAcc 0.9200 TestAcc 0.8611 0.9150
epoch 1500 LossPred 0.1086 LossAtt 0.4951 TrainAcc 0.9800 TestAcc 0.8616 0.9550
epoch 1600 LossPred 0.1022 LossAtt 0.5041 TrainAcc 0.9700 TestAcc 0.8646 0.9650
epoch 1700 LossPred 0.1102 LossAtt 0.5141 TrainAcc 0.9700 TestAcc 0.8724 0.9450
epoch 1800 LossPred 0.1383 LossAtt 0.5297 TrainAcc 0.9500 TestAcc 0.8546 0.9400
epoch 1900 LossPred 0.1046 LossAtt 0.5186 TrainAcc 0.9700 TestAcc 0.8656 0.9550
epoch 2000 LossPred 0.1200 LossAtt 0.5261 TrainAcc 0.9600 TestAcc 0.8649 0.9550
epoch 2100 LossPred 0.1394 LossAtt 0.5305 TrainAcc 0.9400 TestAcc 0.8721 0.9400
epoch 2200 LossPred 0.1103 LossAtt 0.5446 TrainAcc 0.9700 TestAcc 0.8771 0.9550
epoch 2300 LossPred 0.1080 LossAtt 0.5257 TrainAcc 0.9600 TestAcc 0.8729 0.9550
epoch 2400 LossPred 0.1016 LossAtt 0.5310 TrainAcc 0.9700 TestAcc 0.8716 0.9500
epoch 2500 LossPred 0.1159 LossAtt 0.5494 TrainAcc 0.9700 TestAcc 0.8754 0.9600
Optimization Finished!
********** replication  24  **********
epoch   0 LossPred 1.2828 LossAtt 1.0207 TrainAcc 0.5000 TestAcc 0.4807 0.4800
epoch 100 LossPred 0.9883 LossAtt 0.3785 TrainAcc 0.5100 TestAcc 0.4920 0.5100
epoch 200 LossPred 0.8603 LossAtt 0.3714 TrainAcc 0.7500 TestAcc 0.7052 0.7350
epoch 300 LossPred 0.7714 LossAtt 0.4349 TrainAcc 0.7600 TestAcc 0.7913 0.7700
epoch 400 LossPred 0.6483 LossAtt 0.3725 TrainAcc 0.7700 TestAcc 0.8053 0.8050
epoch 500 LossPred 0.5990 LossAtt 0.3728 TrainAcc 0.8300 TestAcc 0.8481 0.7950
epoch 600 LossPred 0.5230 LossAtt 0.3588 TrainAcc 0.8300 TestAcc 0.8338 0.8250
epoch 700 LossPred 0.7256 LossAtt 0.3485 TrainAcc 0.7300 TestAcc 0.6867 0.7100
epoch 800 LossPred 0.6953 LossAtt 0.3772 TrainAcc 0.7800 TestAcc 0.7643 0.7650
epoch 900 LossPred 0.5610 LossAtt 0.3080 TrainAcc 0.7800 TestAcc 0.7843 0.7900
epoch 1000 LossPred 0.4881 LossAtt 0.3158 TrainAcc 0.8500 TestAcc 0.8546 0.8200
epoch 1100 LossPred 0.5056 LossAtt 0.3030 TrainAcc 0.8200 TestAcc 0.7995 0.7900
epoch 1200 LossPred 0.5130 LossAtt 0.2782 TrainAcc 0.8100 TestAcc 0.8346 0.8100
epoch 1300 LossPred 0.5564 LossAtt 0.2572 TrainAcc 0.7800 TestAcc 0.7838 0.7950
epoch 1400 LossPred 0.5248 LossAtt 0.2621 TrainAcc 0.8100 TestAcc 0.8166 0.8150
epoch 1500 LossPred 0.4989 LossAtt 0.2817 TrainAcc 0.8400 TestAcc 0.8456 0.8300
epoch 1600 LossPred 0.4825 LossAtt 0.2639 TrainAcc 0.8200 TestAcc 0.8323 0.8150
epoch 1700 LossPred 0.6879 LossAtt 0.2601 TrainAcc 0.7200 TestAcc 0.7060 0.7500
epoch 1800 LossPred 0.8228 LossAtt 0.2751 TrainAcc 0.6400 TestAcc 0.6334 0.6400
epoch 1900 LossPred 0.5687 LossAtt 0.2967 TrainAcc 0.8100 TestAcc 0.8341 0.8050
epoch 2000 LossPred 1.0650 LossAtt 0.3385 TrainAcc 0.5500 TestAcc 0.5586 0.5300
epoch 2100 LossPred 0.8176 LossAtt 0.3259 TrainAcc 0.6000 TestAcc 0.5871 0.6200
epoch 2200 LossPred 0.8262 LossAtt 0.3651 TrainAcc 0.6800 TestAcc 0.6642 0.6650
epoch 2300 LossPred 0.9533 LossAtt 0.3479 TrainAcc 0.5700 TestAcc 0.5853 0.5500
epoch 2400 LossPred 0.5472 LossAtt 0.3260 TrainAcc 0.8500 TestAcc 0.8086 0.8050
epoch 2500 LossPred 0.6189 LossAtt 0.3182 TrainAcc 0.7500 TestAcc 0.7347 0.7450
Optimization Finished!
********** replication  25  **********
epoch   0 LossPred 1.1269 LossAtt 1.0223 TrainAcc 0.4900 TestAcc 0.4317 0.4850
epoch 100 LossPred 0.9182 LossAtt 0.4903 TrainAcc 0.6500 TestAcc 0.5378 0.6450
epoch 200 LossPred 0.8225 LossAtt 0.5662 TrainAcc 0.6800 TestAcc 0.5593 0.6750
epoch 300 LossPred 0.4378 LossAtt 0.5722 TrainAcc 0.8700 TestAcc 0.8453 0.8900
epoch 400 LossPred 0.2254 LossAtt 0.5512 TrainAcc 0.9400 TestAcc 0.8824 0.9300
epoch 500 LossPred 0.1711 LossAtt 0.5596 TrainAcc 0.9700 TestAcc 0.8944 0.9650
epoch 600 LossPred 0.1712 LossAtt 0.5214 TrainAcc 0.9500 TestAcc 0.8936 0.9500
epoch 700 LossPred 0.1470 LossAtt 0.5193 TrainAcc 0.9700 TestAcc 0.8919 0.9600
epoch 800 LossPred 0.1315 LossAtt 0.5153 TrainAcc 0.9600 TestAcc 0.9079 0.9650
epoch 900 LossPred 0.1421 LossAtt 0.5298 TrainAcc 0.9400 TestAcc 0.9027 0.9600
epoch 1000 LossPred 0.1244 LossAtt 0.5309 TrainAcc 0.9700 TestAcc 0.9012 0.9600
epoch 1100 LossPred 0.1088 LossAtt 0.4909 TrainAcc 0.9700 TestAcc 0.9062 0.9750
epoch 1200 LossPred 0.1337 LossAtt 0.4645 TrainAcc 0.9700 TestAcc 0.8909 0.9500
epoch 1300 LossPred 0.0952 LossAtt 0.4509 TrainAcc 0.9800 TestAcc 0.9097 0.9750
epoch 1400 LossPred 0.0811 LossAtt 0.4410 TrainAcc 0.9900 TestAcc 0.9077 0.9700
epoch 1500 LossPred 0.0921 LossAtt 0.4512 TrainAcc 0.9800 TestAcc 0.9047 0.9700
epoch 1600 LossPred 0.0698 LossAtt 0.4039 TrainAcc 0.9900 TestAcc 0.9089 0.9750
epoch 1700 LossPred 0.0650 LossAtt 0.4461 TrainAcc 0.9900 TestAcc 0.9079 0.9750
epoch 1800 LossPred 0.0654 LossAtt 0.4264 TrainAcc 0.9900 TestAcc 0.9069 0.9750
epoch 1900 LossPred 0.0765 LossAtt 0.4303 TrainAcc 0.9700 TestAcc 0.8969 0.9750
epoch 2000 LossPred 0.0655 LossAtt 0.3957 TrainAcc 0.9900 TestAcc 0.9069 0.9800
epoch 2100 LossPred 0.1301 LossAtt 0.4312 TrainAcc 0.9600 TestAcc 0.8986 0.9650
epoch 2200 LossPred 0.0617 LossAtt 0.4284 TrainAcc 0.9900 TestAcc 0.9037 0.9850
epoch 2300 LossPred 0.0572 LossAtt 0.4343 TrainAcc 0.9900 TestAcc 0.9007 0.9750
epoch 2400 LossPred 0.0908 LossAtt 0.4313 TrainAcc 0.9700 TestAcc 0.8831 0.9700
epoch 2500 LossPred 0.0527 LossAtt 0.4453 TrainAcc 0.9900 TestAcc 0.8976 0.9800
Optimization Finished!
********** replication  26  **********
epoch   0 LossPred 1.0145 LossAtt 0.9887 TrainAcc 0.4800 TestAcc 0.4499 0.4400
epoch 100 LossPred 0.8521 LossAtt 0.3962 TrainAcc 0.7100 TestAcc 0.6096 0.7050
epoch 200 LossPred 0.7797 LossAtt 0.3202 TrainAcc 0.7100 TestAcc 0.6096 0.7100
epoch 300 LossPred 0.6488 LossAtt 0.4018 TrainAcc 0.7500 TestAcc 0.8036 0.7900
epoch 400 LossPred 0.4355 LossAtt 0.3205 TrainAcc 0.8700 TestAcc 0.7845 0.8450
epoch 500 LossPred 0.3970 LossAtt 0.3077 TrainAcc 0.8700 TestAcc 0.8106 0.8650
epoch 600 LossPred 0.3600 LossAtt 0.3210 TrainAcc 0.9000 TestAcc 0.7973 0.8500
epoch 700 LossPred 0.4141 LossAtt 0.3170 TrainAcc 0.8800 TestAcc 0.7598 0.8700
epoch 800 LossPred 0.4275 LossAtt 0.2925 TrainAcc 0.8600 TestAcc 0.7505 0.8550
epoch 900 LossPred 0.4326 LossAtt 0.3141 TrainAcc 0.8600 TestAcc 0.7548 0.8650
epoch 1000 LossPred 0.4025 LossAtt 0.3008 TrainAcc 0.8800 TestAcc 0.7758 0.8400
epoch 1100 LossPred 0.3624 LossAtt 0.3004 TrainAcc 0.8700 TestAcc 0.7983 0.8600
epoch 1200 LossPred 0.3555 LossAtt 0.2947 TrainAcc 0.8800 TestAcc 0.8113 0.8600
epoch 1300 LossPred 0.3537 LossAtt 0.2906 TrainAcc 0.8700 TestAcc 0.8096 0.8600
epoch 1400 LossPred 0.3810 LossAtt 0.2844 TrainAcc 0.8700 TestAcc 0.8208 0.8650
epoch 1500 LossPred 0.3823 LossAtt 0.2957 TrainAcc 0.8800 TestAcc 0.8071 0.8600
epoch 1600 LossPred 0.3746 LossAtt 0.2862 TrainAcc 0.8800 TestAcc 0.7908 0.8550
epoch 1700 LossPred 0.3559 LossAtt 0.2770 TrainAcc 0.8700 TestAcc 0.8298 0.8650
epoch 1800 LossPred 0.3407 LossAtt 0.2994 TrainAcc 0.8700 TestAcc 0.8301 0.8600
epoch 1900 LossPred 0.3248 LossAtt 0.3067 TrainAcc 0.9000 TestAcc 0.8141 0.8600
epoch 2000 LossPred 0.3084 LossAtt 0.2946 TrainAcc 0.9000 TestAcc 0.8193 0.8750
epoch 2100 LossPred 0.3073 LossAtt 0.2882 TrainAcc 0.8900 TestAcc 0.8436 0.8800
epoch 2200 LossPred 0.3356 LossAtt 0.2936 TrainAcc 0.8900 TestAcc 0.7993 0.8800
epoch 2300 LossPred 0.3486 LossAtt 0.2927 TrainAcc 0.8900 TestAcc 0.8704 0.8900
epoch 2400 LossPred 0.2919 LossAtt 0.3088 TrainAcc 0.9000 TestAcc 0.8273 0.8800
epoch 2500 LossPred 0.2387 LossAtt 0.2945 TrainAcc 0.9300 TestAcc 0.8846 0.9100
Optimization Finished!
********** replication  27  **********
epoch   0 LossPred 1.0963 LossAtt 1.0461 TrainAcc 0.5900 TestAcc 0.6076 0.5600
epoch 100 LossPred 0.9608 LossAtt 0.4146 TrainAcc 0.5600 TestAcc 0.5808 0.5600
epoch 200 LossPred 0.9201 LossAtt 0.3477 TrainAcc 0.6100 TestAcc 0.6046 0.6100
epoch 300 LossPred 0.8727 LossAtt 0.3656 TrainAcc 0.6100 TestAcc 0.6046 0.6100
epoch 400 LossPred 0.2765 LossAtt 0.5413 TrainAcc 0.9300 TestAcc 0.9247 0.9050
epoch 500 LossPred 0.1790 LossAtt 0.5327 TrainAcc 0.9500 TestAcc 0.9174 0.9150
epoch 600 LossPred 0.1606 LossAtt 0.4593 TrainAcc 0.9600 TestAcc 0.9359 0.9100
epoch 700 LossPred 0.1959 LossAtt 0.4402 TrainAcc 0.9300 TestAcc 0.9137 0.9150
epoch 800 LossPred 0.4199 LossAtt 0.4085 TrainAcc 0.8400 TestAcc 0.8251 0.8450
epoch 900 LossPred 0.2659 LossAtt 0.4266 TrainAcc 0.9200 TestAcc 0.8976 0.8950
epoch 1000 LossPred 0.2167 LossAtt 0.4527 TrainAcc 0.9200 TestAcc 0.9107 0.9050
epoch 1100 LossPred 0.3153 LossAtt 0.4315 TrainAcc 0.8700 TestAcc 0.8629 0.8650
epoch 1200 LossPred 0.2246 LossAtt 0.4430 TrainAcc 0.9300 TestAcc 0.9079 0.9200
epoch 1300 LossPred 0.2337 LossAtt 0.4583 TrainAcc 0.9200 TestAcc 0.9092 0.8950
epoch 1400 LossPred 0.4684 LossAtt 0.4818 TrainAcc 0.8500 TestAcc 0.8096 0.8400
epoch 1500 LossPred 0.2783 LossAtt 0.4766 TrainAcc 0.9100 TestAcc 0.8969 0.8950
epoch 1600 LossPred 0.3121 LossAtt 0.4627 TrainAcc 0.8900 TestAcc 0.8561 0.8950
epoch 1700 LossPred 0.3167 LossAtt 0.4482 TrainAcc 0.8900 TestAcc 0.8661 0.8900
epoch 1800 LossPred 0.3813 LossAtt 0.4623 TrainAcc 0.8500 TestAcc 0.8353 0.8550
epoch 1900 LossPred 0.2841 LossAtt 0.4331 TrainAcc 0.9100 TestAcc 0.8954 0.8850
epoch 2000 LossPred 0.2051 LossAtt 0.4210 TrainAcc 0.9200 TestAcc 0.9112 0.9150
epoch 2100 LossPred 0.1961 LossAtt 0.4084 TrainAcc 0.9500 TestAcc 0.9202 0.9200
epoch 2200 LossPred 0.2527 LossAtt 0.4348 TrainAcc 0.9300 TestAcc 0.8999 0.9150
epoch 2300 LossPred 0.2655 LossAtt 0.4175 TrainAcc 0.9100 TestAcc 0.8711 0.9100
epoch 2400 LossPred 0.1877 LossAtt 0.4169 TrainAcc 0.9400 TestAcc 0.9152 0.9150
epoch 2500 LossPred 0.1655 LossAtt 0.4472 TrainAcc 0.9500 TestAcc 0.9134 0.9200
Optimization Finished!
********** replication  28  **********
epoch   0 LossPred 1.3867 LossAtt 0.9881 TrainAcc 0.4800 TestAcc 0.4512 0.4550
epoch 100 LossPred 1.0079 LossAtt 0.3363 TrainAcc 0.5300 TestAcc 0.3956 0.5300
epoch 200 LossPred 0.9898 LossAtt 0.2587 TrainAcc 0.5300 TestAcc 0.3956 0.5300
epoch 300 LossPred 0.9844 LossAtt 0.2645 TrainAcc 0.5300 TestAcc 0.3956 0.5300
epoch 400 LossPred 0.9465 LossAtt 0.3533 TrainAcc 0.5800 TestAcc 0.4484 0.5750
epoch 500 LossPred 0.9218 LossAtt 0.3404 TrainAcc 0.6000 TestAcc 0.4660 0.5850
epoch 600 LossPred 0.8406 LossAtt 0.4076 TrainAcc 0.6500 TestAcc 0.5813 0.6550
epoch 700 LossPred 0.4268 LossAtt 0.4722 TrainAcc 0.8700 TestAcc 0.8959 0.8400
epoch 800 LossPred 0.3384 LossAtt 0.4914 TrainAcc 0.9200 TestAcc 0.8989 0.8900
epoch 900 LossPred 0.2428 LossAtt 0.5419 TrainAcc 0.9400 TestAcc 0.9152 0.9100
epoch 1000 LossPred 0.2148 LossAtt 0.5342 TrainAcc 0.9500 TestAcc 0.9217 0.9100
epoch 1100 LossPred 0.1830 LossAtt 0.5521 TrainAcc 0.9600 TestAcc 0.9219 0.9250
epoch 1200 LossPred 0.1801 LossAtt 0.5282 TrainAcc 0.9600 TestAcc 0.9204 0.9300
epoch 1300 LossPred 0.1724 LossAtt 0.5444 TrainAcc 0.9600 TestAcc 0.9342 0.9550
epoch 1400 LossPred 0.1843 LossAtt 0.5166 TrainAcc 0.9500 TestAcc 0.9394 0.9550
epoch 1500 LossPred 0.1936 LossAtt 0.5313 TrainAcc 0.9500 TestAcc 0.9434 0.9500
epoch 1600 LossPred 0.1286 LossAtt 0.5278 TrainAcc 0.9700 TestAcc 0.9442 0.9500
epoch 1700 LossPred 0.1307 LossAtt 0.5181 TrainAcc 0.9600 TestAcc 0.9497 0.9550
epoch 1800 LossPred 0.1553 LossAtt 0.5050 TrainAcc 0.9400 TestAcc 0.8979 0.9250
epoch 1900 LossPred 0.2014 LossAtt 0.4929 TrainAcc 0.9400 TestAcc 0.8991 0.9100
epoch 2000 LossPred 0.1241 LossAtt 0.5160 TrainAcc 0.9600 TestAcc 0.9414 0.9350
epoch 2100 LossPred 0.1923 LossAtt 0.5002 TrainAcc 0.9300 TestAcc 0.9277 0.9250
epoch 2200 LossPred 0.1460 LossAtt 0.4724 TrainAcc 0.9400 TestAcc 0.9394 0.9500
epoch 2300 LossPred 0.1481 LossAtt 0.4930 TrainAcc 0.9600 TestAcc 0.9017 0.9200
epoch 2400 LossPred 0.1331 LossAtt 0.4821 TrainAcc 0.9700 TestAcc 0.9137 0.9300
epoch 2500 LossPred 0.1531 LossAtt 0.5001 TrainAcc 0.9400 TestAcc 0.9072 0.9200
Optimization Finished!
********** replication  29  **********
epoch   0 LossPred 1.2334 LossAtt 1.0194 TrainAcc 0.5100 TestAcc 0.5200 0.4600
epoch 100 LossPred 0.9312 LossAtt 0.4740 TrainAcc 0.6500 TestAcc 0.6159 0.6500
epoch 200 LossPred 0.8312 LossAtt 0.5120 TrainAcc 0.6700 TestAcc 0.5883 0.6850
epoch 300 LossPred 0.3629 LossAtt 0.5349 TrainAcc 0.9000 TestAcc 0.8416 0.8950
epoch 400 LossPred 0.2680 LossAtt 0.4894 TrainAcc 0.9100 TestAcc 0.8776 0.8900
epoch 500 LossPred 0.2328 LossAtt 0.4604 TrainAcc 0.9400 TestAcc 0.8849 0.9400
epoch 600 LossPred 0.2304 LossAtt 0.4531 TrainAcc 0.9300 TestAcc 0.8854 0.9350
epoch 700 LossPred 0.1942 LossAtt 0.4208 TrainAcc 0.9500 TestAcc 0.8921 0.9550
epoch 800 LossPred 0.2169 LossAtt 0.4086 TrainAcc 0.9500 TestAcc 0.8906 0.9400
epoch 900 LossPred 0.1783 LossAtt 0.4254 TrainAcc 0.9600 TestAcc 0.8909 0.9450
epoch 1000 LossPred 0.2195 LossAtt 0.4459 TrainAcc 0.9300 TestAcc 0.8851 0.9000
epoch 1100 LossPred 0.1814 LossAtt 0.4198 TrainAcc 0.9600 TestAcc 0.8829 0.9250
epoch 1200 LossPred 0.1689 LossAtt 0.4143 TrainAcc 0.9500 TestAcc 0.8921 0.9150
epoch 1300 LossPred 0.2513 LossAtt 0.4517 TrainAcc 0.9100 TestAcc 0.8891 0.8900
epoch 1400 LossPred 0.1802 LossAtt 0.4265 TrainAcc 0.9400 TestAcc 0.8869 0.9000
epoch 1500 LossPred 0.1794 LossAtt 0.4360 TrainAcc 0.9400 TestAcc 0.8976 0.9250
epoch 1600 LossPred 0.1969 LossAtt 0.4345 TrainAcc 0.9300 TestAcc 0.9022 0.9200
epoch 1700 LossPred 0.1877 LossAtt 0.4160 TrainAcc 0.9300 TestAcc 0.8939 0.9050
epoch 1800 LossPred 0.1454 LossAtt 0.4341 TrainAcc 0.9700 TestAcc 0.9002 0.9100
epoch 1900 LossPred 0.1500 LossAtt 0.4110 TrainAcc 0.9600 TestAcc 0.8964 0.9200
epoch 2000 LossPred 0.1337 LossAtt 0.4067 TrainAcc 0.9800 TestAcc 0.8976 0.9100
epoch 2100 LossPred 0.1166 LossAtt 0.4159 TrainAcc 0.9800 TestAcc 0.9067 0.9200
epoch 2200 LossPred 0.1318 LossAtt 0.4407 TrainAcc 0.9700 TestAcc 0.8979 0.9100
epoch 2300 LossPred 0.1320 LossAtt 0.3960 TrainAcc 0.9700 TestAcc 0.8964 0.9300
epoch 2400 LossPred 0.1525 LossAtt 0.4291 TrainAcc 0.9600 TestAcc 0.9132 0.9400
epoch 2500 LossPred 0.1313 LossAtt 0.4026 TrainAcc 0.9700 TestAcc 0.9029 0.9450
Optimization Finished!
********** replication  30  **********
epoch   0 LossPred 1.2422 LossAtt 1.0136 TrainAcc 0.4500 TestAcc 0.5325 0.4700
epoch 100 LossPred 0.9555 LossAtt 0.4806 TrainAcc 0.6100 TestAcc 0.5901 0.6100
epoch 200 LossPred 0.8840 LossAtt 0.4881 TrainAcc 0.6900 TestAcc 0.6261 0.6750
epoch 300 LossPred 0.7156 LossAtt 0.5804 TrainAcc 0.8100 TestAcc 0.6722 0.7950
epoch 400 LossPred 0.3725 LossAtt 0.5991 TrainAcc 0.8800 TestAcc 0.8368 0.8650
epoch 500 LossPred 0.3609 LossAtt 0.5267 TrainAcc 0.8700 TestAcc 0.8348 0.8800
epoch 600 LossPred 0.2770 LossAtt 0.4528 TrainAcc 0.9100 TestAcc 0.8789 0.8900
epoch 700 LossPred 0.2850 LossAtt 0.4200 TrainAcc 0.9000 TestAcc 0.8834 0.8850
epoch 800 LossPred 0.2216 LossAtt 0.3924 TrainAcc 0.9200 TestAcc 0.8834 0.9100
epoch 900 LossPred 0.2110 LossAtt 0.3641 TrainAcc 0.9300 TestAcc 0.8926 0.9050
epoch 1000 LossPred 0.1978 LossAtt 0.3593 TrainAcc 0.9200 TestAcc 0.8914 0.9000
epoch 1100 LossPred 0.2292 LossAtt 0.3553 TrainAcc 0.8900 TestAcc 0.8936 0.8900
epoch 1200 LossPred 0.1718 LossAtt 0.3478 TrainAcc 0.9500 TestAcc 0.9059 0.9050
epoch 1300 LossPred 0.1805 LossAtt 0.3604 TrainAcc 0.9300 TestAcc 0.8961 0.9050
epoch 1400 LossPred 0.2063 LossAtt 0.3621 TrainAcc 0.9100 TestAcc 0.8781 0.9000
epoch 1500 LossPred 0.1564 LossAtt 0.3499 TrainAcc 0.9400 TestAcc 0.9194 0.9200
epoch 1600 LossPred 0.1661 LossAtt 0.3694 TrainAcc 0.9400 TestAcc 0.8931 0.9150
epoch 1700 LossPred 0.0777 LossAtt 0.3447 TrainAcc 1.0000 TestAcc 0.9379 0.9350
Optimization Finished!
********** replication  31  **********
epoch   0 LossPred 1.0650 LossAtt 1.0071 TrainAcc 0.5900 TestAcc 0.5716 0.5850
epoch 100 LossPred 0.8901 LossAtt 0.4050 TrainAcc 0.6400 TestAcc 0.5968 0.6400
epoch 200 LossPred 0.7377 LossAtt 0.4428 TrainAcc 0.7900 TestAcc 0.6944 0.7600
epoch 300 LossPred 0.5072 LossAtt 0.4689 TrainAcc 0.8500 TestAcc 0.8038 0.8050
epoch 400 LossPred 0.3594 LossAtt 0.4689 TrainAcc 0.8800 TestAcc 0.8493 0.8450
epoch 500 LossPred 0.2736 LossAtt 0.4715 TrainAcc 0.9200 TestAcc 0.8686 0.8850
epoch 600 LossPred 0.2141 LossAtt 0.4597 TrainAcc 0.9500 TestAcc 0.9012 0.9250
epoch 700 LossPred 0.2629 LossAtt 0.4475 TrainAcc 0.8900 TestAcc 0.8774 0.8850
epoch 800 LossPred 0.2441 LossAtt 0.4245 TrainAcc 0.9200 TestAcc 0.8799 0.9100
epoch 900 LossPred 0.2003 LossAtt 0.4510 TrainAcc 0.9700 TestAcc 0.8999 0.9300
epoch 1000 LossPred 0.5047 LossAtt 0.4260 TrainAcc 0.8400 TestAcc 0.7898 0.8150
epoch 1100 LossPred 0.2013 LossAtt 0.4396 TrainAcc 0.9400 TestAcc 0.8871 0.9100
epoch 1200 LossPred 0.1610 LossAtt 0.4235 TrainAcc 0.9600 TestAcc 0.8879 0.9150
epoch 1300 LossPred 0.1971 LossAtt 0.4425 TrainAcc 0.9300 TestAcc 0.8781 0.9150
epoch 1400 LossPred 0.1738 LossAtt 0.4348 TrainAcc 0.9600 TestAcc 0.8786 0.9200
epoch 1500 LossPred 0.1712 LossAtt 0.4291 TrainAcc 0.9400 TestAcc 0.8714 0.9200
epoch 1600 LossPred 0.2024 LossAtt 0.4412 TrainAcc 0.9200 TestAcc 0.8651 0.9200
epoch 1700 LossPred 0.2676 LossAtt 0.4448 TrainAcc 0.9100 TestAcc 0.8614 0.9200
epoch 1800 LossPred 0.1460 LossAtt 0.4630 TrainAcc 0.9700 TestAcc 0.8761 0.9300
epoch 1900 LossPred 0.1507 LossAtt 0.4427 TrainAcc 0.9700 TestAcc 0.8731 0.9250
epoch 2000 LossPred 0.2366 LossAtt 0.4767 TrainAcc 0.9100 TestAcc 0.8616 0.9000
epoch 2100 LossPred 0.1493 LossAtt 0.4796 TrainAcc 0.9600 TestAcc 0.8671 0.9300
epoch 2200 LossPred 0.1649 LossAtt 0.4754 TrainAcc 0.9500 TestAcc 0.8649 0.9350
epoch 2300 LossPred 0.1571 LossAtt 0.4746 TrainAcc 0.9600 TestAcc 0.8751 0.9400
epoch 2400 LossPred 0.1718 LossAtt 0.4565 TrainAcc 0.9600 TestAcc 0.8651 0.9200
epoch 2500 LossPred 0.1671 LossAtt 0.4400 TrainAcc 0.9600 TestAcc 0.8629 0.9350
Optimization Finished!
********** replication  32  **********
epoch   0 LossPred 1.0679 LossAtt 1.0211 TrainAcc 0.4900 TestAcc 0.5388 0.5150
epoch 100 LossPred 0.9251 LossAtt 0.3518 TrainAcc 0.6600 TestAcc 0.6011 0.6700
epoch 200 LossPred 0.8855 LossAtt 0.3295 TrainAcc 0.6900 TestAcc 0.6336 0.6350
epoch 300 LossPred 0.3393 LossAtt 0.3124 TrainAcc 0.9200 TestAcc 0.8821 0.8900
epoch 400 LossPred 0.2779 LossAtt 0.2865 TrainAcc 0.9000 TestAcc 0.8774 0.9000
epoch 500 LossPred 0.2683 LossAtt 0.2610 TrainAcc 0.9000 TestAcc 0.8746 0.9000
epoch 600 LossPred 0.2640 LossAtt 0.2679 TrainAcc 0.9200 TestAcc 0.8794 0.9000
epoch 700 LossPred 0.2579 LossAtt 0.2762 TrainAcc 0.9100 TestAcc 0.8816 0.8950
epoch 800 LossPred 0.2548 LossAtt 0.2735 TrainAcc 0.9100 TestAcc 0.8969 0.9150
epoch 900 LossPred 0.2489 LossAtt 0.2450 TrainAcc 0.9000 TestAcc 0.8939 0.9150
epoch 1000 LossPred 0.2361 LossAtt 0.2617 TrainAcc 0.9200 TestAcc 0.8909 0.9100
epoch 1100 LossPred 0.2115 LossAtt 0.2548 TrainAcc 0.9300 TestAcc 0.9109 0.9150
epoch 1200 LossPred 0.2102 LossAtt 0.2599 TrainAcc 0.9300 TestAcc 0.9197 0.9100
epoch 1300 LossPred 0.1914 LossAtt 0.2628 TrainAcc 0.9100 TestAcc 0.9047 0.9050
epoch 1400 LossPred 0.2288 LossAtt 0.2475 TrainAcc 0.9200 TestAcc 0.9082 0.9100
epoch 1500 LossPred 0.2361 LossAtt 0.2640 TrainAcc 0.9200 TestAcc 0.9059 0.9050
epoch 1600 LossPred 0.2030 LossAtt 0.2511 TrainAcc 0.9200 TestAcc 0.9234 0.9150
epoch 1700 LossPred 0.4326 LossAtt 0.2484 TrainAcc 0.8300 TestAcc 0.8188 0.8400
epoch 1800 LossPred 0.1999 LossAtt 0.2375 TrainAcc 0.9500 TestAcc 0.9530 0.9300
epoch 1900 LossPred 0.2678 LossAtt 0.2353 TrainAcc 0.9100 TestAcc 0.8984 0.8700
epoch 2000 LossPred 0.1650 LossAtt 0.2359 TrainAcc 0.9500 TestAcc 0.9302 0.9200
epoch 2100 LossPred 0.1461 LossAtt 0.2462 TrainAcc 0.9500 TestAcc 0.9362 0.9200
epoch 2200 LossPred 0.3023 LossAtt 0.2352 TrainAcc 0.8900 TestAcc 0.8711 0.8900
epoch 2300 LossPred 0.3247 LossAtt 0.2376 TrainAcc 0.8900 TestAcc 0.8699 0.8550
epoch 2400 LossPred 0.4358 LossAtt 0.2531 TrainAcc 0.8400 TestAcc 0.8166 0.8450
epoch 2500 LossPred 0.3252 LossAtt 0.2568 TrainAcc 0.8900 TestAcc 0.8686 0.8550
Optimization Finished!
********** replication  33  **********
epoch   0 LossPred 1.1696 LossAtt 1.0075 TrainAcc 0.5500 TestAcc 0.5741 0.5450
epoch 100 LossPred 0.9527 LossAtt 0.5273 TrainAcc 0.6200 TestAcc 0.6046 0.6200
epoch 200 LossPred 0.8815 LossAtt 0.4785 TrainAcc 0.6300 TestAcc 0.6014 0.6350
epoch 300 LossPred 0.6297 LossAtt 0.4610 TrainAcc 0.8100 TestAcc 0.7888 0.8150
epoch 400 LossPred 0.3481 LossAtt 0.3627 TrainAcc 0.9100 TestAcc 0.8741 0.8800
epoch 500 LossPred 0.3293 LossAtt 0.3354 TrainAcc 0.9100 TestAcc 0.8881 0.8800
epoch 600 LossPred 0.3211 LossAtt 0.3194 TrainAcc 0.9100 TestAcc 0.8951 0.8900
epoch 700 LossPred 0.3185 LossAtt 0.3255 TrainAcc 0.9100 TestAcc 0.8929 0.8800
epoch 800 LossPred 0.3146 LossAtt 0.3125 TrainAcc 0.9100 TestAcc 0.8981 0.8900
epoch 900 LossPred 0.3129 LossAtt 0.3042 TrainAcc 0.9100 TestAcc 0.8944 0.9000
epoch 1000 LossPred 0.3088 LossAtt 0.3080 TrainAcc 0.9100 TestAcc 0.9072 0.8950
epoch 1100 LossPred 0.3036 LossAtt 0.3130 TrainAcc 0.9100 TestAcc 0.9149 0.9050
epoch 1200 LossPred 0.2896 LossAtt 0.2828 TrainAcc 0.9100 TestAcc 0.9299 0.9100
epoch 1300 LossPred 0.2209 LossAtt 0.2810 TrainAcc 0.9400 TestAcc 0.9665 0.9250
epoch 1400 LossPred 0.2415 LossAtt 0.2765 TrainAcc 0.9100 TestAcc 0.9362 0.9000
epoch 1500 LossPred 0.1358 LossAtt 0.2651 TrainAcc 0.9600 TestAcc 0.9444 0.9500
epoch 1600 LossPred 0.1461 LossAtt 0.2778 TrainAcc 0.9600 TestAcc 0.9615 0.9150
epoch 1700 LossPred 0.2696 LossAtt 0.2540 TrainAcc 0.9100 TestAcc 0.8896 0.9050
epoch 1800 LossPred 0.3157 LossAtt 0.2624 TrainAcc 0.8600 TestAcc 0.8699 0.8600
epoch 1900 LossPred 0.1964 LossAtt 0.2754 TrainAcc 0.9500 TestAcc 0.9157 0.9200
epoch 2000 LossPred 0.0998 LossAtt 0.2672 TrainAcc 0.9800 TestAcc 0.9610 0.9550
epoch 2100 LossPred 0.0813 LossAtt 0.2453 TrainAcc 0.9900 TestAcc 0.9712 0.9700
epoch 2200 LossPred 0.0975 LossAtt 0.2503 TrainAcc 0.9600 TestAcc 0.9522 0.9700
epoch 2300 LossPred 0.1982 LossAtt 0.2451 TrainAcc 0.9200 TestAcc 0.9127 0.9250
epoch 2400 LossPred 0.1398 LossAtt 0.2664 TrainAcc 0.9300 TestAcc 0.9347 0.9550
epoch 2500 LossPred 0.1301 LossAtt 0.2455 TrainAcc 0.9300 TestAcc 0.9389 0.9550
Optimization Finished!
********** replication  34  **********
epoch   0 LossPred 1.0779 LossAtt 1.0066 TrainAcc 0.4600 TestAcc 0.4955 0.4600
epoch 100 LossPred 0.8858 LossAtt 0.3762 TrainAcc 0.6500 TestAcc 0.6056 0.6500
epoch 200 LossPred 0.7320 LossAtt 0.4669 TrainAcc 0.8100 TestAcc 0.6957 0.7550
epoch 300 LossPred 0.4174 LossAtt 0.4975 TrainAcc 0.8800 TestAcc 0.8604 0.8700
epoch 400 LossPred 0.2974 LossAtt 0.5164 TrainAcc 0.9000 TestAcc 0.8966 0.8700
epoch 500 LossPred 0.2548 LossAtt 0.5073 TrainAcc 0.9200 TestAcc 0.9034 0.8800
epoch 600 LossPred 0.2393 LossAtt 0.5099 TrainAcc 0.9200 TestAcc 0.9029 0.8950
epoch 700 LossPred 0.2049 LossAtt 0.5214 TrainAcc 0.9400 TestAcc 0.8884 0.8950
epoch 800 LossPred 0.2011 LossAtt 0.5236 TrainAcc 0.9400 TestAcc 0.8809 0.8950
epoch 900 LossPred 0.1864 LossAtt 0.5156 TrainAcc 0.9400 TestAcc 0.9059 0.9150
epoch 1000 LossPred 0.2014 LossAtt 0.5134 TrainAcc 0.9500 TestAcc 0.8591 0.9050
epoch 1100 LossPred 0.1467 LossAtt 0.5163 TrainAcc 0.9600 TestAcc 0.9067 0.9100
epoch 1200 LossPred 0.1785 LossAtt 0.5029 TrainAcc 0.9400 TestAcc 0.9334 0.9400
epoch 1300 LossPred 0.3413 LossAtt 0.4578 TrainAcc 0.8700 TestAcc 0.8378 0.8500
epoch 1400 LossPred 0.3783 LossAtt 0.4667 TrainAcc 0.8900 TestAcc 0.8333 0.8650
epoch 1500 LossPred 0.3954 LossAtt 0.4444 TrainAcc 0.8600 TestAcc 0.8268 0.8450
epoch 1600 LossPred 0.1674 LossAtt 0.4409 TrainAcc 0.9400 TestAcc 0.9167 0.9350
epoch 1700 LossPred 0.1755 LossAtt 0.4475 TrainAcc 0.9300 TestAcc 0.9249 0.9350
epoch 1800 LossPred 0.1487 LossAtt 0.4383 TrainAcc 0.9600 TestAcc 0.9059 0.9300
epoch 1900 LossPred 0.1507 LossAtt 0.4686 TrainAcc 0.9700 TestAcc 0.9284 0.9550
epoch 2000 LossPred 0.2748 LossAtt 0.4309 TrainAcc 0.9200 TestAcc 0.8721 0.8750
epoch 2100 LossPred 0.1583 LossAtt 0.4303 TrainAcc 0.9600 TestAcc 0.9322 0.9550
epoch 2200 LossPred 0.2226 LossAtt 0.4314 TrainAcc 0.9300 TestAcc 0.8981 0.8950
epoch 2300 LossPred 0.1396 LossAtt 0.4499 TrainAcc 0.9700 TestAcc 0.9264 0.9500
epoch 2400 LossPred 0.1413 LossAtt 0.4400 TrainAcc 0.9600 TestAcc 0.9322 0.9450
epoch 2500 LossPred 0.1810 LossAtt 0.4767 TrainAcc 0.9300 TestAcc 0.9152 0.9250
Optimization Finished!
********** replication  35  **********
epoch   0 LossPred 1.4435 LossAtt 1.0319 TrainAcc 0.4900 TestAcc 0.4329 0.4550
epoch 100 LossPred 1.0831 LossAtt 0.4806 TrainAcc 0.4800 TestAcc 0.4354 0.5100
epoch 200 LossPred 0.9582 LossAtt 0.4622 TrainAcc 0.6400 TestAcc 0.5210 0.6450
epoch 300 LossPred 0.8548 LossAtt 0.4816 TrainAcc 0.6800 TestAcc 0.5160 0.6750
epoch 400 LossPred 0.8031 LossAtt 0.4211 TrainAcc 0.7000 TestAcc 0.5573 0.6950
epoch 500 LossPred 0.7669 LossAtt 0.4140 TrainAcc 0.7300 TestAcc 0.5546 0.7050
epoch 600 LossPred 0.7246 LossAtt 0.4267 TrainAcc 0.7300 TestAcc 0.5506 0.7150
epoch 700 LossPred 0.6985 LossAtt 0.4227 TrainAcc 0.7300 TestAcc 0.5483 0.7200
epoch 800 LossPred 0.6881 LossAtt 0.4482 TrainAcc 0.7700 TestAcc 0.5488 0.7100
epoch 900 LossPred 0.6868 LossAtt 0.4755 TrainAcc 0.7500 TestAcc 0.5453 0.7400
epoch 1000 LossPred 0.6462 LossAtt 0.5451 TrainAcc 0.7700 TestAcc 0.5551 0.7500
epoch 1100 LossPred 0.6174 LossAtt 0.5746 TrainAcc 0.8000 TestAcc 0.5631 0.7650
epoch 1200 LossPred 0.6962 LossAtt 0.5278 TrainAcc 0.7600 TestAcc 0.5651 0.7500
epoch 1300 LossPred 0.5719 LossAtt 0.5187 TrainAcc 0.8100 TestAcc 0.5831 0.7600
epoch 1400 LossPred 0.5597 LossAtt 0.5438 TrainAcc 0.8000 TestAcc 0.5883 0.7750
epoch 1500 LossPred 0.5196 LossAtt 0.5375 TrainAcc 0.8100 TestAcc 0.5986 0.7600
epoch 1600 LossPred 0.4758 LossAtt 0.5533 TrainAcc 0.8500 TestAcc 0.6086 0.7850
epoch 1700 LossPred 0.4386 LossAtt 0.5360 TrainAcc 0.8500 TestAcc 0.6504 0.8300
epoch 1800 LossPred 0.4658 LossAtt 0.5503 TrainAcc 0.8600 TestAcc 0.6637 0.8000
epoch 1900 LossPred 0.3951 LossAtt 0.5395 TrainAcc 0.8900 TestAcc 0.6744 0.8150
epoch 2000 LossPred 0.3860 LossAtt 0.5565 TrainAcc 0.8800 TestAcc 0.6934 0.8250
epoch 2100 LossPred 0.4217 LossAtt 0.5329 TrainAcc 0.8700 TestAcc 0.6799 0.7750
epoch 2200 LossPred 0.4868 LossAtt 0.5361 TrainAcc 0.8000 TestAcc 0.6737 0.7700
epoch 2300 LossPred 0.5651 LossAtt 0.5171 TrainAcc 0.8200 TestAcc 0.6862 0.8500
epoch 2400 LossPred 0.3858 LossAtt 0.5397 TrainAcc 0.8700 TestAcc 0.7087 0.8250
epoch 2500 LossPred 0.4223 LossAtt 0.5169 TrainAcc 0.8600 TestAcc 0.6909 0.7850
Optimization Finished!
********** replication  36  **********
epoch   0 LossPred 1.1843 LossAtt 1.0254 TrainAcc 0.5700 TestAcc 0.5818 0.5550
epoch 100 LossPred 0.9301 LossAtt 0.4169 TrainAcc 0.5700 TestAcc 0.6064 0.6000
epoch 200 LossPred 0.8933 LossAtt 0.4369 TrainAcc 0.6400 TestAcc 0.6066 0.6400
epoch 300 LossPred 0.8605 LossAtt 0.5008 TrainAcc 0.6600 TestAcc 0.6134 0.6400
epoch 400 LossPred 0.8444 LossAtt 0.4984 TrainAcc 0.6700 TestAcc 0.6136 0.6700
epoch 500 LossPred 0.8270 LossAtt 0.5299 TrainAcc 0.6700 TestAcc 0.6151 0.6700
epoch 600 LossPred 0.7601 LossAtt 0.5184 TrainAcc 0.7300 TestAcc 0.6101 0.7150
epoch 700 LossPred 0.4836 LossAtt 0.3773 TrainAcc 0.8400 TestAcc 0.7968 0.8850
epoch 800 LossPred 0.4721 LossAtt 0.3533 TrainAcc 0.8300 TestAcc 0.7885 0.8400
epoch 900 LossPred 0.4474 LossAtt 0.3749 TrainAcc 0.8600 TestAcc 0.7963 0.8700
epoch 1000 LossPred 0.4614 LossAtt 0.3564 TrainAcc 0.8400 TestAcc 0.7963 0.8600
epoch 1100 LossPred 0.4442 LossAtt 0.3416 TrainAcc 0.8700 TestAcc 0.7970 0.8700
epoch 1200 LossPred 0.4571 LossAtt 0.3319 TrainAcc 0.8300 TestAcc 0.7960 0.8600
epoch 1300 LossPred 0.4461 LossAtt 0.3651 TrainAcc 0.8600 TestAcc 0.7988 0.8800
epoch 1400 LossPred 0.4485 LossAtt 0.3312 TrainAcc 0.8500 TestAcc 0.7798 0.8650
epoch 1500 LossPred 0.4443 LossAtt 0.3417 TrainAcc 0.8500 TestAcc 0.7998 0.8750
epoch 1600 LossPred 0.4308 LossAtt 0.3237 TrainAcc 0.8800 TestAcc 0.8008 0.8850
epoch 1700 LossPred 0.4390 LossAtt 0.3515 TrainAcc 0.8700 TestAcc 0.8056 0.8750
epoch 1800 LossPred 0.4326 LossAtt 0.3477 TrainAcc 0.8800 TestAcc 0.8013 0.8800
epoch 1900 LossPred 0.4017 LossAtt 0.3526 TrainAcc 0.8700 TestAcc 0.7825 0.8550
epoch 2000 LossPred 0.3990 LossAtt 0.3719 TrainAcc 0.8500 TestAcc 0.7715 0.8600
epoch 2100 LossPred 0.3730 LossAtt 0.3653 TrainAcc 0.8700 TestAcc 0.7798 0.8850
epoch 2200 LossPred 0.3877 LossAtt 0.3754 TrainAcc 0.8800 TestAcc 0.8016 0.8800
epoch 2300 LossPred 0.3644 LossAtt 0.3912 TrainAcc 0.8900 TestAcc 0.8076 0.9000
epoch 2400 LossPred 0.3675 LossAtt 0.3947 TrainAcc 0.8700 TestAcc 0.8061 0.8800
epoch 2500 LossPred 0.3517 LossAtt 0.4057 TrainAcc 0.8900 TestAcc 0.8123 0.9000
Optimization Finished!
********** replication  37  **********
epoch   0 LossPred 0.9849 LossAtt 1.0083 TrainAcc 0.5900 TestAcc 0.5058 0.5900
epoch 100 LossPred 0.9325 LossAtt 0.3932 TrainAcc 0.5900 TestAcc 0.6084 0.6100
epoch 200 LossPred 0.8408 LossAtt 0.3829 TrainAcc 0.6700 TestAcc 0.6527 0.6700
epoch 300 LossPred 0.3829 LossAtt 0.4205 TrainAcc 0.8800 TestAcc 0.8231 0.8550
epoch 400 LossPred 0.3606 LossAtt 0.4296 TrainAcc 0.8900 TestAcc 0.8208 0.8400
epoch 500 LossPred 0.3565 LossAtt 0.3657 TrainAcc 0.8800 TestAcc 0.8461 0.8750
epoch 600 LossPred 0.3737 LossAtt 0.3295 TrainAcc 0.8800 TestAcc 0.8511 0.8850
epoch 700 LossPred 0.3637 LossAtt 0.3034 TrainAcc 0.8800 TestAcc 0.8306 0.8650
epoch 800 LossPred 0.3783 LossAtt 0.3305 TrainAcc 0.8800 TestAcc 0.8478 0.8700
epoch 900 LossPred 0.3527 LossAtt 0.3318 TrainAcc 0.8800 TestAcc 0.8391 0.8600
epoch 1000 LossPred 0.3546 LossAtt 0.2850 TrainAcc 0.8900 TestAcc 0.8296 0.8450
epoch 1100 LossPred 0.3465 LossAtt 0.3140 TrainAcc 0.8900 TestAcc 0.8481 0.8750
epoch 1200 LossPred 0.3470 LossAtt 0.3125 TrainAcc 0.8900 TestAcc 0.8554 0.8800
epoch 1300 LossPred 0.3511 LossAtt 0.3018 TrainAcc 0.8900 TestAcc 0.8391 0.8550
epoch 1400 LossPred 0.3423 LossAtt 0.2934 TrainAcc 0.8900 TestAcc 0.8641 0.8900
epoch 1500 LossPred 0.1919 LossAtt 0.2908 TrainAcc 0.9400 TestAcc 0.8879 0.9100
epoch 1600 LossPred 0.2163 LossAtt 0.2943 TrainAcc 0.9200 TestAcc 0.8939 0.9200
epoch 1700 LossPred 0.1775 LossAtt 0.2989 TrainAcc 0.9500 TestAcc 0.8849 0.9200
epoch 1800 LossPred 0.1367 LossAtt 0.2952 TrainAcc 0.9500 TestAcc 0.8991 0.9300
epoch 1900 LossPred 0.2488 LossAtt 0.3029 TrainAcc 0.9300 TestAcc 0.8709 0.9350
epoch 2000 LossPred 0.1320 LossAtt 0.2859 TrainAcc 0.9700 TestAcc 0.8996 0.9250
epoch 2100 LossPred 0.1527 LossAtt 0.2859 TrainAcc 0.9500 TestAcc 0.8954 0.9350
epoch 2200 LossPred 0.1269 LossAtt 0.2868 TrainAcc 0.9600 TestAcc 0.9004 0.9500
epoch 2300 LossPred 0.1409 LossAtt 0.2690 TrainAcc 0.9600 TestAcc 0.8971 0.9450
epoch 2400 LossPred 0.1613 LossAtt 0.2688 TrainAcc 0.9600 TestAcc 0.8966 0.9300
epoch 2500 LossPred 0.1576 LossAtt 0.2817 TrainAcc 0.9600 TestAcc 0.9057 0.9350
Optimization Finished!
********** replication  38  **********
epoch   0 LossPred 1.0808 LossAtt 1.0079 TrainAcc 0.5600 TestAcc 0.5448 0.5500
epoch 100 LossPred 0.9484 LossAtt 0.3682 TrainAcc 0.6200 TestAcc 0.6256 0.6200
epoch 200 LossPred 0.9303 LossAtt 0.3576 TrainAcc 0.6200 TestAcc 0.6256 0.6200
epoch 300 LossPred 0.8903 LossAtt 0.3392 TrainAcc 0.6400 TestAcc 0.5833 0.6450
epoch 400 LossPred 0.8521 LossAtt 0.4239 TrainAcc 0.6600 TestAcc 0.6151 0.6550
epoch 500 LossPred 0.2387 LossAtt 0.5086 TrainAcc 0.9300 TestAcc 0.8554 0.9350
epoch 600 LossPred 0.1877 LossAtt 0.4473 TrainAcc 0.9500 TestAcc 0.8739 0.9550
epoch 700 LossPred 0.1222 LossAtt 0.4296 TrainAcc 0.9500 TestAcc 0.8794 0.9550
epoch 800 LossPred 0.1015 LossAtt 0.4071 TrainAcc 0.9600 TestAcc 0.8869 0.9550
epoch 900 LossPred 0.1750 LossAtt 0.4108 TrainAcc 0.9400 TestAcc 0.8836 0.9400
epoch 1000 LossPred 0.0792 LossAtt 0.4097 TrainAcc 1.0000 TestAcc 0.9067 0.9950
Optimization Finished!
********** replication  39  **********
epoch   0 LossPred 1.2126 LossAtt 0.9895 TrainAcc 0.4400 TestAcc 0.4297 0.4550
epoch 100 LossPred 0.9768 LossAtt 0.3680 TrainAcc 0.5500 TestAcc 0.4590 0.5700
epoch 200 LossPred 0.9257 LossAtt 0.3127 TrainAcc 0.6100 TestAcc 0.6281 0.6000
epoch 300 LossPred 0.8838 LossAtt 0.3406 TrainAcc 0.6200 TestAcc 0.6494 0.6350
epoch 400 LossPred 0.3735 LossAtt 0.4509 TrainAcc 0.9500 TestAcc 0.8771 0.9000
epoch 500 LossPred 0.2441 LossAtt 0.4394 TrainAcc 0.9600 TestAcc 0.8826 0.9400
epoch 600 LossPred 0.2056 LossAtt 0.4353 TrainAcc 0.9600 TestAcc 0.8791 0.9400
epoch 700 LossPred 0.1898 LossAtt 0.4615 TrainAcc 0.9600 TestAcc 0.8841 0.9450
epoch 800 LossPred 0.1789 LossAtt 0.4308 TrainAcc 0.9600 TestAcc 0.8904 0.9500
epoch 900 LossPred 0.1767 LossAtt 0.4276 TrainAcc 0.9600 TestAcc 0.8941 0.9450
epoch 1000 LossPred 0.1728 LossAtt 0.4051 TrainAcc 0.9400 TestAcc 0.8809 0.9400
epoch 1100 LossPred 0.1613 LossAtt 0.3577 TrainAcc 0.9400 TestAcc 0.8856 0.9450
epoch 1200 LossPred 0.1969 LossAtt 0.3708 TrainAcc 0.9600 TestAcc 0.9124 0.9450
epoch 1300 LossPred 0.1379 LossAtt 0.3392 TrainAcc 0.9500 TestAcc 0.9229 0.9650
epoch 1400 LossPred 0.1341 LossAtt 0.3435 TrainAcc 0.9800 TestAcc 0.9224 0.9650
epoch 1500 LossPred 0.1753 LossAtt 0.3650 TrainAcc 0.9400 TestAcc 0.8881 0.9550
epoch 1600 LossPred 0.1971 LossAtt 0.3559 TrainAcc 0.9400 TestAcc 0.8779 0.9500
epoch 1700 LossPred 0.1148 LossAtt 0.3449 TrainAcc 0.9800 TestAcc 0.9289 0.9750
epoch 1800 LossPred 0.1547 LossAtt 0.3633 TrainAcc 0.9800 TestAcc 0.8991 0.9650
epoch 1900 LossPred 0.1056 LossAtt 0.3563 TrainAcc 0.9800 TestAcc 0.9354 0.9700
epoch 2000 LossPred 0.1271 LossAtt 0.3557 TrainAcc 0.9900 TestAcc 0.9107 0.9850
epoch 2100 LossPred 0.0948 LossAtt 0.3730 TrainAcc 0.9800 TestAcc 0.9399 0.9800
epoch 2200 LossPred 0.1272 LossAtt 0.3883 TrainAcc 0.9700 TestAcc 0.9057 0.9650
epoch 2300 LossPred 0.1353 LossAtt 0.3677 TrainAcc 0.9700 TestAcc 0.9219 0.9700
epoch 2400 LossPred 0.1150 LossAtt 0.3963 TrainAcc 0.9600 TestAcc 0.9224 0.9550
epoch 2500 LossPred 0.1365 LossAtt 0.3854 TrainAcc 0.9600 TestAcc 0.9097 0.9500
Optimization Finished!
********** replication  40  **********
epoch   0 LossPred 1.0702 LossAtt 1.0233 TrainAcc 0.6000 TestAcc 0.6011 0.5950
epoch 100 LossPred 0.9603 LossAtt 0.3354 TrainAcc 0.6000 TestAcc 0.6041 0.6000
epoch 200 LossPred 0.9599 LossAtt 0.1779 TrainAcc 0.6000 TestAcc 0.6041 0.6000
epoch 300 LossPred 0.9587 LossAtt 0.1621 TrainAcc 0.6000 TestAcc 0.6041 0.6000
epoch 400 LossPred 0.9582 LossAtt 0.2076 TrainAcc 0.6000 TestAcc 0.6041 0.6000
epoch 500 LossPred 0.9579 LossAtt 0.2324 TrainAcc 0.6000 TestAcc 0.6041 0.6000
epoch 600 LossPred 0.9406 LossAtt 0.3292 TrainAcc 0.6100 TestAcc 0.6797 0.6300
epoch 700 LossPred 0.3532 LossAtt 0.2694 TrainAcc 0.8600 TestAcc 0.8826 0.8600
epoch 800 LossPred 0.3021 LossAtt 0.2854 TrainAcc 0.8800 TestAcc 0.9059 0.8600
epoch 900 LossPred 0.2376 LossAtt 0.2703 TrainAcc 0.9300 TestAcc 0.9072 0.8850
epoch 1000 LossPred 0.4181 LossAtt 0.2784 TrainAcc 0.8700 TestAcc 0.8233 0.8450
epoch 1100 LossPred 0.3957 LossAtt 0.2703 TrainAcc 0.8500 TestAcc 0.8896 0.8500
epoch 1200 LossPred 0.4002 LossAtt 0.2868 TrainAcc 0.8600 TestAcc 0.8569 0.8550
epoch 1300 LossPred 0.2646 LossAtt 0.2727 TrainAcc 0.9000 TestAcc 0.9337 0.8850
epoch 1400 LossPred 0.3859 LossAtt 0.2523 TrainAcc 0.8600 TestAcc 0.8471 0.8750
epoch 1500 LossPred 0.3086 LossAtt 0.2842 TrainAcc 0.8800 TestAcc 0.9097 0.8850
epoch 1600 LossPred 0.2668 LossAtt 0.2545 TrainAcc 0.8900 TestAcc 0.9252 0.8800
epoch 1700 LossPred 0.4102 LossAtt 0.2447 TrainAcc 0.8500 TestAcc 0.8691 0.8600
epoch 1800 LossPred 0.2138 LossAtt 0.2657 TrainAcc 0.9200 TestAcc 0.9087 0.8800
epoch 1900 LossPred 0.1929 LossAtt 0.2587 TrainAcc 0.9300 TestAcc 0.9277 0.9000
epoch 2000 LossPred 0.1866 LossAtt 0.2527 TrainAcc 0.9400 TestAcc 0.9172 0.9050
epoch 2100 LossPred 0.1689 LossAtt 0.2351 TrainAcc 0.9400 TestAcc 0.9592 0.8950
epoch 2200 LossPred 0.2261 LossAtt 0.2577 TrainAcc 0.9100 TestAcc 0.9314 0.9050
epoch 2300 LossPred 0.1843 LossAtt 0.2372 TrainAcc 0.9400 TestAcc 0.8999 0.8850
epoch 2400 LossPred 0.1543 LossAtt 0.2435 TrainAcc 0.9600 TestAcc 0.9497 0.9100
epoch 2500 LossPred 0.1472 LossAtt 0.2534 TrainAcc 0.9600 TestAcc 0.9429 0.9000
Optimization Finished!
********** replication  41  **********
epoch   0 LossPred 0.9601 LossAtt 0.9986 TrainAcc 0.6200 TestAcc 0.4952 0.6200
epoch 100 LossPred 0.8503 LossAtt 0.5330 TrainAcc 0.6400 TestAcc 0.6241 0.6550
epoch 200 LossPred 0.6788 LossAtt 0.5939 TrainAcc 0.8100 TestAcc 0.7295 0.8100
epoch 300 LossPred 0.3139 LossAtt 0.5540 TrainAcc 0.8900 TestAcc 0.9019 0.8850
epoch 400 LossPred 0.5323 LossAtt 0.5203 TrainAcc 0.8500 TestAcc 0.7773 0.8500
epoch 500 LossPred 0.3998 LossAtt 0.5205 TrainAcc 0.8800 TestAcc 0.8283 0.8850
epoch 600 LossPred 0.3127 LossAtt 0.5328 TrainAcc 0.9200 TestAcc 0.8651 0.9050
epoch 700 LossPred 0.7184 LossAtt 0.4663 TrainAcc 0.7700 TestAcc 0.7092 0.8000
epoch 800 LossPred 0.4566 LossAtt 0.4948 TrainAcc 0.8200 TestAcc 0.7910 0.8400
epoch 900 LossPred 0.2930 LossAtt 0.5229 TrainAcc 0.9100 TestAcc 0.8749 0.9050
epoch 1000 LossPred 0.1805 LossAtt 0.4993 TrainAcc 0.9400 TestAcc 0.9214 0.9400
epoch 1100 LossPred 0.1427 LossAtt 0.5253 TrainAcc 0.9600 TestAcc 0.9319 0.9550
epoch 1200 LossPred 0.1564 LossAtt 0.5076 TrainAcc 0.9600 TestAcc 0.9347 0.9550
epoch 1300 LossPred 0.1881 LossAtt 0.5142 TrainAcc 0.9500 TestAcc 0.9057 0.9500
epoch 1400 LossPred 0.1122 LossAtt 0.4989 TrainAcc 0.9500 TestAcc 0.9267 0.9600
epoch 1500 LossPred 0.1388 LossAtt 0.5164 TrainAcc 0.9800 TestAcc 0.9327 0.9700
epoch 1600 LossPred 0.1437 LossAtt 0.4615 TrainAcc 0.9600 TestAcc 0.9092 0.9500
epoch 1700 LossPred 0.0977 LossAtt 0.4984 TrainAcc 0.9700 TestAcc 0.9232 0.9600
epoch 1800 LossPred 0.0944 LossAtt 0.4866 TrainAcc 0.9700 TestAcc 0.9152 0.9800
epoch 1900 LossPred 0.0797 LossAtt 0.4774 TrainAcc 0.9700 TestAcc 0.9184 0.9750
epoch 2000 LossPred 0.0697 LossAtt 0.4864 TrainAcc 0.9900 TestAcc 0.9294 0.9800
epoch 2100 LossPred 0.0633 LossAtt 0.4607 TrainAcc 0.9700 TestAcc 0.9194 0.9800
epoch 2200 LossPred 0.0941 LossAtt 0.4717 TrainAcc 0.9800 TestAcc 0.9159 0.9650
epoch 2300 LossPred 0.2598 LossAtt 0.4339 TrainAcc 0.9200 TestAcc 0.8786 0.9250
epoch 2400 LossPred 0.1389 LossAtt 0.4439 TrainAcc 0.9600 TestAcc 0.9004 0.9600
epoch 2500 LossPred 0.0662 LossAtt 0.4758 TrainAcc 0.9800 TestAcc 0.9177 0.9750
Optimization Finished!
********** replication  42  **********
epoch   0 LossPred 1.0488 LossAtt 0.9695 TrainAcc 0.4000 TestAcc 0.3754 0.4100
epoch 100 LossPred 0.8887 LossAtt 0.3680 TrainAcc 0.6500 TestAcc 0.6076 0.6500
epoch 200 LossPred 0.7500 LossAtt 0.4306 TrainAcc 0.7500 TestAcc 0.6774 0.7050
epoch 300 LossPred 0.4744 LossAtt 0.4323 TrainAcc 0.8600 TestAcc 0.8163 0.8550
epoch 400 LossPred 0.4592 LossAtt 0.4129 TrainAcc 0.8700 TestAcc 0.8178 0.8450
epoch 500 LossPred 0.5813 LossAtt 0.4466 TrainAcc 0.7900 TestAcc 0.7515 0.8050
epoch 600 LossPred 0.5535 LossAtt 0.4250 TrainAcc 0.7900 TestAcc 0.7573 0.8150
epoch 700 LossPred 0.6040 LossAtt 0.4089 TrainAcc 0.8000 TestAcc 0.7420 0.7950
epoch 800 LossPred 0.4276 LossAtt 0.3773 TrainAcc 0.8700 TestAcc 0.8118 0.8550
epoch 900 LossPred 0.5303 LossAtt 0.3681 TrainAcc 0.8200 TestAcc 0.7958 0.7950
epoch 1000 LossPred 0.3408 LossAtt 0.3927 TrainAcc 0.9100 TestAcc 0.8614 0.8850
epoch 1100 LossPred 0.5935 LossAtt 0.3588 TrainAcc 0.7800 TestAcc 0.7600 0.7950
epoch 1200 LossPred 0.3198 LossAtt 0.3691 TrainAcc 0.9100 TestAcc 0.8636 0.8850
epoch 1300 LossPred 0.2930 LossAtt 0.3810 TrainAcc 0.8800 TestAcc 0.8731 0.9000
epoch 1400 LossPred 0.2693 LossAtt 0.3627 TrainAcc 0.9400 TestAcc 0.8889 0.9150
epoch 1500 LossPred 0.3115 LossAtt 0.3550 TrainAcc 0.9000 TestAcc 0.8726 0.8950
epoch 1600 LossPred 0.4123 LossAtt 0.3447 TrainAcc 0.8700 TestAcc 0.8311 0.8200
epoch 1700 LossPred 0.3413 LossAtt 0.3404 TrainAcc 0.8800 TestAcc 0.8549 0.8850
epoch 1800 LossPred 0.2363 LossAtt 0.3501 TrainAcc 0.9200 TestAcc 0.9007 0.9200
epoch 1900 LossPred 0.2698 LossAtt 0.3455 TrainAcc 0.9100 TestAcc 0.8879 0.8900
epoch 2000 LossPred 0.2434 LossAtt 0.3387 TrainAcc 0.9000 TestAcc 0.8951 0.9100
epoch 2100 LossPred 0.2442 LossAtt 0.3253 TrainAcc 0.8900 TestAcc 0.8919 0.9100
epoch 2200 LossPred 0.2393 LossAtt 0.3468 TrainAcc 0.9300 TestAcc 0.8879 0.9050
epoch 2300 LossPred 0.2021 LossAtt 0.3251 TrainAcc 0.9500 TestAcc 0.9039 0.9250
epoch 2400 LossPred 0.2045 LossAtt 0.3298 TrainAcc 0.9200 TestAcc 0.9044 0.9150
epoch 2500 LossPred 0.2346 LossAtt 0.3278 TrainAcc 0.9200 TestAcc 0.8891 0.9050
Optimization Finished!
********** replication  43  **********
epoch   0 LossPred 0.9974 LossAtt 1.0307 TrainAcc 0.5600 TestAcc 0.5318 0.5600
epoch 100 LossPred 0.8965 LossAtt 0.4499 TrainAcc 0.6200 TestAcc 0.6011 0.6200
epoch 200 LossPred 0.8674 LossAtt 0.3594 TrainAcc 0.6100 TestAcc 0.6154 0.6150
epoch 300 LossPred 0.4323 LossAtt 0.4198 TrainAcc 0.8500 TestAcc 0.8243 0.8800
epoch 400 LossPred 0.3344 LossAtt 0.4257 TrainAcc 0.9200 TestAcc 0.8949 0.8900
epoch 500 LossPred 0.3099 LossAtt 0.4019 TrainAcc 0.8900 TestAcc 0.9192 0.9000
epoch 600 LossPred 0.3766 LossAtt 0.4005 TrainAcc 0.8500 TestAcc 0.8854 0.8600
epoch 700 LossPred 0.2969 LossAtt 0.4078 TrainAcc 0.9000 TestAcc 0.9177 0.8600
epoch 800 LossPred 0.4250 LossAtt 0.3736 TrainAcc 0.8200 TestAcc 0.8544 0.8400
epoch 900 LossPred 0.4640 LossAtt 0.3905 TrainAcc 0.8400 TestAcc 0.8423 0.8200
epoch 1000 LossPred 0.3780 LossAtt 0.3665 TrainAcc 0.8500 TestAcc 0.8799 0.8650
epoch 1100 LossPred 0.3669 LossAtt 0.3660 TrainAcc 0.8600 TestAcc 0.8881 0.8850
epoch 1200 LossPred 0.3850 LossAtt 0.3533 TrainAcc 0.8400 TestAcc 0.8709 0.8400
epoch 1300 LossPred 0.2567 LossAtt 0.3707 TrainAcc 0.9100 TestAcc 0.9069 0.9200
epoch 1400 LossPred 0.2377 LossAtt 0.3487 TrainAcc 0.9300 TestAcc 0.9239 0.9150
epoch 1500 LossPred 0.2294 LossAtt 0.3450 TrainAcc 0.9300 TestAcc 0.9212 0.9200
epoch 1600 LossPred 0.2600 LossAtt 0.3433 TrainAcc 0.9100 TestAcc 0.9324 0.9000
epoch 1700 LossPred 0.3021 LossAtt 0.3343 TrainAcc 0.9000 TestAcc 0.9054 0.8950
epoch 1800 LossPred 0.2407 LossAtt 0.3411 TrainAcc 0.9300 TestAcc 0.9124 0.9200
epoch 1900 LossPred 0.2782 LossAtt 0.3308 TrainAcc 0.9000 TestAcc 0.8881 0.9050
epoch 2000 LossPred 0.3052 LossAtt 0.3261 TrainAcc 0.9000 TestAcc 0.9009 0.8650
epoch 2100 LossPred 0.2927 LossAtt 0.2909 TrainAcc 0.9200 TestAcc 0.8899 0.8900
epoch 2200 LossPred 0.1883 LossAtt 0.3018 TrainAcc 0.9500 TestAcc 0.9037 0.9300
epoch 2300 LossPred 0.2357 LossAtt 0.2866 TrainAcc 0.9200 TestAcc 0.8889 0.9300
epoch 2400 LossPred 0.3442 LossAtt 0.3027 TrainAcc 0.8800 TestAcc 0.8814 0.8750
epoch 2500 LossPred 0.3268 LossAtt 0.2815 TrainAcc 0.8900 TestAcc 0.8801 0.8850
Optimization Finished!
********** replication  44  **********
epoch   0 LossPred 0.8396 LossAtt 1.0239 TrainAcc 0.6900 TestAcc 0.5698 0.6850
epoch 100 LossPred 0.7689 LossAtt 0.4385 TrainAcc 0.7200 TestAcc 0.6096 0.7250
epoch 200 LossPred 0.7163 LossAtt 0.4144 TrainAcc 0.7700 TestAcc 0.6414 0.7550
epoch 300 LossPred 0.4298 LossAtt 0.4923 TrainAcc 0.8500 TestAcc 0.8278 0.8500
epoch 400 LossPred 0.3422 LossAtt 0.3943 TrainAcc 0.8700 TestAcc 0.8744 0.8350
epoch 500 LossPred 0.2882 LossAtt 0.3771 TrainAcc 0.8800 TestAcc 0.8876 0.8800
epoch 600 LossPred 0.2320 LossAtt 0.3908 TrainAcc 0.9400 TestAcc 0.9017 0.9100
epoch 700 LossPred 0.2868 LossAtt 0.3593 TrainAcc 0.9000 TestAcc 0.8921 0.8850
epoch 800 LossPred 0.2140 LossAtt 0.3465 TrainAcc 0.9200 TestAcc 0.8754 0.8950
epoch 900 LossPred 0.1973 LossAtt 0.3503 TrainAcc 0.9300 TestAcc 0.9179 0.9200
epoch 1000 LossPred 0.2038 LossAtt 0.3480 TrainAcc 0.9300 TestAcc 0.8814 0.9200
epoch 1100 LossPred 0.1662 LossAtt 0.3141 TrainAcc 0.9400 TestAcc 0.9122 0.9200
epoch 1200 LossPred 0.1507 LossAtt 0.3458 TrainAcc 0.9800 TestAcc 0.9122 0.9200
epoch 1300 LossPred 0.1459 LossAtt 0.3228 TrainAcc 0.9700 TestAcc 0.9179 0.9350
epoch 1400 LossPred 0.1986 LossAtt 0.3236 TrainAcc 0.9300 TestAcc 0.9004 0.9100
epoch 1500 LossPred 0.1399 LossAtt 0.2995 TrainAcc 0.9700 TestAcc 0.9284 0.9150
epoch 1600 LossPred 0.1370 LossAtt 0.3057 TrainAcc 0.9600 TestAcc 0.9169 0.9300
epoch 1700 LossPred 0.1605 LossAtt 0.3181 TrainAcc 0.9500 TestAcc 0.9004 0.9200
epoch 1800 LossPred 0.1294 LossAtt 0.3094 TrainAcc 0.9600 TestAcc 0.9204 0.9500
epoch 1900 LossPred 0.1280 LossAtt 0.3017 TrainAcc 0.9700 TestAcc 0.9159 0.9250
epoch 2000 LossPred 0.1039 LossAtt 0.2920 TrainAcc 0.9800 TestAcc 0.9457 0.9300
epoch 2100 LossPred 0.1675 LossAtt 0.2943 TrainAcc 0.9500 TestAcc 0.9242 0.9100
epoch 2200 LossPred 0.1300 LossAtt 0.2833 TrainAcc 0.9600 TestAcc 0.9247 0.9300
epoch 2300 LossPred 0.1971 LossAtt 0.2887 TrainAcc 0.9300 TestAcc 0.9119 0.9250
epoch 2400 LossPred 0.1278 LossAtt 0.3005 TrainAcc 0.9700 TestAcc 0.9404 0.9350
epoch 2500 LossPred 0.1394 LossAtt 0.2977 TrainAcc 0.9500 TestAcc 0.9374 0.9200
Optimization Finished!
********** replication  45  **********
epoch   0 LossPred 1.2003 LossAtt 0.9935 TrainAcc 0.5000 TestAcc 0.5268 0.5000
epoch 100 LossPred 0.9797 LossAtt 0.3881 TrainAcc 0.5600 TestAcc 0.6004 0.5600
epoch 200 LossPred 0.9635 LossAtt 0.3565 TrainAcc 0.5600 TestAcc 0.6004 0.5900
epoch 300 LossPred 0.9638 LossAtt 0.4500 TrainAcc 0.5900 TestAcc 0.5185 0.5800
epoch 400 LossPred 0.9583 LossAtt 0.4265 TrainAcc 0.6100 TestAcc 0.5200 0.5900
epoch 500 LossPred 0.9493 LossAtt 0.3844 TrainAcc 0.5900 TestAcc 0.5185 0.5900
epoch 600 LossPred 0.9349 LossAtt 0.3656 TrainAcc 0.6000 TestAcc 0.5405 0.5900
epoch 700 LossPred 0.8853 LossAtt 0.4471 TrainAcc 0.6200 TestAcc 0.5933 0.6700
epoch 800 LossPred 0.3308 LossAtt 0.4196 TrainAcc 0.9100 TestAcc 0.8764 0.9150
epoch 900 LossPred 0.2251 LossAtt 0.3966 TrainAcc 0.9400 TestAcc 0.9009 0.9450
epoch 1000 LossPred 0.2302 LossAtt 0.3722 TrainAcc 0.9100 TestAcc 0.9087 0.9050
epoch 1100 LossPred 0.1942 LossAtt 0.3725 TrainAcc 0.9300 TestAcc 0.8936 0.9300
epoch 1200 LossPred 0.1881 LossAtt 0.3585 TrainAcc 0.9300 TestAcc 0.9054 0.9300
epoch 1300 LossPred 0.2007 LossAtt 0.3814 TrainAcc 0.9300 TestAcc 0.8859 0.9300
epoch 1400 LossPred 0.1987 LossAtt 0.3674 TrainAcc 0.9400 TestAcc 0.8909 0.9300
epoch 1500 LossPred 0.1963 LossAtt 0.3542 TrainAcc 0.9200 TestAcc 0.9037 0.9200
epoch 1600 LossPred 0.1922 LossAtt 0.3419 TrainAcc 0.9200 TestAcc 0.9167 0.9300
epoch 1700 LossPred 0.1958 LossAtt 0.3574 TrainAcc 0.9300 TestAcc 0.9054 0.9350
epoch 1800 LossPred 0.2165 LossAtt 0.3670 TrainAcc 0.9300 TestAcc 0.8809 0.9350
epoch 1900 LossPred 0.1642 LossAtt 0.3745 TrainAcc 0.9600 TestAcc 0.9207 0.9450
epoch 2000 LossPred 0.1703 LossAtt 0.3743 TrainAcc 0.9500 TestAcc 0.9019 0.9400
epoch 2100 LossPred 0.1689 LossAtt 0.3761 TrainAcc 0.9400 TestAcc 0.9124 0.9400
epoch 2200 LossPred 0.1614 LossAtt 0.3447 TrainAcc 0.9400 TestAcc 0.9102 0.9500
epoch 2300 LossPred 0.1522 LossAtt 0.3395 TrainAcc 0.9600 TestAcc 0.9142 0.9500
epoch 2400 LossPred 0.1769 LossAtt 0.3605 TrainAcc 0.9400 TestAcc 0.9072 0.9350
epoch 2500 LossPred 0.1589 LossAtt 0.3395 TrainAcc 0.9400 TestAcc 0.9127 0.9350
Optimization Finished!
********** replication  46  **********
epoch   0 LossPred 0.9851 LossAtt 1.0325 TrainAcc 0.5900 TestAcc 0.5018 0.5450
epoch 100 LossPred 0.9146 LossAtt 0.3504 TrainAcc 0.6200 TestAcc 0.6121 0.6350
epoch 200 LossPred 0.9018 LossAtt 0.2745 TrainAcc 0.6200 TestAcc 0.6121 0.6250
epoch 300 LossPred 0.8982 LossAtt 0.2683 TrainAcc 0.6200 TestAcc 0.6121 0.6300
epoch 400 LossPred 0.8791 LossAtt 0.3253 TrainAcc 0.6400 TestAcc 0.6371 0.6550
epoch 500 LossPred 0.6455 LossAtt 0.4216 TrainAcc 0.7900 TestAcc 0.7750 0.7850
epoch 600 LossPred 0.5132 LossAtt 0.3375 TrainAcc 0.8000 TestAcc 0.8626 0.8350
epoch 700 LossPred 0.3642 LossAtt 0.3010 TrainAcc 0.9000 TestAcc 0.9082 0.9250
epoch 800 LossPred 0.3085 LossAtt 0.2797 TrainAcc 0.9200 TestAcc 0.8574 0.9100
epoch 900 LossPred 0.2727 LossAtt 0.2554 TrainAcc 0.9400 TestAcc 0.8631 0.9350
epoch 1000 LossPred 0.3154 LossAtt 0.2518 TrainAcc 0.9100 TestAcc 0.8951 0.9000
epoch 1100 LossPred 0.3007 LossAtt 0.2506 TrainAcc 0.9200 TestAcc 0.9032 0.9150
epoch 1200 LossPred 0.2615 LossAtt 0.2395 TrainAcc 0.9200 TestAcc 0.8946 0.9200
epoch 1300 LossPred 0.6328 LossAtt 0.2421 TrainAcc 0.7600 TestAcc 0.7075 0.7550
epoch 1400 LossPred 1.0563 LossAtt 0.1960 TrainAcc 0.6300 TestAcc 0.5563 0.6500
epoch 1500 LossPred 0.3572 LossAtt 0.2330 TrainAcc 0.8900 TestAcc 0.8011 0.8900
epoch 1600 LossPred 0.5292 LossAtt 0.2412 TrainAcc 0.8400 TestAcc 0.7755 0.8300
epoch 1700 LossPred 0.6485 LossAtt 0.2445 TrainAcc 0.7800 TestAcc 0.7267 0.7850
epoch 1800 LossPred 0.2686 LossAtt 0.2335 TrainAcc 0.9200 TestAcc 0.8991 0.9250
epoch 1900 LossPred 0.2160 LossAtt 0.2358 TrainAcc 0.9400 TestAcc 0.8699 0.9400
epoch 2000 LossPred 0.6465 LossAtt 0.2549 TrainAcc 0.7600 TestAcc 0.8266 0.7650
epoch 2100 LossPred 0.2951 LossAtt 0.2457 TrainAcc 0.9000 TestAcc 0.9027 0.8950
epoch 2200 LossPred 0.4074 LossAtt 0.2499 TrainAcc 0.8700 TestAcc 0.7735 0.8750
epoch 2300 LossPred 0.2606 LossAtt 0.2522 TrainAcc 0.9200 TestAcc 0.8396 0.9150
epoch 2400 LossPred 0.2573 LossAtt 0.2924 TrainAcc 0.9100 TestAcc 0.8463 0.9150
epoch 2500 LossPred 0.3292 LossAtt 0.2848 TrainAcc 0.9100 TestAcc 0.8188 0.9050
Optimization Finished!
********** replication  47  **********
epoch   0 LossPred 1.2044 LossAtt 1.0137 TrainAcc 0.3900 TestAcc 0.4517 0.3850
epoch 100 LossPred 0.9422 LossAtt 0.2720 TrainAcc 0.6000 TestAcc 0.6089 0.6300
epoch 200 LossPred 0.9131 LossAtt 0.2278 TrainAcc 0.6500 TestAcc 0.5983 0.6450
epoch 300 LossPred 0.8772 LossAtt 0.2951 TrainAcc 0.6500 TestAcc 0.5983 0.6500
epoch 400 LossPred 0.5072 LossAtt 0.3797 TrainAcc 0.8400 TestAcc 0.8408 0.8500
epoch 500 LossPred 0.3868 LossAtt 0.3855 TrainAcc 0.8400 TestAcc 0.8408 0.8500
epoch 600 LossPred 0.3368 LossAtt 0.3616 TrainAcc 0.8700 TestAcc 0.8606 0.8800
epoch 700 LossPred 0.2837 LossAtt 0.3249 TrainAcc 0.9100 TestAcc 0.8801 0.8950
epoch 800 LossPred 0.2224 LossAtt 0.3438 TrainAcc 0.9100 TestAcc 0.9127 0.9000
epoch 900 LossPred 0.1868 LossAtt 0.3367 TrainAcc 0.9400 TestAcc 0.9469 0.9200
epoch 1000 LossPred 0.1659 LossAtt 0.3406 TrainAcc 0.9500 TestAcc 0.9612 0.9250
epoch 1100 LossPred 0.2421 LossAtt 0.3055 TrainAcc 0.8900 TestAcc 0.9374 0.8950
epoch 1200 LossPred 0.2124 LossAtt 0.3036 TrainAcc 0.9000 TestAcc 0.9499 0.9100
epoch 1300 LossPred 0.1449 LossAtt 0.2975 TrainAcc 0.9800 TestAcc 0.9630 0.9400
epoch 1400 LossPred 0.1544 LossAtt 0.3147 TrainAcc 0.9400 TestAcc 0.9117 0.9200
epoch 1500 LossPred 0.1884 LossAtt 0.2936 TrainAcc 0.9200 TestAcc 0.9667 0.9150
epoch 1600 LossPred 0.2179 LossAtt 0.3143 TrainAcc 0.9200 TestAcc 0.8311 0.9100
epoch 1700 LossPred 0.1335 LossAtt 0.3104 TrainAcc 0.9500 TestAcc 0.9214 0.9350
epoch 1800 LossPred 0.1140 LossAtt 0.2912 TrainAcc 0.9800 TestAcc 0.9575 0.9450
epoch 1900 LossPred 0.1998 LossAtt 0.2984 TrainAcc 0.9100 TestAcc 0.9437 0.9150
epoch 2000 LossPred 0.4101 LossAtt 0.3204 TrainAcc 0.8400 TestAcc 0.7495 0.8650
epoch 2100 LossPred 0.1517 LossAtt 0.3013 TrainAcc 0.9500 TestAcc 0.9092 0.9250
epoch 2200 LossPred 0.1480 LossAtt 0.2917 TrainAcc 0.9500 TestAcc 0.9735 0.9400
epoch 2300 LossPred 0.1508 LossAtt 0.2766 TrainAcc 0.9300 TestAcc 0.8831 0.9200
epoch 2400 LossPred 0.1195 LossAtt 0.2870 TrainAcc 0.9800 TestAcc 0.9532 0.9300
epoch 2500 LossPred 0.1882 LossAtt 0.2896 TrainAcc 0.9500 TestAcc 0.9032 0.9250
Optimization Finished!
********** replication  48  **********
epoch   0 LossPred 1.0134 LossAtt 1.0090 TrainAcc 0.5900 TestAcc 0.5601 0.5600
epoch 100 LossPred 0.9158 LossAtt 0.4924 TrainAcc 0.6200 TestAcc 0.6074 0.6150
epoch 200 LossPred 0.8978 LossAtt 0.4971 TrainAcc 0.6200 TestAcc 0.6074 0.6100
epoch 300 LossPred 0.4401 LossAtt 0.5613 TrainAcc 0.8900 TestAcc 0.8393 0.8450
epoch 400 LossPred 0.3017 LossAtt 0.5246 TrainAcc 0.9100 TestAcc 0.8406 0.8650
epoch 500 LossPred 0.3811 LossAtt 0.4977 TrainAcc 0.8900 TestAcc 0.8443 0.8450
epoch 600 LossPred 0.2996 LossAtt 0.4729 TrainAcc 0.9200 TestAcc 0.8268 0.8600
epoch 700 LossPred 0.2865 LossAtt 0.4635 TrainAcc 0.9100 TestAcc 0.8326 0.8750
epoch 800 LossPred 0.2811 LossAtt 0.4487 TrainAcc 0.9200 TestAcc 0.8443 0.8850
epoch 900 LossPred 0.2618 LossAtt 0.4497 TrainAcc 0.9300 TestAcc 0.8531 0.8650
epoch 1000 LossPred 0.2510 LossAtt 0.4369 TrainAcc 0.9300 TestAcc 0.8696 0.8900
epoch 1100 LossPred 0.2035 LossAtt 0.3837 TrainAcc 0.9400 TestAcc 0.8764 0.8850
epoch 1200 LossPred 0.2294 LossAtt 0.3982 TrainAcc 0.9400 TestAcc 0.8649 0.8800
epoch 1300 LossPred 0.1815 LossAtt 0.3600 TrainAcc 0.9500 TestAcc 0.8816 0.8900
epoch 1400 LossPred 0.2031 LossAtt 0.3513 TrainAcc 0.9400 TestAcc 0.8741 0.8850
epoch 1500 LossPred 0.1660 LossAtt 0.3743 TrainAcc 0.9500 TestAcc 0.8834 0.9000
epoch 1600 LossPred 0.1620 LossAtt 0.3829 TrainAcc 0.9400 TestAcc 0.8831 0.9000
epoch 1700 LossPred 0.1582 LossAtt 0.3833 TrainAcc 0.9400 TestAcc 0.8851 0.9050
epoch 1800 LossPred 0.1714 LossAtt 0.3826 TrainAcc 0.9300 TestAcc 0.8849 0.8850
epoch 1900 LossPred 0.1333 LossAtt 0.4144 TrainAcc 0.9600 TestAcc 0.8964 0.9100
epoch 2000 LossPred 0.1443 LossAtt 0.4070 TrainAcc 0.9500 TestAcc 0.8999 0.9200
epoch 2100 LossPred 0.1517 LossAtt 0.4158 TrainAcc 0.9500 TestAcc 0.8964 0.9200
epoch 2200 LossPred 0.1398 LossAtt 0.4063 TrainAcc 0.9400 TestAcc 0.9012 0.9250
epoch 2300 LossPred 0.1268 LossAtt 0.3888 TrainAcc 0.9600 TestAcc 0.8971 0.9100
epoch 2400 LossPred 0.2078 LossAtt 0.3978 TrainAcc 0.9300 TestAcc 0.8846 0.9150
epoch 2500 LossPred 0.1824 LossAtt 0.4244 TrainAcc 0.9300 TestAcc 0.8684 0.9050
Optimization Finished!
********** replication  49  **********
epoch   0 LossPred 1.1152 LossAtt 1.0166 TrainAcc 0.4600 TestAcc 0.4635 0.4600
epoch 100 LossPred 0.9676 LossAtt 0.4139 TrainAcc 0.5800 TestAcc 0.6134 0.5800
epoch 200 LossPred 0.9662 LossAtt 0.3477 TrainAcc 0.5800 TestAcc 0.6134 0.5800
epoch 300 LossPred 0.9584 LossAtt 0.3016 TrainAcc 0.5800 TestAcc 0.6134 0.5850
epoch 400 LossPred 0.4846 LossAtt 0.4409 TrainAcc 0.9300 TestAcc 0.8614 0.8900
epoch 500 LossPred 0.2916 LossAtt 0.4689 TrainAcc 0.9100 TestAcc 0.8886 0.8850
epoch 600 LossPred 0.2778 LossAtt 0.4510 TrainAcc 0.9100 TestAcc 0.8984 0.8950
epoch 700 LossPred 0.2028 LossAtt 0.4982 TrainAcc 0.9500 TestAcc 0.9177 0.9200
epoch 800 LossPred 0.1615 LossAtt 0.5062 TrainAcc 0.9700 TestAcc 0.9377 0.9500
epoch 900 LossPred 0.1688 LossAtt 0.5180 TrainAcc 0.9700 TestAcc 0.9272 0.9350
epoch 1000 LossPred 0.1251 LossAtt 0.5171 TrainAcc 0.9600 TestAcc 0.9372 0.9650
epoch 1100 LossPred 0.1059 LossAtt 0.5148 TrainAcc 0.9700 TestAcc 0.9462 0.9650
epoch 1200 LossPred 0.1671 LossAtt 0.5460 TrainAcc 0.9400 TestAcc 0.8939 0.9400
epoch 1300 LossPred 0.1130 LossAtt 0.5193 TrainAcc 0.9700 TestAcc 0.9459 0.9450
epoch 1400 LossPred 0.1744 LossAtt 0.5541 TrainAcc 0.9300 TestAcc 0.8941 0.9250
epoch 1500 LossPred 0.0660 LossAtt 0.5344 TrainAcc 0.9800 TestAcc 0.9449 0.9700
epoch 1600 LossPred 0.0747 LossAtt 0.5281 TrainAcc 0.9900 TestAcc 0.9077 0.9650
epoch 1700 LossPred 0.0540 LossAtt 0.5330 TrainAcc 1.0000 TestAcc 0.9362 0.9650
Optimization Finished!
********** replication  50  **********
epoch   0 LossPred 0.9996 LossAtt 1.0010 TrainAcc 0.6000 TestAcc 0.5761 0.6000
epoch 100 LossPred 0.8912 LossAtt 0.2921 TrainAcc 0.6700 TestAcc 0.6196 0.6550
epoch 200 LossPred 0.8589 LossAtt 0.2756 TrainAcc 0.6700 TestAcc 0.6196 0.6750
epoch 300 LossPred 0.8098 LossAtt 0.2902 TrainAcc 0.6800 TestAcc 0.6439 0.6750
epoch 400 LossPred 0.5019 LossAtt 0.4023 TrainAcc 0.8300 TestAcc 0.8546 0.8000
epoch 500 LossPred 0.5245 LossAtt 0.4153 TrainAcc 0.8200 TestAcc 0.8443 0.7850
epoch 600 LossPred 0.5352 LossAtt 0.4326 TrainAcc 0.8000 TestAcc 0.8431 0.7750
epoch 700 LossPred 0.6231 LossAtt 0.4191 TrainAcc 0.7700 TestAcc 0.8373 0.7900
epoch 800 LossPred 0.4554 LossAtt 0.4404 TrainAcc 0.8300 TestAcc 0.8689 0.8150
epoch 900 LossPred 0.4465 LossAtt 0.4264 TrainAcc 0.8500 TestAcc 0.8659 0.8400
epoch 1000 LossPred 0.4166 LossAtt 0.4099 TrainAcc 0.8500 TestAcc 0.8811 0.8500
epoch 1100 LossPred 0.4085 LossAtt 0.4231 TrainAcc 0.8700 TestAcc 0.8859 0.8250
epoch 1200 LossPred 0.4230 LossAtt 0.4078 TrainAcc 0.8500 TestAcc 0.8896 0.8250
epoch 1300 LossPred 0.3814 LossAtt 0.4209 TrainAcc 0.8600 TestAcc 0.8839 0.8500
epoch 1400 LossPred 0.3959 LossAtt 0.4026 TrainAcc 0.8500 TestAcc 0.8929 0.8350
epoch 1500 LossPred 0.2779 LossAtt 0.3963 TrainAcc 0.8900 TestAcc 0.9267 0.8600
epoch 1600 LossPred 0.2268 LossAtt 0.4098 TrainAcc 0.9500 TestAcc 0.9377 0.8850
epoch 1700 LossPred 0.4345 LossAtt 0.4164 TrainAcc 0.8100 TestAcc 0.8486 0.8300
epoch 1800 LossPred 0.3081 LossAtt 0.3946 TrainAcc 0.9000 TestAcc 0.9079 0.8650
epoch 1900 LossPred 0.2569 LossAtt 0.3684 TrainAcc 0.9100 TestAcc 0.9024 0.8950
epoch 2000 LossPred 0.2484 LossAtt 0.3384 TrainAcc 0.9200 TestAcc 0.9582 0.8800
epoch 2100 LossPred 0.5237 LossAtt 0.3276 TrainAcc 0.8100 TestAcc 0.8293 0.8100
epoch 2200 LossPred 0.2829 LossAtt 0.3427 TrainAcc 0.9100 TestAcc 0.9287 0.8700
epoch 2300 LossPred 0.4001 LossAtt 0.3444 TrainAcc 0.8500 TestAcc 0.8681 0.8450
epoch 2400 LossPred 0.6007 LossAtt 0.3438 TrainAcc 0.7800 TestAcc 0.8418 0.7650
epoch 2500 LossPred 0.2212 LossAtt 0.3371 TrainAcc 0.9200 TestAcc 0.9319 0.9100
Optimization Finished!
********** replication  51  **********
epoch   0 LossPred 1.2356 LossAtt 1.0108 TrainAcc 0.4900 TestAcc 0.4530 0.4950
epoch 100 LossPred 0.9017 LossAtt 0.4995 TrainAcc 0.6600 TestAcc 0.5886 0.6550
epoch 200 LossPred 0.8231 LossAtt 0.5117 TrainAcc 0.7200 TestAcc 0.5768 0.7000
epoch 300 LossPred 0.7885 LossAtt 0.4962 TrainAcc 0.7200 TestAcc 0.6069 0.7050
epoch 400 LossPred 0.7713 LossAtt 0.5052 TrainAcc 0.7100 TestAcc 0.6121 0.7000
epoch 500 LossPred 0.6905 LossAtt 0.5276 TrainAcc 0.7400 TestAcc 0.6411 0.7150
epoch 600 LossPred 0.6753 LossAtt 0.4167 TrainAcc 0.7400 TestAcc 0.6464 0.7400
epoch 700 LossPred 0.6623 LossAtt 0.4136 TrainAcc 0.7400 TestAcc 0.6484 0.7450
epoch 800 LossPred 0.6556 LossAtt 0.3663 TrainAcc 0.7500 TestAcc 0.6454 0.7350
epoch 900 LossPred 0.6523 LossAtt 0.3718 TrainAcc 0.7500 TestAcc 0.6507 0.7300
epoch 1000 LossPred 0.6474 LossAtt 0.3732 TrainAcc 0.7500 TestAcc 0.6524 0.7250
epoch 1100 LossPred 0.6413 LossAtt 0.3611 TrainAcc 0.7500 TestAcc 0.6484 0.7350
epoch 1200 LossPred 0.6491 LossAtt 0.4043 TrainAcc 0.7400 TestAcc 0.6502 0.7450
epoch 1300 LossPred 0.6260 LossAtt 0.4071 TrainAcc 0.7600 TestAcc 0.6414 0.7450
epoch 1400 LossPred 0.6284 LossAtt 0.3576 TrainAcc 0.7700 TestAcc 0.6391 0.7550
epoch 1500 LossPred 0.6216 LossAtt 0.3774 TrainAcc 0.7600 TestAcc 0.6451 0.7550
epoch 1600 LossPred 0.5917 LossAtt 0.3966 TrainAcc 0.7600 TestAcc 0.6484 0.7550
epoch 1700 LossPred 0.5991 LossAtt 0.3922 TrainAcc 0.7700 TestAcc 0.6549 0.7400
epoch 1800 LossPred 0.5914 LossAtt 0.3811 TrainAcc 0.7700 TestAcc 0.6494 0.7600
epoch 1900 LossPred 0.5844 LossAtt 0.3873 TrainAcc 0.7800 TestAcc 0.6512 0.7500
epoch 2000 LossPred 0.6274 LossAtt 0.3641 TrainAcc 0.7700 TestAcc 0.6469 0.7450
epoch 2100 LossPred 0.5767 LossAtt 0.3546 TrainAcc 0.7900 TestAcc 0.6469 0.7550
epoch 2200 LossPred 0.5804 LossAtt 0.3738 TrainAcc 0.7700 TestAcc 0.6491 0.7550
epoch 2300 LossPred 0.5999 LossAtt 0.3576 TrainAcc 0.7700 TestAcc 0.6449 0.7500
epoch 2400 LossPred 0.5986 LossAtt 0.3571 TrainAcc 0.7800 TestAcc 0.6504 0.7400
epoch 2500 LossPred 0.5943 LossAtt 0.3751 TrainAcc 0.7700 TestAcc 0.6494 0.7550
Optimization Finished!
********** replication  52  **********
epoch   0 LossPred 0.9905 LossAtt 1.0251 TrainAcc 0.5700 TestAcc 0.5621 0.5800
epoch 100 LossPred 0.9163 LossAtt 0.4596 TrainAcc 0.6400 TestAcc 0.5793 0.6400
epoch 200 LossPred 0.9003 LossAtt 0.3866 TrainAcc 0.6800 TestAcc 0.6121 0.6400
epoch 300 LossPred 0.5580 LossAtt 0.4832 TrainAcc 0.8300 TestAcc 0.8161 0.8250
epoch 400 LossPred 0.4592 LossAtt 0.4226 TrainAcc 0.8400 TestAcc 0.8431 0.8350
epoch 500 LossPred 0.3881 LossAtt 0.3948 TrainAcc 0.8700 TestAcc 0.8624 0.8450
epoch 600 LossPred 0.4075 LossAtt 0.3852 TrainAcc 0.8700 TestAcc 0.8611 0.8500
epoch 700 LossPred 0.3704 LossAtt 0.4031 TrainAcc 0.8700 TestAcc 0.8666 0.8600
epoch 800 LossPred 0.3586 LossAtt 0.3791 TrainAcc 0.8800 TestAcc 0.8666 0.8550
epoch 900 LossPred 0.3789 LossAtt 0.3704 TrainAcc 0.8700 TestAcc 0.8686 0.8600
epoch 1000 LossPred 0.3678 LossAtt 0.3610 TrainAcc 0.8800 TestAcc 0.8701 0.8500
epoch 1100 LossPred 0.4148 LossAtt 0.3768 TrainAcc 0.8500 TestAcc 0.8594 0.8650
epoch 1200 LossPred 0.3991 LossAtt 0.3596 TrainAcc 0.8600 TestAcc 0.8569 0.8550
epoch 1300 LossPred 0.4363 LossAtt 0.3478 TrainAcc 0.8300 TestAcc 0.8483 0.8450
epoch 1400 LossPred 0.4264 LossAtt 0.3584 TrainAcc 0.8500 TestAcc 0.8381 0.8200
epoch 1500 LossPred 0.3328 LossAtt 0.3498 TrainAcc 0.8800 TestAcc 0.8684 0.8550
epoch 1600 LossPred 0.6077 LossAtt 0.3061 TrainAcc 0.7900 TestAcc 0.7372 0.7950
epoch 1700 LossPred 0.4106 LossAtt 0.3181 TrainAcc 0.8600 TestAcc 0.8584 0.8550
epoch 1800 LossPred 0.3929 LossAtt 0.3063 TrainAcc 0.8500 TestAcc 0.8544 0.8550
epoch 1900 LossPred 0.3367 LossAtt 0.2945 TrainAcc 0.8900 TestAcc 0.8784 0.8450
epoch 2000 LossPred 0.4482 LossAtt 0.2896 TrainAcc 0.8400 TestAcc 0.8589 0.8400
epoch 2100 LossPred 0.3580 LossAtt 0.2852 TrainAcc 0.8700 TestAcc 0.8699 0.8650
epoch 2200 LossPred 0.3744 LossAtt 0.2771 TrainAcc 0.8700 TestAcc 0.8649 0.8500
epoch 2300 LossPred 0.4746 LossAtt 0.2933 TrainAcc 0.8400 TestAcc 0.8376 0.8250
epoch 2400 LossPred 0.4178 LossAtt 0.3055 TrainAcc 0.8600 TestAcc 0.8511 0.8600
epoch 2500 LossPred 0.5385 LossAtt 0.2930 TrainAcc 0.8400 TestAcc 0.7743 0.8200
Optimization Finished!
********** replication  53  **********
epoch   0 LossPred 1.1312 LossAtt 1.0026 TrainAcc 0.4300 TestAcc 0.4299 0.4100
epoch 100 LossPred 0.9702 LossAtt 0.4389 TrainAcc 0.5600 TestAcc 0.5796 0.5700
epoch 200 LossPred 0.9582 LossAtt 0.4619 TrainAcc 0.5800 TestAcc 0.5753 0.5900
epoch 300 LossPred 0.9397 LossAtt 0.4570 TrainAcc 0.5800 TestAcc 0.5841 0.5900
epoch 400 LossPred 0.9113 LossAtt 0.4561 TrainAcc 0.6100 TestAcc 0.5918 0.6100
epoch 500 LossPred 0.8908 LossAtt 0.4686 TrainAcc 0.6500 TestAcc 0.5841 0.6400
epoch 600 LossPred 0.8792 LossAtt 0.5178 TrainAcc 0.6100 TestAcc 0.5708 0.5950
epoch 700 LossPred 0.8164 LossAtt 0.5691 TrainAcc 0.6500 TestAcc 0.5408 0.6500
epoch 800 LossPred 0.7751 LossAtt 0.5441 TrainAcc 0.6900 TestAcc 0.5325 0.6700
epoch 900 LossPred 0.7319 LossAtt 0.4847 TrainAcc 0.7300 TestAcc 0.5508 0.7050
epoch 1000 LossPred 0.7542 LossAtt 0.4860 TrainAcc 0.7600 TestAcc 0.5493 0.6750
epoch 1100 LossPred 0.7626 LossAtt 0.4973 TrainAcc 0.7200 TestAcc 0.5601 0.6950
epoch 1200 LossPred 0.7880 LossAtt 0.5432 TrainAcc 0.6900 TestAcc 0.5586 0.6700
epoch 1300 LossPred 0.7690 LossAtt 0.5475 TrainAcc 0.7100 TestAcc 0.5563 0.6600
epoch 1400 LossPred 0.7350 LossAtt 0.5471 TrainAcc 0.7100 TestAcc 0.5493 0.6700
epoch 1500 LossPred 0.7093 LossAtt 0.4924 TrainAcc 0.7100 TestAcc 0.5453 0.6850
epoch 1600 LossPred 0.7560 LossAtt 0.5128 TrainAcc 0.6900 TestAcc 0.5388 0.6950
epoch 1700 LossPred 0.7172 LossAtt 0.4903 TrainAcc 0.7300 TestAcc 0.5408 0.7000
epoch 1800 LossPred 0.7915 LossAtt 0.5022 TrainAcc 0.7000 TestAcc 0.5425 0.7350
epoch 1900 LossPred 0.7379 LossAtt 0.5171 TrainAcc 0.7700 TestAcc 0.5390 0.7450
epoch 2000 LossPred 0.6858 LossAtt 0.5130 TrainAcc 0.7700 TestAcc 0.5295 0.7250
epoch 2100 LossPred 0.6856 LossAtt 0.4958 TrainAcc 0.7600 TestAcc 0.5310 0.7050
epoch 2200 LossPred 0.6813 LossAtt 0.5017 TrainAcc 0.7700 TestAcc 0.5295 0.7350
epoch 2300 LossPred 0.6719 LossAtt 0.4953 TrainAcc 0.7800 TestAcc 0.5285 0.7650
epoch 2400 LossPred 0.7756 LossAtt 0.5096 TrainAcc 0.7200 TestAcc 0.5243 0.7350
epoch 2500 LossPred 0.7257 LossAtt 0.4958 TrainAcc 0.7400 TestAcc 0.5348 0.6850
Optimization Finished!
********** replication  54  **********
epoch   0 LossPred 1.0067 LossAtt 0.9933 TrainAcc 0.5300 TestAcc 0.5606 0.5200
epoch 100 LossPred 0.9352 LossAtt 0.4143 TrainAcc 0.6100 TestAcc 0.6101 0.6100
epoch 200 LossPred 0.9149 LossAtt 0.2541 TrainAcc 0.6200 TestAcc 0.6216 0.6200
epoch 300 LossPred 0.8999 LossAtt 0.2453 TrainAcc 0.6200 TestAcc 0.6216 0.6150
epoch 400 LossPred 0.8699 LossAtt 0.3463 TrainAcc 0.6700 TestAcc 0.6529 0.6650
epoch 500 LossPred 0.2263 LossAtt 0.3347 TrainAcc 0.9400 TestAcc 0.8746 0.9000
epoch 600 LossPred 0.1994 LossAtt 0.3082 TrainAcc 0.9400 TestAcc 0.8924 0.9300
epoch 700 LossPred 0.1434 LossAtt 0.2786 TrainAcc 0.9700 TestAcc 0.9162 0.9250
epoch 800 LossPred 0.2172 LossAtt 0.2546 TrainAcc 0.9300 TestAcc 0.8681 0.9200
epoch 900 LossPred 0.1388 LossAtt 0.2537 TrainAcc 0.9800 TestAcc 0.9064 0.9300
epoch 1000 LossPred 0.1666 LossAtt 0.2466 TrainAcc 0.9500 TestAcc 0.9072 0.9150
epoch 1100 LossPred 0.1039 LossAtt 0.2442 TrainAcc 0.9800 TestAcc 0.9212 0.9450
epoch 1200 LossPred 0.1699 LossAtt 0.2504 TrainAcc 0.9400 TestAcc 0.9187 0.9250
epoch 1300 LossPred 0.1142 LossAtt 0.2478 TrainAcc 0.9700 TestAcc 0.9074 0.9300
epoch 1400 LossPred 0.1217 LossAtt 0.2456 TrainAcc 0.9700 TestAcc 0.9189 0.9150
epoch 1500 LossPred 0.1156 LossAtt 0.2330 TrainAcc 0.9600 TestAcc 0.9087 0.9550
epoch 1600 LossPred 0.2003 LossAtt 0.2191 TrainAcc 0.9300 TestAcc 0.8876 0.9400
epoch 1700 LossPred 0.1813 LossAtt 0.2256 TrainAcc 0.9400 TestAcc 0.8941 0.9500
epoch 1800 LossPred 0.2055 LossAtt 0.2325 TrainAcc 0.9200 TestAcc 0.8799 0.9100
epoch 1900 LossPred 0.1525 LossAtt 0.2206 TrainAcc 0.9600 TestAcc 0.8994 0.9400
epoch 2000 LossPred 0.1858 LossAtt 0.2301 TrainAcc 0.9400 TestAcc 0.8841 0.9350
epoch 2100 LossPred 0.1312 LossAtt 0.2227 TrainAcc 0.9600 TestAcc 0.9119 0.9350
epoch 2200 LossPred 0.2376 LossAtt 0.2256 TrainAcc 0.9200 TestAcc 0.8701 0.9100
epoch 2300 LossPred 0.2664 LossAtt 0.2271 TrainAcc 0.9100 TestAcc 0.8676 0.9100
epoch 2400 LossPred 0.1950 LossAtt 0.2256 TrainAcc 0.9200 TestAcc 0.8821 0.9400
epoch 2500 LossPred 0.3333 LossAtt 0.2209 TrainAcc 0.8700 TestAcc 0.8376 0.8900
Optimization Finished!
********** replication  55  **********
epoch   0 LossPred 1.0749 LossAtt 1.0001 TrainAcc 0.3900 TestAcc 0.3946 0.3900
epoch 100 LossPred 0.9198 LossAtt 0.3844 TrainAcc 0.6400 TestAcc 0.6031 0.6400
epoch 200 LossPred 0.8870 LossAtt 0.3646 TrainAcc 0.6400 TestAcc 0.6031 0.6400
epoch 300 LossPred 0.8434 LossAtt 0.4192 TrainAcc 0.6900 TestAcc 0.5928 0.6750
epoch 400 LossPred 0.8211 LossAtt 0.4128 TrainAcc 0.6800 TestAcc 0.6196 0.6900
epoch 500 LossPred 0.4043 LossAtt 0.3898 TrainAcc 0.9000 TestAcc 0.8413 0.8800
epoch 600 LossPred 0.3083 LossAtt 0.3609 TrainAcc 0.9200 TestAcc 0.8706 0.8800
epoch 700 LossPred 0.2914 LossAtt 0.3669 TrainAcc 0.9200 TestAcc 0.8836 0.9100
epoch 800 LossPred 0.2158 LossAtt 0.3441 TrainAcc 0.9300 TestAcc 0.9077 0.9000
epoch 900 LossPred 0.1785 LossAtt 0.3618 TrainAcc 0.9600 TestAcc 0.9209 0.9050
epoch 1000 LossPred 0.1592 LossAtt 0.3561 TrainAcc 0.9500 TestAcc 0.9397 0.9100
epoch 1100 LossPred 0.1368 LossAtt 0.3536 TrainAcc 0.9600 TestAcc 0.9472 0.9100
epoch 1200 LossPred 0.1778 LossAtt 0.3636 TrainAcc 0.9600 TestAcc 0.9294 0.9100
epoch 1300 LossPred 0.1570 LossAtt 0.3572 TrainAcc 0.9400 TestAcc 0.9374 0.9250
epoch 1400 LossPred 0.1490 LossAtt 0.3561 TrainAcc 0.9500 TestAcc 0.9379 0.9100
epoch 1500 LossPred 0.1599 LossAtt 0.3550 TrainAcc 0.9400 TestAcc 0.9322 0.9150
epoch 1600 LossPred 0.2780 LossAtt 0.3604 TrainAcc 0.9000 TestAcc 0.8736 0.8650
epoch 1700 LossPred 0.1382 LossAtt 0.3750 TrainAcc 0.9400 TestAcc 0.9349 0.9000
epoch 1800 LossPred 0.1254 LossAtt 0.3609 TrainAcc 0.9700 TestAcc 0.9464 0.9400
epoch 1900 LossPred 0.1133 LossAtt 0.3607 TrainAcc 0.9700 TestAcc 0.9499 0.9300
epoch 2000 LossPred 0.1396 LossAtt 0.3363 TrainAcc 0.9600 TestAcc 0.9372 0.9050
epoch 2100 LossPred 0.1012 LossAtt 0.3737 TrainAcc 0.9800 TestAcc 0.9517 0.9300
epoch 2200 LossPred 0.1370 LossAtt 0.3659 TrainAcc 0.9800 TestAcc 0.9367 0.9150
epoch 2300 LossPred 0.1200 LossAtt 0.3516 TrainAcc 0.9800 TestAcc 0.9382 0.9250
epoch 2400 LossPred 0.1171 LossAtt 0.3649 TrainAcc 0.9800 TestAcc 0.9392 0.9250
epoch 2500 LossPred 0.1616 LossAtt 0.3621 TrainAcc 0.9500 TestAcc 0.9297 0.9050
Optimization Finished!
********** replication  56  **********
epoch   0 LossPred 1.2773 LossAtt 1.0081 TrainAcc 0.4100 TestAcc 0.4515 0.3750
epoch 100 LossPred 0.9554 LossAtt 0.2929 TrainAcc 0.6200 TestAcc 0.5596 0.6250
epoch 200 LossPred 0.9492 LossAtt 0.3262 TrainAcc 0.5400 TestAcc 0.5105 0.5400
epoch 300 LossPred 0.8524 LossAtt 0.3452 TrainAcc 0.6800 TestAcc 0.6431 0.7050
epoch 400 LossPred 0.5330 LossAtt 0.3556 TrainAcc 0.9200 TestAcc 0.8879 0.8550
epoch 500 LossPred 0.4161 LossAtt 0.3264 TrainAcc 0.9000 TestAcc 0.8839 0.8750
epoch 600 LossPred 0.3683 LossAtt 0.3128 TrainAcc 0.9000 TestAcc 0.8896 0.8850
epoch 700 LossPred 0.3506 LossAtt 0.3114 TrainAcc 0.9000 TestAcc 0.8909 0.8550
epoch 800 LossPred 0.3410 LossAtt 0.3124 TrainAcc 0.9100 TestAcc 0.8911 0.8700
epoch 900 LossPred 0.3807 LossAtt 0.3085 TrainAcc 0.8600 TestAcc 0.8716 0.8400
epoch 1000 LossPred 0.3209 LossAtt 0.2947 TrainAcc 0.9000 TestAcc 0.8936 0.8800
epoch 1100 LossPred 0.3950 LossAtt 0.2889 TrainAcc 0.8500 TestAcc 0.8671 0.8350
epoch 1200 LossPred 0.3143 LossAtt 0.2946 TrainAcc 0.9100 TestAcc 0.8961 0.8650
epoch 1300 LossPred 0.3143 LossAtt 0.2874 TrainAcc 0.8900 TestAcc 0.8961 0.8800
epoch 1400 LossPred 0.3307 LossAtt 0.2766 TrainAcc 0.8900 TestAcc 0.8831 0.8650
epoch 1500 LossPred 0.2915 LossAtt 0.2823 TrainAcc 0.9000 TestAcc 0.8984 0.8850
epoch 1600 LossPred 0.3026 LossAtt 0.2776 TrainAcc 0.8900 TestAcc 0.8929 0.8800
epoch 1700 LossPred 0.3087 LossAtt 0.2893 TrainAcc 0.8900 TestAcc 0.8896 0.8750
epoch 1800 LossPred 0.2919 LossAtt 0.2644 TrainAcc 0.8900 TestAcc 0.8994 0.8850
epoch 1900 LossPred 0.3071 LossAtt 0.2638 TrainAcc 0.9000 TestAcc 0.8911 0.8600
epoch 2000 LossPred 0.2875 LossAtt 0.2596 TrainAcc 0.9100 TestAcc 0.8986 0.8700
epoch 2100 LossPred 0.3079 LossAtt 0.2497 TrainAcc 0.8900 TestAcc 0.8899 0.8600
epoch 2200 LossPred 0.3784 LossAtt 0.2377 TrainAcc 0.8700 TestAcc 0.8719 0.8500
epoch 2300 LossPred 0.3141 LossAtt 0.2622 TrainAcc 0.8900 TestAcc 0.8904 0.8550
epoch 2400 LossPred 0.4003 LossAtt 0.2425 TrainAcc 0.8700 TestAcc 0.8556 0.8250
epoch 2500 LossPred 0.3541 LossAtt 0.2592 TrainAcc 0.8800 TestAcc 0.8674 0.8450
Optimization Finished!
********** replication  57  **********
epoch   0 LossPred 0.9604 LossAtt 1.0193 TrainAcc 0.6000 TestAcc 0.5776 0.5950
epoch 100 LossPred 0.8886 LossAtt 0.3873 TrainAcc 0.6400 TestAcc 0.6124 0.6500
epoch 200 LossPred 0.8397 LossAtt 0.4083 TrainAcc 0.6200 TestAcc 0.6456 0.6350
epoch 300 LossPred 0.2499 LossAtt 0.4210 TrainAcc 0.9100 TestAcc 0.9017 0.8900
epoch 400 LossPred 0.1783 LossAtt 0.4186 TrainAcc 0.9700 TestAcc 0.9384 0.8950
epoch 500 LossPred 0.1899 LossAtt 0.4043 TrainAcc 0.9300 TestAcc 0.9129 0.9000
epoch 600 LossPred 0.1913 LossAtt 0.3010 TrainAcc 0.9500 TestAcc 0.9362 0.8850
epoch 700 LossPred 0.1599 LossAtt 0.2796 TrainAcc 0.9600 TestAcc 0.9184 0.9150
epoch 800 LossPred 0.2364 LossAtt 0.2706 TrainAcc 0.9200 TestAcc 0.8721 0.9150
epoch 900 LossPred 0.1296 LossAtt 0.2764 TrainAcc 0.9700 TestAcc 0.9349 0.9350
epoch 1000 LossPred 0.1158 LossAtt 0.2577 TrainAcc 0.9700 TestAcc 0.9570 0.9450
epoch 1100 LossPred 0.1139 LossAtt 0.2729 TrainAcc 0.9700 TestAcc 0.9722 0.9300
epoch 1200 LossPred 0.2228 LossAtt 0.2542 TrainAcc 0.9600 TestAcc 0.9492 0.8850
epoch 1300 LossPred 0.3838 LossAtt 0.2855 TrainAcc 0.8700 TestAcc 0.8571 0.8750
epoch 1400 LossPred 0.3187 LossAtt 0.2606 TrainAcc 0.8700 TestAcc 0.8974 0.8600
epoch 1500 LossPred 0.2357 LossAtt 0.2757 TrainAcc 0.9300 TestAcc 0.9262 0.8750
epoch 1600 LossPred 0.1388 LossAtt 0.2644 TrainAcc 0.9700 TestAcc 0.9374 0.9200
epoch 1700 LossPred 0.4497 LossAtt 0.2392 TrainAcc 0.8500 TestAcc 0.8201 0.8750
epoch 1800 LossPred 0.3764 LossAtt 0.2503 TrainAcc 0.8700 TestAcc 0.8466 0.9000
epoch 1900 LossPred 0.4719 LossAtt 0.2583 TrainAcc 0.8300 TestAcc 0.8131 0.8750
epoch 2000 LossPred 0.3817 LossAtt 0.2455 TrainAcc 0.9000 TestAcc 0.8511 0.8750
epoch 2100 LossPred 0.4308 LossAtt 0.2585 TrainAcc 0.8700 TestAcc 0.8276 0.8850
epoch 2200 LossPred 0.5234 LossAtt 0.2574 TrainAcc 0.8200 TestAcc 0.7983 0.8700
epoch 2300 LossPred 0.4081 LossAtt 0.2518 TrainAcc 0.8700 TestAcc 0.8376 0.8950
epoch 2400 LossPred 0.4846 LossAtt 0.2550 TrainAcc 0.8200 TestAcc 0.8056 0.8700
epoch 2500 LossPred 0.3565 LossAtt 0.2576 TrainAcc 0.8800 TestAcc 0.8529 0.8900
Optimization Finished!
********** replication  58  **********
epoch   0 LossPred 0.9921 LossAtt 0.9993 TrainAcc 0.6100 TestAcc 0.5413 0.6150
epoch 100 LossPred 0.9175 LossAtt 0.3799 TrainAcc 0.6200 TestAcc 0.5916 0.6200
epoch 200 LossPred 0.5729 LossAtt 0.4145 TrainAcc 0.8600 TestAcc 0.7898 0.8150
epoch 300 LossPred 0.4699 LossAtt 0.3806 TrainAcc 0.8500 TestAcc 0.8026 0.8450
epoch 400 LossPred 0.3973 LossAtt 0.3848 TrainAcc 0.8600 TestAcc 0.8398 0.8350
epoch 500 LossPred 0.3394 LossAtt 0.3690 TrainAcc 0.8700 TestAcc 0.8889 0.8550
epoch 600 LossPred 0.2825 LossAtt 0.3754 TrainAcc 0.9100 TestAcc 0.8986 0.8800
epoch 700 LossPred 0.2949 LossAtt 0.3827 TrainAcc 0.9000 TestAcc 0.8859 0.8750
epoch 800 LossPred 0.4187 LossAtt 0.3851 TrainAcc 0.8500 TestAcc 0.8198 0.8300
epoch 900 LossPred 0.3017 LossAtt 0.3645 TrainAcc 0.8900 TestAcc 0.8771 0.8700
epoch 1000 LossPred 0.3499 LossAtt 0.3908 TrainAcc 0.8700 TestAcc 0.8524 0.8550
epoch 1100 LossPred 0.3705 LossAtt 0.3756 TrainAcc 0.8700 TestAcc 0.8471 0.8350
epoch 1200 LossPred 0.2462 LossAtt 0.3665 TrainAcc 0.9100 TestAcc 0.8879 0.8800
epoch 1300 LossPred 0.2854 LossAtt 0.3722 TrainAcc 0.9000 TestAcc 0.8729 0.8650
epoch 1400 LossPred 0.2774 LossAtt 0.3566 TrainAcc 0.9000 TestAcc 0.8701 0.8600
epoch 1500 LossPred 0.2389 LossAtt 0.3567 TrainAcc 0.9300 TestAcc 0.9044 0.9050
epoch 1600 LossPred 0.2648 LossAtt 0.3610 TrainAcc 0.9300 TestAcc 0.8781 0.8800
epoch 1700 LossPred 0.2369 LossAtt 0.3815 TrainAcc 0.9300 TestAcc 0.8926 0.9050
epoch 1800 LossPred 0.2554 LossAtt 0.3765 TrainAcc 0.9100 TestAcc 0.8781 0.9000
epoch 1900 LossPred 0.2614 LossAtt 0.3684 TrainAcc 0.9200 TestAcc 0.8861 0.8850
epoch 2000 LossPred 0.2273 LossAtt 0.3762 TrainAcc 0.9000 TestAcc 0.8976 0.8950
epoch 2100 LossPred 0.2694 LossAtt 0.3573 TrainAcc 0.9200 TestAcc 0.8709 0.9150
epoch 2200 LossPred 0.2996 LossAtt 0.3647 TrainAcc 0.9100 TestAcc 0.8784 0.8900
epoch 2300 LossPred 0.4151 LossAtt 0.3607 TrainAcc 0.8200 TestAcc 0.8251 0.8300
epoch 2400 LossPred 0.3109 LossAtt 0.3677 TrainAcc 0.9000 TestAcc 0.8761 0.8700
epoch 2500 LossPred 0.2467 LossAtt 0.3822 TrainAcc 0.9200 TestAcc 0.8711 0.8850
Optimization Finished!
********** replication  59  **********
epoch   0 LossPred 1.2476 LossAtt 1.0010 TrainAcc 0.4500 TestAcc 0.4484 0.4500
epoch 100 LossPred 0.9920 LossAtt 0.2537 TrainAcc 0.5500 TestAcc 0.6041 0.5500
epoch 200 LossPred 0.9827 LossAtt 0.2205 TrainAcc 0.5500 TestAcc 0.6041 0.5500
epoch 300 LossPred 0.9601 LossAtt 0.2561 TrainAcc 0.5900 TestAcc 0.6089 0.5800
epoch 400 LossPred 0.9517 LossAtt 0.2697 TrainAcc 0.5900 TestAcc 0.6089 0.5800
epoch 500 LossPred 0.9399 LossAtt 0.2735 TrainAcc 0.5900 TestAcc 0.6089 0.5800
epoch 600 LossPred 0.9280 LossAtt 0.2270 TrainAcc 0.5900 TestAcc 0.6089 0.5700
epoch 700 LossPred 0.9197 LossAtt 0.2379 TrainAcc 0.5900 TestAcc 0.6089 0.5750
epoch 800 LossPred 0.9029 LossAtt 0.2522 TrainAcc 0.6400 TestAcc 0.6381 0.6400
epoch 900 LossPred 0.8232 LossAtt 0.2882 TrainAcc 0.6500 TestAcc 0.6539 0.6600
epoch 1000 LossPred 0.4893 LossAtt 0.4785 TrainAcc 0.7900 TestAcc 0.7590 0.7850
epoch 1100 LossPred 0.1742 LossAtt 0.4315 TrainAcc 0.9400 TestAcc 0.9067 0.9400
epoch 1200 LossPred 0.1374 LossAtt 0.4194 TrainAcc 0.9600 TestAcc 0.9127 0.9700
epoch 1300 LossPred 0.1226 LossAtt 0.3960 TrainAcc 0.9700 TestAcc 0.9214 0.9650
epoch 1400 LossPred 0.1303 LossAtt 0.4045 TrainAcc 0.9700 TestAcc 0.9294 0.9550
epoch 1500 LossPred 0.1716 LossAtt 0.4084 TrainAcc 0.9300 TestAcc 0.8834 0.9400
epoch 1600 LossPred 0.1160 LossAtt 0.4060 TrainAcc 0.9700 TestAcc 0.9224 0.9500
epoch 1700 LossPred 0.1137 LossAtt 0.4313 TrainAcc 0.9600 TestAcc 0.9287 0.9500
epoch 1800 LossPred 0.0975 LossAtt 0.4140 TrainAcc 0.9800 TestAcc 0.9284 0.9650
epoch 1900 LossPred 0.0939 LossAtt 0.4191 TrainAcc 0.9800 TestAcc 0.9264 0.9750
epoch 2000 LossPred 0.0996 LossAtt 0.4163 TrainAcc 0.9900 TestAcc 0.9189 0.9650
epoch 2100 LossPred 0.2081 LossAtt 0.4274 TrainAcc 0.9300 TestAcc 0.8799 0.9100
epoch 2200 LossPred 0.1053 LossAtt 0.4109 TrainAcc 0.9700 TestAcc 0.9434 0.9500
epoch 2300 LossPred 0.0763 LossAtt 0.4298 TrainAcc 0.9800 TestAcc 0.9429 0.9750
epoch 2400 LossPred 0.1405 LossAtt 0.4109 TrainAcc 0.9500 TestAcc 0.8969 0.9450
epoch 2500 LossPred 0.1859 LossAtt 0.4247 TrainAcc 0.9300 TestAcc 0.9214 0.9250
Optimization Finished!
********** replication  60  **********
epoch   0 LossPred 0.9912 LossAtt 0.9927 TrainAcc 0.5300 TestAcc 0.4930 0.4900
epoch 100 LossPred 0.9284 LossAtt 0.4714 TrainAcc 0.6300 TestAcc 0.6006 0.6300
epoch 200 LossPred 0.9215 LossAtt 0.4506 TrainAcc 0.6300 TestAcc 0.6006 0.6300
epoch 300 LossPred 0.8946 LossAtt 0.5331 TrainAcc 0.6500 TestAcc 0.6169 0.6350
epoch 400 LossPred 0.8062 LossAtt 0.5801 TrainAcc 0.6900 TestAcc 0.7245 0.7000
epoch 500 LossPred 0.3678 LossAtt 0.5412 TrainAcc 0.8700 TestAcc 0.8871 0.8550
epoch 600 LossPred 0.2609 LossAtt 0.5599 TrainAcc 0.9100 TestAcc 0.8881 0.9050
epoch 700 LossPred 0.2315 LossAtt 0.5447 TrainAcc 0.9200 TestAcc 0.8959 0.9200
epoch 800 LossPred 0.1837 LossAtt 0.5672 TrainAcc 0.9500 TestAcc 0.8926 0.9250
epoch 900 LossPred 0.1873 LossAtt 0.5709 TrainAcc 0.9400 TestAcc 0.9064 0.9300
epoch 1000 LossPred 0.2180 LossAtt 0.5784 TrainAcc 0.9300 TestAcc 0.8884 0.9250
epoch 1100 LossPred 0.2597 LossAtt 0.5694 TrainAcc 0.9400 TestAcc 0.8719 0.9150
epoch 1200 LossPred 0.2213 LossAtt 0.5420 TrainAcc 0.9200 TestAcc 0.8774 0.9300
epoch 1300 LossPred 0.1618 LossAtt 0.5430 TrainAcc 0.9500 TestAcc 0.9122 0.9300
epoch 1400 LossPred 0.2297 LossAtt 0.5219 TrainAcc 0.9200 TestAcc 0.8809 0.9350
epoch 1500 LossPred 0.1563 LossAtt 0.5127 TrainAcc 0.9400 TestAcc 0.8989 0.9350
epoch 1600 LossPred 0.1937 LossAtt 0.5062 TrainAcc 0.9400 TestAcc 0.8851 0.9400
epoch 1700 LossPred 0.1115 LossAtt 0.4760 TrainAcc 0.9800 TestAcc 0.9079 0.9500
epoch 1800 LossPred 0.1193 LossAtt 0.5098 TrainAcc 0.9600 TestAcc 0.9122 0.9650
epoch 1900 LossPred 0.1048 LossAtt 0.4968 TrainAcc 0.9700 TestAcc 0.9057 0.9600
epoch 2000 LossPred 0.1069 LossAtt 0.4843 TrainAcc 0.9800 TestAcc 0.9132 0.9400
epoch 2100 LossPred 0.2398 LossAtt 0.5017 TrainAcc 0.9200 TestAcc 0.8894 0.9350
epoch 2200 LossPred 0.1009 LossAtt 0.5024 TrainAcc 0.9800 TestAcc 0.9069 0.9500
epoch 2300 LossPred 0.1877 LossAtt 0.4815 TrainAcc 0.9200 TestAcc 0.8911 0.9250
epoch 2400 LossPred 0.1248 LossAtt 0.4667 TrainAcc 0.9600 TestAcc 0.9244 0.9700
epoch 2500 LossPred 0.2046 LossAtt 0.4655 TrainAcc 0.9300 TestAcc 0.8951 0.9350
Optimization Finished!
********** replication  61  **********
epoch   0 LossPred 1.1331 LossAtt 1.0113 TrainAcc 0.4600 TestAcc 0.5183 0.4600
epoch 100 LossPred 0.9927 LossAtt 0.4362 TrainAcc 0.5300 TestAcc 0.4167 0.5250
epoch 200 LossPred 0.9772 LossAtt 0.3835 TrainAcc 0.5400 TestAcc 0.4334 0.5700
epoch 300 LossPred 0.9458 LossAtt 0.4031 TrainAcc 0.6300 TestAcc 0.5793 0.6300
epoch 400 LossPred 0.8978 LossAtt 0.4208 TrainAcc 0.6400 TestAcc 0.5886 0.6400
epoch 500 LossPred 0.8573 LossAtt 0.4500 TrainAcc 0.6700 TestAcc 0.6031 0.6700
epoch 600 LossPred 0.6317 LossAtt 0.4471 TrainAcc 0.7800 TestAcc 0.7615 0.7800
epoch 700 LossPred 0.4988 LossAtt 0.4623 TrainAcc 0.8200 TestAcc 0.8231 0.8500
epoch 800 LossPred 0.3813 LossAtt 0.4857 TrainAcc 0.8600 TestAcc 0.8188 0.8550
epoch 900 LossPred 0.1977 LossAtt 0.4175 TrainAcc 0.9400 TestAcc 0.8916 0.9200
epoch 1000 LossPred 0.1609 LossAtt 0.4044 TrainAcc 0.9600 TestAcc 0.8759 0.9050
epoch 1100 LossPred 0.1734 LossAtt 0.3630 TrainAcc 0.9500 TestAcc 0.8924 0.9350
epoch 1200 LossPred 0.1645 LossAtt 0.3640 TrainAcc 0.9500 TestAcc 0.8881 0.9550
epoch 1300 LossPred 0.2416 LossAtt 0.3702 TrainAcc 0.9200 TestAcc 0.8534 0.8950
epoch 1400 LossPred 0.3215 LossAtt 0.3780 TrainAcc 0.8700 TestAcc 0.8398 0.8900
epoch 1500 LossPred 0.1816 LossAtt 0.4016 TrainAcc 0.9200 TestAcc 0.8696 0.9200
epoch 1600 LossPred 0.1359 LossAtt 0.4626 TrainAcc 0.9700 TestAcc 0.8986 0.9450
epoch 1700 LossPred 0.1806 LossAtt 0.4723 TrainAcc 0.9400 TestAcc 0.8856 0.9350
epoch 1800 LossPred 0.1376 LossAtt 0.4841 TrainAcc 0.9600 TestAcc 0.8836 0.9500
epoch 1900 LossPred 0.1690 LossAtt 0.4755 TrainAcc 0.9500 TestAcc 0.8936 0.9250
epoch 2000 LossPred 0.2432 LossAtt 0.4666 TrainAcc 0.9100 TestAcc 0.8701 0.8950
epoch 2100 LossPred 0.1221 LossAtt 0.4855 TrainAcc 0.9600 TestAcc 0.8864 0.9650
epoch 2200 LossPred 0.2721 LossAtt 0.4901 TrainAcc 0.8900 TestAcc 0.8521 0.9000
epoch 2300 LossPred 0.1930 LossAtt 0.4551 TrainAcc 0.9300 TestAcc 0.8694 0.9300
epoch 2400 LossPred 0.1122 LossAtt 0.4329 TrainAcc 0.9700 TestAcc 0.8791 0.9700
epoch 2500 LossPred 0.1122 LossAtt 0.4399 TrainAcc 0.9700 TestAcc 0.8764 0.9700
Optimization Finished!
********** replication  62  **********
epoch   0 LossPred 1.1584 LossAtt 1.0368 TrainAcc 0.4400 TestAcc 0.4394 0.4700
epoch 100 LossPred 0.9587 LossAtt 0.5015 TrainAcc 0.5600 TestAcc 0.4940 0.5600
epoch 200 LossPred 0.8657 LossAtt 0.4703 TrainAcc 0.6700 TestAcc 0.6014 0.7000
epoch 300 LossPred 0.6005 LossAtt 0.5674 TrainAcc 0.8300 TestAcc 0.7382 0.8350
epoch 400 LossPred 0.2393 LossAtt 0.5697 TrainAcc 0.9400 TestAcc 0.8911 0.9450
epoch 500 LossPred 0.1777 LossAtt 0.4712 TrainAcc 0.9700 TestAcc 0.8986 0.9550
epoch 600 LossPred 0.1930 LossAtt 0.4219 TrainAcc 0.9500 TestAcc 0.8826 0.9600
epoch 700 LossPred 0.2231 LossAtt 0.4126 TrainAcc 0.9300 TestAcc 0.8926 0.9400
epoch 800 LossPred 0.1468 LossAtt 0.3913 TrainAcc 0.9600 TestAcc 0.9039 0.9650
epoch 900 LossPred 0.1262 LossAtt 0.4072 TrainAcc 0.9700 TestAcc 0.9222 0.9750
epoch 1000 LossPred 0.1136 LossAtt 0.3946 TrainAcc 0.9800 TestAcc 0.9224 0.9700
epoch 1100 LossPred 0.1197 LossAtt 0.3881 TrainAcc 0.9700 TestAcc 0.9229 0.9650
epoch 1200 LossPred 0.1111 LossAtt 0.3575 TrainAcc 0.9800 TestAcc 0.9259 0.9700
epoch 1300 LossPred 0.1279 LossAtt 0.3762 TrainAcc 0.9700 TestAcc 0.9214 0.9700
epoch 1400 LossPred 0.0973 LossAtt 0.3616 TrainAcc 0.9900 TestAcc 0.9347 0.9650
epoch 1500 LossPred 0.0830 LossAtt 0.3481 TrainAcc 0.9900 TestAcc 0.9442 0.9850
epoch 1600 LossPred 0.0815 LossAtt 0.3828 TrainAcc 0.9900 TestAcc 0.9419 0.9800
epoch 1700 LossPred 0.1087 LossAtt 0.3609 TrainAcc 0.9800 TestAcc 0.9302 0.9750
epoch 1800 LossPred 0.0890 LossAtt 0.3549 TrainAcc 0.9900 TestAcc 0.9314 0.9750
epoch 1900 LossPred 0.0670 LossAtt 0.3541 TrainAcc 0.9900 TestAcc 0.9527 0.9850
epoch 2000 LossPred 0.0796 LossAtt 0.3713 TrainAcc 0.9900 TestAcc 0.9374 0.9700
epoch 2100 LossPred 0.0826 LossAtt 0.3539 TrainAcc 0.9900 TestAcc 0.9392 0.9700
epoch 2200 LossPred 0.0606 LossAtt 0.3582 TrainAcc 0.9900 TestAcc 0.9530 0.9850
epoch 2300 LossPred 0.0677 LossAtt 0.3619 TrainAcc 0.9900 TestAcc 0.9555 0.9750
epoch 2400 LossPred 0.0593 LossAtt 0.3559 TrainAcc 0.9900 TestAcc 0.9550 0.9800
epoch 2500 LossPred 0.0731 LossAtt 0.3610 TrainAcc 0.9900 TestAcc 0.9432 0.9800
Optimization Finished!
********** replication  63  **********
epoch   0 LossPred 1.1173 LossAtt 1.0118 TrainAcc 0.4800 TestAcc 0.4640 0.4600
epoch 100 LossPred 0.9400 LossAtt 0.4488 TrainAcc 0.6300 TestAcc 0.6004 0.6300
epoch 200 LossPred 0.8984 LossAtt 0.4571 TrainAcc 0.6300 TestAcc 0.6004 0.6250
epoch 300 LossPred 0.8463 LossAtt 0.5212 TrainAcc 0.6100 TestAcc 0.6169 0.6450
epoch 400 LossPred 0.5735 LossAtt 0.5485 TrainAcc 0.8500 TestAcc 0.8448 0.8350
epoch 500 LossPred 0.3782 LossAtt 0.5414 TrainAcc 0.9000 TestAcc 0.8874 0.8800
epoch 600 LossPred 0.2190 LossAtt 0.5373 TrainAcc 0.9700 TestAcc 0.9432 0.8900
epoch 700 LossPred 0.5913 LossAtt 0.5215 TrainAcc 0.7600 TestAcc 0.7588 0.7700
epoch 800 LossPred 0.3184 LossAtt 0.4717 TrainAcc 0.9000 TestAcc 0.8869 0.8600
epoch 900 LossPred 0.2387 LossAtt 0.4263 TrainAcc 0.9300 TestAcc 0.9082 0.8700
epoch 1000 LossPred 0.5242 LossAtt 0.4261 TrainAcc 0.7900 TestAcc 0.7668 0.8100
epoch 1100 LossPred 0.3415 LossAtt 0.4153 TrainAcc 0.8800 TestAcc 0.8929 0.8900
epoch 1200 LossPred 0.3266 LossAtt 0.4219 TrainAcc 0.9000 TestAcc 0.8794 0.8350
epoch 1300 LossPred 0.2796 LossAtt 0.4243 TrainAcc 0.9000 TestAcc 0.8846 0.8400
epoch 1400 LossPred 0.3557 LossAtt 0.4319 TrainAcc 0.8700 TestAcc 0.8829 0.8750
epoch 1500 LossPred 0.4115 LossAtt 0.4334 TrainAcc 0.8500 TestAcc 0.8436 0.8300
epoch 1600 LossPred 0.3939 LossAtt 0.4185 TrainAcc 0.8600 TestAcc 0.8559 0.8000
epoch 1700 LossPred 0.4052 LossAtt 0.3800 TrainAcc 0.8600 TestAcc 0.8649 0.8550
epoch 1800 LossPred 0.3589 LossAtt 0.4116 TrainAcc 0.8600 TestAcc 0.8511 0.8250
epoch 1900 LossPred 0.3336 LossAtt 0.4150 TrainAcc 0.8900 TestAcc 0.8674 0.8300
epoch 2000 LossPred 0.5188 LossAtt 0.4129 TrainAcc 0.8100 TestAcc 0.8346 0.8150
epoch 2100 LossPred 0.2934 LossAtt 0.4068 TrainAcc 0.9100 TestAcc 0.8714 0.8600
epoch 2200 LossPred 0.3778 LossAtt 0.3976 TrainAcc 0.8800 TestAcc 0.8666 0.8650
epoch 2300 LossPred 0.4016 LossAtt 0.4186 TrainAcc 0.8600 TestAcc 0.8443 0.8150
epoch 2400 LossPred 0.3667 LossAtt 0.4133 TrainAcc 0.8900 TestAcc 0.8521 0.8450
epoch 2500 LossPred 0.3810 LossAtt 0.4226 TrainAcc 0.8700 TestAcc 0.8516 0.8500
Optimization Finished!
********** replication  64  **********
epoch   0 LossPred 1.1517 LossAtt 0.9962 TrainAcc 0.4500 TestAcc 0.4635 0.4800
epoch 100 LossPred 0.9673 LossAtt 0.4225 TrainAcc 0.6300 TestAcc 0.6074 0.6200
epoch 200 LossPred 0.9253 LossAtt 0.4461 TrainAcc 0.6200 TestAcc 0.6119 0.6200
epoch 300 LossPred 0.8956 LossAtt 0.4394 TrainAcc 0.6300 TestAcc 0.6542 0.6200
epoch 400 LossPred 0.4110 LossAtt 0.4336 TrainAcc 0.9100 TestAcc 0.8736 0.8600
epoch 500 LossPred 0.3204 LossAtt 0.4271 TrainAcc 0.9200 TestAcc 0.8804 0.8650
epoch 600 LossPred 0.3078 LossAtt 0.3990 TrainAcc 0.9100 TestAcc 0.8816 0.8900
epoch 700 LossPred 0.2829 LossAtt 0.3680 TrainAcc 0.9100 TestAcc 0.8864 0.8800
epoch 800 LossPred 0.2338 LossAtt 0.3625 TrainAcc 0.9200 TestAcc 0.8956 0.9100
epoch 900 LossPred 0.2130 LossAtt 0.3540 TrainAcc 0.9400 TestAcc 0.9069 0.8900
epoch 1000 LossPred 0.2141 LossAtt 0.3613 TrainAcc 0.9300 TestAcc 0.9022 0.9000
epoch 1100 LossPred 0.1933 LossAtt 0.3621 TrainAcc 0.9500 TestAcc 0.9087 0.8800
epoch 1200 LossPred 0.1641 LossAtt 0.3465 TrainAcc 0.9400 TestAcc 0.9134 0.9150
epoch 1300 LossPred 0.1646 LossAtt 0.3537 TrainAcc 0.9600 TestAcc 0.9257 0.8850
epoch 1400 LossPred 0.2527 LossAtt 0.3358 TrainAcc 0.9200 TestAcc 0.8994 0.8250
epoch 1500 LossPred 0.1855 LossAtt 0.3399 TrainAcc 0.9600 TestAcc 0.9089 0.8800
epoch 1600 LossPred 0.1738 LossAtt 0.3422 TrainAcc 0.9300 TestAcc 0.9192 0.9300
epoch 1700 LossPred 0.1542 LossAtt 0.3256 TrainAcc 0.9700 TestAcc 0.9107 0.9200
epoch 1800 LossPred 0.1777 LossAtt 0.3312 TrainAcc 0.9300 TestAcc 0.9189 0.9450
epoch 1900 LossPred 0.2373 LossAtt 0.3182 TrainAcc 0.9300 TestAcc 0.8864 0.8500
epoch 2000 LossPred 0.2496 LossAtt 0.3097 TrainAcc 0.9300 TestAcc 0.9084 0.9300
epoch 2100 LossPred 0.1785 LossAtt 0.3201 TrainAcc 0.9600 TestAcc 0.9129 0.8800
epoch 2200 LossPred 0.1361 LossAtt 0.3309 TrainAcc 0.9600 TestAcc 0.9264 0.9400
epoch 2300 LossPred 0.1696 LossAtt 0.3175 TrainAcc 0.9600 TestAcc 0.9047 0.9000
epoch 2400 LossPred 0.1609 LossAtt 0.3200 TrainAcc 0.9400 TestAcc 0.9347 0.9300
epoch 2500 LossPred 0.1985 LossAtt 0.3103 TrainAcc 0.9400 TestAcc 0.8986 0.9000
Optimization Finished!
********** replication  65  **********
epoch   0 LossPred 1.2604 LossAtt 1.0011 TrainAcc 0.3700 TestAcc 0.4560 0.3750
epoch 100 LossPred 0.9283 LossAtt 0.4957 TrainAcc 0.6000 TestAcc 0.6421 0.6250
epoch 200 LossPred 0.6985 LossAtt 0.4528 TrainAcc 0.7900 TestAcc 0.7833 0.7800
epoch 300 LossPred 0.3681 LossAtt 0.3750 TrainAcc 0.8700 TestAcc 0.8874 0.8700
epoch 400 LossPred 0.3454 LossAtt 0.3002 TrainAcc 0.8800 TestAcc 0.8874 0.8600
epoch 500 LossPred 0.4170 LossAtt 0.2663 TrainAcc 0.8500 TestAcc 0.8776 0.8300
epoch 600 LossPred 0.3125 LossAtt 0.2486 TrainAcc 0.8800 TestAcc 0.8931 0.8650
epoch 700 LossPred 0.4138 LossAtt 0.2629 TrainAcc 0.8800 TestAcc 0.8233 0.8550
epoch 800 LossPred 0.3936 LossAtt 0.2455 TrainAcc 0.8600 TestAcc 0.8331 0.8650
epoch 900 LossPred 0.3163 LossAtt 0.2685 TrainAcc 0.8800 TestAcc 0.8741 0.8800
epoch 1000 LossPred 0.2977 LossAtt 0.2736 TrainAcc 0.8900 TestAcc 0.8786 0.8700
epoch 1100 LossPred 0.4694 LossAtt 0.2915 TrainAcc 0.8400 TestAcc 0.8201 0.8300
epoch 1200 LossPred 0.2706 LossAtt 0.2958 TrainAcc 0.8900 TestAcc 0.8931 0.8700
epoch 1300 LossPred 0.4710 LossAtt 0.2975 TrainAcc 0.8800 TestAcc 0.7935 0.8400
epoch 1400 LossPred 0.4239 LossAtt 0.3187 TrainAcc 0.8900 TestAcc 0.8253 0.8600
epoch 1500 LossPred 0.4557 LossAtt 0.3228 TrainAcc 0.8700 TestAcc 0.8003 0.8400
epoch 1600 LossPred 0.6352 LossAtt 0.3090 TrainAcc 0.8200 TestAcc 0.7420 0.7850
epoch 1700 LossPred 0.4257 LossAtt 0.3459 TrainAcc 0.8600 TestAcc 0.8241 0.8350
epoch 1800 LossPred 0.3411 LossAtt 0.3787 TrainAcc 0.8800 TestAcc 0.8624 0.8700
epoch 1900 LossPred 0.4589 LossAtt 0.4064 TrainAcc 0.8200 TestAcc 0.8003 0.8400
epoch 2000 LossPred 0.3781 LossAtt 0.3796 TrainAcc 0.8500 TestAcc 0.8338 0.8550
epoch 2100 LossPred 0.2741 LossAtt 0.3936 TrainAcc 0.9200 TestAcc 0.8686 0.8800
epoch 2200 LossPred 0.3139 LossAtt 0.3840 TrainAcc 0.9100 TestAcc 0.8371 0.8750
epoch 2300 LossPred 0.3745 LossAtt 0.3929 TrainAcc 0.8800 TestAcc 0.8383 0.8500
epoch 2400 LossPred 0.2483 LossAtt 0.4179 TrainAcc 0.9200 TestAcc 0.8729 0.8700
epoch 2500 LossPred 0.2711 LossAtt 0.3831 TrainAcc 0.9100 TestAcc 0.8624 0.8750
Optimization Finished!
********** replication  66  **********
epoch   0 LossPred 1.1886 LossAtt 1.0117 TrainAcc 0.3700 TestAcc 0.3911 0.3650
epoch 100 LossPred 0.8073 LossAtt 0.3407 TrainAcc 0.7300 TestAcc 0.6269 0.7200
epoch 200 LossPred 0.4141 LossAtt 0.3399 TrainAcc 0.8900 TestAcc 0.8138 0.8750
epoch 300 LossPred 0.3130 LossAtt 0.3462 TrainAcc 0.9300 TestAcc 0.8338 0.8800
epoch 400 LossPred 0.2570 LossAtt 0.3575 TrainAcc 0.9400 TestAcc 0.8626 0.8900
epoch 500 LossPred 0.2202 LossAtt 0.3541 TrainAcc 0.9300 TestAcc 0.9077 0.9050
epoch 600 LossPred 0.1828 LossAtt 0.3732 TrainAcc 0.9400 TestAcc 0.9219 0.9150
epoch 700 LossPred 0.2342 LossAtt 0.3468 TrainAcc 0.9200 TestAcc 0.8323 0.8950
epoch 800 LossPred 0.1222 LossAtt 0.3732 TrainAcc 0.9800 TestAcc 0.9162 0.9250
epoch 900 LossPred 0.1307 LossAtt 0.3619 TrainAcc 0.9800 TestAcc 0.9224 0.9200
epoch 1000 LossPred 0.1017 LossAtt 0.3774 TrainAcc 0.9800 TestAcc 0.9074 0.9200
epoch 1100 LossPred 0.1091 LossAtt 0.3414 TrainAcc 0.9700 TestAcc 0.9137 0.9250
epoch 1200 LossPred 0.1097 LossAtt 0.3665 TrainAcc 0.9800 TestAcc 0.9357 0.9300
epoch 1300 LossPred 0.0766 LossAtt 0.3594 TrainAcc 0.9900 TestAcc 0.9314 0.9250
epoch 1400 LossPred 0.0697 LossAtt 0.3606 TrainAcc 0.9900 TestAcc 0.9449 0.9350
epoch 1500 LossPred 0.1156 LossAtt 0.3260 TrainAcc 0.9600 TestAcc 0.9157 0.9350
epoch 1600 LossPred 0.1808 LossAtt 0.3032 TrainAcc 0.9400 TestAcc 0.8466 0.9250
epoch 1700 LossPred 0.1233 LossAtt 0.3068 TrainAcc 0.9700 TestAcc 0.8894 0.9350
epoch 1800 LossPred 0.1182 LossAtt 0.2976 TrainAcc 0.9600 TestAcc 0.9147 0.9300
epoch 1900 LossPred 0.1134 LossAtt 0.2924 TrainAcc 0.9600 TestAcc 0.9204 0.9300
epoch 2000 LossPred 0.1101 LossAtt 0.3044 TrainAcc 0.9600 TestAcc 0.9227 0.9400
epoch 2100 LossPred 0.1423 LossAtt 0.2958 TrainAcc 0.9500 TestAcc 0.9304 0.9350
epoch 2200 LossPred 0.1080 LossAtt 0.3099 TrainAcc 0.9500 TestAcc 0.9309 0.9550
epoch 2300 LossPred 0.1194 LossAtt 0.2893 TrainAcc 0.9600 TestAcc 0.8886 0.9250
epoch 2400 LossPred 0.0987 LossAtt 0.3133 TrainAcc 0.9700 TestAcc 0.9224 0.9350
epoch 2500 LossPred 0.1194 LossAtt 0.2834 TrainAcc 0.9600 TestAcc 0.8969 0.9400
Optimization Finished!
********** replication  67  **********
epoch   0 LossPred 1.0387 LossAtt 1.0083 TrainAcc 0.5300 TestAcc 0.5606 0.5350
epoch 100 LossPred 0.9723 LossAtt 0.3524 TrainAcc 0.5700 TestAcc 0.5761 0.5850
epoch 200 LossPred 0.9428 LossAtt 0.3337 TrainAcc 0.6100 TestAcc 0.6001 0.5900
epoch 300 LossPred 0.9024 LossAtt 0.3213 TrainAcc 0.6100 TestAcc 0.6016 0.6100
epoch 400 LossPred 0.2753 LossAtt 0.4246 TrainAcc 0.9500 TestAcc 0.8554 0.9150
epoch 500 LossPred 0.1726 LossAtt 0.4010 TrainAcc 0.9700 TestAcc 0.8834 0.9450
epoch 600 LossPred 0.1659 LossAtt 0.3923 TrainAcc 0.9600 TestAcc 0.8951 0.9350
epoch 700 LossPred 0.1207 LossAtt 0.3646 TrainAcc 0.9700 TestAcc 0.9002 0.9600
epoch 800 LossPred 0.1155 LossAtt 0.3561 TrainAcc 0.9700 TestAcc 0.9012 0.9700
epoch 900 LossPred 0.0896 LossAtt 0.3435 TrainAcc 0.9800 TestAcc 0.8984 0.9800
epoch 1000 LossPred 0.0900 LossAtt 0.3048 TrainAcc 0.9800 TestAcc 0.8996 0.9800
epoch 1100 LossPred 0.1481 LossAtt 0.2959 TrainAcc 0.9600 TestAcc 0.8836 0.9550
epoch 1200 LossPred 0.1931 LossAtt 0.3020 TrainAcc 0.9500 TestAcc 0.8814 0.9550
epoch 1300 LossPred 0.0608 LossAtt 0.2859 TrainAcc 0.9900 TestAcc 0.9092 0.9800
epoch 1400 LossPred 0.0621 LossAtt 0.3014 TrainAcc 1.0000 TestAcc 0.9097 0.9900
Optimization Finished!
********** replication  68  **********
epoch   0 LossPred 1.0123 LossAtt 0.9961 TrainAcc 0.5800 TestAcc 0.6116 0.5950
epoch 100 LossPred 0.8752 LossAtt 0.5102 TrainAcc 0.6300 TestAcc 0.6214 0.6300
epoch 200 LossPred 0.8017 LossAtt 0.4750 TrainAcc 0.7100 TestAcc 0.6404 0.6850
epoch 300 LossPred 0.7171 LossAtt 0.4783 TrainAcc 0.7400 TestAcc 0.6739 0.7350
epoch 400 LossPred 0.6609 LossAtt 0.4407 TrainAcc 0.7600 TestAcc 0.7365 0.7550
epoch 500 LossPred 0.3252 LossAtt 0.4532 TrainAcc 0.9200 TestAcc 0.9157 0.8950
epoch 600 LossPred 0.2272 LossAtt 0.4219 TrainAcc 0.9500 TestAcc 0.9184 0.9300
epoch 700 LossPred 0.2363 LossAtt 0.4138 TrainAcc 0.9100 TestAcc 0.8906 0.9200
epoch 800 LossPred 0.1409 LossAtt 0.3841 TrainAcc 0.9700 TestAcc 0.9239 0.9600
epoch 900 LossPred 0.1279 LossAtt 0.3596 TrainAcc 0.9800 TestAcc 0.9284 0.9650
epoch 1000 LossPred 0.1375 LossAtt 0.3568 TrainAcc 0.9800 TestAcc 0.9192 0.9800
epoch 1100 LossPred 0.0994 LossAtt 0.3766 TrainAcc 0.9800 TestAcc 0.9219 0.9650
epoch 1200 LossPred 0.0968 LossAtt 0.3458 TrainAcc 0.9800 TestAcc 0.9227 0.9650
epoch 1300 LossPred 0.1319 LossAtt 0.3716 TrainAcc 0.9600 TestAcc 0.9212 0.9550
epoch 1400 LossPred 0.1159 LossAtt 0.3325 TrainAcc 0.9500 TestAcc 0.9137 0.9550
epoch 1500 LossPred 0.0867 LossAtt 0.3484 TrainAcc 0.9900 TestAcc 0.9257 0.9850
epoch 1600 LossPred 0.0729 LossAtt 0.3259 TrainAcc 0.9900 TestAcc 0.9294 0.9700
epoch 1700 LossPred 0.0782 LossAtt 0.3407 TrainAcc 0.9900 TestAcc 0.9199 0.9650
epoch 1800 LossPred 0.0630 LossAtt 0.3188 TrainAcc 0.9900 TestAcc 0.9267 0.9750
epoch 1900 LossPred 0.1653 LossAtt 0.3608 TrainAcc 0.9400 TestAcc 0.9019 0.9550
epoch 2000 LossPred 0.0923 LossAtt 0.3289 TrainAcc 0.9800 TestAcc 0.9254 0.9700
epoch 2100 LossPred 0.0767 LossAtt 0.3306 TrainAcc 0.9800 TestAcc 0.9159 0.9600
epoch 2200 LossPred 0.0517 LossAtt 0.3119 TrainAcc 0.9900 TestAcc 0.9332 0.9700
epoch 2300 LossPred 0.0794 LossAtt 0.3130 TrainAcc 0.9900 TestAcc 0.9149 0.9600
epoch 2400 LossPred 0.0500 LossAtt 0.3075 TrainAcc 0.9900 TestAcc 0.9292 0.9850
epoch 2500 LossPred 0.0562 LossAtt 0.3135 TrainAcc 0.9900 TestAcc 0.9244 0.9600
Optimization Finished!
********** replication  69  **********
epoch   0 LossPred 1.2609 LossAtt 1.0354 TrainAcc 0.5300 TestAcc 0.4499 0.5200
epoch 100 LossPred 1.0321 LossAtt 0.4179 TrainAcc 0.5300 TestAcc 0.4499 0.5100
epoch 200 LossPred 0.9473 LossAtt 0.2939 TrainAcc 0.5100 TestAcc 0.4489 0.5050
epoch 300 LossPred 0.8973 LossAtt 0.3190 TrainAcc 0.6900 TestAcc 0.6424 0.6800
epoch 400 LossPred 0.5217 LossAtt 0.4436 TrainAcc 0.8700 TestAcc 0.8669 0.8300
epoch 500 LossPred 0.4320 LossAtt 0.4453 TrainAcc 0.8600 TestAcc 0.8541 0.8300
epoch 600 LossPred 0.3780 LossAtt 0.4207 TrainAcc 0.8900 TestAcc 0.8311 0.8550
epoch 700 LossPred 0.3458 LossAtt 0.4278 TrainAcc 0.9000 TestAcc 0.8408 0.8800
epoch 800 LossPred 0.4123 LossAtt 0.4330 TrainAcc 0.8800 TestAcc 0.8241 0.8900
epoch 900 LossPred 0.3249 LossAtt 0.4517 TrainAcc 0.9000 TestAcc 0.8579 0.8700
epoch 1000 LossPred 0.3338 LossAtt 0.4302 TrainAcc 0.8900 TestAcc 0.8343 0.8900
epoch 1100 LossPred 0.3269 LossAtt 0.4175 TrainAcc 0.9000 TestAcc 0.8549 0.8600
epoch 1200 LossPred 0.3003 LossAtt 0.3831 TrainAcc 0.9000 TestAcc 0.8491 0.8850
epoch 1300 LossPred 0.3217 LossAtt 0.3846 TrainAcc 0.8900 TestAcc 0.8594 0.8800
epoch 1400 LossPred 0.2950 LossAtt 0.3480 TrainAcc 0.9100 TestAcc 0.8611 0.9000
epoch 1500 LossPred 0.3147 LossAtt 0.3402 TrainAcc 0.9100 TestAcc 0.8338 0.9000
epoch 1600 LossPred 0.2964 LossAtt 0.3376 TrainAcc 0.9000 TestAcc 0.8338 0.9000
epoch 1700 LossPred 0.2847 LossAtt 0.3368 TrainAcc 0.9100 TestAcc 0.8408 0.9100
epoch 1800 LossPred 0.2752 LossAtt 0.3569 TrainAcc 0.9100 TestAcc 0.8551 0.8950
epoch 1900 LossPred 0.3573 LossAtt 0.3608 TrainAcc 0.8900 TestAcc 0.8266 0.8850
epoch 2000 LossPred 0.2760 LossAtt 0.3339 TrainAcc 0.9000 TestAcc 0.8376 0.9000
epoch 2100 LossPred 0.2888 LossAtt 0.3449 TrainAcc 0.9200 TestAcc 0.8654 0.9150
epoch 2200 LossPred 0.2828 LossAtt 0.3367 TrainAcc 0.9200 TestAcc 0.8493 0.9100
epoch 2300 LossPred 0.3558 LossAtt 0.3315 TrainAcc 0.9000 TestAcc 0.8669 0.9050
epoch 2400 LossPred 0.2857 LossAtt 0.3426 TrainAcc 0.9200 TestAcc 0.8706 0.9200
epoch 2500 LossPred 0.2753 LossAtt 0.3552 TrainAcc 0.9300 TestAcc 0.8699 0.9300
Optimization Finished!
********** replication  70  **********
epoch   0 LossPred 1.2481 LossAtt 1.0209 TrainAcc 0.4800 TestAcc 0.5691 0.4800
epoch 100 LossPred 1.0208 LossAtt 0.4980 TrainAcc 0.5200 TestAcc 0.5483 0.5150
epoch 200 LossPred 0.9868 LossAtt 0.4269 TrainAcc 0.5700 TestAcc 0.5383 0.5800
epoch 300 LossPred 0.9700 LossAtt 0.4646 TrainAcc 0.5700 TestAcc 0.5300 0.5750
epoch 400 LossPred 0.9623 LossAtt 0.4734 TrainAcc 0.5700 TestAcc 0.5305 0.5950
epoch 500 LossPred 0.9570 LossAtt 0.4620 TrainAcc 0.5600 TestAcc 0.5243 0.5950
epoch 600 LossPred 0.9496 LossAtt 0.4986 TrainAcc 0.5800 TestAcc 0.5335 0.5800
epoch 700 LossPred 0.9375 LossAtt 0.5098 TrainAcc 0.6000 TestAcc 0.5333 0.5850
epoch 800 LossPred 0.9302 LossAtt 0.4941 TrainAcc 0.6000 TestAcc 0.5138 0.6000
epoch 900 LossPred 0.9149 LossAtt 0.4678 TrainAcc 0.6200 TestAcc 0.5153 0.6150
epoch 1000 LossPred 0.9038 LossAtt 0.4681 TrainAcc 0.6600 TestAcc 0.5385 0.6100
epoch 1100 LossPred 0.9026 LossAtt 0.4628 TrainAcc 0.6500 TestAcc 0.5343 0.5900
epoch 1200 LossPred 0.8926 LossAtt 0.4509 TrainAcc 0.6700 TestAcc 0.5205 0.5950
epoch 1300 LossPred 0.8872 LossAtt 0.4597 TrainAcc 0.6200 TestAcc 0.5295 0.6100
epoch 1400 LossPred 0.8719 LossAtt 0.4272 TrainAcc 0.6300 TestAcc 0.5285 0.6000
epoch 1500 LossPred 0.8547 LossAtt 0.4502 TrainAcc 0.6700 TestAcc 0.5293 0.6250
epoch 1600 LossPred 0.8436 LossAtt 0.4091 TrainAcc 0.6800 TestAcc 0.5310 0.6200
epoch 1700 LossPred 0.8392 LossAtt 0.3921 TrainAcc 0.6900 TestAcc 0.5293 0.6200
epoch 1800 LossPred 0.8530 LossAtt 0.3901 TrainAcc 0.6800 TestAcc 0.5320 0.6250
epoch 1900 LossPred 0.8650 LossAtt 0.3689 TrainAcc 0.6700 TestAcc 0.5298 0.6200
epoch 2000 LossPred 0.8065 LossAtt 0.3592 TrainAcc 0.7000 TestAcc 0.5343 0.6150
epoch 2100 LossPred 0.8175 LossAtt 0.3686 TrainAcc 0.6800 TestAcc 0.5330 0.6150
epoch 2200 LossPred 0.9164 LossAtt 0.4124 TrainAcc 0.6100 TestAcc 0.5233 0.6050
epoch 2300 LossPred 0.8536 LossAtt 0.3527 TrainAcc 0.6500 TestAcc 0.5238 0.6250
epoch 2400 LossPred 0.8559 LossAtt 0.3866 TrainAcc 0.6900 TestAcc 0.5200 0.6100
epoch 2500 LossPred 0.8494 LossAtt 0.3791 TrainAcc 0.6600 TestAcc 0.5255 0.6150
Optimization Finished!
********** replication  71  **********
epoch   0 LossPred 1.0927 LossAtt 0.9987 TrainAcc 0.5600 TestAcc 0.5480 0.5350
epoch 100 LossPred 0.9163 LossAtt 0.5022 TrainAcc 0.6000 TestAcc 0.5883 0.5750
epoch 200 LossPred 0.8481 LossAtt 0.5144 TrainAcc 0.6800 TestAcc 0.5858 0.6800
epoch 300 LossPred 0.7540 LossAtt 0.5374 TrainAcc 0.7400 TestAcc 0.6421 0.7200
epoch 400 LossPred 0.3348 LossAtt 0.5113 TrainAcc 0.9200 TestAcc 0.8466 0.9050
epoch 500 LossPred 0.2809 LossAtt 0.5026 TrainAcc 0.9400 TestAcc 0.8541 0.9300
epoch 600 LossPred 0.2314 LossAtt 0.4869 TrainAcc 0.9500 TestAcc 0.8616 0.9400
epoch 700 LossPred 0.2602 LossAtt 0.4378 TrainAcc 0.9000 TestAcc 0.8759 0.9150
epoch 800 LossPred 0.1761 LossAtt 0.4349 TrainAcc 0.9600 TestAcc 0.8776 0.9550
epoch 900 LossPred 0.2236 LossAtt 0.4234 TrainAcc 0.9200 TestAcc 0.8791 0.9250
epoch 1000 LossPred 0.1571 LossAtt 0.4079 TrainAcc 0.9600 TestAcc 0.8839 0.9550
epoch 1100 LossPred 0.1974 LossAtt 0.3909 TrainAcc 0.9400 TestAcc 0.8649 0.9350
epoch 1200 LossPred 0.1347 LossAtt 0.4016 TrainAcc 0.9600 TestAcc 0.8784 0.9600
epoch 1300 LossPred 0.1480 LossAtt 0.4263 TrainAcc 0.9600 TestAcc 0.8711 0.9600
epoch 1400 LossPred 0.1156 LossAtt 0.4424 TrainAcc 0.9800 TestAcc 0.8814 0.9700
epoch 1500 LossPred 0.1933 LossAtt 0.4187 TrainAcc 0.9300 TestAcc 0.8656 0.9300
epoch 1600 LossPred 0.1070 LossAtt 0.4094 TrainAcc 0.9800 TestAcc 0.8859 0.9650
epoch 1700 LossPred 0.1495 LossAtt 0.4224 TrainAcc 0.9400 TestAcc 0.8744 0.9500
epoch 1800 LossPred 0.1086 LossAtt 0.4369 TrainAcc 0.9700 TestAcc 0.8876 0.9700
epoch 1900 LossPred 0.0960 LossAtt 0.3886 TrainAcc 0.9800 TestAcc 0.8864 0.9600
epoch 2000 LossPred 0.1131 LossAtt 0.4483 TrainAcc 0.9800 TestAcc 0.8849 0.9650
epoch 2100 LossPred 0.1020 LossAtt 0.4237 TrainAcc 0.9800 TestAcc 0.8886 0.9800
epoch 2200 LossPred 0.0939 LossAtt 0.4262 TrainAcc 0.9800 TestAcc 0.8919 0.9800
epoch 2300 LossPred 0.2787 LossAtt 0.4109 TrainAcc 0.9000 TestAcc 0.8681 0.8850
epoch 2400 LossPred 0.1202 LossAtt 0.4165 TrainAcc 0.9700 TestAcc 0.8874 0.9450
epoch 2500 LossPred 0.2008 LossAtt 0.3887 TrainAcc 0.9300 TestAcc 0.8674 0.9100
Optimization Finished!
********** replication  72  **********
epoch   0 LossPred 1.0406 LossAtt 0.9864 TrainAcc 0.5600 TestAcc 0.5666 0.5550
epoch 100 LossPred 0.8853 LossAtt 0.3893 TrainAcc 0.6400 TestAcc 0.6141 0.6400
epoch 200 LossPred 0.8737 LossAtt 0.2592 TrainAcc 0.6400 TestAcc 0.6141 0.6400
epoch 300 LossPred 0.8707 LossAtt 0.2297 TrainAcc 0.6400 TestAcc 0.6141 0.6400
epoch 400 LossPred 0.8688 LossAtt 0.2002 TrainAcc 0.6400 TestAcc 0.6141 0.6400
epoch 500 LossPred 0.8709 LossAtt 0.1554 TrainAcc 0.6400 TestAcc 0.6141 0.6400
epoch 600 LossPred 0.8903 LossAtt 0.1975 TrainAcc 0.6400 TestAcc 0.6141 0.6400
epoch 700 LossPred 0.7480 LossAtt 0.3162 TrainAcc 0.7100 TestAcc 0.7017 0.7100
epoch 800 LossPred 0.3103 LossAtt 0.4052 TrainAcc 0.9200 TestAcc 0.9327 0.8950
epoch 900 LossPred 0.2507 LossAtt 0.4042 TrainAcc 0.9300 TestAcc 0.9224 0.9100
epoch 1000 LossPred 0.2650 LossAtt 0.3800 TrainAcc 0.9200 TestAcc 0.9304 0.9050
epoch 1100 LossPred 0.2205 LossAtt 0.3974 TrainAcc 0.9400 TestAcc 0.8921 0.9000
epoch 1200 LossPred 0.1790 LossAtt 0.3661 TrainAcc 0.9500 TestAcc 0.9302 0.9450
epoch 1300 LossPred 0.5251 LossAtt 0.3489 TrainAcc 0.8200 TestAcc 0.7758 0.8200
epoch 1400 LossPred 0.1903 LossAtt 0.3653 TrainAcc 0.9200 TestAcc 0.9012 0.9100
epoch 1500 LossPred 0.1965 LossAtt 0.3639 TrainAcc 0.9700 TestAcc 0.9384 0.9500
epoch 1600 LossPred 0.1512 LossAtt 0.3826 TrainAcc 0.9700 TestAcc 0.9397 0.9600
epoch 1700 LossPred 0.2588 LossAtt 0.4011 TrainAcc 0.9300 TestAcc 0.9222 0.9400
epoch 1800 LossPred 0.4409 LossAtt 0.3851 TrainAcc 0.8200 TestAcc 0.8744 0.8650
epoch 1900 LossPred 0.2936 LossAtt 0.3995 TrainAcc 0.9100 TestAcc 0.9132 0.9200
epoch 2000 LossPred 0.4212 LossAtt 0.3882 TrainAcc 0.8200 TestAcc 0.8776 0.8450
epoch 2100 LossPred 0.2489 LossAtt 0.4001 TrainAcc 0.9100 TestAcc 0.8916 0.9200
epoch 2200 LossPred 0.3110 LossAtt 0.3947 TrainAcc 0.9000 TestAcc 0.8596 0.8900
epoch 2300 LossPred 0.2664 LossAtt 0.3792 TrainAcc 0.9200 TestAcc 0.9052 0.9350
epoch 2400 LossPred 0.2791 LossAtt 0.3637 TrainAcc 0.9000 TestAcc 0.9107 0.8950
epoch 2500 LossPred 0.3544 LossAtt 0.3513 TrainAcc 0.8800 TestAcc 0.8336 0.8750
Optimization Finished!
********** replication  73  **********
epoch   0 LossPred 1.0247 LossAtt 1.0084 TrainAcc 0.5300 TestAcc 0.5781 0.5750
epoch 100 LossPred 0.9338 LossAtt 0.3060 TrainAcc 0.6200 TestAcc 0.5961 0.6200
epoch 200 LossPred 0.9420 LossAtt 0.1694 TrainAcc 0.6200 TestAcc 0.5961 0.6350
epoch 300 LossPred 0.8974 LossAtt 0.1919 TrainAcc 0.6200 TestAcc 0.5961 0.6550
epoch 400 LossPred 0.8601 LossAtt 0.2404 TrainAcc 0.6600 TestAcc 0.6394 0.6600
epoch 500 LossPred 0.3705 LossAtt 0.2818 TrainAcc 0.9200 TestAcc 0.8216 0.8500
epoch 600 LossPred 0.3449 LossAtt 0.2779 TrainAcc 0.9000 TestAcc 0.8471 0.8550
epoch 700 LossPred 0.3160 LossAtt 0.2834 TrainAcc 0.9200 TestAcc 0.8504 0.8600
epoch 800 LossPred 0.3126 LossAtt 0.3016 TrainAcc 0.9100 TestAcc 0.8496 0.8600
epoch 900 LossPred 0.3018 LossAtt 0.3103 TrainAcc 0.9300 TestAcc 0.8296 0.8500
epoch 1000 LossPred 0.2880 LossAtt 0.3117 TrainAcc 0.9300 TestAcc 0.8473 0.8600
epoch 1100 LossPred 0.2877 LossAtt 0.2999 TrainAcc 0.9300 TestAcc 0.8521 0.8650
epoch 1200 LossPred 0.2824 LossAtt 0.3129 TrainAcc 0.9300 TestAcc 0.8541 0.8600
epoch 1300 LossPred 0.2834 LossAtt 0.3130 TrainAcc 0.9400 TestAcc 0.8531 0.8600
epoch 1400 LossPred 0.2947 LossAtt 0.2822 TrainAcc 0.9400 TestAcc 0.8328 0.8650
epoch 1500 LossPred 0.2986 LossAtt 0.2677 TrainAcc 0.9200 TestAcc 0.8261 0.8650
epoch 1600 LossPred 0.2879 LossAtt 0.2597 TrainAcc 0.9300 TestAcc 0.8318 0.8700
epoch 1700 LossPred 0.2649 LossAtt 0.2440 TrainAcc 0.9400 TestAcc 0.8579 0.8700
epoch 1800 LossPred 0.2943 LossAtt 0.2312 TrainAcc 0.9100 TestAcc 0.8624 0.8600
epoch 1900 LossPred 0.3181 LossAtt 0.2077 TrainAcc 0.9200 TestAcc 0.8564 0.8550
epoch 2000 LossPred 0.3266 LossAtt 0.2061 TrainAcc 0.9100 TestAcc 0.8551 0.8500
epoch 2100 LossPred 0.2524 LossAtt 0.2345 TrainAcc 0.9300 TestAcc 0.8666 0.8700
epoch 2200 LossPred 0.2442 LossAtt 0.2218 TrainAcc 0.9400 TestAcc 0.8654 0.8800
epoch 2300 LossPred 0.2437 LossAtt 0.2209 TrainAcc 0.9400 TestAcc 0.8679 0.8700
epoch 2400 LossPred 0.3212 LossAtt 0.2232 TrainAcc 0.9000 TestAcc 0.8624 0.8700
epoch 2500 LossPred 0.3867 LossAtt 0.2339 TrainAcc 0.8700 TestAcc 0.8188 0.8700
Optimization Finished!
********** replication  74  **********
epoch   0 LossPred 1.0815 LossAtt 0.9912 TrainAcc 0.4200 TestAcc 0.4552 0.4550
epoch 100 LossPred 0.9591 LossAtt 0.4979 TrainAcc 0.5800 TestAcc 0.6026 0.5950
epoch 200 LossPred 0.9189 LossAtt 0.4847 TrainAcc 0.6400 TestAcc 0.6259 0.6300
epoch 300 LossPred 0.4473 LossAtt 0.4813 TrainAcc 0.8800 TestAcc 0.8491 0.8750
epoch 400 LossPred 0.3660 LossAtt 0.4855 TrainAcc 0.8900 TestAcc 0.8473 0.8550
epoch 500 LossPred 0.2988 LossAtt 0.4435 TrainAcc 0.9400 TestAcc 0.8624 0.8550
epoch 600 LossPred 0.2861 LossAtt 0.4422 TrainAcc 0.9300 TestAcc 0.8651 0.8600
epoch 700 LossPred 0.3077 LossAtt 0.4375 TrainAcc 0.8900 TestAcc 0.8609 0.8750
epoch 800 LossPred 0.2678 LossAtt 0.4134 TrainAcc 0.9200 TestAcc 0.8669 0.8700
epoch 900 LossPred 0.2857 LossAtt 0.4031 TrainAcc 0.9000 TestAcc 0.8391 0.8650
epoch 1000 LossPred 0.2662 LossAtt 0.3841 TrainAcc 0.9200 TestAcc 0.8611 0.8750
epoch 1100 LossPred 0.2873 LossAtt 0.3947 TrainAcc 0.8900 TestAcc 0.8716 0.8750
epoch 1200 LossPred 0.2349 LossAtt 0.3557 TrainAcc 0.9400 TestAcc 0.8451 0.8950
epoch 1300 LossPred 0.2426 LossAtt 0.3664 TrainAcc 0.9200 TestAcc 0.8534 0.8900
epoch 1400 LossPred 0.2159 LossAtt 0.3694 TrainAcc 0.9400 TestAcc 0.8431 0.8900
epoch 1500 LossPred 0.2314 LossAtt 0.3520 TrainAcc 0.9200 TestAcc 0.8539 0.8700
epoch 1600 LossPred 0.3894 LossAtt 0.3489 TrainAcc 0.8700 TestAcc 0.8521 0.8700
epoch 1700 LossPred 0.2028 LossAtt 0.3602 TrainAcc 0.9400 TestAcc 0.8421 0.8950
epoch 1800 LossPred 0.3327 LossAtt 0.3429 TrainAcc 0.8700 TestAcc 0.8206 0.8700
epoch 1900 LossPred 0.1997 LossAtt 0.3532 TrainAcc 0.9400 TestAcc 0.8388 0.8850
epoch 2000 LossPred 0.2108 LossAtt 0.3615 TrainAcc 0.9400 TestAcc 0.8468 0.8850
epoch 2100 LossPred 0.2873 LossAtt 0.3437 TrainAcc 0.8800 TestAcc 0.8231 0.8700
epoch 2200 LossPred 0.2416 LossAtt 0.3427 TrainAcc 0.9100 TestAcc 0.8386 0.8800
epoch 2300 LossPred 0.2231 LossAtt 0.3325 TrainAcc 0.9300 TestAcc 0.8341 0.8900
epoch 2400 LossPred 0.2521 LossAtt 0.3409 TrainAcc 0.8900 TestAcc 0.8331 0.8800
epoch 2500 LossPred 0.2283 LossAtt 0.3445 TrainAcc 0.9400 TestAcc 0.8408 0.8950
Optimization Finished!
********** replication  75  **********
epoch   0 LossPred 1.2757 LossAtt 1.0117 TrainAcc 0.5200 TestAcc 0.4980 0.5350
epoch 100 LossPred 1.0530 LossAtt 0.4642 TrainAcc 0.4700 TestAcc 0.4822 0.4550
epoch 200 LossPred 0.9905 LossAtt 0.5001 TrainAcc 0.4800 TestAcc 0.5175 0.4900
epoch 300 LossPred 0.7550 LossAtt 0.5281 TrainAcc 0.8500 TestAcc 0.8604 0.8150
epoch 400 LossPred 0.6092 LossAtt 0.4410 TrainAcc 0.8300 TestAcc 0.8386 0.8250
epoch 500 LossPred 0.4252 LossAtt 0.3633 TrainAcc 0.9000 TestAcc 0.8804 0.9050
epoch 600 LossPred 0.4097 LossAtt 0.3879 TrainAcc 0.8900 TestAcc 0.8584 0.8950
epoch 700 LossPred 0.3254 LossAtt 0.3612 TrainAcc 0.9000 TestAcc 0.8861 0.9050
epoch 800 LossPred 0.4908 LossAtt 0.3649 TrainAcc 0.8400 TestAcc 0.8168 0.8350
epoch 900 LossPred 0.5095 LossAtt 0.3946 TrainAcc 0.8100 TestAcc 0.8098 0.8050
epoch 1000 LossPred 0.4438 LossAtt 0.3700 TrainAcc 0.8700 TestAcc 0.8366 0.8600
epoch 1100 LossPred 0.4621 LossAtt 0.4212 TrainAcc 0.8300 TestAcc 0.8221 0.8200
epoch 1200 LossPred 0.4615 LossAtt 0.3894 TrainAcc 0.8600 TestAcc 0.8241 0.8600
epoch 1300 LossPred 0.4739 LossAtt 0.3976 TrainAcc 0.8400 TestAcc 0.8161 0.8500
epoch 1400 LossPred 0.2549 LossAtt 0.3978 TrainAcc 0.9500 TestAcc 0.9217 0.9450
epoch 1500 LossPred 0.2458 LossAtt 0.3990 TrainAcc 0.9500 TestAcc 0.9204 0.9450
epoch 1600 LossPred 0.2414 LossAtt 0.3856 TrainAcc 0.9600 TestAcc 0.9127 0.9450
epoch 1700 LossPred 0.2245 LossAtt 0.4177 TrainAcc 0.9600 TestAcc 0.9319 0.9500
epoch 1800 LossPred 0.4271 LossAtt 0.4135 TrainAcc 0.8600 TestAcc 0.8391 0.8650
epoch 1900 LossPred 0.2188 LossAtt 0.4247 TrainAcc 0.9700 TestAcc 0.9469 0.9450
epoch 2000 LossPred 0.3453 LossAtt 0.4186 TrainAcc 0.8500 TestAcc 0.8526 0.8650
epoch 2100 LossPred 0.4734 LossAtt 0.4217 TrainAcc 0.8000 TestAcc 0.8191 0.8000
epoch 2200 LossPred 0.4600 LossAtt 0.4443 TrainAcc 0.8100 TestAcc 0.8251 0.8100
epoch 2300 LossPred 0.3257 LossAtt 0.4208 TrainAcc 0.8800 TestAcc 0.8589 0.8600
epoch 2400 LossPred 0.2254 LossAtt 0.4326 TrainAcc 0.9600 TestAcc 0.9282 0.9400
epoch 2500 LossPred 0.1902 LossAtt 0.4473 TrainAcc 0.9400 TestAcc 0.9427 0.9450
Optimization Finished!
********** replication  76  **********
epoch   0 LossPred 0.9101 LossAtt 0.9677 TrainAcc 0.6400 TestAcc 0.5538 0.6300
epoch 100 LossPred 0.8034 LossAtt 0.4430 TrainAcc 0.7100 TestAcc 0.5888 0.7100
epoch 200 LossPred 0.7348 LossAtt 0.3723 TrainAcc 0.7400 TestAcc 0.6777 0.7450
epoch 300 LossPred 0.3487 LossAtt 0.3214 TrainAcc 0.8500 TestAcc 0.8316 0.8500
epoch 400 LossPred 0.3404 LossAtt 0.3127 TrainAcc 0.8500 TestAcc 0.8423 0.8550
epoch 500 LossPred 0.3175 LossAtt 0.3193 TrainAcc 0.8500 TestAcc 0.8526 0.8700
epoch 600 LossPred 0.2982 LossAtt 0.3186 TrainAcc 0.9000 TestAcc 0.8361 0.8800
epoch 700 LossPred 0.3134 LossAtt 0.3207 TrainAcc 0.8900 TestAcc 0.8599 0.8900
epoch 800 LossPred 0.2882 LossAtt 0.3052 TrainAcc 0.9200 TestAcc 0.8654 0.8850
epoch 900 LossPred 0.2811 LossAtt 0.2938 TrainAcc 0.9200 TestAcc 0.8674 0.8950
epoch 1000 LossPred 0.2891 LossAtt 0.2915 TrainAcc 0.9000 TestAcc 0.8519 0.9000
epoch 1100 LossPred 0.2871 LossAtt 0.2994 TrainAcc 0.9100 TestAcc 0.8601 0.8950
epoch 1200 LossPred 0.2794 LossAtt 0.2844 TrainAcc 0.9100 TestAcc 0.8639 0.9000
epoch 1300 LossPred 0.3553 LossAtt 0.2729 TrainAcc 0.8900 TestAcc 0.8526 0.8900
epoch 1400 LossPred 0.2773 LossAtt 0.2932 TrainAcc 0.9100 TestAcc 0.8443 0.8900
epoch 1500 LossPred 0.2724 LossAtt 0.2619 TrainAcc 0.9100 TestAcc 0.8448 0.8900
epoch 1600 LossPred 0.2706 LossAtt 0.2404 TrainAcc 0.9200 TestAcc 0.8639 0.9100
epoch 1700 LossPred 0.2690 LossAtt 0.2494 TrainAcc 0.9100 TestAcc 0.8629 0.9000
epoch 1800 LossPred 0.2671 LossAtt 0.2337 TrainAcc 0.9300 TestAcc 0.8509 0.9050
epoch 1900 LossPred 0.2508 LossAtt 0.2477 TrainAcc 0.9100 TestAcc 0.8458 0.8950
epoch 2000 LossPred 0.2325 LossAtt 0.2503 TrainAcc 0.9300 TestAcc 0.8644 0.9250
epoch 2100 LossPred 0.2325 LossAtt 0.2291 TrainAcc 0.9200 TestAcc 0.8759 0.9400
epoch 2200 LossPred 0.2265 LossAtt 0.2381 TrainAcc 0.9300 TestAcc 0.8726 0.9100
epoch 2300 LossPred 0.2107 LossAtt 0.2193 TrainAcc 0.9400 TestAcc 0.8776 0.9250
epoch 2400 LossPred 0.2259 LossAtt 0.2242 TrainAcc 0.9200 TestAcc 0.8744 0.9300
epoch 2500 LossPred 0.2098 LossAtt 0.2159 TrainAcc 0.9400 TestAcc 0.8786 0.9300
Optimization Finished!
********** replication  77  **********
epoch   0 LossPred 1.0355 LossAtt 0.9989 TrainAcc 0.5200 TestAcc 0.5836 0.5300
epoch 100 LossPred 0.9489 LossAtt 0.4820 TrainAcc 0.6000 TestAcc 0.5856 0.5650
epoch 200 LossPred 0.9390 LossAtt 0.4385 TrainAcc 0.6000 TestAcc 0.5856 0.5850
epoch 300 LossPred 0.9199 LossAtt 0.4971 TrainAcc 0.6600 TestAcc 0.6091 0.6150
epoch 400 LossPred 0.7386 LossAtt 0.6197 TrainAcc 0.7700 TestAcc 0.7302 0.7400
epoch 500 LossPred 0.3197 LossAtt 0.6050 TrainAcc 0.9100 TestAcc 0.8584 0.9000
epoch 600 LossPred 0.2629 LossAtt 0.5064 TrainAcc 0.9200 TestAcc 0.9172 0.9050
epoch 700 LossPred 0.2079 LossAtt 0.4526 TrainAcc 0.9400 TestAcc 0.8606 0.9400
epoch 800 LossPred 0.2693 LossAtt 0.4343 TrainAcc 0.9100 TestAcc 0.8966 0.8950
epoch 900 LossPred 0.2095 LossAtt 0.4296 TrainAcc 0.9200 TestAcc 0.9004 0.9300
epoch 1000 LossPred 0.1637 LossAtt 0.4108 TrainAcc 0.9300 TestAcc 0.9089 0.9400
epoch 1100 LossPred 0.1421 LossAtt 0.4020 TrainAcc 0.9500 TestAcc 0.8979 0.9500
epoch 1200 LossPred 0.1392 LossAtt 0.4164 TrainAcc 0.9500 TestAcc 0.9097 0.9400
epoch 1300 LossPred 0.1336 LossAtt 0.4235 TrainAcc 0.9400 TestAcc 0.9142 0.9400
epoch 1400 LossPred 0.1947 LossAtt 0.4097 TrainAcc 0.9500 TestAcc 0.8423 0.9500
epoch 1500 LossPred 0.1262 LossAtt 0.4128 TrainAcc 0.9500 TestAcc 0.9174 0.9500
epoch 1600 LossPred 0.3306 LossAtt 0.3840 TrainAcc 0.8700 TestAcc 0.8926 0.8650
epoch 1700 LossPred 0.1831 LossAtt 0.4093 TrainAcc 0.9200 TestAcc 0.9167 0.9250
epoch 1800 LossPred 0.1689 LossAtt 0.4267 TrainAcc 0.9300 TestAcc 0.8954 0.9400
epoch 1900 LossPred 0.1449 LossAtt 0.4259 TrainAcc 0.9600 TestAcc 0.8774 0.9550
epoch 2000 LossPred 0.1950 LossAtt 0.4103 TrainAcc 0.9500 TestAcc 0.8428 0.9300
epoch 2100 LossPred 0.1327 LossAtt 0.4093 TrainAcc 0.9600 TestAcc 0.8874 0.9650
epoch 2200 LossPred 0.1845 LossAtt 0.4099 TrainAcc 0.9300 TestAcc 0.8954 0.9300
epoch 2300 LossPred 0.1039 LossAtt 0.4260 TrainAcc 0.9700 TestAcc 0.9042 0.9650
epoch 2400 LossPred 0.1376 LossAtt 0.4537 TrainAcc 0.9300 TestAcc 0.8866 0.9400
epoch 2500 LossPred 0.1478 LossAtt 0.4582 TrainAcc 0.9500 TestAcc 0.8871 0.9400
Optimization Finished!
********** replication  78  **********
epoch   0 LossPred 0.9015 LossAtt 0.9800 TrainAcc 0.6400 TestAcc 0.5676 0.6550
epoch 100 LossPred 0.8437 LossAtt 0.4353 TrainAcc 0.6800 TestAcc 0.6281 0.6750
epoch 200 LossPred 0.2908 LossAtt 0.3974 TrainAcc 0.9100 TestAcc 0.8348 0.8700
epoch 300 LossPred 0.2421 LossAtt 0.3626 TrainAcc 0.9200 TestAcc 0.8466 0.8800
epoch 400 LossPred 0.2296 LossAtt 0.3745 TrainAcc 0.9100 TestAcc 0.8564 0.8850
epoch 500 LossPred 0.2737 LossAtt 0.3500 TrainAcc 0.8800 TestAcc 0.8681 0.8700
epoch 600 LossPred 0.2095 LossAtt 0.3588 TrainAcc 0.9100 TestAcc 0.8566 0.8950
epoch 700 LossPred 0.3526 LossAtt 0.3853 TrainAcc 0.8800 TestAcc 0.8443 0.8400
epoch 800 LossPred 0.4545 LossAtt 0.3269 TrainAcc 0.8300 TestAcc 0.8288 0.8400
epoch 900 LossPred 0.2721 LossAtt 0.3031 TrainAcc 0.9200 TestAcc 0.8483 0.8900
epoch 1000 LossPred 0.2918 LossAtt 0.3144 TrainAcc 0.8800 TestAcc 0.8796 0.8750
epoch 1100 LossPred 0.2440 LossAtt 0.3385 TrainAcc 0.9000 TestAcc 0.8681 0.8800
epoch 1200 LossPred 0.2330 LossAtt 0.3186 TrainAcc 0.9300 TestAcc 0.8551 0.8850
epoch 1300 LossPred 0.2540 LossAtt 0.2952 TrainAcc 0.9100 TestAcc 0.8604 0.8650
epoch 1400 LossPred 0.2937 LossAtt 0.3444 TrainAcc 0.9100 TestAcc 0.8331 0.8650
epoch 1500 LossPred 0.3124 LossAtt 0.3245 TrainAcc 0.9000 TestAcc 0.8363 0.8550
epoch 1600 LossPred 0.2940 LossAtt 0.3130 TrainAcc 0.8900 TestAcc 0.8506 0.8500
epoch 1700 LossPred 0.3170 LossAtt 0.3077 TrainAcc 0.8900 TestAcc 0.8313 0.8400
epoch 1800 LossPred 0.3952 LossAtt 0.3093 TrainAcc 0.8600 TestAcc 0.8551 0.8350
epoch 1900 LossPred 0.3270 LossAtt 0.3079 TrainAcc 0.8800 TestAcc 0.8539 0.8500
epoch 2000 LossPred 0.3244 LossAtt 0.2960 TrainAcc 0.8800 TestAcc 0.8521 0.8500
epoch 2100 LossPred 0.2775 LossAtt 0.2939 TrainAcc 0.8900 TestAcc 0.8644 0.8750
epoch 2200 LossPred 0.6970 LossAtt 0.2791 TrainAcc 0.7700 TestAcc 0.7648 0.8000
epoch 2300 LossPred 0.9336 LossAtt 0.3040 TrainAcc 0.6600 TestAcc 0.5933 0.6600
epoch 2400 LossPred 0.8901 LossAtt 0.3298 TrainAcc 0.6700 TestAcc 0.6094 0.6550
epoch 2500 LossPred 0.8080 LossAtt 0.2962 TrainAcc 0.6700 TestAcc 0.6459 0.6950
Optimization Finished!
********** replication  79  **********
epoch   0 LossPred 1.1512 LossAtt 1.0293 TrainAcc 0.4000 TestAcc 0.4757 0.4400
epoch 100 LossPred 0.8899 LossAtt 0.4391 TrainAcc 0.6800 TestAcc 0.6024 0.6950
epoch 200 LossPred 0.7096 LossAtt 0.4834 TrainAcc 0.7600 TestAcc 0.6229 0.7750
epoch 300 LossPred 0.3421 LossAtt 0.5098 TrainAcc 0.8900 TestAcc 0.8604 0.8950
epoch 400 LossPred 0.2951 LossAtt 0.4812 TrainAcc 0.9000 TestAcc 0.8574 0.8800
epoch 500 LossPred 0.2530 LossAtt 0.4704 TrainAcc 0.9200 TestAcc 0.8851 0.9150
epoch 600 LossPred 0.2360 LossAtt 0.4826 TrainAcc 0.9400 TestAcc 0.8789 0.9100
epoch 700 LossPred 0.2426 LossAtt 0.4789 TrainAcc 0.9300 TestAcc 0.8939 0.9150
epoch 800 LossPred 0.2080 LossAtt 0.4872 TrainAcc 0.9400 TestAcc 0.8846 0.9200
epoch 900 LossPred 0.2304 LossAtt 0.4753 TrainAcc 0.9200 TestAcc 0.8904 0.8950
epoch 1000 LossPred 0.1950 LossAtt 0.4628 TrainAcc 0.9400 TestAcc 0.8834 0.9250
epoch 1100 LossPred 0.2116 LossAtt 0.4410 TrainAcc 0.9300 TestAcc 0.9097 0.9400
epoch 1200 LossPred 0.1747 LossAtt 0.4449 TrainAcc 0.9400 TestAcc 0.8954 0.9200
epoch 1300 LossPred 0.2948 LossAtt 0.4368 TrainAcc 0.8800 TestAcc 0.8243 0.8600
epoch 1400 LossPred 0.1631 LossAtt 0.4370 TrainAcc 0.9500 TestAcc 0.8984 0.9350
epoch 1500 LossPred 0.3244 LossAtt 0.4009 TrainAcc 0.9000 TestAcc 0.8554 0.8650
epoch 1600 LossPred 0.1613 LossAtt 0.4164 TrainAcc 0.9600 TestAcc 0.8941 0.9550
epoch 1700 LossPred 0.1597 LossAtt 0.4070 TrainAcc 0.9400 TestAcc 0.9142 0.9300
epoch 1800 LossPred 0.5996 LossAtt 0.3992 TrainAcc 0.8000 TestAcc 0.7853 0.8100
epoch 1900 LossPred 0.3129 LossAtt 0.3830 TrainAcc 0.8600 TestAcc 0.8704 0.8800
epoch 2000 LossPred 0.2065 LossAtt 0.3915 TrainAcc 0.9300 TestAcc 0.9054 0.9350
epoch 2100 LossPred 0.1901 LossAtt 0.3763 TrainAcc 0.9300 TestAcc 0.9154 0.9450
epoch 2200 LossPred 0.1620 LossAtt 0.3872 TrainAcc 0.9700 TestAcc 0.9119 0.9500
epoch 2300 LossPred 0.2716 LossAtt 0.3697 TrainAcc 0.9000 TestAcc 0.8966 0.9150
epoch 2400 LossPred 0.3286 LossAtt 0.3807 TrainAcc 0.8600 TestAcc 0.8664 0.8900
epoch 2500 LossPred 0.1438 LossAtt 0.3747 TrainAcc 0.9500 TestAcc 0.9067 0.9450
Optimization Finished!
********** replication  80  **********
epoch   0 LossPred 1.0537 LossAtt 1.0126 TrainAcc 0.5700 TestAcc 0.4332 0.5150
epoch 100 LossPred 0.9378 LossAtt 0.5373 TrainAcc 0.6000 TestAcc 0.5045 0.5950
epoch 200 LossPred 0.9231 LossAtt 0.4742 TrainAcc 0.6000 TestAcc 0.4827 0.5950
epoch 300 LossPred 0.8861 LossAtt 0.4438 TrainAcc 0.6700 TestAcc 0.5435 0.6700
epoch 400 LossPred 0.8787 LossAtt 0.4093 TrainAcc 0.6700 TestAcc 0.5601 0.6700
epoch 500 LossPred 0.8599 LossAtt 0.4242 TrainAcc 0.6900 TestAcc 0.5516 0.6600
epoch 600 LossPred 0.8340 LossAtt 0.4285 TrainAcc 0.7100 TestAcc 0.5858 0.6800
epoch 700 LossPred 0.7802 LossAtt 0.3046 TrainAcc 0.6800 TestAcc 0.7545 0.7100
epoch 800 LossPred 0.6121 LossAtt 0.3271 TrainAcc 0.7700 TestAcc 0.7317 0.7550
epoch 900 LossPred 0.6501 LossAtt 0.3076 TrainAcc 0.7500 TestAcc 0.6977 0.7500
epoch 1000 LossPred 0.3772 LossAtt 0.3132 TrainAcc 0.9100 TestAcc 0.8741 0.8550
epoch 1100 LossPred 0.6054 LossAtt 0.3103 TrainAcc 0.7700 TestAcc 0.7885 0.7950
epoch 1200 LossPred 0.4097 LossAtt 0.3008 TrainAcc 0.8700 TestAcc 0.8318 0.8400
epoch 1300 LossPred 0.5270 LossAtt 0.2850 TrainAcc 0.8000 TestAcc 0.7520 0.7950
epoch 1400 LossPred 0.3278 LossAtt 0.2631 TrainAcc 0.9200 TestAcc 0.8801 0.8550
epoch 1500 LossPred 0.9040 LossAtt 0.3075 TrainAcc 0.6800 TestAcc 0.6139 0.6800
epoch 1600 LossPred 0.3219 LossAtt 0.2530 TrainAcc 0.9100 TestAcc 0.8784 0.8600
epoch 1700 LossPred 0.3320 LossAtt 0.2500 TrainAcc 0.8700 TestAcc 0.8639 0.8850
epoch 1800 LossPred 0.3030 LossAtt 0.3030 TrainAcc 0.9200 TestAcc 0.8218 0.8850
epoch 1900 LossPred 0.3330 LossAtt 0.3029 TrainAcc 0.9000 TestAcc 0.7815 0.8700
epoch 2000 LossPred 0.3460 LossAtt 0.2928 TrainAcc 0.8900 TestAcc 0.8308 0.8800
epoch 2100 LossPred 0.2940 LossAtt 0.3180 TrainAcc 0.9100 TestAcc 0.8388 0.8800
epoch 2200 LossPred 0.2506 LossAtt 0.3576 TrainAcc 0.9300 TestAcc 0.8609 0.8950
epoch 2300 LossPred 0.2330 LossAtt 0.3673 TrainAcc 0.9300 TestAcc 0.8669 0.9050
epoch 2400 LossPred 0.1817 LossAtt 0.3654 TrainAcc 0.9500 TestAcc 0.9177 0.9200
epoch 2500 LossPred 0.1698 LossAtt 0.3486 TrainAcc 0.9600 TestAcc 0.9234 0.9300
Optimization Finished!
********** replication  81  **********
epoch   0 LossPred 1.2101 LossAtt 1.0071 TrainAcc 0.4700 TestAcc 0.4680 0.4250
epoch 100 LossPred 0.9600 LossAtt 0.3659 TrainAcc 0.6100 TestAcc 0.6091 0.6100
epoch 200 LossPred 0.9392 LossAtt 0.3051 TrainAcc 0.6100 TestAcc 0.6091 0.6100
epoch 300 LossPred 0.9359 LossAtt 0.2347 TrainAcc 0.6100 TestAcc 0.6091 0.6100
epoch 400 LossPred 0.9539 LossAtt 0.1767 TrainAcc 0.6100 TestAcc 0.6091 0.6100
epoch 500 LossPred 0.9824 LossAtt 0.1369 TrainAcc 0.6100 TestAcc 0.6091 0.5900
epoch 600 LossPred 0.9917 LossAtt 0.1393 TrainAcc 0.5100 TestAcc 0.4957 0.5100
epoch 700 LossPred 0.9926 LossAtt 0.1413 TrainAcc 0.5100 TestAcc 0.4957 0.5100
epoch 800 LossPred 0.9901 LossAtt 0.1372 TrainAcc 0.5100 TestAcc 0.4957 0.5100
epoch 900 LossPred 0.9865 LossAtt 0.1608 TrainAcc 0.6600 TestAcc 0.6036 0.6000
epoch 1000 LossPred 0.9784 LossAtt 0.1287 TrainAcc 0.6100 TestAcc 0.6089 0.6100
epoch 1100 LossPred 0.9834 LossAtt 0.0883 TrainAcc 0.6100 TestAcc 0.6091 0.6050
epoch 1200 LossPred 0.9832 LossAtt 0.0992 TrainAcc 0.6100 TestAcc 0.6091 0.6100
epoch 1300 LossPred 0.9831 LossAtt 0.0874 TrainAcc 0.6100 TestAcc 0.6091 0.6100
epoch 1400 LossPred 0.9841 LossAtt 0.0785 TrainAcc 0.6100 TestAcc 0.6091 0.6100
epoch 1500 LossPred 0.9840 LossAtt 0.0632 TrainAcc 0.6100 TestAcc 0.6091 0.6100
epoch 1600 LossPred 0.9834 LossAtt 0.0558 TrainAcc 0.6100 TestAcc 0.6091 0.6100
epoch 1700 LossPred 0.9833 LossAtt 0.0750 TrainAcc 0.6100 TestAcc 0.6091 0.6100
epoch 1800 LossPred 0.9863 LossAtt 0.0504 TrainAcc 0.6100 TestAcc 0.6091 0.6100
epoch 1900 LossPred 0.9847 LossAtt 0.0464 TrainAcc 0.6100 TestAcc 0.6091 0.6100
epoch 2000 LossPred 0.9849 LossAtt 0.0435 TrainAcc 0.6100 TestAcc 0.6091 0.6100
epoch 2100 LossPred 0.9891 LossAtt 0.0468 TrainAcc 0.6100 TestAcc 0.6091 0.5500
epoch 2200 LossPred 0.9886 LossAtt 0.0464 TrainAcc 0.6100 TestAcc 0.6091 0.6100
epoch 2300 LossPred 0.9937 LossAtt 0.0425 TrainAcc 0.5100 TestAcc 0.4957 0.5100
epoch 2400 LossPred 0.9907 LossAtt 0.0610 TrainAcc 0.6100 TestAcc 0.6091 0.5950
epoch 2500 LossPred 0.9875 LossAtt 0.0334 TrainAcc 0.6100 TestAcc 0.6091 0.6100
Optimization Finished!
********** replication  82  **********
epoch   0 LossPred 1.1342 LossAtt 0.9940 TrainAcc 0.5000 TestAcc 0.5053 0.5100
epoch 100 LossPred 0.9327 LossAtt 0.2715 TrainAcc 0.6100 TestAcc 0.5921 0.6000
epoch 200 LossPred 0.9281 LossAtt 0.1933 TrainAcc 0.6100 TestAcc 0.5921 0.6100
epoch 300 LossPred 0.9205 LossAtt 0.2258 TrainAcc 0.6100 TestAcc 0.5921 0.6050
epoch 400 LossPred 0.9034 LossAtt 0.2510 TrainAcc 0.6300 TestAcc 0.6552 0.6300
epoch 500 LossPred 0.4419 LossAtt 0.3527 TrainAcc 0.8500 TestAcc 0.8158 0.8450
epoch 600 LossPred 0.9593 LossAtt 0.3169 TrainAcc 0.6100 TestAcc 0.6321 0.6100
epoch 700 LossPred 0.3919 LossAtt 0.2978 TrainAcc 0.9100 TestAcc 0.8944 0.8850
epoch 800 LossPred 0.9118 LossAtt 0.2866 TrainAcc 0.6100 TestAcc 0.6527 0.5950
epoch 900 LossPred 0.8469 LossAtt 0.2678 TrainAcc 0.6600 TestAcc 0.7055 0.6650
epoch 1000 LossPred 0.4701 LossAtt 0.2825 TrainAcc 0.8400 TestAcc 0.8448 0.8600
epoch 1100 LossPred 0.6780 LossAtt 0.3009 TrainAcc 0.7200 TestAcc 0.7750 0.7200
epoch 1200 LossPred 0.4938 LossAtt 0.2935 TrainAcc 0.8500 TestAcc 0.8961 0.8650
epoch 1300 LossPred 0.4553 LossAtt 0.3173 TrainAcc 0.8900 TestAcc 0.8964 0.8800
epoch 1400 LossPred 0.4073 LossAtt 0.2841 TrainAcc 0.8900 TestAcc 0.8884 0.8850
epoch 1500 LossPred 0.3616 LossAtt 0.2780 TrainAcc 0.9000 TestAcc 0.8844 0.8900
epoch 1600 LossPred 0.3589 LossAtt 0.2774 TrainAcc 0.8900 TestAcc 0.8811 0.8950
epoch 1700 LossPred 0.3431 LossAtt 0.2811 TrainAcc 0.8800 TestAcc 0.8839 0.8850
epoch 1800 LossPred 0.3745 LossAtt 0.2731 TrainAcc 0.8700 TestAcc 0.8461 0.8600
epoch 1900 LossPred 0.3729 LossAtt 0.2597 TrainAcc 0.8700 TestAcc 0.8569 0.8700
epoch 2000 LossPred 0.3885 LossAtt 0.2599 TrainAcc 0.8800 TestAcc 0.8676 0.8900
epoch 2100 LossPred 0.6278 LossAtt 0.2514 TrainAcc 0.7900 TestAcc 0.8023 0.8050
epoch 2200 LossPred 0.6325 LossAtt 0.2724 TrainAcc 0.7700 TestAcc 0.8216 0.7650
epoch 2300 LossPred 0.4100 LossAtt 0.2832 TrainAcc 0.8900 TestAcc 0.8546 0.8600
epoch 2400 LossPred 0.4233 LossAtt 0.2904 TrainAcc 0.8600 TestAcc 0.8421 0.8400
epoch 2500 LossPred 0.4086 LossAtt 0.2639 TrainAcc 0.8600 TestAcc 0.8586 0.8600
Optimization Finished!
********** replication  83  **********
epoch   0 LossPred 0.9520 LossAtt 1.0021 TrainAcc 0.6200 TestAcc 0.5796 0.6350
epoch 100 LossPred 0.9023 LossAtt 0.4144 TrainAcc 0.6300 TestAcc 0.5898 0.6350
epoch 200 LossPred 0.8640 LossAtt 0.5155 TrainAcc 0.6700 TestAcc 0.6231 0.6550
epoch 300 LossPred 0.7665 LossAtt 0.5542 TrainAcc 0.7300 TestAcc 0.6499 0.6850
epoch 400 LossPred 0.2948 LossAtt 0.5586 TrainAcc 0.9200 TestAcc 0.8544 0.9200
epoch 500 LossPred 0.1826 LossAtt 0.5448 TrainAcc 0.9500 TestAcc 0.8839 0.9450
epoch 600 LossPred 0.1559 LossAtt 0.5135 TrainAcc 0.9600 TestAcc 0.8791 0.9400
epoch 700 LossPred 0.1572 LossAtt 0.5236 TrainAcc 0.9600 TestAcc 0.8759 0.9300
epoch 800 LossPred 0.1461 LossAtt 0.5101 TrainAcc 0.9600 TestAcc 0.8824 0.9450
epoch 900 LossPred 0.1908 LossAtt 0.4800 TrainAcc 0.9300 TestAcc 0.8771 0.9500
epoch 1000 LossPred 0.1452 LossAtt 0.4916 TrainAcc 0.9500 TestAcc 0.8854 0.9400
epoch 1100 LossPred 0.1486 LossAtt 0.4964 TrainAcc 0.9700 TestAcc 0.8811 0.9250
epoch 1200 LossPred 0.2967 LossAtt 0.4841 TrainAcc 0.9100 TestAcc 0.8671 0.9350
epoch 1300 LossPred 0.1238 LossAtt 0.4552 TrainAcc 0.9600 TestAcc 0.8874 0.9600
epoch 1400 LossPred 0.1920 LossAtt 0.4859 TrainAcc 0.9300 TestAcc 0.8784 0.9100
epoch 1500 LossPred 0.1073 LossAtt 0.4747 TrainAcc 0.9700 TestAcc 0.8829 0.9550
epoch 1600 LossPred 0.0948 LossAtt 0.4731 TrainAcc 0.9800 TestAcc 0.8841 0.9700
epoch 1700 LossPred 0.1375 LossAtt 0.4792 TrainAcc 0.9700 TestAcc 0.8761 0.9400
epoch 1800 LossPred 0.1504 LossAtt 0.4698 TrainAcc 0.9500 TestAcc 0.8809 0.9250
epoch 1900 LossPred 0.3368 LossAtt 0.5398 TrainAcc 0.8900 TestAcc 0.8561 0.8950
epoch 2000 LossPred 0.1174 LossAtt 0.4663 TrainAcc 0.9600 TestAcc 0.8844 0.9550
epoch 2100 LossPred 0.1535 LossAtt 0.4723 TrainAcc 0.9600 TestAcc 0.8696 0.9450
epoch 2200 LossPred 0.1190 LossAtt 0.4806 TrainAcc 0.9700 TestAcc 0.8766 0.9600
epoch 2300 LossPred 0.1361 LossAtt 0.4801 TrainAcc 0.9600 TestAcc 0.8749 0.9500
epoch 2400 LossPred 0.1172 LossAtt 0.4639 TrainAcc 0.9700 TestAcc 0.8736 0.9650
epoch 2500 LossPred 0.3297 LossAtt 0.4679 TrainAcc 0.9000 TestAcc 0.8571 0.9350
Optimization Finished!
********** replication  84  **********
epoch   0 LossPred 1.1505 LossAtt 1.0220 TrainAcc 0.4700 TestAcc 0.4687 0.4850
epoch 100 LossPred 0.9153 LossAtt 0.4544 TrainAcc 0.6500 TestAcc 0.6041 0.6500
epoch 200 LossPred 0.8814 LossAtt 0.4231 TrainAcc 0.6700 TestAcc 0.6321 0.6550
epoch 300 LossPred 0.8645 LossAtt 0.4314 TrainAcc 0.6800 TestAcc 0.6647 0.6700
epoch 400 LossPred 0.6182 LossAtt 0.4536 TrainAcc 0.7800 TestAcc 0.8133 0.7550
epoch 500 LossPred 0.5657 LossAtt 0.4265 TrainAcc 0.8300 TestAcc 0.8296 0.7950
epoch 600 LossPred 0.5280 LossAtt 0.4699 TrainAcc 0.8400 TestAcc 0.8526 0.8300
epoch 700 LossPred 0.3464 LossAtt 0.5083 TrainAcc 0.9000 TestAcc 0.8784 0.8750
epoch 800 LossPred 0.4344 LossAtt 0.4909 TrainAcc 0.8500 TestAcc 0.8554 0.8350
epoch 900 LossPred 0.3558 LossAtt 0.5155 TrainAcc 0.8800 TestAcc 0.8876 0.8350
epoch 1000 LossPred 0.3091 LossAtt 0.4946 TrainAcc 0.9100 TestAcc 0.8931 0.8800
epoch 1100 LossPred 0.2337 LossAtt 0.5243 TrainAcc 0.9300 TestAcc 0.8876 0.8800
epoch 1200 LossPred 0.2244 LossAtt 0.5192 TrainAcc 0.9200 TestAcc 0.9012 0.8650
epoch 1300 LossPred 0.2786 LossAtt 0.4956 TrainAcc 0.9200 TestAcc 0.8961 0.8850
epoch 1400 LossPred 0.3204 LossAtt 0.5431 TrainAcc 0.9000 TestAcc 0.8789 0.8700
epoch 1500 LossPred 0.2047 LossAtt 0.4984 TrainAcc 0.9400 TestAcc 0.9124 0.9050
epoch 1600 LossPred 0.2807 LossAtt 0.5321 TrainAcc 0.9200 TestAcc 0.8981 0.8850
epoch 1700 LossPred 0.2734 LossAtt 0.4972 TrainAcc 0.9300 TestAcc 0.9017 0.8850
epoch 1800 LossPred 0.2871 LossAtt 0.5116 TrainAcc 0.9000 TestAcc 0.8924 0.8500
epoch 1900 LossPred 0.2372 LossAtt 0.5160 TrainAcc 0.9200 TestAcc 0.8939 0.8950
epoch 2000 LossPred 0.1909 LossAtt 0.5075 TrainAcc 0.9400 TestAcc 0.8964 0.8900
epoch 2100 LossPred 0.1896 LossAtt 0.4965 TrainAcc 0.9400 TestAcc 0.8919 0.8950
epoch 2200 LossPred 0.1982 LossAtt 0.5289 TrainAcc 0.9400 TestAcc 0.9027 0.9000
epoch 2300 LossPred 0.2592 LossAtt 0.4718 TrainAcc 0.9200 TestAcc 0.9047 0.8900
epoch 2400 LossPred 0.2911 LossAtt 0.4850 TrainAcc 0.9200 TestAcc 0.9047 0.9000
epoch 2500 LossPred 0.2969 LossAtt 0.4681 TrainAcc 0.9000 TestAcc 0.8909 0.8500
Optimization Finished!
********** replication  85  **********
epoch   0 LossPred 1.0703 LossAtt 1.0583 TrainAcc 0.5400 TestAcc 0.4800 0.5250
epoch 100 LossPred 0.9119 LossAtt 0.3485 TrainAcc 0.6500 TestAcc 0.6109 0.6450
epoch 200 LossPred 0.9042 LossAtt 0.1662 TrainAcc 0.6500 TestAcc 0.6109 0.6500
epoch 300 LossPred 0.9033 LossAtt 0.1671 TrainAcc 0.6500 TestAcc 0.6109 0.6500
epoch 400 LossPred 0.8969 LossAtt 0.2100 TrainAcc 0.6500 TestAcc 0.6109 0.6500
epoch 500 LossPred 0.8478 LossAtt 0.3367 TrainAcc 0.6500 TestAcc 0.6109 0.6600
epoch 600 LossPred 0.5145 LossAtt 0.4193 TrainAcc 0.8200 TestAcc 0.8163 0.8100
epoch 700 LossPred 0.2908 LossAtt 0.4118 TrainAcc 0.9100 TestAcc 0.8754 0.9100
epoch 800 LossPred 0.2845 LossAtt 0.3939 TrainAcc 0.8900 TestAcc 0.8811 0.8900
epoch 900 LossPred 0.2066 LossAtt 0.4120 TrainAcc 0.9300 TestAcc 0.8746 0.9150
epoch 1000 LossPred 0.1865 LossAtt 0.3958 TrainAcc 0.9400 TestAcc 0.8784 0.9150
epoch 1100 LossPred 0.2034 LossAtt 0.3909 TrainAcc 0.9300 TestAcc 0.8871 0.9150
epoch 1200 LossPred 0.2018 LossAtt 0.3977 TrainAcc 0.9400 TestAcc 0.8721 0.9150
epoch 1300 LossPred 0.1349 LossAtt 0.3780 TrainAcc 0.9600 TestAcc 0.8831 0.9300
epoch 1400 LossPred 0.3235 LossAtt 0.3909 TrainAcc 0.8900 TestAcc 0.8458 0.9050
epoch 1500 LossPred 0.1545 LossAtt 0.3740 TrainAcc 0.9600 TestAcc 0.8594 0.9250
epoch 1600 LossPred 0.1988 LossAtt 0.3698 TrainAcc 0.9400 TestAcc 0.8921 0.9150
epoch 1700 LossPred 0.2318 LossAtt 0.3741 TrainAcc 0.9100 TestAcc 0.8854 0.9250
epoch 1800 LossPred 0.1283 LossAtt 0.3910 TrainAcc 0.9600 TestAcc 0.8956 0.9300
epoch 1900 LossPred 0.1873 LossAtt 0.3887 TrainAcc 0.9600 TestAcc 0.9324 0.9400
epoch 2000 LossPred 0.1892 LossAtt 0.3791 TrainAcc 0.9400 TestAcc 0.8694 0.9200
epoch 2100 LossPred 0.1652 LossAtt 0.3792 TrainAcc 0.9500 TestAcc 0.9034 0.9350
epoch 2200 LossPred 0.1252 LossAtt 0.3794 TrainAcc 0.9600 TestAcc 0.8766 0.9300
epoch 2300 LossPred 0.1419 LossAtt 0.3632 TrainAcc 0.9500 TestAcc 0.9122 0.9450
epoch 2400 LossPred 0.5971 LossAtt 0.3830 TrainAcc 0.8300 TestAcc 0.7703 0.8100
epoch 2500 LossPred 0.3765 LossAtt 0.3952 TrainAcc 0.8700 TestAcc 0.8263 0.8850
Optimization Finished!
********** replication  86  **********
epoch   0 LossPred 1.0912 LossAtt 1.0171 TrainAcc 0.3900 TestAcc 0.3916 0.4000
epoch 100 LossPred 0.9311 LossAtt 0.3942 TrainAcc 0.6000 TestAcc 0.5125 0.6000
epoch 200 LossPred 0.9083 LossAtt 0.4049 TrainAcc 0.6300 TestAcc 0.5523 0.6200
epoch 300 LossPred 0.8995 LossAtt 0.3707 TrainAcc 0.6600 TestAcc 0.5861 0.6350
epoch 400 LossPred 0.8845 LossAtt 0.3505 TrainAcc 0.6300 TestAcc 0.5020 0.6200
epoch 500 LossPred 0.8809 LossAtt 0.2844 TrainAcc 0.6600 TestAcc 0.5883 0.6250
epoch 600 LossPred 0.9034 LossAtt 0.2578 TrainAcc 0.6000 TestAcc 0.5125 0.6000
epoch 700 LossPred 0.9097 LossAtt 0.2921 TrainAcc 0.6000 TestAcc 0.5125 0.6000
epoch 800 LossPred 0.9008 LossAtt 0.3690 TrainAcc 0.6000 TestAcc 0.5125 0.5900
epoch 900 LossPred 0.8879 LossAtt 0.3692 TrainAcc 0.6100 TestAcc 0.6084 0.6100
epoch 1000 LossPred 0.8822 LossAtt 0.2776 TrainAcc 0.6100 TestAcc 0.6084 0.6050
epoch 1100 LossPred 0.8797 LossAtt 0.2190 TrainAcc 0.6100 TestAcc 0.6084 0.6150
epoch 1200 LossPred 0.8817 LossAtt 0.2402 TrainAcc 0.6100 TestAcc 0.6084 0.6100
epoch 1300 LossPred 0.8841 LossAtt 0.2141 TrainAcc 0.6100 TestAcc 0.6084 0.5950
epoch 1400 LossPred 0.8860 LossAtt 0.1650 TrainAcc 0.6300 TestAcc 0.5966 0.6000
epoch 1500 LossPred 0.8835 LossAtt 0.1736 TrainAcc 0.6100 TestAcc 0.6084 0.6000
epoch 1600 LossPred 0.8861 LossAtt 0.1410 TrainAcc 0.6100 TestAcc 0.6084 0.5950
epoch 1700 LossPred 0.9101 LossAtt 0.1135 TrainAcc 0.6000 TestAcc 0.5125 0.6000
epoch 1800 LossPred 0.9188 LossAtt 0.0459 TrainAcc 0.6000 TestAcc 0.5125 0.6000
epoch 1900 LossPred 0.9171 LossAtt 0.0484 TrainAcc 0.5200 TestAcc 0.4807 0.5950
epoch 2000 LossPred 0.9183 LossAtt 0.0362 TrainAcc 0.6000 TestAcc 0.5125 0.6000
epoch 2100 LossPred 0.9211 LossAtt 0.0425 TrainAcc 0.6100 TestAcc 0.6084 0.6100
epoch 2200 LossPred 0.9209 LossAtt 0.0532 TrainAcc 0.6000 TestAcc 0.5125 0.6000
epoch 2300 LossPred 0.9220 LossAtt 0.0304 TrainAcc 0.6000 TestAcc 0.5125 0.6000
epoch 2400 LossPred 0.9290 LossAtt 0.0333 TrainAcc 0.6100 TestAcc 0.6084 0.6100
epoch 2500 LossPred 0.9206 LossAtt 0.0242 TrainAcc 0.6000 TestAcc 0.5125 0.6000
Optimization Finished!
********** replication  87  **********
epoch   0 LossPred 1.0639 LossAtt 1.0295 TrainAcc 0.5500 TestAcc 0.5513 0.5600
epoch 100 LossPred 0.9487 LossAtt 0.3867 TrainAcc 0.6000 TestAcc 0.6051 0.6050
epoch 200 LossPred 0.9267 LossAtt 0.3601 TrainAcc 0.6100 TestAcc 0.6199 0.6200
epoch 300 LossPred 0.3988 LossAtt 0.3726 TrainAcc 0.8900 TestAcc 0.8859 0.8700
epoch 400 LossPred 0.3506 LossAtt 0.3379 TrainAcc 0.8800 TestAcc 0.8901 0.8850
epoch 500 LossPred 0.3766 LossAtt 0.3248 TrainAcc 0.8900 TestAcc 0.8599 0.8650
epoch 600 LossPred 0.3684 LossAtt 0.3224 TrainAcc 0.8900 TestAcc 0.8826 0.8700
epoch 700 LossPred 0.3748 LossAtt 0.3075 TrainAcc 0.8900 TestAcc 0.8654 0.8700
epoch 800 LossPred 0.4192 LossAtt 0.3028 TrainAcc 0.8500 TestAcc 0.8684 0.8650
epoch 900 LossPred 0.3482 LossAtt 0.3094 TrainAcc 0.8700 TestAcc 0.8919 0.8850
epoch 1000 LossPred 0.3392 LossAtt 0.3255 TrainAcc 0.8900 TestAcc 0.8909 0.8650
epoch 1100 LossPred 0.3805 LossAtt 0.3396 TrainAcc 0.8600 TestAcc 0.8766 0.8650
epoch 1200 LossPred 0.3266 LossAtt 0.3351 TrainAcc 0.8900 TestAcc 0.9074 0.8950
epoch 1300 LossPred 0.2958 LossAtt 0.3404 TrainAcc 0.8900 TestAcc 0.9207 0.8950
epoch 1400 LossPred 0.2822 LossAtt 0.3722 TrainAcc 0.9300 TestAcc 0.9289 0.9050
epoch 1500 LossPred 0.5029 LossAtt 0.3471 TrainAcc 0.8200 TestAcc 0.8574 0.8400
epoch 1600 LossPred 0.2704 LossAtt 0.3631 TrainAcc 0.9000 TestAcc 0.9162 0.8800
epoch 1700 LossPred 0.4525 LossAtt 0.3640 TrainAcc 0.8400 TestAcc 0.8731 0.8400
epoch 1800 LossPred 0.3264 LossAtt 0.3549 TrainAcc 0.8800 TestAcc 0.8949 0.8950
epoch 1900 LossPred 0.2703 LossAtt 0.3555 TrainAcc 0.8900 TestAcc 0.9204 0.8900
epoch 2000 LossPred 0.4083 LossAtt 0.3547 TrainAcc 0.8500 TestAcc 0.8699 0.8550
epoch 2100 LossPred 0.3198 LossAtt 0.3488 TrainAcc 0.8900 TestAcc 0.9209 0.8800
epoch 2200 LossPred 0.3422 LossAtt 0.3397 TrainAcc 0.8800 TestAcc 0.8969 0.8700
epoch 2300 LossPred 0.3984 LossAtt 0.3572 TrainAcc 0.8500 TestAcc 0.8859 0.8600
epoch 2400 LossPred 0.2462 LossAtt 0.3441 TrainAcc 0.9300 TestAcc 0.9299 0.9100
epoch 2500 LossPred 0.2639 LossAtt 0.3317 TrainAcc 0.8900 TestAcc 0.9132 0.9050
Optimization Finished!
********** replication  88  **********
epoch   0 LossPred 1.2501 LossAtt 1.0100 TrainAcc 0.4400 TestAcc 0.4167 0.4750
epoch 100 LossPred 1.0315 LossAtt 0.4451 TrainAcc 0.5400 TestAcc 0.5253 0.5550
epoch 200 LossPred 0.9607 LossAtt 0.3278 TrainAcc 0.5300 TestAcc 0.5198 0.5250
epoch 300 LossPred 0.8969 LossAtt 0.3888 TrainAcc 0.6800 TestAcc 0.6714 0.6300
epoch 400 LossPred 0.2795 LossAtt 0.3886 TrainAcc 0.9100 TestAcc 0.8679 0.8850
epoch 500 LossPred 0.2962 LossAtt 0.4012 TrainAcc 0.8900 TestAcc 0.8911 0.9000
epoch 600 LossPred 0.2240 LossAtt 0.4096 TrainAcc 0.9400 TestAcc 0.8936 0.9000
epoch 700 LossPred 0.1731 LossAtt 0.4003 TrainAcc 0.9500 TestAcc 0.8859 0.9150
epoch 800 LossPred 0.1902 LossAtt 0.4086 TrainAcc 0.9300 TestAcc 0.8901 0.9150
epoch 900 LossPred 0.1547 LossAtt 0.4027 TrainAcc 0.9600 TestAcc 0.8954 0.9150
epoch 1000 LossPred 0.2243 LossAtt 0.4048 TrainAcc 0.9100 TestAcc 0.9139 0.9050
epoch 1100 LossPred 0.1781 LossAtt 0.4125 TrainAcc 0.9300 TestAcc 0.9184 0.9050
epoch 1200 LossPred 0.1177 LossAtt 0.3994 TrainAcc 0.9600 TestAcc 0.9029 0.9300
epoch 1300 LossPred 0.1644 LossAtt 0.4097 TrainAcc 0.9600 TestAcc 0.8961 0.9350
epoch 1400 LossPred 0.2129 LossAtt 0.4129 TrainAcc 0.9300 TestAcc 0.8686 0.8950
epoch 1500 LossPred 0.1542 LossAtt 0.3974 TrainAcc 0.9400 TestAcc 0.9352 0.9100
epoch 1600 LossPred 0.2267 LossAtt 0.4146 TrainAcc 0.9100 TestAcc 0.9142 0.9000
epoch 1700 LossPred 0.1395 LossAtt 0.4023 TrainAcc 0.9600 TestAcc 0.9152 0.9300
epoch 1800 LossPred 0.1769 LossAtt 0.3915 TrainAcc 0.9400 TestAcc 0.8751 0.9050
epoch 1900 LossPred 0.1662 LossAtt 0.4013 TrainAcc 0.9400 TestAcc 0.9234 0.9100
epoch 2000 LossPred 0.1515 LossAtt 0.4060 TrainAcc 0.9300 TestAcc 0.9302 0.9300
epoch 2100 LossPred 0.2995 LossAtt 0.3702 TrainAcc 0.9000 TestAcc 0.8468 0.8750
epoch 2200 LossPred 0.1576 LossAtt 0.3863 TrainAcc 0.9500 TestAcc 0.8769 0.9050
epoch 2300 LossPred 0.1452 LossAtt 0.3980 TrainAcc 0.9400 TestAcc 0.9022 0.9200
epoch 2400 LossPred 0.1314 LossAtt 0.3957 TrainAcc 0.9400 TestAcc 0.9034 0.9250
epoch 2500 LossPred 0.1402 LossAtt 0.3914 TrainAcc 0.9500 TestAcc 0.9002 0.9250
Optimization Finished!
********** replication  89  **********
epoch   0 LossPred 1.0369 LossAtt 0.9981 TrainAcc 0.3600 TestAcc 0.5295 0.4300
epoch 100 LossPred 0.8545 LossAtt 0.4813 TrainAcc 0.6900 TestAcc 0.5941 0.6900
epoch 200 LossPred 0.8076 LossAtt 0.4228 TrainAcc 0.7200 TestAcc 0.6219 0.7200
epoch 300 LossPred 0.7335 LossAtt 0.4326 TrainAcc 0.7300 TestAcc 0.6707 0.7400
epoch 400 LossPred 0.4701 LossAtt 0.4638 TrainAcc 0.8700 TestAcc 0.8383 0.8550
epoch 500 LossPred 0.4330 LossAtt 0.4293 TrainAcc 0.8400 TestAcc 0.8431 0.8750
epoch 600 LossPred 0.3027 LossAtt 0.4042 TrainAcc 0.9100 TestAcc 0.8731 0.9050
epoch 700 LossPred 0.2874 LossAtt 0.3635 TrainAcc 0.9200 TestAcc 0.8711 0.9100
epoch 800 LossPred 0.2812 LossAtt 0.3641 TrainAcc 0.9300 TestAcc 0.8651 0.8900
epoch 900 LossPred 0.2687 LossAtt 0.3605 TrainAcc 0.8900 TestAcc 0.8666 0.9200
epoch 1000 LossPred 0.2599 LossAtt 0.3267 TrainAcc 0.9200 TestAcc 0.8686 0.9100
epoch 1100 LossPred 0.2595 LossAtt 0.3345 TrainAcc 0.9000 TestAcc 0.8639 0.9050
epoch 1200 LossPred 0.2607 LossAtt 0.3230 TrainAcc 0.8900 TestAcc 0.8531 0.9100
epoch 1300 LossPred 0.2518 LossAtt 0.3029 TrainAcc 0.9000 TestAcc 0.8604 0.9100
epoch 1400 LossPred 0.2520 LossAtt 0.3107 TrainAcc 0.9000 TestAcc 0.8596 0.9100
epoch 1500 LossPred 0.2875 LossAtt 0.2978 TrainAcc 0.8800 TestAcc 0.8644 0.8800
epoch 1600 LossPred 0.2560 LossAtt 0.2926 TrainAcc 0.8900 TestAcc 0.8601 0.8950
epoch 1700 LossPred 0.2577 LossAtt 0.2874 TrainAcc 0.9000 TestAcc 0.8534 0.8900
epoch 1800 LossPred 0.2747 LossAtt 0.2880 TrainAcc 0.8900 TestAcc 0.8448 0.8900
epoch 1900 LossPred 0.3224 LossAtt 0.2796 TrainAcc 0.8700 TestAcc 0.8621 0.8800
epoch 2000 LossPred 0.2711 LossAtt 0.2832 TrainAcc 0.8700 TestAcc 0.8641 0.8750
epoch 2100 LossPred 0.2639 LossAtt 0.2619 TrainAcc 0.9000 TestAcc 0.8506 0.8900
epoch 2200 LossPred 0.2749 LossAtt 0.2758 TrainAcc 0.8900 TestAcc 0.8501 0.8850
epoch 2300 LossPred 0.3675 LossAtt 0.2741 TrainAcc 0.8600 TestAcc 0.8401 0.8700
epoch 2400 LossPred 0.2672 LossAtt 0.2874 TrainAcc 0.8900 TestAcc 0.8586 0.8950
epoch 2500 LossPred 0.2766 LossAtt 0.2899 TrainAcc 0.9000 TestAcc 0.8416 0.9000
Optimization Finished!
********** replication  90  **********
epoch   0 LossPred 1.5512 LossAtt 1.0033 TrainAcc 0.3400 TestAcc 0.4297 0.3400
epoch 100 LossPred 1.0759 LossAtt 0.2770 TrainAcc 0.4200 TestAcc 0.5065 0.4200
epoch 200 LossPred 0.8998 LossAtt 0.2458 TrainAcc 0.6900 TestAcc 0.6149 0.6700
epoch 300 LossPred 0.8132 LossAtt 0.3117 TrainAcc 0.6700 TestAcc 0.6094 0.6900
epoch 400 LossPred 0.4702 LossAtt 0.3815 TrainAcc 0.8800 TestAcc 0.8516 0.8200
epoch 500 LossPred 0.4054 LossAtt 0.3711 TrainAcc 0.8800 TestAcc 0.8128 0.8400
epoch 600 LossPred 0.3647 LossAtt 0.3669 TrainAcc 0.8900 TestAcc 0.8301 0.8400
epoch 700 LossPred 0.3656 LossAtt 0.3544 TrainAcc 0.8900 TestAcc 0.8401 0.8250
epoch 800 LossPred 0.3937 LossAtt 0.3341 TrainAcc 0.8800 TestAcc 0.8546 0.8150
epoch 900 LossPred 0.3382 LossAtt 0.3345 TrainAcc 0.9000 TestAcc 0.8498 0.8150
epoch 1000 LossPred 0.3598 LossAtt 0.3142 TrainAcc 0.8800 TestAcc 0.8288 0.8350
epoch 1100 LossPred 0.3787 LossAtt 0.3067 TrainAcc 0.8800 TestAcc 0.8251 0.8350
epoch 1200 LossPred 0.3831 LossAtt 0.3035 TrainAcc 0.8700 TestAcc 0.8313 0.8250
epoch 1300 LossPred 0.3588 LossAtt 0.3047 TrainAcc 0.8800 TestAcc 0.8286 0.8350
epoch 1400 LossPred 0.3428 LossAtt 0.2973 TrainAcc 0.8900 TestAcc 0.8191 0.8300
epoch 1500 LossPred 0.3274 LossAtt 0.3075 TrainAcc 0.9000 TestAcc 0.8496 0.8100
epoch 1600 LossPred 0.3568 LossAtt 0.2992 TrainAcc 0.8800 TestAcc 0.8323 0.8250
epoch 1700 LossPred 0.3233 LossAtt 0.2930 TrainAcc 0.8800 TestAcc 0.8446 0.8050
epoch 1800 LossPred 0.3493 LossAtt 0.3122 TrainAcc 0.8900 TestAcc 0.8536 0.8000
epoch 1900 LossPred 0.3071 LossAtt 0.2927 TrainAcc 0.9100 TestAcc 0.8306 0.8300
epoch 2000 LossPred 0.3240 LossAtt 0.2988 TrainAcc 0.9000 TestAcc 0.8476 0.8450
epoch 2100 LossPred 0.2972 LossAtt 0.3135 TrainAcc 0.9000 TestAcc 0.8561 0.8350
epoch 2200 LossPred 0.2832 LossAtt 0.2883 TrainAcc 0.9100 TestAcc 0.8408 0.8300
epoch 2300 LossPred 0.2631 LossAtt 0.2763 TrainAcc 0.9100 TestAcc 0.8566 0.8350
epoch 2400 LossPred 0.2778 LossAtt 0.2940 TrainAcc 0.9100 TestAcc 0.8511 0.8600
epoch 2500 LossPred 0.2218 LossAtt 0.2771 TrainAcc 0.9400 TestAcc 0.8849 0.8600
Optimization Finished!
********** replication  91  **********
epoch   0 LossPred 1.0161 LossAtt 0.9876 TrainAcc 0.4900 TestAcc 0.5090 0.4750
epoch 100 LossPred 0.9461 LossAtt 0.4753 TrainAcc 0.5600 TestAcc 0.6081 0.5600
epoch 200 LossPred 0.8985 LossAtt 0.5049 TrainAcc 0.6500 TestAcc 0.6697 0.6200
epoch 300 LossPred 0.7499 LossAtt 0.6044 TrainAcc 0.7300 TestAcc 0.7660 0.7300
epoch 400 LossPred 0.4217 LossAtt 0.5087 TrainAcc 0.8900 TestAcc 0.8431 0.8700
epoch 500 LossPred 0.4089 LossAtt 0.4666 TrainAcc 0.8800 TestAcc 0.8423 0.8600
epoch 600 LossPred 0.4161 LossAtt 0.4801 TrainAcc 0.8900 TestAcc 0.8514 0.8650
epoch 700 LossPred 0.4197 LossAtt 0.4707 TrainAcc 0.8800 TestAcc 0.8443 0.8700
epoch 800 LossPred 0.4049 LossAtt 0.4734 TrainAcc 0.8700 TestAcc 0.8496 0.8800
epoch 900 LossPred 0.3868 LossAtt 0.5230 TrainAcc 0.8700 TestAcc 0.8621 0.8850
epoch 1000 LossPred 0.5301 LossAtt 0.5316 TrainAcc 0.8300 TestAcc 0.7913 0.8150
epoch 1100 LossPred 0.2927 LossAtt 0.5351 TrainAcc 0.9000 TestAcc 0.8971 0.9150
epoch 1200 LossPred 0.3335 LossAtt 0.4932 TrainAcc 0.8800 TestAcc 0.8649 0.9100
epoch 1300 LossPred 0.2843 LossAtt 0.5065 TrainAcc 0.9100 TestAcc 0.9047 0.8750
epoch 1400 LossPred 0.2710 LossAtt 0.4689 TrainAcc 0.9200 TestAcc 0.9022 0.8700
epoch 1500 LossPred 0.3328 LossAtt 0.5104 TrainAcc 0.8700 TestAcc 0.8746 0.8800
epoch 1600 LossPred 0.2056 LossAtt 0.5194 TrainAcc 0.9500 TestAcc 0.9374 0.9000
epoch 1700 LossPred 0.3762 LossAtt 0.5318 TrainAcc 0.8600 TestAcc 0.8694 0.8300
epoch 1800 LossPred 0.4911 LossAtt 0.5438 TrainAcc 0.8100 TestAcc 0.7990 0.8250
epoch 1900 LossPred 0.3760 LossAtt 0.5199 TrainAcc 0.8800 TestAcc 0.8539 0.8750
epoch 2000 LossPred 0.3400 LossAtt 0.4834 TrainAcc 0.9100 TestAcc 0.8706 0.8750
epoch 2100 LossPred 0.2431 LossAtt 0.4994 TrainAcc 0.9100 TestAcc 0.9074 0.9000
epoch 2200 LossPred 0.2120 LossAtt 0.4711 TrainAcc 0.9500 TestAcc 0.9585 0.9050
epoch 2300 LossPred 0.2093 LossAtt 0.4972 TrainAcc 0.9500 TestAcc 0.9404 0.9100
epoch 2400 LossPred 0.2419 LossAtt 0.4705 TrainAcc 0.9400 TestAcc 0.9472 0.8950
epoch 2500 LossPred 0.2463 LossAtt 0.4791 TrainAcc 0.9300 TestAcc 0.9437 0.8800
Optimization Finished!
********** replication  92  **********
epoch   0 LossPred 1.3029 LossAtt 1.0015 TrainAcc 0.5000 TestAcc 0.4462 0.4900
epoch 100 LossPred 0.9851 LossAtt 0.4757 TrainAcc 0.5400 TestAcc 0.4782 0.5600
epoch 200 LossPred 0.9095 LossAtt 0.4707 TrainAcc 0.6200 TestAcc 0.6146 0.6200
epoch 300 LossPred 0.7181 LossAtt 0.5294 TrainAcc 0.7800 TestAcc 0.8066 0.7650
epoch 400 LossPred 0.5385 LossAtt 0.4811 TrainAcc 0.8500 TestAcc 0.8879 0.8300
epoch 500 LossPred 0.4120 LossAtt 0.4796 TrainAcc 0.8900 TestAcc 0.8966 0.8350
epoch 600 LossPred 0.3680 LossAtt 0.4742 TrainAcc 0.8900 TestAcc 0.9042 0.8850
epoch 700 LossPred 0.3402 LossAtt 0.4620 TrainAcc 0.8900 TestAcc 0.9234 0.9000
epoch 800 LossPred 0.3192 LossAtt 0.4688 TrainAcc 0.9100 TestAcc 0.9267 0.8800
epoch 900 LossPred 0.2887 LossAtt 0.4368 TrainAcc 0.9200 TestAcc 0.9264 0.9050
epoch 1000 LossPred 0.3494 LossAtt 0.4325 TrainAcc 0.8600 TestAcc 0.8774 0.8900
epoch 1100 LossPred 0.2715 LossAtt 0.4100 TrainAcc 0.9200 TestAcc 0.9492 0.9100
epoch 1200 LossPred 0.2589 LossAtt 0.4119 TrainAcc 0.9300 TestAcc 0.9382 0.9100
epoch 1300 LossPred 0.2576 LossAtt 0.4316 TrainAcc 0.9300 TestAcc 0.9477 0.9200
epoch 1400 LossPred 0.2375 LossAtt 0.4669 TrainAcc 0.9400 TestAcc 0.9372 0.9100
epoch 1500 LossPred 0.3972 LossAtt 0.4677 TrainAcc 0.8300 TestAcc 0.8456 0.8650
epoch 1600 LossPred 0.2975 LossAtt 0.4604 TrainAcc 0.9000 TestAcc 0.9259 0.8650
epoch 1700 LossPred 0.5369 LossAtt 0.5027 TrainAcc 0.7800 TestAcc 0.8216 0.7850
epoch 1800 LossPred 0.2512 LossAtt 0.5297 TrainAcc 0.9300 TestAcc 0.9537 0.9050
epoch 1900 LossPred 0.3305 LossAtt 0.5182 TrainAcc 0.8900 TestAcc 0.9119 0.8550
epoch 2000 LossPred 0.2579 LossAtt 0.5260 TrainAcc 0.9300 TestAcc 0.9222 0.9250
epoch 2100 LossPred 0.8202 LossAtt 0.5837 TrainAcc 0.7100 TestAcc 0.7575 0.7100
epoch 2200 LossPred 0.3775 LossAtt 0.5792 TrainAcc 0.8700 TestAcc 0.8671 0.8500
epoch 2300 LossPred 0.3802 LossAtt 0.5823 TrainAcc 0.8700 TestAcc 0.8929 0.8600
epoch 2400 LossPred 0.3635 LossAtt 0.5592 TrainAcc 0.8800 TestAcc 0.8606 0.8650
epoch 2500 LossPred 0.4355 LossAtt 0.5018 TrainAcc 0.8100 TestAcc 0.8676 0.8100
Optimization Finished!
********** replication  93  **********
epoch   0 LossPred 1.0283 LossAtt 1.0286 TrainAcc 0.6000 TestAcc 0.5453 0.6050
epoch 100 LossPred 0.8817 LossAtt 0.4981 TrainAcc 0.6800 TestAcc 0.6071 0.6800
epoch 200 LossPred 0.8456 LossAtt 0.4800 TrainAcc 0.6800 TestAcc 0.6071 0.6800
epoch 300 LossPred 0.6449 LossAtt 0.6149 TrainAcc 0.7700 TestAcc 0.7195 0.7700
epoch 400 LossPred 0.2660 LossAtt 0.4691 TrainAcc 0.9300 TestAcc 0.8388 0.9150
epoch 500 LossPred 0.2566 LossAtt 0.4451 TrainAcc 0.9300 TestAcc 0.8288 0.9050
epoch 600 LossPred 0.2872 LossAtt 0.4006 TrainAcc 0.9100 TestAcc 0.8478 0.8850
epoch 700 LossPred 0.2539 LossAtt 0.3805 TrainAcc 0.9300 TestAcc 0.8443 0.9250
epoch 800 LossPred 0.2551 LossAtt 0.3791 TrainAcc 0.9300 TestAcc 0.8411 0.9200
epoch 900 LossPred 0.2315 LossAtt 0.3465 TrainAcc 0.9300 TestAcc 0.8303 0.9250
epoch 1000 LossPred 0.1632 LossAtt 0.3721 TrainAcc 0.9600 TestAcc 0.8606 0.9150
epoch 1100 LossPred 0.2254 LossAtt 0.3537 TrainAcc 0.9200 TestAcc 0.8606 0.9400
epoch 1200 LossPred 0.1609 LossAtt 0.3523 TrainAcc 0.9500 TestAcc 0.8606 0.9400
epoch 1300 LossPred 0.1881 LossAtt 0.3612 TrainAcc 0.9400 TestAcc 0.8581 0.9350
epoch 1400 LossPred 0.1501 LossAtt 0.3759 TrainAcc 0.9600 TestAcc 0.8574 0.9450
epoch 1500 LossPred 0.1677 LossAtt 0.3710 TrainAcc 0.9300 TestAcc 0.8619 0.9450
epoch 1600 LossPred 0.1545 LossAtt 0.3596 TrainAcc 0.9500 TestAcc 0.8671 0.9400
epoch 1700 LossPred 0.1796 LossAtt 0.3650 TrainAcc 0.9300 TestAcc 0.8619 0.9400
epoch 1800 LossPred 0.1935 LossAtt 0.3581 TrainAcc 0.9200 TestAcc 0.8564 0.9200
epoch 1900 LossPred 0.1338 LossAtt 0.3705 TrainAcc 0.9500 TestAcc 0.8781 0.9550
epoch 2000 LossPred 0.1777 LossAtt 0.3790 TrainAcc 0.9300 TestAcc 0.8776 0.9250
epoch 2100 LossPred 0.1255 LossAtt 0.3899 TrainAcc 0.9500 TestAcc 0.8996 0.9500
epoch 2200 LossPred 0.1242 LossAtt 0.3725 TrainAcc 0.9600 TestAcc 0.8939 0.9500
epoch 2300 LossPred 0.1422 LossAtt 0.3762 TrainAcc 0.9400 TestAcc 0.9069 0.9250
epoch 2400 LossPred 0.1213 LossAtt 0.3932 TrainAcc 0.9600 TestAcc 0.8924 0.9450
epoch 2500 LossPred 0.1026 LossAtt 0.3501 TrainAcc 0.9700 TestAcc 0.9072 0.9500
Optimization Finished!
********** replication  94  **********
epoch   0 LossPred 1.0096 LossAtt 0.9864 TrainAcc 0.5300 TestAcc 0.4359 0.5150
epoch 100 LossPred 0.9488 LossAtt 0.4092 TrainAcc 0.6100 TestAcc 0.5328 0.6200
epoch 200 LossPred 0.9292 LossAtt 0.3417 TrainAcc 0.6200 TestAcc 0.5153 0.5950
epoch 300 LossPred 0.9229 LossAtt 0.2752 TrainAcc 0.6400 TestAcc 0.5075 0.6050
epoch 400 LossPred 0.9049 LossAtt 0.2754 TrainAcc 0.6700 TestAcc 0.5158 0.6000
epoch 500 LossPred 0.8915 LossAtt 0.2923 TrainAcc 0.6700 TestAcc 0.5175 0.6550
epoch 600 LossPred 0.8838 LossAtt 0.3191 TrainAcc 0.6700 TestAcc 0.5213 0.6850
epoch 700 LossPred 0.8792 LossAtt 0.3679 TrainAcc 0.6700 TestAcc 0.5198 0.6900
epoch 800 LossPred 0.8730 LossAtt 0.3734 TrainAcc 0.6700 TestAcc 0.5245 0.6850
epoch 900 LossPred 0.8711 LossAtt 0.3470 TrainAcc 0.6700 TestAcc 0.5250 0.6850
epoch 1000 LossPred 0.8697 LossAtt 0.3486 TrainAcc 0.6700 TestAcc 0.5248 0.6850
epoch 1100 LossPred 0.8668 LossAtt 0.3592 TrainAcc 0.6800 TestAcc 0.5420 0.6950
epoch 1200 LossPred 0.8649 LossAtt 0.3503 TrainAcc 0.6800 TestAcc 0.5473 0.7000
epoch 1300 LossPred 0.8587 LossAtt 0.3117 TrainAcc 0.6700 TestAcc 0.5423 0.6800
epoch 1400 LossPred 0.8537 LossAtt 0.2847 TrainAcc 0.6800 TestAcc 0.5468 0.6900
epoch 1500 LossPred 0.8611 LossAtt 0.3402 TrainAcc 0.6800 TestAcc 0.5498 0.6950
epoch 1600 LossPred 0.8657 LossAtt 0.3286 TrainAcc 0.6900 TestAcc 0.5458 0.6900
epoch 1700 LossPred 0.8629 LossAtt 0.3165 TrainAcc 0.6600 TestAcc 0.5293 0.6800
epoch 1800 LossPred 0.8610 LossAtt 0.3557 TrainAcc 0.6600 TestAcc 0.5413 0.6700
epoch 1900 LossPred 0.8181 LossAtt 0.3456 TrainAcc 0.6800 TestAcc 0.5653 0.6800
epoch 2000 LossPred 0.7965 LossAtt 0.3224 TrainAcc 0.7000 TestAcc 0.5651 0.6750
epoch 2100 LossPred 0.7690 LossAtt 0.2938 TrainAcc 0.7300 TestAcc 0.5928 0.6750
epoch 2200 LossPred 0.7740 LossAtt 0.3278 TrainAcc 0.7200 TestAcc 0.5916 0.6950
epoch 2300 LossPred 0.7451 LossAtt 0.3355 TrainAcc 0.7400 TestAcc 0.5956 0.6950
epoch 2400 LossPred 0.7243 LossAtt 0.3571 TrainAcc 0.7400 TestAcc 0.5943 0.7050
epoch 2500 LossPred 0.7207 LossAtt 0.3561 TrainAcc 0.7400 TestAcc 0.5983 0.7050
Optimization Finished!
********** replication  95  **********
epoch   0 LossPred 1.0815 LossAtt 0.9889 TrainAcc 0.5300 TestAcc 0.4489 0.4850
epoch 100 LossPred 0.9279 LossAtt 0.3778 TrainAcc 0.6200 TestAcc 0.6076 0.6150
epoch 200 LossPred 0.8214 LossAtt 0.4081 TrainAcc 0.6700 TestAcc 0.6476 0.6900
epoch 300 LossPred 0.3023 LossAtt 0.4135 TrainAcc 0.9200 TestAcc 0.8739 0.9350
epoch 400 LossPred 0.2318 LossAtt 0.4213 TrainAcc 0.9600 TestAcc 0.8971 0.9300
epoch 500 LossPred 0.1945 LossAtt 0.4285 TrainAcc 0.9700 TestAcc 0.8966 0.9400
epoch 600 LossPred 0.2339 LossAtt 0.4058 TrainAcc 0.9400 TestAcc 0.9004 0.9100
epoch 700 LossPred 0.3411 LossAtt 0.4244 TrainAcc 0.9100 TestAcc 0.8266 0.8600
epoch 800 LossPred 0.4035 LossAtt 0.4019 TrainAcc 0.8600 TestAcc 0.8641 0.8500
epoch 900 LossPred 0.4742 LossAtt 0.4183 TrainAcc 0.8300 TestAcc 0.8471 0.8150
epoch 1000 LossPred 0.2852 LossAtt 0.4104 TrainAcc 0.9100 TestAcc 0.8861 0.8850
epoch 1100 LossPred 0.1938 LossAtt 0.3983 TrainAcc 0.9400 TestAcc 0.8964 0.9400
epoch 1200 LossPred 0.2828 LossAtt 0.3853 TrainAcc 0.9300 TestAcc 0.8476 0.8900
epoch 1300 LossPred 0.2278 LossAtt 0.3990 TrainAcc 0.9400 TestAcc 0.8949 0.9050
epoch 1400 LossPred 0.1859 LossAtt 0.3884 TrainAcc 0.9400 TestAcc 0.9052 0.9150
epoch 1500 LossPred 0.2841 LossAtt 0.3984 TrainAcc 0.9000 TestAcc 0.8581 0.9050
epoch 1600 LossPred 0.2296 LossAtt 0.3891 TrainAcc 0.9300 TestAcc 0.8951 0.9050
epoch 1700 LossPred 0.3096 LossAtt 0.3947 TrainAcc 0.9000 TestAcc 0.8501 0.9100
epoch 1800 LossPred 0.2587 LossAtt 0.4017 TrainAcc 0.9300 TestAcc 0.8949 0.9100
epoch 1900 LossPred 0.1764 LossAtt 0.3681 TrainAcc 0.9600 TestAcc 0.9012 0.9450
epoch 2000 LossPred 0.3217 LossAtt 0.3774 TrainAcc 0.9000 TestAcc 0.8438 0.8950
epoch 2100 LossPred 0.2489 LossAtt 0.3884 TrainAcc 0.9300 TestAcc 0.8691 0.9200
epoch 2200 LossPred 0.1652 LossAtt 0.3614 TrainAcc 0.9600 TestAcc 0.9052 0.9450
epoch 2300 LossPred 0.1946 LossAtt 0.3604 TrainAcc 0.9600 TestAcc 0.9014 0.9200
epoch 2400 LossPred 0.2584 LossAtt 0.3528 TrainAcc 0.9200 TestAcc 0.8884 0.9150
epoch 2500 LossPred 0.1562 LossAtt 0.3620 TrainAcc 0.9500 TestAcc 0.9034 0.9450
Optimization Finished!
********** replication  96  **********
epoch   0 LossPred 1.0426 LossAtt 1.0009 TrainAcc 0.5300 TestAcc 0.5065 0.5350
epoch 100 LossPred 0.8971 LossAtt 0.4489 TrainAcc 0.6800 TestAcc 0.5998 0.6600
epoch 200 LossPred 0.8460 LossAtt 0.4270 TrainAcc 0.6800 TestAcc 0.5998 0.6800
epoch 300 LossPred 0.7347 LossAtt 0.4721 TrainAcc 0.7200 TestAcc 0.6577 0.7500
epoch 400 LossPred 0.3211 LossAtt 0.4506 TrainAcc 0.9200 TestAcc 0.8566 0.8650
epoch 500 LossPred 0.3125 LossAtt 0.4350 TrainAcc 0.9300 TestAcc 0.8473 0.8650
epoch 600 LossPred 0.2978 LossAtt 0.4220 TrainAcc 0.9100 TestAcc 0.8701 0.8750
epoch 700 LossPred 0.2878 LossAtt 0.4150 TrainAcc 0.9200 TestAcc 0.8621 0.8700
epoch 800 LossPred 0.2690 LossAtt 0.4025 TrainAcc 0.9300 TestAcc 0.8634 0.8800
epoch 900 LossPred 0.3008 LossAtt 0.3989 TrainAcc 0.8800 TestAcc 0.8706 0.8750
epoch 1000 LossPred 0.2861 LossAtt 0.3791 TrainAcc 0.9100 TestAcc 0.8601 0.8700
epoch 1100 LossPred 0.2683 LossAtt 0.3909 TrainAcc 0.9300 TestAcc 0.8601 0.8850
epoch 1200 LossPred 0.2518 LossAtt 0.3904 TrainAcc 0.9300 TestAcc 0.8731 0.8700
epoch 1300 LossPred 0.2579 LossAtt 0.3864 TrainAcc 0.9100 TestAcc 0.8736 0.8950
epoch 1400 LossPred 0.2583 LossAtt 0.3722 TrainAcc 0.9300 TestAcc 0.8896 0.8800
epoch 1500 LossPred 0.2464 LossAtt 0.3704 TrainAcc 0.9300 TestAcc 0.8714 0.8900
epoch 1600 LossPred 0.2272 LossAtt 0.3580 TrainAcc 0.9400 TestAcc 0.8841 0.9000
epoch 1700 LossPred 0.1984 LossAtt 0.3772 TrainAcc 0.9400 TestAcc 0.8939 0.8950
epoch 1800 LossPred 0.2270 LossAtt 0.3941 TrainAcc 0.9200 TestAcc 0.8869 0.8900
epoch 1900 LossPred 0.1728 LossAtt 0.3964 TrainAcc 0.9500 TestAcc 0.9052 0.9200
epoch 2000 LossPred 0.1888 LossAtt 0.3944 TrainAcc 0.9400 TestAcc 0.9254 0.8850
epoch 2100 LossPred 0.1816 LossAtt 0.3934 TrainAcc 0.9300 TestAcc 0.8954 0.9200
epoch 2200 LossPred 0.2107 LossAtt 0.3980 TrainAcc 0.9300 TestAcc 0.8841 0.9100
epoch 2300 LossPred 0.1165 LossAtt 0.4020 TrainAcc 0.9700 TestAcc 0.9387 0.9350
epoch 2400 LossPred 0.5373 LossAtt 0.3999 TrainAcc 0.8000 TestAcc 0.7988 0.7950
epoch 2500 LossPred 0.1098 LossAtt 0.3985 TrainAcc 0.9700 TestAcc 0.9349 0.9400
Optimization Finished!
********** replication  97  **********
epoch   0 LossPred 1.0195 LossAtt 0.9954 TrainAcc 0.5300 TestAcc 0.5360 0.5500
epoch 100 LossPred 0.9736 LossAtt 0.3503 TrainAcc 0.5800 TestAcc 0.6006 0.5800
epoch 200 LossPred 0.9732 LossAtt 0.2108 TrainAcc 0.5800 TestAcc 0.6006 0.5800
epoch 300 LossPred 0.9725 LossAtt 0.1173 TrainAcc 0.5800 TestAcc 0.6006 0.5800
epoch 400 LossPred 0.9695 LossAtt 0.1233 TrainAcc 0.5800 TestAcc 0.6006 0.5800
epoch 500 LossPred 0.9708 LossAtt 0.1607 TrainAcc 0.5800 TestAcc 0.6006 0.5800
epoch 600 LossPred 0.5248 LossAtt 0.2938 TrainAcc 0.8200 TestAcc 0.8378 0.8300
epoch 700 LossPred 0.2773 LossAtt 0.2761 TrainAcc 0.9200 TestAcc 0.8761 0.8800
epoch 800 LossPred 0.2228 LossAtt 0.2962 TrainAcc 0.9200 TestAcc 0.9269 0.9200
epoch 900 LossPred 0.1858 LossAtt 0.2834 TrainAcc 0.9500 TestAcc 0.9344 0.9200
epoch 1000 LossPred 0.2030 LossAtt 0.2914 TrainAcc 0.9400 TestAcc 0.9434 0.9200
epoch 1100 LossPred 0.1617 LossAtt 0.2934 TrainAcc 0.9600 TestAcc 0.9282 0.9150
epoch 1200 LossPred 0.2013 LossAtt 0.2862 TrainAcc 0.9500 TestAcc 0.9452 0.9150
epoch 1300 LossPred 0.1719 LossAtt 0.2886 TrainAcc 0.9500 TestAcc 0.9124 0.9000
epoch 1400 LossPred 0.1521 LossAtt 0.3004 TrainAcc 0.9600 TestAcc 0.9214 0.9200
epoch 1500 LossPred 0.2029 LossAtt 0.2916 TrainAcc 0.9300 TestAcc 0.9184 0.9050
epoch 1600 LossPred 0.3269 LossAtt 0.2878 TrainAcc 0.9100 TestAcc 0.8594 0.8750
epoch 1700 LossPred 0.1813 LossAtt 0.2936 TrainAcc 0.9500 TestAcc 0.9449 0.9300
epoch 1800 LossPred 0.1588 LossAtt 0.2805 TrainAcc 0.9600 TestAcc 0.9234 0.9100
epoch 1900 LossPred 0.1393 LossAtt 0.3003 TrainAcc 0.9500 TestAcc 0.9319 0.9250
epoch 2000 LossPred 0.3222 LossAtt 0.2752 TrainAcc 0.8900 TestAcc 0.9089 0.9000
epoch 2100 LossPred 0.1573 LossAtt 0.3165 TrainAcc 0.9600 TestAcc 0.9204 0.9050
epoch 2200 LossPred 0.2938 LossAtt 0.2709 TrainAcc 0.8900 TestAcc 0.8546 0.8600
epoch 2300 LossPred 0.1901 LossAtt 0.2928 TrainAcc 0.9600 TestAcc 0.9447 0.9250
epoch 2400 LossPred 0.1552 LossAtt 0.2715 TrainAcc 0.9600 TestAcc 0.9224 0.9200
epoch 2500 LossPred 0.3229 LossAtt 0.2878 TrainAcc 0.8900 TestAcc 0.9119 0.8850
Optimization Finished!
********** replication  98  **********
epoch   0 LossPred 1.1520 LossAtt 1.0037 TrainAcc 0.4400 TestAcc 0.5045 0.4500
epoch 100 LossPred 0.9524 LossAtt 0.4320 TrainAcc 0.5800 TestAcc 0.6046 0.5750
epoch 200 LossPred 0.9436 LossAtt 0.3962 TrainAcc 0.5800 TestAcc 0.6046 0.5800
epoch 300 LossPred 0.9268 LossAtt 0.3943 TrainAcc 0.6000 TestAcc 0.6514 0.6000
epoch 400 LossPred 0.6006 LossAtt 0.4627 TrainAcc 0.8500 TestAcc 0.8493 0.8650
epoch 500 LossPred 0.4357 LossAtt 0.4370 TrainAcc 0.8400 TestAcc 0.8604 0.8250
epoch 600 LossPred 0.4108 LossAtt 0.3891 TrainAcc 0.8500 TestAcc 0.8734 0.8350
epoch 700 LossPred 0.3577 LossAtt 0.3587 TrainAcc 0.8600 TestAcc 0.8996 0.8900
epoch 800 LossPred 0.2927 LossAtt 0.3326 TrainAcc 0.9000 TestAcc 0.9209 0.9050
epoch 900 LossPred 0.3202 LossAtt 0.3178 TrainAcc 0.9100 TestAcc 0.8839 0.8950
epoch 1000 LossPred 0.2908 LossAtt 0.3278 TrainAcc 0.9100 TestAcc 0.9194 0.8850
epoch 1100 LossPred 0.5939 LossAtt 0.3161 TrainAcc 0.7900 TestAcc 0.8113 0.7800
epoch 1200 LossPred 0.3643 LossAtt 0.3131 TrainAcc 0.8500 TestAcc 0.8911 0.8500
epoch 1300 LossPred 0.2959 LossAtt 0.3356 TrainAcc 0.8900 TestAcc 0.8904 0.9000
epoch 1400 LossPred 0.6201 LossAtt 0.3189 TrainAcc 0.8100 TestAcc 0.8101 0.8000
epoch 1500 LossPred 0.3673 LossAtt 0.3223 TrainAcc 0.8600 TestAcc 0.9132 0.8650
epoch 1600 LossPred 0.4709 LossAtt 0.3179 TrainAcc 0.8500 TestAcc 0.8038 0.8400
epoch 1700 LossPred 0.3520 LossAtt 0.3445 TrainAcc 0.8800 TestAcc 0.8656 0.8750
epoch 1800 LossPred 0.3993 LossAtt 0.3138 TrainAcc 0.8900 TestAcc 0.9119 0.8700
epoch 1900 LossPred 0.3133 LossAtt 0.3373 TrainAcc 0.9000 TestAcc 0.8759 0.8950
epoch 2000 LossPred 0.2829 LossAtt 0.3518 TrainAcc 0.9100 TestAcc 0.8911 0.9000
epoch 2100 LossPred 0.3885 LossAtt 0.3639 TrainAcc 0.8500 TestAcc 0.8791 0.8650
epoch 2200 LossPred 0.3081 LossAtt 0.3587 TrainAcc 0.8900 TestAcc 0.9047 0.8950
epoch 2300 LossPred 0.3283 LossAtt 0.3656 TrainAcc 0.8900 TestAcc 0.8744 0.9050
epoch 2400 LossPred 0.3030 LossAtt 0.3856 TrainAcc 0.9100 TestAcc 0.8921 0.8900
epoch 2500 LossPred 0.4672 LossAtt 0.4007 TrainAcc 0.8200 TestAcc 0.8684 0.8300
Optimization Finished!
********** replication  99  **********
epoch   0 LossPred 1.0697 LossAtt 1.0153 TrainAcc 0.5000 TestAcc 0.5023 0.5250
epoch 100 LossPred 0.8681 LossAtt 0.3214 TrainAcc 0.7100 TestAcc 0.6416 0.6650
epoch 200 LossPred 0.5964 LossAtt 0.4370 TrainAcc 0.8000 TestAcc 0.7503 0.8050
epoch 300 LossPred 1.0089 LossAtt 0.3558 TrainAcc 0.6200 TestAcc 0.5395 0.6350
epoch 400 LossPred 0.6684 LossAtt 0.4047 TrainAcc 0.7500 TestAcc 0.7728 0.7450
epoch 500 LossPred 0.4230 LossAtt 0.3657 TrainAcc 0.8300 TestAcc 0.8311 0.8300
epoch 600 LossPred 0.3967 LossAtt 0.3788 TrainAcc 0.8900 TestAcc 0.8529 0.8200
epoch 700 LossPred 0.4088 LossAtt 0.3594 TrainAcc 0.8400 TestAcc 0.8461 0.8350
epoch 800 LossPred 0.4409 LossAtt 0.3555 TrainAcc 0.8300 TestAcc 0.8148 0.8250
epoch 900 LossPred 0.3153 LossAtt 0.3801 TrainAcc 0.9200 TestAcc 0.8606 0.8500
epoch 1000 LossPred 0.3181 LossAtt 0.3708 TrainAcc 0.9100 TestAcc 0.8609 0.8350
epoch 1100 LossPred 0.2815 LossAtt 0.3686 TrainAcc 0.9300 TestAcc 0.8666 0.8200
epoch 1200 LossPred 0.4739 LossAtt 0.3855 TrainAcc 0.8400 TestAcc 0.8196 0.8200
epoch 1300 LossPred 0.3601 LossAtt 0.3666 TrainAcc 0.9000 TestAcc 0.8561 0.8300
epoch 1400 LossPred 0.3490 LossAtt 0.3547 TrainAcc 0.8900 TestAcc 0.8521 0.8500
epoch 1500 LossPred 0.4328 LossAtt 0.3324 TrainAcc 0.8700 TestAcc 0.8341 0.8200
epoch 1600 LossPred 0.3853 LossAtt 0.3205 TrainAcc 0.8900 TestAcc 0.8468 0.8250
epoch 1700 LossPred 0.3414 LossAtt 0.3220 TrainAcc 0.8800 TestAcc 0.8524 0.8500
epoch 1800 LossPred 0.3539 LossAtt 0.3361 TrainAcc 0.8900 TestAcc 0.8446 0.8250
epoch 1900 LossPred 0.3268 LossAtt 0.3383 TrainAcc 0.8800 TestAcc 0.8504 0.8550
epoch 2000 LossPred 0.3551 LossAtt 0.3689 TrainAcc 0.8900 TestAcc 0.8446 0.8300
epoch 2100 LossPred 0.3354 LossAtt 0.3303 TrainAcc 0.9100 TestAcc 0.8621 0.8400
epoch 2200 LossPred 0.4371 LossAtt 0.3548 TrainAcc 0.8200 TestAcc 0.8443 0.8450
epoch 2300 LossPred 0.3628 LossAtt 0.3312 TrainAcc 0.8900 TestAcc 0.8506 0.8550
epoch 2400 LossPred 0.3640 LossAtt 0.3684 TrainAcc 0.8800 TestAcc 0.8579 0.8350
epoch 2500 LossPred 0.3709 LossAtt 0.3386 TrainAcc 0.8700 TestAcc 0.8466 0.8450
Optimization Finished!
********************************************************************
Namespace(arch='tanh', batch_size=256, display_epoch=100, input_noise_level=0.15, latent_attractor_space=True, loss_switch_frequency=0, lrate_attractor=0.002, lrate_prediction=0.002, lrate_wt_penalty=0.0, n_attractor_hidden=10, n_attractor_steps=15, n_hidden=5, n_replications=100, noise_level=0.5, report_best_train_performance=True, seq_len=15, task='majority', train_attr_weights_on_prediction=False, training_epochs=2500)
********************************************************************
mean train accuracy 0.9358001
indiv runs  [0.99, 0.94, 0.6, 0.99, 0.59, 0.99, 0.97, 0.93, 0.93, 0.98, 0.97, 0.97, 0.82, 0.95, 0.98, 0.98, 0.95, 0.84, 1.0, 0.97, 0.96, 0.97, 0.99, 0.98, 0.85, 0.99, 0.93, 0.96, 0.97, 0.98, 1.0, 0.97, 0.95, 0.99, 0.97, 0.89, 0.89, 0.97, 1.0, 0.99, 0.96, 0.99, 0.95, 0.95, 0.98, 0.96, 0.94, 0.98, 0.96, 1.0, 0.95, 0.79, 0.89, 0.78, 0.98, 0.98, 0.92, 0.97, 0.93, 0.99, 0.98, 0.97, 0.99, 0.97, 0.97, 0.92, 0.99, 1.0, 0.99, 0.93, 0.7, 0.98, 0.97, 0.94, 0.94, 0.97, 0.94, 0.97, 0.93, 0.97, 0.96, 0.66, 0.91, 0.98, 0.94, 0.96, 0.66, 0.93, 0.96, 0.93, 0.94, 0.95, 0.94, 0.97, 0.74, 0.97, 0.97, 0.96, 0.91, 0.93]
mean epoch 1501.0
indiv epochs  [1701, 1701, 1001, 1701, 1401]
test1 accuracy mean  0.8769319  median  0.90690696
test2 accuracy mean  0.9007499  median  0.925
test1 indiv runs  [0.9754755, 0.9086587, 0.6048549, 0.9401902, 0.5175175, 0.9191692, 0.9667167, 0.8398398, 0.9119119, 0.8608609, 0.9246747, 0.8858859, 0.6271271, 0.8786286, 0.9416917, 0.9612112, 0.9191692, 0.7507508, 0.9604605, 0.9209209, 0.8993994, 0.9411912, 0.9652152, 0.8616116, 0.8546046, 0.9076577, 0.8846346, 0.9359359, 0.9441942, 0.8976476, 0.9379379, 0.8998999, 0.952953, 0.9712212, 0.9284284, 0.6744244, 0.8075576, 0.8996496, 0.9066567, 0.9106607, 0.9496997, 0.9294294, 0.9039039, 0.9036537, 0.9121622, 0.9206707, 0.8631131, 0.962963, 0.8963964, 0.9361862, 0.9376877, 0.6468969, 0.8783784, 0.5285285, 0.9064064, 0.9517017, 0.8878879, 0.9384384, 0.9044044, 0.9189189, 0.9079079, 0.8986486, 0.9346847, 0.9431932, 0.9106607, 0.8686186, 0.9314314, 0.9096597, 0.9256757, 0.8698699, 0.5342843, 0.8813814, 0.9384384, 0.8531031, 0.8623624, 0.9469469, 0.8776276, 0.9041542, 0.8551051, 0.9119119, 0.9234234, 0.6036036, 0.8943944, 0.8841341, 0.9124124, 0.8831331, 0.5860861, 0.9289289, 0.8953954, 0.8651151, 0.8848849, 0.9374374, 0.9371872, 0.9071572, 0.5955956, 0.8966466, 0.9386887, 0.9281782, 0.8838839, 0.8666166]
test2 indiv runs  [0.935, 0.905, 0.59, 0.96, 0.58, 0.965, 0.925, 0.925, 0.925, 0.97, 0.95, 0.935, 0.755, 0.95, 0.905, 0.955, 0.915, 0.785, 0.995, 0.95, 0.91, 0.915, 0.935, 0.955, 0.82, 0.97, 0.91, 0.91, 0.95, 0.91, 0.935, 0.93, 0.93, 0.97, 0.955, 0.815, 0.9, 0.925, 0.995, 0.985, 0.91, 0.98, 0.925, 0.93, 0.92, 0.945, 0.935, 0.94, 0.91, 0.965, 0.885, 0.755, 0.845, 0.765, 0.93, 0.93, 0.855, 0.895, 0.905, 0.965, 0.95, 0.945, 0.965, 0.89, 0.92, 0.88, 0.925, 0.99, 0.985, 0.93, 0.615, 0.97, 0.95, 0.86, 0.855, 0.945, 0.925, 0.965, 0.885, 0.95, 0.93, 0.6, 0.885, 0.97, 0.905, 0.93, 0.635, 0.905, 0.915, 0.89, 0.86, 0.9, 0.91, 0.95, 0.695, 0.94, 0.935, 0.915, 0.895, 0.82]
