Namespace(arch='tanh', batch_size=256, display_epoch=100, input_noise_level=0.15, latent_attractor_space=True, loss_switch_frequency=0, lrate_attractor=0.002, lrate_prediction=0.002, lrate_wt_penalty=0.0, n_attractor_hidden=20, n_attractor_steps=5, n_hidden=10, n_replications=100, noise_level=0.25, report_best_train_performance=True, seq_len=20, task='majority', train_attr_weights_on_prediction=False, training_epochs=2500)
TRAINING ON 100 EXAMPLES, TESTING ON 3996
********** replication  0  **********
epoch   0 LossPred 1.0955 LossAtt 1.0263 TrainAcc 0.6000 TestAcc 0.5120 0.5300
epoch 100 LossPred 0.8986 LossAtt 0.3065 TrainAcc 0.6500 TestAcc 0.5916 0.6450
epoch 200 LossPred 0.8398 LossAtt 0.3191 TrainAcc 0.6700 TestAcc 0.6016 0.6650
epoch 300 LossPred 0.5441 LossAtt 0.4380 TrainAcc 0.8200 TestAcc 0.7863 0.8000
epoch 400 LossPred 0.2944 LossAtt 0.4015 TrainAcc 0.9300 TestAcc 0.8839 0.8750
epoch 500 LossPred 0.2244 LossAtt 0.4158 TrainAcc 0.9500 TestAcc 0.8874 0.8950
epoch 600 LossPred 0.1525 LossAtt 0.4062 TrainAcc 0.9700 TestAcc 0.9062 0.8950
epoch 700 LossPred 0.1352 LossAtt 0.4168 TrainAcc 0.9700 TestAcc 0.9024 0.8700
epoch 800 LossPred 0.1201 LossAtt 0.4021 TrainAcc 0.9700 TestAcc 0.9047 0.8900
epoch 900 LossPred 0.1069 LossAtt 0.4078 TrainAcc 0.9700 TestAcc 0.9107 0.9100
epoch 1000 LossPred 0.2142 LossAtt 0.4032 TrainAcc 0.9400 TestAcc 0.8779 0.9000
epoch 1100 LossPred 0.0880 LossAtt 0.4144 TrainAcc 0.9800 TestAcc 0.9077 0.9150
epoch 1200 LossPred 0.1044 LossAtt 0.3865 TrainAcc 0.9800 TestAcc 0.9004 0.9250
epoch 1300 LossPred 0.0792 LossAtt 0.3916 TrainAcc 0.9900 TestAcc 0.9072 0.9200
epoch 1400 LossPred 0.0893 LossAtt 0.3852 TrainAcc 0.9800 TestAcc 0.9049 0.9000
epoch 1500 LossPred 0.0748 LossAtt 0.3947 TrainAcc 0.9800 TestAcc 0.9009 0.9350
epoch 1600 LossPred 0.0937 LossAtt 0.3786 TrainAcc 0.9700 TestAcc 0.8979 0.9400
epoch 1700 LossPred 0.0652 LossAtt 0.3863 TrainAcc 0.9900 TestAcc 0.9067 0.9400
epoch 1800 LossPred 0.0626 LossAtt 0.3733 TrainAcc 0.9900 TestAcc 0.9014 0.9400
epoch 1900 LossPred 0.0656 LossAtt 0.3728 TrainAcc 0.9800 TestAcc 0.8984 0.9500
epoch 2000 LossPred 0.0626 LossAtt 0.3664 TrainAcc 0.9900 TestAcc 0.8986 0.9500
epoch 2100 LossPred 0.0765 LossAtt 0.3804 TrainAcc 0.9800 TestAcc 0.8936 0.9450
epoch 2200 LossPred 0.0557 LossAtt 0.3618 TrainAcc 0.9900 TestAcc 0.9009 0.9450
epoch 2300 LossPred 0.0537 LossAtt 0.3658 TrainAcc 0.9900 TestAcc 0.9002 0.9550
epoch 2400 LossPred 0.0567 LossAtt 0.3647 TrainAcc 0.9900 TestAcc 0.8961 0.9500
epoch 2500 LossPred 0.0380 LossAtt 0.3725 TrainAcc 0.9900 TestAcc 0.8856 0.9450
Optimization Finished!
********** replication  1  **********
epoch   0 LossPred 1.1419 LossAtt 1.0411 TrainAcc 0.4900 TestAcc 0.5458 0.4850
epoch 100 LossPred 0.7554 LossAtt 0.4202 TrainAcc 0.7200 TestAcc 0.5906 0.7200
epoch 200 LossPred 0.4547 LossAtt 0.4678 TrainAcc 0.8900 TestAcc 0.7565 0.8800
epoch 300 LossPred 0.2769 LossAtt 0.4468 TrainAcc 0.9300 TestAcc 0.8659 0.9050
epoch 400 LossPred 0.2436 LossAtt 0.4351 TrainAcc 0.9400 TestAcc 0.8594 0.9150
epoch 500 LossPred 0.2543 LossAtt 0.4295 TrainAcc 0.9200 TestAcc 0.8516 0.9050
epoch 600 LossPred 0.1894 LossAtt 0.4188 TrainAcc 0.9400 TestAcc 0.8834 0.9200
epoch 700 LossPred 0.1630 LossAtt 0.3913 TrainAcc 0.9400 TestAcc 0.8914 0.9250
epoch 800 LossPred 0.2308 LossAtt 0.3884 TrainAcc 0.9400 TestAcc 0.8656 0.8800
epoch 900 LossPred 0.1851 LossAtt 0.3796 TrainAcc 0.9500 TestAcc 0.8759 0.9000
epoch 1000 LossPred 0.3284 LossAtt 0.3675 TrainAcc 0.8800 TestAcc 0.8646 0.8850
epoch 1100 LossPred 0.1635 LossAtt 0.3708 TrainAcc 0.9500 TestAcc 0.8689 0.9150
epoch 1200 LossPred 0.0954 LossAtt 0.3735 TrainAcc 0.9900 TestAcc 0.8926 0.9200
epoch 1300 LossPred 0.1077 LossAtt 0.3737 TrainAcc 0.9800 TestAcc 0.8901 0.9250
epoch 1400 LossPred 0.0777 LossAtt 0.3750 TrainAcc 0.9800 TestAcc 0.8851 0.9300
epoch 1500 LossPred 0.0728 LossAtt 0.3788 TrainAcc 0.9800 TestAcc 0.8819 0.9350
epoch 1600 LossPred 0.1101 LossAtt 0.3833 TrainAcc 0.9600 TestAcc 0.8766 0.9150
epoch 1700 LossPred 0.0752 LossAtt 0.3789 TrainAcc 0.9800 TestAcc 0.8776 0.9450
epoch 1800 LossPred 0.0653 LossAtt 0.3703 TrainAcc 0.9900 TestAcc 0.8704 0.9300
epoch 1900 LossPred 0.0529 LossAtt 0.3771 TrainAcc 0.9900 TestAcc 0.8771 0.9450
epoch 2000 LossPred 0.0580 LossAtt 0.3692 TrainAcc 0.9900 TestAcc 0.8696 0.9350
epoch 2100 LossPred 0.0693 LossAtt 0.3588 TrainAcc 0.9900 TestAcc 0.8656 0.9400
epoch 2200 LossPred 0.0453 LossAtt 0.3648 TrainAcc 0.9900 TestAcc 0.8719 0.9500
epoch 2300 LossPred 0.0459 LossAtt 0.3665 TrainAcc 0.9900 TestAcc 0.8704 0.9400
epoch 2400 LossPred 0.0426 LossAtt 0.3578 TrainAcc 0.9900 TestAcc 0.8701 0.9450
epoch 2500 LossPred 0.0590 LossAtt 0.3528 TrainAcc 0.9900 TestAcc 0.8624 0.9300
Optimization Finished!
********** replication  2  **********
epoch   0 LossPred 1.0484 LossAtt 1.0142 TrainAcc 0.5400 TestAcc 0.4412 0.4550
epoch 100 LossPred 0.8686 LossAtt 0.2802 TrainAcc 0.6600 TestAcc 0.5716 0.6600
epoch 200 LossPred 0.8351 LossAtt 0.2539 TrainAcc 0.6600 TestAcc 0.5716 0.6600
epoch 300 LossPred 0.4279 LossAtt 0.3225 TrainAcc 0.8800 TestAcc 0.8478 0.8600
epoch 400 LossPred 0.2999 LossAtt 0.3104 TrainAcc 0.9100 TestAcc 0.8594 0.9100
epoch 500 LossPred 0.4106 LossAtt 0.3120 TrainAcc 0.8500 TestAcc 0.8276 0.8650
epoch 600 LossPred 0.2297 LossAtt 0.3021 TrainAcc 0.9300 TestAcc 0.8776 0.8800
epoch 700 LossPred 0.3188 LossAtt 0.3176 TrainAcc 0.9100 TestAcc 0.8709 0.8650
epoch 800 LossPred 0.2158 LossAtt 0.3158 TrainAcc 0.9200 TestAcc 0.8881 0.8900
epoch 900 LossPred 0.4493 LossAtt 0.3068 TrainAcc 0.8600 TestAcc 0.8519 0.8250
epoch 1000 LossPred 0.3611 LossAtt 0.2738 TrainAcc 0.8900 TestAcc 0.8436 0.8700
epoch 1100 LossPred 0.1898 LossAtt 0.2613 TrainAcc 0.9400 TestAcc 0.8879 0.8900
epoch 1200 LossPred 0.2369 LossAtt 0.2423 TrainAcc 0.9200 TestAcc 0.8884 0.9200
epoch 1300 LossPred 0.1795 LossAtt 0.2452 TrainAcc 0.9400 TestAcc 0.8974 0.9350
epoch 1400 LossPred 0.2570 LossAtt 0.2470 TrainAcc 0.9100 TestAcc 0.8926 0.8800
epoch 1500 LossPred 0.1332 LossAtt 0.2359 TrainAcc 0.9700 TestAcc 0.9127 0.9350
epoch 1600 LossPred 0.1849 LossAtt 0.2367 TrainAcc 0.9400 TestAcc 0.9107 0.9250
epoch 1700 LossPred 0.2803 LossAtt 0.2347 TrainAcc 0.9000 TestAcc 0.8851 0.9100
epoch 1800 LossPred 0.1714 LossAtt 0.2441 TrainAcc 0.9500 TestAcc 0.9079 0.9400
epoch 1900 LossPred 0.1264 LossAtt 0.2411 TrainAcc 0.9500 TestAcc 0.9119 0.9450
epoch 2000 LossPred 0.1247 LossAtt 0.2528 TrainAcc 0.9600 TestAcc 0.9149 0.9450
epoch 2100 LossPred 0.1023 LossAtt 0.2523 TrainAcc 0.9800 TestAcc 0.9179 0.9700
epoch 2200 LossPred 0.3086 LossAtt 0.2565 TrainAcc 0.8800 TestAcc 0.8836 0.9150
epoch 2300 LossPred 0.3140 LossAtt 0.2556 TrainAcc 0.8800 TestAcc 0.8846 0.8700
epoch 2400 LossPred 0.1265 LossAtt 0.2719 TrainAcc 0.9700 TestAcc 0.9157 0.9500
epoch 2500 LossPred 0.1094 LossAtt 0.2535 TrainAcc 0.9700 TestAcc 0.9189 0.9550
Optimization Finished!
********** replication  3  **********
epoch   0 LossPred 1.0260 LossAtt 1.0503 TrainAcc 0.4400 TestAcc 0.4464 0.4350
epoch 100 LossPred 0.8496 LossAtt 0.3893 TrainAcc 0.6400 TestAcc 0.5841 0.6350
epoch 200 LossPred 0.3626 LossAtt 0.4119 TrainAcc 0.8900 TestAcc 0.8531 0.8550
epoch 300 LossPred 0.2600 LossAtt 0.4255 TrainAcc 0.9300 TestAcc 0.8906 0.9000
epoch 400 LossPred 0.2219 LossAtt 0.4230 TrainAcc 0.9400 TestAcc 0.8929 0.9100
epoch 500 LossPred 0.1694 LossAtt 0.4271 TrainAcc 0.9500 TestAcc 0.9062 0.9150
epoch 600 LossPred 0.1381 LossAtt 0.4161 TrainAcc 0.9800 TestAcc 0.9112 0.9250
epoch 700 LossPred 0.1461 LossAtt 0.3978 TrainAcc 0.9700 TestAcc 0.8991 0.9150
epoch 800 LossPred 0.1146 LossAtt 0.4004 TrainAcc 0.9800 TestAcc 0.9104 0.9250
epoch 900 LossPred 0.1153 LossAtt 0.3939 TrainAcc 0.9800 TestAcc 0.9079 0.9400
epoch 1000 LossPred 0.0982 LossAtt 0.3683 TrainAcc 0.9800 TestAcc 0.9107 0.9500
epoch 1100 LossPred 0.0956 LossAtt 0.3611 TrainAcc 0.9800 TestAcc 0.9129 0.9500
epoch 1200 LossPred 0.0874 LossAtt 0.3571 TrainAcc 0.9800 TestAcc 0.9124 0.9550
epoch 1300 LossPred 0.0824 LossAtt 0.3496 TrainAcc 0.9800 TestAcc 0.9147 0.9350
epoch 1400 LossPred 0.0788 LossAtt 0.3432 TrainAcc 0.9800 TestAcc 0.9107 0.9400
epoch 1500 LossPred 0.0992 LossAtt 0.3402 TrainAcc 0.9900 TestAcc 0.8884 0.9400
epoch 1600 LossPred 0.0885 LossAtt 0.3368 TrainAcc 0.9800 TestAcc 0.9032 0.9500
epoch 1700 LossPred 0.0799 LossAtt 0.3413 TrainAcc 0.9800 TestAcc 0.8966 0.9550
epoch 1800 LossPred 0.0589 LossAtt 0.3268 TrainAcc 0.9900 TestAcc 0.8991 0.9500
epoch 1900 LossPred 0.0571 LossAtt 0.3325 TrainAcc 0.9900 TestAcc 0.8959 0.9400
epoch 2000 LossPred 0.0535 LossAtt 0.3434 TrainAcc 0.9900 TestAcc 0.8964 0.9500
epoch 2100 LossPred 0.0571 LossAtt 0.3462 TrainAcc 0.9900 TestAcc 0.8884 0.9500
epoch 2200 LossPred 0.0551 LossAtt 0.3293 TrainAcc 0.9900 TestAcc 0.8916 0.9450
epoch 2300 LossPred 0.0650 LossAtt 0.3416 TrainAcc 0.9900 TestAcc 0.8931 0.9700
epoch 2400 LossPred 0.0503 LossAtt 0.3388 TrainAcc 0.9900 TestAcc 0.8946 0.9450
epoch 2500 LossPred 0.1129 LossAtt 0.3314 TrainAcc 0.9700 TestAcc 0.8493 0.9150
Optimization Finished!
********** replication  4  **********
epoch   0 LossPred 1.0614 LossAtt 1.0279 TrainAcc 0.4100 TestAcc 0.3946 0.4100
epoch 100 LossPred 0.8574 LossAtt 0.2703 TrainAcc 0.6700 TestAcc 0.5891 0.6700
epoch 200 LossPred 0.8464 LossAtt 0.2494 TrainAcc 0.6700 TestAcc 0.5891 0.6700
epoch 300 LossPred 0.6070 LossAtt 0.3258 TrainAcc 0.7600 TestAcc 0.7252 0.7600
epoch 400 LossPred 0.5673 LossAtt 0.2950 TrainAcc 0.8500 TestAcc 0.7980 0.8000
epoch 500 LossPred 0.7236 LossAtt 0.2885 TrainAcc 0.6800 TestAcc 0.7305 0.6850
epoch 600 LossPred 0.5651 LossAtt 0.2688 TrainAcc 0.7800 TestAcc 0.7905 0.7800
epoch 700 LossPred 0.4177 LossAtt 0.2734 TrainAcc 0.8600 TestAcc 0.8666 0.8650
epoch 800 LossPred 0.4790 LossAtt 0.2707 TrainAcc 0.8300 TestAcc 0.8366 0.8300
epoch 900 LossPred 0.3551 LossAtt 0.2712 TrainAcc 0.9000 TestAcc 0.8911 0.8850
epoch 1000 LossPred 0.3159 LossAtt 0.2643 TrainAcc 0.8900 TestAcc 0.9054 0.9150
epoch 1100 LossPred 0.5318 LossAtt 0.2936 TrainAcc 0.7700 TestAcc 0.8126 0.7750
epoch 1200 LossPred 0.5238 LossAtt 0.2730 TrainAcc 0.7900 TestAcc 0.8051 0.7750
epoch 1300 LossPred 0.4611 LossAtt 0.2521 TrainAcc 0.8500 TestAcc 0.8233 0.8000
epoch 1400 LossPred 0.3471 LossAtt 0.2517 TrainAcc 0.9200 TestAcc 0.9007 0.8800
epoch 1500 LossPred 0.2935 LossAtt 0.2436 TrainAcc 0.8700 TestAcc 0.8866 0.8500
epoch 1600 LossPred 0.4177 LossAtt 0.2467 TrainAcc 0.8600 TestAcc 0.8336 0.8050
epoch 1700 LossPred 0.3374 LossAtt 0.2353 TrainAcc 0.8700 TestAcc 0.8646 0.8350
epoch 1800 LossPred 0.2509 LossAtt 0.2362 TrainAcc 0.9300 TestAcc 0.9032 0.8950
epoch 1900 LossPred 0.2526 LossAtt 0.2283 TrainAcc 0.9200 TestAcc 0.9017 0.9000
epoch 2000 LossPred 0.4440 LossAtt 0.2325 TrainAcc 0.8400 TestAcc 0.8291 0.8050
epoch 2100 LossPred 0.4518 LossAtt 0.2257 TrainAcc 0.8500 TestAcc 0.8989 0.8600
epoch 2200 LossPred 0.2898 LossAtt 0.2324 TrainAcc 0.8800 TestAcc 0.8724 0.8450
epoch 2300 LossPred 0.3457 LossAtt 0.2326 TrainAcc 0.8600 TestAcc 0.8569 0.8350
epoch 2400 LossPred 0.2395 LossAtt 0.2254 TrainAcc 0.9100 TestAcc 0.8969 0.8750
epoch 2500 LossPred 0.3374 LossAtt 0.2257 TrainAcc 0.9100 TestAcc 0.8966 0.9050
Optimization Finished!
********** replication  5  **********
epoch   0 LossPred 0.9903 LossAtt 1.0155 TrainAcc 0.5300 TestAcc 0.5153 0.5400
epoch 100 LossPred 0.8501 LossAtt 0.3230 TrainAcc 0.6600 TestAcc 0.5938 0.6600
epoch 200 LossPred 0.3974 LossAtt 0.3465 TrainAcc 0.8700 TestAcc 0.8216 0.8450
epoch 300 LossPred 0.3666 LossAtt 0.3281 TrainAcc 0.8700 TestAcc 0.8111 0.8400
epoch 400 LossPred 0.3526 LossAtt 0.3236 TrainAcc 0.8900 TestAcc 0.8408 0.8350
epoch 500 LossPred 0.3932 LossAtt 0.3039 TrainAcc 0.8800 TestAcc 0.8519 0.8800
epoch 600 LossPred 0.3200 LossAtt 0.2914 TrainAcc 0.8900 TestAcc 0.8193 0.8500
epoch 700 LossPred 0.2643 LossAtt 0.2919 TrainAcc 0.9000 TestAcc 0.8466 0.8850
epoch 800 LossPred 0.2259 LossAtt 0.3027 TrainAcc 0.9100 TestAcc 0.8601 0.9000
epoch 900 LossPred 0.1976 LossAtt 0.3229 TrainAcc 0.9200 TestAcc 0.8851 0.9100
epoch 1000 LossPred 0.1514 LossAtt 0.3129 TrainAcc 0.9600 TestAcc 0.9007 0.9200
epoch 1100 LossPred 0.1239 LossAtt 0.3271 TrainAcc 0.9800 TestAcc 0.8964 0.9450
epoch 1200 LossPred 0.1101 LossAtt 0.3248 TrainAcc 0.9800 TestAcc 0.9107 0.9550
epoch 1300 LossPred 0.1173 LossAtt 0.3199 TrainAcc 0.9600 TestAcc 0.9127 0.9250
epoch 1400 LossPred 0.1033 LossAtt 0.3328 TrainAcc 0.9900 TestAcc 0.8916 0.9600
epoch 1500 LossPred 0.0859 LossAtt 0.3268 TrainAcc 0.9800 TestAcc 0.9057 0.9550
epoch 1600 LossPred 0.0781 LossAtt 0.3344 TrainAcc 0.9900 TestAcc 0.8999 0.9650
epoch 1700 LossPred 0.1107 LossAtt 0.3068 TrainAcc 0.9600 TestAcc 0.9092 0.9400
epoch 1800 LossPred 0.0668 LossAtt 0.3140 TrainAcc 0.9900 TestAcc 0.9049 0.9650
epoch 1900 LossPred 0.0638 LossAtt 0.3102 TrainAcc 1.0000 TestAcc 0.9094 0.9700
Optimization Finished!
********** replication  6  **********
epoch   0 LossPred 1.2509 LossAtt 1.0143 TrainAcc 0.4100 TestAcc 0.4097 0.5000
epoch 100 LossPred 0.9310 LossAtt 0.3337 TrainAcc 0.6100 TestAcc 0.5698 0.6250
epoch 200 LossPred 0.9114 LossAtt 0.3235 TrainAcc 0.6100 TestAcc 0.5753 0.6100
epoch 300 LossPred 0.4359 LossAtt 0.3304 TrainAcc 0.9000 TestAcc 0.8126 0.8600
epoch 400 LossPred 0.3361 LossAtt 0.2848 TrainAcc 0.9100 TestAcc 0.8136 0.8750
epoch 500 LossPred 0.3028 LossAtt 0.2733 TrainAcc 0.9200 TestAcc 0.8283 0.8800
epoch 600 LossPred 0.3527 LossAtt 0.2676 TrainAcc 0.9000 TestAcc 0.8081 0.8500
epoch 700 LossPred 0.2636 LossAtt 0.2664 TrainAcc 0.9200 TestAcc 0.8268 0.8750
epoch 800 LossPred 0.2579 LossAtt 0.2646 TrainAcc 0.9200 TestAcc 0.8276 0.8850
epoch 900 LossPred 0.2610 LossAtt 0.2435 TrainAcc 0.9100 TestAcc 0.8251 0.8750
epoch 1000 LossPred 0.2485 LossAtt 0.2563 TrainAcc 0.9200 TestAcc 0.8278 0.8900
epoch 1100 LossPred 0.2470 LossAtt 0.2594 TrainAcc 0.9200 TestAcc 0.8283 0.9000
epoch 1200 LossPred 0.2543 LossAtt 0.2398 TrainAcc 0.9100 TestAcc 0.8333 0.9100
epoch 1300 LossPred 0.2426 LossAtt 0.2325 TrainAcc 0.9200 TestAcc 0.8293 0.9000
epoch 1400 LossPred 0.2526 LossAtt 0.2451 TrainAcc 0.9100 TestAcc 0.8336 0.9150
epoch 1500 LossPred 0.2416 LossAtt 0.2358 TrainAcc 0.9000 TestAcc 0.8298 0.8850
epoch 1600 LossPred 0.2523 LossAtt 0.2190 TrainAcc 0.9000 TestAcc 0.8271 0.8900
epoch 1700 LossPred 0.2393 LossAtt 0.2301 TrainAcc 0.9200 TestAcc 0.8366 0.9200
epoch 1800 LossPred 0.2995 LossAtt 0.2257 TrainAcc 0.9100 TestAcc 0.8366 0.9150
epoch 1900 LossPred 0.2369 LossAtt 0.2219 TrainAcc 0.9100 TestAcc 0.8351 0.9100
epoch 2000 LossPred 0.2525 LossAtt 0.2117 TrainAcc 0.9200 TestAcc 0.8351 0.9200
epoch 2100 LossPred 0.2456 LossAtt 0.2039 TrainAcc 0.9200 TestAcc 0.8386 0.9200
epoch 2200 LossPred 0.2366 LossAtt 0.1995 TrainAcc 0.9200 TestAcc 0.8386 0.9100
epoch 2300 LossPred 0.2346 LossAtt 0.2049 TrainAcc 0.9200 TestAcc 0.8338 0.9050
epoch 2400 LossPred 0.3222 LossAtt 0.1937 TrainAcc 0.8900 TestAcc 0.8358 0.9000
epoch 2500 LossPred 0.2226 LossAtt 0.2009 TrainAcc 0.9300 TestAcc 0.8376 0.9100
Optimization Finished!
********** replication  7  **********
epoch   0 LossPred 1.0763 LossAtt 1.0240 TrainAcc 0.4800 TestAcc 0.5458 0.5150
epoch 100 LossPred 0.8986 LossAtt 0.4137 TrainAcc 0.6100 TestAcc 0.5175 0.6200
epoch 200 LossPred 0.8051 LossAtt 0.4088 TrainAcc 0.7100 TestAcc 0.5090 0.7100
epoch 300 LossPred 0.6853 LossAtt 0.4275 TrainAcc 0.7400 TestAcc 0.5400 0.7500
epoch 400 LossPred 0.3236 LossAtt 0.5219 TrainAcc 0.9100 TestAcc 0.7513 0.8900
epoch 500 LossPred 0.2598 LossAtt 0.4971 TrainAcc 0.9400 TestAcc 0.7935 0.9100
epoch 600 LossPred 0.2587 LossAtt 0.4835 TrainAcc 0.9200 TestAcc 0.8053 0.9150
epoch 700 LossPred 0.2057 LossAtt 0.4706 TrainAcc 0.9400 TestAcc 0.7935 0.9200
epoch 800 LossPred 0.1825 LossAtt 0.4642 TrainAcc 0.9400 TestAcc 0.7900 0.9200
epoch 900 LossPred 0.1893 LossAtt 0.4679 TrainAcc 0.9400 TestAcc 0.8003 0.9250
epoch 1000 LossPred 0.1697 LossAtt 0.4651 TrainAcc 0.9300 TestAcc 0.8021 0.9250
epoch 1100 LossPred 0.1525 LossAtt 0.4368 TrainAcc 0.9500 TestAcc 0.8006 0.9200
epoch 1200 LossPred 0.1383 LossAtt 0.4420 TrainAcc 0.9700 TestAcc 0.8043 0.9500
epoch 1300 LossPred 0.1262 LossAtt 0.4296 TrainAcc 0.9700 TestAcc 0.8021 0.9500
epoch 1400 LossPred 0.1193 LossAtt 0.4190 TrainAcc 0.9700 TestAcc 0.8031 0.9550
epoch 1500 LossPred 0.1137 LossAtt 0.4149 TrainAcc 0.9800 TestAcc 0.7960 0.9400
epoch 1600 LossPred 0.1101 LossAtt 0.4172 TrainAcc 0.9800 TestAcc 0.7998 0.9550
epoch 1700 LossPred 0.1140 LossAtt 0.4249 TrainAcc 0.9800 TestAcc 0.7885 0.9800
epoch 1800 LossPred 0.1058 LossAtt 0.4135 TrainAcc 0.9800 TestAcc 0.7910 0.9500
epoch 1900 LossPred 0.1027 LossAtt 0.4343 TrainAcc 0.9800 TestAcc 0.7885 0.9700
epoch 2000 LossPred 0.1039 LossAtt 0.4283 TrainAcc 0.9800 TestAcc 0.7908 0.9800
epoch 2100 LossPred 0.1034 LossAtt 0.4105 TrainAcc 0.9800 TestAcc 0.7905 0.9750
epoch 2200 LossPred 0.0999 LossAtt 0.4153 TrainAcc 0.9800 TestAcc 0.7833 0.9800
epoch 2300 LossPred 0.0964 LossAtt 0.4053 TrainAcc 0.9800 TestAcc 0.7785 0.9650
epoch 2400 LossPred 0.1037 LossAtt 0.4165 TrainAcc 0.9800 TestAcc 0.7913 0.9750
epoch 2500 LossPred 0.0951 LossAtt 0.4160 TrainAcc 0.9800 TestAcc 0.7870 0.9750
Optimization Finished!
********** replication  8  **********
epoch   0 LossPred 1.1830 LossAtt 1.0460 TrainAcc 0.4600 TestAcc 0.5135 0.4450
epoch 100 LossPred 0.8833 LossAtt 0.3724 TrainAcc 0.6600 TestAcc 0.5731 0.6600
epoch 200 LossPred 0.5148 LossAtt 0.4609 TrainAcc 0.8600 TestAcc 0.8589 0.8250
epoch 300 LossPred 0.3575 LossAtt 0.4132 TrainAcc 0.9000 TestAcc 0.8501 0.8450
epoch 400 LossPred 0.2204 LossAtt 0.3941 TrainAcc 0.9200 TestAcc 0.8824 0.8550
epoch 500 LossPred 0.2177 LossAtt 0.3902 TrainAcc 0.9400 TestAcc 0.8911 0.8850
epoch 600 LossPred 0.2274 LossAtt 0.3845 TrainAcc 0.9400 TestAcc 0.8976 0.8850
epoch 700 LossPred 0.1538 LossAtt 0.3728 TrainAcc 0.9500 TestAcc 0.8734 0.9000
epoch 800 LossPred 0.1438 LossAtt 0.3663 TrainAcc 0.9800 TestAcc 0.8779 0.9000
epoch 900 LossPred 0.2285 LossAtt 0.3660 TrainAcc 0.9300 TestAcc 0.8954 0.8850
epoch 1000 LossPred 0.1522 LossAtt 0.3529 TrainAcc 0.9600 TestAcc 0.8716 0.8950
epoch 1100 LossPred 0.1493 LossAtt 0.3714 TrainAcc 0.9600 TestAcc 0.9009 0.8900
epoch 1200 LossPred 0.1293 LossAtt 0.3695 TrainAcc 0.9700 TestAcc 0.8829 0.8950
epoch 1300 LossPred 0.1215 LossAtt 0.3700 TrainAcc 0.9600 TestAcc 0.8764 0.8750
epoch 1400 LossPred 0.0991 LossAtt 0.3738 TrainAcc 0.9900 TestAcc 0.9004 0.8950
epoch 1500 LossPred 0.1515 LossAtt 0.3828 TrainAcc 0.9500 TestAcc 0.8941 0.9000
epoch 1600 LossPred 0.1201 LossAtt 0.3864 TrainAcc 0.9600 TestAcc 0.8889 0.9100
epoch 1700 LossPred 0.0997 LossAtt 0.3753 TrainAcc 0.9900 TestAcc 0.8906 0.9000
epoch 1800 LossPred 0.1154 LossAtt 0.3900 TrainAcc 0.9800 TestAcc 0.9074 0.8950
epoch 1900 LossPred 0.0816 LossAtt 0.3833 TrainAcc 0.9800 TestAcc 0.8891 0.9050
epoch 2000 LossPred 0.0792 LossAtt 0.4173 TrainAcc 0.9800 TestAcc 0.8851 0.9150
epoch 2100 LossPred 0.0984 LossAtt 0.3967 TrainAcc 0.9700 TestAcc 0.8764 0.9050
epoch 2200 LossPred 0.0833 LossAtt 0.3900 TrainAcc 0.9800 TestAcc 0.8814 0.9100
epoch 2300 LossPred 0.0574 LossAtt 0.3896 TrainAcc 0.9900 TestAcc 0.8946 0.9250
epoch 2400 LossPred 0.0479 LossAtt 0.3893 TrainAcc 1.0000 TestAcc 0.9009 0.9250
Optimization Finished!
********** replication  9  **********
epoch   0 LossPred 1.2102 LossAtt 1.0433 TrainAcc 0.4000 TestAcc 0.4182 0.4050
epoch 100 LossPred 0.9479 LossAtt 0.3667 TrainAcc 0.6000 TestAcc 0.5818 0.6000
epoch 200 LossPred 0.9121 LossAtt 0.3645 TrainAcc 0.6000 TestAcc 0.5818 0.6000
epoch 300 LossPred 0.3750 LossAtt 0.4008 TrainAcc 0.9000 TestAcc 0.8624 0.8500
epoch 400 LossPred 0.2712 LossAtt 0.4045 TrainAcc 0.9400 TestAcc 0.8619 0.8650
epoch 500 LossPred 0.2591 LossAtt 0.3956 TrainAcc 0.9200 TestAcc 0.8601 0.8850
epoch 600 LossPred 0.2843 LossAtt 0.3719 TrainAcc 0.9100 TestAcc 0.8614 0.8650
epoch 700 LossPred 0.1912 LossAtt 0.3761 TrainAcc 0.9700 TestAcc 0.8989 0.9150
epoch 800 LossPred 0.1115 LossAtt 0.3565 TrainAcc 0.9900 TestAcc 0.8949 0.9200
epoch 900 LossPred 0.1386 LossAtt 0.3416 TrainAcc 0.9600 TestAcc 0.8819 0.9100
epoch 1000 LossPred 0.0576 LossAtt 0.3566 TrainAcc 0.9900 TestAcc 0.9014 0.9400
epoch 1100 LossPred 0.0475 LossAtt 0.3397 TrainAcc 1.0000 TestAcc 0.9014 0.9500
Optimization Finished!
********** replication  10  **********
epoch   0 LossPred 1.1029 LossAtt 1.0267 TrainAcc 0.4900 TestAcc 0.4707 0.4500
epoch 100 LossPred 0.8439 LossAtt 0.3311 TrainAcc 0.6600 TestAcc 0.6454 0.6500
epoch 200 LossPred 0.4139 LossAtt 0.3357 TrainAcc 0.8800 TestAcc 0.8353 0.8550
epoch 300 LossPred 0.4817 LossAtt 0.3213 TrainAcc 0.8200 TestAcc 0.7945 0.8000
epoch 400 LossPred 0.2123 LossAtt 0.3392 TrainAcc 0.9300 TestAcc 0.8779 0.8750
epoch 500 LossPred 0.1982 LossAtt 0.3361 TrainAcc 0.9300 TestAcc 0.8949 0.9000
epoch 600 LossPred 0.3625 LossAtt 0.3391 TrainAcc 0.8700 TestAcc 0.8148 0.8100
epoch 700 LossPred 0.1680 LossAtt 0.3456 TrainAcc 0.9400 TestAcc 0.8916 0.9100
epoch 800 LossPred 0.2113 LossAtt 0.3446 TrainAcc 0.9600 TestAcc 0.8991 0.9250
epoch 900 LossPred 0.3510 LossAtt 0.3533 TrainAcc 0.8800 TestAcc 0.8398 0.8850
epoch 1000 LossPred 0.1678 LossAtt 0.3632 TrainAcc 0.9600 TestAcc 0.9037 0.9300
epoch 1100 LossPred 0.1280 LossAtt 0.3661 TrainAcc 0.9700 TestAcc 0.8871 0.8850
epoch 1200 LossPred 0.1011 LossAtt 0.3455 TrainAcc 0.9900 TestAcc 0.9022 0.9100
epoch 1300 LossPred 0.0883 LossAtt 0.3531 TrainAcc 0.9900 TestAcc 0.9059 0.9200
epoch 1400 LossPred 0.0848 LossAtt 0.3529 TrainAcc 0.9900 TestAcc 0.9139 0.9300
epoch 1500 LossPred 0.1063 LossAtt 0.3326 TrainAcc 0.9700 TestAcc 0.8821 0.8900
epoch 1600 LossPred 0.0695 LossAtt 0.3396 TrainAcc 1.0000 TestAcc 0.9144 0.9300
Optimization Finished!
********** replication  11  **********
epoch   0 LossPred 1.0229 LossAtt 1.0195 TrainAcc 0.6000 TestAcc 0.5748 0.6000
epoch 100 LossPred 0.8797 LossAtt 0.2819 TrainAcc 0.6300 TestAcc 0.5988 0.6400
epoch 200 LossPred 0.7135 LossAtt 0.4003 TrainAcc 0.7200 TestAcc 0.7400 0.6950
epoch 300 LossPred 0.4560 LossAtt 0.3126 TrainAcc 0.8500 TestAcc 0.8361 0.8000
epoch 400 LossPred 0.3680 LossAtt 0.3049 TrainAcc 0.8700 TestAcc 0.8631 0.8450
epoch 500 LossPred 0.2407 LossAtt 0.3536 TrainAcc 0.9500 TestAcc 0.9234 0.8900
epoch 600 LossPred 0.1401 LossAtt 0.3593 TrainAcc 0.9500 TestAcc 0.9510 0.9600
epoch 700 LossPred 0.1167 LossAtt 0.3464 TrainAcc 0.9800 TestAcc 0.9409 0.9500
epoch 800 LossPred 0.1026 LossAtt 0.3323 TrainAcc 0.9800 TestAcc 0.9577 0.9600
epoch 900 LossPred 0.0983 LossAtt 0.3064 TrainAcc 0.9900 TestAcc 0.9647 0.9700
epoch 1000 LossPred 0.1487 LossAtt 0.3070 TrainAcc 0.9500 TestAcc 0.9535 0.9550
epoch 1100 LossPred 0.0934 LossAtt 0.2872 TrainAcc 0.9800 TestAcc 0.9635 0.9800
epoch 1200 LossPred 0.2876 LossAtt 0.2655 TrainAcc 0.9000 TestAcc 0.8986 0.9100
epoch 1300 LossPred 0.3085 LossAtt 0.2737 TrainAcc 0.8600 TestAcc 0.8899 0.8700
epoch 1400 LossPred 0.0676 LossAtt 0.2552 TrainAcc 0.9900 TestAcc 0.9737 0.9850
epoch 1500 LossPred 0.0761 LossAtt 0.2628 TrainAcc 0.9900 TestAcc 0.9707 0.9850
epoch 1600 LossPred 0.2174 LossAtt 0.2504 TrainAcc 0.9200 TestAcc 0.9084 0.9300
epoch 1700 LossPred 0.0625 LossAtt 0.2532 TrainAcc 0.9800 TestAcc 0.9750 0.9850
epoch 1800 LossPred 0.0672 LossAtt 0.2316 TrainAcc 0.9900 TestAcc 0.9660 0.9750
epoch 1900 LossPred 0.0782 LossAtt 0.2311 TrainAcc 0.9800 TestAcc 0.9632 0.9800
epoch 2000 LossPred 0.0610 LossAtt 0.2267 TrainAcc 0.9900 TestAcc 0.9675 0.9750
epoch 2100 LossPred 0.0627 LossAtt 0.2160 TrainAcc 0.9800 TestAcc 0.9720 0.9850
epoch 2200 LossPred 0.0939 LossAtt 0.2079 TrainAcc 0.9700 TestAcc 0.9597 0.9550
epoch 2300 LossPred 0.0521 LossAtt 0.2133 TrainAcc 0.9900 TestAcc 0.9692 0.9850
epoch 2400 LossPred 0.0371 LossAtt 0.2177 TrainAcc 0.9900 TestAcc 0.9772 0.9900
epoch 2500 LossPred 0.0383 LossAtt 0.2099 TrainAcc 0.9900 TestAcc 0.9792 0.9950
Optimization Finished!
********** replication  12  **********
epoch   0 LossPred 1.0014 LossAtt 1.0307 TrainAcc 0.5300 TestAcc 0.5103 0.5250
epoch 100 LossPred 0.8849 LossAtt 0.4227 TrainAcc 0.6000 TestAcc 0.6314 0.6050
epoch 200 LossPred 0.1979 LossAtt 0.3931 TrainAcc 0.9600 TestAcc 0.9107 0.9050
epoch 300 LossPred 0.1368 LossAtt 0.3771 TrainAcc 0.9700 TestAcc 0.9177 0.9200
epoch 400 LossPred 0.1375 LossAtt 0.3577 TrainAcc 0.9700 TestAcc 0.9029 0.9200
epoch 500 LossPred 0.1176 LossAtt 0.3554 TrainAcc 0.9700 TestAcc 0.9162 0.9200
epoch 600 LossPred 0.0940 LossAtt 0.3506 TrainAcc 0.9700 TestAcc 0.9347 0.9350
epoch 700 LossPred 0.1032 LossAtt 0.3610 TrainAcc 0.9600 TestAcc 0.9334 0.9400
epoch 800 LossPred 0.0877 LossAtt 0.3428 TrainAcc 0.9700 TestAcc 0.9334 0.9450
epoch 900 LossPred 0.0985 LossAtt 0.3321 TrainAcc 0.9800 TestAcc 0.9252 0.9200
epoch 1000 LossPred 0.0529 LossAtt 0.3356 TrainAcc 1.0000 TestAcc 0.9124 0.9550
Optimization Finished!
********** replication  13  **********
epoch   0 LossPred 1.0866 LossAtt 1.0325 TrainAcc 0.4700 TestAcc 0.4665 0.4850
epoch 100 LossPred 0.6541 LossAtt 0.3975 TrainAcc 0.7700 TestAcc 0.6777 0.7500
epoch 200 LossPred 0.3027 LossAtt 0.3338 TrainAcc 0.8900 TestAcc 0.8851 0.8850
epoch 300 LossPred 0.2282 LossAtt 0.3406 TrainAcc 0.9400 TestAcc 0.8869 0.8650
epoch 400 LossPred 0.1793 LossAtt 0.3181 TrainAcc 0.9600 TestAcc 0.8959 0.8550
epoch 500 LossPred 0.1548 LossAtt 0.3152 TrainAcc 0.9600 TestAcc 0.9079 0.8650
epoch 600 LossPred 0.1466 LossAtt 0.3238 TrainAcc 0.9500 TestAcc 0.8946 0.8750
epoch 700 LossPred 0.3085 LossAtt 0.3141 TrainAcc 0.8900 TestAcc 0.8539 0.8750
epoch 800 LossPred 0.1109 LossAtt 0.3263 TrainAcc 0.9600 TestAcc 0.9067 0.9200
epoch 900 LossPred 0.2079 LossAtt 0.3301 TrainAcc 0.9400 TestAcc 0.8641 0.8850
epoch 1000 LossPred 0.2547 LossAtt 0.3191 TrainAcc 0.8900 TestAcc 0.8824 0.9000
epoch 1100 LossPred 0.3023 LossAtt 0.3253 TrainAcc 0.8900 TestAcc 0.8586 0.8900
epoch 1200 LossPred 0.1153 LossAtt 0.3283 TrainAcc 0.9800 TestAcc 0.8939 0.9350
epoch 1300 LossPred 0.1356 LossAtt 0.3013 TrainAcc 0.9700 TestAcc 0.9069 0.9300
epoch 1400 LossPred 0.0816 LossAtt 0.3172 TrainAcc 0.9900 TestAcc 0.9037 0.9600
epoch 1500 LossPred 0.0767 LossAtt 0.3114 TrainAcc 0.9800 TestAcc 0.9007 0.9600
epoch 1600 LossPred 0.0822 LossAtt 0.2873 TrainAcc 0.9800 TestAcc 0.9102 0.9600
epoch 1700 LossPred 0.1162 LossAtt 0.2873 TrainAcc 0.9800 TestAcc 0.8914 0.9500
epoch 1800 LossPred 0.0633 LossAtt 0.2731 TrainAcc 0.9800 TestAcc 0.9129 0.9750
epoch 1900 LossPred 0.0549 LossAtt 0.2615 TrainAcc 0.9800 TestAcc 0.9147 0.9800
epoch 2000 LossPred 0.0502 LossAtt 0.2576 TrainAcc 1.0000 TestAcc 0.9182 0.9800
Optimization Finished!
********** replication  14  **********
epoch   0 LossPred 1.0275 LossAtt 1.0154 TrainAcc 0.5300 TestAcc 0.4967 0.5400
epoch 100 LossPred 0.8581 LossAtt 0.3033 TrainAcc 0.6000 TestAcc 0.5688 0.5950
epoch 200 LossPred 0.8463 LossAtt 0.2497 TrainAcc 0.6000 TestAcc 0.5688 0.6000
epoch 300 LossPred 0.8396 LossAtt 0.2379 TrainAcc 0.6000 TestAcc 0.5688 0.6150
epoch 400 LossPred 0.8328 LossAtt 0.2157 TrainAcc 0.6100 TestAcc 0.5300 0.6150
epoch 500 LossPred 0.8245 LossAtt 0.1955 TrainAcc 0.6200 TestAcc 0.5448 0.6200
epoch 600 LossPred 0.8130 LossAtt 0.2659 TrainAcc 0.6300 TestAcc 0.5606 0.6300
epoch 700 LossPred 0.7653 LossAtt 0.4472 TrainAcc 0.6800 TestAcc 0.5996 0.6850
epoch 800 LossPred 0.4542 LossAtt 0.5636 TrainAcc 0.8300 TestAcc 0.7065 0.8250
epoch 900 LossPred 0.3588 LossAtt 0.5289 TrainAcc 0.8900 TestAcc 0.7365 0.8300
epoch 1000 LossPred 0.4083 LossAtt 0.5354 TrainAcc 0.8700 TestAcc 0.7623 0.8450
epoch 1100 LossPred 0.1574 LossAtt 0.5599 TrainAcc 0.9600 TestAcc 0.7943 0.9000
epoch 1200 LossPred 0.0934 LossAtt 0.5199 TrainAcc 0.9900 TestAcc 0.8191 0.9200
epoch 1300 LossPred 0.0785 LossAtt 0.5336 TrainAcc 0.9900 TestAcc 0.8186 0.9350
epoch 1400 LossPred 0.0728 LossAtt 0.5254 TrainAcc 0.9900 TestAcc 0.8241 0.9350
epoch 1500 LossPred 0.0630 LossAtt 0.5135 TrainAcc 0.9900 TestAcc 0.8108 0.9200
epoch 1600 LossPred 0.0520 LossAtt 0.5183 TrainAcc 0.9900 TestAcc 0.8168 0.9200
epoch 1700 LossPred 0.0567 LossAtt 0.5286 TrainAcc 0.9900 TestAcc 0.8221 0.9300
epoch 1800 LossPred 0.0525 LossAtt 0.5135 TrainAcc 0.9900 TestAcc 0.8171 0.9250
epoch 1900 LossPred 0.0184 LossAtt 0.5369 TrainAcc 1.0000 TestAcc 0.8171 0.9250
Optimization Finished!
********** replication  15  **********
epoch   0 LossPred 1.1307 LossAtt 1.0282 TrainAcc 0.4900 TestAcc 0.5501 0.4550
epoch 100 LossPred 0.9513 LossAtt 0.2969 TrainAcc 0.5800 TestAcc 0.5871 0.5800
epoch 200 LossPred 0.8775 LossAtt 0.2874 TrainAcc 0.6900 TestAcc 0.6527 0.6550
epoch 300 LossPred 0.3275 LossAtt 0.3118 TrainAcc 0.9200 TestAcc 0.8338 0.9050
epoch 400 LossPred 0.3324 LossAtt 0.3025 TrainAcc 0.9000 TestAcc 0.8498 0.9050
epoch 500 LossPred 0.1833 LossAtt 0.2816 TrainAcc 0.9600 TestAcc 0.8539 0.9250
epoch 600 LossPred 0.1768 LossAtt 0.2771 TrainAcc 0.9600 TestAcc 0.8534 0.9400
epoch 700 LossPred 0.1798 LossAtt 0.2610 TrainAcc 0.9500 TestAcc 0.8546 0.9400
epoch 800 LossPred 0.1566 LossAtt 0.2758 TrainAcc 0.9600 TestAcc 0.8521 0.9300
epoch 900 LossPred 0.1390 LossAtt 0.2750 TrainAcc 0.9600 TestAcc 0.8524 0.9400
epoch 1000 LossPred 0.2860 LossAtt 0.2761 TrainAcc 0.9000 TestAcc 0.8356 0.9150
epoch 1100 LossPred 0.1629 LossAtt 0.2643 TrainAcc 0.9400 TestAcc 0.8406 0.9600
epoch 1200 LossPred 0.1132 LossAtt 0.2703 TrainAcc 0.9700 TestAcc 0.8496 0.9400
epoch 1300 LossPred 0.1118 LossAtt 0.2495 TrainAcc 0.9700 TestAcc 0.8441 0.9450
epoch 1400 LossPred 0.1379 LossAtt 0.2653 TrainAcc 0.9700 TestAcc 0.8451 0.9500
epoch 1500 LossPred 0.1088 LossAtt 0.2404 TrainAcc 0.9700 TestAcc 0.8413 0.9500
epoch 1600 LossPred 0.1109 LossAtt 0.2338 TrainAcc 0.9700 TestAcc 0.8438 0.9450
epoch 1700 LossPred 0.1308 LossAtt 0.2277 TrainAcc 0.9700 TestAcc 0.8491 0.9350
epoch 1800 LossPred 0.1237 LossAtt 0.2287 TrainAcc 0.9700 TestAcc 0.8426 0.9550
epoch 1900 LossPred 0.1206 LossAtt 0.2129 TrainAcc 0.9700 TestAcc 0.8478 0.9550
epoch 2000 LossPred 0.1124 LossAtt 0.2181 TrainAcc 0.9700 TestAcc 0.8491 0.9600
epoch 2100 LossPred 0.1102 LossAtt 0.2109 TrainAcc 0.9700 TestAcc 0.8438 0.9550
epoch 2200 LossPred 0.1409 LossAtt 0.2110 TrainAcc 0.9600 TestAcc 0.8481 0.9500
epoch 2300 LossPred 0.1213 LossAtt 0.2052 TrainAcc 0.9700 TestAcc 0.8483 0.9550
epoch 2400 LossPred 0.1212 LossAtt 0.2144 TrainAcc 0.9700 TestAcc 0.8501 0.9550
epoch 2500 LossPred 0.1188 LossAtt 0.2112 TrainAcc 0.9700 TestAcc 0.8493 0.9450
Optimization Finished!
********** replication  16  **********
epoch   0 LossPred 1.3277 LossAtt 0.9946 TrainAcc 0.4300 TestAcc 0.4114 0.4300
epoch 100 LossPred 0.9040 LossAtt 0.2861 TrainAcc 0.6400 TestAcc 0.5706 0.6400
epoch 200 LossPred 0.8936 LossAtt 0.2273 TrainAcc 0.6400 TestAcc 0.5706 0.6400
epoch 300 LossPred 0.8643 LossAtt 0.2640 TrainAcc 0.6700 TestAcc 0.5818 0.6650
epoch 400 LossPred 0.5432 LossAtt 0.3886 TrainAcc 0.8300 TestAcc 0.8301 0.8200
epoch 500 LossPred 0.3519 LossAtt 0.3669 TrainAcc 0.8800 TestAcc 0.8776 0.8850
epoch 600 LossPred 0.3259 LossAtt 0.3591 TrainAcc 0.8800 TestAcc 0.8781 0.8650
epoch 700 LossPred 0.2240 LossAtt 0.3212 TrainAcc 0.9400 TestAcc 0.8829 0.9050
epoch 800 LossPred 0.1642 LossAtt 0.3158 TrainAcc 0.9700 TestAcc 0.9054 0.9450
epoch 900 LossPred 0.1606 LossAtt 0.3029 TrainAcc 0.9500 TestAcc 0.8991 0.9550
epoch 1000 LossPred 0.1722 LossAtt 0.3256 TrainAcc 0.9300 TestAcc 0.9009 0.9300
epoch 1100 LossPred 0.1471 LossAtt 0.3006 TrainAcc 0.9500 TestAcc 0.9072 0.9550
epoch 1200 LossPred 0.1216 LossAtt 0.2874 TrainAcc 0.9700 TestAcc 0.9169 0.9500
epoch 1300 LossPred 0.1121 LossAtt 0.3058 TrainAcc 0.9700 TestAcc 0.9204 0.9500
epoch 1400 LossPred 0.1057 LossAtt 0.3042 TrainAcc 0.9800 TestAcc 0.9272 0.9500
epoch 1500 LossPred 0.1328 LossAtt 0.2990 TrainAcc 0.9800 TestAcc 0.9262 0.9400
epoch 1600 LossPred 0.1085 LossAtt 0.2916 TrainAcc 0.9600 TestAcc 0.9247 0.9600
epoch 1700 LossPred 0.0879 LossAtt 0.2945 TrainAcc 0.9800 TestAcc 0.9347 0.9500
epoch 1800 LossPred 0.1657 LossAtt 0.3031 TrainAcc 0.9300 TestAcc 0.9027 0.9550
epoch 1900 LossPred 0.1121 LossAtt 0.3074 TrainAcc 0.9500 TestAcc 0.9304 0.9650
epoch 2000 LossPred 0.3777 LossAtt 0.2903 TrainAcc 0.8900 TestAcc 0.8776 0.8400
epoch 2100 LossPred 0.0709 LossAtt 0.2894 TrainAcc 0.9800 TestAcc 0.9487 0.9500
epoch 2200 LossPred 0.1167 LossAtt 0.2759 TrainAcc 0.9800 TestAcc 0.9467 0.9600
epoch 2300 LossPred 0.0642 LossAtt 0.2895 TrainAcc 0.9800 TestAcc 0.9580 0.9600
epoch 2400 LossPred 0.0862 LossAtt 0.2777 TrainAcc 0.9800 TestAcc 0.9494 0.9600
epoch 2500 LossPred 0.1185 LossAtt 0.2683 TrainAcc 0.9700 TestAcc 0.9444 0.9450
Optimization Finished!
********** replication  17  **********
epoch   0 LossPred 1.0250 LossAtt 1.0309 TrainAcc 0.4600 TestAcc 0.5113 0.4700
epoch 100 LossPred 0.9129 LossAtt 0.3371 TrainAcc 0.6600 TestAcc 0.6379 0.6600
epoch 200 LossPred 0.8700 LossAtt 0.2816 TrainAcc 0.7100 TestAcc 0.6494 0.6550
epoch 300 LossPred 0.8289 LossAtt 0.2693 TrainAcc 0.7100 TestAcc 0.6512 0.7000
epoch 400 LossPred 0.6466 LossAtt 0.3284 TrainAcc 0.7600 TestAcc 0.8566 0.8100
epoch 500 LossPred 0.4670 LossAtt 0.3336 TrainAcc 0.8500 TestAcc 0.8276 0.7950
epoch 600 LossPred 0.2258 LossAtt 0.3367 TrainAcc 0.9500 TestAcc 0.8824 0.9000
epoch 700 LossPred 0.2088 LossAtt 0.3244 TrainAcc 0.9400 TestAcc 0.8734 0.8950
epoch 800 LossPred 0.2010 LossAtt 0.3263 TrainAcc 0.9600 TestAcc 0.8734 0.9000
epoch 900 LossPred 0.1633 LossAtt 0.3190 TrainAcc 0.9700 TestAcc 0.8726 0.8900
epoch 1000 LossPred 0.2630 LossAtt 0.3372 TrainAcc 0.9200 TestAcc 0.8676 0.8750
epoch 1100 LossPred 0.1448 LossAtt 0.3153 TrainAcc 0.9800 TestAcc 0.8826 0.9000
epoch 1200 LossPred 0.1565 LossAtt 0.2950 TrainAcc 0.9600 TestAcc 0.8724 0.8900
epoch 1300 LossPred 0.1445 LossAtt 0.3059 TrainAcc 0.9700 TestAcc 0.8786 0.9050
epoch 1400 LossPred 0.1213 LossAtt 0.3085 TrainAcc 0.9800 TestAcc 0.8766 0.9000
epoch 1500 LossPred 0.1679 LossAtt 0.2988 TrainAcc 0.9600 TestAcc 0.8831 0.8900
epoch 1600 LossPred 0.1848 LossAtt 0.3048 TrainAcc 0.9500 TestAcc 0.8824 0.9000
epoch 1700 LossPred 0.1938 LossAtt 0.3019 TrainAcc 0.9500 TestAcc 0.8719 0.8850
epoch 1800 LossPred 0.1295 LossAtt 0.3161 TrainAcc 0.9700 TestAcc 0.8789 0.9000
epoch 1900 LossPred 0.1286 LossAtt 0.3022 TrainAcc 0.9700 TestAcc 0.8819 0.9100
epoch 2000 LossPred 0.1302 LossAtt 0.2937 TrainAcc 0.9700 TestAcc 0.8821 0.9100
epoch 2100 LossPred 0.1072 LossAtt 0.2956 TrainAcc 0.9800 TestAcc 0.8829 0.9100
epoch 2200 LossPred 0.1534 LossAtt 0.2989 TrainAcc 0.9600 TestAcc 0.8729 0.8950
epoch 2300 LossPred 0.1759 LossAtt 0.2837 TrainAcc 0.9500 TestAcc 0.8721 0.8950
epoch 2400 LossPred 0.1249 LossAtt 0.2934 TrainAcc 0.9800 TestAcc 0.8789 0.9000
epoch 2500 LossPred 0.3641 LossAtt 0.2947 TrainAcc 0.8800 TestAcc 0.8506 0.8600
Optimization Finished!
********** replication  18  **********
epoch   0 LossPred 1.1346 LossAtt 1.0396 TrainAcc 0.4100 TestAcc 0.4552 0.4400
epoch 100 LossPred 0.8417 LossAtt 0.3721 TrainAcc 0.6400 TestAcc 0.6349 0.6350
epoch 200 LossPred 0.5009 LossAtt 0.3346 TrainAcc 0.8500 TestAcc 0.8403 0.8300
epoch 300 LossPred 0.4685 LossAtt 0.3134 TrainAcc 0.8500 TestAcc 0.8411 0.8250
epoch 400 LossPred 0.4297 LossAtt 0.3080 TrainAcc 0.8300 TestAcc 0.8473 0.8300
epoch 500 LossPred 0.3604 LossAtt 0.2946 TrainAcc 0.8800 TestAcc 0.8428 0.8400
epoch 600 LossPred 0.4740 LossAtt 0.3014 TrainAcc 0.8700 TestAcc 0.8181 0.8500
epoch 700 LossPred 0.4329 LossAtt 0.2972 TrainAcc 0.8400 TestAcc 0.8534 0.8400
epoch 800 LossPred 0.3104 LossAtt 0.3193 TrainAcc 0.9100 TestAcc 0.8446 0.8500
epoch 900 LossPred 0.4084 LossAtt 0.3282 TrainAcc 0.8500 TestAcc 0.7933 0.8200
epoch 1000 LossPred 0.2768 LossAtt 0.3307 TrainAcc 0.9200 TestAcc 0.8396 0.8750
epoch 1100 LossPred 0.2201 LossAtt 0.3447 TrainAcc 0.9400 TestAcc 0.8406 0.8900
epoch 1200 LossPred 0.2154 LossAtt 0.3458 TrainAcc 0.9400 TestAcc 0.8393 0.9150
epoch 1300 LossPred 0.2676 LossAtt 0.3551 TrainAcc 0.8900 TestAcc 0.8296 0.8800
epoch 1400 LossPred 0.1594 LossAtt 0.3422 TrainAcc 0.9700 TestAcc 0.8466 0.9300
epoch 1500 LossPred 0.1567 LossAtt 0.3470 TrainAcc 0.9500 TestAcc 0.8473 0.9250
epoch 1600 LossPred 0.1496 LossAtt 0.3364 TrainAcc 0.9600 TestAcc 0.8476 0.9150
epoch 1700 LossPred 0.1276 LossAtt 0.3456 TrainAcc 0.9800 TestAcc 0.8458 0.9250
epoch 1800 LossPred 0.1510 LossAtt 0.3376 TrainAcc 0.9600 TestAcc 0.8476 0.9050
epoch 1900 LossPred 0.1296 LossAtt 0.3407 TrainAcc 0.9800 TestAcc 0.8491 0.9200
epoch 2000 LossPred 0.1299 LossAtt 0.3301 TrainAcc 0.9700 TestAcc 0.8504 0.9000
epoch 2100 LossPred 0.1468 LossAtt 0.3194 TrainAcc 0.9600 TestAcc 0.8488 0.9200
epoch 2200 LossPred 0.1136 LossAtt 0.3265 TrainAcc 0.9800 TestAcc 0.8456 0.9350
epoch 2300 LossPred 0.1094 LossAtt 0.3265 TrainAcc 0.9700 TestAcc 0.8534 0.9200
epoch 2400 LossPred 0.1237 LossAtt 0.3205 TrainAcc 0.9600 TestAcc 0.8509 0.9150
epoch 2500 LossPred 0.2186 LossAtt 0.3252 TrainAcc 0.9000 TestAcc 0.8328 0.8900
Optimization Finished!
********** replication  19  **********
epoch   0 LossPred 1.1303 LossAtt 1.0301 TrainAcc 0.3800 TestAcc 0.4224 0.4150
epoch 100 LossPred 0.8166 LossAtt 0.4088 TrainAcc 0.7300 TestAcc 0.6326 0.7250
epoch 200 LossPred 0.3707 LossAtt 0.3551 TrainAcc 0.9100 TestAcc 0.8273 0.9100
epoch 300 LossPred 0.3586 LossAtt 0.3484 TrainAcc 0.8800 TestAcc 0.8516 0.8600
epoch 400 LossPred 0.2821 LossAtt 0.3493 TrainAcc 0.9200 TestAcc 0.8594 0.9100
epoch 500 LossPred 0.2133 LossAtt 0.3063 TrainAcc 0.9400 TestAcc 0.8719 0.9150
epoch 600 LossPred 0.1993 LossAtt 0.2759 TrainAcc 0.9400 TestAcc 0.8751 0.9200
epoch 700 LossPred 0.1790 LossAtt 0.2754 TrainAcc 0.9500 TestAcc 0.8879 0.9300
epoch 800 LossPred 0.1769 LossAtt 0.2560 TrainAcc 0.9500 TestAcc 0.8834 0.9400
epoch 900 LossPred 0.1763 LossAtt 0.2585 TrainAcc 0.9500 TestAcc 0.8874 0.9250
epoch 1000 LossPred 0.1625 LossAtt 0.2595 TrainAcc 0.9400 TestAcc 0.8921 0.9250
epoch 1100 LossPred 0.1785 LossAtt 0.2615 TrainAcc 0.9500 TestAcc 0.8796 0.9450
epoch 1200 LossPred 0.1485 LossAtt 0.2607 TrainAcc 0.9600 TestAcc 0.8949 0.9400
epoch 1300 LossPred 0.1500 LossAtt 0.2757 TrainAcc 0.9500 TestAcc 0.8874 0.9350
epoch 1400 LossPred 0.1438 LossAtt 0.2752 TrainAcc 0.9600 TestAcc 0.8944 0.9550
epoch 1500 LossPred 0.1336 LossAtt 0.2655 TrainAcc 0.9600 TestAcc 0.8974 0.9450
epoch 1600 LossPred 0.1453 LossAtt 0.2835 TrainAcc 0.9500 TestAcc 0.8756 0.9350
epoch 1700 LossPred 0.1197 LossAtt 0.2893 TrainAcc 0.9500 TestAcc 0.8949 0.9500
epoch 1800 LossPred 0.0733 LossAtt 0.2966 TrainAcc 0.9800 TestAcc 0.9217 0.9750
epoch 1900 LossPred 0.0793 LossAtt 0.3014 TrainAcc 0.9800 TestAcc 0.9329 0.9700
epoch 2000 LossPred 0.0686 LossAtt 0.2896 TrainAcc 0.9800 TestAcc 0.9259 0.9900
epoch 2100 LossPred 0.0623 LossAtt 0.2911 TrainAcc 0.9900 TestAcc 0.9189 0.9900
epoch 2200 LossPred 0.0961 LossAtt 0.2982 TrainAcc 0.9600 TestAcc 0.9234 0.9700
epoch 2300 LossPred 0.0580 LossAtt 0.3115 TrainAcc 0.9900 TestAcc 0.9442 0.9850
epoch 2400 LossPred 0.0421 LossAtt 0.2888 TrainAcc 0.9900 TestAcc 0.9434 1.0000
epoch 2500 LossPred 0.0528 LossAtt 0.2958 TrainAcc 0.9900 TestAcc 0.9249 0.9800
Optimization Finished!
********** replication  20  **********
epoch   0 LossPred 1.0527 LossAtt 1.0445 TrainAcc 0.5100 TestAcc 0.5403 0.4900
epoch 100 LossPred 0.7726 LossAtt 0.3802 TrainAcc 0.7400 TestAcc 0.6334 0.7400
epoch 200 LossPred 0.3460 LossAtt 0.3966 TrainAcc 0.9000 TestAcc 0.8591 0.8750
epoch 300 LossPred 0.2955 LossAtt 0.3877 TrainAcc 0.9000 TestAcc 0.8734 0.8900
epoch 400 LossPred 0.2708 LossAtt 0.3564 TrainAcc 0.9100 TestAcc 0.8776 0.9000
epoch 500 LossPred 0.2672 LossAtt 0.3631 TrainAcc 0.9100 TestAcc 0.8816 0.9050
epoch 600 LossPred 0.1857 LossAtt 0.3634 TrainAcc 0.9400 TestAcc 0.9292 0.9200
epoch 700 LossPred 0.1376 LossAtt 0.3504 TrainAcc 0.9600 TestAcc 0.9447 0.9300
epoch 800 LossPred 0.1055 LossAtt 0.3550 TrainAcc 0.9800 TestAcc 0.9510 0.9350
epoch 900 LossPred 0.0843 LossAtt 0.3466 TrainAcc 0.9900 TestAcc 0.9520 0.9300
epoch 1000 LossPred 0.1144 LossAtt 0.3563 TrainAcc 0.9700 TestAcc 0.9339 0.9450
epoch 1100 LossPred 0.0630 LossAtt 0.3586 TrainAcc 1.0000 TestAcc 0.9457 0.9400
Optimization Finished!
********** replication  21  **********
epoch   0 LossPred 1.0632 LossAtt 1.0281 TrainAcc 0.4900 TestAcc 0.4990 0.5150
epoch 100 LossPred 0.7710 LossAtt 0.3616 TrainAcc 0.7400 TestAcc 0.6544 0.7500
epoch 200 LossPred 0.2651 LossAtt 0.3647 TrainAcc 0.9300 TestAcc 0.8741 0.9200
epoch 300 LossPred 0.2037 LossAtt 0.3871 TrainAcc 0.9600 TestAcc 0.8759 0.9350
epoch 400 LossPred 0.1713 LossAtt 0.3924 TrainAcc 0.9800 TestAcc 0.8831 0.9250
epoch 500 LossPred 0.1811 LossAtt 0.3727 TrainAcc 0.9600 TestAcc 0.8636 0.9300
epoch 600 LossPred 0.1233 LossAtt 0.3526 TrainAcc 0.9800 TestAcc 0.8859 0.9400
epoch 700 LossPred 0.1720 LossAtt 0.3428 TrainAcc 0.9500 TestAcc 0.8654 0.9400
epoch 800 LossPred 0.1213 LossAtt 0.3421 TrainAcc 0.9700 TestAcc 0.8844 0.9350
epoch 900 LossPred 0.1394 LossAtt 0.3273 TrainAcc 0.9700 TestAcc 0.8724 0.9400
epoch 1000 LossPred 0.1098 LossAtt 0.3331 TrainAcc 0.9700 TestAcc 0.8871 0.9300
epoch 1100 LossPred 0.1042 LossAtt 0.3254 TrainAcc 0.9800 TestAcc 0.8811 0.9350
epoch 1200 LossPred 0.1064 LossAtt 0.3328 TrainAcc 0.9800 TestAcc 0.8759 0.9450
epoch 1300 LossPred 0.0948 LossAtt 0.3280 TrainAcc 0.9800 TestAcc 0.8839 0.9350
epoch 1400 LossPred 0.1028 LossAtt 0.3287 TrainAcc 0.9800 TestAcc 0.8736 0.9400
epoch 1500 LossPred 0.0945 LossAtt 0.3241 TrainAcc 0.9800 TestAcc 0.8771 0.9350
epoch 1600 LossPred 0.0924 LossAtt 0.3102 TrainAcc 0.9800 TestAcc 0.8766 0.9400
epoch 1700 LossPred 0.0942 LossAtt 0.3136 TrainAcc 0.9800 TestAcc 0.8751 0.9400
epoch 1800 LossPred 0.1344 LossAtt 0.3307 TrainAcc 0.9700 TestAcc 0.8649 0.9250
epoch 1900 LossPred 0.0891 LossAtt 0.3114 TrainAcc 0.9800 TestAcc 0.8731 0.9450
epoch 2000 LossPred 0.0897 LossAtt 0.3136 TrainAcc 0.9800 TestAcc 0.8784 0.9450
epoch 2100 LossPred 0.0884 LossAtt 0.3017 TrainAcc 0.9800 TestAcc 0.8696 0.9400
epoch 2200 LossPred 0.0881 LossAtt 0.2894 TrainAcc 0.9800 TestAcc 0.8671 0.9400
epoch 2300 LossPred 0.0866 LossAtt 0.3010 TrainAcc 0.9800 TestAcc 0.8714 0.9450
epoch 2400 LossPred 0.1017 LossAtt 0.2942 TrainAcc 0.9800 TestAcc 0.8691 0.9450
epoch 2500 LossPred 0.0880 LossAtt 0.2910 TrainAcc 0.9800 TestAcc 0.8619 0.9450
Optimization Finished!
********** replication  22  **********
epoch   0 LossPred 1.0697 LossAtt 1.0068 TrainAcc 0.5400 TestAcc 0.5258 0.5350
epoch 100 LossPred 0.9146 LossAtt 0.2849 TrainAcc 0.5800 TestAcc 0.5941 0.5800
epoch 200 LossPred 0.5492 LossAtt 0.3403 TrainAcc 0.8400 TestAcc 0.7715 0.8200
epoch 300 LossPred 0.6606 LossAtt 0.2709 TrainAcc 0.7200 TestAcc 0.7613 0.7100
epoch 400 LossPred 0.4086 LossAtt 0.2703 TrainAcc 0.8900 TestAcc 0.8383 0.8400
epoch 500 LossPred 0.7355 LossAtt 0.2663 TrainAcc 0.7200 TestAcc 0.7733 0.7200
epoch 600 LossPred 0.5091 LossAtt 0.2992 TrainAcc 0.8600 TestAcc 0.8488 0.8000
epoch 700 LossPred 0.4573 LossAtt 0.2649 TrainAcc 0.8400 TestAcc 0.7998 0.8050
epoch 800 LossPred 0.5514 LossAtt 0.2532 TrainAcc 0.8100 TestAcc 0.7518 0.7950
epoch 900 LossPred 0.3630 LossAtt 0.2469 TrainAcc 0.9200 TestAcc 0.8281 0.8450
epoch 1000 LossPred 0.4019 LossAtt 0.2515 TrainAcc 0.8500 TestAcc 0.8381 0.8350
epoch 1100 LossPred 0.4417 LossAtt 0.2541 TrainAcc 0.8600 TestAcc 0.8441 0.8150
epoch 1200 LossPred 0.3479 LossAtt 0.2348 TrainAcc 0.9000 TestAcc 0.8436 0.8450
epoch 1300 LossPred 0.3294 LossAtt 0.2265 TrainAcc 0.9200 TestAcc 0.8241 0.8450
epoch 1400 LossPred 0.3152 LossAtt 0.2233 TrainAcc 0.9200 TestAcc 0.8281 0.8450
epoch 1500 LossPred 0.3189 LossAtt 0.2394 TrainAcc 0.9000 TestAcc 0.8273 0.8500
epoch 1600 LossPred 0.3236 LossAtt 0.2525 TrainAcc 0.9000 TestAcc 0.8448 0.8550
epoch 1700 LossPred 0.3170 LossAtt 0.2876 TrainAcc 0.9200 TestAcc 0.8361 0.8550
epoch 1800 LossPred 0.3051 LossAtt 0.2962 TrainAcc 0.9300 TestAcc 0.8458 0.8550
epoch 1900 LossPred 0.3219 LossAtt 0.3032 TrainAcc 0.9000 TestAcc 0.8423 0.8550
epoch 2000 LossPred 0.3075 LossAtt 0.3090 TrainAcc 0.9200 TestAcc 0.8554 0.8550
epoch 2100 LossPred 0.3198 LossAtt 0.3073 TrainAcc 0.8900 TestAcc 0.8624 0.8450
epoch 2200 LossPred 0.3710 LossAtt 0.3131 TrainAcc 0.8900 TestAcc 0.8253 0.8550
epoch 2300 LossPred 0.2956 LossAtt 0.3280 TrainAcc 0.9100 TestAcc 0.8616 0.8400
epoch 2400 LossPred 0.2996 LossAtt 0.3413 TrainAcc 0.9200 TestAcc 0.8629 0.8600
epoch 2500 LossPred 0.2023 LossAtt 0.3400 TrainAcc 0.9200 TestAcc 0.8946 0.9050
Optimization Finished!
********** replication  23  **********
epoch   0 LossPred 1.0529 LossAtt 1.0294 TrainAcc 0.5100 TestAcc 0.5065 0.5150
epoch 100 LossPred 0.9410 LossAtt 0.3131 TrainAcc 0.5900 TestAcc 0.5906 0.5850
epoch 200 LossPred 0.6632 LossAtt 0.3434 TrainAcc 0.7300 TestAcc 0.8113 0.7450
epoch 300 LossPred 0.5190 LossAtt 0.3357 TrainAcc 0.8100 TestAcc 0.8163 0.7900
epoch 400 LossPred 0.3552 LossAtt 0.3527 TrainAcc 0.8800 TestAcc 0.8904 0.8550
epoch 500 LossPred 0.3141 LossAtt 0.3599 TrainAcc 0.8900 TestAcc 0.8951 0.8750
epoch 600 LossPred 0.3986 LossAtt 0.3417 TrainAcc 0.8800 TestAcc 0.8453 0.8200
epoch 700 LossPred 0.2729 LossAtt 0.3138 TrainAcc 0.9200 TestAcc 0.8791 0.8800
epoch 800 LossPred 0.2481 LossAtt 0.3108 TrainAcc 0.9200 TestAcc 0.8841 0.8800
epoch 900 LossPred 0.2528 LossAtt 0.3000 TrainAcc 0.9300 TestAcc 0.8999 0.9200
epoch 1000 LossPred 0.2450 LossAtt 0.2935 TrainAcc 0.9100 TestAcc 0.8831 0.8850
epoch 1100 LossPred 0.2066 LossAtt 0.2915 TrainAcc 0.9200 TestAcc 0.9082 0.9200
epoch 1200 LossPred 0.3026 LossAtt 0.2753 TrainAcc 0.8900 TestAcc 0.8696 0.8700
epoch 1300 LossPred 0.2462 LossAtt 0.2626 TrainAcc 0.9200 TestAcc 0.8839 0.9050
epoch 1400 LossPred 0.4299 LossAtt 0.2748 TrainAcc 0.8300 TestAcc 0.8456 0.8450
epoch 1500 LossPred 0.2567 LossAtt 0.2586 TrainAcc 0.9200 TestAcc 0.8936 0.9000
epoch 1600 LossPred 0.2039 LossAtt 0.2465 TrainAcc 0.9200 TestAcc 0.9044 0.9250
epoch 1700 LossPred 0.2290 LossAtt 0.2428 TrainAcc 0.9400 TestAcc 0.9069 0.9050
epoch 1800 LossPred 0.2031 LossAtt 0.2435 TrainAcc 0.9300 TestAcc 0.9054 0.9300
epoch 1900 LossPred 0.2488 LossAtt 0.2457 TrainAcc 0.9200 TestAcc 0.9049 0.8950
epoch 2000 LossPred 0.2080 LossAtt 0.2244 TrainAcc 0.9300 TestAcc 0.8946 0.9300
epoch 2100 LossPred 0.1946 LossAtt 0.2254 TrainAcc 0.9400 TestAcc 0.9097 0.9350
epoch 2200 LossPred 0.3158 LossAtt 0.2144 TrainAcc 0.8800 TestAcc 0.8889 0.8650
epoch 2300 LossPred 0.3707 LossAtt 0.2215 TrainAcc 0.8700 TestAcc 0.8539 0.8700
epoch 2400 LossPred 0.3052 LossAtt 0.2126 TrainAcc 0.9000 TestAcc 0.8634 0.9050
epoch 2500 LossPred 0.2883 LossAtt 0.2102 TrainAcc 0.9000 TestAcc 0.8711 0.9100
Optimization Finished!
********** replication  24  **********
epoch   0 LossPred 1.0518 LossAtt 1.0192 TrainAcc 0.4700 TestAcc 0.5043 0.4700
epoch 100 LossPred 0.9413 LossAtt 0.2362 TrainAcc 0.6100 TestAcc 0.5888 0.6100
epoch 200 LossPred 0.9401 LossAtt 0.1191 TrainAcc 0.6100 TestAcc 0.5888 0.6100
epoch 300 LossPred 0.9396 LossAtt 0.0983 TrainAcc 0.6100 TestAcc 0.5888 0.6100
epoch 400 LossPred 0.9391 LossAtt 0.1166 TrainAcc 0.6100 TestAcc 0.5888 0.6100
epoch 500 LossPred 0.9384 LossAtt 0.1113 TrainAcc 0.6100 TestAcc 0.5888 0.6100
epoch 600 LossPred 0.9025 LossAtt 0.3017 TrainAcc 0.5800 TestAcc 0.6759 0.5850
epoch 700 LossPred 0.3551 LossAtt 0.2984 TrainAcc 0.9100 TestAcc 0.8799 0.8950
epoch 800 LossPred 0.2759 LossAtt 0.3105 TrainAcc 0.9400 TestAcc 0.9232 0.9050
epoch 900 LossPred 0.2199 LossAtt 0.3251 TrainAcc 0.9400 TestAcc 0.9172 0.9000
epoch 1000 LossPred 0.1936 LossAtt 0.3166 TrainAcc 0.9400 TestAcc 0.9107 0.9250
epoch 1100 LossPred 0.2567 LossAtt 0.3150 TrainAcc 0.9100 TestAcc 0.9044 0.9050
epoch 1200 LossPred 0.1935 LossAtt 0.3163 TrainAcc 0.9400 TestAcc 0.9122 0.9300
epoch 1300 LossPred 0.3946 LossAtt 0.3362 TrainAcc 0.8500 TestAcc 0.8456 0.8850
epoch 1400 LossPred 0.2506 LossAtt 0.2988 TrainAcc 0.9000 TestAcc 0.8954 0.9100
epoch 1500 LossPred 0.1842 LossAtt 0.2839 TrainAcc 0.9500 TestAcc 0.9309 0.9200
epoch 1600 LossPred 0.1589 LossAtt 0.2857 TrainAcc 0.9600 TestAcc 0.9279 0.9400
epoch 1700 LossPred 0.2125 LossAtt 0.2723 TrainAcc 0.9200 TestAcc 0.8879 0.8950
epoch 1800 LossPred 0.1589 LossAtt 0.2724 TrainAcc 0.9500 TestAcc 0.9147 0.9350
epoch 1900 LossPred 0.1832 LossAtt 0.2762 TrainAcc 0.9500 TestAcc 0.9374 0.9250
epoch 2000 LossPred 0.1357 LossAtt 0.2508 TrainAcc 0.9600 TestAcc 0.9414 0.9400
epoch 2100 LossPred 0.1334 LossAtt 0.2689 TrainAcc 0.9500 TestAcc 0.9302 0.9400
epoch 2200 LossPred 0.1679 LossAtt 0.2537 TrainAcc 0.9400 TestAcc 0.9344 0.9300
epoch 2300 LossPred 0.2163 LossAtt 0.2421 TrainAcc 0.9100 TestAcc 0.8876 0.8950
epoch 2400 LossPred 0.1268 LossAtt 0.2327 TrainAcc 0.9700 TestAcc 0.9207 0.9350
epoch 2500 LossPred 0.1086 LossAtt 0.2391 TrainAcc 0.9700 TestAcc 0.9459 0.9500
Optimization Finished!
********** replication  25  **********
epoch   0 LossPred 0.9773 LossAtt 1.0343 TrainAcc 0.5600 TestAcc 0.4580 0.5800
epoch 100 LossPred 0.8955 LossAtt 0.2850 TrainAcc 0.6400 TestAcc 0.5786 0.6400
epoch 200 LossPred 0.8147 LossAtt 0.3416 TrainAcc 0.6900 TestAcc 0.6464 0.6900
epoch 300 LossPred 0.3872 LossAtt 0.3654 TrainAcc 0.8600 TestAcc 0.8313 0.8650
epoch 400 LossPred 0.4122 LossAtt 0.3199 TrainAcc 0.8400 TestAcc 0.8188 0.8300
epoch 500 LossPred 0.3807 LossAtt 0.2902 TrainAcc 0.8700 TestAcc 0.8276 0.8650
epoch 600 LossPred 0.4589 LossAtt 0.2946 TrainAcc 0.8400 TestAcc 0.8111 0.8300
epoch 700 LossPred 0.4294 LossAtt 0.2923 TrainAcc 0.8500 TestAcc 0.8206 0.8350
epoch 800 LossPred 0.3389 LossAtt 0.2688 TrainAcc 0.8700 TestAcc 0.8281 0.8550
epoch 900 LossPred 0.3704 LossAtt 0.2735 TrainAcc 0.8600 TestAcc 0.8198 0.8350
epoch 1000 LossPred 0.3380 LossAtt 0.2583 TrainAcc 0.8800 TestAcc 0.8318 0.8400
epoch 1100 LossPred 1.1860 LossAtt 0.2366 TrainAcc 0.6400 TestAcc 0.6136 0.6450
epoch 1200 LossPred 0.4031 LossAtt 0.2250 TrainAcc 0.8900 TestAcc 0.8231 0.8500
epoch 1300 LossPred 0.7952 LossAtt 0.2013 TrainAcc 0.6800 TestAcc 0.6151 0.6700
epoch 1400 LossPred 0.7046 LossAtt 0.2186 TrainAcc 0.7400 TestAcc 0.7450 0.7900
epoch 1500 LossPred 0.7334 LossAtt 0.1867 TrainAcc 0.7100 TestAcc 0.6014 0.6900
epoch 1600 LossPred 0.7058 LossAtt 0.1869 TrainAcc 0.7100 TestAcc 0.6006 0.7100
epoch 1700 LossPred 0.6870 LossAtt 0.1780 TrainAcc 0.7300 TestAcc 0.6547 0.7250
epoch 1800 LossPred 0.6642 LossAtt 0.1806 TrainAcc 0.7500 TestAcc 0.6634 0.7500
epoch 1900 LossPred 0.6715 LossAtt 0.1902 TrainAcc 0.7500 TestAcc 0.6867 0.7550
epoch 2000 LossPred 0.6887 LossAtt 0.1682 TrainAcc 0.7400 TestAcc 0.6862 0.7350
epoch 2100 LossPred 0.7204 LossAtt 0.1753 TrainAcc 0.7100 TestAcc 0.6894 0.7300
epoch 2200 LossPred 0.7177 LossAtt 0.1861 TrainAcc 0.7100 TestAcc 0.6869 0.7150
epoch 2300 LossPred 0.7119 LossAtt 0.1662 TrainAcc 0.6900 TestAcc 0.6827 0.6950
epoch 2400 LossPred 0.7066 LossAtt 0.1650 TrainAcc 0.7000 TestAcc 0.6882 0.7100
epoch 2500 LossPred 0.7016 LossAtt 0.1643 TrainAcc 0.7000 TestAcc 0.6904 0.7200
Optimization Finished!
********** replication  26  **********
epoch   0 LossPred 0.9481 LossAtt 1.0160 TrainAcc 0.5800 TestAcc 0.5521 0.5900
epoch 100 LossPred 0.8412 LossAtt 0.3805 TrainAcc 0.6600 TestAcc 0.5933 0.6650
epoch 200 LossPred 0.8212 LossAtt 0.3142 TrainAcc 0.6900 TestAcc 0.5803 0.6800
epoch 300 LossPred 0.7388 LossAtt 0.3493 TrainAcc 0.7300 TestAcc 0.6234 0.7300
epoch 400 LossPred 0.3732 LossAtt 0.3767 TrainAcc 0.9000 TestAcc 0.8293 0.8750
epoch 500 LossPred 0.3152 LossAtt 0.3536 TrainAcc 0.9100 TestAcc 0.8303 0.8950
epoch 600 LossPred 0.3320 LossAtt 0.3469 TrainAcc 0.9000 TestAcc 0.8213 0.8900
epoch 700 LossPred 0.2881 LossAtt 0.3423 TrainAcc 0.9100 TestAcc 0.8318 0.8950
epoch 800 LossPred 0.2778 LossAtt 0.3262 TrainAcc 0.9000 TestAcc 0.8263 0.8850
epoch 900 LossPred 0.2685 LossAtt 0.3331 TrainAcc 0.9100 TestAcc 0.8221 0.8850
epoch 1000 LossPred 0.2797 LossAtt 0.3199 TrainAcc 0.8900 TestAcc 0.8183 0.8800
epoch 1100 LossPred 0.3040 LossAtt 0.3311 TrainAcc 0.8900 TestAcc 0.8058 0.8700
epoch 1200 LossPred 0.2710 LossAtt 0.3389 TrainAcc 0.9100 TestAcc 0.8228 0.8950
epoch 1300 LossPred 0.2613 LossAtt 0.3298 TrainAcc 0.9100 TestAcc 0.8146 0.8950
epoch 1400 LossPred 0.2720 LossAtt 0.3377 TrainAcc 0.9100 TestAcc 0.8261 0.8900
epoch 1500 LossPred 0.2612 LossAtt 0.3382 TrainAcc 0.9100 TestAcc 0.8238 0.8850
epoch 1600 LossPred 0.4813 LossAtt 0.3475 TrainAcc 0.8500 TestAcc 0.7795 0.8450
epoch 1700 LossPred 0.3227 LossAtt 0.3390 TrainAcc 0.8900 TestAcc 0.8063 0.8750
epoch 1800 LossPred 0.2221 LossAtt 0.3345 TrainAcc 0.9300 TestAcc 0.8091 0.8700
epoch 1900 LossPred 0.2364 LossAtt 0.3342 TrainAcc 0.9200 TestAcc 0.8071 0.8700
epoch 2000 LossPred 0.2182 LossAtt 0.3536 TrainAcc 0.9300 TestAcc 0.8023 0.8750
epoch 2100 LossPred 0.2610 LossAtt 0.3541 TrainAcc 0.9200 TestAcc 0.8021 0.8800
epoch 2200 LossPred 0.2979 LossAtt 0.3327 TrainAcc 0.9200 TestAcc 0.8098 0.8900
epoch 2300 LossPred 0.2343 LossAtt 0.3563 TrainAcc 0.9200 TestAcc 0.8078 0.8900
epoch 2400 LossPred 0.2380 LossAtt 0.3363 TrainAcc 0.9300 TestAcc 0.8031 0.8950
epoch 2500 LossPred 0.2926 LossAtt 0.3338 TrainAcc 0.9100 TestAcc 0.8003 0.8900
Optimization Finished!
********** replication  27  **********
epoch   0 LossPred 1.1380 LossAtt 1.0175 TrainAcc 0.4300 TestAcc 0.4462 0.4450
epoch 100 LossPred 0.9361 LossAtt 0.2728 TrainAcc 0.6200 TestAcc 0.5473 0.6100
epoch 200 LossPred 0.9103 LossAtt 0.3008 TrainAcc 0.6100 TestAcc 0.4950 0.6150
epoch 300 LossPred 0.8785 LossAtt 0.3273 TrainAcc 0.6400 TestAcc 0.4960 0.6250
epoch 400 LossPred 0.8113 LossAtt 0.3521 TrainAcc 0.6700 TestAcc 0.5130 0.7000
epoch 500 LossPred 0.7680 LossAtt 0.3725 TrainAcc 0.7100 TestAcc 0.5448 0.7100
epoch 600 LossPred 0.7106 LossAtt 0.3868 TrainAcc 0.7500 TestAcc 0.5566 0.7650
epoch 700 LossPred 0.4045 LossAtt 0.4514 TrainAcc 0.8700 TestAcc 0.7830 0.8450
epoch 800 LossPred 0.3767 LossAtt 0.4566 TrainAcc 0.8800 TestAcc 0.8161 0.8100
epoch 900 LossPred 0.1478 LossAtt 0.4532 TrainAcc 0.9500 TestAcc 0.8321 0.8950
epoch 1000 LossPred 0.1229 LossAtt 0.4514 TrainAcc 0.9700 TestAcc 0.8291 0.9350
epoch 1100 LossPred 0.1103 LossAtt 0.4352 TrainAcc 0.9800 TestAcc 0.8076 0.9200
epoch 1200 LossPred 0.1201 LossAtt 0.4307 TrainAcc 0.9700 TestAcc 0.8243 0.9000
epoch 1300 LossPred 0.0967 LossAtt 0.4395 TrainAcc 0.9700 TestAcc 0.8261 0.9200
epoch 1400 LossPred 0.0785 LossAtt 0.4268 TrainAcc 0.9800 TestAcc 0.8263 0.9100
epoch 1500 LossPred 0.0871 LossAtt 0.4322 TrainAcc 0.9800 TestAcc 0.8146 0.9150
epoch 1600 LossPred 0.1028 LossAtt 0.4197 TrainAcc 0.9700 TestAcc 0.8348 0.8950
epoch 1700 LossPred 0.1067 LossAtt 0.4151 TrainAcc 0.9600 TestAcc 0.8176 0.9100
epoch 1800 LossPred 0.0617 LossAtt 0.4085 TrainAcc 0.9900 TestAcc 0.8248 0.9200
epoch 1900 LossPred 0.1365 LossAtt 0.4151 TrainAcc 0.9500 TestAcc 0.8238 0.8650
epoch 2000 LossPred 0.0864 LossAtt 0.4101 TrainAcc 0.9800 TestAcc 0.8176 0.9000
epoch 2100 LossPred 0.1100 LossAtt 0.4107 TrainAcc 0.9700 TestAcc 0.8118 0.9000
epoch 2200 LossPred 0.0533 LossAtt 0.4198 TrainAcc 0.9900 TestAcc 0.8161 0.9100
epoch 2300 LossPred 0.0520 LossAtt 0.4086 TrainAcc 0.9900 TestAcc 0.8168 0.9150
epoch 2400 LossPred 0.0602 LossAtt 0.4055 TrainAcc 0.9900 TestAcc 0.8136 0.8950
epoch 2500 LossPred 0.0677 LossAtt 0.4044 TrainAcc 0.9900 TestAcc 0.8228 0.9150
Optimization Finished!
********** replication  28  **********
epoch   0 LossPred 1.1919 LossAtt 1.0174 TrainAcc 0.3600 TestAcc 0.4259 0.4200
epoch 100 LossPred 0.7675 LossAtt 0.3886 TrainAcc 0.7000 TestAcc 0.5881 0.6950
epoch 200 LossPred 0.7048 LossAtt 0.3734 TrainAcc 0.7800 TestAcc 0.6379 0.7800
epoch 300 LossPred 0.6703 LossAtt 0.3878 TrainAcc 0.7800 TestAcc 0.6379 0.7800
epoch 400 LossPred 0.6425 LossAtt 0.4035 TrainAcc 0.7800 TestAcc 0.6379 0.7800
epoch 500 LossPred 0.6202 LossAtt 0.4135 TrainAcc 0.7800 TestAcc 0.6379 0.7800
epoch 600 LossPred 0.5872 LossAtt 0.4333 TrainAcc 0.8000 TestAcc 0.6316 0.7850
epoch 700 LossPred 0.5643 LossAtt 0.4824 TrainAcc 0.8200 TestAcc 0.6171 0.8100
epoch 800 LossPred 0.5216 LossAtt 0.4796 TrainAcc 0.8200 TestAcc 0.6146 0.8150
epoch 900 LossPred 0.4739 LossAtt 0.5253 TrainAcc 0.8400 TestAcc 0.6114 0.8200
epoch 1000 LossPred 0.4324 LossAtt 0.5151 TrainAcc 0.8600 TestAcc 0.6171 0.8250
epoch 1100 LossPred 0.3894 LossAtt 0.5207 TrainAcc 0.8600 TestAcc 0.6164 0.8300
epoch 1200 LossPred 0.3733 LossAtt 0.5242 TrainAcc 0.8700 TestAcc 0.6074 0.8400
epoch 1300 LossPred 0.3686 LossAtt 0.5164 TrainAcc 0.8900 TestAcc 0.5968 0.8600
epoch 1400 LossPred 0.3277 LossAtt 0.5213 TrainAcc 0.8900 TestAcc 0.5923 0.8650
epoch 1500 LossPred 0.3202 LossAtt 0.5195 TrainAcc 0.9000 TestAcc 0.6016 0.8450
epoch 1600 LossPred 0.3091 LossAtt 0.5428 TrainAcc 0.9100 TestAcc 0.5958 0.8350
epoch 1700 LossPred 0.2762 LossAtt 0.5241 TrainAcc 0.9300 TestAcc 0.5988 0.8500
epoch 1800 LossPred 0.2727 LossAtt 0.5030 TrainAcc 0.9300 TestAcc 0.6029 0.8350
epoch 1900 LossPred 0.2527 LossAtt 0.5197 TrainAcc 0.9400 TestAcc 0.6066 0.8500
epoch 2000 LossPred 0.2464 LossAtt 0.5108 TrainAcc 0.9400 TestAcc 0.6064 0.8600
epoch 2100 LossPred 0.2594 LossAtt 0.5238 TrainAcc 0.9300 TestAcc 0.6076 0.8400
epoch 2200 LossPred 0.2436 LossAtt 0.5029 TrainAcc 0.9400 TestAcc 0.6029 0.8500
epoch 2300 LossPred 0.2803 LossAtt 0.5158 TrainAcc 0.9200 TestAcc 0.6074 0.8500
epoch 2400 LossPred 0.2248 LossAtt 0.4747 TrainAcc 0.9500 TestAcc 0.6014 0.8450
epoch 2500 LossPred 0.2180 LossAtt 0.5026 TrainAcc 0.9500 TestAcc 0.6014 0.8300
Optimization Finished!
********** replication  29  **********
epoch   0 LossPred 1.0175 LossAtt 1.0502 TrainAcc 0.5000 TestAcc 0.4672 0.4950
epoch 100 LossPred 0.9354 LossAtt 0.2916 TrainAcc 0.6500 TestAcc 0.6276 0.6350
epoch 200 LossPred 0.3359 LossAtt 0.3097 TrainAcc 0.9200 TestAcc 0.8666 0.8750
epoch 300 LossPred 0.2871 LossAtt 0.3013 TrainAcc 0.9300 TestAcc 0.8616 0.8800
epoch 400 LossPred 0.2633 LossAtt 0.3286 TrainAcc 0.9400 TestAcc 0.8699 0.8900
epoch 500 LossPred 0.2476 LossAtt 0.3060 TrainAcc 0.9300 TestAcc 0.8849 0.8900
epoch 600 LossPred 0.2292 LossAtt 0.3011 TrainAcc 0.9300 TestAcc 0.8596 0.9150
epoch 700 LossPred 0.3233 LossAtt 0.2853 TrainAcc 0.9100 TestAcc 0.8171 0.8950
epoch 800 LossPred 0.1768 LossAtt 0.2748 TrainAcc 0.9500 TestAcc 0.9134 0.8850
epoch 900 LossPred 0.3699 LossAtt 0.2958 TrainAcc 0.8700 TestAcc 0.8498 0.8150
epoch 1000 LossPred 0.2607 LossAtt 0.2738 TrainAcc 0.9300 TestAcc 0.8303 0.9100
epoch 1100 LossPred 0.4821 LossAtt 0.2950 TrainAcc 0.8400 TestAcc 0.8403 0.8050
epoch 1200 LossPred 0.2742 LossAtt 0.2671 TrainAcc 0.9200 TestAcc 0.8418 0.9000
epoch 1300 LossPred 0.4212 LossAtt 0.2901 TrainAcc 0.8600 TestAcc 0.8493 0.8250
epoch 1400 LossPred 0.2492 LossAtt 0.2613 TrainAcc 0.9200 TestAcc 0.8398 0.9000
epoch 1500 LossPred 0.1970 LossAtt 0.2707 TrainAcc 0.9500 TestAcc 0.8784 0.9450
epoch 1600 LossPred 0.2372 LossAtt 0.2591 TrainAcc 0.9300 TestAcc 0.8411 0.9050
epoch 1700 LossPred 0.2215 LossAtt 0.2420 TrainAcc 0.9400 TestAcc 0.8501 0.9200
epoch 1800 LossPred 0.2977 LossAtt 0.2764 TrainAcc 0.8900 TestAcc 0.8876 0.8800
epoch 1900 LossPred 0.2328 LossAtt 0.2563 TrainAcc 0.9300 TestAcc 0.8391 0.9250
epoch 2000 LossPred 0.1912 LossAtt 0.2548 TrainAcc 0.9500 TestAcc 0.8871 0.9500
epoch 2100 LossPred 0.2010 LossAtt 0.2618 TrainAcc 0.9500 TestAcc 0.8959 0.9400
epoch 2200 LossPred 0.1997 LossAtt 0.2604 TrainAcc 0.9400 TestAcc 0.8699 0.9450
epoch 2300 LossPred 0.1759 LossAtt 0.2317 TrainAcc 0.9400 TestAcc 0.9012 0.9400
epoch 2400 LossPred 0.3144 LossAtt 0.2415 TrainAcc 0.9000 TestAcc 0.8741 0.8800
epoch 2500 LossPred 0.3996 LossAtt 0.2397 TrainAcc 0.8600 TestAcc 0.7845 0.8450
Optimization Finished!
********** replication  30  **********
epoch   0 LossPred 0.9882 LossAtt 1.0443 TrainAcc 0.5200 TestAcc 0.4119 0.5350
epoch 100 LossPred 0.7579 LossAtt 0.3081 TrainAcc 0.7200 TestAcc 0.5863 0.7200
epoch 200 LossPred 0.7497 LossAtt 0.2674 TrainAcc 0.7200 TestAcc 0.5863 0.7300
epoch 300 LossPred 0.7271 LossAtt 0.2989 TrainAcc 0.7500 TestAcc 0.5826 0.7500
epoch 400 LossPred 0.4578 LossAtt 0.3461 TrainAcc 0.8500 TestAcc 0.7482 0.8500
epoch 500 LossPred 0.2325 LossAtt 0.3546 TrainAcc 0.9500 TestAcc 0.8794 0.9350
epoch 600 LossPred 0.2681 LossAtt 0.3696 TrainAcc 0.9000 TestAcc 0.8559 0.8800
epoch 700 LossPred 0.1923 LossAtt 0.3684 TrainAcc 0.9500 TestAcc 0.8764 0.9300
epoch 800 LossPred 0.1567 LossAtt 0.3746 TrainAcc 0.9600 TestAcc 0.8774 0.9400
epoch 900 LossPred 0.1336 LossAtt 0.3622 TrainAcc 0.9600 TestAcc 0.8729 0.9450
epoch 1000 LossPred 0.1167 LossAtt 0.3939 TrainAcc 0.9800 TestAcc 0.8731 0.9400
epoch 1100 LossPred 0.1058 LossAtt 0.3966 TrainAcc 0.9700 TestAcc 0.8821 0.9400
epoch 1200 LossPred 0.0979 LossAtt 0.3912 TrainAcc 0.9700 TestAcc 0.8826 0.9500
epoch 1300 LossPred 0.0876 LossAtt 0.3976 TrainAcc 0.9700 TestAcc 0.8879 0.9500
epoch 1400 LossPred 0.0917 LossAtt 0.3833 TrainAcc 0.9700 TestAcc 0.8889 0.9500
epoch 1500 LossPred 0.0715 LossAtt 0.3875 TrainAcc 0.9700 TestAcc 0.8764 0.9300
epoch 1600 LossPred 0.0927 LossAtt 0.3886 TrainAcc 0.9800 TestAcc 0.8709 0.9100
epoch 1700 LossPred 0.0637 LossAtt 0.3891 TrainAcc 0.9800 TestAcc 0.8766 0.9400
epoch 1800 LossPred 0.0573 LossAtt 0.3744 TrainAcc 0.9900 TestAcc 0.8836 0.9550
epoch 1900 LossPred 0.0393 LossAtt 0.3892 TrainAcc 0.9900 TestAcc 0.8954 0.9600
epoch 2000 LossPred 0.0376 LossAtt 0.3775 TrainAcc 0.9900 TestAcc 0.8929 0.9600
epoch 2100 LossPred 0.0393 LossAtt 0.3799 TrainAcc 0.9900 TestAcc 0.8999 0.9600
epoch 2200 LossPred 0.0749 LossAtt 0.3667 TrainAcc 0.9700 TestAcc 0.8989 0.9650
epoch 2300 LossPred 0.0265 LossAtt 0.3773 TrainAcc 0.9900 TestAcc 0.8836 0.9550
epoch 2400 LossPred 0.0195 LossAtt 0.3682 TrainAcc 1.0000 TestAcc 0.8874 0.9750
Optimization Finished!
********** replication  31  **********
epoch   0 LossPred 1.1343 LossAtt 1.0143 TrainAcc 0.4800 TestAcc 0.4162 0.4800
epoch 100 LossPred 0.9213 LossAtt 0.3887 TrainAcc 0.6400 TestAcc 0.5526 0.6550
epoch 200 LossPred 0.7597 LossAtt 0.4448 TrainAcc 0.7000 TestAcc 0.5325 0.7050
epoch 300 LossPred 0.6836 LossAtt 0.4795 TrainAcc 0.7300 TestAcc 0.5248 0.7050
epoch 400 LossPred 0.6494 LossAtt 0.4533 TrainAcc 0.7600 TestAcc 0.5185 0.7050
epoch 500 LossPred 0.6102 LossAtt 0.4608 TrainAcc 0.8000 TestAcc 0.5215 0.7000
epoch 600 LossPred 0.5965 LossAtt 0.4530 TrainAcc 0.8000 TestAcc 0.5250 0.7100
epoch 700 LossPred 0.5850 LossAtt 0.4470 TrainAcc 0.8100 TestAcc 0.5230 0.7150
epoch 800 LossPred 0.5727 LossAtt 0.4328 TrainAcc 0.8100 TestAcc 0.5245 0.7150
epoch 900 LossPred 0.5741 LossAtt 0.4371 TrainAcc 0.8000 TestAcc 0.5245 0.7150
epoch 1000 LossPred 0.5441 LossAtt 0.4278 TrainAcc 0.8200 TestAcc 0.5210 0.7150
epoch 1100 LossPred 0.5402 LossAtt 0.4177 TrainAcc 0.8200 TestAcc 0.5190 0.7250
epoch 1200 LossPred 0.5296 LossAtt 0.4115 TrainAcc 0.8100 TestAcc 0.5163 0.7300
epoch 1300 LossPred 0.5331 LossAtt 0.4174 TrainAcc 0.8100 TestAcc 0.5203 0.7550
epoch 1400 LossPred 0.5315 LossAtt 0.4259 TrainAcc 0.8300 TestAcc 0.5240 0.7500
epoch 1500 LossPred 0.5507 LossAtt 0.4131 TrainAcc 0.8000 TestAcc 0.5183 0.7400
epoch 1600 LossPred 0.5051 LossAtt 0.4314 TrainAcc 0.8300 TestAcc 0.5283 0.7550
epoch 1700 LossPred 0.5024 LossAtt 0.4152 TrainAcc 0.8400 TestAcc 0.5280 0.7600
epoch 1800 LossPred 0.5248 LossAtt 0.4044 TrainAcc 0.8200 TestAcc 0.5245 0.7550
epoch 1900 LossPred 0.5165 LossAtt 0.4207 TrainAcc 0.8300 TestAcc 0.5315 0.7550
epoch 2000 LossPred 0.5019 LossAtt 0.4085 TrainAcc 0.8400 TestAcc 0.5363 0.7450
epoch 2100 LossPred 0.4853 LossAtt 0.4016 TrainAcc 0.8400 TestAcc 0.5335 0.7600
epoch 2200 LossPred 0.4814 LossAtt 0.3942 TrainAcc 0.8400 TestAcc 0.5348 0.7650
epoch 2300 LossPred 0.4730 LossAtt 0.4200 TrainAcc 0.8500 TestAcc 0.5375 0.7500
epoch 2400 LossPred 0.5233 LossAtt 0.4149 TrainAcc 0.8100 TestAcc 0.5323 0.7650
epoch 2500 LossPred 0.4817 LossAtt 0.4161 TrainAcc 0.8300 TestAcc 0.5390 0.7500
Optimization Finished!
********** replication  32  **********
epoch   0 LossPred 0.9954 LossAtt 1.0011 TrainAcc 0.5500 TestAcc 0.4827 0.5450
epoch 100 LossPred 0.8884 LossAtt 0.3774 TrainAcc 0.6500 TestAcc 0.5863 0.6500
epoch 200 LossPred 0.7747 LossAtt 0.3381 TrainAcc 0.7000 TestAcc 0.6379 0.6950
epoch 300 LossPred 0.3657 LossAtt 0.3994 TrainAcc 0.8600 TestAcc 0.8113 0.8400
epoch 400 LossPred 0.3309 LossAtt 0.3681 TrainAcc 0.8800 TestAcc 0.8001 0.8400
epoch 500 LossPred 0.3195 LossAtt 0.3532 TrainAcc 0.8800 TestAcc 0.7970 0.8600
epoch 600 LossPred 0.2939 LossAtt 0.3584 TrainAcc 0.8900 TestAcc 0.8106 0.8650
epoch 700 LossPred 0.2762 LossAtt 0.3764 TrainAcc 0.8900 TestAcc 0.8181 0.8600
epoch 800 LossPred 0.2605 LossAtt 0.3731 TrainAcc 0.8900 TestAcc 0.8261 0.8500
epoch 900 LossPred 0.2515 LossAtt 0.3720 TrainAcc 0.9000 TestAcc 0.8298 0.8650
epoch 1000 LossPred 0.2602 LossAtt 0.3699 TrainAcc 0.9100 TestAcc 0.8551 0.8700
epoch 1100 LossPred 0.2287 LossAtt 0.3448 TrainAcc 0.9200 TestAcc 0.8619 0.8800
epoch 1200 LossPred 0.2452 LossAtt 0.3452 TrainAcc 0.9200 TestAcc 0.8526 0.8850
epoch 1300 LossPred 0.1966 LossAtt 0.3521 TrainAcc 0.9400 TestAcc 0.8616 0.9000
epoch 1400 LossPred 0.3099 LossAtt 0.3608 TrainAcc 0.8900 TestAcc 0.8511 0.8400
epoch 1500 LossPred 0.1639 LossAtt 0.3814 TrainAcc 0.9600 TestAcc 0.8704 0.9150
epoch 1600 LossPred 0.1797 LossAtt 0.3662 TrainAcc 0.9300 TestAcc 0.8779 0.9000
epoch 1700 LossPred 0.1306 LossAtt 0.4164 TrainAcc 0.9600 TestAcc 0.8834 0.9200
epoch 1800 LossPred 0.1053 LossAtt 0.4005 TrainAcc 0.9600 TestAcc 0.8946 0.9300
epoch 1900 LossPred 0.0932 LossAtt 0.4093 TrainAcc 0.9600 TestAcc 0.8879 0.9200
epoch 2000 LossPred 0.0746 LossAtt 0.4229 TrainAcc 0.9800 TestAcc 0.8939 0.9350
epoch 2100 LossPred 0.0666 LossAtt 0.4225 TrainAcc 0.9800 TestAcc 0.8936 0.9450
epoch 2200 LossPred 0.0664 LossAtt 0.4258 TrainAcc 0.9800 TestAcc 0.9002 0.9450
epoch 2300 LossPred 0.0653 LossAtt 0.4111 TrainAcc 0.9800 TestAcc 0.8881 0.9450
epoch 2400 LossPred 0.0581 LossAtt 0.4110 TrainAcc 0.9800 TestAcc 0.8846 0.9450
epoch 2500 LossPred 0.0589 LossAtt 0.4336 TrainAcc 0.9800 TestAcc 0.8876 0.9550
Optimization Finished!
********** replication  33  **********
epoch   0 LossPred 1.0228 LossAtt 1.0370 TrainAcc 0.4600 TestAcc 0.5015 0.4650
epoch 100 LossPred 0.8362 LossAtt 0.4383 TrainAcc 0.6800 TestAcc 0.6044 0.6750
epoch 200 LossPred 0.3361 LossAtt 0.4215 TrainAcc 0.9000 TestAcc 0.8478 0.8500
epoch 300 LossPred 0.3584 LossAtt 0.4402 TrainAcc 0.8700 TestAcc 0.8141 0.8450
epoch 400 LossPred 0.2739 LossAtt 0.4356 TrainAcc 0.9300 TestAcc 0.8358 0.8550
epoch 500 LossPred 0.2625 LossAtt 0.4275 TrainAcc 0.9300 TestAcc 0.8448 0.8500
epoch 600 LossPred 0.2185 LossAtt 0.4352 TrainAcc 0.9200 TestAcc 0.8516 0.8900
epoch 700 LossPred 0.3846 LossAtt 0.4399 TrainAcc 0.8600 TestAcc 0.8501 0.8300
epoch 800 LossPred 0.2239 LossAtt 0.4277 TrainAcc 0.9300 TestAcc 0.8569 0.8900
epoch 900 LossPred 0.1648 LossAtt 0.4172 TrainAcc 0.9500 TestAcc 0.8541 0.8950
epoch 1000 LossPred 0.1666 LossAtt 0.3984 TrainAcc 0.9700 TestAcc 0.8326 0.9100
epoch 1100 LossPred 0.1705 LossAtt 0.3858 TrainAcc 0.9400 TestAcc 0.8701 0.9000
epoch 1200 LossPred 0.2007 LossAtt 0.3745 TrainAcc 0.9300 TestAcc 0.8709 0.8950
epoch 1300 LossPred 0.2207 LossAtt 0.3535 TrainAcc 0.9200 TestAcc 0.8248 0.9150
epoch 1400 LossPred 0.1184 LossAtt 0.3508 TrainAcc 0.9700 TestAcc 0.8496 0.9250
epoch 1500 LossPred 0.1100 LossAtt 0.3380 TrainAcc 0.9900 TestAcc 0.8584 0.9250
epoch 1600 LossPred 0.0932 LossAtt 0.3255 TrainAcc 0.9800 TestAcc 0.8714 0.9450
epoch 1700 LossPred 0.1522 LossAtt 0.3161 TrainAcc 0.9500 TestAcc 0.8441 0.9200
epoch 1800 LossPred 0.0768 LossAtt 0.3066 TrainAcc 0.9800 TestAcc 0.8751 0.9500
epoch 1900 LossPred 0.0613 LossAtt 0.3119 TrainAcc 0.9900 TestAcc 0.8859 0.9550
epoch 2000 LossPred 0.2397 LossAtt 0.3232 TrainAcc 0.9300 TestAcc 0.8741 0.9000
epoch 2100 LossPred 0.0420 LossAtt 0.3158 TrainAcc 1.0000 TestAcc 0.8884 0.9800
Optimization Finished!
********** replication  34  **********
epoch   0 LossPred 1.2169 LossAtt 1.0492 TrainAcc 0.4200 TestAcc 0.4687 0.4400
epoch 100 LossPred 0.9077 LossAtt 0.3124 TrainAcc 0.6500 TestAcc 0.6054 0.6500
epoch 200 LossPred 0.7355 LossAtt 0.3423 TrainAcc 0.6500 TestAcc 0.6054 0.6500
epoch 300 LossPred 0.7311 LossAtt 0.3040 TrainAcc 0.7200 TestAcc 0.7012 0.7400
epoch 400 LossPred 0.3815 LossAtt 0.2537 TrainAcc 0.9000 TestAcc 0.8288 0.8100
epoch 500 LossPred 0.3035 LossAtt 0.2544 TrainAcc 0.9100 TestAcc 0.8458 0.8500
epoch 600 LossPred 0.2865 LossAtt 0.2455 TrainAcc 0.9100 TestAcc 0.8441 0.8600
epoch 700 LossPred 0.2760 LossAtt 0.2646 TrainAcc 0.9100 TestAcc 0.8481 0.8650
epoch 800 LossPred 0.3628 LossAtt 0.2558 TrainAcc 0.8900 TestAcc 0.8418 0.8300
epoch 900 LossPred 0.2320 LossAtt 0.2617 TrainAcc 0.9400 TestAcc 0.8498 0.8750
epoch 1000 LossPred 0.2481 LossAtt 0.2599 TrainAcc 0.9200 TestAcc 0.8576 0.8750
epoch 1100 LossPred 0.3559 LossAtt 0.2633 TrainAcc 0.8700 TestAcc 0.8493 0.8500
epoch 1200 LossPred 0.2198 LossAtt 0.2497 TrainAcc 0.9500 TestAcc 0.8511 0.8800
epoch 1300 LossPred 0.3807 LossAtt 0.2566 TrainAcc 0.8500 TestAcc 0.8288 0.8500
epoch 1400 LossPred 0.2475 LossAtt 0.2416 TrainAcc 0.9300 TestAcc 0.8606 0.8900
epoch 1500 LossPred 0.2323 LossAtt 0.2417 TrainAcc 0.9400 TestAcc 0.8606 0.8800
epoch 1600 LossPred 0.2246 LossAtt 0.2416 TrainAcc 0.9300 TestAcc 0.8591 0.8650
epoch 1700 LossPred 0.2589 LossAtt 0.2355 TrainAcc 0.9000 TestAcc 0.8581 0.8750
epoch 1800 LossPred 0.2216 LossAtt 0.2309 TrainAcc 0.9300 TestAcc 0.8611 0.8700
epoch 1900 LossPred 0.3256 LossAtt 0.2196 TrainAcc 0.9100 TestAcc 0.8313 0.8800
epoch 2000 LossPred 0.2475 LossAtt 0.2186 TrainAcc 0.9400 TestAcc 0.8393 0.8950
epoch 2100 LossPred 0.2553 LossAtt 0.2265 TrainAcc 0.9000 TestAcc 0.8556 0.8800
epoch 2200 LossPred 0.1921 LossAtt 0.2311 TrainAcc 0.9300 TestAcc 0.8669 0.8850
epoch 2300 LossPred 0.2040 LossAtt 0.2302 TrainAcc 0.9200 TestAcc 0.8604 0.9000
epoch 2400 LossPred 0.1818 LossAtt 0.2188 TrainAcc 0.9500 TestAcc 0.8609 0.9000
epoch 2500 LossPred 0.2373 LossAtt 0.2186 TrainAcc 0.9400 TestAcc 0.8426 0.8950
Optimization Finished!
********** replication  35  **********
epoch   0 LossPred 1.2076 LossAtt 1.0286 TrainAcc 0.3800 TestAcc 0.4940 0.4250
epoch 100 LossPred 0.8843 LossAtt 0.3415 TrainAcc 0.6600 TestAcc 0.5898 0.6650
epoch 200 LossPred 0.8679 LossAtt 0.2717 TrainAcc 0.6600 TestAcc 0.5898 0.6600
epoch 300 LossPred 0.8470 LossAtt 0.2414 TrainAcc 0.6800 TestAcc 0.5541 0.6800
epoch 400 LossPred 0.7998 LossAtt 0.2976 TrainAcc 0.6800 TestAcc 0.5611 0.6800
epoch 500 LossPred 0.3783 LossAtt 0.3897 TrainAcc 0.8800 TestAcc 0.8071 0.8350
epoch 600 LossPred 0.2863 LossAtt 0.3921 TrainAcc 0.8900 TestAcc 0.8536 0.8750
epoch 700 LossPred 0.2445 LossAtt 0.4098 TrainAcc 0.9300 TestAcc 0.8519 0.8700
epoch 800 LossPred 0.2290 LossAtt 0.4073 TrainAcc 0.9100 TestAcc 0.8504 0.9050
epoch 900 LossPred 0.2126 LossAtt 0.4114 TrainAcc 0.9100 TestAcc 0.8463 0.9000
epoch 1000 LossPred 0.1695 LossAtt 0.4311 TrainAcc 0.9500 TestAcc 0.8483 0.9050
epoch 1100 LossPred 0.1314 LossAtt 0.4277 TrainAcc 0.9600 TestAcc 0.8596 0.9150
epoch 1200 LossPred 0.0969 LossAtt 0.4103 TrainAcc 0.9800 TestAcc 0.8579 0.9150
epoch 1300 LossPred 0.0902 LossAtt 0.4028 TrainAcc 0.9800 TestAcc 0.8554 0.9200
epoch 1400 LossPred 0.0977 LossAtt 0.4113 TrainAcc 0.9700 TestAcc 0.8504 0.9150
epoch 1500 LossPred 0.0855 LossAtt 0.4062 TrainAcc 0.9800 TestAcc 0.8506 0.9300
epoch 1600 LossPred 0.1166 LossAtt 0.3950 TrainAcc 0.9800 TestAcc 0.8521 0.9200
epoch 1700 LossPred 0.0844 LossAtt 0.3933 TrainAcc 0.9900 TestAcc 0.8514 0.9250
epoch 1800 LossPred 0.0664 LossAtt 0.3920 TrainAcc 0.9900 TestAcc 0.8476 0.9350
epoch 1900 LossPred 0.0628 LossAtt 0.3719 TrainAcc 0.9900 TestAcc 0.8463 0.9350
epoch 2000 LossPred 0.1515 LossAtt 0.3826 TrainAcc 0.9700 TestAcc 0.8343 0.9100
epoch 2100 LossPred 0.0774 LossAtt 0.3880 TrainAcc 0.9800 TestAcc 0.8403 0.9150
epoch 2200 LossPred 0.0552 LossAtt 0.3877 TrainAcc 0.9900 TestAcc 0.8416 0.9300
epoch 2300 LossPred 0.0561 LossAtt 0.3812 TrainAcc 0.9900 TestAcc 0.8436 0.9200
epoch 2400 LossPred 0.0524 LossAtt 0.3755 TrainAcc 0.9900 TestAcc 0.8433 0.9400
epoch 2500 LossPred 0.0503 LossAtt 0.3620 TrainAcc 0.9900 TestAcc 0.8383 0.9350
Optimization Finished!
********** replication  36  **********
epoch   0 LossPred 1.0943 LossAtt 1.0577 TrainAcc 0.4800 TestAcc 0.4580 0.4750
epoch 100 LossPred 0.9316 LossAtt 0.3299 TrainAcc 0.6000 TestAcc 0.5918 0.6000
epoch 200 LossPred 0.9159 LossAtt 0.2728 TrainAcc 0.5900 TestAcc 0.5498 0.5900
epoch 300 LossPred 0.8698 LossAtt 0.3066 TrainAcc 0.6500 TestAcc 0.5691 0.6550
epoch 400 LossPred 0.8446 LossAtt 0.3128 TrainAcc 0.6900 TestAcc 0.5716 0.6700
epoch 500 LossPred 0.7955 LossAtt 0.3886 TrainAcc 0.7100 TestAcc 0.5751 0.6750
epoch 600 LossPred 0.7386 LossAtt 0.3888 TrainAcc 0.7200 TestAcc 0.5823 0.7150
epoch 700 LossPred 0.6211 LossAtt 0.4804 TrainAcc 0.7900 TestAcc 0.6574 0.7800
epoch 800 LossPred 0.3556 LossAtt 0.4612 TrainAcc 0.9100 TestAcc 0.7848 0.8600
epoch 900 LossPred 0.2918 LossAtt 0.4264 TrainAcc 0.9200 TestAcc 0.7635 0.9000
epoch 1000 LossPred 0.2710 LossAtt 0.4273 TrainAcc 0.9200 TestAcc 0.7803 0.9050
epoch 1100 LossPred 0.2481 LossAtt 0.4199 TrainAcc 0.9300 TestAcc 0.7850 0.8900
epoch 1200 LossPred 0.2413 LossAtt 0.4133 TrainAcc 0.9200 TestAcc 0.7760 0.9150
epoch 1300 LossPred 0.2264 LossAtt 0.4192 TrainAcc 0.9400 TestAcc 0.7858 0.9050
epoch 1400 LossPred 0.2123 LossAtt 0.4259 TrainAcc 0.9500 TestAcc 0.7740 0.9200
epoch 1500 LossPred 0.2016 LossAtt 0.4225 TrainAcc 0.9500 TestAcc 0.7898 0.9200
epoch 1600 LossPred 0.1748 LossAtt 0.4424 TrainAcc 0.9500 TestAcc 0.7788 0.9250
epoch 1700 LossPred 0.1734 LossAtt 0.4370 TrainAcc 0.9600 TestAcc 0.7808 0.9050
epoch 1800 LossPred 0.1697 LossAtt 0.4292 TrainAcc 0.9600 TestAcc 0.7980 0.9100
epoch 1900 LossPred 0.1214 LossAtt 0.4356 TrainAcc 0.9600 TestAcc 0.8318 0.9300
epoch 2000 LossPred 0.0950 LossAtt 0.4349 TrainAcc 0.9800 TestAcc 0.8251 0.9400
epoch 2100 LossPred 0.0872 LossAtt 0.4423 TrainAcc 0.9700 TestAcc 0.8321 0.9250
epoch 2200 LossPred 0.0696 LossAtt 0.4413 TrainAcc 0.9900 TestAcc 0.8461 0.9300
epoch 2300 LossPred 0.0743 LossAtt 0.4295 TrainAcc 0.9900 TestAcc 0.8361 0.9350
epoch 2400 LossPred 0.0700 LossAtt 0.4249 TrainAcc 0.9800 TestAcc 0.8428 0.9350
epoch 2500 LossPred 0.0555 LossAtt 0.4372 TrainAcc 0.9900 TestAcc 0.8328 0.9450
Optimization Finished!
********** replication  37  **********
epoch   0 LossPred 0.9606 LossAtt 1.0352 TrainAcc 0.5200 TestAcc 0.4835 0.5900
epoch 100 LossPred 0.7117 LossAtt 0.3605 TrainAcc 0.7200 TestAcc 0.6562 0.7350
epoch 200 LossPred 0.2063 LossAtt 0.2868 TrainAcc 0.9500 TestAcc 0.8596 0.9200
epoch 300 LossPred 0.1676 LossAtt 0.2869 TrainAcc 0.9400 TestAcc 0.8714 0.9250
epoch 400 LossPred 0.1741 LossAtt 0.2636 TrainAcc 0.9400 TestAcc 0.8391 0.8800
epoch 500 LossPred 0.1599 LossAtt 0.2505 TrainAcc 0.9400 TestAcc 0.8804 0.9200
epoch 600 LossPred 0.1373 LossAtt 0.2374 TrainAcc 0.9600 TestAcc 0.8699 0.9150
epoch 700 LossPred 0.1436 LossAtt 0.2306 TrainAcc 0.9400 TestAcc 0.8591 0.9100
epoch 800 LossPred 0.1373 LossAtt 0.2427 TrainAcc 0.9500 TestAcc 0.8486 0.9100
epoch 900 LossPred 0.1902 LossAtt 0.2459 TrainAcc 0.9300 TestAcc 0.8301 0.8950
epoch 1000 LossPred 0.1611 LossAtt 0.2319 TrainAcc 0.9600 TestAcc 0.8431 0.9050
epoch 1100 LossPred 0.2079 LossAtt 0.2231 TrainAcc 0.9200 TestAcc 0.8784 0.9200
epoch 1200 LossPred 0.2155 LossAtt 0.2233 TrainAcc 0.9200 TestAcc 0.8774 0.9000
epoch 1300 LossPred 0.1400 LossAtt 0.2174 TrainAcc 0.9600 TestAcc 0.8621 0.9250
epoch 1400 LossPred 0.1579 LossAtt 0.2244 TrainAcc 0.9400 TestAcc 0.8433 0.9100
epoch 1500 LossPred 0.2141 LossAtt 0.2232 TrainAcc 0.9200 TestAcc 0.8771 0.9000
epoch 1600 LossPred 0.2191 LossAtt 0.2200 TrainAcc 0.9200 TestAcc 0.8441 0.9100
epoch 1700 LossPred 0.1814 LossAtt 0.2134 TrainAcc 0.9400 TestAcc 0.8649 0.9200
epoch 1800 LossPred 0.1479 LossAtt 0.2230 TrainAcc 0.9600 TestAcc 0.8551 0.9150
epoch 1900 LossPred 0.1284 LossAtt 0.2330 TrainAcc 0.9600 TestAcc 0.8691 0.9300
epoch 2000 LossPred 0.1309 LossAtt 0.2232 TrainAcc 0.9600 TestAcc 0.8644 0.9250
epoch 2100 LossPred 0.1328 LossAtt 0.2208 TrainAcc 0.9500 TestAcc 0.8589 0.9200
epoch 2200 LossPred 0.2009 LossAtt 0.2196 TrainAcc 0.9400 TestAcc 0.8594 0.9250
epoch 2300 LossPred 0.2311 LossAtt 0.2221 TrainAcc 0.9200 TestAcc 0.8173 0.8950
epoch 2400 LossPred 0.1904 LossAtt 0.2170 TrainAcc 0.9300 TestAcc 0.8368 0.9200
epoch 2500 LossPred 0.1477 LossAtt 0.2157 TrainAcc 0.9500 TestAcc 0.8519 0.9250
Optimization Finished!
********** replication  38  **********
epoch   0 LossPred 1.0331 LossAtt 1.0256 TrainAcc 0.5000 TestAcc 0.4817 0.5200
epoch 100 LossPred 0.8536 LossAtt 0.3434 TrainAcc 0.7200 TestAcc 0.6456 0.7250
epoch 200 LossPred 0.5296 LossAtt 0.4007 TrainAcc 0.8300 TestAcc 0.8416 0.8350
epoch 300 LossPred 0.4178 LossAtt 0.3527 TrainAcc 0.8500 TestAcc 0.8343 0.8400
epoch 400 LossPred 0.3164 LossAtt 0.3365 TrainAcc 0.9100 TestAcc 0.8686 0.8800
epoch 500 LossPred 0.3248 LossAtt 0.3343 TrainAcc 0.9000 TestAcc 0.8791 0.8750
epoch 600 LossPred 0.2467 LossAtt 0.3428 TrainAcc 0.9100 TestAcc 0.9204 0.9000
epoch 700 LossPred 0.4807 LossAtt 0.3636 TrainAcc 0.8400 TestAcc 0.8201 0.8250
epoch 800 LossPred 0.3338 LossAtt 0.3566 TrainAcc 0.8700 TestAcc 0.8509 0.8950
epoch 900 LossPred 0.1381 LossAtt 0.3466 TrainAcc 0.9600 TestAcc 0.9224 0.9200
epoch 1000 LossPred 0.1349 LossAtt 0.3341 TrainAcc 0.9700 TestAcc 0.9142 0.9200
epoch 1100 LossPred 0.1068 LossAtt 0.3315 TrainAcc 0.9600 TestAcc 0.9419 0.9600
epoch 1200 LossPred 0.3009 LossAtt 0.3114 TrainAcc 0.8800 TestAcc 0.8526 0.9150
epoch 1300 LossPred 0.2410 LossAtt 0.3264 TrainAcc 0.8900 TestAcc 0.8859 0.8800
epoch 1400 LossPred 0.2079 LossAtt 0.3184 TrainAcc 0.9100 TestAcc 0.9034 0.8900
epoch 1500 LossPred 0.1499 LossAtt 0.3063 TrainAcc 0.9400 TestAcc 0.9147 0.9450
epoch 1600 LossPred 0.1013 LossAtt 0.3006 TrainAcc 0.9800 TestAcc 0.9334 0.9500
epoch 1700 LossPred 0.0802 LossAtt 0.2916 TrainAcc 0.9800 TestAcc 0.9392 0.9750
epoch 1800 LossPred 0.1626 LossAtt 0.2965 TrainAcc 0.9400 TestAcc 0.9087 0.9450
epoch 1900 LossPred 0.0750 LossAtt 0.2919 TrainAcc 0.9800 TestAcc 0.9432 0.9750
epoch 2000 LossPred 0.0767 LossAtt 0.2853 TrainAcc 0.9800 TestAcc 0.9409 0.9800
epoch 2100 LossPred 0.1178 LossAtt 0.2868 TrainAcc 0.9500 TestAcc 0.9292 0.9500
epoch 2200 LossPred 0.0854 LossAtt 0.2995 TrainAcc 0.9700 TestAcc 0.9177 0.9550
epoch 2300 LossPred 0.4222 LossAtt 0.2848 TrainAcc 0.8600 TestAcc 0.8311 0.8800
epoch 2400 LossPred 0.0897 LossAtt 0.2835 TrainAcc 0.9700 TestAcc 0.9224 0.9650
epoch 2500 LossPred 0.0774 LossAtt 0.2916 TrainAcc 0.9800 TestAcc 0.9487 0.9800
Optimization Finished!
********** replication  39  **********
epoch   0 LossPred 0.9801 LossAtt 1.0165 TrainAcc 0.5900 TestAcc 0.5738 0.5950
epoch 100 LossPred 0.8735 LossAtt 0.4506 TrainAcc 0.6200 TestAcc 0.6356 0.6000
epoch 200 LossPred 0.4049 LossAtt 0.4704 TrainAcc 0.8700 TestAcc 0.8348 0.8400
epoch 300 LossPred 0.3187 LossAtt 0.4498 TrainAcc 0.8900 TestAcc 0.8616 0.8950
epoch 400 LossPred 0.2367 LossAtt 0.4411 TrainAcc 0.9400 TestAcc 0.8829 0.9100
epoch 500 LossPred 0.1962 LossAtt 0.4245 TrainAcc 0.9500 TestAcc 0.8851 0.9100
epoch 600 LossPred 0.1649 LossAtt 0.4228 TrainAcc 0.9600 TestAcc 0.8931 0.9200
epoch 700 LossPred 0.1573 LossAtt 0.4306 TrainAcc 0.9700 TestAcc 0.8891 0.9350
epoch 800 LossPred 0.1793 LossAtt 0.4284 TrainAcc 0.9500 TestAcc 0.8896 0.9100
epoch 900 LossPred 0.1089 LossAtt 0.4175 TrainAcc 0.9800 TestAcc 0.8901 0.9400
epoch 1000 LossPred 0.1454 LossAtt 0.4226 TrainAcc 0.9700 TestAcc 0.8869 0.9450
epoch 1100 LossPred 0.1023 LossAtt 0.4293 TrainAcc 0.9800 TestAcc 0.8974 0.9450
epoch 1200 LossPred 0.1309 LossAtt 0.4225 TrainAcc 0.9600 TestAcc 0.8816 0.9450
epoch 1300 LossPred 0.1826 LossAtt 0.4262 TrainAcc 0.9400 TestAcc 0.8924 0.9100
epoch 1400 LossPred 0.1026 LossAtt 0.4099 TrainAcc 0.9800 TestAcc 0.8974 0.9600
epoch 1500 LossPred 0.0833 LossAtt 0.4072 TrainAcc 0.9900 TestAcc 0.9067 0.9550
epoch 1600 LossPred 0.0995 LossAtt 0.3939 TrainAcc 0.9800 TestAcc 0.8869 0.9600
epoch 1700 LossPred 0.1107 LossAtt 0.3836 TrainAcc 0.9700 TestAcc 0.9017 0.9350
epoch 1800 LossPred 0.0678 LossAtt 0.3854 TrainAcc 0.9800 TestAcc 0.9054 0.9300
epoch 1900 LossPred 0.2014 LossAtt 0.3845 TrainAcc 0.9300 TestAcc 0.8749 0.9350
epoch 2000 LossPred 0.0721 LossAtt 0.3671 TrainAcc 0.9800 TestAcc 0.8931 0.9700
epoch 2100 LossPred 0.0415 LossAtt 0.3712 TrainAcc 0.9900 TestAcc 0.8969 0.9700
epoch 2200 LossPred 0.0293 LossAtt 0.3692 TrainAcc 1.0000 TestAcc 0.8849 0.9550
Optimization Finished!
********** replication  40  **********
epoch   0 LossPred 1.1919 LossAtt 1.0077 TrainAcc 0.4800 TestAcc 0.5435 0.4550
epoch 100 LossPred 0.9084 LossAtt 0.3949 TrainAcc 0.6100 TestAcc 0.5856 0.6100
epoch 200 LossPred 0.8924 LossAtt 0.3055 TrainAcc 0.6100 TestAcc 0.5856 0.6100
epoch 300 LossPred 0.8658 LossAtt 0.3039 TrainAcc 0.6900 TestAcc 0.6326 0.6650
epoch 400 LossPred 0.7791 LossAtt 0.4161 TrainAcc 0.7200 TestAcc 0.6381 0.7400
epoch 500 LossPred 0.6340 LossAtt 0.4452 TrainAcc 0.8100 TestAcc 0.5896 0.7850
epoch 600 LossPred 0.5530 LossAtt 0.4469 TrainAcc 0.8500 TestAcc 0.6259 0.7900
epoch 700 LossPred 0.4887 LossAtt 0.4012 TrainAcc 0.8400 TestAcc 0.6311 0.7700
epoch 800 LossPred 0.4654 LossAtt 0.4001 TrainAcc 0.8400 TestAcc 0.6279 0.7700
epoch 900 LossPred 0.4440 LossAtt 0.4029 TrainAcc 0.8500 TestAcc 0.6246 0.7750
epoch 1000 LossPred 0.4392 LossAtt 0.3942 TrainAcc 0.8500 TestAcc 0.6199 0.7700
epoch 1100 LossPred 0.4239 LossAtt 0.3913 TrainAcc 0.8500 TestAcc 0.6161 0.7850
epoch 1200 LossPred 0.4295 LossAtt 0.3859 TrainAcc 0.8400 TestAcc 0.6126 0.7800
epoch 1300 LossPred 0.4147 LossAtt 0.3704 TrainAcc 0.8400 TestAcc 0.6191 0.7800
epoch 1400 LossPred 0.4099 LossAtt 0.3790 TrainAcc 0.8500 TestAcc 0.6136 0.7800
epoch 1500 LossPred 0.4059 LossAtt 0.3806 TrainAcc 0.8400 TestAcc 0.6079 0.7850
epoch 1600 LossPred 0.3996 LossAtt 0.4012 TrainAcc 0.8500 TestAcc 0.6141 0.7750
epoch 1700 LossPred 0.4100 LossAtt 0.4028 TrainAcc 0.8600 TestAcc 0.6151 0.8000
epoch 1800 LossPred 0.3835 LossAtt 0.4287 TrainAcc 0.8500 TestAcc 0.6219 0.8000
epoch 1900 LossPred 0.3572 LossAtt 0.4309 TrainAcc 0.8900 TestAcc 0.6036 0.8000
epoch 2000 LossPred 0.2753 LossAtt 0.4195 TrainAcc 0.9300 TestAcc 0.6166 0.8500
epoch 2100 LossPred 0.2610 LossAtt 0.4258 TrainAcc 0.9200 TestAcc 0.6216 0.8000
epoch 2200 LossPred 0.3118 LossAtt 0.4388 TrainAcc 0.9100 TestAcc 0.6216 0.8200
epoch 2300 LossPred 0.2678 LossAtt 0.4124 TrainAcc 0.9200 TestAcc 0.6154 0.8200
epoch 2400 LossPred 0.2691 LossAtt 0.4351 TrainAcc 0.9200 TestAcc 0.6154 0.8100
epoch 2500 LossPred 0.2372 LossAtt 0.4054 TrainAcc 0.9100 TestAcc 0.6104 0.8050
Optimization Finished!
********** replication  41  **********
epoch   0 LossPred 0.9933 LossAtt 1.0131 TrainAcc 0.5500 TestAcc 0.4935 0.5450
epoch 100 LossPred 0.9083 LossAtt 0.3220 TrainAcc 0.6400 TestAcc 0.5330 0.6400
epoch 200 LossPred 0.8726 LossAtt 0.3797 TrainAcc 0.6400 TestAcc 0.5543 0.6400
epoch 300 LossPred 0.3779 LossAtt 0.4441 TrainAcc 0.8600 TestAcc 0.8581 0.8500
epoch 400 LossPred 0.2890 LossAtt 0.4350 TrainAcc 0.9200 TestAcc 0.8521 0.8750
epoch 500 LossPred 0.3418 LossAtt 0.4087 TrainAcc 0.9100 TestAcc 0.8331 0.9100
epoch 600 LossPred 0.2076 LossAtt 0.4132 TrainAcc 0.9500 TestAcc 0.8676 0.9200
epoch 700 LossPred 0.2255 LossAtt 0.4229 TrainAcc 0.9100 TestAcc 0.8709 0.8850
epoch 800 LossPred 0.3906 LossAtt 0.4285 TrainAcc 0.8700 TestAcc 0.8191 0.8800
epoch 900 LossPred 0.1040 LossAtt 0.4357 TrainAcc 0.9700 TestAcc 0.8806 0.9200
epoch 1000 LossPred 0.1535 LossAtt 0.4150 TrainAcc 0.9400 TestAcc 0.8884 0.9100
epoch 1100 LossPred 0.0822 LossAtt 0.4162 TrainAcc 0.9800 TestAcc 0.8796 0.9200
epoch 1200 LossPred 0.0907 LossAtt 0.4266 TrainAcc 0.9700 TestAcc 0.8894 0.9350
epoch 1300 LossPred 0.0878 LossAtt 0.4055 TrainAcc 0.9700 TestAcc 0.8694 0.9350
epoch 1400 LossPred 0.0447 LossAtt 0.3914 TrainAcc 1.0000 TestAcc 0.8836 0.9350
Optimization Finished!
********** replication  42  **********
epoch   0 LossPred 1.0476 LossAtt 1.0172 TrainAcc 0.4500 TestAcc 0.4982 0.4500
epoch 100 LossPred 0.9303 LossAtt 0.4123 TrainAcc 0.6100 TestAcc 0.5896 0.6500
epoch 200 LossPred 0.3390 LossAtt 0.4457 TrainAcc 0.9400 TestAcc 0.8579 0.8850
epoch 300 LossPred 0.1909 LossAtt 0.4580 TrainAcc 0.9500 TestAcc 0.8616 0.9150
epoch 400 LossPred 0.1487 LossAtt 0.4566 TrainAcc 0.9600 TestAcc 0.8711 0.9300
epoch 500 LossPred 0.1263 LossAtt 0.4719 TrainAcc 0.9800 TestAcc 0.8691 0.9300
epoch 600 LossPred 0.1225 LossAtt 0.4628 TrainAcc 0.9700 TestAcc 0.8724 0.9250
epoch 700 LossPred 0.1036 LossAtt 0.4676 TrainAcc 0.9800 TestAcc 0.8711 0.9250
epoch 800 LossPred 0.0969 LossAtt 0.4709 TrainAcc 0.9700 TestAcc 0.8699 0.9350
epoch 900 LossPred 0.0915 LossAtt 0.4758 TrainAcc 0.9700 TestAcc 0.8681 0.9350
epoch 1000 LossPred 0.0801 LossAtt 0.4773 TrainAcc 0.9800 TestAcc 0.8641 0.9300
epoch 1100 LossPred 0.0709 LossAtt 0.4719 TrainAcc 0.9900 TestAcc 0.8621 0.9450
epoch 1200 LossPred 0.0625 LossAtt 0.4722 TrainAcc 0.9900 TestAcc 0.8576 0.9550
epoch 1300 LossPred 0.0486 LossAtt 0.4809 TrainAcc 0.9900 TestAcc 0.8641 0.9650
epoch 1400 LossPred 0.0443 LossAtt 0.4680 TrainAcc 0.9900 TestAcc 0.8554 0.9600
epoch 1500 LossPred 0.0398 LossAtt 0.4800 TrainAcc 0.9900 TestAcc 0.8611 0.9650
epoch 1600 LossPred 0.0281 LossAtt 0.4829 TrainAcc 1.0000 TestAcc 0.8478 0.9600
Optimization Finished!
********** replication  43  **********
epoch   0 LossPred 1.1135 LossAtt 1.0459 TrainAcc 0.4100 TestAcc 0.4164 0.4100
epoch 100 LossPred 0.8859 LossAtt 0.2769 TrainAcc 0.6100 TestAcc 0.5993 0.6100
epoch 200 LossPred 0.8498 LossAtt 0.2736 TrainAcc 0.6900 TestAcc 0.5983 0.6900
epoch 300 LossPred 0.4317 LossAtt 0.5078 TrainAcc 0.8500 TestAcc 0.8473 0.8650
epoch 400 LossPred 0.2300 LossAtt 0.3224 TrainAcc 0.9400 TestAcc 0.8964 0.8950
epoch 500 LossPred 0.4007 LossAtt 0.3770 TrainAcc 0.8700 TestAcc 0.8468 0.8900
epoch 600 LossPred 0.2108 LossAtt 0.3267 TrainAcc 0.9300 TestAcc 0.8939 0.8950
epoch 700 LossPred 0.1515 LossAtt 0.3160 TrainAcc 0.9500 TestAcc 0.9244 0.9050
epoch 800 LossPred 0.1530 LossAtt 0.2970 TrainAcc 0.9500 TestAcc 0.9184 0.9300
epoch 900 LossPred 0.2834 LossAtt 0.3059 TrainAcc 0.9100 TestAcc 0.8529 0.8750
epoch 1000 LossPred 0.2825 LossAtt 0.3092 TrainAcc 0.9000 TestAcc 0.8584 0.9000
epoch 1100 LossPred 0.1818 LossAtt 0.3168 TrainAcc 0.9300 TestAcc 0.8911 0.9250
epoch 1200 LossPred 0.2807 LossAtt 0.2989 TrainAcc 0.9000 TestAcc 0.8659 0.9100
epoch 1300 LossPred 0.1197 LossAtt 0.2935 TrainAcc 0.9700 TestAcc 0.9044 0.9500
epoch 1400 LossPred 0.0999 LossAtt 0.2883 TrainAcc 0.9700 TestAcc 0.9132 0.9500
epoch 1500 LossPred 0.2639 LossAtt 0.2831 TrainAcc 0.9100 TestAcc 0.8646 0.8900
epoch 1600 LossPred 0.1712 LossAtt 0.3073 TrainAcc 0.9500 TestAcc 0.8986 0.9150
epoch 1700 LossPred 0.1231 LossAtt 0.2980 TrainAcc 0.9600 TestAcc 0.9129 0.9400
epoch 1800 LossPred 0.1128 LossAtt 0.3156 TrainAcc 0.9700 TestAcc 0.9224 0.9500
epoch 1900 LossPred 0.0867 LossAtt 0.3280 TrainAcc 0.9700 TestAcc 0.9197 0.9750
epoch 2000 LossPred 0.0699 LossAtt 0.3277 TrainAcc 0.9900 TestAcc 0.9339 0.9800
epoch 2100 LossPred 0.0661 LossAtt 0.3370 TrainAcc 0.9800 TestAcc 0.9139 0.9750
epoch 2200 LossPred 0.0355 LossAtt 0.3493 TrainAcc 0.9900 TestAcc 0.9242 0.9850
epoch 2300 LossPred 0.0956 LossAtt 0.3668 TrainAcc 0.9700 TestAcc 0.8956 0.9500
epoch 2400 LossPred 0.0797 LossAtt 0.3930 TrainAcc 0.9800 TestAcc 0.9087 0.9750
epoch 2500 LossPred 0.0145 LossAtt 0.4042 TrainAcc 1.0000 TestAcc 0.9299 0.9800
Optimization Finished!
********** replication  44  **********
epoch   0 LossPred 1.1856 LossAtt 1.0072 TrainAcc 0.4400 TestAcc 0.4122 0.4400
epoch 100 LossPred 0.9222 LossAtt 0.4002 TrainAcc 0.6500 TestAcc 0.5521 0.6400
epoch 200 LossPred 0.8575 LossAtt 0.3806 TrainAcc 0.6900 TestAcc 0.6394 0.6850
epoch 300 LossPred 0.7026 LossAtt 0.4800 TrainAcc 0.7500 TestAcc 0.6812 0.7650
epoch 400 LossPred 0.3469 LossAtt 0.4827 TrainAcc 0.9100 TestAcc 0.7920 0.8600
epoch 500 LossPred 0.3933 LossAtt 0.4712 TrainAcc 0.8800 TestAcc 0.7815 0.8700
epoch 600 LossPred 0.2620 LossAtt 0.4634 TrainAcc 0.9200 TestAcc 0.8048 0.8750
epoch 700 LossPred 0.2185 LossAtt 0.4783 TrainAcc 0.9500 TestAcc 0.8091 0.8800
epoch 800 LossPred 0.1740 LossAtt 0.4710 TrainAcc 0.9600 TestAcc 0.8041 0.9100
epoch 900 LossPred 0.1597 LossAtt 0.4430 TrainAcc 0.9600 TestAcc 0.7985 0.9100
epoch 1000 LossPred 0.1543 LossAtt 0.4269 TrainAcc 0.9600 TestAcc 0.7890 0.9050
epoch 1100 LossPred 0.1417 LossAtt 0.4321 TrainAcc 0.9600 TestAcc 0.7905 0.9100
epoch 1200 LossPred 0.1331 LossAtt 0.4387 TrainAcc 0.9700 TestAcc 0.7950 0.9100
epoch 1300 LossPred 0.1172 LossAtt 0.4368 TrainAcc 0.9700 TestAcc 0.7963 0.9000
epoch 1400 LossPred 0.1091 LossAtt 0.4206 TrainAcc 0.9800 TestAcc 0.7930 0.9100
epoch 1500 LossPred 0.1072 LossAtt 0.4255 TrainAcc 0.9800 TestAcc 0.7948 0.9200
epoch 1600 LossPred 0.1002 LossAtt 0.4170 TrainAcc 0.9800 TestAcc 0.7845 0.9200
epoch 1700 LossPred 0.0958 LossAtt 0.3968 TrainAcc 0.9800 TestAcc 0.7825 0.9250
epoch 1800 LossPred 0.1034 LossAtt 0.4080 TrainAcc 0.9800 TestAcc 0.7920 0.9150
epoch 1900 LossPred 0.0939 LossAtt 0.3811 TrainAcc 0.9800 TestAcc 0.7760 0.9150
epoch 2000 LossPred 0.0930 LossAtt 0.3892 TrainAcc 0.9800 TestAcc 0.7848 0.9250
epoch 2100 LossPred 0.0934 LossAtt 0.3780 TrainAcc 0.9800 TestAcc 0.7818 0.9200
epoch 2200 LossPred 0.1067 LossAtt 0.3914 TrainAcc 0.9800 TestAcc 0.7895 0.9250
epoch 2300 LossPred 0.0956 LossAtt 0.3847 TrainAcc 0.9800 TestAcc 0.7733 0.9100
epoch 2400 LossPred 0.0941 LossAtt 0.3749 TrainAcc 0.9800 TestAcc 0.7705 0.9100
epoch 2500 LossPred 0.0931 LossAtt 0.3875 TrainAcc 0.9800 TestAcc 0.7823 0.9300
Optimization Finished!
********** replication  45  **********
epoch   0 LossPred 1.0279 LossAtt 1.0486 TrainAcc 0.5200 TestAcc 0.4942 0.4950
epoch 100 LossPred 0.7194 LossAtt 0.3392 TrainAcc 0.7000 TestAcc 0.5921 0.7000
epoch 200 LossPred 0.6995 LossAtt 0.2982 TrainAcc 0.7000 TestAcc 0.6419 0.7100
epoch 300 LossPred 0.2944 LossAtt 0.3312 TrainAcc 0.9200 TestAcc 0.8551 0.8950
epoch 400 LossPred 0.3019 LossAtt 0.3007 TrainAcc 0.9100 TestAcc 0.8258 0.8800
epoch 500 LossPred 0.2386 LossAtt 0.3090 TrainAcc 0.9200 TestAcc 0.8716 0.8800
epoch 600 LossPred 0.2059 LossAtt 0.2978 TrainAcc 0.9400 TestAcc 0.8871 0.8700
epoch 700 LossPred 0.4021 LossAtt 0.2970 TrainAcc 0.8800 TestAcc 0.7593 0.8450
epoch 800 LossPred 0.2638 LossAtt 0.2908 TrainAcc 0.9300 TestAcc 0.8473 0.8900
epoch 900 LossPred 0.2617 LossAtt 0.2805 TrainAcc 0.9100 TestAcc 0.8501 0.9050
epoch 1000 LossPred 0.1976 LossAtt 0.2847 TrainAcc 0.9200 TestAcc 0.8809 0.9150
epoch 1100 LossPred 0.3541 LossAtt 0.2923 TrainAcc 0.8400 TestAcc 0.8471 0.8500
epoch 1200 LossPred 0.2494 LossAtt 0.3020 TrainAcc 0.9200 TestAcc 0.8666 0.9250
epoch 1300 LossPred 0.2239 LossAtt 0.3402 TrainAcc 0.9200 TestAcc 0.8706 0.9000
epoch 1400 LossPred 0.2150 LossAtt 0.3437 TrainAcc 0.9100 TestAcc 0.8856 0.8850
epoch 1500 LossPred 0.2379 LossAtt 0.3523 TrainAcc 0.9000 TestAcc 0.8764 0.8850
epoch 1600 LossPred 0.3098 LossAtt 0.3403 TrainAcc 0.9000 TestAcc 0.8356 0.8900
epoch 1700 LossPred 0.2036 LossAtt 0.3451 TrainAcc 0.9200 TestAcc 0.8849 0.8950
epoch 1800 LossPred 0.2912 LossAtt 0.3022 TrainAcc 0.8800 TestAcc 0.8361 0.8800
epoch 1900 LossPred 0.2321 LossAtt 0.2854 TrainAcc 0.9300 TestAcc 0.8614 0.9050
epoch 2000 LossPred 0.2223 LossAtt 0.2757 TrainAcc 0.9200 TestAcc 0.8861 0.9050
epoch 2100 LossPred 0.2431 LossAtt 0.2542 TrainAcc 0.9200 TestAcc 0.8418 0.9150
epoch 2200 LossPred 0.2252 LossAtt 0.2404 TrainAcc 0.9200 TestAcc 0.8699 0.9100
epoch 2300 LossPred 0.3872 LossAtt 0.2275 TrainAcc 0.8800 TestAcc 0.7868 0.8750
epoch 2400 LossPred 0.2814 LossAtt 0.2180 TrainAcc 0.9100 TestAcc 0.8306 0.8950
epoch 2500 LossPred 0.1858 LossAtt 0.2271 TrainAcc 0.9300 TestAcc 0.8786 0.9300
Optimization Finished!
********** replication  46  **********
epoch   0 LossPred 1.1275 LossAtt 1.0193 TrainAcc 0.4900 TestAcc 0.5055 0.5000
epoch 100 LossPred 0.8684 LossAtt 0.3637 TrainAcc 0.6100 TestAcc 0.5921 0.6000
epoch 200 LossPred 0.5981 LossAtt 0.4414 TrainAcc 0.8300 TestAcc 0.7795 0.8200
epoch 300 LossPred 0.2127 LossAtt 0.4418 TrainAcc 0.9400 TestAcc 0.8851 0.9400
epoch 400 LossPred 0.1298 LossAtt 0.4454 TrainAcc 0.9700 TestAcc 0.9144 0.9650
epoch 500 LossPred 0.1525 LossAtt 0.4405 TrainAcc 0.9500 TestAcc 0.8969 0.9600
epoch 600 LossPred 0.1082 LossAtt 0.4354 TrainAcc 0.9700 TestAcc 0.9187 0.9750
epoch 700 LossPred 0.1178 LossAtt 0.4138 TrainAcc 0.9700 TestAcc 0.9227 0.9550
epoch 800 LossPred 0.0779 LossAtt 0.4250 TrainAcc 0.9900 TestAcc 0.9292 0.9900
epoch 900 LossPred 0.1854 LossAtt 0.4210 TrainAcc 0.9300 TestAcc 0.8731 0.9550
epoch 1000 LossPred 0.0511 LossAtt 0.4144 TrainAcc 0.9800 TestAcc 0.9459 0.9950
epoch 1100 LossPred 0.0570 LossAtt 0.4100 TrainAcc 0.9800 TestAcc 0.9262 0.9750
epoch 1200 LossPred 0.0310 LossAtt 0.4042 TrainAcc 0.9900 TestAcc 0.9422 0.9950
epoch 1300 LossPred 0.0386 LossAtt 0.4166 TrainAcc 0.9900 TestAcc 0.9297 0.9950
epoch 1400 LossPred 0.0118 LossAtt 0.4102 TrainAcc 1.0000 TestAcc 0.9352 0.9950
Optimization Finished!
********** replication  47  **********
epoch   0 LossPred 1.1987 LossAtt 1.0391 TrainAcc 0.4200 TestAcc 0.4560 0.4550
epoch 100 LossPred 0.8970 LossAtt 0.3547 TrainAcc 0.5900 TestAcc 0.6056 0.5950
epoch 200 LossPred 0.8684 LossAtt 0.3240 TrainAcc 0.6000 TestAcc 0.5958 0.5750
epoch 300 LossPred 0.8578 LossAtt 0.3036 TrainAcc 0.6300 TestAcc 0.6104 0.6000
epoch 400 LossPred 0.8237 LossAtt 0.3724 TrainAcc 0.6500 TestAcc 0.6151 0.6550
epoch 500 LossPred 0.2672 LossAtt 0.3784 TrainAcc 0.9200 TestAcc 0.8291 0.9100
epoch 600 LossPred 0.2362 LossAtt 0.3549 TrainAcc 0.9500 TestAcc 0.8168 0.9150
epoch 700 LossPred 0.1677 LossAtt 0.3199 TrainAcc 0.9600 TestAcc 0.8303 0.9200
epoch 800 LossPred 0.1957 LossAtt 0.3307 TrainAcc 0.9400 TestAcc 0.8509 0.9200
epoch 900 LossPred 0.1611 LossAtt 0.3247 TrainAcc 0.9600 TestAcc 0.8466 0.9300
epoch 1000 LossPred 0.1470 LossAtt 0.3418 TrainAcc 0.9700 TestAcc 0.8516 0.9350
epoch 1100 LossPred 0.1592 LossAtt 0.3341 TrainAcc 0.9400 TestAcc 0.8599 0.9200
epoch 1200 LossPred 0.1667 LossAtt 0.3437 TrainAcc 0.9600 TestAcc 0.8649 0.9200
epoch 1300 LossPred 0.1523 LossAtt 0.3185 TrainAcc 0.9600 TestAcc 0.8704 0.9350
epoch 1400 LossPred 0.1140 LossAtt 0.3204 TrainAcc 0.9700 TestAcc 0.8659 0.9600
epoch 1500 LossPred 0.1297 LossAtt 0.3185 TrainAcc 0.9600 TestAcc 0.8581 0.9400
epoch 1600 LossPred 0.3179 LossAtt 0.3130 TrainAcc 0.9000 TestAcc 0.8266 0.8750
epoch 1700 LossPred 0.0912 LossAtt 0.2970 TrainAcc 0.9800 TestAcc 0.8656 0.9550
epoch 1800 LossPred 0.1076 LossAtt 0.3092 TrainAcc 0.9700 TestAcc 0.8589 0.9600
epoch 1900 LossPred 0.1054 LossAtt 0.3038 TrainAcc 0.9800 TestAcc 0.8461 0.9150
epoch 2000 LossPred 0.1515 LossAtt 0.2982 TrainAcc 0.9400 TestAcc 0.8491 0.9500
epoch 2100 LossPred 0.0776 LossAtt 0.2854 TrainAcc 0.9800 TestAcc 0.8491 0.9600
epoch 2200 LossPred 0.0783 LossAtt 0.2883 TrainAcc 0.9800 TestAcc 0.8488 0.9650
epoch 2300 LossPred 0.0738 LossAtt 0.2778 TrainAcc 0.9800 TestAcc 0.8483 0.9600
epoch 2400 LossPred 0.0687 LossAtt 0.2831 TrainAcc 0.9800 TestAcc 0.8481 0.9600
epoch 2500 LossPred 0.0668 LossAtt 0.2815 TrainAcc 0.9800 TestAcc 0.8624 0.9550
Optimization Finished!
********** replication  48  **********
epoch   0 LossPred 0.9018 LossAtt 1.0215 TrainAcc 0.6500 TestAcc 0.5458 0.6450
epoch 100 LossPred 0.4543 LossAtt 0.3690 TrainAcc 0.8500 TestAcc 0.8706 0.8350
epoch 200 LossPred 0.4326 LossAtt 0.3214 TrainAcc 0.8200 TestAcc 0.8316 0.8400
epoch 300 LossPred 0.3448 LossAtt 0.3018 TrainAcc 0.8800 TestAcc 0.8884 0.8750
epoch 400 LossPred 0.2417 LossAtt 0.2888 TrainAcc 0.9000 TestAcc 0.9264 0.8850
epoch 500 LossPred 0.1946 LossAtt 0.2864 TrainAcc 0.9400 TestAcc 0.9342 0.9250
epoch 600 LossPred 0.1705 LossAtt 0.2882 TrainAcc 0.9600 TestAcc 0.9494 0.9250
epoch 700 LossPred 0.2903 LossAtt 0.2714 TrainAcc 0.9000 TestAcc 0.9022 0.9250
epoch 800 LossPred 0.1505 LossAtt 0.2921 TrainAcc 0.9500 TestAcc 0.9497 0.9350
epoch 900 LossPred 0.1153 LossAtt 0.2921 TrainAcc 0.9600 TestAcc 0.9402 0.9350
epoch 1000 LossPred 0.2265 LossAtt 0.2876 TrainAcc 0.9200 TestAcc 0.8909 0.8950
epoch 1100 LossPred 0.1940 LossAtt 0.2886 TrainAcc 0.9200 TestAcc 0.8971 0.9050
epoch 1200 LossPred 0.3296 LossAtt 0.2878 TrainAcc 0.8800 TestAcc 0.8666 0.8700
epoch 1300 LossPred 0.1366 LossAtt 0.2773 TrainAcc 0.9500 TestAcc 0.9247 0.8950
epoch 1400 LossPred 0.0621 LossAtt 0.2918 TrainAcc 0.9900 TestAcc 0.9379 0.9350
epoch 1500 LossPred 0.0618 LossAtt 0.2805 TrainAcc 0.9900 TestAcc 0.9297 0.9400
epoch 1600 LossPred 0.0467 LossAtt 0.2788 TrainAcc 0.9900 TestAcc 0.9372 0.9450
epoch 1700 LossPred 0.0524 LossAtt 0.2801 TrainAcc 0.9900 TestAcc 0.9409 0.9400
epoch 1800 LossPred 0.1242 LossAtt 0.2764 TrainAcc 0.9400 TestAcc 0.9214 0.9150
epoch 1900 LossPred 0.0554 LossAtt 0.2763 TrainAcc 0.9800 TestAcc 0.9252 0.9450
epoch 2000 LossPred 0.0813 LossAtt 0.2686 TrainAcc 0.9800 TestAcc 0.9279 0.9250
epoch 2100 LossPred 0.0678 LossAtt 0.2581 TrainAcc 0.9700 TestAcc 0.9364 0.9350
epoch 2200 LossPred 0.0531 LossAtt 0.2719 TrainAcc 0.9800 TestAcc 0.9267 0.9450
epoch 2300 LossPred 0.0420 LossAtt 0.2765 TrainAcc 1.0000 TestAcc 0.9409 0.9450
Optimization Finished!
********** replication  49  **********
epoch   0 LossPred 0.9805 LossAtt 1.0113 TrainAcc 0.5500 TestAcc 0.4712 0.5900
epoch 100 LossPred 0.8190 LossAtt 0.4246 TrainAcc 0.7300 TestAcc 0.5761 0.7450
epoch 200 LossPred 0.7467 LossAtt 0.4297 TrainAcc 0.7300 TestAcc 0.5818 0.7400
epoch 300 LossPred 0.6051 LossAtt 0.5038 TrainAcc 0.8100 TestAcc 0.5738 0.7700
epoch 400 LossPred 0.4681 LossAtt 0.5534 TrainAcc 0.8400 TestAcc 0.5591 0.8250
epoch 500 LossPred 0.3950 LossAtt 0.5412 TrainAcc 0.8800 TestAcc 0.5718 0.8100
epoch 600 LossPred 0.3269 LossAtt 0.5174 TrainAcc 0.9100 TestAcc 0.5691 0.8200
epoch 700 LossPred 0.2833 LossAtt 0.4997 TrainAcc 0.9300 TestAcc 0.5708 0.8050
epoch 800 LossPred 0.2476 LossAtt 0.5076 TrainAcc 0.9400 TestAcc 0.5731 0.8000
epoch 900 LossPred 0.2044 LossAtt 0.5104 TrainAcc 0.9700 TestAcc 0.5768 0.8200
epoch 1000 LossPred 0.1942 LossAtt 0.5288 TrainAcc 0.9700 TestAcc 0.5726 0.8150
epoch 1100 LossPred 0.1955 LossAtt 0.5196 TrainAcc 0.9700 TestAcc 0.5683 0.7950
epoch 1200 LossPred 0.1465 LossAtt 0.5178 TrainAcc 0.9800 TestAcc 0.5495 0.8300
epoch 1300 LossPred 0.1331 LossAtt 0.5228 TrainAcc 0.9800 TestAcc 0.5508 0.7850
epoch 1400 LossPred 0.1267 LossAtt 0.5275 TrainAcc 0.9800 TestAcc 0.5493 0.8100
epoch 1500 LossPred 0.1148 LossAtt 0.5083 TrainAcc 0.9800 TestAcc 0.5455 0.8050
epoch 1600 LossPred 0.1200 LossAtt 0.5069 TrainAcc 0.9800 TestAcc 0.5488 0.8000
epoch 1700 LossPred 0.1032 LossAtt 0.5056 TrainAcc 0.9800 TestAcc 0.5473 0.7950
epoch 1800 LossPred 0.1100 LossAtt 0.5080 TrainAcc 0.9800 TestAcc 0.5478 0.7900
epoch 1900 LossPred 0.0986 LossAtt 0.5086 TrainAcc 0.9800 TestAcc 0.5483 0.7900
epoch 2000 LossPred 0.1337 LossAtt 0.4974 TrainAcc 0.9600 TestAcc 0.5531 0.7900
epoch 2100 LossPred 0.1440 LossAtt 0.5063 TrainAcc 0.9700 TestAcc 0.5601 0.7750
epoch 2200 LossPred 0.0829 LossAtt 0.4877 TrainAcc 0.9800 TestAcc 0.5453 0.8100
epoch 2300 LossPred 0.0823 LossAtt 0.4745 TrainAcc 0.9800 TestAcc 0.5508 0.7850
epoch 2400 LossPred 0.0776 LossAtt 0.4821 TrainAcc 0.9800 TestAcc 0.5440 0.8200
epoch 2500 LossPred 0.1012 LossAtt 0.4832 TrainAcc 0.9700 TestAcc 0.5536 0.7950
Optimization Finished!
********** replication  50  **********
epoch   0 LossPred 1.2740 LossAtt 1.0969 TrainAcc 0.4600 TestAcc 0.5065 0.4500
epoch 100 LossPred 0.8512 LossAtt 0.4038 TrainAcc 0.7200 TestAcc 0.5888 0.6900
epoch 200 LossPred 0.4744 LossAtt 0.3464 TrainAcc 0.8700 TestAcc 0.7828 0.8350
epoch 300 LossPred 0.3005 LossAtt 0.3436 TrainAcc 0.8900 TestAcc 0.8614 0.8900
epoch 400 LossPred 0.2723 LossAtt 0.3036 TrainAcc 0.8900 TestAcc 0.8699 0.9050
epoch 500 LossPred 0.2796 LossAtt 0.3006 TrainAcc 0.9200 TestAcc 0.8594 0.8900
epoch 600 LossPred 0.2413 LossAtt 0.2984 TrainAcc 0.9200 TestAcc 0.8774 0.8950
epoch 700 LossPred 0.2372 LossAtt 0.2774 TrainAcc 0.9100 TestAcc 0.8786 0.8850
epoch 800 LossPred 0.2363 LossAtt 0.2759 TrainAcc 0.9200 TestAcc 0.8831 0.8850
epoch 900 LossPred 0.2383 LossAtt 0.2634 TrainAcc 0.9100 TestAcc 0.8731 0.9000
epoch 1000 LossPred 0.2292 LossAtt 0.2685 TrainAcc 0.9100 TestAcc 0.8791 0.9050
epoch 1100 LossPred 0.4045 LossAtt 0.2809 TrainAcc 0.8800 TestAcc 0.8306 0.8500
epoch 1200 LossPred 0.2182 LossAtt 0.2653 TrainAcc 0.9200 TestAcc 0.8881 0.9000
epoch 1300 LossPred 0.2620 LossAtt 0.2818 TrainAcc 0.9200 TestAcc 0.8701 0.9100
epoch 1400 LossPred 0.2786 LossAtt 0.2883 TrainAcc 0.9100 TestAcc 0.8526 0.8900
epoch 1500 LossPred 0.2309 LossAtt 0.2938 TrainAcc 0.9300 TestAcc 0.8864 0.9100
epoch 1600 LossPred 0.1801 LossAtt 0.3070 TrainAcc 0.9500 TestAcc 0.9012 0.9200
epoch 1700 LossPred 0.3097 LossAtt 0.3006 TrainAcc 0.8800 TestAcc 0.8276 0.8550
epoch 1800 LossPred 0.1993 LossAtt 0.3123 TrainAcc 0.9300 TestAcc 0.8909 0.9250
epoch 1900 LossPred 0.2097 LossAtt 0.2983 TrainAcc 0.9300 TestAcc 0.8884 0.9250
epoch 2000 LossPred 0.2472 LossAtt 0.3085 TrainAcc 0.9000 TestAcc 0.8876 0.9150
epoch 2100 LossPred 0.1222 LossAtt 0.3086 TrainAcc 0.9700 TestAcc 0.9044 0.9250
epoch 2200 LossPred 0.1814 LossAtt 0.3097 TrainAcc 0.9400 TestAcc 0.8846 0.9100
epoch 2300 LossPred 0.0999 LossAtt 0.3067 TrainAcc 0.9800 TestAcc 0.8989 0.9450
epoch 2400 LossPred 0.2133 LossAtt 0.3038 TrainAcc 0.9100 TestAcc 0.8829 0.9150
epoch 2500 LossPred 0.0868 LossAtt 0.3019 TrainAcc 0.9800 TestAcc 0.9054 0.9450
Optimization Finished!
********** replication  51  **********
epoch   0 LossPred 1.0638 LossAtt 1.0124 TrainAcc 0.5800 TestAcc 0.5593 0.5300
epoch 100 LossPred 0.9433 LossAtt 0.3538 TrainAcc 0.5900 TestAcc 0.5963 0.5900
epoch 200 LossPred 0.6023 LossAtt 0.4273 TrainAcc 0.7800 TestAcc 0.8096 0.7700
epoch 300 LossPred 0.4186 LossAtt 0.4171 TrainAcc 0.8600 TestAcc 0.8699 0.7900
epoch 400 LossPred 0.2838 LossAtt 0.3985 TrainAcc 0.9200 TestAcc 0.9254 0.8600
epoch 500 LossPred 0.2855 LossAtt 0.4121 TrainAcc 0.9200 TestAcc 0.9189 0.8550
epoch 600 LossPred 0.2427 LossAtt 0.4056 TrainAcc 0.9200 TestAcc 0.9174 0.8750
epoch 700 LossPred 0.1825 LossAtt 0.3911 TrainAcc 0.9700 TestAcc 0.9297 0.9150
epoch 800 LossPred 0.4387 LossAtt 0.3885 TrainAcc 0.8300 TestAcc 0.8706 0.8300
epoch 900 LossPred 0.2980 LossAtt 0.3792 TrainAcc 0.8600 TestAcc 0.8969 0.8700
epoch 1000 LossPred 0.1842 LossAtt 0.3976 TrainAcc 0.9400 TestAcc 0.9129 0.9300
epoch 1100 LossPred 0.1190 LossAtt 0.3982 TrainAcc 0.9800 TestAcc 0.9127 0.9450
epoch 1200 LossPred 0.0814 LossAtt 0.3835 TrainAcc 0.9900 TestAcc 0.9134 0.9550
epoch 1300 LossPred 0.0938 LossAtt 0.3841 TrainAcc 0.9700 TestAcc 0.9154 0.9500
epoch 1400 LossPred 0.0786 LossAtt 0.3694 TrainAcc 0.9900 TestAcc 0.9124 0.9650
epoch 1500 LossPred 0.0846 LossAtt 0.3692 TrainAcc 0.9800 TestAcc 0.9079 0.9650
epoch 1600 LossPred 0.0502 LossAtt 0.3728 TrainAcc 0.9900 TestAcc 0.9097 0.9600
epoch 1700 LossPred 0.1784 LossAtt 0.3757 TrainAcc 0.9400 TestAcc 0.8884 0.9050
epoch 1800 LossPred 0.0578 LossAtt 0.3625 TrainAcc 0.9900 TestAcc 0.9049 0.9550
epoch 1900 LossPred 0.0351 LossAtt 0.3743 TrainAcc 1.0000 TestAcc 0.9082 0.9650
Optimization Finished!
********** replication  52  **********
epoch   0 LossPred 0.9975 LossAtt 1.0255 TrainAcc 0.5900 TestAcc 0.5936 0.5600
epoch 100 LossPred 0.6692 LossAtt 0.3929 TrainAcc 0.7600 TestAcc 0.6849 0.7800
epoch 200 LossPred 0.2055 LossAtt 0.3316 TrainAcc 0.9500 TestAcc 0.8506 0.9000
epoch 300 LossPred 0.1832 LossAtt 0.3065 TrainAcc 0.9500 TestAcc 0.8496 0.9050
epoch 400 LossPred 0.1528 LossAtt 0.3042 TrainAcc 0.9600 TestAcc 0.8566 0.9000
epoch 500 LossPred 0.1271 LossAtt 0.3191 TrainAcc 0.9600 TestAcc 0.8524 0.9100
epoch 600 LossPred 0.1084 LossAtt 0.3280 TrainAcc 0.9800 TestAcc 0.8486 0.9150
epoch 700 LossPred 0.0841 LossAtt 0.3302 TrainAcc 0.9800 TestAcc 0.8456 0.8950
epoch 800 LossPred 0.0789 LossAtt 0.3314 TrainAcc 0.9800 TestAcc 0.8428 0.9050
epoch 900 LossPred 0.0635 LossAtt 0.3515 TrainAcc 0.9900 TestAcc 0.8426 0.8850
epoch 1000 LossPred 0.0663 LossAtt 0.3358 TrainAcc 0.9900 TestAcc 0.8448 0.9150
epoch 1100 LossPred 0.0470 LossAtt 0.3338 TrainAcc 0.9900 TestAcc 0.8406 0.8950
epoch 1200 LossPred 0.0515 LossAtt 0.3369 TrainAcc 0.9900 TestAcc 0.8388 0.9200
epoch 1300 LossPred 0.0466 LossAtt 0.3203 TrainAcc 1.0000 TestAcc 0.8396 0.9200
Optimization Finished!
********** replication  53  **********
epoch   0 LossPred 1.2072 LossAtt 1.0298 TrainAcc 0.4300 TestAcc 0.5033 0.4400
epoch 100 LossPred 0.9311 LossAtt 0.3520 TrainAcc 0.6700 TestAcc 0.6184 0.6700
epoch 200 LossPred 0.8988 LossAtt 0.2995 TrainAcc 0.6700 TestAcc 0.6184 0.6700
epoch 300 LossPred 0.8727 LossAtt 0.2487 TrainAcc 0.6700 TestAcc 0.6184 0.6700
epoch 400 LossPred 0.8340 LossAtt 0.2783 TrainAcc 0.6700 TestAcc 0.6184 0.6800
epoch 500 LossPred 0.3555 LossAtt 0.3471 TrainAcc 0.9000 TestAcc 0.8564 0.8700
epoch 600 LossPred 0.3236 LossAtt 0.3427 TrainAcc 0.8800 TestAcc 0.8571 0.8750
epoch 700 LossPred 0.3650 LossAtt 0.3339 TrainAcc 0.8700 TestAcc 0.8654 0.8700
epoch 800 LossPred 0.2575 LossAtt 0.3304 TrainAcc 0.9200 TestAcc 0.8669 0.8950
epoch 900 LossPred 0.2193 LossAtt 0.3163 TrainAcc 0.9300 TestAcc 0.8566 0.8850
epoch 1000 LossPred 0.2533 LossAtt 0.3144 TrainAcc 0.9100 TestAcc 0.8539 0.8950
epoch 1100 LossPred 0.2142 LossAtt 0.3149 TrainAcc 0.9300 TestAcc 0.8564 0.8950
epoch 1200 LossPred 0.2026 LossAtt 0.3168 TrainAcc 0.9300 TestAcc 0.8594 0.9050
epoch 1300 LossPred 0.2015 LossAtt 0.3038 TrainAcc 0.9300 TestAcc 0.8524 0.8900
epoch 1400 LossPred 0.1813 LossAtt 0.2982 TrainAcc 0.9400 TestAcc 0.8621 0.9000
epoch 1500 LossPred 0.1778 LossAtt 0.2931 TrainAcc 0.9500 TestAcc 0.8701 0.9150
epoch 1600 LossPred 0.1790 LossAtt 0.2875 TrainAcc 0.9500 TestAcc 0.8701 0.9200
epoch 1700 LossPred 0.1798 LossAtt 0.2932 TrainAcc 0.9400 TestAcc 0.8666 0.9050
epoch 1800 LossPred 0.1524 LossAtt 0.2885 TrainAcc 0.9600 TestAcc 0.8556 0.8950
epoch 1900 LossPred 0.1736 LossAtt 0.2784 TrainAcc 0.9400 TestAcc 0.8756 0.9300
epoch 2000 LossPred 0.1472 LossAtt 0.2686 TrainAcc 0.9600 TestAcc 0.8606 0.8950
epoch 2100 LossPred 0.1475 LossAtt 0.2799 TrainAcc 0.9600 TestAcc 0.8651 0.9050
epoch 2200 LossPred 0.1405 LossAtt 0.2774 TrainAcc 0.9600 TestAcc 0.8591 0.9150
epoch 2300 LossPred 0.1410 LossAtt 0.2650 TrainAcc 0.9600 TestAcc 0.8644 0.9200
epoch 2400 LossPred 0.2612 LossAtt 0.2776 TrainAcc 0.9100 TestAcc 0.8544 0.8750
epoch 2500 LossPred 0.1447 LossAtt 0.2590 TrainAcc 0.9600 TestAcc 0.8564 0.9100
Optimization Finished!
********** replication  54  **********
epoch   0 LossPred 1.0642 LossAtt 1.0338 TrainAcc 0.5300 TestAcc 0.5913 0.5100
epoch 100 LossPred 0.8727 LossAtt 0.4113 TrainAcc 0.6800 TestAcc 0.5763 0.6800
epoch 200 LossPred 0.7673 LossAtt 0.4614 TrainAcc 0.7300 TestAcc 0.5270 0.7200
epoch 300 LossPred 0.6534 LossAtt 0.5410 TrainAcc 0.8000 TestAcc 0.5495 0.7900
epoch 400 LossPred 0.4768 LossAtt 0.5304 TrainAcc 0.8500 TestAcc 0.7400 0.8500
epoch 500 LossPred 0.4142 LossAtt 0.5166 TrainAcc 0.8700 TestAcc 0.7465 0.8700
epoch 600 LossPred 0.3693 LossAtt 0.5092 TrainAcc 0.9100 TestAcc 0.7292 0.8850
epoch 700 LossPred 0.3477 LossAtt 0.5334 TrainAcc 0.9100 TestAcc 0.7593 0.8700
epoch 800 LossPred 0.3038 LossAtt 0.4923 TrainAcc 0.9300 TestAcc 0.7367 0.8800
epoch 900 LossPred 0.3222 LossAtt 0.4914 TrainAcc 0.9200 TestAcc 0.7693 0.8800
epoch 1000 LossPred 0.2818 LossAtt 0.4826 TrainAcc 0.9300 TestAcc 0.7505 0.8700
epoch 1100 LossPred 0.2537 LossAtt 0.4727 TrainAcc 0.9400 TestAcc 0.7585 0.8850
epoch 1200 LossPred 0.2431 LossAtt 0.4761 TrainAcc 0.9400 TestAcc 0.7730 0.8900
epoch 1300 LossPred 0.2835 LossAtt 0.4688 TrainAcc 0.9200 TestAcc 0.7720 0.8650
epoch 1400 LossPred 0.2249 LossAtt 0.4786 TrainAcc 0.9400 TestAcc 0.7703 0.8850
epoch 1500 LossPred 0.2137 LossAtt 0.4697 TrainAcc 0.9500 TestAcc 0.7585 0.9000
epoch 1600 LossPred 0.1922 LossAtt 0.4724 TrainAcc 0.9600 TestAcc 0.7708 0.9100
epoch 1700 LossPred 0.1865 LossAtt 0.4821 TrainAcc 0.9600 TestAcc 0.7528 0.9150
epoch 1800 LossPred 0.1758 LossAtt 0.4757 TrainAcc 0.9600 TestAcc 0.7553 0.9150
epoch 1900 LossPred 0.1664 LossAtt 0.4721 TrainAcc 0.9600 TestAcc 0.7593 0.9150
epoch 2000 LossPred 0.1620 LossAtt 0.4902 TrainAcc 0.9600 TestAcc 0.7593 0.9200
epoch 2100 LossPred 0.1563 LossAtt 0.4692 TrainAcc 0.9600 TestAcc 0.7455 0.9200
epoch 2200 LossPred 0.1523 LossAtt 0.4696 TrainAcc 0.9600 TestAcc 0.7362 0.9250
epoch 2300 LossPred 0.1433 LossAtt 0.4762 TrainAcc 0.9700 TestAcc 0.7415 0.9200
epoch 2400 LossPred 0.1356 LossAtt 0.4657 TrainAcc 0.9700 TestAcc 0.7435 0.9050
epoch 2500 LossPred 0.1292 LossAtt 0.4739 TrainAcc 0.9700 TestAcc 0.7457 0.9250
Optimization Finished!
********** replication  55  **********
epoch   0 LossPred 1.1257 LossAtt 1.0226 TrainAcc 0.4300 TestAcc 0.4102 0.4450
epoch 100 LossPred 0.9087 LossAtt 0.2944 TrainAcc 0.6000 TestAcc 0.5868 0.6050
epoch 200 LossPred 0.4399 LossAtt 0.3175 TrainAcc 0.8600 TestAcc 0.8609 0.8350
epoch 300 LossPred 0.3854 LossAtt 0.3075 TrainAcc 0.8800 TestAcc 0.8581 0.8550
epoch 400 LossPred 0.3976 LossAtt 0.2938 TrainAcc 0.8500 TestAcc 0.8571 0.8400
epoch 500 LossPred 0.3539 LossAtt 0.2683 TrainAcc 0.8800 TestAcc 0.8601 0.8600
epoch 600 LossPred 0.4250 LossAtt 0.2647 TrainAcc 0.8500 TestAcc 0.8704 0.8300
epoch 700 LossPred 0.3197 LossAtt 0.2751 TrainAcc 0.9100 TestAcc 0.8736 0.8650
epoch 800 LossPred 0.3421 LossAtt 0.2648 TrainAcc 0.8800 TestAcc 0.8886 0.8500
epoch 900 LossPred 0.2845 LossAtt 0.2699 TrainAcc 0.9200 TestAcc 0.8786 0.8950
epoch 1000 LossPred 0.2657 LossAtt 0.2726 TrainAcc 0.9200 TestAcc 0.8784 0.9000
epoch 1100 LossPred 0.2687 LossAtt 0.2723 TrainAcc 0.9100 TestAcc 0.8804 0.9050
epoch 1200 LossPred 0.2486 LossAtt 0.2544 TrainAcc 0.9400 TestAcc 0.9084 0.8800
epoch 1300 LossPred 0.2411 LossAtt 0.2533 TrainAcc 0.9200 TestAcc 0.9072 0.8750
epoch 1400 LossPred 0.1838 LossAtt 0.2531 TrainAcc 0.9300 TestAcc 0.8939 0.9050
epoch 1500 LossPred 0.2019 LossAtt 0.2406 TrainAcc 0.9300 TestAcc 0.8829 0.9150
epoch 1600 LossPred 0.1617 LossAtt 0.2329 TrainAcc 0.9500 TestAcc 0.8959 0.9300
epoch 1700 LossPred 0.1730 LossAtt 0.2257 TrainAcc 0.9400 TestAcc 0.9252 0.9300
epoch 1800 LossPred 0.1386 LossAtt 0.2377 TrainAcc 0.9500 TestAcc 0.9354 0.9200
epoch 1900 LossPred 0.1298 LossAtt 0.2345 TrainAcc 0.9600 TestAcc 0.9284 0.9200
epoch 2000 LossPred 0.1362 LossAtt 0.2348 TrainAcc 0.9600 TestAcc 0.9259 0.9300
epoch 2100 LossPred 0.1445 LossAtt 0.2367 TrainAcc 0.9600 TestAcc 0.9429 0.9450
epoch 2200 LossPred 0.1825 LossAtt 0.2338 TrainAcc 0.9200 TestAcc 0.9289 0.9300
epoch 2300 LossPred 0.1254 LossAtt 0.2505 TrainAcc 0.9600 TestAcc 0.9550 0.9350
epoch 2400 LossPred 0.1353 LossAtt 0.2832 TrainAcc 0.9500 TestAcc 0.9322 0.9250
epoch 2500 LossPred 0.0978 LossAtt 0.2714 TrainAcc 0.9500 TestAcc 0.9632 0.9500
Optimization Finished!
********** replication  56  **********
epoch   0 LossPred 1.0185 LossAtt 1.0316 TrainAcc 0.4800 TestAcc 0.4797 0.4850
epoch 100 LossPred 0.8891 LossAtt 0.3407 TrainAcc 0.6400 TestAcc 0.5863 0.6350
epoch 200 LossPred 0.4044 LossAtt 0.3873 TrainAcc 0.8900 TestAcc 0.8443 0.8800
epoch 300 LossPred 0.2763 LossAtt 0.3535 TrainAcc 0.9200 TestAcc 0.8759 0.8900
epoch 400 LossPred 0.1671 LossAtt 0.3544 TrainAcc 0.9600 TestAcc 0.8791 0.8900
epoch 500 LossPred 0.1778 LossAtt 0.3216 TrainAcc 0.9500 TestAcc 0.8916 0.9050
epoch 600 LossPred 0.2036 LossAtt 0.3341 TrainAcc 0.9300 TestAcc 0.8836 0.9200
epoch 700 LossPred 0.3138 LossAtt 0.3557 TrainAcc 0.9000 TestAcc 0.8403 0.8700
epoch 800 LossPred 0.2300 LossAtt 0.3464 TrainAcc 0.9200 TestAcc 0.8819 0.9300
epoch 900 LossPred 0.2500 LossAtt 0.3453 TrainAcc 0.9100 TestAcc 0.8769 0.9300
epoch 1000 LossPred 0.1277 LossAtt 0.3566 TrainAcc 0.9800 TestAcc 0.8926 0.9200
epoch 1100 LossPred 0.1757 LossAtt 0.3429 TrainAcc 0.9500 TestAcc 0.8591 0.8750
epoch 1200 LossPred 0.1364 LossAtt 0.3305 TrainAcc 0.9600 TestAcc 0.8906 0.9400
epoch 1300 LossPred 0.1217 LossAtt 0.3265 TrainAcc 0.9700 TestAcc 0.8929 0.9350
epoch 1400 LossPred 0.1064 LossAtt 0.2908 TrainAcc 0.9800 TestAcc 0.8894 0.9500
epoch 1500 LossPred 0.1571 LossAtt 0.3072 TrainAcc 0.9600 TestAcc 0.8876 0.9450
epoch 1600 LossPred 0.1752 LossAtt 0.3118 TrainAcc 0.9400 TestAcc 0.8946 0.9350
epoch 1700 LossPred 0.1704 LossAtt 0.3011 TrainAcc 0.9500 TestAcc 0.8546 0.9100
epoch 1800 LossPred 0.2355 LossAtt 0.2929 TrainAcc 0.9100 TestAcc 0.8821 0.9200
epoch 1900 LossPred 0.1326 LossAtt 0.2952 TrainAcc 0.9600 TestAcc 0.8659 0.9300
epoch 2000 LossPred 0.2197 LossAtt 0.3042 TrainAcc 0.9300 TestAcc 0.8814 0.9250
epoch 2100 LossPred 0.1027 LossAtt 0.3086 TrainAcc 0.9700 TestAcc 0.8656 0.9400
epoch 2200 LossPred 0.0703 LossAtt 0.2872 TrainAcc 0.9900 TestAcc 0.8921 0.9550
epoch 2300 LossPred 0.0672 LossAtt 0.2961 TrainAcc 0.9900 TestAcc 0.8819 0.9450
epoch 2400 LossPred 0.0692 LossAtt 0.3099 TrainAcc 0.9900 TestAcc 0.8761 0.9400
epoch 2500 LossPred 0.0487 LossAtt 0.3012 TrainAcc 0.9900 TestAcc 0.8899 0.9550
Optimization Finished!
********** replication  57  **********
epoch   0 LossPred 1.2069 LossAtt 1.0823 TrainAcc 0.4200 TestAcc 0.4422 0.4600
epoch 100 LossPred 0.9035 LossAtt 0.3842 TrainAcc 0.6600 TestAcc 0.6416 0.6600
epoch 200 LossPred 0.5714 LossAtt 0.4237 TrainAcc 0.8400 TestAcc 0.8161 0.8250
epoch 300 LossPred 0.3701 LossAtt 0.4514 TrainAcc 0.9200 TestAcc 0.8529 0.8550
epoch 400 LossPred 0.2510 LossAtt 0.4198 TrainAcc 0.9400 TestAcc 0.8539 0.8300
epoch 500 LossPred 0.1980 LossAtt 0.4140 TrainAcc 0.9500 TestAcc 0.8636 0.8550
epoch 600 LossPred 0.1893 LossAtt 0.3857 TrainAcc 0.9500 TestAcc 0.8604 0.8600
epoch 700 LossPred 0.1852 LossAtt 0.3758 TrainAcc 0.9500 TestAcc 0.8574 0.8400
epoch 800 LossPred 0.1699 LossAtt 0.3587 TrainAcc 0.9600 TestAcc 0.8706 0.8750
epoch 900 LossPred 0.2036 LossAtt 0.3479 TrainAcc 0.9300 TestAcc 0.8509 0.8700
epoch 1000 LossPred 0.1482 LossAtt 0.3597 TrainAcc 0.9500 TestAcc 0.8691 0.9050
epoch 1100 LossPred 0.1385 LossAtt 0.3416 TrainAcc 0.9500 TestAcc 0.8706 0.9050
epoch 1200 LossPred 0.1435 LossAtt 0.3416 TrainAcc 0.9500 TestAcc 0.8679 0.9150
epoch 1300 LossPred 0.1458 LossAtt 0.3451 TrainAcc 0.9600 TestAcc 0.8596 0.9100
epoch 1400 LossPred 0.1486 LossAtt 0.3467 TrainAcc 0.9600 TestAcc 0.8751 0.9350
epoch 1500 LossPred 0.1859 LossAtt 0.3446 TrainAcc 0.9400 TestAcc 0.8466 0.8800
epoch 1600 LossPred 0.1275 LossAtt 0.3516 TrainAcc 0.9700 TestAcc 0.8739 0.9500
epoch 1700 LossPred 0.1187 LossAtt 0.3554 TrainAcc 0.9700 TestAcc 0.8819 0.9450
epoch 1800 LossPred 0.2126 LossAtt 0.3676 TrainAcc 0.9100 TestAcc 0.8871 0.9250
epoch 1900 LossPred 0.0825 LossAtt 0.3512 TrainAcc 0.9800 TestAcc 0.9052 0.9650
epoch 2000 LossPred 0.0694 LossAtt 0.3439 TrainAcc 1.0000 TestAcc 0.9017 0.9900
Optimization Finished!
********** replication  58  **********
epoch   0 LossPred 1.0631 LossAtt 1.0349 TrainAcc 0.4500 TestAcc 0.5010 0.4700
epoch 100 LossPred 0.9205 LossAtt 0.3567 TrainAcc 0.5900 TestAcc 0.5913 0.5900
epoch 200 LossPred 0.6577 LossAtt 0.3480 TrainAcc 0.7700 TestAcc 0.7563 0.7700
epoch 300 LossPred 0.4668 LossAtt 0.2977 TrainAcc 0.8600 TestAcc 0.8291 0.8350
epoch 400 LossPred 0.3881 LossAtt 0.3000 TrainAcc 0.8800 TestAcc 0.8531 0.8200
epoch 500 LossPred 0.4632 LossAtt 0.2981 TrainAcc 0.8500 TestAcc 0.8026 0.8200
epoch 600 LossPred 0.6201 LossAtt 0.2908 TrainAcc 0.7700 TestAcc 0.7550 0.7900
epoch 700 LossPred 0.4039 LossAtt 0.2956 TrainAcc 0.8700 TestAcc 0.8256 0.8400
epoch 800 LossPred 0.3765 LossAtt 0.2863 TrainAcc 0.8800 TestAcc 0.8411 0.8400
epoch 900 LossPred 0.4448 LossAtt 0.2922 TrainAcc 0.8500 TestAcc 0.8208 0.8450
epoch 1000 LossPred 0.3508 LossAtt 0.3002 TrainAcc 0.8700 TestAcc 0.8326 0.8450
epoch 1100 LossPred 0.4787 LossAtt 0.2888 TrainAcc 0.8200 TestAcc 0.8391 0.8350
epoch 1200 LossPred 0.4033 LossAtt 0.2765 TrainAcc 0.8700 TestAcc 0.8251 0.8450
epoch 1300 LossPred 0.4072 LossAtt 0.2691 TrainAcc 0.8500 TestAcc 0.8381 0.8450
epoch 1400 LossPred 0.3262 LossAtt 0.2584 TrainAcc 0.8900 TestAcc 0.8551 0.8500
epoch 1500 LossPred 0.4892 LossAtt 0.2476 TrainAcc 0.8500 TestAcc 0.7875 0.8200
epoch 1600 LossPred 0.3011 LossAtt 0.2484 TrainAcc 0.8900 TestAcc 0.8554 0.8750
epoch 1700 LossPred 0.3037 LossAtt 0.2584 TrainAcc 0.9200 TestAcc 0.8456 0.8700
epoch 1800 LossPred 0.3659 LossAtt 0.2523 TrainAcc 0.8800 TestAcc 0.8268 0.8550
epoch 1900 LossPred 0.3663 LossAtt 0.2556 TrainAcc 0.8800 TestAcc 0.8193 0.8700
epoch 2000 LossPred 0.5337 LossAtt 0.2522 TrainAcc 0.8400 TestAcc 0.7778 0.8150
epoch 2100 LossPred 0.3131 LossAtt 0.2679 TrainAcc 0.9000 TestAcc 0.8328 0.8700
epoch 2200 LossPred 0.2787 LossAtt 0.2797 TrainAcc 0.9200 TestAcc 0.8473 0.8800
epoch 2300 LossPred 0.2668 LossAtt 0.2800 TrainAcc 0.9300 TestAcc 0.8504 0.8850
epoch 2400 LossPred 0.2517 LossAtt 0.2706 TrainAcc 0.9100 TestAcc 0.8576 0.8850
epoch 2500 LossPred 0.2493 LossAtt 0.2738 TrainAcc 0.9100 TestAcc 0.8514 0.9000
Optimization Finished!
********** replication  59  **********
epoch   0 LossPred 1.0203 LossAtt 1.0359 TrainAcc 0.6000 TestAcc 0.4952 0.5900
epoch 100 LossPred 0.9143 LossAtt 0.3873 TrainAcc 0.6200 TestAcc 0.4877 0.6050
epoch 200 LossPred 0.7881 LossAtt 0.4617 TrainAcc 0.7200 TestAcc 0.5658 0.7000
epoch 300 LossPred 0.2351 LossAtt 0.4967 TrainAcc 0.9300 TestAcc 0.8994 0.9200
epoch 400 LossPred 0.2161 LossAtt 0.4601 TrainAcc 0.9400 TestAcc 0.9124 0.9200
epoch 500 LossPred 0.1010 LossAtt 0.4464 TrainAcc 0.9900 TestAcc 0.9369 0.9500
epoch 600 LossPred 0.0735 LossAtt 0.4461 TrainAcc 0.9900 TestAcc 0.9282 0.9500
epoch 700 LossPred 0.2514 LossAtt 0.4117 TrainAcc 0.8800 TestAcc 0.8786 0.8750
epoch 800 LossPred 0.0455 LossAtt 0.4085 TrainAcc 0.9900 TestAcc 0.9202 0.9450
epoch 900 LossPred 0.0342 LossAtt 0.3979 TrainAcc 1.0000 TestAcc 0.9232 0.9600
Optimization Finished!
********** replication  60  **********
epoch   0 LossPred 1.0320 LossAtt 1.0285 TrainAcc 0.4400 TestAcc 0.5040 0.4650
epoch 100 LossPred 0.8640 LossAtt 0.2536 TrainAcc 0.6700 TestAcc 0.5878 0.6700
epoch 200 LossPred 0.5179 LossAtt 0.3665 TrainAcc 0.7700 TestAcc 0.7575 0.7950
epoch 300 LossPred 0.4868 LossAtt 0.3313 TrainAcc 0.8500 TestAcc 0.8208 0.8450
epoch 400 LossPred 0.2625 LossAtt 0.2940 TrainAcc 0.9300 TestAcc 0.8729 0.8850
epoch 500 LossPred 0.6426 LossAtt 0.3182 TrainAcc 0.7300 TestAcc 0.7540 0.7350
epoch 600 LossPred 0.3763 LossAtt 0.2899 TrainAcc 0.8700 TestAcc 0.8408 0.8900
epoch 700 LossPred 0.3315 LossAtt 0.2694 TrainAcc 0.8800 TestAcc 0.8519 0.8850
epoch 800 LossPred 0.2892 LossAtt 0.2613 TrainAcc 0.8900 TestAcc 0.8591 0.8850
epoch 900 LossPred 0.2845 LossAtt 0.2442 TrainAcc 0.8900 TestAcc 0.8654 0.8950
epoch 1000 LossPred 0.2240 LossAtt 0.2519 TrainAcc 0.9600 TestAcc 0.8584 0.9200
epoch 1100 LossPred 0.2940 LossAtt 0.2474 TrainAcc 0.9100 TestAcc 0.8438 0.9000
epoch 1200 LossPred 0.3547 LossAtt 0.2255 TrainAcc 0.8700 TestAcc 0.8011 0.8550
epoch 1300 LossPred 0.1907 LossAtt 0.2110 TrainAcc 0.9400 TestAcc 0.8266 0.9150
epoch 1400 LossPred 0.2993 LossAtt 0.2116 TrainAcc 0.8700 TestAcc 0.8076 0.8750
epoch 1500 LossPred 0.1389 LossAtt 0.1960 TrainAcc 0.9500 TestAcc 0.8316 0.9250
epoch 1600 LossPred 0.2068 LossAtt 0.1915 TrainAcc 0.9400 TestAcc 0.8266 0.9150
epoch 1700 LossPred 0.1370 LossAtt 0.1880 TrainAcc 0.9600 TestAcc 0.8423 0.9350
epoch 1800 LossPred 0.1564 LossAtt 0.1954 TrainAcc 0.9600 TestAcc 0.8446 0.9200
epoch 1900 LossPred 0.1597 LossAtt 0.1916 TrainAcc 0.9600 TestAcc 0.8418 0.9450
epoch 2000 LossPred 0.1717 LossAtt 0.1866 TrainAcc 0.9500 TestAcc 0.8443 0.9400
epoch 2100 LossPred 0.1172 LossAtt 0.1837 TrainAcc 0.9700 TestAcc 0.8391 0.9400
epoch 2200 LossPred 0.1562 LossAtt 0.1832 TrainAcc 0.9600 TestAcc 0.8318 0.9500
epoch 2300 LossPred 0.1371 LossAtt 0.1882 TrainAcc 0.9600 TestAcc 0.8426 0.9450
epoch 2400 LossPred 0.1626 LossAtt 0.1897 TrainAcc 0.9600 TestAcc 0.8418 0.9550
epoch 2500 LossPred 0.2713 LossAtt 0.1905 TrainAcc 0.8900 TestAcc 0.8156 0.8850
Optimization Finished!
********** replication  61  **********
epoch   0 LossPred 0.9859 LossAtt 1.0122 TrainAcc 0.5800 TestAcc 0.5173 0.5700
epoch 100 LossPred 0.8313 LossAtt 0.4352 TrainAcc 0.7000 TestAcc 0.6354 0.6700
epoch 200 LossPred 0.3197 LossAtt 0.4093 TrainAcc 0.9200 TestAcc 0.8636 0.8950
epoch 300 LossPred 0.2217 LossAtt 0.4124 TrainAcc 0.9400 TestAcc 0.8896 0.9150
epoch 400 LossPred 0.1436 LossAtt 0.4187 TrainAcc 0.9600 TestAcc 0.8959 0.9400
epoch 500 LossPred 0.1474 LossAtt 0.4098 TrainAcc 0.9600 TestAcc 0.8914 0.9600
epoch 600 LossPred 0.1065 LossAtt 0.3876 TrainAcc 0.9800 TestAcc 0.8979 0.9200
epoch 700 LossPred 0.0797 LossAtt 0.3871 TrainAcc 0.9800 TestAcc 0.9162 0.9400
epoch 800 LossPred 0.1113 LossAtt 0.3760 TrainAcc 0.9700 TestAcc 0.9064 0.9150
epoch 900 LossPred 0.0839 LossAtt 0.3763 TrainAcc 0.9800 TestAcc 0.9159 0.9550
epoch 1000 LossPred 0.0728 LossAtt 0.3789 TrainAcc 0.9800 TestAcc 0.9227 0.9500
epoch 1100 LossPred 0.0633 LossAtt 0.3725 TrainAcc 0.9800 TestAcc 0.9159 0.9300
epoch 1200 LossPred 0.0429 LossAtt 0.3679 TrainAcc 1.0000 TestAcc 0.9267 0.9450
Optimization Finished!
********** replication  62  **********
epoch   0 LossPred 1.0783 LossAtt 1.0263 TrainAcc 0.5400 TestAcc 0.5703 0.5600
epoch 100 LossPred 0.8942 LossAtt 0.3981 TrainAcc 0.6800 TestAcc 0.6772 0.6850
epoch 200 LossPred 0.6381 LossAtt 0.3854 TrainAcc 0.7800 TestAcc 0.8193 0.7700
epoch 300 LossPred 0.4148 LossAtt 0.3558 TrainAcc 0.8700 TestAcc 0.8811 0.8600
epoch 400 LossPred 0.3904 LossAtt 0.3369 TrainAcc 0.8800 TestAcc 0.8726 0.8450
epoch 500 LossPred 0.3491 LossAtt 0.3206 TrainAcc 0.8800 TestAcc 0.8681 0.8800
epoch 600 LossPred 0.3414 LossAtt 0.3126 TrainAcc 0.8700 TestAcc 0.8701 0.8750
epoch 700 LossPred 0.3267 LossAtt 0.2924 TrainAcc 0.9000 TestAcc 0.8734 0.8850
epoch 800 LossPred 0.4378 LossAtt 0.2788 TrainAcc 0.8300 TestAcc 0.8511 0.8350
epoch 900 LossPred 0.3369 LossAtt 0.2761 TrainAcc 0.8800 TestAcc 0.8746 0.8850
epoch 1000 LossPred 0.3178 LossAtt 0.2567 TrainAcc 0.9000 TestAcc 0.8746 0.8900
epoch 1100 LossPred 0.2851 LossAtt 0.2579 TrainAcc 0.9200 TestAcc 0.8731 0.8900
epoch 1200 LossPred 0.2890 LossAtt 0.2529 TrainAcc 0.9100 TestAcc 0.8769 0.8950
epoch 1300 LossPred 0.3095 LossAtt 0.2383 TrainAcc 0.9000 TestAcc 0.8684 0.9050
epoch 1400 LossPred 0.3059 LossAtt 0.2413 TrainAcc 0.9000 TestAcc 0.8726 0.8700
epoch 1500 LossPred 0.3197 LossAtt 0.2362 TrainAcc 0.8900 TestAcc 0.8629 0.9000
epoch 1600 LossPred 0.2656 LossAtt 0.2369 TrainAcc 0.9300 TestAcc 0.8744 0.8950
epoch 1700 LossPred 0.2658 LossAtt 0.2287 TrainAcc 0.9300 TestAcc 0.8761 0.9100
epoch 1800 LossPred 0.4448 LossAtt 0.2347 TrainAcc 0.8500 TestAcc 0.8599 0.8350
epoch 1900 LossPred 0.3687 LossAtt 0.2368 TrainAcc 0.8600 TestAcc 0.8586 0.8500
epoch 2000 LossPred 0.2662 LossAtt 0.2355 TrainAcc 0.9100 TestAcc 0.8706 0.8700
epoch 2100 LossPred 0.3993 LossAtt 0.2157 TrainAcc 0.8600 TestAcc 0.8681 0.8600
epoch 2200 LossPred 0.3551 LossAtt 0.2108 TrainAcc 0.8700 TestAcc 0.8579 0.8800
epoch 2300 LossPred 0.4180 LossAtt 0.2170 TrainAcc 0.8400 TestAcc 0.8453 0.8750
epoch 2400 LossPred 0.2688 LossAtt 0.2159 TrainAcc 0.9300 TestAcc 0.8799 0.9100
epoch 2500 LossPred 0.2785 LossAtt 0.2095 TrainAcc 0.9200 TestAcc 0.8761 0.9200
Optimization Finished!
********** replication  63  **********
epoch   0 LossPred 1.0100 LossAtt 1.0166 TrainAcc 0.5200 TestAcc 0.4800 0.5200
epoch 100 LossPred 0.9420 LossAtt 0.3039 TrainAcc 0.6000 TestAcc 0.6069 0.6200
epoch 200 LossPred 0.7745 LossAtt 0.4933 TrainAcc 0.7400 TestAcc 0.6924 0.7000
epoch 300 LossPred 0.3277 LossAtt 0.4417 TrainAcc 0.9200 TestAcc 0.8736 0.8800
epoch 400 LossPred 0.2890 LossAtt 0.4241 TrainAcc 0.9300 TestAcc 0.8864 0.8900
epoch 500 LossPred 0.2820 LossAtt 0.3953 TrainAcc 0.9100 TestAcc 0.8854 0.8900
epoch 600 LossPred 0.3365 LossAtt 0.3915 TrainAcc 0.8600 TestAcc 0.8706 0.8850
epoch 700 LossPred 0.2485 LossAtt 0.3835 TrainAcc 0.9300 TestAcc 0.8916 0.9050
epoch 800 LossPred 0.3296 LossAtt 0.3710 TrainAcc 0.8600 TestAcc 0.8711 0.8850
epoch 900 LossPred 0.3620 LossAtt 0.3582 TrainAcc 0.8600 TestAcc 0.8556 0.8900
epoch 1000 LossPred 0.3856 LossAtt 0.3675 TrainAcc 0.8600 TestAcc 0.8476 0.8600
epoch 1100 LossPred 0.2598 LossAtt 0.3510 TrainAcc 0.9300 TestAcc 0.8846 0.8950
epoch 1200 LossPred 0.2499 LossAtt 0.3510 TrainAcc 0.9300 TestAcc 0.8874 0.9100
epoch 1300 LossPred 0.2299 LossAtt 0.3467 TrainAcc 0.9500 TestAcc 0.8889 0.9050
epoch 1400 LossPred 0.2486 LossAtt 0.3486 TrainAcc 0.9100 TestAcc 0.8811 0.9050
epoch 1500 LossPred 0.2457 LossAtt 0.3338 TrainAcc 0.9100 TestAcc 0.8814 0.9100
epoch 1600 LossPred 0.2242 LossAtt 0.3368 TrainAcc 0.9500 TestAcc 0.8889 0.9050
epoch 1700 LossPred 0.2410 LossAtt 0.3350 TrainAcc 0.9000 TestAcc 0.8856 0.9050
epoch 1800 LossPred 0.2560 LossAtt 0.3268 TrainAcc 0.9100 TestAcc 0.8754 0.8950
epoch 1900 LossPred 0.2211 LossAtt 0.3367 TrainAcc 0.9400 TestAcc 0.8929 0.9150
epoch 2000 LossPred 0.2234 LossAtt 0.3198 TrainAcc 0.9500 TestAcc 0.8826 0.9050
epoch 2100 LossPred 0.2106 LossAtt 0.3155 TrainAcc 0.9500 TestAcc 0.8936 0.9100
epoch 2200 LossPred 0.2172 LossAtt 0.3115 TrainAcc 0.9400 TestAcc 0.8849 0.9050
epoch 2300 LossPred 0.2097 LossAtt 0.3079 TrainAcc 0.9500 TestAcc 0.8779 0.8900
epoch 2400 LossPred 0.2644 LossAtt 0.3038 TrainAcc 0.9200 TestAcc 0.8684 0.8950
epoch 2500 LossPred 0.1859 LossAtt 0.3006 TrainAcc 0.9600 TestAcc 0.8734 0.8850
Optimization Finished!
********** replication  64  **********
epoch   0 LossPred 0.9912 LossAtt 1.0319 TrainAcc 0.5700 TestAcc 0.5603 0.5450
epoch 100 LossPred 0.7928 LossAtt 0.3450 TrainAcc 0.6500 TestAcc 0.6396 0.6550
epoch 200 LossPred 0.3629 LossAtt 0.3682 TrainAcc 0.9100 TestAcc 0.8536 0.8550
epoch 300 LossPred 0.3425 LossAtt 0.3613 TrainAcc 0.8800 TestAcc 0.8486 0.8700
epoch 400 LossPred 0.2429 LossAtt 0.3287 TrainAcc 0.9200 TestAcc 0.8704 0.8700
epoch 500 LossPred 0.2256 LossAtt 0.3334 TrainAcc 0.9400 TestAcc 0.8689 0.8950
epoch 600 LossPred 0.2079 LossAtt 0.3249 TrainAcc 0.9400 TestAcc 0.8686 0.9100
epoch 700 LossPred 0.2538 LossAtt 0.3257 TrainAcc 0.9200 TestAcc 0.8498 0.9000
epoch 800 LossPred 0.1842 LossAtt 0.3282 TrainAcc 0.9500 TestAcc 0.8804 0.9200
epoch 900 LossPred 0.2051 LossAtt 0.3337 TrainAcc 0.9400 TestAcc 0.8669 0.9150
epoch 1000 LossPred 0.2623 LossAtt 0.3214 TrainAcc 0.9300 TestAcc 0.8456 0.9000
epoch 1100 LossPred 0.2235 LossAtt 0.3032 TrainAcc 0.9400 TestAcc 0.8689 0.9100
epoch 1200 LossPred 0.1367 LossAtt 0.3029 TrainAcc 0.9700 TestAcc 0.8964 0.9350
epoch 1300 LossPred 0.3063 LossAtt 0.3102 TrainAcc 0.8600 TestAcc 0.8799 0.8700
epoch 1400 LossPred 0.1281 LossAtt 0.2982 TrainAcc 0.9500 TestAcc 0.9052 0.9350
epoch 1500 LossPred 0.2746 LossAtt 0.2970 TrainAcc 0.9000 TestAcc 0.8871 0.8700
epoch 1600 LossPred 0.1885 LossAtt 0.2846 TrainAcc 0.9400 TestAcc 0.8759 0.9150
epoch 1700 LossPred 0.1280 LossAtt 0.2680 TrainAcc 0.9400 TestAcc 0.9157 0.9500
epoch 1800 LossPred 0.1864 LossAtt 0.2745 TrainAcc 0.9300 TestAcc 0.9084 0.9100
epoch 1900 LossPred 0.1655 LossAtt 0.2676 TrainAcc 0.9500 TestAcc 0.9189 0.9150
epoch 2000 LossPred 0.1696 LossAtt 0.2559 TrainAcc 0.9300 TestAcc 0.9174 0.9200
epoch 2100 LossPred 0.1980 LossAtt 0.2457 TrainAcc 0.9400 TestAcc 0.9077 0.9050
epoch 2200 LossPred 0.1433 LossAtt 0.2381 TrainAcc 0.9600 TestAcc 0.9159 0.9400
epoch 2300 LossPred 0.1460 LossAtt 0.2298 TrainAcc 0.9400 TestAcc 0.9062 0.9300
epoch 2400 LossPred 0.2373 LossAtt 0.2457 TrainAcc 0.8900 TestAcc 0.8571 0.8900
epoch 2500 LossPred 0.2562 LossAtt 0.2372 TrainAcc 0.9000 TestAcc 0.8501 0.9000
Optimization Finished!
********** replication  65  **********
epoch   0 LossPred 1.0838 LossAtt 1.0163 TrainAcc 0.4600 TestAcc 0.5696 0.4700
epoch 100 LossPred 0.7979 LossAtt 0.4129 TrainAcc 0.6900 TestAcc 0.5726 0.7050
epoch 200 LossPred 0.4030 LossAtt 0.3860 TrainAcc 0.8500 TestAcc 0.8381 0.8400
epoch 300 LossPred 0.3575 LossAtt 0.3516 TrainAcc 0.8600 TestAcc 0.8556 0.8350
epoch 400 LossPred 0.4292 LossAtt 0.3529 TrainAcc 0.8400 TestAcc 0.8078 0.7900
epoch 500 LossPred 0.4111 LossAtt 0.3421 TrainAcc 0.8500 TestAcc 0.8111 0.7950
epoch 600 LossPred 0.3411 LossAtt 0.3283 TrainAcc 0.8900 TestAcc 0.8609 0.8400
epoch 700 LossPred 0.2526 LossAtt 0.3387 TrainAcc 0.9200 TestAcc 0.8684 0.8700
epoch 800 LossPred 0.2924 LossAtt 0.3436 TrainAcc 0.8900 TestAcc 0.8821 0.8650
epoch 900 LossPred 0.2982 LossAtt 0.3406 TrainAcc 0.8900 TestAcc 0.8529 0.8350
epoch 1000 LossPred 0.2547 LossAtt 0.3392 TrainAcc 0.9100 TestAcc 0.8819 0.8750
epoch 1100 LossPred 0.2735 LossAtt 0.3441 TrainAcc 0.9100 TestAcc 0.8864 0.8850
epoch 1200 LossPred 0.2513 LossAtt 0.3440 TrainAcc 0.9300 TestAcc 0.8671 0.8850
epoch 1300 LossPred 0.5712 LossAtt 0.3345 TrainAcc 0.8100 TestAcc 0.7460 0.7700
epoch 1400 LossPred 0.4087 LossAtt 0.3130 TrainAcc 0.8700 TestAcc 0.7973 0.8000
epoch 1500 LossPred 0.2657 LossAtt 0.3210 TrainAcc 0.9200 TestAcc 0.8574 0.8900
epoch 1600 LossPred 0.2839 LossAtt 0.3089 TrainAcc 0.9200 TestAcc 0.8524 0.8900
epoch 1700 LossPred 0.2525 LossAtt 0.3064 TrainAcc 0.9200 TestAcc 0.8621 0.8900
epoch 1800 LossPred 0.3222 LossAtt 0.3043 TrainAcc 0.8800 TestAcc 0.8504 0.8600
epoch 1900 LossPred 0.2956 LossAtt 0.2922 TrainAcc 0.9000 TestAcc 0.8631 0.8850
epoch 2000 LossPred 0.2823 LossAtt 0.3088 TrainAcc 0.9100 TestAcc 0.8559 0.8750
epoch 2100 LossPred 0.3368 LossAtt 0.2919 TrainAcc 0.8700 TestAcc 0.8246 0.8650
epoch 2200 LossPred 0.3700 LossAtt 0.2914 TrainAcc 0.8600 TestAcc 0.8431 0.8450
epoch 2300 LossPred 0.2941 LossAtt 0.2833 TrainAcc 0.9100 TestAcc 0.8661 0.8700
epoch 2400 LossPred 0.3733 LossAtt 0.2787 TrainAcc 0.8500 TestAcc 0.8181 0.8650
epoch 2500 LossPred 0.2826 LossAtt 0.2844 TrainAcc 0.9000 TestAcc 0.8478 0.8700
Optimization Finished!
********** replication  66  **********
epoch   0 LossPred 0.9978 LossAtt 1.0492 TrainAcc 0.6000 TestAcc 0.5123 0.5800
epoch 100 LossPred 0.8554 LossAtt 0.4217 TrainAcc 0.6800 TestAcc 0.6259 0.6850
epoch 200 LossPred 0.4845 LossAtt 0.4287 TrainAcc 0.8400 TestAcc 0.8456 0.8100
epoch 300 LossPred 0.3565 LossAtt 0.3604 TrainAcc 0.8700 TestAcc 0.8651 0.8550
epoch 400 LossPred 0.3373 LossAtt 0.3507 TrainAcc 0.8900 TestAcc 0.8674 0.8750
epoch 500 LossPred 0.4818 LossAtt 0.3587 TrainAcc 0.8300 TestAcc 0.8098 0.8350
epoch 600 LossPred 0.2325 LossAtt 0.3690 TrainAcc 0.9300 TestAcc 0.8896 0.9150
epoch 700 LossPred 0.2556 LossAtt 0.3525 TrainAcc 0.9200 TestAcc 0.8679 0.8750
epoch 800 LossPred 0.5578 LossAtt 0.3524 TrainAcc 0.7900 TestAcc 0.7888 0.8000
epoch 900 LossPred 0.1825 LossAtt 0.3487 TrainAcc 0.9500 TestAcc 0.8896 0.9200
epoch 1000 LossPred 0.1709 LossAtt 0.3445 TrainAcc 0.9500 TestAcc 0.8961 0.9300
epoch 1100 LossPred 0.1915 LossAtt 0.3488 TrainAcc 0.9400 TestAcc 0.8929 0.9200
epoch 1200 LossPred 0.1739 LossAtt 0.3385 TrainAcc 0.9400 TestAcc 0.8796 0.9100
epoch 1300 LossPred 0.5805 LossAtt 0.3422 TrainAcc 0.8100 TestAcc 0.7965 0.8100
epoch 1400 LossPred 0.1805 LossAtt 0.3428 TrainAcc 0.9500 TestAcc 0.8926 0.9200
epoch 1500 LossPred 0.1714 LossAtt 0.3325 TrainAcc 0.9500 TestAcc 0.8934 0.9000
epoch 1600 LossPred 0.1454 LossAtt 0.3244 TrainAcc 0.9700 TestAcc 0.9009 0.9400
epoch 1700 LossPred 0.1832 LossAtt 0.3226 TrainAcc 0.9500 TestAcc 0.9034 0.9050
epoch 1800 LossPred 0.2208 LossAtt 0.3358 TrainAcc 0.9300 TestAcc 0.9089 0.9150
epoch 1900 LossPred 0.1811 LossAtt 0.3303 TrainAcc 0.9600 TestAcc 0.8911 0.9150
epoch 2000 LossPred 0.1506 LossAtt 0.3245 TrainAcc 0.9600 TestAcc 0.9009 0.9200
epoch 2100 LossPred 0.1496 LossAtt 0.3229 TrainAcc 0.9500 TestAcc 0.9089 0.9300
epoch 2200 LossPred 0.1499 LossAtt 0.3217 TrainAcc 0.9600 TestAcc 0.9014 0.9250
epoch 2300 LossPred 0.6614 LossAtt 0.3110 TrainAcc 0.7700 TestAcc 0.7675 0.7700
epoch 2400 LossPred 0.2191 LossAtt 0.3120 TrainAcc 0.9200 TestAcc 0.8609 0.9200
epoch 2500 LossPred 0.1393 LossAtt 0.3069 TrainAcc 0.9400 TestAcc 0.8986 0.9350
Optimization Finished!
********** replication  67  **********
epoch   0 LossPred 1.1078 LossAtt 1.0158 TrainAcc 0.4300 TestAcc 0.4975 0.4350
epoch 100 LossPred 0.8706 LossAtt 0.2980 TrainAcc 0.6500 TestAcc 0.5818 0.6850
epoch 200 LossPred 0.4361 LossAtt 0.3987 TrainAcc 0.8600 TestAcc 0.8371 0.8300
epoch 300 LossPred 0.2107 LossAtt 0.3778 TrainAcc 0.9700 TestAcc 0.8879 0.9300
epoch 400 LossPred 0.2709 LossAtt 0.3667 TrainAcc 0.8900 TestAcc 0.8806 0.8500
epoch 500 LossPred 0.2184 LossAtt 0.3565 TrainAcc 0.9200 TestAcc 0.8839 0.9050
epoch 600 LossPred 0.1901 LossAtt 0.3348 TrainAcc 0.9500 TestAcc 0.8854 0.9100
epoch 700 LossPred 0.3866 LossAtt 0.3139 TrainAcc 0.8600 TestAcc 0.8303 0.8400
epoch 800 LossPred 0.3714 LossAtt 0.3281 TrainAcc 0.8600 TestAcc 0.8308 0.8050
epoch 900 LossPred 0.3906 LossAtt 0.3128 TrainAcc 0.8800 TestAcc 0.8306 0.7950
epoch 1000 LossPred 0.2384 LossAtt 0.2867 TrainAcc 0.9400 TestAcc 0.8906 0.8900
epoch 1100 LossPred 0.1766 LossAtt 0.2494 TrainAcc 0.9700 TestAcc 0.8891 0.9150
epoch 1200 LossPred 0.3133 LossAtt 0.2773 TrainAcc 0.8700 TestAcc 0.8418 0.8550
epoch 1300 LossPred 0.3105 LossAtt 0.2799 TrainAcc 0.8900 TestAcc 0.8559 0.8850
epoch 1400 LossPred 0.2093 LossAtt 0.2552 TrainAcc 0.9500 TestAcc 0.8816 0.9100
epoch 1500 LossPred 0.1948 LossAtt 0.2303 TrainAcc 0.9400 TestAcc 0.8989 0.8800
epoch 1600 LossPred 0.6080 LossAtt 0.2543 TrainAcc 0.8100 TestAcc 0.7568 0.7950
epoch 1700 LossPred 0.2743 LossAtt 0.2424 TrainAcc 0.9200 TestAcc 0.8704 0.8900
epoch 1800 LossPred 0.2264 LossAtt 0.2193 TrainAcc 0.9200 TestAcc 0.8861 0.8750
epoch 1900 LossPred 0.4044 LossAtt 0.2359 TrainAcc 0.8600 TestAcc 0.8276 0.8600
epoch 2000 LossPred 0.1902 LossAtt 0.2143 TrainAcc 0.9200 TestAcc 0.8986 0.8950
epoch 2100 LossPred 0.4869 LossAtt 0.2073 TrainAcc 0.8400 TestAcc 0.8156 0.8200
epoch 2200 LossPred 0.1684 LossAtt 0.2149 TrainAcc 0.9500 TestAcc 0.9117 0.9300
epoch 2300 LossPred 0.2872 LossAtt 0.2222 TrainAcc 0.9000 TestAcc 0.8636 0.8750
epoch 2400 LossPred 0.3706 LossAtt 0.2279 TrainAcc 0.8700 TestAcc 0.8403 0.8500
epoch 2500 LossPred 0.1778 LossAtt 0.2263 TrainAcc 0.9300 TestAcc 0.9129 0.9200
Optimization Finished!
********** replication  68  **********
epoch   0 LossPred 1.0144 LossAtt 1.0296 TrainAcc 0.4700 TestAcc 0.4855 0.4950
epoch 100 LossPred 0.8650 LossAtt 0.3325 TrainAcc 0.6800 TestAcc 0.6159 0.6500
epoch 200 LossPred 0.3949 LossAtt 0.3771 TrainAcc 0.8800 TestAcc 0.8428 0.8350
epoch 300 LossPred 0.2913 LossAtt 0.3482 TrainAcc 0.9300 TestAcc 0.8699 0.8850
epoch 400 LossPred 0.2986 LossAtt 0.3264 TrainAcc 0.8900 TestAcc 0.8854 0.8650
epoch 500 LossPred 0.2460 LossAtt 0.3118 TrainAcc 0.9300 TestAcc 0.8796 0.8900
epoch 600 LossPred 0.2760 LossAtt 0.2934 TrainAcc 0.9100 TestAcc 0.8729 0.8750
epoch 700 LossPred 0.2316 LossAtt 0.2801 TrainAcc 0.9200 TestAcc 0.9004 0.8700
epoch 800 LossPred 0.3754 LossAtt 0.2847 TrainAcc 0.8600 TestAcc 0.8869 0.8450
epoch 900 LossPred 0.2681 LossAtt 0.2685 TrainAcc 0.9200 TestAcc 0.8631 0.8850
epoch 1000 LossPred 0.2462 LossAtt 0.2765 TrainAcc 0.9300 TestAcc 0.8706 0.8900
epoch 1100 LossPred 0.1876 LossAtt 0.2511 TrainAcc 0.9400 TestAcc 0.8966 0.9150
epoch 1200 LossPred 0.2141 LossAtt 0.2569 TrainAcc 0.9300 TestAcc 0.8999 0.9100
epoch 1300 LossPred 0.4418 LossAtt 0.2482 TrainAcc 0.8400 TestAcc 0.8273 0.8450
epoch 1400 LossPred 0.5109 LossAtt 0.2690 TrainAcc 0.8300 TestAcc 0.8514 0.8300
epoch 1500 LossPred 0.2889 LossAtt 0.2890 TrainAcc 0.9000 TestAcc 0.8896 0.8900
epoch 1600 LossPred 0.2687 LossAtt 0.2703 TrainAcc 0.9100 TestAcc 0.8956 0.8850
epoch 1700 LossPred 0.2125 LossAtt 0.2649 TrainAcc 0.9300 TestAcc 0.8831 0.9250
epoch 1800 LossPred 0.3057 LossAtt 0.2661 TrainAcc 0.9000 TestAcc 0.8556 0.8900
epoch 1900 LossPred 0.1958 LossAtt 0.2629 TrainAcc 0.9500 TestAcc 0.8881 0.9350
epoch 2000 LossPred 0.2251 LossAtt 0.2897 TrainAcc 0.9200 TestAcc 0.8739 0.9150
epoch 2100 LossPred 0.1947 LossAtt 0.2819 TrainAcc 0.9500 TestAcc 0.8821 0.9300
epoch 2200 LossPred 0.1872 LossAtt 0.2797 TrainAcc 0.9400 TestAcc 0.8789 0.9300
epoch 2300 LossPred 0.2192 LossAtt 0.3205 TrainAcc 0.9100 TestAcc 0.8804 0.9050
epoch 2400 LossPred 0.1492 LossAtt 0.3105 TrainAcc 0.9400 TestAcc 0.8806 0.9350
epoch 2500 LossPred 0.2804 LossAtt 0.3028 TrainAcc 0.8900 TestAcc 0.8756 0.9000
Optimization Finished!
********** replication  69  **********
epoch   0 LossPred 0.9825 LossAtt 1.0125 TrainAcc 0.5900 TestAcc 0.5548 0.5650
epoch 100 LossPred 0.8652 LossAtt 0.3770 TrainAcc 0.6600 TestAcc 0.6441 0.6550
epoch 200 LossPred 0.7478 LossAtt 0.4912 TrainAcc 0.6900 TestAcc 0.5678 0.6850
epoch 300 LossPred 0.3360 LossAtt 0.6164 TrainAcc 0.8800 TestAcc 0.7868 0.8750
epoch 400 LossPred 0.1223 LossAtt 0.6344 TrainAcc 0.9800 TestAcc 0.8313 0.9150
epoch 500 LossPred 0.0651 LossAtt 0.6337 TrainAcc 0.9900 TestAcc 0.8376 0.9350
epoch 600 LossPred 0.0383 LossAtt 0.6130 TrainAcc 0.9900 TestAcc 0.8416 0.9600
epoch 700 LossPred 0.0247 LossAtt 0.6262 TrainAcc 0.9900 TestAcc 0.8481 0.9600
epoch 800 LossPred 0.0214 LossAtt 0.5983 TrainAcc 0.9900 TestAcc 0.8481 0.9450
epoch 900 LossPred 0.0141 LossAtt 0.6001 TrainAcc 1.0000 TestAcc 0.8551 0.9600
Optimization Finished!
********** replication  70  **********
epoch   0 LossPred 1.0987 LossAtt 1.0109 TrainAcc 0.3700 TestAcc 0.4537 0.4000
epoch 100 LossPred 0.8793 LossAtt 0.4110 TrainAcc 0.6500 TestAcc 0.5435 0.6450
epoch 200 LossPred 0.8268 LossAtt 0.3794 TrainAcc 0.7100 TestAcc 0.5766 0.7000
epoch 300 LossPred 0.2975 LossAtt 0.4688 TrainAcc 0.9100 TestAcc 0.8358 0.8800
epoch 400 LossPred 0.1360 LossAtt 0.4265 TrainAcc 0.9700 TestAcc 0.8776 0.9550
epoch 500 LossPred 0.1129 LossAtt 0.4233 TrainAcc 0.9700 TestAcc 0.8796 0.9700
epoch 600 LossPred 0.0520 LossAtt 0.4230 TrainAcc 1.0000 TestAcc 0.8679 0.9700
Optimization Finished!
********** replication  71  **********
epoch   0 LossPred 1.0313 LossAtt 1.0058 TrainAcc 0.4700 TestAcc 0.4622 0.4950
epoch 100 LossPred 0.9122 LossAtt 0.2259 TrainAcc 0.6400 TestAcc 0.5813 0.6400
epoch 200 LossPred 0.9089 LossAtt 0.1067 TrainAcc 0.6400 TestAcc 0.5813 0.6400
epoch 300 LossPred 0.8050 LossAtt 0.3880 TrainAcc 0.6800 TestAcc 0.6496 0.6950
epoch 400 LossPred 0.5216 LossAtt 0.2831 TrainAcc 0.8200 TestAcc 0.7888 0.7700
epoch 500 LossPred 0.4832 LossAtt 0.2856 TrainAcc 0.8300 TestAcc 0.8118 0.8100
epoch 600 LossPred 0.4580 LossAtt 0.2984 TrainAcc 0.8700 TestAcc 0.8081 0.7900
epoch 700 LossPred 0.2961 LossAtt 0.3362 TrainAcc 0.9000 TestAcc 0.8461 0.8450
epoch 800 LossPred 0.2226 LossAtt 0.3337 TrainAcc 0.9100 TestAcc 0.9034 0.9050
epoch 900 LossPred 0.2066 LossAtt 0.3439 TrainAcc 0.9200 TestAcc 0.8981 0.9200
epoch 1000 LossPred 0.1860 LossAtt 0.3432 TrainAcc 0.9400 TestAcc 0.8899 0.9400
epoch 1100 LossPred 0.1650 LossAtt 0.3218 TrainAcc 0.9400 TestAcc 0.8754 0.9200
epoch 1200 LossPred 0.1790 LossAtt 0.3427 TrainAcc 0.9400 TestAcc 0.8864 0.9500
epoch 1300 LossPred 0.1538 LossAtt 0.3372 TrainAcc 0.9500 TestAcc 0.8764 0.9450
epoch 1400 LossPred 0.1726 LossAtt 0.3437 TrainAcc 0.9500 TestAcc 0.8436 0.9100
epoch 1500 LossPred 0.1426 LossAtt 0.3523 TrainAcc 0.9500 TestAcc 0.8679 0.9300
epoch 1600 LossPred 0.1469 LossAtt 0.3614 TrainAcc 0.9500 TestAcc 0.8826 0.9600
epoch 1700 LossPred 0.0961 LossAtt 0.3746 TrainAcc 0.9800 TestAcc 0.8781 0.9600
epoch 1800 LossPred 0.0874 LossAtt 0.3821 TrainAcc 0.9600 TestAcc 0.8706 0.9600
epoch 1900 LossPred 0.0873 LossAtt 0.3494 TrainAcc 0.9800 TestAcc 0.8719 0.9650
epoch 2000 LossPred 0.0883 LossAtt 0.3461 TrainAcc 0.9600 TestAcc 0.8856 0.9700
epoch 2100 LossPred 0.0733 LossAtt 0.3562 TrainAcc 0.9800 TestAcc 0.8854 0.9800
epoch 2200 LossPred 0.0833 LossAtt 0.3434 TrainAcc 0.9800 TestAcc 0.8864 0.9750
epoch 2300 LossPred 0.0726 LossAtt 0.3385 TrainAcc 0.9800 TestAcc 0.8824 0.9700
epoch 2400 LossPred 0.0856 LossAtt 0.3377 TrainAcc 0.9600 TestAcc 0.8621 0.9700
epoch 2500 LossPred 0.0530 LossAtt 0.3242 TrainAcc 0.9800 TestAcc 0.8759 0.9850
Optimization Finished!
********** replication  72  **********
epoch   0 LossPred 1.0810 LossAtt 1.0437 TrainAcc 0.4000 TestAcc 0.4192 0.4350
epoch 100 LossPred 0.8897 LossAtt 0.3332 TrainAcc 0.6300 TestAcc 0.5973 0.6300
epoch 200 LossPred 0.8698 LossAtt 0.2750 TrainAcc 0.6300 TestAcc 0.5973 0.6300
epoch 300 LossPred 0.4422 LossAtt 0.3234 TrainAcc 0.8700 TestAcc 0.8441 0.8550
epoch 400 LossPred 0.4256 LossAtt 0.2902 TrainAcc 0.8600 TestAcc 0.8373 0.8450
epoch 500 LossPred 0.4554 LossAtt 0.2730 TrainAcc 0.8400 TestAcc 0.8251 0.8150
epoch 600 LossPred 0.4283 LossAtt 0.2400 TrainAcc 0.8500 TestAcc 0.8241 0.7900
epoch 700 LossPred 0.3695 LossAtt 0.2288 TrainAcc 0.8600 TestAcc 0.8406 0.8450
epoch 800 LossPred 0.3643 LossAtt 0.2314 TrainAcc 0.8800 TestAcc 0.8443 0.8700
epoch 900 LossPred 0.3926 LossAtt 0.2115 TrainAcc 0.8800 TestAcc 0.8433 0.8550
epoch 1000 LossPred 0.4507 LossAtt 0.2383 TrainAcc 0.8500 TestAcc 0.8336 0.8300
epoch 1100 LossPred 0.3755 LossAtt 0.2557 TrainAcc 0.8800 TestAcc 0.8541 0.8550
epoch 1200 LossPred 0.6237 LossAtt 0.2644 TrainAcc 0.7600 TestAcc 0.7885 0.7850
epoch 1300 LossPred 0.4961 LossAtt 0.2689 TrainAcc 0.8200 TestAcc 0.8061 0.8250
epoch 1400 LossPred 0.3959 LossAtt 0.2524 TrainAcc 0.8500 TestAcc 0.8621 0.8350
epoch 1500 LossPred 0.4412 LossAtt 0.2489 TrainAcc 0.8100 TestAcc 0.8566 0.8250
epoch 1600 LossPred 0.3497 LossAtt 0.2558 TrainAcc 0.8600 TestAcc 0.8791 0.8700
epoch 1700 LossPred 0.3289 LossAtt 0.2346 TrainAcc 0.8900 TestAcc 0.8724 0.8600
epoch 1800 LossPred 0.3218 LossAtt 0.2197 TrainAcc 0.8900 TestAcc 0.8744 0.8850
epoch 1900 LossPred 0.3184 LossAtt 0.2161 TrainAcc 0.8700 TestAcc 0.8774 0.8600
epoch 2000 LossPred 0.3294 LossAtt 0.2137 TrainAcc 0.8800 TestAcc 0.8651 0.8600
epoch 2100 LossPred 0.3147 LossAtt 0.2029 TrainAcc 0.8900 TestAcc 0.8819 0.8800
epoch 2200 LossPred 0.3282 LossAtt 0.2064 TrainAcc 0.8800 TestAcc 0.8796 0.8800
epoch 2300 LossPred 0.2365 LossAtt 0.2036 TrainAcc 0.9200 TestAcc 0.8674 0.8900
epoch 2400 LossPred 0.2180 LossAtt 0.1891 TrainAcc 0.9200 TestAcc 0.8776 0.9250
epoch 2500 LossPred 0.2025 LossAtt 0.1915 TrainAcc 0.9300 TestAcc 0.8691 0.9150
Optimization Finished!
********** replication  73  **********
epoch   0 LossPred 0.9632 LossAtt 1.0412 TrainAcc 0.6500 TestAcc 0.5891 0.6550
epoch 100 LossPred 0.9016 LossAtt 0.2908 TrainAcc 0.6500 TestAcc 0.5891 0.6500
epoch 200 LossPred 0.8825 LossAtt 0.2702 TrainAcc 0.6500 TestAcc 0.5891 0.6400
epoch 300 LossPred 0.5214 LossAtt 0.2522 TrainAcc 0.8300 TestAcc 0.8446 0.7900
epoch 400 LossPred 0.5181 LossAtt 0.2166 TrainAcc 0.8300 TestAcc 0.7880 0.8150
epoch 500 LossPred 0.5444 LossAtt 0.2124 TrainAcc 0.8000 TestAcc 0.7427 0.7850
epoch 600 LossPred 0.4357 LossAtt 0.2143 TrainAcc 0.8600 TestAcc 0.8311 0.8300
epoch 700 LossPred 0.4613 LossAtt 0.1951 TrainAcc 0.8500 TestAcc 0.8163 0.8200
epoch 800 LossPred 0.4821 LossAtt 0.1955 TrainAcc 0.8300 TestAcc 0.8443 0.8000
epoch 900 LossPred 0.3993 LossAtt 0.1891 TrainAcc 0.8600 TestAcc 0.8396 0.8150
epoch 1000 LossPred 0.4088 LossAtt 0.1931 TrainAcc 0.8700 TestAcc 0.8504 0.8000
epoch 1100 LossPred 0.4015 LossAtt 0.1810 TrainAcc 0.8600 TestAcc 0.8293 0.8150
epoch 1200 LossPred 0.3904 LossAtt 0.1880 TrainAcc 0.8700 TestAcc 0.8346 0.8100
epoch 1300 LossPred 0.3977 LossAtt 0.1793 TrainAcc 0.8700 TestAcc 0.8403 0.8000
epoch 1400 LossPred 0.3891 LossAtt 0.1815 TrainAcc 0.8700 TestAcc 0.8441 0.8150
epoch 1500 LossPred 0.3851 LossAtt 0.1959 TrainAcc 0.8800 TestAcc 0.8336 0.8200
epoch 1600 LossPred 0.3904 LossAtt 0.1953 TrainAcc 0.8700 TestAcc 0.8426 0.8100
epoch 1700 LossPred 0.3847 LossAtt 0.2176 TrainAcc 0.8800 TestAcc 0.8408 0.8300
epoch 1800 LossPred 0.5379 LossAtt 0.2224 TrainAcc 0.8200 TestAcc 0.8416 0.7800
epoch 1900 LossPred 0.6482 LossAtt 0.2213 TrainAcc 0.7700 TestAcc 0.8166 0.7500
epoch 2000 LossPred 0.3935 LossAtt 0.2409 TrainAcc 0.8500 TestAcc 0.8609 0.8100
epoch 2100 LossPred 0.4026 LossAtt 0.2527 TrainAcc 0.8600 TestAcc 0.8574 0.8050
epoch 2200 LossPred 0.4195 LossAtt 0.2528 TrainAcc 0.8600 TestAcc 0.8048 0.8100
epoch 2300 LossPred 0.6438 LossAtt 0.2566 TrainAcc 0.7800 TestAcc 0.6862 0.7700
epoch 2400 LossPred 0.3167 LossAtt 0.2289 TrainAcc 0.9000 TestAcc 0.8736 0.8300
epoch 2500 LossPred 0.3394 LossAtt 0.2484 TrainAcc 0.8600 TestAcc 0.8509 0.8400
Optimization Finished!
********** replication  74  **********
epoch   0 LossPred 1.0860 LossAtt 1.0699 TrainAcc 0.6200 TestAcc 0.5363 0.5600
epoch 100 LossPred 0.8857 LossAtt 0.3883 TrainAcc 0.6200 TestAcc 0.5133 0.6150
epoch 200 LossPred 0.8273 LossAtt 0.3645 TrainAcc 0.6800 TestAcc 0.5818 0.6950
epoch 300 LossPred 0.6942 LossAtt 0.4215 TrainAcc 0.7700 TestAcc 0.5721 0.7300
epoch 400 LossPred 0.5703 LossAtt 0.4578 TrainAcc 0.8200 TestAcc 0.5868 0.8000
epoch 500 LossPred 0.4882 LossAtt 0.4960 TrainAcc 0.8600 TestAcc 0.5946 0.7750
epoch 600 LossPred 0.4404 LossAtt 0.4780 TrainAcc 0.8600 TestAcc 0.6286 0.7950
epoch 700 LossPred 0.3851 LossAtt 0.4626 TrainAcc 0.9000 TestAcc 0.6454 0.8400
epoch 800 LossPred 0.3483 LossAtt 0.4643 TrainAcc 0.9200 TestAcc 0.6524 0.8400
epoch 900 LossPred 0.3505 LossAtt 0.4491 TrainAcc 0.9300 TestAcc 0.6539 0.8200
epoch 1000 LossPred 0.3217 LossAtt 0.4338 TrainAcc 0.9200 TestAcc 0.6577 0.8300
epoch 1100 LossPred 0.3063 LossAtt 0.4426 TrainAcc 0.9200 TestAcc 0.6669 0.8300
epoch 1200 LossPred 0.2903 LossAtt 0.4352 TrainAcc 0.9300 TestAcc 0.6647 0.8450
epoch 1300 LossPred 0.2885 LossAtt 0.4364 TrainAcc 0.9300 TestAcc 0.6632 0.8250
epoch 1400 LossPred 0.2699 LossAtt 0.4437 TrainAcc 0.9300 TestAcc 0.6662 0.8450
epoch 1500 LossPred 0.2732 LossAtt 0.4376 TrainAcc 0.9300 TestAcc 0.6669 0.8500
epoch 1600 LossPred 0.2586 LossAtt 0.4354 TrainAcc 0.9300 TestAcc 0.6662 0.8350
epoch 1700 LossPred 0.2519 LossAtt 0.4367 TrainAcc 0.9400 TestAcc 0.6592 0.8550
epoch 1800 LossPred 0.2834 LossAtt 0.4377 TrainAcc 0.9200 TestAcc 0.6672 0.8450
epoch 1900 LossPred 0.2337 LossAtt 0.4270 TrainAcc 0.9400 TestAcc 0.6662 0.8800
epoch 2000 LossPred 0.2338 LossAtt 0.4165 TrainAcc 0.9400 TestAcc 0.6481 0.8500
epoch 2100 LossPred 0.2270 LossAtt 0.4377 TrainAcc 0.9400 TestAcc 0.6499 0.8500
epoch 2200 LossPred 0.2483 LossAtt 0.4210 TrainAcc 0.9400 TestAcc 0.6669 0.8800
epoch 2300 LossPred 0.2247 LossAtt 0.3965 TrainAcc 0.9400 TestAcc 0.6512 0.8550
epoch 2400 LossPred 0.2280 LossAtt 0.4032 TrainAcc 0.9500 TestAcc 0.6697 0.8600
epoch 2500 LossPred 0.2238 LossAtt 0.4102 TrainAcc 0.9400 TestAcc 0.6341 0.8250
Optimization Finished!
********** replication  75  **********
epoch   0 LossPred 1.0537 LossAtt 1.0495 TrainAcc 0.4700 TestAcc 0.4489 0.4500
epoch 100 LossPred 0.8475 LossAtt 0.3056 TrainAcc 0.6600 TestAcc 0.5843 0.6600
epoch 200 LossPred 0.4575 LossAtt 0.3591 TrainAcc 0.8700 TestAcc 0.8371 0.8400
epoch 300 LossPred 0.5081 LossAtt 0.3424 TrainAcc 0.8200 TestAcc 0.7913 0.8000
epoch 400 LossPred 0.4985 LossAtt 0.3455 TrainAcc 0.8300 TestAcc 0.8111 0.8500
epoch 500 LossPred 0.3361 LossAtt 0.3331 TrainAcc 0.8900 TestAcc 0.8601 0.8650
epoch 600 LossPred 0.2771 LossAtt 0.3287 TrainAcc 0.9200 TestAcc 0.8604 0.8850
epoch 700 LossPred 0.2608 LossAtt 0.3485 TrainAcc 0.9000 TestAcc 0.8901 0.9050
epoch 800 LossPred 0.3447 LossAtt 0.3372 TrainAcc 0.8900 TestAcc 0.8651 0.8850
epoch 900 LossPred 0.3126 LossAtt 0.3312 TrainAcc 0.8800 TestAcc 0.8346 0.9050
epoch 1000 LossPred 0.3329 LossAtt 0.3444 TrainAcc 0.9000 TestAcc 0.8629 0.8800
epoch 1100 LossPred 0.2647 LossAtt 0.3502 TrainAcc 0.9100 TestAcc 0.8811 0.9050
epoch 1200 LossPred 0.2221 LossAtt 0.3659 TrainAcc 0.9300 TestAcc 0.8811 0.9200
epoch 1300 LossPred 0.2359 LossAtt 0.3602 TrainAcc 0.9200 TestAcc 0.8921 0.9250
epoch 1400 LossPred 0.1936 LossAtt 0.3677 TrainAcc 0.9400 TestAcc 0.8816 0.9200
epoch 1500 LossPred 0.2220 LossAtt 0.3543 TrainAcc 0.9300 TestAcc 0.8834 0.9150
epoch 1600 LossPred 0.2011 LossAtt 0.3438 TrainAcc 0.9400 TestAcc 0.8871 0.9250
epoch 1700 LossPred 0.3106 LossAtt 0.3425 TrainAcc 0.8900 TestAcc 0.8283 0.8950
epoch 1800 LossPred 0.1897 LossAtt 0.3408 TrainAcc 0.9400 TestAcc 0.8854 0.9250
epoch 1900 LossPred 0.1677 LossAtt 0.3448 TrainAcc 0.9500 TestAcc 0.8721 0.9600
epoch 2000 LossPred 0.1440 LossAtt 0.3516 TrainAcc 0.9600 TestAcc 0.8814 0.9500
epoch 2100 LossPred 0.1928 LossAtt 0.3495 TrainAcc 0.9300 TestAcc 0.8706 0.9100
epoch 2200 LossPred 0.1261 LossAtt 0.3497 TrainAcc 0.9700 TestAcc 0.8866 0.9550
epoch 2300 LossPred 0.1849 LossAtt 0.3580 TrainAcc 0.9500 TestAcc 0.8676 0.9300
epoch 2400 LossPred 0.3171 LossAtt 0.3508 TrainAcc 0.8800 TestAcc 0.8396 0.8900
epoch 2500 LossPred 0.2210 LossAtt 0.3625 TrainAcc 0.9200 TestAcc 0.8341 0.9300
Optimization Finished!
********** replication  76  **********
epoch   0 LossPred 1.2017 LossAtt 1.0955 TrainAcc 0.4700 TestAcc 0.4802 0.4650
epoch 100 LossPred 0.8457 LossAtt 0.4076 TrainAcc 0.6400 TestAcc 0.5953 0.6400
epoch 200 LossPred 0.5786 LossAtt 0.4154 TrainAcc 0.8300 TestAcc 0.7905 0.8100
epoch 300 LossPred 0.3619 LossAtt 0.4118 TrainAcc 0.9100 TestAcc 0.8253 0.8600
epoch 400 LossPred 0.3110 LossAtt 0.3701 TrainAcc 0.9100 TestAcc 0.8401 0.8550
epoch 500 LossPred 0.2895 LossAtt 0.3585 TrainAcc 0.9200 TestAcc 0.8343 0.8700
epoch 600 LossPred 0.2811 LossAtt 0.3589 TrainAcc 0.9200 TestAcc 0.8406 0.8600
epoch 700 LossPred 0.2420 LossAtt 0.3433 TrainAcc 0.9300 TestAcc 0.8589 0.8700
epoch 800 LossPred 0.2311 LossAtt 0.3522 TrainAcc 0.9300 TestAcc 0.8549 0.8850
epoch 900 LossPred 0.2291 LossAtt 0.3570 TrainAcc 0.9200 TestAcc 0.8544 0.8950
epoch 1000 LossPred 0.2308 LossAtt 0.3355 TrainAcc 0.9200 TestAcc 0.8566 0.9100
epoch 1100 LossPred 0.2197 LossAtt 0.3349 TrainAcc 0.9300 TestAcc 0.8721 0.9000
epoch 1200 LossPred 0.2136 LossAtt 0.3470 TrainAcc 0.9300 TestAcc 0.8704 0.8950
epoch 1300 LossPred 0.2041 LossAtt 0.3306 TrainAcc 0.9300 TestAcc 0.8639 0.9250
epoch 1400 LossPred 0.1956 LossAtt 0.3257 TrainAcc 0.9400 TestAcc 0.8816 0.9100
epoch 1500 LossPred 0.1969 LossAtt 0.3283 TrainAcc 0.9500 TestAcc 0.8774 0.9050
epoch 1600 LossPred 0.2050 LossAtt 0.3156 TrainAcc 0.9300 TestAcc 0.8729 0.9000
epoch 1700 LossPred 0.2758 LossAtt 0.3276 TrainAcc 0.9100 TestAcc 0.8328 0.9050
epoch 1800 LossPred 0.1672 LossAtt 0.3243 TrainAcc 0.9500 TestAcc 0.8539 0.9250
epoch 1900 LossPred 0.1289 LossAtt 0.3354 TrainAcc 0.9500 TestAcc 0.8679 0.9600
epoch 2000 LossPred 0.2692 LossAtt 0.3265 TrainAcc 0.9100 TestAcc 0.8198 0.8900
epoch 2100 LossPred 0.1054 LossAtt 0.3488 TrainAcc 0.9900 TestAcc 0.8566 0.9400
epoch 2200 LossPred 0.0806 LossAtt 0.3525 TrainAcc 0.9900 TestAcc 0.8581 0.9600
epoch 2300 LossPred 0.1666 LossAtt 0.3408 TrainAcc 0.9400 TestAcc 0.8228 0.9150
epoch 2400 LossPred 0.0877 LossAtt 0.3543 TrainAcc 0.9800 TestAcc 0.8569 0.9700
epoch 2500 LossPred 0.0571 LossAtt 0.3346 TrainAcc 0.9900 TestAcc 0.8596 0.9700
Optimization Finished!
********** replication  77  **********
epoch   0 LossPred 1.0359 LossAtt 1.0371 TrainAcc 0.4900 TestAcc 0.4069 0.4900
epoch 100 LossPred 0.9437 LossAtt 0.3822 TrainAcc 0.6300 TestAcc 0.5350 0.6200
epoch 200 LossPred 0.8582 LossAtt 0.4312 TrainAcc 0.6500 TestAcc 0.5140 0.6650
epoch 300 LossPred 0.7896 LossAtt 0.4515 TrainAcc 0.7000 TestAcc 0.5093 0.6950
epoch 400 LossPred 0.7719 LossAtt 0.4763 TrainAcc 0.7200 TestAcc 0.5110 0.7100
epoch 500 LossPred 0.7453 LossAtt 0.5061 TrainAcc 0.7200 TestAcc 0.5158 0.7000
epoch 600 LossPred 0.7111 LossAtt 0.4975 TrainAcc 0.7400 TestAcc 0.5208 0.7000
epoch 700 LossPred 0.6770 LossAtt 0.5179 TrainAcc 0.7500 TestAcc 0.5330 0.7050
epoch 800 LossPred 0.6219 LossAtt 0.5261 TrainAcc 0.7500 TestAcc 0.5468 0.7400
epoch 900 LossPred 0.5343 LossAtt 0.4948 TrainAcc 0.7900 TestAcc 0.5688 0.7100
epoch 1000 LossPred 0.4828 LossAtt 0.5088 TrainAcc 0.8000 TestAcc 0.5896 0.7150
epoch 1100 LossPred 0.4703 LossAtt 0.5020 TrainAcc 0.8200 TestAcc 0.6074 0.7350
epoch 1200 LossPred 0.3953 LossAtt 0.5229 TrainAcc 0.8300 TestAcc 0.6329 0.7700
epoch 1300 LossPred 0.3133 LossAtt 0.5236 TrainAcc 0.8700 TestAcc 0.6181 0.7500
epoch 1400 LossPred 0.2853 LossAtt 0.5240 TrainAcc 0.8800 TestAcc 0.6201 0.7700
epoch 1500 LossPred 0.2557 LossAtt 0.5319 TrainAcc 0.9000 TestAcc 0.6131 0.7600
epoch 1600 LossPred 0.2462 LossAtt 0.5218 TrainAcc 0.9000 TestAcc 0.6316 0.7650
epoch 1700 LossPred 0.2265 LossAtt 0.5196 TrainAcc 0.9000 TestAcc 0.6164 0.7750
epoch 1800 LossPred 0.2144 LossAtt 0.5335 TrainAcc 0.9000 TestAcc 0.6181 0.7750
epoch 1900 LossPred 0.2045 LossAtt 0.5231 TrainAcc 0.9100 TestAcc 0.6179 0.7900
epoch 2000 LossPred 0.1943 LossAtt 0.5181 TrainAcc 0.9100 TestAcc 0.6084 0.7950
epoch 2100 LossPred 0.1926 LossAtt 0.5260 TrainAcc 0.9200 TestAcc 0.6101 0.8100
epoch 2200 LossPred 0.1786 LossAtt 0.5158 TrainAcc 0.9500 TestAcc 0.6184 0.8150
epoch 2300 LossPred 0.1777 LossAtt 0.5282 TrainAcc 0.9300 TestAcc 0.6071 0.8000
epoch 2400 LossPred 0.1799 LossAtt 0.5346 TrainAcc 0.9300 TestAcc 0.6136 0.8150
epoch 2500 LossPred 0.1698 LossAtt 0.5238 TrainAcc 0.9400 TestAcc 0.6124 0.8100
Optimization Finished!
********** replication  78  **********
epoch   0 LossPred 1.0528 LossAtt 1.0085 TrainAcc 0.5300 TestAcc 0.4780 0.5800
epoch 100 LossPred 0.8310 LossAtt 0.3693 TrainAcc 0.6300 TestAcc 0.5743 0.6700
epoch 200 LossPred 0.3750 LossAtt 0.4213 TrainAcc 0.8800 TestAcc 0.8446 0.8700
epoch 300 LossPred 0.2909 LossAtt 0.3980 TrainAcc 0.9200 TestAcc 0.8278 0.9050
epoch 400 LossPred 0.2764 LossAtt 0.3781 TrainAcc 0.9100 TestAcc 0.8516 0.8900
epoch 500 LossPred 0.2206 LossAtt 0.3656 TrainAcc 0.9400 TestAcc 0.8321 0.8950
epoch 600 LossPred 0.2644 LossAtt 0.3520 TrainAcc 0.9000 TestAcc 0.8138 0.9000
epoch 700 LossPred 0.1968 LossAtt 0.3594 TrainAcc 0.9400 TestAcc 0.8181 0.9100
epoch 800 LossPred 0.2107 LossAtt 0.3589 TrainAcc 0.9300 TestAcc 0.8401 0.9050
epoch 900 LossPred 0.1463 LossAtt 0.3584 TrainAcc 0.9600 TestAcc 0.8398 0.9050
epoch 1000 LossPred 0.2814 LossAtt 0.3509 TrainAcc 0.9100 TestAcc 0.8036 0.8800
epoch 1100 LossPred 0.1366 LossAtt 0.3570 TrainAcc 0.9600 TestAcc 0.8466 0.9000
epoch 1200 LossPred 0.1479 LossAtt 0.3479 TrainAcc 0.9600 TestAcc 0.8488 0.9200
epoch 1300 LossPred 0.1237 LossAtt 0.3472 TrainAcc 0.9600 TestAcc 0.8441 0.9200
epoch 1400 LossPred 0.1106 LossAtt 0.3483 TrainAcc 0.9800 TestAcc 0.8539 0.9400
epoch 1500 LossPred 0.1293 LossAtt 0.3318 TrainAcc 0.9500 TestAcc 0.8448 0.9300
epoch 1600 LossPred 0.2236 LossAtt 0.3395 TrainAcc 0.9300 TestAcc 0.8333 0.9250
epoch 1700 LossPred 0.1016 LossAtt 0.3270 TrainAcc 0.9700 TestAcc 0.8496 0.9300
epoch 1800 LossPred 0.0907 LossAtt 0.3368 TrainAcc 0.9800 TestAcc 0.8546 0.9300
epoch 1900 LossPred 0.1137 LossAtt 0.3298 TrainAcc 0.9700 TestAcc 0.8391 0.9150
epoch 2000 LossPred 0.1010 LossAtt 0.3282 TrainAcc 0.9700 TestAcc 0.8536 0.9350
epoch 2100 LossPred 0.1462 LossAtt 0.3156 TrainAcc 0.9500 TestAcc 0.8348 0.9200
epoch 2200 LossPred 0.1055 LossAtt 0.3171 TrainAcc 0.9900 TestAcc 0.8456 0.9100
epoch 2300 LossPred 0.0820 LossAtt 0.3096 TrainAcc 0.9800 TestAcc 0.8549 0.9250
epoch 2400 LossPred 0.0816 LossAtt 0.3041 TrainAcc 0.9800 TestAcc 0.8549 0.9250
epoch 2500 LossPred 0.1349 LossAtt 0.3111 TrainAcc 0.9400 TestAcc 0.8326 0.9150
Optimization Finished!
********** replication  79  **********
epoch   0 LossPred 1.2751 LossAtt 1.0351 TrainAcc 0.3900 TestAcc 0.4697 0.4400
epoch 100 LossPred 0.8604 LossAtt 0.3872 TrainAcc 0.6700 TestAcc 0.6311 0.6800
epoch 200 LossPred 0.4578 LossAtt 0.3921 TrainAcc 0.9000 TestAcc 0.8766 0.8500
epoch 300 LossPred 0.3463 LossAtt 0.3676 TrainAcc 0.9100 TestAcc 0.8809 0.8500
epoch 400 LossPred 0.2788 LossAtt 0.3787 TrainAcc 0.9200 TestAcc 0.8901 0.9000
epoch 500 LossPred 0.2383 LossAtt 0.3612 TrainAcc 0.9300 TestAcc 0.9032 0.9150
epoch 600 LossPred 0.1845 LossAtt 0.3479 TrainAcc 0.9500 TestAcc 0.9152 0.9350
epoch 700 LossPred 0.2451 LossAtt 0.3536 TrainAcc 0.9200 TestAcc 0.9049 0.8900
epoch 800 LossPred 0.1596 LossAtt 0.3463 TrainAcc 0.9600 TestAcc 0.9339 0.9250
epoch 900 LossPred 0.1475 LossAtt 0.3444 TrainAcc 0.9500 TestAcc 0.9337 0.9550
epoch 1000 LossPred 0.1583 LossAtt 0.3336 TrainAcc 0.9600 TestAcc 0.9417 0.9200
epoch 1100 LossPred 0.1510 LossAtt 0.3523 TrainAcc 0.9600 TestAcc 0.9079 0.9300
epoch 1200 LossPred 0.1180 LossAtt 0.3416 TrainAcc 0.9700 TestAcc 0.9479 0.9400
epoch 1300 LossPred 0.1003 LossAtt 0.3494 TrainAcc 0.9800 TestAcc 0.9427 0.9500
epoch 1400 LossPred 0.1340 LossAtt 0.3460 TrainAcc 0.9700 TestAcc 0.9144 0.9350
epoch 1500 LossPred 0.0849 LossAtt 0.3427 TrainAcc 0.9800 TestAcc 0.9557 0.9550
epoch 1600 LossPred 0.0819 LossAtt 0.3262 TrainAcc 0.9700 TestAcc 0.9562 0.9550
epoch 1700 LossPred 0.0691 LossAtt 0.3285 TrainAcc 0.9900 TestAcc 0.9392 0.9550
epoch 1800 LossPred 0.0588 LossAtt 0.2983 TrainAcc 0.9900 TestAcc 0.9462 0.9550
epoch 1900 LossPred 0.0943 LossAtt 0.3027 TrainAcc 0.9600 TestAcc 0.9582 0.9500
epoch 2000 LossPred 0.0453 LossAtt 0.3037 TrainAcc 1.0000 TestAcc 0.9499 0.9700
Optimization Finished!
********** replication  80  **********
epoch   0 LossPred 1.1165 LossAtt 1.0357 TrainAcc 0.4400 TestAcc 0.4607 0.4450
epoch 100 LossPred 0.8730 LossAtt 0.2847 TrainAcc 0.6400 TestAcc 0.5856 0.6400
epoch 200 LossPred 0.4706 LossAtt 0.2841 TrainAcc 0.9100 TestAcc 0.8493 0.9100
epoch 300 LossPred 0.3422 LossAtt 0.3070 TrainAcc 0.9100 TestAcc 0.8601 0.8850
epoch 400 LossPred 0.3217 LossAtt 0.2913 TrainAcc 0.9100 TestAcc 0.8358 0.8750
epoch 500 LossPred 0.4094 LossAtt 0.2623 TrainAcc 0.8900 TestAcc 0.8498 0.8700
epoch 600 LossPred 0.3786 LossAtt 0.2323 TrainAcc 0.8800 TestAcc 0.8413 0.8550
epoch 700 LossPred 0.4694 LossAtt 0.2388 TrainAcc 0.8400 TestAcc 0.8036 0.8100
epoch 800 LossPred 0.5337 LossAtt 0.2169 TrainAcc 0.8300 TestAcc 0.7873 0.8300
epoch 900 LossPred 0.3857 LossAtt 0.2316 TrainAcc 0.8800 TestAcc 0.8634 0.8700
epoch 1000 LossPred 0.3758 LossAtt 0.2564 TrainAcc 0.8800 TestAcc 0.8331 0.8600
epoch 1100 LossPred 0.3091 LossAtt 0.2829 TrainAcc 0.9100 TestAcc 0.8714 0.8900
epoch 1200 LossPred 0.2497 LossAtt 0.2581 TrainAcc 0.9100 TestAcc 0.8831 0.8950
epoch 1300 LossPred 0.2477 LossAtt 0.2564 TrainAcc 0.9200 TestAcc 0.8789 0.9100
epoch 1400 LossPred 0.2175 LossAtt 0.2359 TrainAcc 0.9400 TestAcc 0.8886 0.9150
epoch 1500 LossPred 0.3623 LossAtt 0.2339 TrainAcc 0.9000 TestAcc 0.8611 0.8750
epoch 1600 LossPred 0.3183 LossAtt 0.2431 TrainAcc 0.8900 TestAcc 0.8599 0.8850
epoch 1700 LossPred 0.2332 LossAtt 0.2199 TrainAcc 0.9300 TestAcc 0.9022 0.9150
epoch 1800 LossPred 0.2291 LossAtt 0.2136 TrainAcc 0.9100 TestAcc 0.8946 0.9200
epoch 1900 LossPred 0.2199 LossAtt 0.1986 TrainAcc 0.9200 TestAcc 0.8939 0.9200
epoch 2000 LossPred 0.2049 LossAtt 0.1858 TrainAcc 0.9300 TestAcc 0.9039 0.9250
epoch 2100 LossPred 0.2461 LossAtt 0.1849 TrainAcc 0.9200 TestAcc 0.8859 0.9050
epoch 2200 LossPred 0.2068 LossAtt 0.1694 TrainAcc 0.9400 TestAcc 0.9027 0.9150
epoch 2300 LossPred 0.2226 LossAtt 0.1732 TrainAcc 0.9400 TestAcc 0.8899 0.9050
epoch 2400 LossPred 0.2405 LossAtt 0.1679 TrainAcc 0.9300 TestAcc 0.9002 0.9050
epoch 2500 LossPred 0.2034 LossAtt 0.1797 TrainAcc 0.9500 TestAcc 0.8944 0.9400
Optimization Finished!
********** replication  81  **********
epoch   0 LossPred 1.0881 LossAtt 1.0316 TrainAcc 0.4100 TestAcc 0.4097 0.4100
epoch 100 LossPred 0.9343 LossAtt 0.3243 TrainAcc 0.5900 TestAcc 0.5903 0.5900
epoch 200 LossPred 0.5841 LossAtt 0.3810 TrainAcc 0.8500 TestAcc 0.8626 0.8250
epoch 300 LossPred 0.4161 LossAtt 0.3389 TrainAcc 0.8900 TestAcc 0.8629 0.8500
epoch 400 LossPred 0.3932 LossAtt 0.3101 TrainAcc 0.8700 TestAcc 0.8971 0.8650
epoch 500 LossPred 0.3298 LossAtt 0.3092 TrainAcc 0.8900 TestAcc 0.9019 0.8700
epoch 600 LossPred 0.3034 LossAtt 0.3282 TrainAcc 0.9100 TestAcc 0.9104 0.8750
epoch 700 LossPred 0.2427 LossAtt 0.3572 TrainAcc 0.9200 TestAcc 0.9079 0.9000
epoch 800 LossPred 0.2986 LossAtt 0.3496 TrainAcc 0.9000 TestAcc 0.8836 0.8800
epoch 900 LossPred 0.2623 LossAtt 0.3735 TrainAcc 0.9200 TestAcc 0.8453 0.8850
epoch 1000 LossPred 0.1534 LossAtt 0.3506 TrainAcc 0.9600 TestAcc 0.9144 0.9550
epoch 1100 LossPred 0.1537 LossAtt 0.3517 TrainAcc 0.9700 TestAcc 0.9044 0.9500
epoch 1200 LossPred 0.1285 LossAtt 0.3351 TrainAcc 0.9700 TestAcc 0.9037 0.9400
epoch 1300 LossPred 0.1276 LossAtt 0.3294 TrainAcc 0.9800 TestAcc 0.9159 0.9400
epoch 1400 LossPred 0.0855 LossAtt 0.3366 TrainAcc 0.9800 TestAcc 0.9207 0.9700
epoch 1500 LossPred 0.0867 LossAtt 0.3168 TrainAcc 0.9900 TestAcc 0.9242 0.9700
epoch 1600 LossPred 0.2428 LossAtt 0.3173 TrainAcc 0.9000 TestAcc 0.8554 0.8850
epoch 1700 LossPred 0.1286 LossAtt 0.2962 TrainAcc 0.9600 TestAcc 0.9104 0.9700
epoch 1800 LossPred 0.1263 LossAtt 0.2953 TrainAcc 0.9700 TestAcc 0.9109 0.9650
epoch 1900 LossPred 0.0639 LossAtt 0.2963 TrainAcc 1.0000 TestAcc 0.9184 0.9550
Optimization Finished!
********** replication  82  **********
epoch   0 LossPred 1.0165 LossAtt 1.0316 TrainAcc 0.5100 TestAcc 0.5345 0.5250
epoch 100 LossPred 0.8338 LossAtt 0.4124 TrainAcc 0.6800 TestAcc 0.7027 0.6800
epoch 200 LossPred 0.3692 LossAtt 0.3911 TrainAcc 0.8900 TestAcc 0.8716 0.8550
epoch 300 LossPred 0.2441 LossAtt 0.3838 TrainAcc 0.9300 TestAcc 0.8774 0.8950
epoch 400 LossPred 0.2705 LossAtt 0.3792 TrainAcc 0.9000 TestAcc 0.8519 0.8500
epoch 500 LossPred 0.2520 LossAtt 0.3557 TrainAcc 0.9200 TestAcc 0.8529 0.8900
epoch 600 LossPred 0.3395 LossAtt 0.3463 TrainAcc 0.8800 TestAcc 0.8346 0.8500
epoch 700 LossPred 0.2066 LossAtt 0.3344 TrainAcc 0.9200 TestAcc 0.8446 0.9000
epoch 800 LossPred 0.1462 LossAtt 0.3490 TrainAcc 0.9600 TestAcc 0.8534 0.9100
epoch 900 LossPred 0.1095 LossAtt 0.3397 TrainAcc 0.9800 TestAcc 0.8531 0.9000
epoch 1000 LossPred 0.0979 LossAtt 0.3309 TrainAcc 0.9800 TestAcc 0.8524 0.9150
epoch 1100 LossPred 0.1704 LossAtt 0.3401 TrainAcc 0.9500 TestAcc 0.8426 0.9000
epoch 1200 LossPred 0.1126 LossAtt 0.3372 TrainAcc 0.9800 TestAcc 0.8403 0.9100
epoch 1300 LossPred 0.1015 LossAtt 0.3441 TrainAcc 0.9700 TestAcc 0.8448 0.9050
epoch 1400 LossPred 0.0916 LossAtt 0.3321 TrainAcc 0.9800 TestAcc 0.8406 0.9150
epoch 1500 LossPred 0.1135 LossAtt 0.3232 TrainAcc 0.9800 TestAcc 0.8351 0.9050
epoch 1600 LossPred 0.2756 LossAtt 0.3454 TrainAcc 0.8900 TestAcc 0.8263 0.8600
epoch 1700 LossPred 0.0898 LossAtt 0.3173 TrainAcc 0.9800 TestAcc 0.8468 0.9150
epoch 1800 LossPred 0.1467 LossAtt 0.3083 TrainAcc 0.9500 TestAcc 0.8413 0.8950
epoch 1900 LossPred 0.1343 LossAtt 0.3142 TrainAcc 0.9500 TestAcc 0.8361 0.8950
epoch 2000 LossPred 0.0850 LossAtt 0.3155 TrainAcc 0.9800 TestAcc 0.8448 0.9000
epoch 2100 LossPred 0.1525 LossAtt 0.3246 TrainAcc 0.9600 TestAcc 0.8431 0.9000
epoch 2200 LossPred 0.3136 LossAtt 0.3189 TrainAcc 0.9200 TestAcc 0.8311 0.8850
epoch 2300 LossPred 0.3864 LossAtt 0.3272 TrainAcc 0.8700 TestAcc 0.8316 0.8300
epoch 2400 LossPred 0.1265 LossAtt 0.3266 TrainAcc 0.9600 TestAcc 0.8629 0.8950
epoch 2500 LossPred 0.1561 LossAtt 0.3190 TrainAcc 0.9500 TestAcc 0.8696 0.9000
Optimization Finished!
********** replication  83  **********
epoch   0 LossPred 1.0515 LossAtt 1.0457 TrainAcc 0.4900 TestAcc 0.4725 0.4400
epoch 100 LossPred 0.7902 LossAtt 0.3764 TrainAcc 0.6700 TestAcc 0.6286 0.6700
epoch 200 LossPred 0.3290 LossAtt 0.4131 TrainAcc 0.9200 TestAcc 0.8664 0.9050
epoch 300 LossPred 0.1980 LossAtt 0.3722 TrainAcc 0.9400 TestAcc 0.8751 0.9150
epoch 400 LossPred 0.2282 LossAtt 0.3560 TrainAcc 0.9100 TestAcc 0.8744 0.9050
epoch 500 LossPred 0.1828 LossAtt 0.3345 TrainAcc 0.9400 TestAcc 0.8591 0.9450
epoch 600 LossPred 0.2015 LossAtt 0.3336 TrainAcc 0.9300 TestAcc 0.8769 0.9350
epoch 700 LossPred 0.1303 LossAtt 0.3351 TrainAcc 0.9600 TestAcc 0.8846 0.9550
epoch 800 LossPred 0.1175 LossAtt 0.3222 TrainAcc 0.9600 TestAcc 0.8889 0.9600
epoch 900 LossPred 0.0915 LossAtt 0.3082 TrainAcc 0.9800 TestAcc 0.8891 0.9750
epoch 1000 LossPred 0.0820 LossAtt 0.3291 TrainAcc 0.9600 TestAcc 0.8881 0.9800
epoch 1100 LossPred 0.0850 LossAtt 0.3116 TrainAcc 0.9700 TestAcc 0.8826 0.9750
epoch 1200 LossPred 0.1164 LossAtt 0.3122 TrainAcc 0.9400 TestAcc 0.8869 0.9600
epoch 1300 LossPred 0.0998 LossAtt 0.2937 TrainAcc 0.9700 TestAcc 0.8861 0.9600
epoch 1400 LossPred 0.0779 LossAtt 0.2926 TrainAcc 0.9800 TestAcc 0.8861 0.9650
epoch 1500 LossPred 0.2211 LossAtt 0.2898 TrainAcc 0.9100 TestAcc 0.8639 0.9250
epoch 1600 LossPred 0.0639 LossAtt 0.2790 TrainAcc 0.9900 TestAcc 0.8866 0.9700
epoch 1700 LossPred 0.0989 LossAtt 0.2751 TrainAcc 0.9700 TestAcc 0.8774 0.9750
epoch 1800 LossPred 0.0466 LossAtt 0.2619 TrainAcc 1.0000 TestAcc 0.8809 0.9700
Optimization Finished!
********** replication  84  **********
epoch   0 LossPred 1.2286 LossAtt 1.0373 TrainAcc 0.4500 TestAcc 0.5215 0.4650
epoch 100 LossPred 0.8688 LossAtt 0.3321 TrainAcc 0.6800 TestAcc 0.6106 0.6750
epoch 200 LossPred 0.8416 LossAtt 0.2765 TrainAcc 0.6600 TestAcc 0.5961 0.6450
epoch 300 LossPred 0.8323 LossAtt 0.2627 TrainAcc 0.6600 TestAcc 0.5961 0.6500
epoch 400 LossPred 0.8041 LossAtt 0.3307 TrainAcc 0.7000 TestAcc 0.6096 0.6900
epoch 500 LossPred 0.7392 LossAtt 0.3713 TrainAcc 0.7400 TestAcc 0.5786 0.7150
epoch 600 LossPred 0.6925 LossAtt 0.4855 TrainAcc 0.7500 TestAcc 0.6174 0.7150
epoch 700 LossPred 0.6228 LossAtt 0.5688 TrainAcc 0.7700 TestAcc 0.6527 0.7450
epoch 800 LossPred 0.4166 LossAtt 0.5867 TrainAcc 0.8800 TestAcc 0.7703 0.8300
epoch 900 LossPred 0.2581 LossAtt 0.5498 TrainAcc 0.9400 TestAcc 0.8218 0.8950
epoch 1000 LossPred 0.1778 LossAtt 0.5447 TrainAcc 0.9600 TestAcc 0.8466 0.9050
epoch 1100 LossPred 0.1441 LossAtt 0.5463 TrainAcc 0.9700 TestAcc 0.8478 0.9200
epoch 1200 LossPred 0.1413 LossAtt 0.5417 TrainAcc 0.9800 TestAcc 0.8333 0.9150
epoch 1300 LossPred 0.1177 LossAtt 0.5407 TrainAcc 0.9800 TestAcc 0.8456 0.9250
epoch 1400 LossPred 0.0677 LossAtt 0.5262 TrainAcc 0.9900 TestAcc 0.8411 0.9300
epoch 1500 LossPred 0.0722 LossAtt 0.5012 TrainAcc 0.9700 TestAcc 0.8413 0.9200
epoch 1600 LossPred 0.0433 LossAtt 0.5073 TrainAcc 1.0000 TestAcc 0.8363 0.9250
Optimization Finished!
********** replication  85  **********
epoch   0 LossPred 1.0207 LossAtt 1.0140 TrainAcc 0.5400 TestAcc 0.5393 0.5100
epoch 100 LossPred 0.8856 LossAtt 0.4184 TrainAcc 0.6200 TestAcc 0.6529 0.6350
epoch 200 LossPred 0.3177 LossAtt 0.4326 TrainAcc 0.9200 TestAcc 0.8756 0.8900
epoch 300 LossPred 0.1970 LossAtt 0.4347 TrainAcc 0.9500 TestAcc 0.8839 0.8750
epoch 400 LossPred 0.1731 LossAtt 0.4456 TrainAcc 0.9600 TestAcc 0.8844 0.8950
epoch 500 LossPred 0.1327 LossAtt 0.4577 TrainAcc 0.9700 TestAcc 0.8861 0.8950
epoch 600 LossPred 0.1353 LossAtt 0.4454 TrainAcc 0.9500 TestAcc 0.8779 0.8700
epoch 700 LossPred 0.0808 LossAtt 0.4654 TrainAcc 0.9800 TestAcc 0.8879 0.8900
epoch 800 LossPred 0.0783 LossAtt 0.4675 TrainAcc 0.9900 TestAcc 0.8929 0.8900
epoch 900 LossPred 0.1185 LossAtt 0.4573 TrainAcc 0.9900 TestAcc 0.8849 0.8950
epoch 1000 LossPred 0.0620 LossAtt 0.4439 TrainAcc 0.9900 TestAcc 0.9029 0.8900
epoch 1100 LossPred 0.0614 LossAtt 0.4328 TrainAcc 1.0000 TestAcc 0.8984 0.9000
Optimization Finished!
********** replication  86  **********
epoch   0 LossPred 1.0269 LossAtt 1.0126 TrainAcc 0.5500 TestAcc 0.5358 0.5300
epoch 100 LossPred 0.8561 LossAtt 0.3041 TrainAcc 0.6600 TestAcc 0.5913 0.6600
epoch 200 LossPred 0.3806 LossAtt 0.4071 TrainAcc 0.9100 TestAcc 0.8391 0.8700
epoch 300 LossPred 0.2165 LossAtt 0.3910 TrainAcc 0.9500 TestAcc 0.8729 0.8850
epoch 400 LossPred 0.2841 LossAtt 0.3847 TrainAcc 0.9100 TestAcc 0.8509 0.8750
epoch 500 LossPred 0.2803 LossAtt 0.3771 TrainAcc 0.9100 TestAcc 0.8138 0.8850
epoch 600 LossPred 0.1842 LossAtt 0.3838 TrainAcc 0.9500 TestAcc 0.8396 0.8900
epoch 700 LossPred 0.1393 LossAtt 0.3604 TrainAcc 0.9700 TestAcc 0.8631 0.9450
epoch 800 LossPred 0.1761 LossAtt 0.3733 TrainAcc 0.9600 TestAcc 0.8659 0.9200
epoch 900 LossPred 0.1642 LossAtt 0.3643 TrainAcc 0.9600 TestAcc 0.8749 0.9350
epoch 1000 LossPred 0.1185 LossAtt 0.3760 TrainAcc 0.9800 TestAcc 0.8721 0.9450
epoch 1100 LossPred 0.1180 LossAtt 0.3554 TrainAcc 0.9800 TestAcc 0.8786 0.9450
epoch 1200 LossPred 0.3759 LossAtt 0.3487 TrainAcc 0.8800 TestAcc 0.7943 0.8850
epoch 1300 LossPred 0.1135 LossAtt 0.3660 TrainAcc 0.9800 TestAcc 0.8779 0.9500
epoch 1400 LossPred 0.1156 LossAtt 0.3443 TrainAcc 0.9800 TestAcc 0.8681 0.9500
epoch 1500 LossPred 0.1247 LossAtt 0.3502 TrainAcc 0.9600 TestAcc 0.8564 0.9500
epoch 1600 LossPred 0.1172 LossAtt 0.3490 TrainAcc 0.9800 TestAcc 0.8616 0.9450
epoch 1700 LossPred 0.1312 LossAtt 0.3555 TrainAcc 0.9700 TestAcc 0.8731 0.9400
epoch 1800 LossPred 0.1529 LossAtt 0.3732 TrainAcc 0.9700 TestAcc 0.8766 0.9300
epoch 1900 LossPred 0.1157 LossAtt 0.3606 TrainAcc 0.9800 TestAcc 0.8716 0.9500
epoch 2000 LossPred 0.1482 LossAtt 0.3980 TrainAcc 0.9600 TestAcc 0.8706 0.9200
epoch 2100 LossPred 0.2913 LossAtt 0.4350 TrainAcc 0.8900 TestAcc 0.8534 0.8600
epoch 2200 LossPred 0.4062 LossAtt 0.4323 TrainAcc 0.8500 TestAcc 0.7785 0.8650
epoch 2300 LossPred 0.1719 LossAtt 0.4024 TrainAcc 0.9600 TestAcc 0.8766 0.9450
epoch 2400 LossPred 0.1933 LossAtt 0.4099 TrainAcc 0.9500 TestAcc 0.8739 0.9150
epoch 2500 LossPred 0.2249 LossAtt 0.4080 TrainAcc 0.9200 TestAcc 0.8403 0.9100
Optimization Finished!
********** replication  87  **********
epoch   0 LossPred 1.0275 LossAtt 1.0507 TrainAcc 0.5800 TestAcc 0.5325 0.5950
epoch 100 LossPred 0.8614 LossAtt 0.3807 TrainAcc 0.6300 TestAcc 0.5468 0.6250
epoch 200 LossPred 0.8088 LossAtt 0.4270 TrainAcc 0.7200 TestAcc 0.6049 0.7050
epoch 300 LossPred 0.1729 LossAtt 0.4629 TrainAcc 0.9500 TestAcc 0.9054 0.9300
epoch 400 LossPred 0.0689 LossAtt 0.4289 TrainAcc 0.9900 TestAcc 0.9219 0.9450
epoch 500 LossPred 0.0388 LossAtt 0.4293 TrainAcc 0.9900 TestAcc 0.9252 0.9650
epoch 600 LossPred 0.0247 LossAtt 0.4166 TrainAcc 1.0000 TestAcc 0.9244 0.9500
Optimization Finished!
********** replication  88  **********
epoch   0 LossPred 1.0952 LossAtt 1.0175 TrainAcc 0.3800 TestAcc 0.4379 0.4050
epoch 100 LossPred 0.8545 LossAtt 0.3710 TrainAcc 0.6500 TestAcc 0.6456 0.6550
epoch 200 LossPred 0.3413 LossAtt 0.4176 TrainAcc 0.9000 TestAcc 0.8886 0.8800
epoch 300 LossPred 0.2322 LossAtt 0.3917 TrainAcc 0.9100 TestAcc 0.9244 0.9100
epoch 400 LossPred 0.1965 LossAtt 0.3750 TrainAcc 0.9400 TestAcc 0.9339 0.9000
epoch 500 LossPred 0.1921 LossAtt 0.3811 TrainAcc 0.9400 TestAcc 0.9499 0.9150
epoch 600 LossPred 0.1642 LossAtt 0.3609 TrainAcc 0.9500 TestAcc 0.9329 0.9200
epoch 700 LossPred 0.1489 LossAtt 0.3618 TrainAcc 0.9500 TestAcc 0.9414 0.9250
epoch 800 LossPred 0.1302 LossAtt 0.3600 TrainAcc 0.9600 TestAcc 0.9562 0.9300
epoch 900 LossPred 0.1157 LossAtt 0.3589 TrainAcc 0.9700 TestAcc 0.9469 0.9450
epoch 1000 LossPred 0.0905 LossAtt 0.3600 TrainAcc 0.9800 TestAcc 0.9304 0.9500
epoch 1100 LossPred 0.0706 LossAtt 0.3571 TrainAcc 0.9900 TestAcc 0.9444 0.9600
epoch 1200 LossPred 0.0785 LossAtt 0.3536 TrainAcc 0.9800 TestAcc 0.9527 0.9650
epoch 1300 LossPred 0.1469 LossAtt 0.3533 TrainAcc 0.9400 TestAcc 0.9424 0.9250
epoch 1400 LossPred 0.0732 LossAtt 0.3531 TrainAcc 0.9800 TestAcc 0.9697 0.9500
epoch 1500 LossPred 0.0366 LossAtt 0.3493 TrainAcc 1.0000 TestAcc 0.9535 0.9650
Optimization Finished!
********** replication  89  **********
epoch   0 LossPred 1.0345 LossAtt 1.0205 TrainAcc 0.4200 TestAcc 0.4064 0.4200
epoch 100 LossPred 0.9034 LossAtt 0.3573 TrainAcc 0.6100 TestAcc 0.5501 0.6150
epoch 200 LossPred 0.5694 LossAtt 0.3859 TrainAcc 0.8100 TestAcc 0.8296 0.8050
epoch 300 LossPred 0.3776 LossAtt 0.3445 TrainAcc 0.8900 TestAcc 0.8088 0.8700
epoch 400 LossPred 0.3761 LossAtt 0.3299 TrainAcc 0.8800 TestAcc 0.8103 0.8650
epoch 500 LossPred 0.3585 LossAtt 0.3119 TrainAcc 0.8800 TestAcc 0.8223 0.8650
epoch 600 LossPred 0.3550 LossAtt 0.3053 TrainAcc 0.9000 TestAcc 0.8478 0.8750
epoch 700 LossPred 0.4014 LossAtt 0.3351 TrainAcc 0.8600 TestAcc 0.8218 0.8550
epoch 800 LossPred 0.2136 LossAtt 0.3804 TrainAcc 0.9200 TestAcc 0.8664 0.9100
epoch 900 LossPred 0.2880 LossAtt 0.3925 TrainAcc 0.9000 TestAcc 0.8456 0.9050
epoch 1000 LossPred 0.2018 LossAtt 0.3811 TrainAcc 0.9300 TestAcc 0.8646 0.9350
epoch 1100 LossPred 0.1668 LossAtt 0.3861 TrainAcc 0.9600 TestAcc 0.8814 0.9300
epoch 1200 LossPred 0.1279 LossAtt 0.3689 TrainAcc 0.9700 TestAcc 0.9067 0.9500
epoch 1300 LossPred 0.1325 LossAtt 0.3507 TrainAcc 0.9700 TestAcc 0.9072 0.9450
epoch 1400 LossPred 0.0490 LossAtt 0.3626 TrainAcc 0.9800 TestAcc 0.8931 0.9500
epoch 1500 LossPred 0.0776 LossAtt 0.3592 TrainAcc 0.9700 TestAcc 0.9087 0.9550
epoch 1600 LossPred 0.0357 LossAtt 0.3488 TrainAcc 0.9900 TestAcc 0.8959 0.9600
epoch 1700 LossPred 0.0634 LossAtt 0.3470 TrainAcc 0.9800 TestAcc 0.8874 0.9450
epoch 1800 LossPred 0.0386 LossAtt 0.3442 TrainAcc 0.9900 TestAcc 0.9037 0.9600
epoch 1900 LossPred 0.0817 LossAtt 0.3375 TrainAcc 0.9800 TestAcc 0.8896 0.9650
epoch 2000 LossPred 0.0697 LossAtt 0.3305 TrainAcc 0.9800 TestAcc 0.8934 0.9650
epoch 2100 LossPred 0.0894 LossAtt 0.3208 TrainAcc 0.9700 TestAcc 0.9087 0.9500
epoch 2200 LossPred 0.0349 LossAtt 0.3053 TrainAcc 0.9900 TestAcc 0.8939 0.9650
epoch 2300 LossPred 0.0283 LossAtt 0.3100 TrainAcc 0.9900 TestAcc 0.9072 0.9650
epoch 2400 LossPred 0.0737 LossAtt 0.3028 TrainAcc 0.9700 TestAcc 0.9044 0.9600
epoch 2500 LossPred 0.0290 LossAtt 0.2948 TrainAcc 0.9900 TestAcc 0.9049 0.9700
Optimization Finished!
********** replication  90  **********
epoch   0 LossPred 1.0583 LossAtt 1.0411 TrainAcc 0.4400 TestAcc 0.5118 0.4350
epoch 100 LossPred 0.8578 LossAtt 0.3199 TrainAcc 0.6600 TestAcc 0.5796 0.6600
epoch 200 LossPred 0.8306 LossAtt 0.2645 TrainAcc 0.6700 TestAcc 0.5866 0.6700
epoch 300 LossPred 0.7968 LossAtt 0.2629 TrainAcc 0.6900 TestAcc 0.6479 0.7000
epoch 400 LossPred 0.4186 LossAtt 0.2729 TrainAcc 0.8800 TestAcc 0.8766 0.8500
epoch 500 LossPred 0.3353 LossAtt 0.2820 TrainAcc 0.8800 TestAcc 0.8771 0.8550
epoch 600 LossPred 0.2798 LossAtt 0.2691 TrainAcc 0.9100 TestAcc 0.9012 0.8750
epoch 700 LossPred 0.2772 LossAtt 0.2392 TrainAcc 0.8700 TestAcc 0.8971 0.8900
epoch 800 LossPred 0.2266 LossAtt 0.2672 TrainAcc 0.9400 TestAcc 0.8981 0.9000
epoch 900 LossPred 0.1249 LossAtt 0.2945 TrainAcc 0.9500 TestAcc 0.9164 0.9250
epoch 1000 LossPred 0.1051 LossAtt 0.2788 TrainAcc 0.9700 TestAcc 0.9164 0.9250
epoch 1100 LossPred 0.0935 LossAtt 0.2764 TrainAcc 0.9700 TestAcc 0.9202 0.9300
epoch 1200 LossPred 0.0873 LossAtt 0.2831 TrainAcc 0.9800 TestAcc 0.9207 0.9450
epoch 1300 LossPred 0.1131 LossAtt 0.2714 TrainAcc 0.9600 TestAcc 0.9174 0.9150
epoch 1400 LossPred 0.1411 LossAtt 0.2678 TrainAcc 0.9500 TestAcc 0.9129 0.9050
epoch 1500 LossPred 0.0788 LossAtt 0.2699 TrainAcc 0.9800 TestAcc 0.9232 0.9500
epoch 1600 LossPred 0.0785 LossAtt 0.2654 TrainAcc 0.9800 TestAcc 0.9252 0.9500
epoch 1700 LossPred 0.2276 LossAtt 0.2835 TrainAcc 0.9100 TestAcc 0.8876 0.9250
epoch 1800 LossPred 0.1093 LossAtt 0.2875 TrainAcc 0.9500 TestAcc 0.9049 0.9500
epoch 1900 LossPred 0.1349 LossAtt 0.2783 TrainAcc 0.9300 TestAcc 0.9017 0.9500
epoch 2000 LossPred 0.0782 LossAtt 0.2767 TrainAcc 0.9700 TestAcc 0.9139 0.9450
epoch 2100 LossPred 0.0662 LossAtt 0.2548 TrainAcc 0.9900 TestAcc 0.9129 0.9650
epoch 2200 LossPred 0.0668 LossAtt 0.2590 TrainAcc 0.9900 TestAcc 0.9134 0.9600
epoch 2300 LossPred 0.1110 LossAtt 0.2647 TrainAcc 0.9500 TestAcc 0.9047 0.9200
epoch 2400 LossPred 0.0770 LossAtt 0.2700 TrainAcc 0.9900 TestAcc 0.9009 0.9700
epoch 2500 LossPred 0.0698 LossAtt 0.2615 TrainAcc 0.9900 TestAcc 0.9017 0.9750
Optimization Finished!
********** replication  91  **********
epoch   0 LossPred 1.0625 LossAtt 1.0871 TrainAcc 0.4600 TestAcc 0.4119 0.4650
epoch 100 LossPred 0.9053 LossAtt 0.3623 TrainAcc 0.6300 TestAcc 0.5803 0.6150
epoch 200 LossPred 0.3326 LossAtt 0.4058 TrainAcc 0.9200 TestAcc 0.8796 0.8750
epoch 300 LossPred 0.1818 LossAtt 0.3930 TrainAcc 0.9600 TestAcc 0.8966 0.9250
epoch 400 LossPred 0.1046 LossAtt 0.3877 TrainAcc 0.9900 TestAcc 0.9272 0.9550
epoch 500 LossPred 0.0755 LossAtt 0.3804 TrainAcc 0.9900 TestAcc 0.9532 0.9650
epoch 600 LossPred 0.1573 LossAtt 0.3832 TrainAcc 0.9600 TestAcc 0.8781 0.9300
epoch 700 LossPred 0.0454 LossAtt 0.3541 TrainAcc 1.0000 TestAcc 0.9575 0.9650
Optimization Finished!
********** replication  92  **********
epoch   0 LossPred 1.2024 LossAtt 1.0430 TrainAcc 0.4500 TestAcc 0.4692 0.4750
epoch 100 LossPred 0.8231 LossAtt 0.2640 TrainAcc 0.6800 TestAcc 0.5911 0.6800
epoch 200 LossPred 0.4282 LossAtt 0.3436 TrainAcc 0.8400 TestAcc 0.8108 0.8500
epoch 300 LossPred 0.3608 LossAtt 0.2943 TrainAcc 0.8700 TestAcc 0.8501 0.8500
epoch 400 LossPred 0.3031 LossAtt 0.2641 TrainAcc 0.9000 TestAcc 0.8639 0.8900
epoch 500 LossPred 0.3099 LossAtt 0.2640 TrainAcc 0.9000 TestAcc 0.8679 0.8650
epoch 600 LossPred 0.2996 LossAtt 0.2837 TrainAcc 0.9100 TestAcc 0.8684 0.8650
epoch 700 LossPred 0.2498 LossAtt 0.3149 TrainAcc 0.9200 TestAcc 0.8954 0.8800
epoch 800 LossPred 0.2162 LossAtt 0.3184 TrainAcc 0.9200 TestAcc 0.9129 0.9000
epoch 900 LossPred 0.1923 LossAtt 0.3016 TrainAcc 0.9400 TestAcc 0.9299 0.9200
epoch 1000 LossPred 0.1323 LossAtt 0.2855 TrainAcc 0.9600 TestAcc 0.9377 0.9350
epoch 1100 LossPred 0.1868 LossAtt 0.2932 TrainAcc 0.9300 TestAcc 0.9087 0.9200
epoch 1200 LossPred 0.1396 LossAtt 0.2876 TrainAcc 0.9800 TestAcc 0.9592 0.9250
epoch 1300 LossPred 0.1579 LossAtt 0.2821 TrainAcc 0.9500 TestAcc 0.9174 0.9300
epoch 1400 LossPred 0.2281 LossAtt 0.2739 TrainAcc 0.9300 TestAcc 0.8501 0.9150
epoch 1500 LossPred 0.1585 LossAtt 0.2681 TrainAcc 0.9400 TestAcc 0.9582 0.9000
epoch 1600 LossPred 0.1326 LossAtt 0.2549 TrainAcc 0.9600 TestAcc 0.9379 0.9250
epoch 1700 LossPred 0.1117 LossAtt 0.2502 TrainAcc 0.9800 TestAcc 0.9467 0.9200
epoch 1800 LossPred 0.1464 LossAtt 0.2506 TrainAcc 0.9500 TestAcc 0.9499 0.9000
epoch 1900 LossPred 0.1534 LossAtt 0.2451 TrainAcc 0.9400 TestAcc 0.9067 0.9400
epoch 2000 LossPred 0.1503 LossAtt 0.2488 TrainAcc 0.9400 TestAcc 0.9374 0.9200
epoch 2100 LossPred 0.1977 LossAtt 0.2410 TrainAcc 0.9400 TestAcc 0.8796 0.9350
epoch 2200 LossPred 0.2210 LossAtt 0.2326 TrainAcc 0.9100 TestAcc 0.9187 0.9000
epoch 2300 LossPred 0.1240 LossAtt 0.2266 TrainAcc 0.9700 TestAcc 0.9329 0.9450
epoch 2400 LossPred 0.3610 LossAtt 0.2308 TrainAcc 0.8900 TestAcc 0.8183 0.8900
epoch 2500 LossPred 0.2242 LossAtt 0.2403 TrainAcc 0.9200 TestAcc 0.9002 0.9000
Optimization Finished!
********** replication  93  **********
epoch   0 LossPred 1.1611 LossAtt 1.0111 TrainAcc 0.4800 TestAcc 0.5258 0.4600
epoch 100 LossPred 0.8591 LossAtt 0.3265 TrainAcc 0.6500 TestAcc 0.5963 0.6500
epoch 200 LossPred 0.7987 LossAtt 0.2987 TrainAcc 0.6600 TestAcc 0.6456 0.6600
epoch 300 LossPred 0.3770 LossAtt 0.3506 TrainAcc 0.8700 TestAcc 0.8318 0.8700
epoch 400 LossPred 0.3739 LossAtt 0.3196 TrainAcc 0.8600 TestAcc 0.8071 0.8700
epoch 500 LossPred 0.2980 LossAtt 0.3148 TrainAcc 0.9000 TestAcc 0.8501 0.8650
epoch 600 LossPred 0.2924 LossAtt 0.3120 TrainAcc 0.9100 TestAcc 0.8579 0.8800
epoch 700 LossPred 0.2762 LossAtt 0.2979 TrainAcc 0.9200 TestAcc 0.8546 0.8750
epoch 800 LossPred 0.3606 LossAtt 0.2891 TrainAcc 0.8800 TestAcc 0.8504 0.8800
epoch 900 LossPred 0.2199 LossAtt 0.2743 TrainAcc 0.9400 TestAcc 0.8338 0.8700
epoch 1000 LossPred 0.2496 LossAtt 0.2819 TrainAcc 0.9300 TestAcc 0.8574 0.8900
epoch 1100 LossPred 0.3129 LossAtt 0.2760 TrainAcc 0.8800 TestAcc 0.8273 0.8500
epoch 1200 LossPred 0.1893 LossAtt 0.2711 TrainAcc 0.9500 TestAcc 0.8356 0.8800
epoch 1300 LossPred 0.2192 LossAtt 0.2652 TrainAcc 0.9400 TestAcc 0.8453 0.8850
epoch 1400 LossPred 0.1878 LossAtt 0.2670 TrainAcc 0.9400 TestAcc 0.8476 0.8850
epoch 1500 LossPred 0.2550 LossAtt 0.2639 TrainAcc 0.9100 TestAcc 0.8674 0.8900
epoch 1600 LossPred 0.1886 LossAtt 0.2521 TrainAcc 0.9300 TestAcc 0.8493 0.9000
epoch 1700 LossPred 0.1907 LossAtt 0.2443 TrainAcc 0.9400 TestAcc 0.8639 0.9050
epoch 1800 LossPred 0.2169 LossAtt 0.2580 TrainAcc 0.9400 TestAcc 0.8631 0.8950
epoch 1900 LossPred 0.1873 LossAtt 0.2474 TrainAcc 0.9400 TestAcc 0.8388 0.8850
epoch 2000 LossPred 0.3386 LossAtt 0.2459 TrainAcc 0.9000 TestAcc 0.8661 0.8700
epoch 2100 LossPred 0.2695 LossAtt 0.2432 TrainAcc 0.8800 TestAcc 0.8321 0.8750
epoch 2200 LossPred 0.2889 LossAtt 0.2572 TrainAcc 0.8900 TestAcc 0.8641 0.8750
epoch 2300 LossPred 0.3195 LossAtt 0.2366 TrainAcc 0.8700 TestAcc 0.8186 0.8600
epoch 2400 LossPred 0.2182 LossAtt 0.2655 TrainAcc 0.9300 TestAcc 0.8666 0.9100
epoch 2500 LossPred 0.2677 LossAtt 0.2577 TrainAcc 0.9100 TestAcc 0.8679 0.8950
Optimization Finished!
********** replication  94  **********
epoch   0 LossPred 1.1919 LossAtt 1.0235 TrainAcc 0.5200 TestAcc 0.4897 0.4900
epoch 100 LossPred 0.8654 LossAtt 0.3704 TrainAcc 0.6100 TestAcc 0.5826 0.6100
epoch 200 LossPred 0.8043 LossAtt 0.2920 TrainAcc 0.7100 TestAcc 0.6296 0.7150
epoch 300 LossPred 0.7458 LossAtt 0.3405 TrainAcc 0.7400 TestAcc 0.6011 0.7350
epoch 400 LossPred 0.6400 LossAtt 0.4397 TrainAcc 0.8000 TestAcc 0.6351 0.7750
epoch 500 LossPred 0.3942 LossAtt 0.4077 TrainAcc 0.8900 TestAcc 0.7553 0.8300
epoch 600 LossPred 0.3093 LossAtt 0.3799 TrainAcc 0.9200 TestAcc 0.7718 0.8750
epoch 700 LossPred 0.2519 LossAtt 0.3928 TrainAcc 0.9300 TestAcc 0.8113 0.8950
epoch 800 LossPred 0.1928 LossAtt 0.4182 TrainAcc 0.9700 TestAcc 0.8251 0.9200
epoch 900 LossPred 0.1456 LossAtt 0.4226 TrainAcc 0.9700 TestAcc 0.8448 0.8950
epoch 1000 LossPred 0.1309 LossAtt 0.4097 TrainAcc 0.9800 TestAcc 0.8323 0.8950
epoch 1100 LossPred 0.0880 LossAtt 0.4133 TrainAcc 0.9900 TestAcc 0.8599 0.9300
epoch 1200 LossPred 0.0896 LossAtt 0.4084 TrainAcc 0.9900 TestAcc 0.8566 0.9200
epoch 1300 LossPred 0.0654 LossAtt 0.4031 TrainAcc 0.9900 TestAcc 0.8659 0.9200
epoch 1400 LossPred 0.2710 LossAtt 0.4056 TrainAcc 0.9100 TestAcc 0.8023 0.8600
epoch 1500 LossPred 0.2316 LossAtt 0.3994 TrainAcc 0.9200 TestAcc 0.8036 0.8850
epoch 1600 LossPred 0.1312 LossAtt 0.3888 TrainAcc 0.9600 TestAcc 0.8286 0.9100
epoch 1700 LossPred 0.0793 LossAtt 0.3815 TrainAcc 0.9700 TestAcc 0.8356 0.9500
epoch 1800 LossPred 0.0589 LossAtt 0.3732 TrainAcc 0.9900 TestAcc 0.8256 0.9400
epoch 1900 LossPred 0.1042 LossAtt 0.3618 TrainAcc 0.9800 TestAcc 0.8108 0.9150
epoch 2000 LossPred 0.1377 LossAtt 0.3499 TrainAcc 0.9800 TestAcc 0.7983 0.9100
epoch 2100 LossPred 0.1034 LossAtt 0.3470 TrainAcc 0.9700 TestAcc 0.8033 0.9000
epoch 2200 LossPred 0.1496 LossAtt 0.3599 TrainAcc 0.9700 TestAcc 0.8008 0.8800
epoch 2300 LossPred 0.0331 LossAtt 0.3426 TrainAcc 1.0000 TestAcc 0.8046 0.9300
Optimization Finished!
********** replication  95  **********
epoch   0 LossPred 1.1486 LossAtt 1.0470 TrainAcc 0.3700 TestAcc 0.4154 0.3750
epoch 100 LossPred 0.7981 LossAtt 0.2911 TrainAcc 0.6900 TestAcc 0.6011 0.6900
epoch 200 LossPred 0.6798 LossAtt 0.3030 TrainAcc 0.7700 TestAcc 0.6572 0.7650
epoch 300 LossPred 0.3352 LossAtt 0.3234 TrainAcc 0.9100 TestAcc 0.8661 0.8750
epoch 400 LossPred 0.3737 LossAtt 0.3173 TrainAcc 0.8800 TestAcc 0.8498 0.8650
epoch 500 LossPred 0.2847 LossAtt 0.2924 TrainAcc 0.9000 TestAcc 0.8711 0.8900
epoch 600 LossPred 0.2477 LossAtt 0.2817 TrainAcc 0.9300 TestAcc 0.8669 0.8950
epoch 700 LossPred 0.2427 LossAtt 0.2877 TrainAcc 0.9200 TestAcc 0.8764 0.9050
epoch 800 LossPred 0.2585 LossAtt 0.2639 TrainAcc 0.9300 TestAcc 0.8529 0.8700
epoch 900 LossPred 0.2073 LossAtt 0.2871 TrainAcc 0.9400 TestAcc 0.8914 0.9100
epoch 1000 LossPred 0.2814 LossAtt 0.2845 TrainAcc 0.9200 TestAcc 0.8649 0.8950
epoch 1100 LossPred 0.2330 LossAtt 0.2903 TrainAcc 0.9200 TestAcc 0.8854 0.9000
epoch 1200 LossPred 0.2360 LossAtt 0.3115 TrainAcc 0.9200 TestAcc 0.8609 0.8950
epoch 1300 LossPred 0.3738 LossAtt 0.3180 TrainAcc 0.8700 TestAcc 0.8263 0.8400
epoch 1400 LossPred 0.2338 LossAtt 0.3262 TrainAcc 0.9200 TestAcc 0.8584 0.9050
epoch 1500 LossPred 0.2146 LossAtt 0.3034 TrainAcc 0.9300 TestAcc 0.8614 0.8900
epoch 1600 LossPred 0.2242 LossAtt 0.3022 TrainAcc 0.9200 TestAcc 0.8604 0.8800
epoch 1700 LossPred 0.2273 LossAtt 0.3061 TrainAcc 0.9400 TestAcc 0.8834 0.9050
epoch 1800 LossPred 0.1805 LossAtt 0.3144 TrainAcc 0.9300 TestAcc 0.8846 0.9150
epoch 1900 LossPred 0.1517 LossAtt 0.3218 TrainAcc 0.9500 TestAcc 0.8961 0.9400
epoch 2000 LossPred 0.2852 LossAtt 0.3361 TrainAcc 0.8800 TestAcc 0.8443 0.8750
epoch 2100 LossPred 0.1857 LossAtt 0.3300 TrainAcc 0.9300 TestAcc 0.8836 0.9350
epoch 2200 LossPred 0.1293 LossAtt 0.3451 TrainAcc 0.9600 TestAcc 0.9052 0.9350
epoch 2300 LossPred 0.1334 LossAtt 0.3519 TrainAcc 0.9600 TestAcc 0.9012 0.9350
epoch 2400 LossPred 0.1506 LossAtt 0.3432 TrainAcc 0.9600 TestAcc 0.8819 0.9400
epoch 2500 LossPred 0.1440 LossAtt 0.3329 TrainAcc 0.9500 TestAcc 0.8756 0.9350
Optimization Finished!
********** replication  96  **********
epoch   0 LossPred 1.0495 LossAtt 1.0150 TrainAcc 0.5000 TestAcc 0.4675 0.5050
epoch 100 LossPred 0.9018 LossAtt 0.3447 TrainAcc 0.6800 TestAcc 0.6164 0.6850
epoch 200 LossPred 0.3729 LossAtt 0.4299 TrainAcc 0.9200 TestAcc 0.8599 0.8750
epoch 300 LossPred 0.2355 LossAtt 0.4309 TrainAcc 0.9500 TestAcc 0.8566 0.8650
epoch 400 LossPred 0.1963 LossAtt 0.4103 TrainAcc 0.9500 TestAcc 0.8591 0.8750
epoch 500 LossPred 0.2077 LossAtt 0.4161 TrainAcc 0.9300 TestAcc 0.8569 0.8950
epoch 600 LossPred 0.2950 LossAtt 0.4040 TrainAcc 0.9200 TestAcc 0.8423 0.8750
epoch 700 LossPred 0.1834 LossAtt 0.3986 TrainAcc 0.9200 TestAcc 0.8584 0.8950
epoch 800 LossPred 0.1187 LossAtt 0.3865 TrainAcc 0.9800 TestAcc 0.8684 0.9250
epoch 900 LossPred 0.1765 LossAtt 0.3823 TrainAcc 0.9400 TestAcc 0.8514 0.8950
epoch 1000 LossPred 0.0997 LossAtt 0.3740 TrainAcc 0.9800 TestAcc 0.8719 0.9150
epoch 1100 LossPred 0.1020 LossAtt 0.3712 TrainAcc 0.9800 TestAcc 0.8694 0.9250
epoch 1200 LossPred 0.0987 LossAtt 0.3584 TrainAcc 0.9700 TestAcc 0.8659 0.9200
epoch 1300 LossPred 0.1083 LossAtt 0.3740 TrainAcc 0.9700 TestAcc 0.8626 0.9150
epoch 1400 LossPred 0.0582 LossAtt 0.3664 TrainAcc 0.9900 TestAcc 0.8759 0.9400
epoch 1500 LossPred 0.0936 LossAtt 0.3650 TrainAcc 0.9600 TestAcc 0.8634 0.9300
epoch 1600 LossPred 0.0893 LossAtt 0.3671 TrainAcc 0.9700 TestAcc 0.8636 0.9250
epoch 1700 LossPred 0.0542 LossAtt 0.3771 TrainAcc 0.9900 TestAcc 0.8649 0.9350
epoch 1800 LossPred 0.0376 LossAtt 0.3816 TrainAcc 0.9900 TestAcc 0.8721 0.9500
epoch 1900 LossPred 0.0478 LossAtt 0.3771 TrainAcc 0.9900 TestAcc 0.8741 0.9450
epoch 2000 LossPred 0.0213 LossAtt 0.3658 TrainAcc 1.0000 TestAcc 0.8736 0.9500
Optimization Finished!
********** replication  97  **********
epoch   0 LossPred 1.0015 LossAtt 1.0539 TrainAcc 0.5200 TestAcc 0.4572 0.5250
epoch 100 LossPred 0.9324 LossAtt 0.3942 TrainAcc 0.6000 TestAcc 0.5848 0.6000
epoch 200 LossPred 0.4258 LossAtt 0.3891 TrainAcc 0.8700 TestAcc 0.8546 0.8400
epoch 300 LossPred 0.3112 LossAtt 0.3685 TrainAcc 0.9200 TestAcc 0.8694 0.8450
epoch 400 LossPred 0.4136 LossAtt 0.3541 TrainAcc 0.8500 TestAcc 0.8293 0.8000
epoch 500 LossPred 0.2859 LossAtt 0.3347 TrainAcc 0.9200 TestAcc 0.8651 0.8750
epoch 600 LossPred 0.2690 LossAtt 0.3257 TrainAcc 0.9200 TestAcc 0.8684 0.8850
epoch 700 LossPred 0.2690 LossAtt 0.3203 TrainAcc 0.9200 TestAcc 0.8681 0.8800
epoch 800 LossPred 0.3105 LossAtt 0.3172 TrainAcc 0.8900 TestAcc 0.8546 0.8450
epoch 900 LossPred 0.2528 LossAtt 0.3266 TrainAcc 0.9200 TestAcc 0.8676 0.8750
epoch 1000 LossPred 0.2392 LossAtt 0.3128 TrainAcc 0.9400 TestAcc 0.8694 0.8850
epoch 1100 LossPred 0.2353 LossAtt 0.3097 TrainAcc 0.9200 TestAcc 0.8656 0.8750
epoch 1200 LossPred 0.2367 LossAtt 0.3130 TrainAcc 0.9300 TestAcc 0.8659 0.8900
epoch 1300 LossPred 0.2170 LossAtt 0.3100 TrainAcc 0.9400 TestAcc 0.8689 0.8950
epoch 1400 LossPred 0.2068 LossAtt 0.3024 TrainAcc 0.9400 TestAcc 0.8616 0.8950
epoch 1500 LossPred 0.2532 LossAtt 0.3088 TrainAcc 0.9200 TestAcc 0.8476 0.8900
epoch 1600 LossPred 0.1955 LossAtt 0.3103 TrainAcc 0.9600 TestAcc 0.8649 0.8900
epoch 1700 LossPred 0.2222 LossAtt 0.3207 TrainAcc 0.9300 TestAcc 0.8448 0.9000
epoch 1800 LossPred 0.2124 LossAtt 0.3176 TrainAcc 0.9400 TestAcc 0.8566 0.9000
epoch 1900 LossPred 0.1955 LossAtt 0.3220 TrainAcc 0.9500 TestAcc 0.8476 0.8900
epoch 2000 LossPred 0.1742 LossAtt 0.3013 TrainAcc 0.9500 TestAcc 0.8539 0.9000
epoch 2100 LossPred 0.1614 LossAtt 0.2958 TrainAcc 0.9500 TestAcc 0.8438 0.8950
epoch 2200 LossPred 0.2067 LossAtt 0.2912 TrainAcc 0.9300 TestAcc 0.8463 0.8750
epoch 2300 LossPred 0.1358 LossAtt 0.2836 TrainAcc 0.9500 TestAcc 0.8519 0.9200
epoch 2400 LossPred 0.1414 LossAtt 0.2844 TrainAcc 0.9500 TestAcc 0.8594 0.9400
epoch 2500 LossPred 0.1478 LossAtt 0.2702 TrainAcc 0.9600 TestAcc 0.8646 0.9350
Optimization Finished!
********** replication  98  **********
epoch   0 LossPred 0.9961 LossAtt 1.0573 TrainAcc 0.6300 TestAcc 0.5868 0.5700
epoch 100 LossPred 0.8520 LossAtt 0.2654 TrainAcc 0.6400 TestAcc 0.5433 0.6250
epoch 200 LossPred 0.8264 LossAtt 0.2001 TrainAcc 0.7000 TestAcc 0.6151 0.6400
epoch 300 LossPred 0.4648 LossAtt 0.2443 TrainAcc 0.8300 TestAcc 0.8476 0.8150
epoch 400 LossPred 0.4673 LossAtt 0.2479 TrainAcc 0.8300 TestAcc 0.8398 0.8200
epoch 500 LossPred 0.3389 LossAtt 0.2499 TrainAcc 0.8700 TestAcc 0.8724 0.8750
epoch 600 LossPred 0.2618 LossAtt 0.2431 TrainAcc 0.9000 TestAcc 0.9017 0.8800
epoch 700 LossPred 0.2444 LossAtt 0.2339 TrainAcc 0.9000 TestAcc 0.9247 0.8750
epoch 800 LossPred 0.2806 LossAtt 0.2394 TrainAcc 0.9000 TestAcc 0.8819 0.8850
epoch 900 LossPred 0.3968 LossAtt 0.2378 TrainAcc 0.8500 TestAcc 0.8561 0.8550
epoch 1000 LossPred 0.2877 LossAtt 0.2173 TrainAcc 0.8900 TestAcc 0.9229 0.8800
epoch 1100 LossPred 0.3265 LossAtt 0.2340 TrainAcc 0.9000 TestAcc 0.8706 0.8700
epoch 1200 LossPred 0.1908 LossAtt 0.2252 TrainAcc 0.9400 TestAcc 0.9547 0.9100
epoch 1300 LossPred 0.2156 LossAtt 0.2355 TrainAcc 0.9200 TestAcc 0.9444 0.9000
epoch 1400 LossPred 0.3189 LossAtt 0.2436 TrainAcc 0.8800 TestAcc 0.8671 0.8800
epoch 1500 LossPred 0.1727 LossAtt 0.2567 TrainAcc 0.9400 TestAcc 0.9194 0.9150
epoch 1600 LossPred 0.1345 LossAtt 0.2610 TrainAcc 0.9600 TestAcc 0.9655 0.9400
epoch 1700 LossPred 0.1280 LossAtt 0.2740 TrainAcc 0.9500 TestAcc 0.9409 0.9300
epoch 1800 LossPred 0.1399 LossAtt 0.2741 TrainAcc 0.9700 TestAcc 0.9505 0.9450
epoch 1900 LossPred 0.1501 LossAtt 0.2759 TrainAcc 0.9500 TestAcc 0.9094 0.9250
epoch 2000 LossPred 0.1102 LossAtt 0.2613 TrainAcc 0.9800 TestAcc 0.9379 0.9550
epoch 2100 LossPred 0.1279 LossAtt 0.2888 TrainAcc 0.9500 TestAcc 0.9219 0.9400
epoch 2200 LossPred 0.1509 LossAtt 0.2739 TrainAcc 0.9200 TestAcc 0.9107 0.9350
epoch 2300 LossPred 0.1264 LossAtt 0.2626 TrainAcc 0.9600 TestAcc 0.9464 0.9500
epoch 2400 LossPred 0.1113 LossAtt 0.2584 TrainAcc 0.9700 TestAcc 0.9417 0.9500
epoch 2500 LossPred 0.1663 LossAtt 0.2588 TrainAcc 0.9400 TestAcc 0.9292 0.9400
Optimization Finished!
********** replication  99  **********
epoch   0 LossPred 1.0988 LossAtt 1.0067 TrainAcc 0.4300 TestAcc 0.5148 0.4250
epoch 100 LossPred 0.9639 LossAtt 0.3223 TrainAcc 0.5700 TestAcc 0.5018 0.5550
epoch 200 LossPred 0.8575 LossAtt 0.3930 TrainAcc 0.6800 TestAcc 0.5546 0.6800
epoch 300 LossPred 0.7625 LossAtt 0.4070 TrainAcc 0.7300 TestAcc 0.5721 0.7350
epoch 400 LossPred 0.6225 LossAtt 0.4739 TrainAcc 0.8300 TestAcc 0.5888 0.8250
epoch 500 LossPred 0.5086 LossAtt 0.4961 TrainAcc 0.8400 TestAcc 0.6346 0.8650
epoch 600 LossPred 0.3912 LossAtt 0.5368 TrainAcc 0.8900 TestAcc 0.6471 0.8800
epoch 700 LossPred 0.3004 LossAtt 0.5390 TrainAcc 0.9100 TestAcc 0.6509 0.8600
epoch 800 LossPred 0.2925 LossAtt 0.5334 TrainAcc 0.9100 TestAcc 0.6522 0.8650
epoch 900 LossPred 0.2399 LossAtt 0.5155 TrainAcc 0.9300 TestAcc 0.6451 0.8650
epoch 1000 LossPred 0.2881 LossAtt 0.5323 TrainAcc 0.9100 TestAcc 0.6486 0.8500
epoch 1100 LossPred 0.2110 LossAtt 0.5086 TrainAcc 0.9500 TestAcc 0.6414 0.8550
epoch 1200 LossPred 0.2037 LossAtt 0.4931 TrainAcc 0.9500 TestAcc 0.6381 0.8750
epoch 1300 LossPred 0.1813 LossAtt 0.4958 TrainAcc 0.9700 TestAcc 0.6339 0.8700
epoch 1400 LossPred 0.1774 LossAtt 0.4810 TrainAcc 0.9600 TestAcc 0.6344 0.8800
epoch 1500 LossPred 0.1507 LossAtt 0.5035 TrainAcc 0.9800 TestAcc 0.6299 0.8850
epoch 1600 LossPred 0.1648 LossAtt 0.4917 TrainAcc 0.9600 TestAcc 0.6299 0.8600
epoch 1700 LossPred 0.1374 LossAtt 0.4718 TrainAcc 0.9800 TestAcc 0.6326 0.8850
epoch 1800 LossPred 0.1327 LossAtt 0.4993 TrainAcc 0.9700 TestAcc 0.6274 0.8900
epoch 1900 LossPred 0.1175 LossAtt 0.4721 TrainAcc 0.9800 TestAcc 0.6291 0.8950
epoch 2000 LossPred 0.1240 LossAtt 0.4670 TrainAcc 0.9800 TestAcc 0.6261 0.8950
epoch 2100 LossPred 0.1103 LossAtt 0.4849 TrainAcc 0.9800 TestAcc 0.6289 0.8900
epoch 2200 LossPred 0.1052 LossAtt 0.4748 TrainAcc 0.9800 TestAcc 0.6201 0.9250
epoch 2300 LossPred 0.1280 LossAtt 0.4707 TrainAcc 0.9700 TestAcc 0.6281 0.9050
epoch 2400 LossPred 0.1027 LossAtt 0.4588 TrainAcc 0.9700 TestAcc 0.6184 0.9150
epoch 2500 LossPred 0.0999 LossAtt 0.4746 TrainAcc 0.9800 TestAcc 0.6194 0.9150
Optimization Finished!
********************************************************************
Namespace(arch='tanh', batch_size=256, display_epoch=100, input_noise_level=0.15, latent_attractor_space=True, loss_switch_frequency=0, lrate_attractor=0.002, lrate_prediction=0.002, lrate_wt_penalty=0.0, n_attractor_hidden=20, n_attractor_steps=5, n_hidden=10, n_replications=100, noise_level=0.25, report_best_train_performance=True, seq_len=20, task='majority', train_attr_weights_on_prediction=False, training_epochs=2500)
********************************************************************
mean train accuracy 0.97520006
indiv runs  [0.99, 0.99, 0.98, 0.99, 0.93, 1.0, 0.93, 0.98, 1.0, 1.0, 1.0, 0.99, 1.0, 1.0, 1.0, 0.97, 0.98, 0.98, 0.98, 0.99, 1.0, 0.98, 0.93, 0.94, 0.97, 0.89, 0.93, 0.99, 0.95, 0.95, 1.0, 0.85, 0.98, 1.0, 0.95, 0.99, 0.99, 0.96, 0.98, 1.0, 0.93, 1.0, 1.0, 1.0, 0.98, 0.94, 1.0, 0.98, 1.0, 0.98, 0.98, 1.0, 1.0, 0.96, 0.97, 0.96, 0.99, 1.0, 0.93, 1.0, 0.97, 1.0, 0.93, 0.96, 0.97, 0.93, 0.97, 0.97, 0.95, 1.0, 1.0, 0.98, 0.93, 0.9, 0.95, 0.97, 0.99, 0.95, 0.99, 1.0, 0.95, 1.0, 0.98, 1.0, 1.0, 1.0, 0.98, 1.0, 1.0, 0.99, 0.99, 1.0, 0.98, 0.95, 1.0, 0.96, 1.0, 0.96, 0.98, 0.98]
mean epoch 1613.12121212
indiv epochs  [1901, 2401, 1101, 1601, 1001, 2001, 1901, 1101, 2401, 2101, 2201, 1401, 1601, 2501, 1401, 2301, 1901, 1301, 2001, 901, 1201, 901, 601, 2001, 1901, 1801, 1601, 1101, 601, 1501, 701, 2301, 2001]
test1 accuracy mean  0.864457  median  0.8857608
test2 accuracy mean  0.92579997  median  0.935
test1 indiv runs  [0.9071572, 0.8926426, 0.9179179, 0.8883884, 0.9031532, 0.9094094, 0.8375876, 0.796046, 0.9009009, 0.9014014, 0.9144144, 0.9647147, 0.9124124, 0.9181682, 0.8170671, 0.8495996, 0.9271772, 0.8826326, 0.8458458, 0.9189189, 0.9456957, 0.8831331, 0.8458458, 0.9069069, 0.9206707, 0.8230731, 0.8090591, 0.8248248, 0.6013514, 0.9134134, 0.8873874, 0.5375375, 0.8938939, 0.8883884, 0.8511011, 0.8513514, 0.8460961, 0.8698699, 0.9334334, 0.8848849, 0.6166166, 0.8836336, 0.8478478, 0.9299299, 0.793043, 0.8871371, 0.9351852, 0.8656156, 0.9409409, 0.5495495, 0.8988989, 0.9081582, 0.8395896, 0.8556056, 0.7414915, 0.9284284, 0.8921421, 0.9016517, 0.8503504, 0.9231732, 0.8390891, 0.9266767, 0.8743744, 0.8733734, 0.8963964, 0.8671171, 0.9009009, 0.8878879, 0.8881381, 0.8551051, 0.8678679, 0.8781281, 0.8691191, 0.8736236, 0.6696697, 0.8866366, 0.8566066, 0.6183684, 0.8455956, 0.9499499, 0.8943944, 0.9184184, 0.8531031, 0.8808809, 0.8363363, 0.8983984, 0.8721221, 0.9244244, 0.9534535, 0.8958959, 0.9129129, 0.9574575, 0.9592092, 0.8355856, 0.8045546, 0.9051552, 0.8736236, 0.8648649, 0.9379379, 0.6298799]
test2 indiv runs  [0.92, 0.92, 0.97, 0.94, 0.895, 0.97, 0.91, 0.94, 0.925, 0.95, 0.93, 0.97, 0.955, 0.98, 0.925, 0.94, 0.95, 0.9, 0.925, 0.99, 0.94, 0.925, 0.855, 0.905, 0.935, 0.85, 0.87, 0.92, 0.845, 0.885, 0.975, 0.75, 0.935, 0.98, 0.88, 0.925, 0.93, 0.915, 0.95, 0.955, 0.85, 0.935, 0.96, 0.98, 0.91, 0.87, 0.995, 0.955, 0.945, 0.83, 0.945, 0.965, 0.92, 0.895, 0.92, 0.92, 0.955, 0.99, 0.885, 0.96, 0.94, 0.945, 0.895, 0.885, 0.935, 0.885, 0.94, 0.93, 0.935, 0.96, 0.97, 0.96, 0.915, 0.83, 0.86, 0.955, 0.94, 0.815, 0.91, 0.97, 0.94, 0.955, 0.9, 0.97, 0.925, 0.9, 0.945, 0.95, 0.965, 0.96, 0.965, 0.965, 0.925, 0.88, 0.93, 0.935, 0.95, 0.89, 0.955, 0.885]
