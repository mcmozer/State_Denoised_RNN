Namespace(arch='tanh', batch_size=256, display_epoch=100, input_noise_level=0.15, latent_attractor_space=True, loss_switch_frequency=0, lrate_attractor=0.002, lrate_prediction=0.002, lrate_wt_penalty=0.0, n_attractor_hidden=20, n_attractor_steps=5, n_hidden=10, n_replications=100, noise_level=0.5, report_best_train_performance=True, seq_len=15, task='majority', train_attr_weights_on_prediction=False, training_epochs=2500)
TRAINING ON 100 EXAMPLES, TESTING ON 3996
********** replication  0  **********
epoch   0 LossPred 1.0935 LossAtt 1.0183 TrainAcc 0.5800 TestAcc 0.5465 0.5750
epoch 100 LossPred 0.9534 LossAtt 0.2499 TrainAcc 0.6100 TestAcc 0.5403 0.6100
epoch 200 LossPred 0.9321 LossAtt 0.2025 TrainAcc 0.6100 TestAcc 0.5403 0.6100
epoch 300 LossPred 0.8765 LossAtt 0.2115 TrainAcc 0.6600 TestAcc 0.5473 0.6600
epoch 400 LossPred 0.8539 LossAtt 0.2370 TrainAcc 0.6700 TestAcc 0.5761 0.6700
epoch 500 LossPred 0.8457 LossAtt 0.2399 TrainAcc 0.6600 TestAcc 0.5551 0.6550
epoch 600 LossPred 0.7014 LossAtt 0.3360 TrainAcc 0.7300 TestAcc 0.6712 0.7200
epoch 700 LossPred 0.3797 LossAtt 0.3414 TrainAcc 0.8900 TestAcc 0.8268 0.8550
epoch 800 LossPred 0.2341 LossAtt 0.3327 TrainAcc 0.9200 TestAcc 0.8916 0.9150
epoch 900 LossPred 0.1804 LossAtt 0.3055 TrainAcc 0.9400 TestAcc 0.8911 0.9400
epoch 1000 LossPred 0.2149 LossAtt 0.2990 TrainAcc 0.9300 TestAcc 0.8759 0.9100
epoch 1100 LossPred 0.2985 LossAtt 0.3028 TrainAcc 0.8800 TestAcc 0.8651 0.8850
epoch 1200 LossPred 0.1841 LossAtt 0.2910 TrainAcc 0.9200 TestAcc 0.8996 0.8950
epoch 1300 LossPred 0.2116 LossAtt 0.2816 TrainAcc 0.9200 TestAcc 0.8909 0.9050
epoch 1400 LossPred 0.2196 LossAtt 0.2806 TrainAcc 0.9200 TestAcc 0.9079 0.9200
epoch 1500 LossPred 0.2219 LossAtt 0.2975 TrainAcc 0.9200 TestAcc 0.8831 0.9150
epoch 1600 LossPred 0.1755 LossAtt 0.2774 TrainAcc 0.9400 TestAcc 0.8991 0.9300
epoch 1700 LossPred 0.1504 LossAtt 0.2747 TrainAcc 0.9500 TestAcc 0.9022 0.9250
epoch 1800 LossPred 0.1220 LossAtt 0.2813 TrainAcc 0.9700 TestAcc 0.9177 0.9550
epoch 1900 LossPred 0.1014 LossAtt 0.2832 TrainAcc 0.9700 TestAcc 0.9272 0.9600
epoch 2000 LossPred 0.1652 LossAtt 0.2877 TrainAcc 0.9400 TestAcc 0.9032 0.9650
epoch 2100 LossPred 0.1071 LossAtt 0.3136 TrainAcc 0.9700 TestAcc 0.9154 0.9600
epoch 2200 LossPred 0.1096 LossAtt 0.2926 TrainAcc 0.9700 TestAcc 0.9147 0.9450
epoch 2300 LossPred 0.0485 LossAtt 0.2889 TrainAcc 0.9800 TestAcc 0.9209 0.9750
epoch 2400 LossPred 0.0441 LossAtt 0.2899 TrainAcc 0.9900 TestAcc 0.9164 0.9750
epoch 2500 LossPred 0.0822 LossAtt 0.2990 TrainAcc 0.9700 TestAcc 0.9137 0.9700
Optimization Finished!
********** replication  1  **********
epoch   0 LossPred 1.1491 LossAtt 1.0223 TrainAcc 0.4400 TestAcc 0.4632 0.4250
epoch 100 LossPred 0.8146 LossAtt 0.3281 TrainAcc 0.7100 TestAcc 0.6074 0.7000
epoch 200 LossPred 0.4676 LossAtt 0.3485 TrainAcc 0.8500 TestAcc 0.8526 0.8650
epoch 300 LossPred 0.3205 LossAtt 0.3401 TrainAcc 0.8900 TestAcc 0.8478 0.8750
epoch 400 LossPred 0.2014 LossAtt 0.3204 TrainAcc 0.9500 TestAcc 0.8914 0.9200
epoch 500 LossPred 0.1490 LossAtt 0.3049 TrainAcc 0.9700 TestAcc 0.9159 0.9150
epoch 600 LossPred 0.1261 LossAtt 0.3050 TrainAcc 0.9600 TestAcc 0.8984 0.9350
epoch 700 LossPred 0.0871 LossAtt 0.3075 TrainAcc 0.9800 TestAcc 0.9079 0.9450
epoch 800 LossPred 0.0887 LossAtt 0.2962 TrainAcc 0.9800 TestAcc 0.9239 0.9500
epoch 900 LossPred 0.0874 LossAtt 0.2903 TrainAcc 0.9700 TestAcc 0.9202 0.9600
epoch 1000 LossPred 0.0681 LossAtt 0.2704 TrainAcc 0.9900 TestAcc 0.9162 0.9750
epoch 1100 LossPred 0.0861 LossAtt 0.2645 TrainAcc 0.9800 TestAcc 0.9209 0.9600
epoch 1200 LossPred 0.0593 LossAtt 0.2625 TrainAcc 1.0000 TestAcc 0.9192 0.9650
Optimization Finished!
********** replication  2  **********
epoch   0 LossPred 1.1087 LossAtt 1.0099 TrainAcc 0.3900 TestAcc 0.4292 0.4050
epoch 100 LossPred 0.8948 LossAtt 0.2671 TrainAcc 0.6300 TestAcc 0.6041 0.6150
epoch 200 LossPred 0.7859 LossAtt 0.2119 TrainAcc 0.7200 TestAcc 0.6922 0.7150
epoch 300 LossPred 0.2630 LossAtt 0.2198 TrainAcc 0.9000 TestAcc 0.8694 0.9100
epoch 400 LossPred 0.1937 LossAtt 0.2209 TrainAcc 0.9300 TestAcc 0.8859 0.9200
epoch 500 LossPred 0.1616 LossAtt 0.2384 TrainAcc 0.9600 TestAcc 0.8964 0.9350
epoch 600 LossPred 0.2275 LossAtt 0.2485 TrainAcc 0.9600 TestAcc 0.8784 0.9200
epoch 700 LossPred 0.1491 LossAtt 0.2463 TrainAcc 0.9500 TestAcc 0.8974 0.9300
epoch 800 LossPred 0.1482 LossAtt 0.2333 TrainAcc 0.9500 TestAcc 0.9072 0.9500
epoch 900 LossPred 0.2375 LossAtt 0.2385 TrainAcc 0.9200 TestAcc 0.8831 0.9450
epoch 1000 LossPred 0.1436 LossAtt 0.2286 TrainAcc 0.9500 TestAcc 0.9239 0.9600
epoch 1100 LossPred 0.1214 LossAtt 0.2114 TrainAcc 0.9800 TestAcc 0.9274 0.9700
epoch 1200 LossPred 0.1197 LossAtt 0.1933 TrainAcc 0.9600 TestAcc 0.9237 0.9700
epoch 1300 LossPred 0.1186 LossAtt 0.2109 TrainAcc 0.9700 TestAcc 0.9169 0.9600
epoch 1400 LossPred 0.1747 LossAtt 0.1991 TrainAcc 0.9400 TestAcc 0.9059 0.9450
epoch 1500 LossPred 0.1072 LossAtt 0.2020 TrainAcc 0.9700 TestAcc 0.9244 0.9750
epoch 1600 LossPred 0.1173 LossAtt 0.1983 TrainAcc 0.9800 TestAcc 0.9212 0.9600
epoch 1700 LossPred 0.1400 LossAtt 0.1902 TrainAcc 0.9700 TestAcc 0.9259 0.9650
epoch 1800 LossPred 0.1213 LossAtt 0.2002 TrainAcc 0.9700 TestAcc 0.9237 0.9600
epoch 1900 LossPred 0.1959 LossAtt 0.2012 TrainAcc 0.9200 TestAcc 0.9142 0.9400
epoch 2000 LossPred 0.1586 LossAtt 0.1919 TrainAcc 0.9500 TestAcc 0.9179 0.9400
epoch 2100 LossPred 0.1834 LossAtt 0.1765 TrainAcc 0.9600 TestAcc 0.9149 0.9550
epoch 2200 LossPred 0.2036 LossAtt 0.1688 TrainAcc 0.9400 TestAcc 0.9099 0.9300
epoch 2300 LossPred 0.1687 LossAtt 0.1612 TrainAcc 0.9500 TestAcc 0.9202 0.9450
epoch 2400 LossPred 0.1131 LossAtt 0.1459 TrainAcc 0.9600 TestAcc 0.9347 0.9600
epoch 2500 LossPred 0.0977 LossAtt 0.1467 TrainAcc 0.9700 TestAcc 0.9352 0.9650
Optimization Finished!
********** replication  3  **********
epoch   0 LossPred 1.0369 LossAtt 1.0312 TrainAcc 0.3600 TestAcc 0.4760 0.3550
epoch 100 LossPred 0.8541 LossAtt 0.2767 TrainAcc 0.7300 TestAcc 0.6577 0.7250
epoch 200 LossPred 0.2989 LossAtt 0.2933 TrainAcc 0.9100 TestAcc 0.8684 0.8900
epoch 300 LossPred 0.2891 LossAtt 0.2793 TrainAcc 0.9100 TestAcc 0.8441 0.8950
epoch 400 LossPred 0.2121 LossAtt 0.2482 TrainAcc 0.9600 TestAcc 0.8699 0.9200
epoch 500 LossPred 0.1814 LossAtt 0.2490 TrainAcc 0.9600 TestAcc 0.8856 0.9300
epoch 600 LossPred 0.1956 LossAtt 0.2399 TrainAcc 0.9500 TestAcc 0.8911 0.9250
epoch 700 LossPred 0.1453 LossAtt 0.2336 TrainAcc 0.9600 TestAcc 0.8924 0.9300
epoch 800 LossPred 0.1332 LossAtt 0.2264 TrainAcc 0.9700 TestAcc 0.8904 0.9300
epoch 900 LossPred 0.1444 LossAtt 0.2159 TrainAcc 0.9600 TestAcc 0.8709 0.9350
epoch 1000 LossPred 0.1169 LossAtt 0.2248 TrainAcc 0.9600 TestAcc 0.9077 0.9500
epoch 1100 LossPred 0.1326 LossAtt 0.2237 TrainAcc 0.9600 TestAcc 0.8966 0.9400
epoch 1200 LossPred 0.0863 LossAtt 0.2253 TrainAcc 0.9700 TestAcc 0.9274 0.9500
epoch 1300 LossPred 0.0783 LossAtt 0.2076 TrainAcc 0.9800 TestAcc 0.9367 0.9500
epoch 1400 LossPred 0.2679 LossAtt 0.2153 TrainAcc 0.9000 TestAcc 0.8584 0.8900
epoch 1500 LossPred 0.1277 LossAtt 0.2290 TrainAcc 0.9600 TestAcc 0.9317 0.9200
epoch 1600 LossPred 0.1402 LossAtt 0.2259 TrainAcc 0.9400 TestAcc 0.9189 0.9250
epoch 1700 LossPred 0.0513 LossAtt 0.2330 TrainAcc 0.9900 TestAcc 0.9439 0.9700
epoch 1800 LossPred 0.0565 LossAtt 0.2328 TrainAcc 0.9900 TestAcc 0.9459 0.9650
epoch 1900 LossPred 0.0984 LossAtt 0.2408 TrainAcc 0.9600 TestAcc 0.9214 0.9550
epoch 2000 LossPred 0.0351 LossAtt 0.2429 TrainAcc 1.0000 TestAcc 0.9520 0.9800
Optimization Finished!
********** replication  4  **********
epoch   0 LossPred 1.0277 LossAtt 1.0065 TrainAcc 0.4700 TestAcc 0.5150 0.4700
epoch 100 LossPred 0.8748 LossAtt 0.3086 TrainAcc 0.6400 TestAcc 0.5793 0.6450
epoch 200 LossPred 0.5353 LossAtt 0.3573 TrainAcc 0.8100 TestAcc 0.7690 0.8100
epoch 300 LossPred 0.3756 LossAtt 0.3044 TrainAcc 0.8600 TestAcc 0.8283 0.8500
epoch 400 LossPred 0.3285 LossAtt 0.2855 TrainAcc 0.8600 TestAcc 0.8526 0.8550
epoch 500 LossPred 0.1913 LossAtt 0.2683 TrainAcc 0.9600 TestAcc 0.9019 0.9000
epoch 600 LossPred 0.2428 LossAtt 0.2758 TrainAcc 0.9100 TestAcc 0.8939 0.9000
epoch 700 LossPred 0.2279 LossAtt 0.2624 TrainAcc 0.9200 TestAcc 0.8981 0.9150
epoch 800 LossPred 0.3113 LossAtt 0.2591 TrainAcc 0.8800 TestAcc 0.8876 0.8700
epoch 900 LossPred 0.3217 LossAtt 0.2577 TrainAcc 0.8700 TestAcc 0.8811 0.8850
epoch 1000 LossPred 0.2908 LossAtt 0.2445 TrainAcc 0.9000 TestAcc 0.8756 0.9050
epoch 1100 LossPred 0.3946 LossAtt 0.2466 TrainAcc 0.8500 TestAcc 0.8218 0.8500
epoch 1200 LossPred 0.2246 LossAtt 0.2486 TrainAcc 0.9400 TestAcc 0.8774 0.9150
epoch 1300 LossPred 0.1954 LossAtt 0.2279 TrainAcc 0.9300 TestAcc 0.8916 0.9150
epoch 1400 LossPred 0.1618 LossAtt 0.2378 TrainAcc 0.9700 TestAcc 0.9217 0.9350
epoch 1500 LossPred 0.1925 LossAtt 0.2333 TrainAcc 0.9400 TestAcc 0.9014 0.9100
epoch 1600 LossPred 0.1385 LossAtt 0.2346 TrainAcc 0.9500 TestAcc 0.9234 0.9250
epoch 1700 LossPred 0.1501 LossAtt 0.2321 TrainAcc 0.9600 TestAcc 0.9194 0.9250
epoch 1800 LossPred 0.1378 LossAtt 0.2329 TrainAcc 0.9600 TestAcc 0.9254 0.9200
epoch 1900 LossPred 0.3093 LossAtt 0.2337 TrainAcc 0.8800 TestAcc 0.9017 0.8950
epoch 2000 LossPred 0.2584 LossAtt 0.2373 TrainAcc 0.9000 TestAcc 0.9032 0.8950
epoch 2100 LossPred 0.1453 LossAtt 0.2284 TrainAcc 0.9600 TestAcc 0.9164 0.9250
epoch 2200 LossPred 0.2039 LossAtt 0.2272 TrainAcc 0.9100 TestAcc 0.8864 0.9050
epoch 2300 LossPred 0.1807 LossAtt 0.2400 TrainAcc 0.9400 TestAcc 0.9139 0.9150
epoch 2400 LossPred 0.1665 LossAtt 0.2326 TrainAcc 0.9500 TestAcc 0.9204 0.9200
epoch 2500 LossPred 0.1512 LossAtt 0.2166 TrainAcc 0.9600 TestAcc 0.9119 0.9200
Optimization Finished!
********** replication  5  **********
epoch   0 LossPred 1.1395 LossAtt 1.0013 TrainAcc 0.3600 TestAcc 0.4294 0.3650
epoch 100 LossPred 0.8564 LossAtt 0.2781 TrainAcc 0.6800 TestAcc 0.5978 0.6700
epoch 200 LossPred 0.8384 LossAtt 0.2789 TrainAcc 0.6900 TestAcc 0.5893 0.6750
epoch 300 LossPred 0.8270 LossAtt 0.2511 TrainAcc 0.6800 TestAcc 0.6134 0.6850
epoch 400 LossPred 0.8215 LossAtt 0.2447 TrainAcc 0.6900 TestAcc 0.5916 0.6850
epoch 500 LossPred 0.8159 LossAtt 0.2578 TrainAcc 0.7000 TestAcc 0.5831 0.6750
epoch 600 LossPred 0.7527 LossAtt 0.3237 TrainAcc 0.7500 TestAcc 0.6782 0.7100
epoch 700 LossPred 0.5836 LossAtt 0.2728 TrainAcc 0.8300 TestAcc 0.7485 0.8100
epoch 800 LossPred 0.4993 LossAtt 0.3025 TrainAcc 0.8500 TestAcc 0.8341 0.8550
epoch 900 LossPred 0.3510 LossAtt 0.2791 TrainAcc 0.9100 TestAcc 0.8559 0.8650
epoch 1000 LossPred 0.2953 LossAtt 0.3131 TrainAcc 0.9100 TestAcc 0.8586 0.8750
epoch 1100 LossPred 0.1699 LossAtt 0.2919 TrainAcc 0.9200 TestAcc 0.8966 0.9050
epoch 1200 LossPred 0.1100 LossAtt 0.3079 TrainAcc 0.9700 TestAcc 0.9212 0.9050
epoch 1300 LossPred 0.1037 LossAtt 0.3078 TrainAcc 0.9900 TestAcc 0.9197 0.9200
epoch 1400 LossPred 0.0653 LossAtt 0.2873 TrainAcc 1.0000 TestAcc 0.9204 0.9150
Optimization Finished!
********** replication  6  **********
epoch   0 LossPred 1.0842 LossAtt 0.9999 TrainAcc 0.4900 TestAcc 0.5075 0.5100
epoch 100 LossPred 0.9135 LossAtt 0.2347 TrainAcc 0.6100 TestAcc 0.5663 0.6050
epoch 200 LossPred 0.8014 LossAtt 0.2792 TrainAcc 0.6700 TestAcc 0.6814 0.6550
epoch 300 LossPred 0.4544 LossAtt 0.2515 TrainAcc 0.8300 TestAcc 0.8501 0.8700
epoch 400 LossPred 0.3982 LossAtt 0.2250 TrainAcc 0.8600 TestAcc 0.8333 0.8800
epoch 500 LossPred 0.3642 LossAtt 0.2072 TrainAcc 0.8800 TestAcc 0.8443 0.8800
epoch 600 LossPred 0.3412 LossAtt 0.2191 TrainAcc 0.9000 TestAcc 0.8819 0.8950
epoch 700 LossPred 0.3336 LossAtt 0.2277 TrainAcc 0.8800 TestAcc 0.8418 0.8700
epoch 800 LossPred 0.3590 LossAtt 0.2372 TrainAcc 0.8900 TestAcc 0.8799 0.8750
epoch 900 LossPred 0.2663 LossAtt 0.2177 TrainAcc 0.9000 TestAcc 0.8824 0.9100
epoch 1000 LossPred 0.2690 LossAtt 0.2060 TrainAcc 0.9100 TestAcc 0.8959 0.8950
epoch 1100 LossPred 0.2301 LossAtt 0.1946 TrainAcc 0.9200 TestAcc 0.8766 0.9000
epoch 1200 LossPred 0.1907 LossAtt 0.1936 TrainAcc 0.9500 TestAcc 0.9119 0.9200
epoch 1300 LossPred 0.1542 LossAtt 0.1812 TrainAcc 0.9600 TestAcc 0.9172 0.9350
epoch 1400 LossPred 0.1448 LossAtt 0.1882 TrainAcc 0.9600 TestAcc 0.9062 0.9500
epoch 1500 LossPred 0.1878 LossAtt 0.1822 TrainAcc 0.9400 TestAcc 0.8959 0.9300
epoch 1600 LossPred 0.1599 LossAtt 0.1735 TrainAcc 0.9500 TestAcc 0.9114 0.9550
epoch 1700 LossPred 0.1354 LossAtt 0.1777 TrainAcc 0.9600 TestAcc 0.9282 0.9600
epoch 1800 LossPred 0.1771 LossAtt 0.1733 TrainAcc 0.9400 TestAcc 0.9017 0.9500
epoch 1900 LossPred 0.1310 LossAtt 0.1750 TrainAcc 0.9600 TestAcc 0.9202 0.9600
epoch 2000 LossPred 0.1679 LossAtt 0.1732 TrainAcc 0.9400 TestAcc 0.9042 0.9500
epoch 2100 LossPred 0.1422 LossAtt 0.1723 TrainAcc 0.9500 TestAcc 0.9147 0.9600
epoch 2200 LossPred 0.1386 LossAtt 0.1723 TrainAcc 0.9700 TestAcc 0.9132 0.9550
epoch 2300 LossPred 0.2457 LossAtt 0.1882 TrainAcc 0.9200 TestAcc 0.8856 0.9100
epoch 2400 LossPred 0.1222 LossAtt 0.1862 TrainAcc 0.9800 TestAcc 0.9102 0.9550
epoch 2500 LossPred 0.2064 LossAtt 0.1963 TrainAcc 0.9300 TestAcc 0.9034 0.9100
Optimization Finished!
********** replication  7  **********
epoch   0 LossPred 1.0507 LossAtt 1.0201 TrainAcc 0.5400 TestAcc 0.5526 0.5450
epoch 100 LossPred 0.8827 LossAtt 0.2990 TrainAcc 0.6600 TestAcc 0.5973 0.6600
epoch 200 LossPred 0.7449 LossAtt 0.2996 TrainAcc 0.7500 TestAcc 0.6602 0.7700
epoch 300 LossPred 0.2682 LossAtt 0.2986 TrainAcc 0.9100 TestAcc 0.8664 0.9200
epoch 400 LossPred 0.1701 LossAtt 0.3133 TrainAcc 0.9600 TestAcc 0.8899 0.9150
epoch 500 LossPred 0.1726 LossAtt 0.3129 TrainAcc 0.9600 TestAcc 0.8981 0.9250
epoch 600 LossPred 0.2496 LossAtt 0.2984 TrainAcc 0.9000 TestAcc 0.8846 0.9000
epoch 700 LossPred 0.1130 LossAtt 0.2856 TrainAcc 0.9800 TestAcc 0.9029 0.9300
epoch 800 LossPred 0.1195 LossAtt 0.2841 TrainAcc 0.9700 TestAcc 0.9022 0.9500
epoch 900 LossPred 0.1465 LossAtt 0.2739 TrainAcc 0.9600 TestAcc 0.9132 0.9300
epoch 1000 LossPred 0.2776 LossAtt 0.2771 TrainAcc 0.9000 TestAcc 0.8674 0.9050
epoch 1100 LossPred 0.1026 LossAtt 0.2683 TrainAcc 0.9800 TestAcc 0.9187 0.9700
epoch 1200 LossPred 0.0947 LossAtt 0.2600 TrainAcc 0.9700 TestAcc 0.9162 0.9750
epoch 1300 LossPred 0.1221 LossAtt 0.2571 TrainAcc 0.9700 TestAcc 0.9152 0.9650
epoch 1400 LossPred 0.1573 LossAtt 0.2611 TrainAcc 0.9400 TestAcc 0.9067 0.9450
epoch 1500 LossPred 0.1824 LossAtt 0.2689 TrainAcc 0.9300 TestAcc 0.8966 0.9400
epoch 1600 LossPred 0.1623 LossAtt 0.2894 TrainAcc 0.9300 TestAcc 0.9124 0.9450
epoch 1700 LossPred 0.0961 LossAtt 0.2883 TrainAcc 0.9600 TestAcc 0.9032 0.9700
epoch 1800 LossPred 0.1104 LossAtt 0.2743 TrainAcc 0.9700 TestAcc 0.9064 0.9650
epoch 1900 LossPred 0.1391 LossAtt 0.2783 TrainAcc 0.9300 TestAcc 0.9054 0.9550
epoch 2000 LossPred 0.1146 LossAtt 0.2836 TrainAcc 0.9400 TestAcc 0.8884 0.9450
epoch 2100 LossPred 0.1632 LossAtt 0.2810 TrainAcc 0.9300 TestAcc 0.8996 0.9500
epoch 2200 LossPred 0.0537 LossAtt 0.2597 TrainAcc 0.9900 TestAcc 0.9024 0.9900
epoch 2300 LossPred 0.0803 LossAtt 0.2835 TrainAcc 0.9700 TestAcc 0.8891 0.9650
epoch 2400 LossPred 0.0480 LossAtt 0.2747 TrainAcc 0.9800 TestAcc 0.9042 0.9850
epoch 2500 LossPred 0.0426 LossAtt 0.2755 TrainAcc 0.9900 TestAcc 0.8986 0.9900
Optimization Finished!
********** replication  8  **********
epoch   0 LossPred 1.2335 LossAtt 1.0162 TrainAcc 0.4100 TestAcc 0.4262 0.4200
epoch 100 LossPred 0.9599 LossAtt 0.2559 TrainAcc 0.6000 TestAcc 0.6016 0.6150
epoch 200 LossPred 0.9479 LossAtt 0.1751 TrainAcc 0.6000 TestAcc 0.6016 0.6000
epoch 300 LossPred 0.4277 LossAtt 0.1643 TrainAcc 0.8900 TestAcc 0.8571 0.8450
epoch 400 LossPred 0.3841 LossAtt 0.1660 TrainAcc 0.8800 TestAcc 0.8779 0.8650
epoch 500 LossPred 0.3111 LossAtt 0.1955 TrainAcc 0.9200 TestAcc 0.8859 0.8500
epoch 600 LossPred 0.2330 LossAtt 0.2041 TrainAcc 0.9400 TestAcc 0.8846 0.8750
epoch 700 LossPred 0.2458 LossAtt 0.2104 TrainAcc 0.9200 TestAcc 0.8851 0.8950
epoch 800 LossPred 0.2423 LossAtt 0.2183 TrainAcc 0.9100 TestAcc 0.8809 0.8900
epoch 900 LossPred 0.2065 LossAtt 0.2092 TrainAcc 0.9400 TestAcc 0.8909 0.9100
epoch 1000 LossPred 0.2635 LossAtt 0.2190 TrainAcc 0.9000 TestAcc 0.8744 0.8950
epoch 1100 LossPred 0.2220 LossAtt 0.2277 TrainAcc 0.9200 TestAcc 0.8889 0.9150
epoch 1200 LossPred 0.1734 LossAtt 0.2403 TrainAcc 0.9400 TestAcc 0.9014 0.9150
epoch 1300 LossPred 0.1740 LossAtt 0.2173 TrainAcc 0.9500 TestAcc 0.9104 0.8950
epoch 1400 LossPred 0.1792 LossAtt 0.2140 TrainAcc 0.9500 TestAcc 0.9009 0.9150
epoch 1500 LossPred 0.1751 LossAtt 0.2260 TrainAcc 0.9400 TestAcc 0.8984 0.9250
epoch 1600 LossPred 0.1491 LossAtt 0.2085 TrainAcc 0.9500 TestAcc 0.9062 0.9150
epoch 1700 LossPred 0.2375 LossAtt 0.2229 TrainAcc 0.9000 TestAcc 0.8884 0.9250
epoch 1800 LossPred 0.2303 LossAtt 0.2090 TrainAcc 0.9200 TestAcc 0.8959 0.8950
epoch 1900 LossPred 0.2469 LossAtt 0.2157 TrainAcc 0.9000 TestAcc 0.8784 0.9200
epoch 2000 LossPred 0.2813 LossAtt 0.2191 TrainAcc 0.9100 TestAcc 0.8736 0.9000
epoch 2100 LossPred 0.2219 LossAtt 0.2069 TrainAcc 0.9400 TestAcc 0.8854 0.9050
epoch 2200 LossPred 0.1488 LossAtt 0.2178 TrainAcc 0.9400 TestAcc 0.8934 0.9250
epoch 2300 LossPred 0.1822 LossAtt 0.2036 TrainAcc 0.9400 TestAcc 0.8921 0.8950
epoch 2400 LossPred 0.1731 LossAtt 0.2106 TrainAcc 0.9400 TestAcc 0.8881 0.9200
epoch 2500 LossPred 0.1633 LossAtt 0.2223 TrainAcc 0.9300 TestAcc 0.9019 0.9000
Optimization Finished!
********** replication  9  **********
epoch   0 LossPred 1.0867 LossAtt 1.0265 TrainAcc 0.5100 TestAcc 0.5233 0.5200
epoch 100 LossPred 0.8783 LossAtt 0.2805 TrainAcc 0.6700 TestAcc 0.5946 0.6750
epoch 200 LossPred 0.8405 LossAtt 0.2686 TrainAcc 0.6800 TestAcc 0.6069 0.6800
epoch 300 LossPred 0.3709 LossAtt 0.3302 TrainAcc 0.8900 TestAcc 0.8844 0.8950
epoch 400 LossPred 0.2100 LossAtt 0.3381 TrainAcc 0.9400 TestAcc 0.9134 0.9000
epoch 500 LossPred 0.1614 LossAtt 0.3529 TrainAcc 0.9600 TestAcc 0.9047 0.9200
epoch 600 LossPred 0.1636 LossAtt 0.3311 TrainAcc 0.9600 TestAcc 0.9127 0.9350
epoch 700 LossPred 0.1932 LossAtt 0.3456 TrainAcc 0.9400 TestAcc 0.9017 0.9300
epoch 800 LossPred 0.1064 LossAtt 0.3363 TrainAcc 0.9800 TestAcc 0.9292 0.9350
epoch 900 LossPred 0.1886 LossAtt 0.3353 TrainAcc 0.9200 TestAcc 0.8881 0.9100
epoch 1000 LossPred 0.1116 LossAtt 0.3328 TrainAcc 0.9700 TestAcc 0.9237 0.9400
epoch 1100 LossPred 0.1735 LossAtt 0.3180 TrainAcc 0.9400 TestAcc 0.8921 0.9300
epoch 1200 LossPred 0.1087 LossAtt 0.3199 TrainAcc 0.9700 TestAcc 0.9172 0.9400
epoch 1300 LossPred 0.0927 LossAtt 0.3170 TrainAcc 0.9800 TestAcc 0.9264 0.9550
epoch 1400 LossPred 0.0856 LossAtt 0.3072 TrainAcc 0.9800 TestAcc 0.9289 0.9400
epoch 1500 LossPred 0.0864 LossAtt 0.2931 TrainAcc 0.9800 TestAcc 0.9229 0.9400
epoch 1600 LossPred 0.1625 LossAtt 0.2890 TrainAcc 0.9600 TestAcc 0.9039 0.9300
epoch 1700 LossPred 0.0910 LossAtt 0.2880 TrainAcc 0.9800 TestAcc 0.9202 0.9500
epoch 1800 LossPred 0.1151 LossAtt 0.2666 TrainAcc 0.9700 TestAcc 0.9147 0.9400
epoch 1900 LossPred 0.0875 LossAtt 0.2702 TrainAcc 0.9800 TestAcc 0.9187 0.9650
epoch 2000 LossPred 0.0875 LossAtt 0.2889 TrainAcc 0.9700 TestAcc 0.9159 0.9700
epoch 2100 LossPred 0.1144 LossAtt 0.2689 TrainAcc 0.9700 TestAcc 0.9122 0.9550
epoch 2200 LossPred 0.0755 LossAtt 0.2759 TrainAcc 0.9800 TestAcc 0.9184 0.9500
epoch 2300 LossPred 0.1179 LossAtt 0.2636 TrainAcc 0.9700 TestAcc 0.9104 0.9450
epoch 2400 LossPred 0.1069 LossAtt 0.2643 TrainAcc 0.9700 TestAcc 0.9162 0.9550
epoch 2500 LossPred 0.1638 LossAtt 0.2633 TrainAcc 0.9500 TestAcc 0.8779 0.9350
Optimization Finished!
********** replication  10  **********
epoch   0 LossPred 0.9809 LossAtt 1.0048 TrainAcc 0.5800 TestAcc 0.5566 0.5600
epoch 100 LossPred 0.8450 LossAtt 0.3182 TrainAcc 0.6800 TestAcc 0.6374 0.6700
epoch 200 LossPred 0.4298 LossAtt 0.3391 TrainAcc 0.8800 TestAcc 0.8779 0.8450
epoch 300 LossPred 0.2992 LossAtt 0.3006 TrainAcc 0.9300 TestAcc 0.9202 0.9000
epoch 400 LossPred 0.2421 LossAtt 0.2620 TrainAcc 0.9100 TestAcc 0.9322 0.8900
epoch 500 LossPred 0.1935 LossAtt 0.2517 TrainAcc 0.9500 TestAcc 0.9527 0.9000
epoch 600 LossPred 0.2068 LossAtt 0.2355 TrainAcc 0.9300 TestAcc 0.9412 0.8950
epoch 700 LossPred 0.5919 LossAtt 0.2287 TrainAcc 0.8100 TestAcc 0.8296 0.8100
epoch 800 LossPred 0.2954 LossAtt 0.2266 TrainAcc 0.9000 TestAcc 0.9042 0.8700
epoch 900 LossPred 0.2197 LossAtt 0.2377 TrainAcc 0.9200 TestAcc 0.9317 0.8850
epoch 1000 LossPred 0.2720 LossAtt 0.2325 TrainAcc 0.8900 TestAcc 0.9144 0.8600
epoch 1100 LossPred 0.2173 LossAtt 0.2429 TrainAcc 0.9300 TestAcc 0.9262 0.9000
epoch 1200 LossPred 0.3861 LossAtt 0.2477 TrainAcc 0.8600 TestAcc 0.8719 0.8200
epoch 1300 LossPred 0.1859 LossAtt 0.2491 TrainAcc 0.9500 TestAcc 0.9327 0.9050
epoch 1400 LossPred 0.1727 LossAtt 0.2410 TrainAcc 0.9600 TestAcc 0.9434 0.9050
epoch 1500 LossPred 0.1670 LossAtt 0.2474 TrainAcc 0.9500 TestAcc 0.9394 0.8850
epoch 1600 LossPred 0.2025 LossAtt 0.2441 TrainAcc 0.9200 TestAcc 0.9267 0.9050
epoch 1700 LossPred 0.1515 LossAtt 0.2412 TrainAcc 0.9600 TestAcc 0.9219 0.9100
epoch 1800 LossPred 0.1505 LossAtt 0.2498 TrainAcc 0.9600 TestAcc 0.9109 0.9000
epoch 1900 LossPred 0.1782 LossAtt 0.2332 TrainAcc 0.9500 TestAcc 0.9027 0.8900
epoch 2000 LossPred 0.1818 LossAtt 0.2435 TrainAcc 0.9500 TestAcc 0.9037 0.8850
epoch 2100 LossPred 0.1631 LossAtt 0.2254 TrainAcc 0.9600 TestAcc 0.9069 0.8800
epoch 2200 LossPred 0.1767 LossAtt 0.2349 TrainAcc 0.9300 TestAcc 0.9177 0.9100
epoch 2300 LossPred 0.1510 LossAtt 0.2419 TrainAcc 0.9700 TestAcc 0.8951 0.9050
epoch 2400 LossPred 0.1363 LossAtt 0.2262 TrainAcc 0.9800 TestAcc 0.8956 0.9100
epoch 2500 LossPred 0.1144 LossAtt 0.2352 TrainAcc 0.9900 TestAcc 0.9054 0.9000
Optimization Finished!
********** replication  11  **********
epoch   0 LossPred 1.1674 LossAtt 0.9877 TrainAcc 0.4900 TestAcc 0.5010 0.4900
epoch 100 LossPred 0.8745 LossAtt 0.2466 TrainAcc 0.6800 TestAcc 0.6041 0.6700
epoch 200 LossPred 0.8379 LossAtt 0.1908 TrainAcc 0.6800 TestAcc 0.6041 0.6800
epoch 300 LossPred 0.5564 LossAtt 0.3022 TrainAcc 0.8400 TestAcc 0.7700 0.8550
epoch 400 LossPred 0.3465 LossAtt 0.2698 TrainAcc 0.8900 TestAcc 0.8674 0.8700
epoch 500 LossPred 0.2257 LossAtt 0.2851 TrainAcc 0.9300 TestAcc 0.8966 0.9250
epoch 600 LossPred 0.2914 LossAtt 0.2991 TrainAcc 0.8800 TestAcc 0.8669 0.8900
epoch 700 LossPred 0.1594 LossAtt 0.2812 TrainAcc 0.9600 TestAcc 0.9184 0.9250
epoch 800 LossPred 0.1552 LossAtt 0.2988 TrainAcc 0.9600 TestAcc 0.9344 0.9400
epoch 900 LossPred 0.2528 LossAtt 0.2974 TrainAcc 0.9100 TestAcc 0.8911 0.9000
epoch 1000 LossPred 0.1722 LossAtt 0.2817 TrainAcc 0.9400 TestAcc 0.9247 0.9350
epoch 1100 LossPred 0.0981 LossAtt 0.2809 TrainAcc 0.9800 TestAcc 0.9474 0.9450
epoch 1200 LossPred 0.1069 LossAtt 0.2629 TrainAcc 0.9600 TestAcc 0.9452 0.9550
epoch 1300 LossPred 0.1461 LossAtt 0.2528 TrainAcc 0.9600 TestAcc 0.9059 0.9350
epoch 1400 LossPred 0.0839 LossAtt 0.2373 TrainAcc 0.9800 TestAcc 0.9550 0.9500
epoch 1500 LossPred 0.0899 LossAtt 0.2429 TrainAcc 0.9800 TestAcc 0.9517 0.9400
epoch 1600 LossPred 0.2777 LossAtt 0.2262 TrainAcc 0.9000 TestAcc 0.8906 0.8900
epoch 1700 LossPred 0.1456 LossAtt 0.2180 TrainAcc 0.9500 TestAcc 0.9284 0.9450
epoch 1800 LossPred 0.2184 LossAtt 0.2183 TrainAcc 0.9100 TestAcc 0.9044 0.9150
epoch 1900 LossPred 0.2450 LossAtt 0.2162 TrainAcc 0.9100 TestAcc 0.8524 0.9200
epoch 2000 LossPred 0.0627 LossAtt 0.2128 TrainAcc 0.9800 TestAcc 0.9545 0.9650
epoch 2100 LossPred 0.0975 LossAtt 0.2134 TrainAcc 0.9700 TestAcc 0.9389 0.9600
epoch 2200 LossPred 0.1197 LossAtt 0.2108 TrainAcc 0.9600 TestAcc 0.9369 0.9500
epoch 2300 LossPred 0.0879 LossAtt 0.2078 TrainAcc 0.9700 TestAcc 0.9434 0.9500
epoch 2400 LossPred 0.0653 LossAtt 0.2061 TrainAcc 0.9800 TestAcc 0.9467 0.9500
epoch 2500 LossPred 0.0924 LossAtt 0.2172 TrainAcc 0.9600 TestAcc 0.9507 0.9500
Optimization Finished!
********** replication  12  **********
epoch   0 LossPred 1.1174 LossAtt 1.0075 TrainAcc 0.3500 TestAcc 0.4484 0.3400
epoch 100 LossPred 0.7422 LossAtt 0.3120 TrainAcc 0.7400 TestAcc 0.6001 0.7300
epoch 200 LossPred 0.2854 LossAtt 0.3102 TrainAcc 0.9100 TestAcc 0.8526 0.8850
epoch 300 LossPred 0.2773 LossAtt 0.2988 TrainAcc 0.9000 TestAcc 0.8471 0.9100
epoch 400 LossPred 0.2268 LossAtt 0.2836 TrainAcc 0.9100 TestAcc 0.8601 0.8850
epoch 500 LossPred 0.1967 LossAtt 0.2781 TrainAcc 0.9400 TestAcc 0.8701 0.9250
epoch 600 LossPred 0.1829 LossAtt 0.2847 TrainAcc 0.9400 TestAcc 0.8744 0.9200
epoch 700 LossPred 0.1584 LossAtt 0.3023 TrainAcc 0.9500 TestAcc 0.8829 0.9350
epoch 800 LossPred 0.1721 LossAtt 0.2999 TrainAcc 0.9400 TestAcc 0.8776 0.9100
epoch 900 LossPred 0.1573 LossAtt 0.2914 TrainAcc 0.9400 TestAcc 0.8846 0.9300
epoch 1000 LossPred 0.1962 LossAtt 0.2866 TrainAcc 0.9300 TestAcc 0.8901 0.9300
epoch 1100 LossPred 0.1286 LossAtt 0.2675 TrainAcc 0.9500 TestAcc 0.9007 0.9550
epoch 1200 LossPred 0.1353 LossAtt 0.2495 TrainAcc 0.9700 TestAcc 0.8916 0.9650
epoch 1300 LossPred 0.0865 LossAtt 0.2511 TrainAcc 0.9700 TestAcc 0.9137 0.9850
epoch 1400 LossPred 0.2116 LossAtt 0.2319 TrainAcc 0.9200 TestAcc 0.8524 0.9250
epoch 1500 LossPred 0.0701 LossAtt 0.2325 TrainAcc 1.0000 TestAcc 0.9277 1.0000
Optimization Finished!
********** replication  13  **********
epoch   0 LossPred 1.0720 LossAtt 1.0171 TrainAcc 0.5100 TestAcc 0.4147 0.5000
epoch 100 LossPred 0.7855 LossAtt 0.3413 TrainAcc 0.7200 TestAcc 0.6884 0.7350
epoch 200 LossPred 0.2000 LossAtt 0.3589 TrainAcc 0.9500 TestAcc 0.8911 0.9500
epoch 300 LossPred 0.1235 LossAtt 0.3576 TrainAcc 0.9700 TestAcc 0.9117 0.9600
epoch 400 LossPred 0.1191 LossAtt 0.3423 TrainAcc 0.9800 TestAcc 0.9119 0.9500
epoch 500 LossPred 0.0503 LossAtt 0.3538 TrainAcc 0.9900 TestAcc 0.9314 0.9650
epoch 600 LossPred 0.0362 LossAtt 0.3159 TrainAcc 1.0000 TestAcc 0.9394 1.0000
Optimization Finished!
********** replication  14  **********
epoch   0 LossPred 1.1310 LossAtt 1.0072 TrainAcc 0.4200 TestAcc 0.4712 0.4200
epoch 100 LossPred 0.8380 LossAtt 0.2742 TrainAcc 0.6600 TestAcc 0.5996 0.6650
epoch 200 LossPred 0.3721 LossAtt 0.2713 TrainAcc 0.9000 TestAcc 0.8891 0.8600
epoch 300 LossPred 0.3641 LossAtt 0.2610 TrainAcc 0.8900 TestAcc 0.8659 0.8650
epoch 400 LossPred 0.2966 LossAtt 0.2794 TrainAcc 0.8900 TestAcc 0.8899 0.8650
epoch 500 LossPred 0.5330 LossAtt 0.2626 TrainAcc 0.7800 TestAcc 0.7835 0.7850
epoch 600 LossPred 0.1487 LossAtt 0.2657 TrainAcc 0.9700 TestAcc 0.9102 0.9150
epoch 700 LossPred 0.1346 LossAtt 0.2556 TrainAcc 0.9600 TestAcc 0.9117 0.9150
epoch 800 LossPred 0.1483 LossAtt 0.2526 TrainAcc 0.9500 TestAcc 0.9127 0.9250
epoch 900 LossPred 0.1355 LossAtt 0.2523 TrainAcc 0.9500 TestAcc 0.9132 0.9200
epoch 1000 LossPred 0.1075 LossAtt 0.2558 TrainAcc 0.9600 TestAcc 0.9207 0.9350
epoch 1100 LossPred 0.1275 LossAtt 0.2418 TrainAcc 0.9700 TestAcc 0.9019 0.9150
epoch 1200 LossPred 0.2119 LossAtt 0.2575 TrainAcc 0.9400 TestAcc 0.8619 0.9100
epoch 1300 LossPred 0.0970 LossAtt 0.2590 TrainAcc 0.9800 TestAcc 0.9207 0.9400
epoch 1400 LossPred 0.0832 LossAtt 0.2330 TrainAcc 0.9800 TestAcc 0.9327 0.9500
epoch 1500 LossPred 0.0881 LossAtt 0.2517 TrainAcc 0.9800 TestAcc 0.9387 0.9450
epoch 1600 LossPred 0.1579 LossAtt 0.2567 TrainAcc 0.9600 TestAcc 0.9039 0.9250
epoch 1700 LossPred 0.0861 LossAtt 0.2603 TrainAcc 0.9700 TestAcc 0.9384 0.9450
epoch 1800 LossPred 0.0750 LossAtt 0.2638 TrainAcc 0.9800 TestAcc 0.9232 0.9600
epoch 1900 LossPred 0.1310 LossAtt 0.2633 TrainAcc 0.9600 TestAcc 0.9002 0.9450
epoch 2000 LossPred 0.1038 LossAtt 0.2595 TrainAcc 0.9700 TestAcc 0.9024 0.9450
epoch 2100 LossPred 0.1149 LossAtt 0.2522 TrainAcc 0.9700 TestAcc 0.9222 0.9500
epoch 2200 LossPred 0.0549 LossAtt 0.2452 TrainAcc 0.9800 TestAcc 0.9324 0.9700
epoch 2300 LossPred 0.0679 LossAtt 0.2402 TrainAcc 0.9800 TestAcc 0.9114 0.9800
epoch 2400 LossPred 0.1380 LossAtt 0.2457 TrainAcc 0.9700 TestAcc 0.8954 0.9400
epoch 2500 LossPred 0.1771 LossAtt 0.2384 TrainAcc 0.9400 TestAcc 0.8936 0.9350
Optimization Finished!
********** replication  15  **********
epoch   0 LossPred 1.0953 LossAtt 1.0184 TrainAcc 0.5300 TestAcc 0.6116 0.5050
epoch 100 LossPred 0.9251 LossAtt 0.2379 TrainAcc 0.6200 TestAcc 0.6016 0.6200
epoch 200 LossPred 0.9045 LossAtt 0.1461 TrainAcc 0.6300 TestAcc 0.5485 0.6300
epoch 300 LossPred 0.8825 LossAtt 0.2062 TrainAcc 0.6700 TestAcc 0.5661 0.6450
epoch 400 LossPred 0.8593 LossAtt 0.2135 TrainAcc 0.6400 TestAcc 0.5666 0.6600
epoch 500 LossPred 0.7461 LossAtt 0.2364 TrainAcc 0.7200 TestAcc 0.5758 0.7250
epoch 600 LossPred 0.4246 LossAtt 0.2272 TrainAcc 0.8700 TestAcc 0.7808 0.8350
epoch 700 LossPred 0.3110 LossAtt 0.2367 TrainAcc 0.8900 TestAcc 0.8243 0.8900
epoch 800 LossPred 0.2147 LossAtt 0.2580 TrainAcc 0.9400 TestAcc 0.8559 0.9050
epoch 900 LossPred 0.1752 LossAtt 0.2363 TrainAcc 0.9500 TestAcc 0.8689 0.9150
epoch 1000 LossPred 0.1482 LossAtt 0.2163 TrainAcc 0.9600 TestAcc 0.8751 0.9250
epoch 1100 LossPred 0.1407 LossAtt 0.2228 TrainAcc 0.9700 TestAcc 0.8774 0.9150
epoch 1200 LossPred 0.1176 LossAtt 0.1989 TrainAcc 0.9600 TestAcc 0.8699 0.9350
epoch 1300 LossPred 0.1151 LossAtt 0.1976 TrainAcc 0.9700 TestAcc 0.8896 0.9400
epoch 1400 LossPred 0.0951 LossAtt 0.2048 TrainAcc 0.9700 TestAcc 0.8904 0.9350
epoch 1500 LossPred 0.0876 LossAtt 0.1985 TrainAcc 0.9800 TestAcc 0.8951 0.9400
epoch 1600 LossPred 0.0923 LossAtt 0.1907 TrainAcc 0.9800 TestAcc 0.8849 0.9400
epoch 1700 LossPred 0.0983 LossAtt 0.2082 TrainAcc 0.9600 TestAcc 0.8909 0.9550
epoch 1800 LossPred 0.0990 LossAtt 0.1929 TrainAcc 0.9800 TestAcc 0.8764 0.9350
epoch 1900 LossPred 0.0840 LossAtt 0.1936 TrainAcc 0.9800 TestAcc 0.8951 0.9300
epoch 2000 LossPred 0.0838 LossAtt 0.1914 TrainAcc 0.9800 TestAcc 0.8929 0.9300
epoch 2100 LossPred 0.0837 LossAtt 0.1856 TrainAcc 0.9800 TestAcc 0.8941 0.9350
epoch 2200 LossPred 0.0907 LossAtt 0.1995 TrainAcc 0.9800 TestAcc 0.8821 0.9300
epoch 2300 LossPred 0.0832 LossAtt 0.2003 TrainAcc 0.9800 TestAcc 0.8904 0.9300
epoch 2400 LossPred 0.0845 LossAtt 0.1993 TrainAcc 0.9800 TestAcc 0.8864 0.9450
epoch 2500 LossPred 0.0799 LossAtt 0.1942 TrainAcc 0.9800 TestAcc 0.8819 0.9400
Optimization Finished!
********** replication  16  **********
epoch   0 LossPred 1.3112 LossAtt 0.9786 TrainAcc 0.4400 TestAcc 0.4997 0.4400
epoch 100 LossPred 0.9070 LossAtt 0.3102 TrainAcc 0.6300 TestAcc 0.5968 0.6300
epoch 200 LossPred 0.8393 LossAtt 0.2789 TrainAcc 0.6900 TestAcc 0.6236 0.6900
epoch 300 LossPred 0.3426 LossAtt 0.2981 TrainAcc 0.9000 TestAcc 0.8554 0.8600
epoch 400 LossPred 0.2536 LossAtt 0.2673 TrainAcc 0.9300 TestAcc 0.8891 0.9100
epoch 500 LossPred 0.2466 LossAtt 0.2270 TrainAcc 0.9100 TestAcc 0.8599 0.9100
epoch 600 LossPred 0.1636 LossAtt 0.2225 TrainAcc 0.9700 TestAcc 0.9382 0.9350
epoch 700 LossPred 0.1606 LossAtt 0.2105 TrainAcc 0.9400 TestAcc 0.9432 0.9100
epoch 800 LossPred 0.1315 LossAtt 0.2140 TrainAcc 0.9800 TestAcc 0.9447 0.9250
epoch 900 LossPred 0.1291 LossAtt 0.2074 TrainAcc 0.9600 TestAcc 0.9359 0.9300
epoch 1000 LossPred 0.1232 LossAtt 0.2070 TrainAcc 0.9700 TestAcc 0.9560 0.9300
epoch 1100 LossPred 0.1082 LossAtt 0.2018 TrainAcc 0.9800 TestAcc 0.9560 0.9400
epoch 1200 LossPred 0.1338 LossAtt 0.2109 TrainAcc 0.9500 TestAcc 0.9214 0.9400
epoch 1300 LossPred 0.1089 LossAtt 0.1994 TrainAcc 0.9600 TestAcc 0.9487 0.9400
epoch 1400 LossPred 0.1379 LossAtt 0.2064 TrainAcc 0.9700 TestAcc 0.9354 0.9100
epoch 1500 LossPred 0.0859 LossAtt 0.2021 TrainAcc 0.9900 TestAcc 0.9555 0.9400
epoch 1600 LossPred 0.0825 LossAtt 0.2062 TrainAcc 0.9700 TestAcc 0.9432 0.9450
epoch 1700 LossPred 0.1403 LossAtt 0.2084 TrainAcc 0.9500 TestAcc 0.9129 0.9450
epoch 1800 LossPred 0.0754 LossAtt 0.2109 TrainAcc 0.9800 TestAcc 0.9474 0.9500
epoch 1900 LossPred 0.1096 LossAtt 0.2270 TrainAcc 0.9800 TestAcc 0.9552 0.9350
epoch 2000 LossPred 0.1096 LossAtt 0.2037 TrainAcc 0.9700 TestAcc 0.9505 0.9350
epoch 2100 LossPred 0.1374 LossAtt 0.2071 TrainAcc 0.9700 TestAcc 0.9364 0.9100
epoch 2200 LossPred 0.0944 LossAtt 0.2069 TrainAcc 0.9700 TestAcc 0.9494 0.9400
epoch 2300 LossPred 0.1469 LossAtt 0.2121 TrainAcc 0.9500 TestAcc 0.9049 0.9300
epoch 2400 LossPred 0.0976 LossAtt 0.2292 TrainAcc 0.9800 TestAcc 0.9577 0.9350
epoch 2500 LossPred 0.0981 LossAtt 0.2176 TrainAcc 0.9700 TestAcc 0.9620 0.9300
Optimization Finished!
********** replication  17  **********
epoch   0 LossPred 1.0177 LossAtt 1.0205 TrainAcc 0.5200 TestAcc 0.4717 0.5000
epoch 100 LossPred 0.8074 LossAtt 0.2745 TrainAcc 0.7200 TestAcc 0.6704 0.7100
epoch 200 LossPred 0.2473 LossAtt 0.2778 TrainAcc 0.9100 TestAcc 0.9027 0.8700
epoch 300 LossPred 0.2357 LossAtt 0.2587 TrainAcc 0.9300 TestAcc 0.8789 0.9000
epoch 400 LossPred 0.1331 LossAtt 0.2193 TrainAcc 0.9700 TestAcc 0.9167 0.9300
epoch 500 LossPred 0.1789 LossAtt 0.2136 TrainAcc 0.9400 TestAcc 0.8939 0.9200
epoch 600 LossPred 0.1218 LossAtt 0.2020 TrainAcc 0.9900 TestAcc 0.9274 0.9300
epoch 700 LossPred 0.1048 LossAtt 0.2167 TrainAcc 0.9700 TestAcc 0.9202 0.9400
epoch 800 LossPred 0.1102 LossAtt 0.2196 TrainAcc 0.9700 TestAcc 0.9219 0.9350
epoch 900 LossPred 0.2771 LossAtt 0.2124 TrainAcc 0.9000 TestAcc 0.8326 0.8900
epoch 1000 LossPred 0.1009 LossAtt 0.2125 TrainAcc 0.9700 TestAcc 0.9202 0.9500
epoch 1100 LossPred 0.1391 LossAtt 0.1949 TrainAcc 0.9600 TestAcc 0.9059 0.9600
epoch 1200 LossPred 0.6881 LossAtt 0.1786 TrainAcc 0.7900 TestAcc 0.7290 0.7700
epoch 1300 LossPred 0.4928 LossAtt 0.1649 TrainAcc 0.8700 TestAcc 0.7875 0.8600
epoch 1400 LossPred 0.3999 LossAtt 0.1698 TrainAcc 0.8800 TestAcc 0.8136 0.8800
epoch 1500 LossPred 0.2831 LossAtt 0.1754 TrainAcc 0.9100 TestAcc 0.8554 0.9050
epoch 1600 LossPred 0.3386 LossAtt 0.1892 TrainAcc 0.8800 TestAcc 0.8358 0.8850
epoch 1700 LossPred 0.1532 LossAtt 0.1948 TrainAcc 0.9700 TestAcc 0.9152 0.9550
epoch 1800 LossPred 0.1163 LossAtt 0.2029 TrainAcc 0.9700 TestAcc 0.9227 0.9400
epoch 1900 LossPred 0.2528 LossAtt 0.1938 TrainAcc 0.9000 TestAcc 0.8651 0.9000
epoch 2000 LossPred 0.3623 LossAtt 0.2093 TrainAcc 0.8800 TestAcc 0.8601 0.8650
epoch 2100 LossPred 0.1963 LossAtt 0.2069 TrainAcc 0.9200 TestAcc 0.8876 0.9200
epoch 2200 LossPred 0.1275 LossAtt 0.1991 TrainAcc 0.9500 TestAcc 0.9257 0.9500
epoch 2300 LossPred 0.1266 LossAtt 0.2107 TrainAcc 0.9500 TestAcc 0.9232 0.9450
epoch 2400 LossPred 0.1076 LossAtt 0.2047 TrainAcc 0.9700 TestAcc 0.9249 0.9500
epoch 2500 LossPred 0.0984 LossAtt 0.2008 TrainAcc 0.9700 TestAcc 0.9344 0.9700
Optimization Finished!
********** replication  18  **********
epoch   0 LossPred 1.0529 LossAtt 1.0327 TrainAcc 0.4900 TestAcc 0.4855 0.5000
epoch 100 LossPred 0.9474 LossAtt 0.2787 TrainAcc 0.5900 TestAcc 0.5711 0.5950
epoch 200 LossPred 0.8919 LossAtt 0.2554 TrainAcc 0.6300 TestAcc 0.5656 0.6250
epoch 300 LossPred 0.8311 LossAtt 0.3072 TrainAcc 0.7000 TestAcc 0.5608 0.7050
epoch 400 LossPred 0.7870 LossAtt 0.3234 TrainAcc 0.7100 TestAcc 0.5543 0.6950
epoch 500 LossPred 0.7519 LossAtt 0.3000 TrainAcc 0.7300 TestAcc 0.5511 0.6950
epoch 600 LossPred 0.6529 LossAtt 0.3407 TrainAcc 0.7800 TestAcc 0.6179 0.7750
epoch 700 LossPred 0.2849 LossAtt 0.4020 TrainAcc 0.9000 TestAcc 0.8263 0.8850
epoch 800 LossPred 0.2227 LossAtt 0.3870 TrainAcc 0.9200 TestAcc 0.8468 0.9000
epoch 900 LossPred 0.2141 LossAtt 0.3774 TrainAcc 0.9200 TestAcc 0.8461 0.8850
epoch 1000 LossPred 0.1727 LossAtt 0.3662 TrainAcc 0.9300 TestAcc 0.8591 0.9150
epoch 1100 LossPred 0.1255 LossAtt 0.3628 TrainAcc 0.9500 TestAcc 0.8586 0.9250
epoch 1200 LossPred 0.1933 LossAtt 0.3808 TrainAcc 0.9200 TestAcc 0.8356 0.9050
epoch 1300 LossPred 0.0718 LossAtt 0.3563 TrainAcc 0.9800 TestAcc 0.8559 0.9550
epoch 1400 LossPred 0.0608 LossAtt 0.3501 TrainAcc 0.9800 TestAcc 0.8544 0.9600
epoch 1500 LossPred 0.0521 LossAtt 0.3391 TrainAcc 0.9900 TestAcc 0.8599 0.9650
epoch 1600 LossPred 0.0966 LossAtt 0.3521 TrainAcc 0.9600 TestAcc 0.8438 0.9150
epoch 1700 LossPred 0.1516 LossAtt 0.3520 TrainAcc 0.9400 TestAcc 0.8363 0.9200
epoch 1800 LossPred 0.0638 LossAtt 0.3368 TrainAcc 0.9800 TestAcc 0.8476 0.9450
epoch 1900 LossPred 0.0455 LossAtt 0.3376 TrainAcc 0.9900 TestAcc 0.8493 0.9750
epoch 2000 LossPred 0.0370 LossAtt 0.3440 TrainAcc 0.9900 TestAcc 0.8483 0.9800
epoch 2100 LossPred 0.0937 LossAtt 0.3328 TrainAcc 0.9700 TestAcc 0.8311 0.9500
epoch 2200 LossPred 0.0255 LossAtt 0.3298 TrainAcc 1.0000 TestAcc 0.8471 0.9800
Optimization Finished!
********** replication  19  **********
epoch   0 LossPred 0.9684 LossAtt 0.9977 TrainAcc 0.5500 TestAcc 0.5030 0.5400
epoch 100 LossPred 0.8341 LossAtt 0.3416 TrainAcc 0.6700 TestAcc 0.6346 0.6600
epoch 200 LossPred 0.2521 LossAtt 0.3369 TrainAcc 0.9500 TestAcc 0.8801 0.9250
epoch 300 LossPred 0.0877 LossAtt 0.3248 TrainAcc 0.9800 TestAcc 0.8991 0.9550
epoch 400 LossPred 0.0876 LossAtt 0.3218 TrainAcc 0.9700 TestAcc 0.8939 0.9600
epoch 500 LossPred 0.1145 LossAtt 0.3333 TrainAcc 0.9600 TestAcc 0.8781 0.9550
epoch 600 LossPred 0.0605 LossAtt 0.3246 TrainAcc 0.9800 TestAcc 0.9064 0.9700
epoch 700 LossPred 0.0244 LossAtt 0.2829 TrainAcc 1.0000 TestAcc 0.9084 0.9900
Optimization Finished!
********** replication  20  **********
epoch   0 LossPred 0.8805 LossAtt 1.0252 TrainAcc 0.6700 TestAcc 0.6086 0.6500
epoch 100 LossPred 0.7429 LossAtt 0.2934 TrainAcc 0.6700 TestAcc 0.6041 0.6800
epoch 200 LossPred 0.3990 LossAtt 0.3056 TrainAcc 0.8500 TestAcc 0.8716 0.8500
epoch 300 LossPred 0.2929 LossAtt 0.3078 TrainAcc 0.9100 TestAcc 0.8914 0.9000
epoch 400 LossPred 0.1446 LossAtt 0.2742 TrainAcc 0.9600 TestAcc 0.9034 0.9100
epoch 500 LossPred 0.1288 LossAtt 0.2596 TrainAcc 0.9700 TestAcc 0.9117 0.9150
epoch 600 LossPred 0.1727 LossAtt 0.2611 TrainAcc 0.9300 TestAcc 0.9049 0.9200
epoch 700 LossPred 0.1632 LossAtt 0.2529 TrainAcc 0.9500 TestAcc 0.9009 0.9150
epoch 800 LossPred 0.1058 LossAtt 0.2404 TrainAcc 0.9700 TestAcc 0.9042 0.9250
epoch 900 LossPred 0.1329 LossAtt 0.2397 TrainAcc 0.9600 TestAcc 0.8999 0.9200
epoch 1000 LossPred 0.2508 LossAtt 0.2398 TrainAcc 0.9200 TestAcc 0.8639 0.9100
epoch 1100 LossPred 0.1029 LossAtt 0.2368 TrainAcc 0.9800 TestAcc 0.9109 0.9450
epoch 1200 LossPred 0.0895 LossAtt 0.2215 TrainAcc 0.9800 TestAcc 0.9042 0.9300
epoch 1300 LossPred 0.1021 LossAtt 0.2377 TrainAcc 0.9700 TestAcc 0.8931 0.9200
epoch 1400 LossPred 0.0908 LossAtt 0.2189 TrainAcc 0.9800 TestAcc 0.9112 0.9400
epoch 1500 LossPred 0.0862 LossAtt 0.2274 TrainAcc 0.9700 TestAcc 0.9222 0.9350
epoch 1600 LossPred 0.1398 LossAtt 0.2225 TrainAcc 0.9400 TestAcc 0.9124 0.9250
epoch 1700 LossPred 0.0720 LossAtt 0.2086 TrainAcc 0.9900 TestAcc 0.9289 0.9450
epoch 1800 LossPred 0.0693 LossAtt 0.2220 TrainAcc 0.9800 TestAcc 0.9209 0.9450
epoch 1900 LossPred 0.0773 LossAtt 0.2182 TrainAcc 0.9800 TestAcc 0.9234 0.9450
epoch 2000 LossPred 0.0713 LossAtt 0.2106 TrainAcc 0.9900 TestAcc 0.9359 0.9550
epoch 2100 LossPred 0.0807 LossAtt 0.2211 TrainAcc 0.9700 TestAcc 0.9304 0.9550
epoch 2200 LossPred 0.0787 LossAtt 0.2115 TrainAcc 0.9900 TestAcc 0.9334 0.9450
epoch 2300 LossPred 0.0626 LossAtt 0.2089 TrainAcc 0.9900 TestAcc 0.9499 0.9600
epoch 2400 LossPred 0.0577 LossAtt 0.2085 TrainAcc 0.9900 TestAcc 0.9332 0.9500
epoch 2500 LossPred 0.0951 LossAtt 0.2128 TrainAcc 0.9700 TestAcc 0.9289 0.9550
Optimization Finished!
********** replication  21  **********
epoch   0 LossPred 1.0613 LossAtt 1.0196 TrainAcc 0.4400 TestAcc 0.5308 0.4600
epoch 100 LossPred 0.8784 LossAtt 0.2780 TrainAcc 0.6500 TestAcc 0.6046 0.6500
epoch 200 LossPred 0.8580 LossAtt 0.2163 TrainAcc 0.6500 TestAcc 0.6046 0.6500
epoch 300 LossPred 0.8494 LossAtt 0.2166 TrainAcc 0.6600 TestAcc 0.6464 0.6600
epoch 400 LossPred 0.8178 LossAtt 0.2311 TrainAcc 0.6800 TestAcc 0.6594 0.6800
epoch 500 LossPred 0.2559 LossAtt 0.2790 TrainAcc 0.9400 TestAcc 0.9189 0.9200
epoch 600 LossPred 0.3132 LossAtt 0.2736 TrainAcc 0.9100 TestAcc 0.8761 0.8900
epoch 700 LossPred 0.1500 LossAtt 0.2660 TrainAcc 0.9700 TestAcc 0.9222 0.9450
epoch 800 LossPred 0.0910 LossAtt 0.2718 TrainAcc 0.9800 TestAcc 0.9309 0.9650
epoch 900 LossPred 0.0663 LossAtt 0.2571 TrainAcc 0.9900 TestAcc 0.9147 0.9750
epoch 1000 LossPred 0.0990 LossAtt 0.2574 TrainAcc 0.9900 TestAcc 0.8989 0.9700
epoch 1100 LossPred 0.0622 LossAtt 0.2459 TrainAcc 0.9900 TestAcc 0.9194 0.9750
epoch 1200 LossPred 0.0706 LossAtt 0.2546 TrainAcc 0.9900 TestAcc 0.9044 0.9750
epoch 1300 LossPred 0.0706 LossAtt 0.2585 TrainAcc 0.9900 TestAcc 0.9177 0.9700
epoch 1400 LossPred 0.0583 LossAtt 0.2412 TrainAcc 0.9800 TestAcc 0.9329 0.9850
epoch 1500 LossPred 0.0620 LossAtt 0.2491 TrainAcc 0.9900 TestAcc 0.9154 0.9800
epoch 1600 LossPred 0.0464 LossAtt 0.2429 TrainAcc 0.9900 TestAcc 0.9239 0.9800
epoch 1700 LossPred 0.2198 LossAtt 0.2552 TrainAcc 0.9100 TestAcc 0.9064 0.9500
epoch 1800 LossPred 0.0680 LossAtt 0.2586 TrainAcc 0.9900 TestAcc 0.9199 0.9750
epoch 1900 LossPred 0.0553 LossAtt 0.2516 TrainAcc 0.9900 TestAcc 0.9457 0.9800
epoch 2000 LossPred 0.0644 LossAtt 0.2469 TrainAcc 0.9800 TestAcc 0.9019 0.9700
epoch 2100 LossPred 0.1485 LossAtt 0.2412 TrainAcc 0.9300 TestAcc 0.8684 0.9650
epoch 2200 LossPred 0.0638 LossAtt 0.2533 TrainAcc 0.9900 TestAcc 0.9312 0.9750
epoch 2300 LossPred 0.0451 LossAtt 0.2509 TrainAcc 0.9900 TestAcc 0.9102 0.9850
epoch 2400 LossPred 0.1050 LossAtt 0.2635 TrainAcc 0.9700 TestAcc 0.9227 0.9800
epoch 2500 LossPred 0.0789 LossAtt 0.2530 TrainAcc 0.9800 TestAcc 0.9104 0.9750
Optimization Finished!
********** replication  22  **********
epoch   0 LossPred 0.9188 LossAtt 0.9906 TrainAcc 0.6300 TestAcc 0.5706 0.6150
epoch 100 LossPred 0.7050 LossAtt 0.3182 TrainAcc 0.7900 TestAcc 0.6642 0.7850
epoch 200 LossPred 0.2308 LossAtt 0.3016 TrainAcc 0.9400 TestAcc 0.9027 0.9200
epoch 300 LossPred 0.1850 LossAtt 0.3052 TrainAcc 0.9500 TestAcc 0.9082 0.9300
epoch 400 LossPred 0.2173 LossAtt 0.3030 TrainAcc 0.9200 TestAcc 0.8659 0.9050
epoch 500 LossPred 0.1257 LossAtt 0.3180 TrainAcc 0.9700 TestAcc 0.9074 0.9450
epoch 600 LossPred 0.1368 LossAtt 0.3188 TrainAcc 0.9400 TestAcc 0.8651 0.9300
epoch 700 LossPred 0.0779 LossAtt 0.3099 TrainAcc 0.9900 TestAcc 0.8764 0.9700
epoch 800 LossPred 0.0642 LossAtt 0.3213 TrainAcc 0.9900 TestAcc 0.8741 0.9600
epoch 900 LossPred 0.1192 LossAtt 0.3102 TrainAcc 0.9700 TestAcc 0.8456 0.9300
epoch 1000 LossPred 0.0707 LossAtt 0.3037 TrainAcc 0.9800 TestAcc 0.8443 0.9500
epoch 1100 LossPred 0.0633 LossAtt 0.2960 TrainAcc 0.9900 TestAcc 0.8611 0.9500
epoch 1200 LossPred 0.0730 LossAtt 0.3046 TrainAcc 0.9900 TestAcc 0.8614 0.9550
epoch 1300 LossPred 0.0755 LossAtt 0.3101 TrainAcc 0.9800 TestAcc 0.8451 0.9450
epoch 1400 LossPred 0.1697 LossAtt 0.2878 TrainAcc 0.9500 TestAcc 0.8473 0.9550
epoch 1500 LossPred 0.0559 LossAtt 0.2990 TrainAcc 0.9800 TestAcc 0.8569 0.9550
epoch 1600 LossPred 0.0406 LossAtt 0.2901 TrainAcc 1.0000 TestAcc 0.8584 0.9600
Optimization Finished!
********** replication  23  **********
epoch   0 LossPred 1.0347 LossAtt 1.0067 TrainAcc 0.5400 TestAcc 0.5325 0.5200
epoch 100 LossPred 0.8776 LossAtt 0.2142 TrainAcc 0.6300 TestAcc 0.5931 0.6300
epoch 200 LossPred 0.3023 LossAtt 0.2219 TrainAcc 0.8900 TestAcc 0.8426 0.9000
epoch 300 LossPred 0.2842 LossAtt 0.2090 TrainAcc 0.9000 TestAcc 0.8466 0.8950
epoch 400 LossPred 0.2102 LossAtt 0.2110 TrainAcc 0.9400 TestAcc 0.8521 0.9400
epoch 500 LossPred 0.2256 LossAtt 0.2302 TrainAcc 0.9300 TestAcc 0.8423 0.9300
epoch 600 LossPred 0.2255 LossAtt 0.2255 TrainAcc 0.9400 TestAcc 0.8461 0.9350
epoch 700 LossPred 0.1548 LossAtt 0.2176 TrainAcc 0.9700 TestAcc 0.8616 0.9300
epoch 800 LossPred 0.1976 LossAtt 0.2188 TrainAcc 0.9400 TestAcc 0.8506 0.9300
epoch 900 LossPred 0.1791 LossAtt 0.2282 TrainAcc 0.9500 TestAcc 0.8486 0.9200
epoch 1000 LossPred 0.1556 LossAtt 0.2086 TrainAcc 0.9500 TestAcc 0.8529 0.9200
epoch 1100 LossPred 0.1398 LossAtt 0.2060 TrainAcc 0.9500 TestAcc 0.8539 0.9350
epoch 1200 LossPred 0.1372 LossAtt 0.2148 TrainAcc 0.9600 TestAcc 0.8579 0.9300
epoch 1300 LossPred 0.1407 LossAtt 0.2022 TrainAcc 0.9600 TestAcc 0.8619 0.9450
epoch 1400 LossPred 0.2066 LossAtt 0.2046 TrainAcc 0.9400 TestAcc 0.8453 0.9450
epoch 1500 LossPred 0.1338 LossAtt 0.1886 TrainAcc 0.9700 TestAcc 0.8571 0.9300
epoch 1600 LossPred 0.1373 LossAtt 0.2051 TrainAcc 0.9600 TestAcc 0.8581 0.9300
epoch 1700 LossPred 0.1285 LossAtt 0.1973 TrainAcc 0.9700 TestAcc 0.8649 0.9350
epoch 1800 LossPred 0.1280 LossAtt 0.1960 TrainAcc 0.9700 TestAcc 0.8641 0.9400
epoch 1900 LossPred 0.1547 LossAtt 0.1930 TrainAcc 0.9500 TestAcc 0.8516 0.9200
epoch 2000 LossPred 0.2238 LossAtt 0.1927 TrainAcc 0.9200 TestAcc 0.8363 0.9000
epoch 2100 LossPred 0.1463 LossAtt 0.2067 TrainAcc 0.9500 TestAcc 0.8564 0.9300
epoch 2200 LossPred 0.1206 LossAtt 0.1905 TrainAcc 0.9700 TestAcc 0.8614 0.9350
epoch 2300 LossPred 0.1392 LossAtt 0.1981 TrainAcc 0.9600 TestAcc 0.8631 0.9400
epoch 2400 LossPred 0.1178 LossAtt 0.1880 TrainAcc 0.9600 TestAcc 0.8516 0.9300
epoch 2500 LossPred 0.1262 LossAtt 0.2069 TrainAcc 0.9600 TestAcc 0.8596 0.9400
Optimization Finished!
********** replication  24  **********
epoch   0 LossPred 1.0501 LossAtt 1.0050 TrainAcc 0.5100 TestAcc 0.5473 0.5100
epoch 100 LossPred 0.8619 LossAtt 0.2239 TrainAcc 0.6700 TestAcc 0.6094 0.6700
epoch 200 LossPred 0.8588 LossAtt 0.1253 TrainAcc 0.6700 TestAcc 0.6094 0.6700
epoch 300 LossPred 0.8556 LossAtt 0.1163 TrainAcc 0.6700 TestAcc 0.6094 0.6700
epoch 400 LossPred 0.8538 LossAtt 0.1226 TrainAcc 0.6700 TestAcc 0.6094 0.6700
epoch 500 LossPred 0.8511 LossAtt 0.1347 TrainAcc 0.6700 TestAcc 0.6094 0.6750
epoch 600 LossPred 0.2819 LossAtt 0.1586 TrainAcc 0.9300 TestAcc 0.8651 0.8950
epoch 700 LossPred 0.2631 LossAtt 0.1473 TrainAcc 0.9400 TestAcc 0.8576 0.8900
epoch 800 LossPred 0.2481 LossAtt 0.1495 TrainAcc 0.9400 TestAcc 0.8659 0.9100
epoch 900 LossPred 0.2956 LossAtt 0.1495 TrainAcc 0.9100 TestAcc 0.8516 0.8700
epoch 1000 LossPred 0.2952 LossAtt 0.1447 TrainAcc 0.9200 TestAcc 0.8656 0.8900
epoch 1100 LossPred 0.2729 LossAtt 0.1461 TrainAcc 0.9300 TestAcc 0.8639 0.8700
epoch 1200 LossPred 0.3450 LossAtt 0.1502 TrainAcc 0.8900 TestAcc 0.8559 0.8700
epoch 1300 LossPred 0.2464 LossAtt 0.1391 TrainAcc 0.9400 TestAcc 0.8624 0.9000
epoch 1400 LossPred 0.3037 LossAtt 0.1299 TrainAcc 0.9100 TestAcc 0.8636 0.8900
epoch 1500 LossPred 0.2652 LossAtt 0.1269 TrainAcc 0.9400 TestAcc 0.8759 0.9150
epoch 1600 LossPred 0.2321 LossAtt 0.1372 TrainAcc 0.9400 TestAcc 0.8604 0.9050
epoch 1700 LossPred 0.2262 LossAtt 0.1243 TrainAcc 0.9500 TestAcc 0.8734 0.9150
epoch 1800 LossPred 0.2696 LossAtt 0.1270 TrainAcc 0.9300 TestAcc 0.8551 0.8700
epoch 1900 LossPred 0.2250 LossAtt 0.1244 TrainAcc 0.9400 TestAcc 0.8659 0.9050
epoch 2000 LossPred 0.2962 LossAtt 0.1226 TrainAcc 0.9100 TestAcc 0.8649 0.8850
epoch 2100 LossPred 0.2837 LossAtt 0.1194 TrainAcc 0.9100 TestAcc 0.8571 0.8650
epoch 2200 LossPred 0.2318 LossAtt 0.1232 TrainAcc 0.9300 TestAcc 0.8686 0.9100
epoch 2300 LossPred 0.2352 LossAtt 0.1231 TrainAcc 0.9300 TestAcc 0.8624 0.8900
epoch 2400 LossPred 0.2297 LossAtt 0.1158 TrainAcc 0.9300 TestAcc 0.8679 0.9050
epoch 2500 LossPred 0.2224 LossAtt 0.1221 TrainAcc 0.9400 TestAcc 0.8629 0.9050
Optimization Finished!
********** replication  25  **********
epoch   0 LossPred 0.9931 LossAtt 1.0229 TrainAcc 0.5000 TestAcc 0.5060 0.5300
epoch 100 LossPred 0.8801 LossAtt 0.2721 TrainAcc 0.6900 TestAcc 0.6341 0.6850
epoch 200 LossPred 0.4479 LossAtt 0.2168 TrainAcc 0.8200 TestAcc 0.8569 0.8450
epoch 300 LossPred 0.3986 LossAtt 0.2008 TrainAcc 0.8900 TestAcc 0.8729 0.8550
epoch 400 LossPred 0.3353 LossAtt 0.2294 TrainAcc 0.9100 TestAcc 0.8891 0.8700
epoch 500 LossPred 0.5760 LossAtt 0.2360 TrainAcc 0.8100 TestAcc 0.8411 0.7950
epoch 600 LossPred 0.3720 LossAtt 0.2391 TrainAcc 0.8600 TestAcc 0.8556 0.8350
epoch 700 LossPred 0.3442 LossAtt 0.2423 TrainAcc 0.8600 TestAcc 0.8836 0.8450
epoch 800 LossPred 0.3575 LossAtt 0.2464 TrainAcc 0.9000 TestAcc 0.8801 0.8750
epoch 900 LossPred 0.2952 LossAtt 0.2430 TrainAcc 0.8800 TestAcc 0.8681 0.8500
epoch 1000 LossPred 0.3057 LossAtt 0.2607 TrainAcc 0.8800 TestAcc 0.8761 0.8500
epoch 1100 LossPred 0.3203 LossAtt 0.2575 TrainAcc 0.8800 TestAcc 0.8806 0.8550
epoch 1200 LossPred 0.2487 LossAtt 0.2377 TrainAcc 0.9100 TestAcc 0.9102 0.9050
epoch 1300 LossPred 0.2590 LossAtt 0.2438 TrainAcc 0.8900 TestAcc 0.9049 0.9100
epoch 1400 LossPred 0.3388 LossAtt 0.2317 TrainAcc 0.9100 TestAcc 0.8876 0.8950
epoch 1500 LossPred 0.2254 LossAtt 0.2172 TrainAcc 0.9100 TestAcc 0.9197 0.9000
epoch 1600 LossPred 0.2156 LossAtt 0.2198 TrainAcc 0.9400 TestAcc 0.9122 0.9000
epoch 1700 LossPred 0.2037 LossAtt 0.2145 TrainAcc 0.9400 TestAcc 0.9197 0.9100
epoch 1800 LossPred 0.3456 LossAtt 0.2081 TrainAcc 0.8400 TestAcc 0.8969 0.8750
epoch 1900 LossPred 0.2025 LossAtt 0.2034 TrainAcc 0.9400 TestAcc 0.9204 0.9200
epoch 2000 LossPred 0.4693 LossAtt 0.2115 TrainAcc 0.8400 TestAcc 0.8401 0.8400
epoch 2100 LossPred 0.1838 LossAtt 0.2000 TrainAcc 0.9500 TestAcc 0.9292 0.9300
epoch 2200 LossPred 0.2103 LossAtt 0.2028 TrainAcc 0.9300 TestAcc 0.9102 0.9150
epoch 2300 LossPred 0.2951 LossAtt 0.2043 TrainAcc 0.9200 TestAcc 0.9264 0.9100
epoch 2400 LossPred 0.2149 LossAtt 0.2100 TrainAcc 0.9500 TestAcc 0.9224 0.9150
epoch 2500 LossPred 0.1919 LossAtt 0.1976 TrainAcc 0.9400 TestAcc 0.9194 0.9250
Optimization Finished!
********** replication  26  **********
epoch   0 LossPred 1.0413 LossAtt 1.0040 TrainAcc 0.4800 TestAcc 0.4625 0.4900
epoch 100 LossPred 0.9593 LossAtt 0.2993 TrainAcc 0.6300 TestAcc 0.5991 0.6250
epoch 200 LossPred 0.8319 LossAtt 0.2708 TrainAcc 0.6800 TestAcc 0.6599 0.6850
epoch 300 LossPred 0.3975 LossAtt 0.3044 TrainAcc 0.8900 TestAcc 0.8606 0.8650
epoch 400 LossPred 0.2918 LossAtt 0.3134 TrainAcc 0.9200 TestAcc 0.8744 0.9200
epoch 500 LossPred 0.2179 LossAtt 0.2622 TrainAcc 0.9300 TestAcc 0.8789 0.9100
epoch 600 LossPred 0.1951 LossAtt 0.2343 TrainAcc 0.9500 TestAcc 0.8889 0.9100
epoch 700 LossPred 0.1934 LossAtt 0.2175 TrainAcc 0.9500 TestAcc 0.8899 0.9100
epoch 800 LossPred 0.2378 LossAtt 0.2027 TrainAcc 0.9100 TestAcc 0.8586 0.9050
epoch 900 LossPred 0.1508 LossAtt 0.1907 TrainAcc 0.9600 TestAcc 0.9174 0.9300
epoch 1000 LossPred 0.1427 LossAtt 0.1932 TrainAcc 0.9700 TestAcc 0.9244 0.9350
epoch 1100 LossPred 0.4000 LossAtt 0.1963 TrainAcc 0.8600 TestAcc 0.8546 0.8500
epoch 1200 LossPred 0.1887 LossAtt 0.1868 TrainAcc 0.9400 TestAcc 0.9049 0.9200
epoch 1300 LossPred 0.2663 LossAtt 0.1733 TrainAcc 0.9200 TestAcc 0.8846 0.9000
epoch 1400 LossPred 0.1669 LossAtt 0.1743 TrainAcc 0.9600 TestAcc 0.9034 0.9350
epoch 1500 LossPred 0.1289 LossAtt 0.1740 TrainAcc 0.9800 TestAcc 0.9237 0.9600
epoch 1600 LossPred 0.1347 LossAtt 0.1620 TrainAcc 0.9600 TestAcc 0.9252 0.9600
epoch 1700 LossPred 0.1274 LossAtt 0.1650 TrainAcc 0.9500 TestAcc 0.9279 0.9500
epoch 1800 LossPred 0.1860 LossAtt 0.1623 TrainAcc 0.9300 TestAcc 0.8791 0.9150
epoch 1900 LossPred 0.2188 LossAtt 0.1553 TrainAcc 0.9200 TestAcc 0.8719 0.8950
epoch 2000 LossPred 0.2714 LossAtt 0.1573 TrainAcc 0.9000 TestAcc 0.8551 0.9000
epoch 2100 LossPred 0.2400 LossAtt 0.1587 TrainAcc 0.9300 TestAcc 0.8861 0.9100
epoch 2200 LossPred 0.1829 LossAtt 0.1591 TrainAcc 0.9400 TestAcc 0.9114 0.9350
epoch 2300 LossPred 0.2107 LossAtt 0.1656 TrainAcc 0.9400 TestAcc 0.8746 0.9200
epoch 2400 LossPred 0.4990 LossAtt 0.1567 TrainAcc 0.8500 TestAcc 0.8226 0.8400
epoch 2500 LossPred 0.5096 LossAtt 0.1737 TrainAcc 0.8400 TestAcc 0.7848 0.8300
Optimization Finished!
********** replication  27  **********
epoch   0 LossPred 1.1700 LossAtt 1.0071 TrainAcc 0.3800 TestAcc 0.4179 0.3800
epoch 100 LossPred 0.8363 LossAtt 0.2580 TrainAcc 0.6800 TestAcc 0.6096 0.6750
epoch 200 LossPred 0.5499 LossAtt 0.1803 TrainAcc 0.8300 TestAcc 0.8093 0.7750
epoch 300 LossPred 0.5238 LossAtt 0.1901 TrainAcc 0.8000 TestAcc 0.8531 0.8050
epoch 400 LossPred 0.5004 LossAtt 0.1585 TrainAcc 0.8400 TestAcc 0.8408 0.8300
epoch 500 LossPred 0.4724 LossAtt 0.1691 TrainAcc 0.8400 TestAcc 0.8398 0.8350
epoch 600 LossPred 0.5961 LossAtt 0.1552 TrainAcc 0.8100 TestAcc 0.7635 0.7800
epoch 700 LossPred 0.4104 LossAtt 0.1551 TrainAcc 0.8700 TestAcc 0.8131 0.8150
epoch 800 LossPred 0.4230 LossAtt 0.1549 TrainAcc 0.8600 TestAcc 0.8361 0.8250
epoch 900 LossPred 0.4563 LossAtt 0.1483 TrainAcc 0.8400 TestAcc 0.8308 0.8250
epoch 1000 LossPred 0.5001 LossAtt 0.1473 TrainAcc 0.8300 TestAcc 0.8048 0.8150
epoch 1100 LossPred 0.5046 LossAtt 0.1691 TrainAcc 0.8400 TestAcc 0.8358 0.8450
epoch 1200 LossPred 0.5463 LossAtt 0.1533 TrainAcc 0.8200 TestAcc 0.8468 0.8400
epoch 1300 LossPred 0.3755 LossAtt 0.1581 TrainAcc 0.8800 TestAcc 0.8278 0.8300
epoch 1400 LossPred 0.3772 LossAtt 0.1622 TrainAcc 0.8700 TestAcc 0.8336 0.8150
epoch 1500 LossPred 0.4208 LossAtt 0.1685 TrainAcc 0.8700 TestAcc 0.8506 0.8450
epoch 1600 LossPred 0.3755 LossAtt 0.1652 TrainAcc 0.8800 TestAcc 0.8306 0.8200
epoch 1700 LossPred 0.5288 LossAtt 0.1424 TrainAcc 0.8300 TestAcc 0.7858 0.7950
epoch 1800 LossPred 0.3988 LossAtt 0.1635 TrainAcc 0.8700 TestAcc 0.8223 0.8150
epoch 1900 LossPred 0.3635 LossAtt 0.1587 TrainAcc 0.8800 TestAcc 0.8421 0.8400
epoch 2000 LossPred 0.3653 LossAtt 0.1546 TrainAcc 0.8800 TestAcc 0.8381 0.8400
epoch 2100 LossPred 0.3634 LossAtt 0.1566 TrainAcc 0.8800 TestAcc 0.8406 0.8350
epoch 2200 LossPred 0.3734 LossAtt 0.1733 TrainAcc 0.8800 TestAcc 0.8371 0.8400
epoch 2300 LossPred 0.4476 LossAtt 0.1483 TrainAcc 0.8500 TestAcc 0.8248 0.8200
epoch 2400 LossPred 0.4250 LossAtt 0.1666 TrainAcc 0.8500 TestAcc 0.8253 0.8200
epoch 2500 LossPred 0.3218 LossAtt 0.1631 TrainAcc 0.9100 TestAcc 0.8491 0.8600
Optimization Finished!
********** replication  28  **********
epoch   0 LossPred 1.3396 LossAtt 0.9962 TrainAcc 0.3400 TestAcc 0.3994 0.3650
epoch 100 LossPred 0.9088 LossAtt 0.2722 TrainAcc 0.6600 TestAcc 0.6129 0.6600
epoch 200 LossPred 0.8819 LossAtt 0.2304 TrainAcc 0.6600 TestAcc 0.6129 0.6600
epoch 300 LossPred 0.4921 LossAtt 0.2984 TrainAcc 0.8900 TestAcc 0.8819 0.8550
epoch 400 LossPred 0.3011 LossAtt 0.2496 TrainAcc 0.9100 TestAcc 0.8836 0.8850
epoch 500 LossPred 0.3624 LossAtt 0.2569 TrainAcc 0.8600 TestAcc 0.8654 0.8750
epoch 600 LossPred 0.3073 LossAtt 0.2497 TrainAcc 0.9100 TestAcc 0.8754 0.8600
epoch 700 LossPred 0.3463 LossAtt 0.2418 TrainAcc 0.8900 TestAcc 0.8606 0.8800
epoch 800 LossPred 0.1516 LossAtt 0.2346 TrainAcc 0.9500 TestAcc 0.8946 0.9400
epoch 900 LossPred 0.2014 LossAtt 0.2400 TrainAcc 0.9300 TestAcc 0.8956 0.9200
epoch 1000 LossPred 0.1488 LossAtt 0.2347 TrainAcc 0.9600 TestAcc 0.8861 0.9300
epoch 1100 LossPred 0.1838 LossAtt 0.2383 TrainAcc 0.9300 TestAcc 0.8936 0.9350
epoch 1200 LossPred 0.1312 LossAtt 0.2266 TrainAcc 0.9700 TestAcc 0.8826 0.9250
epoch 1300 LossPred 0.4097 LossAtt 0.2290 TrainAcc 0.8700 TestAcc 0.8326 0.8550
epoch 1400 LossPred 0.1956 LossAtt 0.2632 TrainAcc 0.9500 TestAcc 0.8856 0.9250
epoch 1500 LossPred 0.4114 LossAtt 0.2600 TrainAcc 0.8600 TestAcc 0.8251 0.8500
epoch 1600 LossPred 0.2889 LossAtt 0.2800 TrainAcc 0.9100 TestAcc 0.8679 0.8850
epoch 1700 LossPred 0.3003 LossAtt 0.2756 TrainAcc 0.9100 TestAcc 0.8744 0.9200
epoch 1800 LossPred 0.2593 LossAtt 0.2682 TrainAcc 0.9200 TestAcc 0.8796 0.9300
epoch 1900 LossPred 0.2277 LossAtt 0.2401 TrainAcc 0.9300 TestAcc 0.8776 0.9150
epoch 2000 LossPred 0.1321 LossAtt 0.2407 TrainAcc 0.9700 TestAcc 0.8914 0.9650
epoch 2100 LossPred 0.1553 LossAtt 0.2360 TrainAcc 0.9500 TestAcc 0.8841 0.9600
epoch 2200 LossPred 0.1500 LossAtt 0.2223 TrainAcc 0.9500 TestAcc 0.8959 0.9650
epoch 2300 LossPred 0.1126 LossAtt 0.2134 TrainAcc 0.9700 TestAcc 0.8866 0.9650
epoch 2400 LossPred 0.1148 LossAtt 0.2244 TrainAcc 0.9700 TestAcc 0.8864 0.9700
epoch 2500 LossPred 0.2243 LossAtt 0.2282 TrainAcc 0.9200 TestAcc 0.8784 0.9150
Optimization Finished!
********** replication  29  **********
epoch   0 LossPred 1.0137 LossAtt 1.0392 TrainAcc 0.5400 TestAcc 0.5048 0.5400
epoch 100 LossPred 0.8173 LossAtt 0.2823 TrainAcc 0.7000 TestAcc 0.6374 0.7050
epoch 200 LossPred 0.4688 LossAtt 0.2430 TrainAcc 0.8300 TestAcc 0.8136 0.8300
epoch 300 LossPred 0.3172 LossAtt 0.2295 TrainAcc 0.9100 TestAcc 0.8869 0.8600
epoch 400 LossPred 0.3153 LossAtt 0.2060 TrainAcc 0.9200 TestAcc 0.8964 0.8700
epoch 500 LossPred 0.2733 LossAtt 0.1954 TrainAcc 0.9200 TestAcc 0.8964 0.8750
epoch 600 LossPred 0.2648 LossAtt 0.1729 TrainAcc 0.9200 TestAcc 0.8884 0.8800
epoch 700 LossPred 0.2709 LossAtt 0.1716 TrainAcc 0.9300 TestAcc 0.8741 0.8750
epoch 800 LossPred 0.2855 LossAtt 0.1660 TrainAcc 0.9200 TestAcc 0.8986 0.8900
epoch 900 LossPred 0.2524 LossAtt 0.1672 TrainAcc 0.9300 TestAcc 0.8914 0.9000
epoch 1000 LossPred 0.3831 LossAtt 0.1622 TrainAcc 0.8900 TestAcc 0.8741 0.8600
epoch 1100 LossPred 0.4535 LossAtt 0.1791 TrainAcc 0.8500 TestAcc 0.8431 0.8300
epoch 1200 LossPred 0.2427 LossAtt 0.1897 TrainAcc 0.9200 TestAcc 0.9272 0.9000
epoch 1300 LossPred 0.2341 LossAtt 0.1956 TrainAcc 0.9300 TestAcc 0.9319 0.9000
epoch 1400 LossPred 0.2272 LossAtt 0.1991 TrainAcc 0.9400 TestAcc 0.9339 0.9200
epoch 1500 LossPred 0.1955 LossAtt 0.2045 TrainAcc 0.9300 TestAcc 0.9079 0.9150
epoch 1600 LossPred 0.2288 LossAtt 0.1864 TrainAcc 0.9300 TestAcc 0.9292 0.9100
epoch 1700 LossPred 0.1836 LossAtt 0.1995 TrainAcc 0.9500 TestAcc 0.9074 0.9250
epoch 1800 LossPred 0.3151 LossAtt 0.2203 TrainAcc 0.8900 TestAcc 0.8338 0.8850
epoch 1900 LossPred 0.1698 LossAtt 0.1979 TrainAcc 0.9200 TestAcc 0.9214 0.9200
epoch 2000 LossPred 0.1577 LossAtt 0.1790 TrainAcc 0.9700 TestAcc 0.9367 0.9250
epoch 2100 LossPred 0.1510 LossAtt 0.1792 TrainAcc 0.9600 TestAcc 0.9299 0.9300
epoch 2200 LossPred 0.1935 LossAtt 0.1885 TrainAcc 0.9100 TestAcc 0.8911 0.9200
epoch 2300 LossPred 0.2098 LossAtt 0.1865 TrainAcc 0.9400 TestAcc 0.9002 0.9400
epoch 2400 LossPred 0.4931 LossAtt 0.2030 TrainAcc 0.8100 TestAcc 0.8036 0.8100
epoch 2500 LossPred 0.2977 LossAtt 0.2026 TrainAcc 0.9200 TestAcc 0.8639 0.9100
Optimization Finished!
********** replication  30  **********
epoch   0 LossPred 1.1443 LossAtt 1.0379 TrainAcc 0.3700 TestAcc 0.3696 0.4050
epoch 100 LossPred 0.8291 LossAtt 0.2552 TrainAcc 0.6300 TestAcc 0.6036 0.6500
epoch 200 LossPred 0.4020 LossAtt 0.3424 TrainAcc 0.8900 TestAcc 0.8509 0.8500
epoch 300 LossPred 0.4122 LossAtt 0.3064 TrainAcc 0.8600 TestAcc 0.8258 0.8150
epoch 400 LossPred 0.3658 LossAtt 0.2871 TrainAcc 0.8800 TestAcc 0.8406 0.8300
epoch 500 LossPred 0.1493 LossAtt 0.2479 TrainAcc 0.9500 TestAcc 0.8771 0.9350
epoch 600 LossPred 0.2079 LossAtt 0.2692 TrainAcc 0.9400 TestAcc 0.8724 0.8950
epoch 700 LossPred 0.2556 LossAtt 0.2463 TrainAcc 0.9100 TestAcc 0.8446 0.8900
epoch 800 LossPred 0.1766 LossAtt 0.2360 TrainAcc 0.9400 TestAcc 0.8799 0.9250
epoch 900 LossPred 0.2380 LossAtt 0.2445 TrainAcc 0.9300 TestAcc 0.8751 0.9000
epoch 1000 LossPred 0.1526 LossAtt 0.2349 TrainAcc 0.9300 TestAcc 0.8739 0.9150
epoch 1100 LossPred 0.2381 LossAtt 0.2264 TrainAcc 0.9300 TestAcc 0.8844 0.8950
epoch 1200 LossPred 0.1820 LossAtt 0.2314 TrainAcc 0.9400 TestAcc 0.8819 0.9250
epoch 1300 LossPred 0.1267 LossAtt 0.2178 TrainAcc 0.9600 TestAcc 0.8789 0.9300
epoch 1400 LossPred 0.3652 LossAtt 0.2225 TrainAcc 0.8800 TestAcc 0.8336 0.8800
epoch 1500 LossPred 0.1707 LossAtt 0.2355 TrainAcc 0.9600 TestAcc 0.8899 0.9200
epoch 1600 LossPred 0.1784 LossAtt 0.2391 TrainAcc 0.9500 TestAcc 0.8839 0.9100
epoch 1700 LossPred 0.1586 LossAtt 0.2152 TrainAcc 0.9600 TestAcc 0.8861 0.9250
epoch 1800 LossPred 0.1709 LossAtt 0.2235 TrainAcc 0.9500 TestAcc 0.8851 0.9250
epoch 1900 LossPred 0.2192 LossAtt 0.2149 TrainAcc 0.9400 TestAcc 0.8711 0.9150
epoch 2000 LossPred 0.1924 LossAtt 0.2095 TrainAcc 0.9200 TestAcc 0.8601 0.9300
epoch 2100 LossPred 0.2692 LossAtt 0.2138 TrainAcc 0.9100 TestAcc 0.8201 0.9100
epoch 2200 LossPred 0.1734 LossAtt 0.2159 TrainAcc 0.9300 TestAcc 0.8664 0.9250
epoch 2300 LossPred 0.1419 LossAtt 0.2118 TrainAcc 0.9300 TestAcc 0.8691 0.9250
epoch 2400 LossPred 0.1958 LossAtt 0.2223 TrainAcc 0.9300 TestAcc 0.8564 0.9250
epoch 2500 LossPred 0.1181 LossAtt 0.2132 TrainAcc 0.9700 TestAcc 0.8721 0.9700
Optimization Finished!
********** replication  31  **********
epoch   0 LossPred 1.1901 LossAtt 1.0069 TrainAcc 0.4000 TestAcc 0.4102 0.4500
epoch 100 LossPred 0.9282 LossAtt 0.2705 TrainAcc 0.6300 TestAcc 0.6036 0.6100
epoch 200 LossPred 0.9126 LossAtt 0.2049 TrainAcc 0.6300 TestAcc 0.6036 0.6350
epoch 300 LossPred 0.9051 LossAtt 0.1901 TrainAcc 0.6500 TestAcc 0.6166 0.6450
epoch 400 LossPred 0.4821 LossAtt 0.2836 TrainAcc 0.8600 TestAcc 0.8216 0.8250
epoch 500 LossPred 0.3847 LossAtt 0.2808 TrainAcc 0.8500 TestAcc 0.8521 0.8450
epoch 600 LossPred 0.3283 LossAtt 0.2923 TrainAcc 0.9100 TestAcc 0.8719 0.8850
epoch 700 LossPred 0.2377 LossAtt 0.3100 TrainAcc 0.9600 TestAcc 0.8844 0.9050
epoch 800 LossPred 0.1947 LossAtt 0.3019 TrainAcc 0.9500 TestAcc 0.8964 0.9100
epoch 900 LossPred 0.2005 LossAtt 0.3216 TrainAcc 0.9300 TestAcc 0.8841 0.9200
epoch 1000 LossPred 0.1241 LossAtt 0.3058 TrainAcc 0.9800 TestAcc 0.8961 0.9300
epoch 1100 LossPred 0.1437 LossAtt 0.2916 TrainAcc 0.9600 TestAcc 0.8914 0.9150
epoch 1200 LossPred 0.1519 LossAtt 0.2974 TrainAcc 0.9400 TestAcc 0.8796 0.9350
epoch 1300 LossPred 0.1009 LossAtt 0.2984 TrainAcc 0.9800 TestAcc 0.8996 0.9450
epoch 1400 LossPred 0.0767 LossAtt 0.2938 TrainAcc 0.9800 TestAcc 0.9234 0.9400
epoch 1500 LossPred 0.0682 LossAtt 0.2766 TrainAcc 0.9900 TestAcc 0.9179 0.9600
epoch 1600 LossPred 0.0716 LossAtt 0.2781 TrainAcc 0.9800 TestAcc 0.9029 0.9550
epoch 1700 LossPred 0.0651 LossAtt 0.2934 TrainAcc 0.9800 TestAcc 0.9119 0.9550
epoch 1800 LossPred 0.1169 LossAtt 0.2671 TrainAcc 0.9700 TestAcc 0.8939 0.9350
epoch 1900 LossPred 0.1169 LossAtt 0.2686 TrainAcc 0.9600 TestAcc 0.8859 0.9450
epoch 2000 LossPred 0.0828 LossAtt 0.2752 TrainAcc 0.9800 TestAcc 0.9117 0.9500
epoch 2100 LossPred 0.0520 LossAtt 0.2675 TrainAcc 0.9900 TestAcc 0.9147 0.9600
epoch 2200 LossPred 0.0775 LossAtt 0.2646 TrainAcc 0.9800 TestAcc 0.8979 0.9500
epoch 2300 LossPred 0.0685 LossAtt 0.2584 TrainAcc 0.9800 TestAcc 0.9192 0.9550
epoch 2400 LossPred 0.0779 LossAtt 0.2555 TrainAcc 0.9800 TestAcc 0.9162 0.9450
epoch 2500 LossPred 0.0595 LossAtt 0.2495 TrainAcc 0.9900 TestAcc 0.9157 0.9500
Optimization Finished!
********** replication  32  **********
epoch   0 LossPred 1.0394 LossAtt 0.9834 TrainAcc 0.5000 TestAcc 0.5403 0.4950
epoch 100 LossPred 0.8282 LossAtt 0.3092 TrainAcc 0.7000 TestAcc 0.6034 0.7050
epoch 200 LossPred 0.6606 LossAtt 0.2792 TrainAcc 0.7800 TestAcc 0.6101 0.7650
epoch 300 LossPred 0.6427 LossAtt 0.2441 TrainAcc 0.7800 TestAcc 0.6101 0.7800
epoch 400 LossPred 0.6285 LossAtt 0.2759 TrainAcc 0.8000 TestAcc 0.6174 0.8000
epoch 500 LossPred 0.5863 LossAtt 0.2853 TrainAcc 0.7900 TestAcc 0.6124 0.8000
epoch 600 LossPred 0.5538 LossAtt 0.2757 TrainAcc 0.8000 TestAcc 0.6069 0.8000
epoch 700 LossPred 0.5330 LossAtt 0.2946 TrainAcc 0.8000 TestAcc 0.6076 0.7850
epoch 800 LossPred 0.5133 LossAtt 0.2873 TrainAcc 0.8200 TestAcc 0.5898 0.8100
epoch 900 LossPred 0.4697 LossAtt 0.2901 TrainAcc 0.8500 TestAcc 0.5723 0.8050
epoch 1000 LossPred 0.4419 LossAtt 0.2976 TrainAcc 0.8800 TestAcc 0.5833 0.8000
epoch 1100 LossPred 0.4173 LossAtt 0.2975 TrainAcc 0.8700 TestAcc 0.5676 0.8150
epoch 1200 LossPred 0.4057 LossAtt 0.2945 TrainAcc 0.8900 TestAcc 0.5681 0.8000
epoch 1300 LossPred 0.4044 LossAtt 0.3035 TrainAcc 0.8800 TestAcc 0.5776 0.8200
epoch 1400 LossPred 0.3932 LossAtt 0.2893 TrainAcc 0.8900 TestAcc 0.5736 0.8200
epoch 1500 LossPred 0.3974 LossAtt 0.2939 TrainAcc 0.8900 TestAcc 0.5763 0.8200
epoch 1600 LossPred 0.3928 LossAtt 0.2558 TrainAcc 0.8800 TestAcc 0.5731 0.8200
epoch 1700 LossPred 0.3812 LossAtt 0.2689 TrainAcc 0.8800 TestAcc 0.5803 0.8300
epoch 1800 LossPred 0.3642 LossAtt 0.2769 TrainAcc 0.8900 TestAcc 0.5818 0.8350
epoch 1900 LossPred 0.3687 LossAtt 0.2776 TrainAcc 0.8800 TestAcc 0.5828 0.8450
epoch 2000 LossPred 0.3544 LossAtt 0.2685 TrainAcc 0.9000 TestAcc 0.5761 0.8500
epoch 2100 LossPred 0.3544 LossAtt 0.2510 TrainAcc 0.9000 TestAcc 0.5781 0.8650
epoch 2200 LossPred 0.3610 LossAtt 0.2757 TrainAcc 0.9200 TestAcc 0.5956 0.8350
epoch 2300 LossPred 0.5118 LossAtt 0.3162 TrainAcc 0.8400 TestAcc 0.6264 0.7900
epoch 2400 LossPred 0.4208 LossAtt 0.3379 TrainAcc 0.8500 TestAcc 0.6259 0.8150
epoch 2500 LossPred 0.3694 LossAtt 0.3520 TrainAcc 0.8700 TestAcc 0.6416 0.8750
Optimization Finished!
********** replication  33  **********
epoch   0 LossPred 1.0170 LossAtt 1.0206 TrainAcc 0.4600 TestAcc 0.4612 0.4850
epoch 100 LossPred 0.8476 LossAtt 0.2908 TrainAcc 0.6800 TestAcc 0.6191 0.7000
epoch 200 LossPred 0.2120 LossAtt 0.2747 TrainAcc 0.9400 TestAcc 0.8806 0.9200
epoch 300 LossPred 0.2783 LossAtt 0.2408 TrainAcc 0.9100 TestAcc 0.8458 0.9250
epoch 400 LossPred 0.1778 LossAtt 0.2219 TrainAcc 0.9400 TestAcc 0.8721 0.9200
epoch 500 LossPred 0.2531 LossAtt 0.2085 TrainAcc 0.9200 TestAcc 0.8606 0.8850
epoch 600 LossPred 0.1631 LossAtt 0.2036 TrainAcc 0.9400 TestAcc 0.8776 0.9400
epoch 700 LossPred 0.2355 LossAtt 0.1936 TrainAcc 0.9300 TestAcc 0.8694 0.8900
epoch 800 LossPred 0.2363 LossAtt 0.1903 TrainAcc 0.9000 TestAcc 0.8596 0.9100
epoch 900 LossPred 0.1815 LossAtt 0.2012 TrainAcc 0.9300 TestAcc 0.8776 0.9250
epoch 1000 LossPred 0.2339 LossAtt 0.1865 TrainAcc 0.9000 TestAcc 0.8649 0.9050
epoch 1100 LossPred 0.2039 LossAtt 0.1727 TrainAcc 0.9200 TestAcc 0.8804 0.9200
epoch 1200 LossPred 0.2374 LossAtt 0.1751 TrainAcc 0.9200 TestAcc 0.8529 0.9100
epoch 1300 LossPred 0.2579 LossAtt 0.1729 TrainAcc 0.9200 TestAcc 0.8699 0.8900
epoch 1400 LossPred 0.1873 LossAtt 0.1715 TrainAcc 0.9400 TestAcc 0.8739 0.9100
epoch 1500 LossPred 0.1981 LossAtt 0.1588 TrainAcc 0.9200 TestAcc 0.8669 0.9150
epoch 1600 LossPred 0.3534 LossAtt 0.1535 TrainAcc 0.8800 TestAcc 0.8088 0.8950
epoch 1700 LossPred 0.4104 LossAtt 0.1479 TrainAcc 0.8500 TestAcc 0.7803 0.8550
epoch 1800 LossPred 0.4462 LossAtt 0.1379 TrainAcc 0.8600 TestAcc 0.8361 0.8550
epoch 1900 LossPred 0.3655 LossAtt 0.1443 TrainAcc 0.8700 TestAcc 0.8088 0.8950
epoch 2000 LossPred 0.4017 LossAtt 0.1539 TrainAcc 0.8600 TestAcc 0.7938 0.8750
epoch 2100 LossPred 0.3819 LossAtt 0.1519 TrainAcc 0.8600 TestAcc 0.7973 0.8750
epoch 2200 LossPred 0.2195 LossAtt 0.1644 TrainAcc 0.9200 TestAcc 0.8689 0.9200
epoch 2300 LossPred 0.2433 LossAtt 0.1574 TrainAcc 0.9100 TestAcc 0.8599 0.9250
epoch 2400 LossPred 0.2985 LossAtt 0.1513 TrainAcc 0.9100 TestAcc 0.8451 0.8950
epoch 2500 LossPred 0.2372 LossAtt 0.1494 TrainAcc 0.9300 TestAcc 0.8559 0.9250
Optimization Finished!
********** replication  34  **********
epoch   0 LossPred 1.0321 LossAtt 1.0277 TrainAcc 0.5900 TestAcc 0.5711 0.6150
epoch 100 LossPred 0.7965 LossAtt 0.2997 TrainAcc 0.6900 TestAcc 0.6201 0.6950
epoch 200 LossPred 0.7538 LossAtt 0.2711 TrainAcc 0.7000 TestAcc 0.5931 0.7000
epoch 300 LossPred 0.7409 LossAtt 0.2344 TrainAcc 0.7000 TestAcc 0.5933 0.7200
epoch 400 LossPred 0.7300 LossAtt 0.2123 TrainAcc 0.6800 TestAcc 0.5933 0.7350
epoch 500 LossPred 0.7124 LossAtt 0.2310 TrainAcc 0.7200 TestAcc 0.6039 0.7400
epoch 600 LossPred 0.6953 LossAtt 0.2877 TrainAcc 0.7200 TestAcc 0.6041 0.7200
epoch 700 LossPred 0.6756 LossAtt 0.3060 TrainAcc 0.7600 TestAcc 0.5866 0.7500
epoch 800 LossPred 0.6337 LossAtt 0.3327 TrainAcc 0.7900 TestAcc 0.5898 0.7700
epoch 900 LossPred 0.6410 LossAtt 0.3368 TrainAcc 0.7600 TestAcc 0.5883 0.7450
epoch 1000 LossPred 0.5950 LossAtt 0.3507 TrainAcc 0.8100 TestAcc 0.5943 0.7550
epoch 1100 LossPred 0.5850 LossAtt 0.3385 TrainAcc 0.7900 TestAcc 0.5938 0.7550
epoch 1200 LossPred 0.6142 LossAtt 0.3423 TrainAcc 0.7500 TestAcc 0.5863 0.7500
epoch 1300 LossPred 0.5684 LossAtt 0.3147 TrainAcc 0.8000 TestAcc 0.6014 0.7600
epoch 1400 LossPred 0.5547 LossAtt 0.3251 TrainAcc 0.8000 TestAcc 0.5911 0.7600
epoch 1500 LossPred 0.5791 LossAtt 0.3299 TrainAcc 0.7900 TestAcc 0.5978 0.7600
epoch 1600 LossPred 0.6193 LossAtt 0.3345 TrainAcc 0.7900 TestAcc 0.5746 0.7350
epoch 1700 LossPred 0.5620 LossAtt 0.3083 TrainAcc 0.8000 TestAcc 0.5898 0.7550
epoch 1800 LossPred 0.5485 LossAtt 0.3334 TrainAcc 0.8200 TestAcc 0.5968 0.7700
epoch 1900 LossPred 0.5396 LossAtt 0.3396 TrainAcc 0.8200 TestAcc 0.5971 0.7400
epoch 2000 LossPred 0.5252 LossAtt 0.3383 TrainAcc 0.8200 TestAcc 0.6011 0.7500
epoch 2100 LossPred 0.5433 LossAtt 0.3399 TrainAcc 0.8100 TestAcc 0.5976 0.7250
epoch 2200 LossPred 0.5516 LossAtt 0.3053 TrainAcc 0.8000 TestAcc 0.5953 0.7300
epoch 2300 LossPred 0.5313 LossAtt 0.3165 TrainAcc 0.8000 TestAcc 0.5936 0.7550
epoch 2400 LossPred 0.5326 LossAtt 0.3098 TrainAcc 0.7900 TestAcc 0.5856 0.7600
epoch 2500 LossPred 0.5197 LossAtt 0.3097 TrainAcc 0.8200 TestAcc 0.5898 0.7500
Optimization Finished!
********** replication  35  **********
epoch   0 LossPred 1.0206 LossAtt 1.0111 TrainAcc 0.5100 TestAcc 0.5450 0.5650
epoch 100 LossPred 0.8544 LossAtt 0.3565 TrainAcc 0.6300 TestAcc 0.6484 0.6500
epoch 200 LossPred 0.2729 LossAtt 0.3261 TrainAcc 0.9100 TestAcc 0.9162 0.8800
epoch 300 LossPred 0.2159 LossAtt 0.3087 TrainAcc 0.9500 TestAcc 0.9229 0.8850
epoch 400 LossPred 0.1919 LossAtt 0.2858 TrainAcc 0.9300 TestAcc 0.9209 0.8850
epoch 500 LossPred 0.1893 LossAtt 0.2889 TrainAcc 0.9400 TestAcc 0.9239 0.8950
epoch 600 LossPred 0.2223 LossAtt 0.2612 TrainAcc 0.9400 TestAcc 0.9199 0.8900
epoch 700 LossPred 0.1622 LossAtt 0.2607 TrainAcc 0.9600 TestAcc 0.9477 0.9450
epoch 800 LossPred 0.2506 LossAtt 0.2566 TrainAcc 0.9100 TestAcc 0.9042 0.9000
epoch 900 LossPred 0.1772 LossAtt 0.2662 TrainAcc 0.9400 TestAcc 0.9172 0.9300
epoch 1000 LossPred 0.3807 LossAtt 0.2945 TrainAcc 0.8700 TestAcc 0.8221 0.8650
epoch 1100 LossPred 0.3066 LossAtt 0.2561 TrainAcc 0.9000 TestAcc 0.8729 0.8950
epoch 1200 LossPred 0.2687 LossAtt 0.2554 TrainAcc 0.9000 TestAcc 0.8934 0.9050
epoch 1300 LossPred 0.2597 LossAtt 0.2439 TrainAcc 0.9100 TestAcc 0.9122 0.9000
epoch 1400 LossPred 0.3073 LossAtt 0.2388 TrainAcc 0.9100 TestAcc 0.8734 0.8950
epoch 1500 LossPred 0.3347 LossAtt 0.2517 TrainAcc 0.9100 TestAcc 0.8636 0.9000
epoch 1600 LossPred 0.3650 LossAtt 0.2419 TrainAcc 0.8900 TestAcc 0.8669 0.8850
epoch 1700 LossPred 0.2190 LossAtt 0.2486 TrainAcc 0.9100 TestAcc 0.9039 0.9250
epoch 1800 LossPred 0.2872 LossAtt 0.2567 TrainAcc 0.9100 TestAcc 0.8736 0.9050
epoch 1900 LossPred 0.2165 LossAtt 0.2423 TrainAcc 0.9500 TestAcc 0.8996 0.9150
epoch 2000 LossPred 0.2902 LossAtt 0.2394 TrainAcc 0.9300 TestAcc 0.8786 0.9150
epoch 2100 LossPred 0.3264 LossAtt 0.2445 TrainAcc 0.9000 TestAcc 0.8624 0.9050
epoch 2200 LossPred 0.1739 LossAtt 0.2322 TrainAcc 0.9300 TestAcc 0.9264 0.9200
epoch 2300 LossPred 0.1719 LossAtt 0.2344 TrainAcc 0.9300 TestAcc 0.9239 0.9200
epoch 2400 LossPred 0.1369 LossAtt 0.2309 TrainAcc 0.9400 TestAcc 0.9427 0.9350
epoch 2500 LossPred 0.1413 LossAtt 0.2408 TrainAcc 0.9500 TestAcc 0.9299 0.9350
Optimization Finished!
********** replication  36  **********
epoch   0 LossPred 1.0300 LossAtt 1.0314 TrainAcc 0.4100 TestAcc 0.5025 0.4750
epoch 100 LossPred 0.8315 LossAtt 0.2539 TrainAcc 0.6900 TestAcc 0.5988 0.6900
epoch 200 LossPred 0.7529 LossAtt 0.2381 TrainAcc 0.7500 TestAcc 0.6587 0.7500
epoch 300 LossPred 0.2405 LossAtt 0.2190 TrainAcc 0.9400 TestAcc 0.9174 0.9200
epoch 400 LossPred 0.1642 LossAtt 0.2043 TrainAcc 0.9500 TestAcc 0.9349 0.9450
epoch 500 LossPred 0.3519 LossAtt 0.1810 TrainAcc 0.8800 TestAcc 0.8468 0.8950
epoch 600 LossPred 0.1248 LossAtt 0.1699 TrainAcc 0.9700 TestAcc 0.9492 0.9700
epoch 700 LossPred 0.1422 LossAtt 0.1637 TrainAcc 0.9700 TestAcc 0.9477 0.9650
epoch 800 LossPred 0.3056 LossAtt 0.1450 TrainAcc 0.8800 TestAcc 0.8594 0.8850
epoch 900 LossPred 0.2590 LossAtt 0.1840 TrainAcc 0.9300 TestAcc 0.8911 0.9200
epoch 1000 LossPred 0.1890 LossAtt 0.1972 TrainAcc 0.9200 TestAcc 0.9117 0.9450
epoch 1100 LossPred 0.0861 LossAtt 0.1915 TrainAcc 0.9700 TestAcc 0.9687 0.9700
epoch 1200 LossPred 0.0618 LossAtt 0.1832 TrainAcc 0.9800 TestAcc 0.9672 0.9750
epoch 1300 LossPred 0.0745 LossAtt 0.1814 TrainAcc 0.9800 TestAcc 0.9557 0.9750
epoch 1400 LossPred 0.1844 LossAtt 0.1686 TrainAcc 0.9400 TestAcc 0.9057 0.9400
epoch 1500 LossPred 0.4083 LossAtt 0.1757 TrainAcc 0.8800 TestAcc 0.8336 0.8800
epoch 1600 LossPred 0.0626 LossAtt 0.1886 TrainAcc 0.9800 TestAcc 0.9542 0.9750
epoch 1700 LossPred 0.0605 LossAtt 0.1836 TrainAcc 0.9800 TestAcc 0.9657 0.9850
epoch 1800 LossPred 0.0848 LossAtt 0.1863 TrainAcc 0.9700 TestAcc 0.9512 0.9800
epoch 1900 LossPred 0.0739 LossAtt 0.1844 TrainAcc 0.9600 TestAcc 0.9464 0.9800
epoch 2000 LossPred 0.0359 LossAtt 0.1872 TrainAcc 0.9900 TestAcc 0.9657 0.9850
epoch 2100 LossPred 0.1960 LossAtt 0.1904 TrainAcc 0.9400 TestAcc 0.9229 0.9550
epoch 2200 LossPred 0.0465 LossAtt 0.1954 TrainAcc 0.9900 TestAcc 0.9512 0.9800
epoch 2300 LossPred 0.0999 LossAtt 0.1874 TrainAcc 0.9700 TestAcc 0.9454 0.9700
epoch 2400 LossPred 0.0742 LossAtt 0.1910 TrainAcc 0.9700 TestAcc 0.9339 0.9750
epoch 2500 LossPred 0.0671 LossAtt 0.1965 TrainAcc 0.9800 TestAcc 0.9434 0.9800
Optimization Finished!
********** replication  37  **********
epoch   0 LossPred 0.9930 LossAtt 1.0162 TrainAcc 0.5300 TestAcc 0.5408 0.5500
epoch 100 LossPred 0.9627 LossAtt 0.2962 TrainAcc 0.5700 TestAcc 0.6111 0.5300
epoch 200 LossPred 0.3657 LossAtt 0.2703 TrainAcc 0.9100 TestAcc 0.8353 0.8700
epoch 300 LossPred 0.3083 LossAtt 0.2383 TrainAcc 0.9200 TestAcc 0.8804 0.9050
epoch 400 LossPred 0.2777 LossAtt 0.2216 TrainAcc 0.9400 TestAcc 0.8841 0.9100
epoch 500 LossPred 0.2337 LossAtt 0.2164 TrainAcc 0.9300 TestAcc 0.8661 0.8900
epoch 600 LossPred 0.3810 LossAtt 0.2255 TrainAcc 0.8900 TestAcc 0.8243 0.8600
epoch 700 LossPred 0.1946 LossAtt 0.2207 TrainAcc 0.9400 TestAcc 0.8796 0.8950
epoch 800 LossPred 0.2565 LossAtt 0.2211 TrainAcc 0.9300 TestAcc 0.8719 0.9000
epoch 900 LossPred 0.2405 LossAtt 0.2093 TrainAcc 0.9300 TestAcc 0.8894 0.9200
epoch 1000 LossPred 0.2004 LossAtt 0.2073 TrainAcc 0.9500 TestAcc 0.9024 0.9200
epoch 1100 LossPred 0.5110 LossAtt 0.2041 TrainAcc 0.8500 TestAcc 0.7995 0.8450
epoch 1200 LossPred 0.4235 LossAtt 0.2061 TrainAcc 0.8600 TestAcc 0.8228 0.8400
epoch 1300 LossPred 0.2139 LossAtt 0.1960 TrainAcc 0.9200 TestAcc 0.8926 0.9250
epoch 1400 LossPred 0.2255 LossAtt 0.1852 TrainAcc 0.9300 TestAcc 0.8994 0.9300
epoch 1500 LossPred 0.2221 LossAtt 0.1912 TrainAcc 0.9400 TestAcc 0.9044 0.9300
epoch 1600 LossPred 0.1874 LossAtt 0.1834 TrainAcc 0.9400 TestAcc 0.8909 0.9450
epoch 1700 LossPred 0.1734 LossAtt 0.1895 TrainAcc 0.9300 TestAcc 0.9114 0.9300
epoch 1800 LossPred 0.3310 LossAtt 0.1984 TrainAcc 0.9000 TestAcc 0.8403 0.8900
epoch 1900 LossPred 0.2325 LossAtt 0.1970 TrainAcc 0.9300 TestAcc 0.8971 0.9350
epoch 2000 LossPred 0.1581 LossAtt 0.1850 TrainAcc 0.9500 TestAcc 0.9189 0.9600
epoch 2100 LossPred 0.1200 LossAtt 0.1786 TrainAcc 0.9800 TestAcc 0.9172 0.9850
epoch 2200 LossPred 0.1683 LossAtt 0.1776 TrainAcc 0.9600 TestAcc 0.9189 0.9650
epoch 2300 LossPred 0.1071 LossAtt 0.1779 TrainAcc 0.9700 TestAcc 0.9234 0.9800
epoch 2400 LossPred 0.2839 LossAtt 0.1791 TrainAcc 0.9100 TestAcc 0.8649 0.9100
epoch 2500 LossPred 0.1387 LossAtt 0.1847 TrainAcc 0.9700 TestAcc 0.9202 0.9700
Optimization Finished!
********** replication  38  **********
epoch   0 LossPred 1.0495 LossAtt 1.0056 TrainAcc 0.5200 TestAcc 0.5883 0.5400
epoch 100 LossPred 0.8919 LossAtt 0.2213 TrainAcc 0.6500 TestAcc 0.6084 0.6500
epoch 200 LossPred 0.7858 LossAtt 0.2046 TrainAcc 0.7100 TestAcc 0.7125 0.7100
epoch 300 LossPred 0.5514 LossAtt 0.1880 TrainAcc 0.7900 TestAcc 0.8083 0.8050
epoch 400 LossPred 0.3784 LossAtt 0.1840 TrainAcc 0.8600 TestAcc 0.8611 0.8600
epoch 500 LossPred 0.3731 LossAtt 0.1902 TrainAcc 0.8600 TestAcc 0.8576 0.8650
epoch 600 LossPred 0.3411 LossAtt 0.2055 TrainAcc 0.8800 TestAcc 0.8579 0.8650
epoch 700 LossPred 0.2745 LossAtt 0.2163 TrainAcc 0.8900 TestAcc 0.8754 0.8850
epoch 800 LossPred 0.1939 LossAtt 0.2251 TrainAcc 0.9400 TestAcc 0.8981 0.9200
epoch 900 LossPred 0.3213 LossAtt 0.2417 TrainAcc 0.9000 TestAcc 0.8626 0.8700
epoch 1000 LossPred 0.3239 LossAtt 0.2386 TrainAcc 0.8800 TestAcc 0.8594 0.8700
epoch 1100 LossPred 0.1972 LossAtt 0.2357 TrainAcc 0.9400 TestAcc 0.9074 0.9250
epoch 1200 LossPred 0.1792 LossAtt 0.2361 TrainAcc 0.9400 TestAcc 0.8951 0.9400
epoch 1300 LossPred 0.2212 LossAtt 0.2334 TrainAcc 0.9400 TestAcc 0.8854 0.9350
epoch 1400 LossPred 0.1728 LossAtt 0.2211 TrainAcc 0.9500 TestAcc 0.9014 0.9400
epoch 1500 LossPred 0.1776 LossAtt 0.2241 TrainAcc 0.9500 TestAcc 0.8866 0.9200
epoch 1600 LossPred 0.1755 LossAtt 0.2136 TrainAcc 0.9500 TestAcc 0.8949 0.9350
epoch 1700 LossPred 0.2663 LossAtt 0.2025 TrainAcc 0.9000 TestAcc 0.8751 0.9050
epoch 1800 LossPred 0.2624 LossAtt 0.1934 TrainAcc 0.9000 TestAcc 0.8769 0.9000
epoch 1900 LossPred 0.1851 LossAtt 0.2058 TrainAcc 0.9500 TestAcc 0.8916 0.9400
epoch 2000 LossPred 0.3739 LossAtt 0.1898 TrainAcc 0.8800 TestAcc 0.8576 0.8800
epoch 2100 LossPred 0.1690 LossAtt 0.1893 TrainAcc 0.9500 TestAcc 0.8986 0.9350
epoch 2200 LossPred 0.1687 LossAtt 0.1933 TrainAcc 0.9400 TestAcc 0.8979 0.9300
epoch 2300 LossPred 0.2335 LossAtt 0.2011 TrainAcc 0.9200 TestAcc 0.9017 0.9250
epoch 2400 LossPred 0.1576 LossAtt 0.1990 TrainAcc 0.9500 TestAcc 0.9007 0.9350
epoch 2500 LossPred 0.1483 LossAtt 0.1935 TrainAcc 0.9600 TestAcc 0.9047 0.9500
Optimization Finished!
********** replication  39  **********
epoch   0 LossPred 1.0640 LossAtt 1.0008 TrainAcc 0.3800 TestAcc 0.4857 0.4050
epoch 100 LossPred 0.8165 LossAtt 0.2425 TrainAcc 0.7000 TestAcc 0.5968 0.7000
epoch 200 LossPred 0.5324 LossAtt 0.2775 TrainAcc 0.8300 TestAcc 0.7470 0.8250
epoch 300 LossPred 0.2186 LossAtt 0.2634 TrainAcc 0.9200 TestAcc 0.8511 0.9200
epoch 400 LossPred 0.1515 LossAtt 0.2475 TrainAcc 0.9700 TestAcc 0.8789 0.9400
epoch 500 LossPred 0.5502 LossAtt 0.3116 TrainAcc 0.8200 TestAcc 0.8121 0.8300
epoch 600 LossPred 0.3634 LossAtt 0.2745 TrainAcc 0.8700 TestAcc 0.8481 0.8600
epoch 700 LossPred 0.2899 LossAtt 0.2386 TrainAcc 0.8900 TestAcc 0.8086 0.8750
epoch 800 LossPred 0.1476 LossAtt 0.2407 TrainAcc 0.9400 TestAcc 0.8579 0.9400
epoch 900 LossPred 0.1148 LossAtt 0.2256 TrainAcc 0.9600 TestAcc 0.8656 0.9550
epoch 1000 LossPred 0.1031 LossAtt 0.2115 TrainAcc 0.9600 TestAcc 0.8619 0.9500
epoch 1100 LossPred 0.0898 LossAtt 0.2147 TrainAcc 0.9800 TestAcc 0.8924 0.9450
epoch 1200 LossPred 0.0795 LossAtt 0.2039 TrainAcc 0.9900 TestAcc 0.8941 0.9550
epoch 1300 LossPred 0.0670 LossAtt 0.2100 TrainAcc 0.9800 TestAcc 0.8736 0.9600
epoch 1400 LossPred 0.0661 LossAtt 0.2089 TrainAcc 0.9700 TestAcc 0.8739 0.9650
epoch 1500 LossPred 0.0701 LossAtt 0.2002 TrainAcc 0.9800 TestAcc 0.8689 0.9700
epoch 1600 LossPred 0.0547 LossAtt 0.2018 TrainAcc 0.9800 TestAcc 0.8804 0.9750
epoch 1700 LossPred 0.0615 LossAtt 0.1898 TrainAcc 1.0000 TestAcc 0.8846 0.9750
Optimization Finished!
********** replication  40  **********
epoch   0 LossPred 1.2298 LossAtt 0.9855 TrainAcc 0.5600 TestAcc 0.5100 0.5200
epoch 100 LossPred 0.7935 LossAtt 0.3386 TrainAcc 0.7500 TestAcc 0.6614 0.7500
epoch 200 LossPred 0.2856 LossAtt 0.3204 TrainAcc 0.9200 TestAcc 0.9004 0.8700
epoch 300 LossPred 0.3918 LossAtt 0.2902 TrainAcc 0.8800 TestAcc 0.8238 0.8450
epoch 400 LossPred 0.1968 LossAtt 0.2466 TrainAcc 0.9300 TestAcc 0.9334 0.9200
epoch 500 LossPred 0.3163 LossAtt 0.2150 TrainAcc 0.8700 TestAcc 0.8544 0.8800
epoch 600 LossPred 0.1880 LossAtt 0.1979 TrainAcc 0.9500 TestAcc 0.9389 0.9400
epoch 700 LossPred 0.1984 LossAtt 0.1902 TrainAcc 0.9200 TestAcc 0.9099 0.9200
epoch 800 LossPred 0.4573 LossAtt 0.1791 TrainAcc 0.8400 TestAcc 0.8466 0.8450
epoch 900 LossPred 0.2179 LossAtt 0.1814 TrainAcc 0.9300 TestAcc 0.9234 0.9250
epoch 1000 LossPred 0.2971 LossAtt 0.1783 TrainAcc 0.8800 TestAcc 0.8641 0.8950
epoch 1100 LossPred 0.3210 LossAtt 0.1823 TrainAcc 0.8900 TestAcc 0.8639 0.8850
epoch 1200 LossPred 0.1943 LossAtt 0.1866 TrainAcc 0.9300 TestAcc 0.9297 0.9350
epoch 1300 LossPred 0.2930 LossAtt 0.1822 TrainAcc 0.9000 TestAcc 0.8886 0.8900
epoch 1400 LossPred 0.4194 LossAtt 0.1673 TrainAcc 0.8500 TestAcc 0.8524 0.8550
epoch 1500 LossPred 0.2740 LossAtt 0.1719 TrainAcc 0.9100 TestAcc 0.8941 0.8750
epoch 1600 LossPred 0.2908 LossAtt 0.1634 TrainAcc 0.9000 TestAcc 0.8829 0.8750
epoch 1700 LossPred 0.3806 LossAtt 0.1675 TrainAcc 0.8500 TestAcc 0.8556 0.8600
epoch 1800 LossPred 0.2355 LossAtt 0.1724 TrainAcc 0.9300 TestAcc 0.9072 0.9000
epoch 1900 LossPred 0.3212 LossAtt 0.1703 TrainAcc 0.9000 TestAcc 0.8781 0.8850
epoch 2000 LossPred 0.3161 LossAtt 0.1581 TrainAcc 0.8800 TestAcc 0.8816 0.8950
epoch 2100 LossPred 0.1816 LossAtt 0.1623 TrainAcc 0.9300 TestAcc 0.9344 0.9300
epoch 2200 LossPred 0.1948 LossAtt 0.1685 TrainAcc 0.9400 TestAcc 0.8974 0.9150
epoch 2300 LossPred 0.1321 LossAtt 0.1724 TrainAcc 0.9600 TestAcc 0.9257 0.9400
epoch 2400 LossPred 0.2723 LossAtt 0.1728 TrainAcc 0.8900 TestAcc 0.8599 0.8800
epoch 2500 LossPred 0.3278 LossAtt 0.1719 TrainAcc 0.8900 TestAcc 0.8524 0.8950
Optimization Finished!
********** replication  41  **********
epoch   0 LossPred 0.9776 LossAtt 1.0007 TrainAcc 0.5800 TestAcc 0.4692 0.5650
epoch 100 LossPred 0.7350 LossAtt 0.3633 TrainAcc 0.7500 TestAcc 0.6852 0.7350
epoch 200 LossPred 0.3943 LossAtt 0.3294 TrainAcc 0.8800 TestAcc 0.8566 0.8600
epoch 300 LossPred 0.2012 LossAtt 0.3317 TrainAcc 0.9400 TestAcc 0.8784 0.8800
epoch 400 LossPred 0.1624 LossAtt 0.3004 TrainAcc 0.9500 TestAcc 0.8924 0.9200
epoch 500 LossPred 0.3263 LossAtt 0.2724 TrainAcc 0.8900 TestAcc 0.8406 0.8650
epoch 600 LossPred 0.2503 LossAtt 0.2630 TrainAcc 0.9100 TestAcc 0.8726 0.9100
epoch 700 LossPred 0.1764 LossAtt 0.2445 TrainAcc 0.9400 TestAcc 0.8761 0.9250
epoch 800 LossPred 0.1796 LossAtt 0.2288 TrainAcc 0.9400 TestAcc 0.8824 0.9450
epoch 900 LossPred 0.2099 LossAtt 0.2311 TrainAcc 0.9300 TestAcc 0.8819 0.9400
epoch 1000 LossPred 0.2363 LossAtt 0.2202 TrainAcc 0.9300 TestAcc 0.8781 0.9200
epoch 1100 LossPred 0.1729 LossAtt 0.2229 TrainAcc 0.9500 TestAcc 0.8849 0.9300
epoch 1200 LossPred 0.2916 LossAtt 0.2223 TrainAcc 0.9000 TestAcc 0.8498 0.8850
epoch 1300 LossPred 0.1884 LossAtt 0.2137 TrainAcc 0.9600 TestAcc 0.8894 0.9450
epoch 1400 LossPred 0.2295 LossAtt 0.1945 TrainAcc 0.9000 TestAcc 0.8711 0.9050
epoch 1500 LossPred 0.1982 LossAtt 0.1960 TrainAcc 0.9300 TestAcc 0.8671 0.9200
epoch 1600 LossPred 0.2257 LossAtt 0.1860 TrainAcc 0.9200 TestAcc 0.8654 0.9250
epoch 1700 LossPred 0.2113 LossAtt 0.1725 TrainAcc 0.9200 TestAcc 0.8524 0.9200
epoch 1800 LossPred 0.2650 LossAtt 0.1876 TrainAcc 0.8900 TestAcc 0.8448 0.8900
epoch 1900 LossPred 0.2171 LossAtt 0.1935 TrainAcc 0.9200 TestAcc 0.8546 0.9050
epoch 2000 LossPred 0.1724 LossAtt 0.1940 TrainAcc 0.9400 TestAcc 0.8589 0.9350
epoch 2100 LossPred 0.1798 LossAtt 0.1901 TrainAcc 0.9300 TestAcc 0.8591 0.9300
epoch 2200 LossPred 0.1747 LossAtt 0.1940 TrainAcc 0.9200 TestAcc 0.8478 0.9300
epoch 2300 LossPred 0.2118 LossAtt 0.1938 TrainAcc 0.9200 TestAcc 0.8471 0.9100
epoch 2400 LossPred 0.2824 LossAtt 0.1940 TrainAcc 0.9000 TestAcc 0.8341 0.9100
epoch 2500 LossPred 0.3289 LossAtt 0.1936 TrainAcc 0.8800 TestAcc 0.8183 0.8800
Optimization Finished!
********** replication  42  **********
epoch   0 LossPred 1.0483 LossAtt 1.0100 TrainAcc 0.4200 TestAcc 0.4237 0.4400
epoch 100 LossPred 0.9193 LossAtt 0.2866 TrainAcc 0.6200 TestAcc 0.6139 0.6050
epoch 200 LossPred 0.8389 LossAtt 0.2370 TrainAcc 0.6700 TestAcc 0.6799 0.6700
epoch 300 LossPred 0.3322 LossAtt 0.2592 TrainAcc 0.9100 TestAcc 0.8851 0.8600
epoch 400 LossPred 0.2107 LossAtt 0.2717 TrainAcc 0.9300 TestAcc 0.9217 0.9250
epoch 500 LossPred 0.2005 LossAtt 0.2687 TrainAcc 0.9300 TestAcc 0.9089 0.9300
epoch 600 LossPred 0.2473 LossAtt 0.2797 TrainAcc 0.9300 TestAcc 0.8949 0.9200
epoch 700 LossPred 0.2437 LossAtt 0.2578 TrainAcc 0.9400 TestAcc 0.8874 0.9300
epoch 800 LossPred 0.2051 LossAtt 0.2431 TrainAcc 0.9400 TestAcc 0.9034 0.9300
epoch 900 LossPred 0.1484 LossAtt 0.2153 TrainAcc 0.9500 TestAcc 0.9204 0.9250
epoch 1000 LossPred 0.2685 LossAtt 0.1925 TrainAcc 0.9000 TestAcc 0.8936 0.8850
epoch 1100 LossPred 0.1534 LossAtt 0.2093 TrainAcc 0.9500 TestAcc 0.9309 0.9300
epoch 1200 LossPred 0.1012 LossAtt 0.1978 TrainAcc 0.9800 TestAcc 0.9282 0.9650
epoch 1300 LossPred 0.2673 LossAtt 0.2056 TrainAcc 0.9200 TestAcc 0.8886 0.9250
epoch 1400 LossPred 0.4873 LossAtt 0.2057 TrainAcc 0.8400 TestAcc 0.8128 0.8200
epoch 1500 LossPred 0.1506 LossAtt 0.2055 TrainAcc 0.9600 TestAcc 0.9222 0.9550
epoch 1600 LossPred 0.1700 LossAtt 0.1957 TrainAcc 0.9400 TestAcc 0.9214 0.9400
epoch 1700 LossPred 0.1104 LossAtt 0.1947 TrainAcc 0.9600 TestAcc 0.9212 0.9600
epoch 1800 LossPred 0.2135 LossAtt 0.1777 TrainAcc 0.9500 TestAcc 0.8989 0.9350
epoch 1900 LossPred 0.1094 LossAtt 0.1835 TrainAcc 0.9600 TestAcc 0.9444 0.9550
epoch 2000 LossPred 0.1110 LossAtt 0.1747 TrainAcc 0.9600 TestAcc 0.9464 0.9600
epoch 2100 LossPred 0.1202 LossAtt 0.1753 TrainAcc 0.9700 TestAcc 0.9454 0.9550
epoch 2200 LossPred 0.1418 LossAtt 0.1775 TrainAcc 0.9500 TestAcc 0.9247 0.9450
epoch 2300 LossPred 0.1070 LossAtt 0.1716 TrainAcc 0.9500 TestAcc 0.9337 0.9500
epoch 2400 LossPred 0.1043 LossAtt 0.1702 TrainAcc 0.9600 TestAcc 0.9362 0.9550
epoch 2500 LossPred 0.1128 LossAtt 0.1703 TrainAcc 0.9500 TestAcc 0.9292 0.9550
Optimization Finished!
********** replication  43  **********
epoch   0 LossPred 1.0848 LossAtt 1.0364 TrainAcc 0.4400 TestAcc 0.3889 0.4350
epoch 100 LossPred 0.9659 LossAtt 0.2332 TrainAcc 0.5600 TestAcc 0.6111 0.5600
epoch 200 LossPred 0.9511 LossAtt 0.2254 TrainAcc 0.5900 TestAcc 0.5711 0.5900
epoch 300 LossPred 0.9236 LossAtt 0.2296 TrainAcc 0.5900 TestAcc 0.5706 0.5900
epoch 400 LossPred 0.6512 LossAtt 0.2902 TrainAcc 0.7600 TestAcc 0.8018 0.7900
epoch 500 LossPred 0.4242 LossAtt 0.2368 TrainAcc 0.8800 TestAcc 0.8991 0.8650
epoch 600 LossPred 0.3219 LossAtt 0.2169 TrainAcc 0.9200 TestAcc 0.9179 0.8900
epoch 700 LossPred 0.4577 LossAtt 0.2140 TrainAcc 0.8500 TestAcc 0.8736 0.8350
epoch 800 LossPred 0.2589 LossAtt 0.2130 TrainAcc 0.9200 TestAcc 0.9262 0.9050
epoch 900 LossPred 0.5015 LossAtt 0.2132 TrainAcc 0.8400 TestAcc 0.8333 0.8050
epoch 1000 LossPred 0.2191 LossAtt 0.2219 TrainAcc 0.9400 TestAcc 0.9384 0.9350
epoch 1100 LossPred 0.4248 LossAtt 0.2186 TrainAcc 0.8500 TestAcc 0.8796 0.8550
epoch 1200 LossPred 0.2047 LossAtt 0.2031 TrainAcc 0.9300 TestAcc 0.9409 0.9450
epoch 1300 LossPred 0.1586 LossAtt 0.1993 TrainAcc 0.9400 TestAcc 0.9439 0.9550
epoch 1400 LossPred 0.1573 LossAtt 0.1932 TrainAcc 0.9400 TestAcc 0.9449 0.9600
epoch 1500 LossPred 0.1519 LossAtt 0.1932 TrainAcc 0.9500 TestAcc 0.9479 0.9550
epoch 1600 LossPred 0.5250 LossAtt 0.2032 TrainAcc 0.8400 TestAcc 0.8529 0.8500
epoch 1700 LossPred 0.1788 LossAtt 0.1997 TrainAcc 0.9400 TestAcc 0.9472 0.9550
epoch 1800 LossPred 0.2469 LossAtt 0.2024 TrainAcc 0.9200 TestAcc 0.9347 0.9250
epoch 1900 LossPred 0.2566 LossAtt 0.2036 TrainAcc 0.9000 TestAcc 0.9247 0.9200
epoch 2000 LossPred 0.0707 LossAtt 0.1908 TrainAcc 0.9900 TestAcc 0.9580 0.9700
epoch 2100 LossPred 0.1233 LossAtt 0.2075 TrainAcc 0.9700 TestAcc 0.9439 0.9650
epoch 2200 LossPred 0.0781 LossAtt 0.1899 TrainAcc 0.9900 TestAcc 0.9547 0.9700
epoch 2300 LossPred 0.1353 LossAtt 0.1849 TrainAcc 0.9600 TestAcc 0.9464 0.9650
epoch 2400 LossPred 0.1393 LossAtt 0.1875 TrainAcc 0.9400 TestAcc 0.9414 0.9300
epoch 2500 LossPred 0.0672 LossAtt 0.1887 TrainAcc 0.9700 TestAcc 0.9615 0.9600
Optimization Finished!
********** replication  44  **********
epoch   0 LossPred 1.2366 LossAtt 0.9867 TrainAcc 0.3900 TestAcc 0.3934 0.3950
epoch 100 LossPred 0.8660 LossAtt 0.3111 TrainAcc 0.6700 TestAcc 0.6004 0.6750
epoch 200 LossPred 0.8410 LossAtt 0.2580 TrainAcc 0.6700 TestAcc 0.5716 0.6900
epoch 300 LossPred 0.8310 LossAtt 0.2511 TrainAcc 0.6800 TestAcc 0.5908 0.6750
epoch 400 LossPred 0.7982 LossAtt 0.2721 TrainAcc 0.7000 TestAcc 0.6234 0.7150
epoch 500 LossPred 0.3908 LossAtt 0.3274 TrainAcc 0.8900 TestAcc 0.8539 0.8800
epoch 600 LossPred 0.2437 LossAtt 0.3266 TrainAcc 0.9300 TestAcc 0.8749 0.9200
epoch 700 LossPred 0.1748 LossAtt 0.3219 TrainAcc 0.9600 TestAcc 0.8726 0.9500
epoch 800 LossPred 0.1750 LossAtt 0.3187 TrainAcc 0.9700 TestAcc 0.8706 0.9250
epoch 900 LossPred 0.1527 LossAtt 0.2921 TrainAcc 0.9700 TestAcc 0.8544 0.9350
epoch 1000 LossPred 0.1152 LossAtt 0.3142 TrainAcc 0.9700 TestAcc 0.8611 0.9450
epoch 1100 LossPred 0.1672 LossAtt 0.2965 TrainAcc 0.9600 TestAcc 0.8426 0.9400
epoch 1200 LossPred 0.1748 LossAtt 0.3086 TrainAcc 0.9400 TestAcc 0.8574 0.9150
epoch 1300 LossPred 0.1755 LossAtt 0.2808 TrainAcc 0.9600 TestAcc 0.8496 0.9350
epoch 1400 LossPred 0.1870 LossAtt 0.2798 TrainAcc 0.9500 TestAcc 0.8388 0.9400
epoch 1500 LossPred 0.0734 LossAtt 0.2764 TrainAcc 0.9900 TestAcc 0.8546 0.9400
epoch 1600 LossPred 0.0887 LossAtt 0.2639 TrainAcc 0.9700 TestAcc 0.8719 0.9450
epoch 1700 LossPred 0.0869 LossAtt 0.2650 TrainAcc 0.9700 TestAcc 0.8646 0.9500
epoch 1800 LossPred 0.0960 LossAtt 0.2692 TrainAcc 0.9800 TestAcc 0.8589 0.9350
epoch 1900 LossPred 0.0766 LossAtt 0.2562 TrainAcc 0.9800 TestAcc 0.8651 0.9450
epoch 2000 LossPred 0.0663 LossAtt 0.2587 TrainAcc 0.9800 TestAcc 0.8674 0.9550
epoch 2100 LossPred 0.0680 LossAtt 0.2515 TrainAcc 0.9800 TestAcc 0.8599 0.9550
epoch 2200 LossPred 0.0531 LossAtt 0.2547 TrainAcc 0.9900 TestAcc 0.8654 0.9600
epoch 2300 LossPred 0.0493 LossAtt 0.2615 TrainAcc 0.9900 TestAcc 0.8611 0.9600
epoch 2400 LossPred 0.0389 LossAtt 0.2555 TrainAcc 1.0000 TestAcc 0.8631 0.9750
Optimization Finished!
********** replication  45  **********
epoch   0 LossPred 1.1037 LossAtt 1.0167 TrainAcc 0.4700 TestAcc 0.4497 0.4350
epoch 100 LossPred 0.9103 LossAtt 0.2670 TrainAcc 0.6300 TestAcc 0.6236 0.6150
epoch 200 LossPred 0.4932 LossAtt 0.2505 TrainAcc 0.8300 TestAcc 0.8516 0.7950
epoch 300 LossPred 0.4085 LossAtt 0.1858 TrainAcc 0.8800 TestAcc 0.8994 0.8150
epoch 400 LossPred 0.3676 LossAtt 0.1799 TrainAcc 0.8800 TestAcc 0.9152 0.8350
epoch 500 LossPred 0.2311 LossAtt 0.2142 TrainAcc 0.9100 TestAcc 0.9039 0.9200
epoch 600 LossPred 0.2367 LossAtt 0.2232 TrainAcc 0.9300 TestAcc 0.9232 0.9100
epoch 700 LossPred 0.0950 LossAtt 0.2093 TrainAcc 0.9900 TestAcc 0.9622 0.9700
epoch 800 LossPred 0.1321 LossAtt 0.1938 TrainAcc 0.9500 TestAcc 0.9349 0.9450
epoch 900 LossPred 0.0788 LossAtt 0.1947 TrainAcc 0.9900 TestAcc 0.9705 0.9550
epoch 1000 LossPred 0.0927 LossAtt 0.1755 TrainAcc 0.9700 TestAcc 0.9542 0.9750
epoch 1100 LossPred 0.1028 LossAtt 0.1865 TrainAcc 0.9800 TestAcc 0.9484 0.9650
epoch 1200 LossPred 0.1023 LossAtt 0.1864 TrainAcc 0.9800 TestAcc 0.9552 0.9650
epoch 1300 LossPred 0.1065 LossAtt 0.1728 TrainAcc 0.9700 TestAcc 0.9572 0.9650
epoch 1400 LossPred 0.1605 LossAtt 0.1758 TrainAcc 0.9500 TestAcc 0.9342 0.9350
epoch 1500 LossPred 0.1583 LossAtt 0.1696 TrainAcc 0.9600 TestAcc 0.9184 0.9500
epoch 1600 LossPred 0.0896 LossAtt 0.1565 TrainAcc 0.9700 TestAcc 0.9494 0.9700
epoch 1700 LossPred 0.1387 LossAtt 0.1377 TrainAcc 0.9600 TestAcc 0.9374 0.9450
epoch 1800 LossPred 0.1814 LossAtt 0.1396 TrainAcc 0.9600 TestAcc 0.9104 0.9400
epoch 1900 LossPred 0.0904 LossAtt 0.1379 TrainAcc 0.9700 TestAcc 0.9407 0.9700
epoch 2000 LossPred 0.1028 LossAtt 0.1477 TrainAcc 0.9700 TestAcc 0.9277 0.9650
epoch 2100 LossPred 0.0848 LossAtt 0.1385 TrainAcc 0.9800 TestAcc 0.9474 0.9650
epoch 2200 LossPred 0.1887 LossAtt 0.1405 TrainAcc 0.9400 TestAcc 0.9184 0.9400
epoch 2300 LossPred 0.0960 LossAtt 0.1598 TrainAcc 0.9800 TestAcc 0.9434 0.9750
epoch 2400 LossPred 0.1729 LossAtt 0.1437 TrainAcc 0.9600 TestAcc 0.9257 0.9450
epoch 2500 LossPred 0.0739 LossAtt 0.1587 TrainAcc 0.9900 TestAcc 0.9625 0.9900
Optimization Finished!
********** replication  46  **********
epoch   0 LossPred 1.2567 LossAtt 1.0050 TrainAcc 0.4300 TestAcc 0.4462 0.4450
epoch 100 LossPred 0.9195 LossAtt 0.2369 TrainAcc 0.6400 TestAcc 0.6001 0.6200
epoch 200 LossPred 0.8559 LossAtt 0.1987 TrainAcc 0.6700 TestAcc 0.6189 0.6500
epoch 300 LossPred 0.4232 LossAtt 0.2080 TrainAcc 0.8500 TestAcc 0.8113 0.8600
epoch 400 LossPred 0.2877 LossAtt 0.2042 TrainAcc 0.9000 TestAcc 0.8448 0.8750
epoch 500 LossPred 0.3030 LossAtt 0.1958 TrainAcc 0.9000 TestAcc 0.8371 0.8950
epoch 600 LossPred 0.3698 LossAtt 0.1939 TrainAcc 0.8600 TestAcc 0.8238 0.8550
epoch 700 LossPred 0.2949 LossAtt 0.1933 TrainAcc 0.9000 TestAcc 0.8326 0.8750
epoch 800 LossPred 0.3169 LossAtt 0.1888 TrainAcc 0.8900 TestAcc 0.8524 0.8800
epoch 900 LossPred 0.2328 LossAtt 0.1947 TrainAcc 0.9200 TestAcc 0.8536 0.9000
epoch 1000 LossPred 0.2301 LossAtt 0.1928 TrainAcc 0.9400 TestAcc 0.8691 0.8900
epoch 1100 LossPred 0.2042 LossAtt 0.1985 TrainAcc 0.9400 TestAcc 0.8629 0.8900
epoch 1200 LossPred 0.1995 LossAtt 0.1838 TrainAcc 0.9500 TestAcc 0.8819 0.9000
epoch 1300 LossPred 0.1807 LossAtt 0.2023 TrainAcc 0.9500 TestAcc 0.8636 0.9000
epoch 1400 LossPred 0.1573 LossAtt 0.2158 TrainAcc 0.9500 TestAcc 0.8751 0.9250
epoch 1500 LossPred 0.1631 LossAtt 0.2134 TrainAcc 0.9600 TestAcc 0.8876 0.9150
epoch 1600 LossPred 0.1612 LossAtt 0.2171 TrainAcc 0.9600 TestAcc 0.8816 0.9350
epoch 1700 LossPred 0.1669 LossAtt 0.2231 TrainAcc 0.9600 TestAcc 0.8796 0.9250
epoch 1800 LossPred 0.1444 LossAtt 0.2071 TrainAcc 0.9700 TestAcc 0.8866 0.9250
epoch 1900 LossPred 0.1393 LossAtt 0.2182 TrainAcc 0.9700 TestAcc 0.8881 0.9300
epoch 2000 LossPred 0.1580 LossAtt 0.2126 TrainAcc 0.9600 TestAcc 0.8804 0.9100
epoch 2100 LossPred 0.1380 LossAtt 0.2109 TrainAcc 0.9700 TestAcc 0.8789 0.9150
epoch 2200 LossPred 0.1302 LossAtt 0.2171 TrainAcc 0.9700 TestAcc 0.8801 0.9150
epoch 2300 LossPred 0.1218 LossAtt 0.2091 TrainAcc 0.9700 TestAcc 0.8734 0.9200
epoch 2400 LossPred 0.2249 LossAtt 0.2234 TrainAcc 0.9200 TestAcc 0.8546 0.9050
epoch 2500 LossPred 0.1216 LossAtt 0.2158 TrainAcc 0.9700 TestAcc 0.8741 0.9300
Optimization Finished!
********** replication  47  **********
epoch   0 LossPred 1.2276 LossAtt 1.0118 TrainAcc 0.4400 TestAcc 0.4434 0.4300
epoch 100 LossPred 0.8321 LossAtt 0.2940 TrainAcc 0.7200 TestAcc 0.6029 0.6950
epoch 200 LossPred 0.7827 LossAtt 0.2574 TrainAcc 0.7100 TestAcc 0.6359 0.7050
epoch 300 LossPred 0.7476 LossAtt 0.2856 TrainAcc 0.7200 TestAcc 0.6206 0.7050
epoch 400 LossPred 0.6998 LossAtt 0.3252 TrainAcc 0.7500 TestAcc 0.5521 0.7450
epoch 500 LossPred 0.6180 LossAtt 0.3699 TrainAcc 0.8000 TestAcc 0.5588 0.7650
epoch 600 LossPred 0.5597 LossAtt 0.3390 TrainAcc 0.8100 TestAcc 0.5558 0.7900
epoch 700 LossPred 0.5259 LossAtt 0.3528 TrainAcc 0.8400 TestAcc 0.5598 0.8050
epoch 800 LossPred 0.4937 LossAtt 0.3772 TrainAcc 0.8400 TestAcc 0.5661 0.8100
epoch 900 LossPred 0.4642 LossAtt 0.4034 TrainAcc 0.8400 TestAcc 0.5668 0.8000
epoch 1000 LossPred 0.4243 LossAtt 0.3999 TrainAcc 0.8700 TestAcc 0.5668 0.8250
epoch 1100 LossPred 0.3898 LossAtt 0.4092 TrainAcc 0.8900 TestAcc 0.5686 0.8450
epoch 1200 LossPred 0.3612 LossAtt 0.4269 TrainAcc 0.8900 TestAcc 0.5616 0.8600
epoch 1300 LossPred 0.3144 LossAtt 0.4297 TrainAcc 0.9300 TestAcc 0.5583 0.8550
epoch 1400 LossPred 0.3223 LossAtt 0.4042 TrainAcc 0.9100 TestAcc 0.5631 0.8950
epoch 1500 LossPred 0.2838 LossAtt 0.3992 TrainAcc 0.9000 TestAcc 0.5611 0.8850
epoch 1600 LossPred 0.2621 LossAtt 0.3885 TrainAcc 0.9400 TestAcc 0.5536 0.8600
epoch 1700 LossPred 0.2355 LossAtt 0.4094 TrainAcc 0.9500 TestAcc 0.5611 0.8950
epoch 1800 LossPred 0.2577 LossAtt 0.4061 TrainAcc 0.9400 TestAcc 0.5613 0.8950
epoch 1900 LossPred 0.2222 LossAtt 0.4089 TrainAcc 0.9500 TestAcc 0.5583 0.8800
epoch 2000 LossPred 0.2558 LossAtt 0.3986 TrainAcc 0.9400 TestAcc 0.5578 0.8600
epoch 2100 LossPred 0.2224 LossAtt 0.4139 TrainAcc 0.9600 TestAcc 0.5566 0.8900
epoch 2200 LossPred 0.2286 LossAtt 0.3948 TrainAcc 0.9500 TestAcc 0.5608 0.8800
epoch 2300 LossPred 0.2137 LossAtt 0.4093 TrainAcc 0.9500 TestAcc 0.5563 0.8800
epoch 2400 LossPred 0.2130 LossAtt 0.4111 TrainAcc 0.9500 TestAcc 0.5613 0.8700
epoch 2500 LossPred 0.2055 LossAtt 0.4200 TrainAcc 0.9600 TestAcc 0.5518 0.8700
Optimization Finished!
********** replication  48  **********
epoch   0 LossPred 1.0126 LossAtt 1.0147 TrainAcc 0.5500 TestAcc 0.5541 0.5550
epoch 100 LossPred 0.3798 LossAtt 0.3080 TrainAcc 0.9400 TestAcc 0.8731 0.9050
epoch 200 LossPred 0.2879 LossAtt 0.2465 TrainAcc 0.9300 TestAcc 0.8876 0.9150
epoch 300 LossPred 0.2882 LossAtt 0.2011 TrainAcc 0.9400 TestAcc 0.8696 0.9000
epoch 400 LossPred 0.3245 LossAtt 0.2082 TrainAcc 0.8900 TestAcc 0.8331 0.8750
epoch 500 LossPred 0.1888 LossAtt 0.2146 TrainAcc 0.9500 TestAcc 0.9032 0.9250
epoch 600 LossPred 0.1467 LossAtt 0.2248 TrainAcc 0.9700 TestAcc 0.9157 0.9400
epoch 700 LossPred 0.4557 LossAtt 0.2283 TrainAcc 0.8200 TestAcc 0.8381 0.8750
epoch 800 LossPred 0.2050 LossAtt 0.2184 TrainAcc 0.9500 TestAcc 0.8974 0.9250
epoch 900 LossPred 0.3221 LossAtt 0.2012 TrainAcc 0.9000 TestAcc 0.8303 0.8850
epoch 1000 LossPred 0.1676 LossAtt 0.2316 TrainAcc 0.9700 TestAcc 0.8956 0.9150
epoch 1100 LossPred 0.1826 LossAtt 0.2117 TrainAcc 0.9400 TestAcc 0.8884 0.9150
epoch 1200 LossPred 0.1096 LossAtt 0.2105 TrainAcc 0.9700 TestAcc 0.9172 0.9350
epoch 1300 LossPred 0.0958 LossAtt 0.1993 TrainAcc 0.9900 TestAcc 0.9242 0.9350
epoch 1400 LossPred 0.0975 LossAtt 0.2093 TrainAcc 0.9800 TestAcc 0.9227 0.9400
epoch 1500 LossPred 0.1777 LossAtt 0.2021 TrainAcc 0.9500 TestAcc 0.8954 0.9250
epoch 1600 LossPred 0.0658 LossAtt 0.1894 TrainAcc 0.9800 TestAcc 0.9242 0.9500
epoch 1700 LossPred 0.0951 LossAtt 0.1985 TrainAcc 0.9700 TestAcc 0.9292 0.9550
epoch 1800 LossPred 0.0736 LossAtt 0.1922 TrainAcc 0.9800 TestAcc 0.9117 0.9600
epoch 1900 LossPred 0.1609 LossAtt 0.1676 TrainAcc 0.9400 TestAcc 0.9122 0.9400
epoch 2000 LossPred 0.1070 LossAtt 0.1623 TrainAcc 0.9700 TestAcc 0.9094 0.9500
epoch 2100 LossPred 0.2586 LossAtt 0.1715 TrainAcc 0.9200 TestAcc 0.8614 0.9100
epoch 2200 LossPred 0.1383 LossAtt 0.1632 TrainAcc 0.9600 TestAcc 0.9124 0.9300
epoch 2300 LossPred 0.3734 LossAtt 0.1507 TrainAcc 0.8900 TestAcc 0.8251 0.8900
epoch 2400 LossPred 0.0921 LossAtt 0.1699 TrainAcc 0.9500 TestAcc 0.9162 0.9600
epoch 2500 LossPred 0.2137 LossAtt 0.1710 TrainAcc 0.9400 TestAcc 0.8824 0.9250
Optimization Finished!
********** replication  49  **********
epoch   0 LossPred 0.9662 LossAtt 0.9976 TrainAcc 0.6100 TestAcc 0.5556 0.6050
epoch 100 LossPred 0.7239 LossAtt 0.3358 TrainAcc 0.7000 TestAcc 0.6069 0.6950
epoch 200 LossPred 0.2317 LossAtt 0.3261 TrainAcc 0.9300 TestAcc 0.8408 0.9300
epoch 300 LossPred 0.1382 LossAtt 0.2946 TrainAcc 0.9600 TestAcc 0.8874 0.9450
epoch 400 LossPred 0.1070 LossAtt 0.2773 TrainAcc 0.9700 TestAcc 0.8836 0.9500
epoch 500 LossPred 0.0883 LossAtt 0.2534 TrainAcc 0.9700 TestAcc 0.8699 0.9450
epoch 600 LossPred 0.0816 LossAtt 0.2520 TrainAcc 0.9800 TestAcc 0.9117 0.9600
epoch 700 LossPred 0.0676 LossAtt 0.2282 TrainAcc 0.9800 TestAcc 0.8721 0.9500
epoch 800 LossPred 0.0503 LossAtt 0.2131 TrainAcc 1.0000 TestAcc 0.9079 0.9750
Optimization Finished!
********** replication  50  **********
epoch   0 LossPred 1.0820 LossAtt 1.0327 TrainAcc 0.5500 TestAcc 0.4702 0.5250
epoch 100 LossPred 0.8379 LossAtt 0.3253 TrainAcc 0.7000 TestAcc 0.6271 0.7150
epoch 200 LossPred 0.3222 LossAtt 0.3359 TrainAcc 0.9200 TestAcc 0.8864 0.8950
epoch 300 LossPred 0.2843 LossAtt 0.3268 TrainAcc 0.9300 TestAcc 0.8976 0.9000
epoch 400 LossPred 0.2335 LossAtt 0.3081 TrainAcc 0.9300 TestAcc 0.8919 0.9200
epoch 500 LossPred 0.1737 LossAtt 0.3061 TrainAcc 0.9700 TestAcc 0.9142 0.9500
epoch 600 LossPred 0.1564 LossAtt 0.2781 TrainAcc 0.9600 TestAcc 0.9204 0.9500
epoch 700 LossPred 0.1993 LossAtt 0.2926 TrainAcc 0.9400 TestAcc 0.8966 0.9400
epoch 800 LossPred 0.1719 LossAtt 0.2846 TrainAcc 0.9400 TestAcc 0.9322 0.9400
epoch 900 LossPred 0.1282 LossAtt 0.2853 TrainAcc 0.9700 TestAcc 0.9287 0.9550
epoch 1000 LossPred 0.0928 LossAtt 0.2945 TrainAcc 0.9900 TestAcc 0.9489 0.9650
epoch 1100 LossPred 0.0861 LossAtt 0.2830 TrainAcc 1.0000 TestAcc 0.9487 0.9800
Optimization Finished!
********** replication  51  **********
epoch   0 LossPred 1.3459 LossAtt 1.0096 TrainAcc 0.4400 TestAcc 0.4760 0.4150
epoch 100 LossPred 0.9391 LossAtt 0.2939 TrainAcc 0.6000 TestAcc 0.5958 0.6050
epoch 200 LossPred 0.8815 LossAtt 0.3082 TrainAcc 0.6400 TestAcc 0.6101 0.6500
epoch 300 LossPred 0.5376 LossAtt 0.3717 TrainAcc 0.8600 TestAcc 0.8413 0.8400
epoch 400 LossPred 0.2319 LossAtt 0.2912 TrainAcc 0.9300 TestAcc 0.8844 0.8700
epoch 500 LossPred 0.1685 LossAtt 0.2551 TrainAcc 0.9600 TestAcc 0.9049 0.9350
epoch 600 LossPred 0.1284 LossAtt 0.2493 TrainAcc 0.9700 TestAcc 0.9049 0.9450
epoch 700 LossPred 0.1177 LossAtt 0.2292 TrainAcc 0.9600 TestAcc 0.9054 0.9600
epoch 800 LossPred 0.1583 LossAtt 0.2418 TrainAcc 0.9500 TestAcc 0.8999 0.9150
epoch 900 LossPred 0.1258 LossAtt 0.2435 TrainAcc 0.9600 TestAcc 0.9099 0.9650
epoch 1000 LossPred 0.1136 LossAtt 0.2393 TrainAcc 0.9600 TestAcc 0.9112 0.9500
epoch 1100 LossPred 0.1335 LossAtt 0.2335 TrainAcc 0.9400 TestAcc 0.8964 0.9250
epoch 1200 LossPred 0.0838 LossAtt 0.2383 TrainAcc 0.9800 TestAcc 0.9174 0.9650
epoch 1300 LossPred 0.1155 LossAtt 0.2511 TrainAcc 0.9700 TestAcc 0.9069 0.9650
epoch 1400 LossPred 0.1238 LossAtt 0.2487 TrainAcc 0.9500 TestAcc 0.8914 0.9400
epoch 1500 LossPred 0.0868 LossAtt 0.2392 TrainAcc 0.9700 TestAcc 0.9087 0.9650
epoch 1600 LossPred 0.0555 LossAtt 0.2528 TrainAcc 0.9800 TestAcc 0.9067 0.9700
epoch 1700 LossPred 0.0522 LossAtt 0.2497 TrainAcc 0.9800 TestAcc 0.9102 0.9800
epoch 1800 LossPred 0.0498 LossAtt 0.2487 TrainAcc 0.9900 TestAcc 0.9047 0.9900
epoch 1900 LossPred 0.0538 LossAtt 0.2519 TrainAcc 0.9800 TestAcc 0.9002 0.9800
epoch 2000 LossPred 0.0432 LossAtt 0.2473 TrainAcc 0.9900 TestAcc 0.9067 0.9950
epoch 2100 LossPred 0.0645 LossAtt 0.2487 TrainAcc 0.9800 TestAcc 0.8989 0.9700
epoch 2200 LossPred 0.0444 LossAtt 0.2592 TrainAcc 0.9800 TestAcc 0.9132 0.9900
epoch 2300 LossPred 0.0453 LossAtt 0.2365 TrainAcc 0.9800 TestAcc 0.9044 0.9800
epoch 2400 LossPred 0.0467 LossAtt 0.2624 TrainAcc 0.9800 TestAcc 0.9024 0.9800
epoch 2500 LossPred 0.0421 LossAtt 0.2383 TrainAcc 0.9800 TestAcc 0.9012 0.9950
Optimization Finished!
********** replication  52  **********
epoch   0 LossPred 0.9859 LossAtt 1.0139 TrainAcc 0.5800 TestAcc 0.5843 0.5750
epoch 100 LossPred 0.4735 LossAtt 0.3719 TrainAcc 0.8500 TestAcc 0.8488 0.8450
epoch 200 LossPred 0.3859 LossAtt 0.2950 TrainAcc 0.8800 TestAcc 0.8519 0.8650
epoch 300 LossPred 0.3513 LossAtt 0.2463 TrainAcc 0.9000 TestAcc 0.8599 0.8700
epoch 400 LossPred 0.3077 LossAtt 0.2352 TrainAcc 0.9200 TestAcc 0.8799 0.8900
epoch 500 LossPred 0.2817 LossAtt 0.2222 TrainAcc 0.9200 TestAcc 0.9132 0.9100
epoch 600 LossPred 0.2867 LossAtt 0.2033 TrainAcc 0.9000 TestAcc 0.9104 0.9100
epoch 700 LossPred 0.3664 LossAtt 0.2111 TrainAcc 0.8700 TestAcc 0.8809 0.8500
epoch 800 LossPred 0.2741 LossAtt 0.2077 TrainAcc 0.9100 TestAcc 0.9009 0.9100
epoch 900 LossPred 0.6131 LossAtt 0.1937 TrainAcc 0.7900 TestAcc 0.7780 0.8000
epoch 1000 LossPred 0.5251 LossAtt 0.1823 TrainAcc 0.8100 TestAcc 0.7860 0.8200
epoch 1100 LossPred 0.3668 LossAtt 0.2105 TrainAcc 0.8800 TestAcc 0.8509 0.8550
epoch 1200 LossPred 0.3306 LossAtt 0.1901 TrainAcc 0.8800 TestAcc 0.8721 0.9000
epoch 1300 LossPred 0.2766 LossAtt 0.1802 TrainAcc 0.8900 TestAcc 0.8859 0.9150
epoch 1400 LossPred 0.3570 LossAtt 0.1807 TrainAcc 0.8800 TestAcc 0.8564 0.8550
epoch 1500 LossPred 0.2012 LossAtt 0.1927 TrainAcc 0.9200 TestAcc 0.8959 0.9300
epoch 1600 LossPred 0.2133 LossAtt 0.1845 TrainAcc 0.9100 TestAcc 0.8916 0.9400
epoch 1700 LossPred 0.3744 LossAtt 0.2006 TrainAcc 0.8900 TestAcc 0.8619 0.8750
epoch 1800 LossPred 0.2427 LossAtt 0.1923 TrainAcc 0.8900 TestAcc 0.8759 0.9350
epoch 1900 LossPred 0.2240 LossAtt 0.1992 TrainAcc 0.9200 TestAcc 0.8909 0.9050
epoch 2000 LossPred 0.3738 LossAtt 0.2048 TrainAcc 0.8800 TestAcc 0.8581 0.8750
epoch 2100 LossPred 0.2275 LossAtt 0.1814 TrainAcc 0.9100 TestAcc 0.8769 0.9250
epoch 2200 LossPred 0.2120 LossAtt 0.1908 TrainAcc 0.9200 TestAcc 0.8854 0.9200
epoch 2300 LossPred 0.2299 LossAtt 0.1813 TrainAcc 0.9200 TestAcc 0.8884 0.9350
epoch 2400 LossPred 0.4139 LossAtt 0.1738 TrainAcc 0.8400 TestAcc 0.8221 0.8450
epoch 2500 LossPred 0.3256 LossAtt 0.1986 TrainAcc 0.9000 TestAcc 0.8564 0.8900
Optimization Finished!
********** replication  53  **********
epoch   0 LossPred 1.1316 LossAtt 1.0147 TrainAcc 0.5000 TestAcc 0.4555 0.5200
epoch 100 LossPred 0.8942 LossAtt 0.2826 TrainAcc 0.6500 TestAcc 0.5796 0.6500
epoch 200 LossPred 0.3852 LossAtt 0.2765 TrainAcc 0.8900 TestAcc 0.8216 0.8800
epoch 300 LossPred 0.2126 LossAtt 0.2402 TrainAcc 0.9400 TestAcc 0.9550 0.9400
epoch 400 LossPred 0.2478 LossAtt 0.2057 TrainAcc 0.9400 TestAcc 0.8919 0.9350
epoch 500 LossPred 0.2126 LossAtt 0.1785 TrainAcc 0.9400 TestAcc 0.9042 0.9450
epoch 600 LossPred 0.1528 LossAtt 0.1660 TrainAcc 0.9500 TestAcc 0.9532 0.9500
epoch 700 LossPred 0.1812 LossAtt 0.1719 TrainAcc 0.9400 TestAcc 0.9317 0.9400
epoch 800 LossPred 0.1395 LossAtt 0.1623 TrainAcc 0.9800 TestAcc 0.9545 0.9700
epoch 900 LossPred 0.1358 LossAtt 0.1481 TrainAcc 0.9700 TestAcc 0.9542 0.9700
epoch 1000 LossPred 0.1665 LossAtt 0.1557 TrainAcc 0.9500 TestAcc 0.9294 0.9450
epoch 1100 LossPred 0.2616 LossAtt 0.1451 TrainAcc 0.9100 TestAcc 0.8524 0.9100
epoch 1200 LossPred 0.2033 LossAtt 0.1382 TrainAcc 0.9300 TestAcc 0.8894 0.9200
epoch 1300 LossPred 0.2670 LossAtt 0.1472 TrainAcc 0.8900 TestAcc 0.8601 0.8900
epoch 1400 LossPred 0.2786 LossAtt 0.1425 TrainAcc 0.9200 TestAcc 0.8601 0.9150
epoch 1500 LossPred 0.6250 LossAtt 0.1446 TrainAcc 0.7900 TestAcc 0.7880 0.7900
epoch 1600 LossPred 0.1812 LossAtt 0.1518 TrainAcc 0.9600 TestAcc 0.8841 0.9450
epoch 1700 LossPred 0.2630 LossAtt 0.1478 TrainAcc 0.9100 TestAcc 0.8571 0.9100
epoch 1800 LossPred 0.2120 LossAtt 0.1452 TrainAcc 0.9500 TestAcc 0.8861 0.9350
epoch 1900 LossPred 0.1549 LossAtt 0.1408 TrainAcc 0.9500 TestAcc 0.8894 0.9450
epoch 2000 LossPred 0.2408 LossAtt 0.1430 TrainAcc 0.9400 TestAcc 0.8649 0.9250
epoch 2100 LossPred 0.2277 LossAtt 0.1352 TrainAcc 0.9400 TestAcc 0.8691 0.9300
epoch 2200 LossPred 0.2324 LossAtt 0.1422 TrainAcc 0.9200 TestAcc 0.8659 0.9100
epoch 2300 LossPred 0.2606 LossAtt 0.1372 TrainAcc 0.9300 TestAcc 0.8591 0.9250
epoch 2400 LossPred 0.2977 LossAtt 0.1391 TrainAcc 0.9100 TestAcc 0.8501 0.8900
epoch 2500 LossPred 0.2515 LossAtt 0.1469 TrainAcc 0.9300 TestAcc 0.8534 0.9100
Optimization Finished!
********** replication  54  **********
epoch   0 LossPred 0.9494 LossAtt 1.0173 TrainAcc 0.6300 TestAcc 0.5916 0.6150
epoch 100 LossPred 0.7316 LossAtt 0.3527 TrainAcc 0.7000 TestAcc 0.6919 0.7250
epoch 200 LossPred 0.3641 LossAtt 0.3449 TrainAcc 0.9000 TestAcc 0.8569 0.8650
epoch 300 LossPred 0.2265 LossAtt 0.3434 TrainAcc 0.9500 TestAcc 0.9129 0.8950
epoch 400 LossPred 0.2862 LossAtt 0.3256 TrainAcc 0.8700 TestAcc 0.8496 0.8600
epoch 500 LossPred 0.1496 LossAtt 0.3217 TrainAcc 0.9400 TestAcc 0.9194 0.9250
epoch 600 LossPred 0.1292 LossAtt 0.3307 TrainAcc 0.9800 TestAcc 0.9082 0.9250
epoch 700 LossPred 0.1625 LossAtt 0.3213 TrainAcc 0.9400 TestAcc 0.9104 0.9050
epoch 800 LossPred 0.1009 LossAtt 0.3119 TrainAcc 0.9700 TestAcc 0.9162 0.9350
epoch 900 LossPred 0.1401 LossAtt 0.3230 TrainAcc 0.9700 TestAcc 0.8931 0.9200
epoch 1000 LossPred 0.1243 LossAtt 0.3179 TrainAcc 0.9700 TestAcc 0.9009 0.9250
epoch 1100 LossPred 0.0733 LossAtt 0.3213 TrainAcc 0.9700 TestAcc 0.9359 0.9200
epoch 1200 LossPred 0.0575 LossAtt 0.3101 TrainAcc 0.9900 TestAcc 0.9447 0.9450
epoch 1300 LossPred 0.0896 LossAtt 0.3073 TrainAcc 0.9900 TestAcc 0.9187 0.9150
epoch 1400 LossPred 0.0597 LossAtt 0.2978 TrainAcc 0.9900 TestAcc 0.9394 0.9300
epoch 1500 LossPred 0.0751 LossAtt 0.3004 TrainAcc 0.9800 TestAcc 0.9362 0.9400
epoch 1600 LossPred 0.1153 LossAtt 0.3157 TrainAcc 0.9400 TestAcc 0.9232 0.9200
epoch 1700 LossPred 0.1133 LossAtt 0.2900 TrainAcc 0.9600 TestAcc 0.9054 0.9200
epoch 1800 LossPred 0.1515 LossAtt 0.2922 TrainAcc 0.9500 TestAcc 0.9039 0.9300
epoch 1900 LossPred 0.1998 LossAtt 0.3029 TrainAcc 0.9200 TestAcc 0.8681 0.8650
epoch 2000 LossPred 0.2386 LossAtt 0.2827 TrainAcc 0.9200 TestAcc 0.8881 0.8950
epoch 2100 LossPred 0.1387 LossAtt 0.2858 TrainAcc 0.9600 TestAcc 0.8919 0.9400
epoch 2200 LossPred 0.0556 LossAtt 0.2760 TrainAcc 0.9800 TestAcc 0.9179 0.9600
epoch 2300 LossPred 0.0449 LossAtt 0.2932 TrainAcc 0.9900 TestAcc 0.9189 0.9750
epoch 2400 LossPred 0.0410 LossAtt 0.2798 TrainAcc 0.9900 TestAcc 0.9207 0.9700
epoch 2500 LossPred 0.0407 LossAtt 0.2686 TrainAcc 0.9900 TestAcc 0.9144 0.9800
Optimization Finished!
********** replication  55  **********
epoch   0 LossPred 1.0185 LossAtt 1.0145 TrainAcc 0.5200 TestAcc 0.4890 0.5450
epoch 100 LossPred 0.9422 LossAtt 0.3009 TrainAcc 0.5900 TestAcc 0.5846 0.5950
epoch 200 LossPred 0.4235 LossAtt 0.2932 TrainAcc 0.8800 TestAcc 0.8759 0.8300
epoch 300 LossPred 0.1391 LossAtt 0.2854 TrainAcc 0.9600 TestAcc 0.9059 0.9450
epoch 400 LossPred 0.2212 LossAtt 0.2917 TrainAcc 0.9300 TestAcc 0.9132 0.9100
epoch 500 LossPred 0.2597 LossAtt 0.2868 TrainAcc 0.9100 TestAcc 0.8984 0.8850
epoch 600 LossPred 0.1456 LossAtt 0.2713 TrainAcc 0.9700 TestAcc 0.9169 0.9400
epoch 700 LossPred 0.1579 LossAtt 0.2787 TrainAcc 0.9700 TestAcc 0.9142 0.9250
epoch 800 LossPred 0.0919 LossAtt 0.2708 TrainAcc 0.9900 TestAcc 0.9149 0.9700
epoch 900 LossPred 0.2409 LossAtt 0.2726 TrainAcc 0.9300 TestAcc 0.8824 0.9200
epoch 1000 LossPred 0.6372 LossAtt 0.2711 TrainAcc 0.7800 TestAcc 0.8038 0.7800
epoch 1100 LossPred 0.3198 LossAtt 0.2585 TrainAcc 0.8600 TestAcc 0.8431 0.8950
epoch 1200 LossPred 0.3399 LossAtt 0.2489 TrainAcc 0.8700 TestAcc 0.8176 0.8850
epoch 1300 LossPred 0.2757 LossAtt 0.2302 TrainAcc 0.9000 TestAcc 0.8816 0.8850
epoch 1400 LossPred 0.2977 LossAtt 0.2325 TrainAcc 0.9000 TestAcc 0.8864 0.9000
epoch 1500 LossPred 0.4969 LossAtt 0.2481 TrainAcc 0.8200 TestAcc 0.7690 0.8100
epoch 1600 LossPred 0.3518 LossAtt 0.2597 TrainAcc 0.8700 TestAcc 0.7975 0.8550
epoch 1700 LossPred 0.1974 LossAtt 0.2271 TrainAcc 0.9400 TestAcc 0.9047 0.9000
epoch 1800 LossPred 0.1762 LossAtt 0.2233 TrainAcc 0.9400 TestAcc 0.9094 0.9250
epoch 1900 LossPred 0.1830 LossAtt 0.2349 TrainAcc 0.9300 TestAcc 0.9074 0.9300
epoch 2000 LossPred 0.1968 LossAtt 0.2349 TrainAcc 0.9300 TestAcc 0.9037 0.9250
epoch 2100 LossPred 0.2365 LossAtt 0.2404 TrainAcc 0.9300 TestAcc 0.8373 0.9050
epoch 2200 LossPred 0.1267 LossAtt 0.2432 TrainAcc 0.9600 TestAcc 0.8744 0.9500
epoch 2300 LossPred 0.1452 LossAtt 0.2244 TrainAcc 0.9400 TestAcc 0.8936 0.9300
epoch 2400 LossPred 0.1182 LossAtt 0.2299 TrainAcc 0.9600 TestAcc 0.9047 0.9500
epoch 2500 LossPred 0.2868 LossAtt 0.2327 TrainAcc 0.8900 TestAcc 0.8749 0.8850
Optimization Finished!
********** replication  56  **********
epoch   0 LossPred 0.9937 LossAtt 1.0157 TrainAcc 0.4900 TestAcc 0.5551 0.5200
epoch 100 LossPred 0.7395 LossAtt 0.3282 TrainAcc 0.7400 TestAcc 0.6514 0.7250
epoch 200 LossPred 0.4031 LossAtt 0.3004 TrainAcc 0.8400 TestAcc 0.8411 0.8550
epoch 300 LossPred 0.5213 LossAtt 0.2957 TrainAcc 0.8200 TestAcc 0.8388 0.8050
epoch 400 LossPred 0.3651 LossAtt 0.2842 TrainAcc 0.8700 TestAcc 0.8654 0.8700
epoch 500 LossPred 0.2341 LossAtt 0.3114 TrainAcc 0.9400 TestAcc 0.9094 0.9100
epoch 600 LossPred 0.3444 LossAtt 0.3056 TrainAcc 0.8600 TestAcc 0.8776 0.8800
epoch 700 LossPred 0.1648 LossAtt 0.2632 TrainAcc 0.9400 TestAcc 0.9182 0.9150
epoch 800 LossPred 0.1199 LossAtt 0.2323 TrainAcc 0.9700 TestAcc 0.9359 0.9650
epoch 900 LossPred 0.2025 LossAtt 0.2185 TrainAcc 0.9200 TestAcc 0.9134 0.9400
epoch 1000 LossPred 0.3889 LossAtt 0.2238 TrainAcc 0.8700 TestAcc 0.8636 0.8800
epoch 1100 LossPred 0.1868 LossAtt 0.2325 TrainAcc 0.9500 TestAcc 0.9167 0.9350
epoch 1200 LossPred 0.1159 LossAtt 0.2344 TrainAcc 0.9600 TestAcc 0.9407 0.9550
epoch 1300 LossPred 0.0969 LossAtt 0.2419 TrainAcc 0.9700 TestAcc 0.9237 0.9550
epoch 1400 LossPred 0.2543 LossAtt 0.2526 TrainAcc 0.9100 TestAcc 0.8784 0.9000
epoch 1500 LossPred 0.1286 LossAtt 0.2477 TrainAcc 0.9700 TestAcc 0.9079 0.9450
epoch 1600 LossPred 0.0967 LossAtt 0.2585 TrainAcc 0.9700 TestAcc 0.9382 0.9650
epoch 1700 LossPred 0.1177 LossAtt 0.2701 TrainAcc 0.9700 TestAcc 0.9082 0.9400
epoch 1800 LossPred 0.1846 LossAtt 0.2636 TrainAcc 0.9500 TestAcc 0.9014 0.9250
epoch 1900 LossPred 0.1210 LossAtt 0.2677 TrainAcc 0.9700 TestAcc 0.9277 0.9550
epoch 2000 LossPred 0.1061 LossAtt 0.2510 TrainAcc 0.9800 TestAcc 0.9212 0.9450
epoch 2100 LossPred 0.0932 LossAtt 0.2503 TrainAcc 0.9700 TestAcc 0.9309 0.9550
epoch 2200 LossPred 0.0911 LossAtt 0.2548 TrainAcc 0.9800 TestAcc 0.9252 0.9700
epoch 2300 LossPred 0.0751 LossAtt 0.2405 TrainAcc 0.9800 TestAcc 0.9357 0.9750
epoch 2400 LossPred 0.0704 LossAtt 0.2426 TrainAcc 0.9900 TestAcc 0.9309 0.9700
epoch 2500 LossPred 0.1347 LossAtt 0.2328 TrainAcc 0.9700 TestAcc 0.9164 0.9450
Optimization Finished!
********** replication  57  **********
epoch   0 LossPred 1.3939 LossAtt 1.0501 TrainAcc 0.4500 TestAcc 0.4282 0.4200
epoch 100 LossPred 0.9017 LossAtt 0.3190 TrainAcc 0.6600 TestAcc 0.5751 0.6550
epoch 200 LossPred 0.8377 LossAtt 0.3036 TrainAcc 0.7000 TestAcc 0.6446 0.6950
epoch 300 LossPred 0.3991 LossAtt 0.3861 TrainAcc 0.9000 TestAcc 0.8621 0.8650
epoch 400 LossPred 0.2738 LossAtt 0.3478 TrainAcc 0.9100 TestAcc 0.8789 0.8850
epoch 500 LossPred 0.1722 LossAtt 0.3225 TrainAcc 0.9700 TestAcc 0.9094 0.9300
epoch 600 LossPred 0.1018 LossAtt 0.3029 TrainAcc 0.9900 TestAcc 0.9382 0.9850
epoch 700 LossPred 0.0693 LossAtt 0.2896 TrainAcc 0.9900 TestAcc 0.9182 0.9900
epoch 800 LossPred 0.0687 LossAtt 0.2738 TrainAcc 0.9900 TestAcc 0.9134 0.9850
epoch 900 LossPred 0.0526 LossAtt 0.2787 TrainAcc 0.9900 TestAcc 0.9092 0.9850
epoch 1000 LossPred 0.0560 LossAtt 0.2560 TrainAcc 0.9900 TestAcc 0.8984 0.9800
epoch 1100 LossPred 0.0253 LossAtt 0.2665 TrainAcc 1.0000 TestAcc 0.9149 0.9950
Optimization Finished!
********** replication  58  **********
epoch   0 LossPred 0.9776 LossAtt 1.0102 TrainAcc 0.5700 TestAcc 0.5536 0.5900
epoch 100 LossPred 0.8141 LossAtt 0.2951 TrainAcc 0.7000 TestAcc 0.6386 0.6900
epoch 200 LossPred 0.3554 LossAtt 0.2417 TrainAcc 0.8800 TestAcc 0.8436 0.8650
epoch 300 LossPred 0.4726 LossAtt 0.2298 TrainAcc 0.8400 TestAcc 0.7803 0.8350
epoch 400 LossPred 0.4098 LossAtt 0.2286 TrainAcc 0.8500 TestAcc 0.7950 0.8400
epoch 500 LossPred 0.2951 LossAtt 0.2226 TrainAcc 0.9000 TestAcc 0.8726 0.8950
epoch 600 LossPred 0.3272 LossAtt 0.2185 TrainAcc 0.8800 TestAcc 0.8366 0.8700
epoch 700 LossPred 0.4803 LossAtt 0.2044 TrainAcc 0.8500 TestAcc 0.8686 0.8300
epoch 800 LossPred 0.4395 LossAtt 0.2027 TrainAcc 0.8500 TestAcc 0.8611 0.8500
epoch 900 LossPred 0.3079 LossAtt 0.1999 TrainAcc 0.9100 TestAcc 0.9099 0.8850
epoch 1000 LossPred 0.2226 LossAtt 0.2058 TrainAcc 0.9300 TestAcc 0.8976 0.9050
epoch 1100 LossPred 0.3420 LossAtt 0.1946 TrainAcc 0.8800 TestAcc 0.8293 0.8650
epoch 1200 LossPred 0.3204 LossAtt 0.2059 TrainAcc 0.8800 TestAcc 0.8478 0.8600
epoch 1300 LossPred 0.2210 LossAtt 0.1978 TrainAcc 0.9200 TestAcc 0.8839 0.8850
epoch 1400 LossPred 0.3331 LossAtt 0.1931 TrainAcc 0.8800 TestAcc 0.8939 0.9000
epoch 1500 LossPred 0.2268 LossAtt 0.2050 TrainAcc 0.9400 TestAcc 0.9129 0.8900
epoch 1600 LossPred 0.2257 LossAtt 0.2049 TrainAcc 0.9300 TestAcc 0.8859 0.9050
epoch 1700 LossPred 0.2642 LossAtt 0.2020 TrainAcc 0.8900 TestAcc 0.8716 0.8950
epoch 1800 LossPred 0.2188 LossAtt 0.1904 TrainAcc 0.9400 TestAcc 0.9032 0.8950
epoch 1900 LossPred 0.2414 LossAtt 0.1951 TrainAcc 0.9300 TestAcc 0.9057 0.9000
epoch 2000 LossPred 0.2630 LossAtt 0.1997 TrainAcc 0.8900 TestAcc 0.8741 0.9000
epoch 2100 LossPred 0.3157 LossAtt 0.2004 TrainAcc 0.8800 TestAcc 0.8846 0.8750
epoch 2200 LossPred 0.3365 LossAtt 0.1974 TrainAcc 0.8700 TestAcc 0.8531 0.8750
epoch 2300 LossPred 0.1954 LossAtt 0.1924 TrainAcc 0.9500 TestAcc 0.9019 0.8950
epoch 2400 LossPred 0.2066 LossAtt 0.1960 TrainAcc 0.9400 TestAcc 0.8909 0.9100
epoch 2500 LossPred 0.3085 LossAtt 0.2041 TrainAcc 0.9000 TestAcc 0.8651 0.8850
Optimization Finished!
********** replication  59  **********
epoch   0 LossPred 1.2077 LossAtt 1.0209 TrainAcc 0.4700 TestAcc 0.4457 0.4600
epoch 100 LossPred 0.6425 LossAtt 0.3494 TrainAcc 0.7700 TestAcc 0.7680 0.7950
epoch 200 LossPred 0.3931 LossAtt 0.3100 TrainAcc 0.8700 TestAcc 0.8393 0.8650
epoch 300 LossPred 0.2838 LossAtt 0.2683 TrainAcc 0.9300 TestAcc 0.8916 0.8900
epoch 400 LossPred 0.3982 LossAtt 0.2697 TrainAcc 0.8400 TestAcc 0.8391 0.8450
epoch 500 LossPred 0.3030 LossAtt 0.2533 TrainAcc 0.9000 TestAcc 0.8806 0.8850
epoch 600 LossPred 0.4618 LossAtt 0.2601 TrainAcc 0.8200 TestAcc 0.8228 0.8050
epoch 700 LossPred 0.2647 LossAtt 0.2471 TrainAcc 0.9400 TestAcc 0.8916 0.9100
epoch 800 LossPred 0.2488 LossAtt 0.2500 TrainAcc 0.9300 TestAcc 0.8851 0.9200
epoch 900 LossPred 0.3081 LossAtt 0.2551 TrainAcc 0.9000 TestAcc 0.8421 0.8750
epoch 1000 LossPred 0.2760 LossAtt 0.2571 TrainAcc 0.9200 TestAcc 0.8744 0.8900
epoch 1100 LossPred 0.3125 LossAtt 0.2408 TrainAcc 0.9000 TestAcc 0.8829 0.8800
epoch 1200 LossPred 0.2214 LossAtt 0.2306 TrainAcc 0.9100 TestAcc 0.9017 0.9200
epoch 1300 LossPred 0.1864 LossAtt 0.2063 TrainAcc 0.9500 TestAcc 0.9144 0.9500
epoch 1400 LossPred 0.1916 LossAtt 0.2011 TrainAcc 0.9100 TestAcc 0.9097 0.9250
epoch 1500 LossPred 0.1986 LossAtt 0.1870 TrainAcc 0.9200 TestAcc 0.9079 0.9250
epoch 1600 LossPred 0.2189 LossAtt 0.1697 TrainAcc 0.9400 TestAcc 0.9099 0.9350
epoch 1700 LossPred 0.1592 LossAtt 0.1613 TrainAcc 0.9400 TestAcc 0.9282 0.9550
epoch 1800 LossPred 0.3140 LossAtt 0.1649 TrainAcc 0.8900 TestAcc 0.8488 0.8950
epoch 1900 LossPred 0.2231 LossAtt 0.1586 TrainAcc 0.9100 TestAcc 0.8959 0.9200
epoch 2000 LossPred 0.2412 LossAtt 0.1594 TrainAcc 0.9100 TestAcc 0.8799 0.9200
epoch 2100 LossPred 0.2985 LossAtt 0.1629 TrainAcc 0.8800 TestAcc 0.8609 0.8850
epoch 2200 LossPred 0.2389 LossAtt 0.1794 TrainAcc 0.9100 TestAcc 0.8801 0.9150
epoch 2300 LossPred 0.1875 LossAtt 0.1568 TrainAcc 0.9300 TestAcc 0.9122 0.9300
epoch 2400 LossPred 0.1563 LossAtt 0.1447 TrainAcc 0.9500 TestAcc 0.9269 0.9500
epoch 2500 LossPred 0.1649 LossAtt 0.1400 TrainAcc 0.9300 TestAcc 0.9199 0.9250
Optimization Finished!
********** replication  60  **********
epoch   0 LossPred 0.9778 LossAtt 1.0175 TrainAcc 0.5800 TestAcc 0.5838 0.5600
epoch 100 LossPred 0.9002 LossAtt 0.3376 TrainAcc 0.6600 TestAcc 0.5906 0.6350
epoch 200 LossPred 0.8196 LossAtt 0.3854 TrainAcc 0.6800 TestAcc 0.5861 0.6550
epoch 300 LossPred 0.7136 LossAtt 0.3704 TrainAcc 0.7400 TestAcc 0.5691 0.7250
epoch 400 LossPred 0.5495 LossAtt 0.4097 TrainAcc 0.8000 TestAcc 0.5931 0.7500
epoch 500 LossPred 0.5037 LossAtt 0.4087 TrainAcc 0.8500 TestAcc 0.5813 0.7450
epoch 600 LossPred 0.4997 LossAtt 0.3694 TrainAcc 0.8200 TestAcc 0.5803 0.7700
epoch 700 LossPred 0.5028 LossAtt 0.3661 TrainAcc 0.8100 TestAcc 0.5898 0.7050
epoch 800 LossPred 0.4780 LossAtt 0.3730 TrainAcc 0.8300 TestAcc 0.5843 0.7450
epoch 900 LossPred 0.4770 LossAtt 0.3617 TrainAcc 0.8200 TestAcc 0.5606 0.7600
epoch 1000 LossPred 0.4744 LossAtt 0.3372 TrainAcc 0.8400 TestAcc 0.5776 0.7700
epoch 1100 LossPred 0.4920 LossAtt 0.3413 TrainAcc 0.8000 TestAcc 0.5871 0.7650
epoch 1200 LossPred 0.4944 LossAtt 0.3405 TrainAcc 0.8200 TestAcc 0.6004 0.7550
epoch 1300 LossPred 0.5012 LossAtt 0.3417 TrainAcc 0.8400 TestAcc 0.6019 0.7650
epoch 1400 LossPred 0.4464 LossAtt 0.3451 TrainAcc 0.8300 TestAcc 0.6049 0.7700
epoch 1500 LossPred 0.4168 LossAtt 0.3374 TrainAcc 0.8300 TestAcc 0.6041 0.7900
epoch 1600 LossPred 0.4303 LossAtt 0.3567 TrainAcc 0.8500 TestAcc 0.5996 0.7900
epoch 1700 LossPred 0.3670 LossAtt 0.3327 TrainAcc 0.8800 TestAcc 0.5938 0.8050
epoch 1800 LossPred 0.3729 LossAtt 0.3171 TrainAcc 0.8800 TestAcc 0.5881 0.7800
epoch 1900 LossPred 0.4121 LossAtt 0.3215 TrainAcc 0.8500 TestAcc 0.6064 0.8150
epoch 2000 LossPred 0.3595 LossAtt 0.3225 TrainAcc 0.8700 TestAcc 0.6041 0.7750
epoch 2100 LossPred 0.3566 LossAtt 0.3101 TrainAcc 0.8800 TestAcc 0.6056 0.7900
epoch 2200 LossPred 0.3749 LossAtt 0.3047 TrainAcc 0.8500 TestAcc 0.6099 0.7750
epoch 2300 LossPred 0.3723 LossAtt 0.2954 TrainAcc 0.8700 TestAcc 0.6091 0.7950
epoch 2400 LossPred 0.4261 LossAtt 0.2978 TrainAcc 0.8700 TestAcc 0.6089 0.8150
epoch 2500 LossPred 0.4112 LossAtt 0.2992 TrainAcc 0.8400 TestAcc 0.6261 0.7900
Optimization Finished!
********** replication  61  **********
epoch   0 LossPred 0.9862 LossAtt 1.0037 TrainAcc 0.5800 TestAcc 0.5135 0.5300
epoch 100 LossPred 0.8048 LossAtt 0.3182 TrainAcc 0.6400 TestAcc 0.6066 0.6500
epoch 200 LossPred 0.7765 LossAtt 0.2629 TrainAcc 0.6800 TestAcc 0.5946 0.7100
epoch 300 LossPred 0.7851 LossAtt 0.2414 TrainAcc 0.6900 TestAcc 0.5786 0.6950
epoch 400 LossPred 0.7501 LossAtt 0.2862 TrainAcc 0.7100 TestAcc 0.6114 0.7050
epoch 500 LossPred 0.6903 LossAtt 0.2902 TrainAcc 0.7400 TestAcc 0.6126 0.7300
epoch 600 LossPred 0.5596 LossAtt 0.3287 TrainAcc 0.7900 TestAcc 0.7212 0.7900
epoch 700 LossPred 0.4432 LossAtt 0.3307 TrainAcc 0.8600 TestAcc 0.7625 0.8350
epoch 800 LossPred 0.3957 LossAtt 0.3253 TrainAcc 0.8800 TestAcc 0.7840 0.8750
epoch 900 LossPred 0.3793 LossAtt 0.3069 TrainAcc 0.8900 TestAcc 0.7738 0.8800
epoch 1000 LossPred 0.3618 LossAtt 0.3017 TrainAcc 0.8900 TestAcc 0.7783 0.8850
epoch 1100 LossPred 0.3467 LossAtt 0.2972 TrainAcc 0.9000 TestAcc 0.8073 0.8750
epoch 1200 LossPred 0.2871 LossAtt 0.3327 TrainAcc 0.9200 TestAcc 0.8036 0.8900
epoch 1300 LossPred 0.2252 LossAtt 0.3155 TrainAcc 0.9300 TestAcc 0.8521 0.9150
epoch 1400 LossPred 0.1895 LossAtt 0.3043 TrainAcc 0.9600 TestAcc 0.8804 0.9350
epoch 1500 LossPred 0.1402 LossAtt 0.3006 TrainAcc 0.9800 TestAcc 0.9012 0.9300
epoch 1600 LossPred 0.1880 LossAtt 0.2867 TrainAcc 0.9400 TestAcc 0.8696 0.9300
epoch 1700 LossPred 0.1400 LossAtt 0.2977 TrainAcc 0.9800 TestAcc 0.9004 0.9200
epoch 1800 LossPred 0.1422 LossAtt 0.2788 TrainAcc 0.9600 TestAcc 0.8831 0.9350
epoch 1900 LossPred 0.1236 LossAtt 0.2888 TrainAcc 0.9700 TestAcc 0.9004 0.9300
epoch 2000 LossPred 0.1287 LossAtt 0.2889 TrainAcc 0.9600 TestAcc 0.8959 0.9450
epoch 2100 LossPred 0.1278 LossAtt 0.2998 TrainAcc 0.9800 TestAcc 0.9067 0.9400
epoch 2200 LossPred 0.2322 LossAtt 0.2910 TrainAcc 0.9200 TestAcc 0.8473 0.9250
epoch 2300 LossPred 0.1733 LossAtt 0.3207 TrainAcc 0.9700 TestAcc 0.9044 0.9150
epoch 2400 LossPred 0.1137 LossAtt 0.3045 TrainAcc 0.9800 TestAcc 0.8989 0.9600
epoch 2500 LossPred 0.1050 LossAtt 0.3031 TrainAcc 0.9800 TestAcc 0.9174 0.9500
Optimization Finished!
********** replication  62  **********
epoch   0 LossPred 1.2686 LossAtt 1.0127 TrainAcc 0.4500 TestAcc 0.4677 0.4450
epoch 100 LossPred 0.8584 LossAtt 0.2766 TrainAcc 0.6900 TestAcc 0.6421 0.7000
epoch 200 LossPred 0.5799 LossAtt 0.2486 TrainAcc 0.8300 TestAcc 0.7948 0.8400
epoch 300 LossPred 0.4671 LossAtt 0.2482 TrainAcc 0.8600 TestAcc 0.8376 0.8400
epoch 400 LossPred 0.3838 LossAtt 0.2527 TrainAcc 0.9100 TestAcc 0.8666 0.8800
epoch 500 LossPred 0.3768 LossAtt 0.2643 TrainAcc 0.9000 TestAcc 0.8619 0.8800
epoch 600 LossPred 0.5077 LossAtt 0.2557 TrainAcc 0.8100 TestAcc 0.8141 0.8300
epoch 700 LossPred 0.4546 LossAtt 0.2675 TrainAcc 0.8600 TestAcc 0.8178 0.8400
epoch 800 LossPred 0.2976 LossAtt 0.2637 TrainAcc 0.8900 TestAcc 0.8936 0.8950
epoch 900 LossPred 0.2792 LossAtt 0.2709 TrainAcc 0.9100 TestAcc 0.8951 0.9150
epoch 1000 LossPred 0.3337 LossAtt 0.2676 TrainAcc 0.8900 TestAcc 0.8491 0.8550
epoch 1100 LossPred 0.2504 LossAtt 0.2571 TrainAcc 0.9100 TestAcc 0.8876 0.9000
epoch 1200 LossPred 0.2533 LossAtt 0.2572 TrainAcc 0.9000 TestAcc 0.8891 0.9100
epoch 1300 LossPred 0.7876 LossAtt 0.2498 TrainAcc 0.7000 TestAcc 0.7190 0.7300
epoch 1400 LossPred 0.4072 LossAtt 0.2527 TrainAcc 0.8600 TestAcc 0.8233 0.8400
epoch 1500 LossPred 0.3177 LossAtt 0.2445 TrainAcc 0.8900 TestAcc 0.8804 0.8800
epoch 1600 LossPred 0.5035 LossAtt 0.2400 TrainAcc 0.7900 TestAcc 0.8116 0.7950
epoch 1700 LossPred 0.2608 LossAtt 0.2365 TrainAcc 0.9500 TestAcc 0.8944 0.9000
epoch 1800 LossPred 0.2800 LossAtt 0.2206 TrainAcc 0.9200 TestAcc 0.8874 0.8800
epoch 1900 LossPred 0.3823 LossAtt 0.2282 TrainAcc 0.8800 TestAcc 0.8423 0.8650
epoch 2000 LossPred 0.4397 LossAtt 0.2022 TrainAcc 0.8300 TestAcc 0.8396 0.8400
epoch 2100 LossPred 0.2435 LossAtt 0.2117 TrainAcc 0.9300 TestAcc 0.8994 0.9150
epoch 2200 LossPred 0.2535 LossAtt 0.2045 TrainAcc 0.9100 TestAcc 0.8956 0.9150
epoch 2300 LossPred 0.2735 LossAtt 0.2104 TrainAcc 0.8900 TestAcc 0.8921 0.9000
epoch 2400 LossPred 0.3413 LossAtt 0.2069 TrainAcc 0.9000 TestAcc 0.8671 0.8850
epoch 2500 LossPred 0.3910 LossAtt 0.1937 TrainAcc 0.8700 TestAcc 0.8353 0.8450
Optimization Finished!
********** replication  63  **********
epoch   0 LossPred 1.0141 LossAtt 1.0063 TrainAcc 0.5400 TestAcc 0.5470 0.5400
epoch 100 LossPred 0.9015 LossAtt 0.2575 TrainAcc 0.6100 TestAcc 0.6004 0.6150
epoch 200 LossPred 0.3316 LossAtt 0.2371 TrainAcc 0.8800 TestAcc 0.8554 0.8750
epoch 300 LossPred 0.3096 LossAtt 0.2168 TrainAcc 0.8800 TestAcc 0.8704 0.8750
epoch 400 LossPred 0.2879 LossAtt 0.2258 TrainAcc 0.8900 TestAcc 0.8604 0.8650
epoch 500 LossPred 0.2347 LossAtt 0.2335 TrainAcc 0.9300 TestAcc 0.8779 0.8850
epoch 600 LossPred 0.4748 LossAtt 0.2208 TrainAcc 0.8300 TestAcc 0.8036 0.8300
epoch 700 LossPred 0.2797 LossAtt 0.2103 TrainAcc 0.9100 TestAcc 0.8536 0.8650
epoch 800 LossPred 0.1981 LossAtt 0.1899 TrainAcc 0.9400 TestAcc 0.8806 0.8950
epoch 900 LossPred 0.2165 LossAtt 0.2059 TrainAcc 0.9200 TestAcc 0.8789 0.8700
epoch 1000 LossPred 0.2013 LossAtt 0.1914 TrainAcc 0.9400 TestAcc 0.8781 0.8850
epoch 1100 LossPred 0.1804 LossAtt 0.1985 TrainAcc 0.9400 TestAcc 0.8854 0.9000
epoch 1200 LossPred 0.1803 LossAtt 0.1863 TrainAcc 0.9400 TestAcc 0.8804 0.9000
epoch 1300 LossPred 0.1865 LossAtt 0.1997 TrainAcc 0.9400 TestAcc 0.8826 0.9100
epoch 1400 LossPred 0.2142 LossAtt 0.2009 TrainAcc 0.9300 TestAcc 0.8841 0.9000
epoch 1500 LossPred 0.2075 LossAtt 0.1910 TrainAcc 0.9300 TestAcc 0.8791 0.8900
epoch 1600 LossPred 0.1649 LossAtt 0.1886 TrainAcc 0.9400 TestAcc 0.8849 0.8950
epoch 1700 LossPred 0.1637 LossAtt 0.2047 TrainAcc 0.9600 TestAcc 0.9044 0.9100
epoch 1800 LossPred 0.2333 LossAtt 0.1997 TrainAcc 0.9300 TestAcc 0.8861 0.9100
epoch 1900 LossPred 0.3719 LossAtt 0.1863 TrainAcc 0.8400 TestAcc 0.8303 0.8700
epoch 2000 LossPred 0.1684 LossAtt 0.1907 TrainAcc 0.9600 TestAcc 0.9089 0.9150
epoch 2100 LossPred 0.1859 LossAtt 0.1935 TrainAcc 0.9500 TestAcc 0.9049 0.9150
epoch 2200 LossPred 0.1640 LossAtt 0.1837 TrainAcc 0.9600 TestAcc 0.9079 0.9150
epoch 2300 LossPred 0.1899 LossAtt 0.1882 TrainAcc 0.9400 TestAcc 0.9049 0.9200
epoch 2400 LossPred 0.4644 LossAtt 0.1993 TrainAcc 0.8600 TestAcc 0.8028 0.8500
epoch 2500 LossPred 0.1795 LossAtt 0.2143 TrainAcc 0.9200 TestAcc 0.8766 0.9100
Optimization Finished!
********** replication  64  **********
epoch   0 LossPred 0.9972 LossAtt 1.0153 TrainAcc 0.5200 TestAcc 0.4717 0.5400
epoch 100 LossPred 0.9205 LossAtt 0.3021 TrainAcc 0.6200 TestAcc 0.6374 0.6250
epoch 200 LossPred 0.3846 LossAtt 0.3287 TrainAcc 0.8600 TestAcc 0.8574 0.8500
epoch 300 LossPred 0.2303 LossAtt 0.2999 TrainAcc 0.9400 TestAcc 0.8679 0.9100
epoch 400 LossPred 0.1970 LossAtt 0.2932 TrainAcc 0.9400 TestAcc 0.8849 0.9250
epoch 500 LossPred 0.1764 LossAtt 0.2853 TrainAcc 0.9500 TestAcc 0.9042 0.9100
epoch 600 LossPred 0.1660 LossAtt 0.2632 TrainAcc 0.9600 TestAcc 0.8896 0.9300
epoch 700 LossPred 0.1529 LossAtt 0.2637 TrainAcc 0.9600 TestAcc 0.8889 0.9200
epoch 800 LossPred 0.1690 LossAtt 0.2414 TrainAcc 0.9600 TestAcc 0.8759 0.9400
epoch 900 LossPred 0.4879 LossAtt 0.2354 TrainAcc 0.8200 TestAcc 0.7603 0.8300
epoch 1000 LossPred 0.1923 LossAtt 0.2233 TrainAcc 0.9200 TestAcc 0.9147 0.9300
epoch 1100 LossPred 0.1674 LossAtt 0.2167 TrainAcc 0.9300 TestAcc 0.9214 0.9350
epoch 1200 LossPred 0.1485 LossAtt 0.2136 TrainAcc 0.9400 TestAcc 0.9162 0.9400
epoch 1300 LossPred 0.3050 LossAtt 0.2219 TrainAcc 0.8800 TestAcc 0.8201 0.8850
epoch 1400 LossPred 0.2907 LossAtt 0.2244 TrainAcc 0.9000 TestAcc 0.8098 0.9050
epoch 1500 LossPred 0.1593 LossAtt 0.2026 TrainAcc 0.9300 TestAcc 0.9032 0.9300
epoch 1600 LossPred 0.1578 LossAtt 0.2050 TrainAcc 0.9500 TestAcc 0.8996 0.9550
epoch 1700 LossPred 0.1602 LossAtt 0.2058 TrainAcc 0.9400 TestAcc 0.9092 0.9400
epoch 1800 LossPred 0.1624 LossAtt 0.2142 TrainAcc 0.9300 TestAcc 0.9149 0.9400
epoch 1900 LossPred 0.1551 LossAtt 0.2006 TrainAcc 0.9400 TestAcc 0.9027 0.9300
epoch 2000 LossPred 0.1670 LossAtt 0.2081 TrainAcc 0.9300 TestAcc 0.9109 0.9350
epoch 2100 LossPred 0.1883 LossAtt 0.2077 TrainAcc 0.9400 TestAcc 0.8729 0.9200
epoch 2200 LossPred 0.2012 LossAtt 0.2097 TrainAcc 0.9300 TestAcc 0.8919 0.9200
epoch 2300 LossPred 0.1598 LossAtt 0.2264 TrainAcc 0.9500 TestAcc 0.8871 0.9400
epoch 2400 LossPred 0.1811 LossAtt 0.2137 TrainAcc 0.9300 TestAcc 0.8989 0.9350
epoch 2500 LossPred 0.1873 LossAtt 0.2240 TrainAcc 0.9500 TestAcc 0.8846 0.9450
Optimization Finished!
********** replication  65  **********
epoch   0 LossPred 1.0721 LossAtt 1.0062 TrainAcc 0.4400 TestAcc 0.5761 0.4500
epoch 100 LossPred 0.8446 LossAtt 0.2798 TrainAcc 0.6800 TestAcc 0.6089 0.6800
epoch 200 LossPred 0.7027 LossAtt 0.2623 TrainAcc 0.7400 TestAcc 0.6652 0.7650
epoch 300 LossPred 0.2213 LossAtt 0.2336 TrainAcc 0.9500 TestAcc 0.8789 0.9150
epoch 400 LossPred 0.2592 LossAtt 0.2125 TrainAcc 0.9200 TestAcc 0.8611 0.9150
epoch 500 LossPred 0.1432 LossAtt 0.2070 TrainAcc 0.9500 TestAcc 0.9222 0.9500
epoch 600 LossPred 0.1217 LossAtt 0.2005 TrainAcc 0.9700 TestAcc 0.8986 0.9650
epoch 700 LossPred 0.0829 LossAtt 0.1882 TrainAcc 0.9800 TestAcc 0.9407 0.9700
epoch 800 LossPred 0.0861 LossAtt 0.1844 TrainAcc 0.9700 TestAcc 0.9342 0.9650
epoch 900 LossPred 0.1072 LossAtt 0.1768 TrainAcc 0.9800 TestAcc 0.9142 0.9600
epoch 1000 LossPred 0.0729 LossAtt 0.1779 TrainAcc 0.9800 TestAcc 0.9114 0.9750
epoch 1100 LossPred 0.2073 LossAtt 0.1704 TrainAcc 0.9300 TestAcc 0.8493 0.9100
epoch 1200 LossPred 0.1119 LossAtt 0.1668 TrainAcc 0.9700 TestAcc 0.9097 0.9650
epoch 1300 LossPred 0.0846 LossAtt 0.1745 TrainAcc 0.9700 TestAcc 0.9089 0.9700
epoch 1400 LossPred 0.0772 LossAtt 0.1751 TrainAcc 0.9700 TestAcc 0.8991 0.9800
epoch 1500 LossPred 0.0743 LossAtt 0.1869 TrainAcc 0.9900 TestAcc 0.9139 0.9750
epoch 1600 LossPred 0.0564 LossAtt 0.1839 TrainAcc 0.9800 TestAcc 0.9064 0.9850
epoch 1700 LossPred 0.0523 LossAtt 0.1877 TrainAcc 0.9900 TestAcc 0.9147 0.9800
epoch 1800 LossPred 0.0728 LossAtt 0.1789 TrainAcc 0.9700 TestAcc 0.8964 0.9800
epoch 1900 LossPred 0.0489 LossAtt 0.1823 TrainAcc 0.9900 TestAcc 0.9117 0.9850
epoch 2000 LossPred 0.1046 LossAtt 0.1774 TrainAcc 0.9700 TestAcc 0.8896 0.9700
epoch 2100 LossPred 0.0341 LossAtt 0.1944 TrainAcc 0.9900 TestAcc 0.9267 0.9900
epoch 2200 LossPred 0.0589 LossAtt 0.2097 TrainAcc 0.9800 TestAcc 0.9034 0.9800
epoch 2300 LossPred 0.0512 LossAtt 0.2048 TrainAcc 0.9900 TestAcc 0.9167 0.9850
epoch 2400 LossPred 0.2304 LossAtt 0.2034 TrainAcc 0.9200 TestAcc 0.9022 0.9350
epoch 2500 LossPred 0.0535 LossAtt 0.2116 TrainAcc 0.9800 TestAcc 0.9044 0.9900
Optimization Finished!
********** replication  66  **********
epoch   0 LossPred 1.0178 LossAtt 1.0355 TrainAcc 0.5500 TestAcc 0.5608 0.5700
epoch 100 LossPred 0.9073 LossAtt 0.2912 TrainAcc 0.6400 TestAcc 0.5678 0.6300
epoch 200 LossPred 0.8725 LossAtt 0.2617 TrainAcc 0.6400 TestAcc 0.5638 0.6500
epoch 300 LossPred 0.8151 LossAtt 0.2651 TrainAcc 0.6900 TestAcc 0.5773 0.6750
epoch 400 LossPred 0.7439 LossAtt 0.3320 TrainAcc 0.7200 TestAcc 0.6079 0.7150
epoch 500 LossPred 0.3689 LossAtt 0.3020 TrainAcc 0.8700 TestAcc 0.8151 0.8350
epoch 600 LossPred 0.1789 LossAtt 0.3127 TrainAcc 0.9600 TestAcc 0.8979 0.9050
epoch 700 LossPred 0.2254 LossAtt 0.3193 TrainAcc 0.9200 TestAcc 0.9094 0.8850
epoch 800 LossPred 0.0935 LossAtt 0.3111 TrainAcc 0.9800 TestAcc 0.9174 0.9600
epoch 900 LossPred 0.1004 LossAtt 0.3109 TrainAcc 0.9900 TestAcc 0.9304 0.9400
epoch 1000 LossPred 0.1077 LossAtt 0.3112 TrainAcc 0.9700 TestAcc 0.9084 0.9550
epoch 1100 LossPred 0.0676 LossAtt 0.2965 TrainAcc 1.0000 TestAcc 0.9279 0.9450
Optimization Finished!
********** replication  67  **********
epoch   0 LossPred 1.1801 LossAtt 1.0144 TrainAcc 0.4300 TestAcc 0.4394 0.4000
epoch 100 LossPred 0.9145 LossAtt 0.2412 TrainAcc 0.6300 TestAcc 0.6126 0.6250
epoch 200 LossPred 0.8558 LossAtt 0.2388 TrainAcc 0.6700 TestAcc 0.6902 0.6650
epoch 300 LossPred 0.3852 LossAtt 0.1982 TrainAcc 0.8700 TestAcc 0.8569 0.8700
epoch 400 LossPred 0.4050 LossAtt 0.1882 TrainAcc 0.8700 TestAcc 0.8501 0.8650
epoch 500 LossPred 0.3498 LossAtt 0.1812 TrainAcc 0.8900 TestAcc 0.8616 0.8550
epoch 600 LossPred 0.3495 LossAtt 0.1599 TrainAcc 0.8900 TestAcc 0.8619 0.8500
epoch 700 LossPred 0.3657 LossAtt 0.1591 TrainAcc 0.8800 TestAcc 0.8616 0.8450
epoch 800 LossPred 0.3746 LossAtt 0.1688 TrainAcc 0.8900 TestAcc 0.8636 0.8400
epoch 900 LossPred 0.4235 LossAtt 0.1531 TrainAcc 0.8700 TestAcc 0.8636 0.8350
epoch 1000 LossPred 0.3731 LossAtt 0.1600 TrainAcc 0.8700 TestAcc 0.8634 0.8350
epoch 1100 LossPred 0.2970 LossAtt 0.2114 TrainAcc 0.9000 TestAcc 0.8804 0.8900
epoch 1200 LossPred 0.3338 LossAtt 0.2156 TrainAcc 0.8800 TestAcc 0.8584 0.8750
epoch 1300 LossPred 0.2162 LossAtt 0.1965 TrainAcc 0.9300 TestAcc 0.9157 0.9450
epoch 1400 LossPred 0.2008 LossAtt 0.1821 TrainAcc 0.9500 TestAcc 0.9079 0.9450
epoch 1500 LossPred 0.3229 LossAtt 0.1743 TrainAcc 0.9000 TestAcc 0.8706 0.8850
epoch 1600 LossPred 0.1713 LossAtt 0.1723 TrainAcc 0.9600 TestAcc 0.9232 0.9600
epoch 1700 LossPred 0.1748 LossAtt 0.1652 TrainAcc 0.9500 TestAcc 0.9242 0.9550
epoch 1800 LossPred 0.2231 LossAtt 0.1631 TrainAcc 0.9300 TestAcc 0.9137 0.9200
epoch 1900 LossPred 0.1970 LossAtt 0.1700 TrainAcc 0.9300 TestAcc 0.9142 0.9350
epoch 2000 LossPred 0.1760 LossAtt 0.1631 TrainAcc 0.9400 TestAcc 0.9209 0.9450
epoch 2100 LossPred 0.1383 LossAtt 0.1526 TrainAcc 0.9600 TestAcc 0.9322 0.9550
epoch 2200 LossPred 0.3373 LossAtt 0.1508 TrainAcc 0.8800 TestAcc 0.8734 0.8750
epoch 2300 LossPred 0.1341 LossAtt 0.1624 TrainAcc 0.9600 TestAcc 0.9292 0.9550
epoch 2400 LossPred 0.2182 LossAtt 0.1543 TrainAcc 0.9500 TestAcc 0.9054 0.9300
epoch 2500 LossPred 0.2290 LossAtt 0.1671 TrainAcc 0.9300 TestAcc 0.8974 0.9150
Optimization Finished!
********** replication  68  **********
epoch   0 LossPred 0.9836 LossAtt 1.0199 TrainAcc 0.5300 TestAcc 0.5866 0.5300
epoch 100 LossPred 0.8488 LossAtt 0.2806 TrainAcc 0.6800 TestAcc 0.6254 0.6700
epoch 200 LossPred 0.5020 LossAtt 0.2964 TrainAcc 0.8400 TestAcc 0.7347 0.8150
epoch 300 LossPred 0.2987 LossAtt 0.2779 TrainAcc 0.9100 TestAcc 0.8363 0.9000
epoch 400 LossPred 0.1866 LossAtt 0.2532 TrainAcc 0.9500 TestAcc 0.8951 0.9150
epoch 500 LossPred 0.2693 LossAtt 0.2451 TrainAcc 0.8900 TestAcc 0.9104 0.9100
epoch 600 LossPred 0.1900 LossAtt 0.2251 TrainAcc 0.9300 TestAcc 0.9319 0.9250
epoch 700 LossPred 0.3249 LossAtt 0.1989 TrainAcc 0.8800 TestAcc 0.8136 0.8900
epoch 800 LossPred 0.2302 LossAtt 0.2208 TrainAcc 0.9100 TestAcc 0.9152 0.9200
epoch 900 LossPred 0.2749 LossAtt 0.2256 TrainAcc 0.9100 TestAcc 0.9029 0.9150
epoch 1000 LossPred 0.2457 LossAtt 0.2349 TrainAcc 0.9100 TestAcc 0.9124 0.9000
epoch 1100 LossPred 0.1556 LossAtt 0.2353 TrainAcc 0.9600 TestAcc 0.8964 0.9500
epoch 1200 LossPred 0.2362 LossAtt 0.2417 TrainAcc 0.9300 TestAcc 0.8706 0.9150
epoch 1300 LossPred 0.3458 LossAtt 0.2291 TrainAcc 0.8900 TestAcc 0.8226 0.9000
epoch 1400 LossPred 0.1689 LossAtt 0.2260 TrainAcc 0.9400 TestAcc 0.9132 0.9450
epoch 1500 LossPred 0.2589 LossAtt 0.2064 TrainAcc 0.9200 TestAcc 0.8799 0.9250
epoch 1600 LossPred 0.2950 LossAtt 0.2131 TrainAcc 0.8900 TestAcc 0.8396 0.9050
epoch 1700 LossPred 0.3246 LossAtt 0.2090 TrainAcc 0.9000 TestAcc 0.8313 0.9000
epoch 1800 LossPred 0.1863 LossAtt 0.2137 TrainAcc 0.9500 TestAcc 0.9177 0.9200
epoch 1900 LossPred 0.2561 LossAtt 0.2076 TrainAcc 0.9200 TestAcc 0.8904 0.8800
epoch 2000 LossPred 0.1836 LossAtt 0.1987 TrainAcc 0.9300 TestAcc 0.8911 0.9300
epoch 2100 LossPred 0.1406 LossAtt 0.1997 TrainAcc 0.9500 TestAcc 0.9319 0.9600
epoch 2200 LossPred 0.1463 LossAtt 0.2158 TrainAcc 0.9500 TestAcc 0.9119 0.9450
epoch 2300 LossPred 0.1502 LossAtt 0.2177 TrainAcc 0.9500 TestAcc 0.9199 0.9450
epoch 2400 LossPred 0.1612 LossAtt 0.2155 TrainAcc 0.9500 TestAcc 0.9247 0.9350
epoch 2500 LossPred 0.0861 LossAtt 0.2208 TrainAcc 0.9700 TestAcc 0.9575 0.9800
Optimization Finished!
********** replication  69  **********
epoch   0 LossPred 1.0537 LossAtt 1.0055 TrainAcc 0.4400 TestAcc 0.4717 0.4500
epoch 100 LossPred 0.9199 LossAtt 0.3373 TrainAcc 0.5900 TestAcc 0.5998 0.6050
epoch 200 LossPred 0.2863 LossAtt 0.3114 TrainAcc 0.9200 TestAcc 0.8816 0.9050
epoch 300 LossPred 0.1850 LossAtt 0.3014 TrainAcc 0.9500 TestAcc 0.8921 0.9150
epoch 400 LossPred 0.0852 LossAtt 0.2859 TrainAcc 0.9800 TestAcc 0.9427 0.9500
epoch 500 LossPred 0.1109 LossAtt 0.2701 TrainAcc 0.9900 TestAcc 0.9397 0.9500
epoch 600 LossPred 0.1903 LossAtt 0.2589 TrainAcc 0.9400 TestAcc 0.9434 0.8750
epoch 700 LossPred 0.0523 LossAtt 0.2482 TrainAcc 0.9900 TestAcc 0.9600 0.9700
epoch 800 LossPred 0.0616 LossAtt 0.2399 TrainAcc 0.9900 TestAcc 0.9137 0.9600
epoch 900 LossPred 0.0471 LossAtt 0.2414 TrainAcc 1.0000 TestAcc 0.9647 0.9500
Optimization Finished!
********** replication  70  **********
epoch   0 LossPred 1.0577 LossAtt 0.9847 TrainAcc 0.4300 TestAcc 0.4314 0.4250
epoch 100 LossPred 0.8852 LossAtt 0.2918 TrainAcc 0.6700 TestAcc 0.6334 0.6650
epoch 200 LossPred 0.4189 LossAtt 0.3251 TrainAcc 0.8700 TestAcc 0.8766 0.8650
epoch 300 LossPred 0.4146 LossAtt 0.2863 TrainAcc 0.8800 TestAcc 0.8714 0.8550
epoch 400 LossPred 0.4489 LossAtt 0.2800 TrainAcc 0.8400 TestAcc 0.7923 0.8600
epoch 500 LossPred 0.1436 LossAtt 0.2552 TrainAcc 0.9700 TestAcc 0.8786 0.9350
epoch 600 LossPred 0.3034 LossAtt 0.2293 TrainAcc 0.9100 TestAcc 0.8829 0.8850
epoch 700 LossPred 0.1663 LossAtt 0.2196 TrainAcc 0.9500 TestAcc 0.8949 0.9250
epoch 800 LossPred 0.1777 LossAtt 0.2064 TrainAcc 0.9400 TestAcc 0.8709 0.9200
epoch 900 LossPred 0.1001 LossAtt 0.2077 TrainAcc 0.9700 TestAcc 0.8856 0.9550
epoch 1000 LossPred 0.1049 LossAtt 0.2013 TrainAcc 0.9700 TestAcc 0.8881 0.9500
epoch 1100 LossPred 0.1074 LossAtt 0.1979 TrainAcc 0.9700 TestAcc 0.8966 0.9550
epoch 1200 LossPred 0.0921 LossAtt 0.1856 TrainAcc 0.9700 TestAcc 0.8879 0.9600
epoch 1300 LossPred 0.1282 LossAtt 0.1874 TrainAcc 0.9600 TestAcc 0.8809 0.9400
epoch 1400 LossPred 0.0839 LossAtt 0.1745 TrainAcc 0.9700 TestAcc 0.8991 0.9600
epoch 1500 LossPred 0.4451 LossAtt 0.1893 TrainAcc 0.8800 TestAcc 0.7895 0.8650
epoch 1600 LossPred 0.0840 LossAtt 0.1747 TrainAcc 0.9700 TestAcc 0.9039 0.9550
epoch 1700 LossPred 0.1466 LossAtt 0.1675 TrainAcc 0.9600 TestAcc 0.8704 0.9300
epoch 1800 LossPred 0.1119 LossAtt 0.1709 TrainAcc 0.9700 TestAcc 0.8721 0.9400
epoch 1900 LossPred 0.0688 LossAtt 0.1578 TrainAcc 0.9800 TestAcc 0.9079 0.9650
epoch 2000 LossPred 0.1903 LossAtt 0.1678 TrainAcc 0.9400 TestAcc 0.8519 0.9150
epoch 2100 LossPred 0.1606 LossAtt 0.1567 TrainAcc 0.9500 TestAcc 0.9154 0.9450
epoch 2200 LossPred 0.1665 LossAtt 0.1540 TrainAcc 0.9500 TestAcc 0.8501 0.9250
epoch 2300 LossPred 0.0955 LossAtt 0.1595 TrainAcc 0.9700 TestAcc 0.8794 0.9550
epoch 2400 LossPred 0.0993 LossAtt 0.1528 TrainAcc 0.9700 TestAcc 0.9189 0.9550
epoch 2500 LossPred 0.1056 LossAtt 0.1470 TrainAcc 0.9600 TestAcc 0.9054 0.9500
Optimization Finished!
********** replication  71  **********
epoch   0 LossPred 0.9749 LossAtt 0.9865 TrainAcc 0.5500 TestAcc 0.5270 0.5550
epoch 100 LossPred 0.9252 LossAtt 0.2690 TrainAcc 0.6200 TestAcc 0.6011 0.6200
epoch 200 LossPred 0.4887 LossAtt 0.2093 TrainAcc 0.8400 TestAcc 0.8436 0.8400
epoch 300 LossPred 0.4369 LossAtt 0.1926 TrainAcc 0.8800 TestAcc 0.8559 0.8500
epoch 400 LossPred 0.4183 LossAtt 0.1897 TrainAcc 0.8700 TestAcc 0.8611 0.8550
epoch 500 LossPred 0.4113 LossAtt 0.1749 TrainAcc 0.8700 TestAcc 0.8641 0.8550
epoch 600 LossPred 0.4159 LossAtt 0.1817 TrainAcc 0.8800 TestAcc 0.8636 0.8500
epoch 700 LossPred 0.3979 LossAtt 0.1846 TrainAcc 0.8800 TestAcc 0.8679 0.8600
epoch 800 LossPred 0.3822 LossAtt 0.1854 TrainAcc 0.8900 TestAcc 0.8696 0.8600
epoch 900 LossPred 0.3637 LossAtt 0.1782 TrainAcc 0.8800 TestAcc 0.8726 0.8600
epoch 1000 LossPred 0.3463 LossAtt 0.1855 TrainAcc 0.9000 TestAcc 0.8861 0.8650
epoch 1100 LossPred 0.3364 LossAtt 0.1925 TrainAcc 0.8900 TestAcc 0.8786 0.8800
epoch 1200 LossPred 0.3156 LossAtt 0.1845 TrainAcc 0.9000 TestAcc 0.8854 0.8650
epoch 1300 LossPred 0.3036 LossAtt 0.1937 TrainAcc 0.9100 TestAcc 0.8919 0.8800
epoch 1400 LossPred 0.2514 LossAtt 0.1945 TrainAcc 0.9200 TestAcc 0.9114 0.8900
epoch 1500 LossPred 0.2327 LossAtt 0.1897 TrainAcc 0.9200 TestAcc 0.8866 0.8950
epoch 1600 LossPred 0.1901 LossAtt 0.1984 TrainAcc 0.9600 TestAcc 0.9277 0.9050
epoch 1700 LossPred 0.2008 LossAtt 0.1859 TrainAcc 0.9300 TestAcc 0.9154 0.9050
epoch 1800 LossPred 0.3124 LossAtt 0.1848 TrainAcc 0.9000 TestAcc 0.8899 0.8800
epoch 1900 LossPred 0.1653 LossAtt 0.1917 TrainAcc 0.9400 TestAcc 0.9147 0.9250
epoch 2000 LossPred 0.2238 LossAtt 0.1880 TrainAcc 0.9000 TestAcc 0.8844 0.9100
epoch 2100 LossPred 0.1418 LossAtt 0.1924 TrainAcc 0.9500 TestAcc 0.9252 0.9300
epoch 2200 LossPred 0.1945 LossAtt 0.1710 TrainAcc 0.9300 TestAcc 0.9302 0.9050
epoch 2300 LossPred 0.1787 LossAtt 0.1601 TrainAcc 0.9500 TestAcc 0.9227 0.8950
epoch 2400 LossPred 0.2416 LossAtt 0.1611 TrainAcc 0.9000 TestAcc 0.8781 0.9100
epoch 2500 LossPred 0.2390 LossAtt 0.1722 TrainAcc 0.9100 TestAcc 0.8821 0.9100
Optimization Finished!
********** replication  72  **********
epoch   0 LossPred 1.1529 LossAtt 1.0335 TrainAcc 0.3700 TestAcc 0.4009 0.4050
epoch 100 LossPred 0.9183 LossAtt 0.2875 TrainAcc 0.6300 TestAcc 0.5991 0.6300
epoch 200 LossPred 0.3878 LossAtt 0.2689 TrainAcc 0.9100 TestAcc 0.8383 0.9000
epoch 300 LossPred 0.2638 LossAtt 0.2495 TrainAcc 0.9100 TestAcc 0.8706 0.9050
epoch 400 LossPred 0.2469 LossAtt 0.2617 TrainAcc 0.9100 TestAcc 0.8671 0.9250
epoch 500 LossPred 0.2359 LossAtt 0.2394 TrainAcc 0.9100 TestAcc 0.8741 0.9250
epoch 600 LossPred 0.2324 LossAtt 0.2605 TrainAcc 0.9100 TestAcc 0.9004 0.9150
epoch 700 LossPred 0.1954 LossAtt 0.2398 TrainAcc 0.9400 TestAcc 0.8974 0.9300
epoch 800 LossPred 0.1763 LossAtt 0.2335 TrainAcc 0.9600 TestAcc 0.9174 0.9450
epoch 900 LossPred 0.1254 LossAtt 0.2322 TrainAcc 0.9700 TestAcc 0.8929 0.9300
epoch 1000 LossPred 0.1128 LossAtt 0.2329 TrainAcc 0.9800 TestAcc 0.8961 0.9350
epoch 1100 LossPred 0.1871 LossAtt 0.2236 TrainAcc 0.9300 TestAcc 0.8544 0.8850
epoch 1200 LossPred 0.1359 LossAtt 0.2201 TrainAcc 0.9600 TestAcc 0.8809 0.9250
epoch 1300 LossPred 0.0966 LossAtt 0.2196 TrainAcc 0.9800 TestAcc 0.8909 0.9350
epoch 1400 LossPred 0.0981 LossAtt 0.2098 TrainAcc 0.9800 TestAcc 0.8856 0.9300
epoch 1500 LossPred 0.0939 LossAtt 0.2047 TrainAcc 0.9800 TestAcc 0.8846 0.9300
epoch 1600 LossPred 0.1739 LossAtt 0.1881 TrainAcc 0.9200 TestAcc 0.8839 0.9250
epoch 1700 LossPred 0.0855 LossAtt 0.1911 TrainAcc 0.9900 TestAcc 0.8809 0.9300
epoch 1800 LossPred 0.0910 LossAtt 0.1923 TrainAcc 0.9800 TestAcc 0.8929 0.9350
epoch 1900 LossPred 0.0794 LossAtt 0.2010 TrainAcc 0.9800 TestAcc 0.8901 0.9500
epoch 2000 LossPred 0.1315 LossAtt 0.1921 TrainAcc 0.9600 TestAcc 0.8896 0.9450
epoch 2100 LossPred 0.1128 LossAtt 0.1908 TrainAcc 0.9700 TestAcc 0.8984 0.9500
epoch 2200 LossPred 0.0800 LossAtt 0.1787 TrainAcc 0.9900 TestAcc 0.8884 0.9400
epoch 2300 LossPred 0.0720 LossAtt 0.1767 TrainAcc 0.9900 TestAcc 0.8834 0.9400
epoch 2400 LossPred 0.1658 LossAtt 0.1682 TrainAcc 0.9300 TestAcc 0.8756 0.9050
epoch 2500 LossPred 0.0763 LossAtt 0.1670 TrainAcc 0.9800 TestAcc 0.8836 0.9450
Optimization Finished!
********** replication  73  **********
epoch   0 LossPred 0.9795 LossAtt 1.0245 TrainAcc 0.6200 TestAcc 0.6079 0.6200
epoch 100 LossPred 0.8451 LossAtt 0.2746 TrainAcc 0.6900 TestAcc 0.5958 0.7050
epoch 200 LossPred 0.8336 LossAtt 0.2284 TrainAcc 0.6900 TestAcc 0.6101 0.7000
epoch 300 LossPred 0.7983 LossAtt 0.2660 TrainAcc 0.6900 TestAcc 0.6101 0.6900
epoch 400 LossPred 0.5306 LossAtt 0.3170 TrainAcc 0.8200 TestAcc 0.7172 0.8150
epoch 500 LossPred 0.4309 LossAtt 0.3138 TrainAcc 0.8200 TestAcc 0.8293 0.8200
epoch 600 LossPred 0.4453 LossAtt 0.2783 TrainAcc 0.8200 TestAcc 0.8341 0.8250
epoch 700 LossPred 0.2931 LossAtt 0.2693 TrainAcc 0.8700 TestAcc 0.8611 0.8750
epoch 800 LossPred 0.1653 LossAtt 0.2622 TrainAcc 0.9500 TestAcc 0.9377 0.9550
epoch 900 LossPred 0.2541 LossAtt 0.2572 TrainAcc 0.9300 TestAcc 0.9054 0.9000
epoch 1000 LossPred 0.2406 LossAtt 0.2386 TrainAcc 0.9200 TestAcc 0.9287 0.8900
epoch 1100 LossPred 0.3730 LossAtt 0.2190 TrainAcc 0.8800 TestAcc 0.8634 0.8600
epoch 1200 LossPred 0.3414 LossAtt 0.2102 TrainAcc 0.8800 TestAcc 0.8721 0.8750
epoch 1300 LossPred 0.4967 LossAtt 0.1960 TrainAcc 0.7800 TestAcc 0.8051 0.7850
epoch 1400 LossPred 0.2607 LossAtt 0.1975 TrainAcc 0.8900 TestAcc 0.9077 0.8900
epoch 1500 LossPred 0.4482 LossAtt 0.1834 TrainAcc 0.8000 TestAcc 0.8321 0.7900
epoch 1600 LossPred 0.4785 LossAtt 0.1875 TrainAcc 0.8000 TestAcc 0.8318 0.7950
epoch 1700 LossPred 0.3989 LossAtt 0.1813 TrainAcc 0.8400 TestAcc 0.8453 0.8050
epoch 1800 LossPred 0.1701 LossAtt 0.1935 TrainAcc 0.9600 TestAcc 0.9364 0.9200
epoch 1900 LossPred 0.2458 LossAtt 0.1991 TrainAcc 0.9000 TestAcc 0.9104 0.8900
epoch 2000 LossPred 0.2564 LossAtt 0.1949 TrainAcc 0.9200 TestAcc 0.9149 0.8850
epoch 2100 LossPred 0.3621 LossAtt 0.1979 TrainAcc 0.8600 TestAcc 0.8629 0.8900
epoch 2200 LossPred 0.2717 LossAtt 0.2069 TrainAcc 0.8900 TestAcc 0.8901 0.9000
epoch 2300 LossPred 0.3016 LossAtt 0.1950 TrainAcc 0.8800 TestAcc 0.9192 0.8800
epoch 2400 LossPred 0.2189 LossAtt 0.2150 TrainAcc 0.9300 TestAcc 0.9459 0.9300
epoch 2500 LossPred 0.2342 LossAtt 0.2074 TrainAcc 0.9200 TestAcc 0.9277 0.8950
Optimization Finished!
********** replication  74  **********
epoch   0 LossPred 0.9944 LossAtt 1.0427 TrainAcc 0.5300 TestAcc 0.5506 0.5400
epoch 100 LossPred 0.9323 LossAtt 0.2671 TrainAcc 0.6200 TestAcc 0.6031 0.6200
epoch 200 LossPred 0.2996 LossAtt 0.2742 TrainAcc 0.9200 TestAcc 0.8348 0.8900
epoch 300 LossPred 0.2668 LossAtt 0.2408 TrainAcc 0.9100 TestAcc 0.8714 0.8950
epoch 400 LossPred 0.2029 LossAtt 0.2267 TrainAcc 0.9500 TestAcc 0.8566 0.8950
epoch 500 LossPred 0.2844 LossAtt 0.2141 TrainAcc 0.9000 TestAcc 0.8756 0.8950
epoch 600 LossPred 0.2427 LossAtt 0.2169 TrainAcc 0.9100 TestAcc 0.8714 0.9000
epoch 700 LossPred 0.2484 LossAtt 0.2032 TrainAcc 0.9200 TestAcc 0.8774 0.8900
epoch 800 LossPred 0.1867 LossAtt 0.2074 TrainAcc 0.9700 TestAcc 0.8691 0.9100
epoch 900 LossPred 0.4185 LossAtt 0.1951 TrainAcc 0.8700 TestAcc 0.8073 0.8650
epoch 1000 LossPred 0.2117 LossAtt 0.2048 TrainAcc 0.9300 TestAcc 0.8766 0.9100
epoch 1100 LossPred 0.2186 LossAtt 0.1969 TrainAcc 0.9100 TestAcc 0.8721 0.9150
epoch 1200 LossPred 0.3399 LossAtt 0.2006 TrainAcc 0.8800 TestAcc 0.8876 0.8750
epoch 1300 LossPred 0.2235 LossAtt 0.2024 TrainAcc 0.9200 TestAcc 0.8864 0.9200
epoch 1400 LossPred 0.2241 LossAtt 0.1969 TrainAcc 0.9400 TestAcc 0.9117 0.9000
epoch 1500 LossPred 0.1790 LossAtt 0.1972 TrainAcc 0.9500 TestAcc 0.8864 0.9000
epoch 1600 LossPred 0.1764 LossAtt 0.1897 TrainAcc 0.9400 TestAcc 0.9009 0.9150
epoch 1700 LossPred 0.1717 LossAtt 0.1999 TrainAcc 0.9400 TestAcc 0.9029 0.9150
epoch 1800 LossPred 0.1631 LossAtt 0.2015 TrainAcc 0.9400 TestAcc 0.9147 0.9100
epoch 1900 LossPred 0.1328 LossAtt 0.1958 TrainAcc 0.9500 TestAcc 0.9129 0.9250
epoch 2000 LossPred 0.1141 LossAtt 0.2122 TrainAcc 0.9600 TestAcc 0.9159 0.9350
epoch 2100 LossPred 0.1170 LossAtt 0.1879 TrainAcc 0.9600 TestAcc 0.9149 0.9350
epoch 2200 LossPred 0.1386 LossAtt 0.1947 TrainAcc 0.9600 TestAcc 0.9042 0.9050
epoch 2300 LossPred 0.1247 LossAtt 0.1865 TrainAcc 0.9600 TestAcc 0.9054 0.9300
epoch 2400 LossPred 0.2234 LossAtt 0.1866 TrainAcc 0.9200 TestAcc 0.8774 0.8800
epoch 2500 LossPred 0.1311 LossAtt 0.1793 TrainAcc 0.9500 TestAcc 0.9487 0.9250
Optimization Finished!
********** replication  75  **********
epoch   0 LossPred 1.0145 LossAtt 1.0165 TrainAcc 0.5400 TestAcc 0.5280 0.5100
epoch 100 LossPred 0.8201 LossAtt 0.2727 TrainAcc 0.7400 TestAcc 0.6434 0.7050
epoch 200 LossPred 0.2936 LossAtt 0.2783 TrainAcc 0.9100 TestAcc 0.8734 0.8900
epoch 300 LossPred 0.1451 LossAtt 0.2840 TrainAcc 0.9500 TestAcc 0.8956 0.9450
epoch 400 LossPred 0.1704 LossAtt 0.2690 TrainAcc 0.9500 TestAcc 0.8801 0.9550
epoch 500 LossPred 0.1400 LossAtt 0.2824 TrainAcc 0.9400 TestAcc 0.8984 0.9500
epoch 600 LossPred 0.1285 LossAtt 0.2673 TrainAcc 0.9600 TestAcc 0.8879 0.9550
epoch 700 LossPred 0.0865 LossAtt 0.2600 TrainAcc 0.9800 TestAcc 0.8991 0.9550
epoch 800 LossPred 0.0867 LossAtt 0.2536 TrainAcc 0.9600 TestAcc 0.9079 0.9600
epoch 900 LossPred 0.0632 LossAtt 0.2518 TrainAcc 0.9800 TestAcc 0.9032 0.9800
epoch 1000 LossPred 0.1258 LossAtt 0.2704 TrainAcc 0.9500 TestAcc 0.8984 0.9500
epoch 1100 LossPred 0.0750 LossAtt 0.2568 TrainAcc 0.9800 TestAcc 0.9112 0.9500
epoch 1200 LossPred 0.0958 LossAtt 0.2737 TrainAcc 0.9600 TestAcc 0.8976 0.9650
epoch 1300 LossPred 0.0552 LossAtt 0.2634 TrainAcc 0.9800 TestAcc 0.9052 0.9600
epoch 1400 LossPred 0.0429 LossAtt 0.2594 TrainAcc 0.9900 TestAcc 0.9179 0.9700
epoch 1500 LossPred 0.0451 LossAtt 0.2620 TrainAcc 0.9800 TestAcc 0.9207 0.9650
epoch 1600 LossPred 0.0657 LossAtt 0.2773 TrainAcc 0.9700 TestAcc 0.9212 0.9650
epoch 1700 LossPred 0.0311 LossAtt 0.2881 TrainAcc 0.9900 TestAcc 0.9224 0.9700
epoch 1800 LossPred 0.0557 LossAtt 0.2848 TrainAcc 0.9900 TestAcc 0.8954 0.9750
epoch 1900 LossPred 0.0158 LossAtt 0.2842 TrainAcc 1.0000 TestAcc 0.9154 0.9850
Optimization Finished!
********** replication  76  **********
epoch   0 LossPred 1.4382 LossAtt 1.0506 TrainAcc 0.3800 TestAcc 0.4199 0.3650
epoch 100 LossPred 0.9111 LossAtt 0.3327 TrainAcc 0.6300 TestAcc 0.6044 0.6400
epoch 200 LossPred 0.5412 LossAtt 0.2984 TrainAcc 0.8400 TestAcc 0.8333 0.8450
epoch 300 LossPred 0.4675 LossAtt 0.2684 TrainAcc 0.8500 TestAcc 0.8616 0.8250
epoch 400 LossPred 0.3470 LossAtt 0.2627 TrainAcc 0.9100 TestAcc 0.9007 0.8750
epoch 500 LossPred 0.3618 LossAtt 0.2837 TrainAcc 0.8800 TestAcc 0.8453 0.8500
epoch 600 LossPred 0.2577 LossAtt 0.2741 TrainAcc 0.9200 TestAcc 0.8959 0.9150
epoch 700 LossPred 0.2271 LossAtt 0.2555 TrainAcc 0.9300 TestAcc 0.9087 0.9350
epoch 800 LossPred 0.1506 LossAtt 0.2417 TrainAcc 0.9800 TestAcc 0.9407 0.9750
epoch 900 LossPred 0.1516 LossAtt 0.2419 TrainAcc 0.9800 TestAcc 0.9327 0.9750
epoch 1000 LossPred 0.6272 LossAtt 0.2637 TrainAcc 0.7800 TestAcc 0.7548 0.7850
epoch 1100 LossPred 0.2840 LossAtt 0.2366 TrainAcc 0.9100 TestAcc 0.8881 0.8900
epoch 1200 LossPred 0.2294 LossAtt 0.2511 TrainAcc 0.9300 TestAcc 0.8591 0.9250
epoch 1300 LossPred 0.1077 LossAtt 0.2349 TrainAcc 0.9700 TestAcc 0.9327 0.9800
epoch 1400 LossPred 0.1072 LossAtt 0.2273 TrainAcc 0.9700 TestAcc 0.9354 0.9750
epoch 1500 LossPred 0.1464 LossAtt 0.2433 TrainAcc 0.9600 TestAcc 0.9052 0.9700
epoch 1600 LossPred 0.1434 LossAtt 0.2513 TrainAcc 0.9500 TestAcc 0.9079 0.9450
epoch 1700 LossPred 0.1793 LossAtt 0.2447 TrainAcc 0.9100 TestAcc 0.8876 0.9100
epoch 1800 LossPred 0.1625 LossAtt 0.2529 TrainAcc 0.9300 TestAcc 0.8879 0.9300
epoch 1900 LossPred 0.1855 LossAtt 0.2435 TrainAcc 0.9600 TestAcc 0.9069 0.9600
epoch 2000 LossPred 0.1618 LossAtt 0.2514 TrainAcc 0.9700 TestAcc 0.9227 0.9650
epoch 2100 LossPred 0.1335 LossAtt 0.2285 TrainAcc 0.9600 TestAcc 0.9237 0.9650
epoch 2200 LossPred 0.1468 LossAtt 0.2391 TrainAcc 0.9600 TestAcc 0.9142 0.9650
epoch 2300 LossPred 0.3011 LossAtt 0.2187 TrainAcc 0.9300 TestAcc 0.8739 0.8950
epoch 2400 LossPred 0.1771 LossAtt 0.2080 TrainAcc 0.9500 TestAcc 0.9032 0.9500
epoch 2500 LossPred 0.1114 LossAtt 0.2093 TrainAcc 0.9700 TestAcc 0.9249 0.9650
Optimization Finished!
********** replication  77  **********
epoch   0 LossPred 1.0086 LossAtt 1.0253 TrainAcc 0.5300 TestAcc 0.4885 0.5300
epoch 100 LossPred 0.9415 LossAtt 0.2918 TrainAcc 0.6100 TestAcc 0.6269 0.6000
epoch 200 LossPred 0.3275 LossAtt 0.3283 TrainAcc 0.8900 TestAcc 0.9027 0.8750
epoch 300 LossPred 0.2046 LossAtt 0.2895 TrainAcc 0.9500 TestAcc 0.9279 0.9000
epoch 400 LossPred 0.6011 LossAtt 0.3031 TrainAcc 0.8200 TestAcc 0.7673 0.8000
epoch 500 LossPred 0.3683 LossAtt 0.3026 TrainAcc 0.8700 TestAcc 0.8186 0.8750
epoch 600 LossPred 0.2937 LossAtt 0.2870 TrainAcc 0.9000 TestAcc 0.8488 0.8900
epoch 700 LossPred 0.2599 LossAtt 0.2935 TrainAcc 0.9200 TestAcc 0.8661 0.9300
epoch 800 LossPred 0.1825 LossAtt 0.2766 TrainAcc 0.9500 TestAcc 0.9384 0.9400
epoch 900 LossPred 0.2024 LossAtt 0.2686 TrainAcc 0.9500 TestAcc 0.9172 0.9450
epoch 1000 LossPred 0.2887 LossAtt 0.2578 TrainAcc 0.8900 TestAcc 0.8609 0.8950
epoch 1100 LossPred 0.1852 LossAtt 0.2408 TrainAcc 0.9300 TestAcc 0.9192 0.9300
epoch 1200 LossPred 0.1443 LossAtt 0.2477 TrainAcc 0.9400 TestAcc 0.9432 0.9450
epoch 1300 LossPred 0.2379 LossAtt 0.2315 TrainAcc 0.9400 TestAcc 0.9017 0.9400
epoch 1400 LossPred 0.1666 LossAtt 0.2336 TrainAcc 0.9300 TestAcc 0.9139 0.9350
epoch 1500 LossPred 0.3701 LossAtt 0.2346 TrainAcc 0.8900 TestAcc 0.8559 0.8750
epoch 1600 LossPred 0.1158 LossAtt 0.2298 TrainAcc 0.9600 TestAcc 0.9289 0.9500
epoch 1700 LossPred 0.1611 LossAtt 0.2328 TrainAcc 0.9500 TestAcc 0.9137 0.9600
epoch 1800 LossPred 0.3200 LossAtt 0.2237 TrainAcc 0.9000 TestAcc 0.8751 0.9050
epoch 1900 LossPred 0.1141 LossAtt 0.2176 TrainAcc 0.9700 TestAcc 0.9334 0.9700
epoch 2000 LossPred 0.1714 LossAtt 0.2342 TrainAcc 0.9300 TestAcc 0.8886 0.9250
epoch 2100 LossPred 0.1560 LossAtt 0.2219 TrainAcc 0.9600 TestAcc 0.9147 0.9600
epoch 2200 LossPred 0.1889 LossAtt 0.2252 TrainAcc 0.9300 TestAcc 0.8861 0.9350
epoch 2300 LossPred 0.0632 LossAtt 0.2211 TrainAcc 0.9700 TestAcc 0.9397 0.9800
epoch 2400 LossPred 0.0585 LossAtt 0.2150 TrainAcc 0.9900 TestAcc 0.9605 0.9900
epoch 2500 LossPred 0.1019 LossAtt 0.2263 TrainAcc 0.9700 TestAcc 0.9174 0.9650
Optimization Finished!
********** replication  78  **********
epoch   0 LossPred 1.1416 LossAtt 1.0064 TrainAcc 0.4900 TestAcc 0.5045 0.5300
epoch 100 LossPred 0.9384 LossAtt 0.2739 TrainAcc 0.5800 TestAcc 0.6316 0.5850
epoch 200 LossPred 0.3094 LossAtt 0.2848 TrainAcc 0.9500 TestAcc 0.9067 0.9500
epoch 300 LossPred 0.1846 LossAtt 0.2427 TrainAcc 0.9400 TestAcc 0.9064 0.9150
epoch 400 LossPred 0.2034 LossAtt 0.2213 TrainAcc 0.9500 TestAcc 0.9252 0.9500
epoch 500 LossPred 0.2563 LossAtt 0.2217 TrainAcc 0.9200 TestAcc 0.8644 0.9050
epoch 600 LossPred 0.2619 LossAtt 0.2057 TrainAcc 0.9000 TestAcc 0.8884 0.9050
epoch 700 LossPred 0.2681 LossAtt 0.2296 TrainAcc 0.9100 TestAcc 0.8626 0.8900
epoch 800 LossPred 0.1440 LossAtt 0.2118 TrainAcc 0.9400 TestAcc 0.9247 0.9450
epoch 900 LossPred 0.1199 LossAtt 0.2159 TrainAcc 0.9600 TestAcc 0.9369 0.9550
epoch 1000 LossPred 0.1051 LossAtt 0.2124 TrainAcc 0.9600 TestAcc 0.9692 0.9650
epoch 1100 LossPred 0.1393 LossAtt 0.2228 TrainAcc 0.9600 TestAcc 0.9542 0.9550
epoch 1200 LossPred 0.4018 LossAtt 0.2171 TrainAcc 0.8500 TestAcc 0.8426 0.8400
epoch 1300 LossPred 0.2728 LossAtt 0.2316 TrainAcc 0.8800 TestAcc 0.8834 0.8900
epoch 1400 LossPred 0.3070 LossAtt 0.2275 TrainAcc 0.8900 TestAcc 0.8689 0.8850
epoch 1500 LossPred 0.1995 LossAtt 0.2377 TrainAcc 0.9500 TestAcc 0.9167 0.9550
epoch 1600 LossPred 0.1900 LossAtt 0.2423 TrainAcc 0.9600 TestAcc 0.9092 0.9600
epoch 1700 LossPred 0.2818 LossAtt 0.2483 TrainAcc 0.8900 TestAcc 0.8614 0.8800
epoch 1800 LossPred 0.1882 LossAtt 0.2438 TrainAcc 0.9400 TestAcc 0.8899 0.9200
epoch 1900 LossPred 0.1818 LossAtt 0.2600 TrainAcc 0.9300 TestAcc 0.8944 0.9200
epoch 2000 LossPred 0.1051 LossAtt 0.2605 TrainAcc 0.9700 TestAcc 0.9319 0.9650
epoch 2100 LossPred 0.1082 LossAtt 0.2703 TrainAcc 0.9700 TestAcc 0.9282 0.9600
epoch 2200 LossPred 0.0970 LossAtt 0.2702 TrainAcc 0.9600 TestAcc 0.9342 0.9600
epoch 2300 LossPred 0.1039 LossAtt 0.2575 TrainAcc 0.9600 TestAcc 0.9259 0.9550
epoch 2400 LossPred 0.0853 LossAtt 0.2523 TrainAcc 0.9600 TestAcc 0.9362 0.9700
epoch 2500 LossPred 0.0625 LossAtt 0.2500 TrainAcc 0.9700 TestAcc 0.9419 0.9750
Optimization Finished!
********** replication  79  **********
epoch   0 LossPred 1.2002 LossAtt 1.0202 TrainAcc 0.4000 TestAcc 0.3999 0.4700
epoch 100 LossPred 0.9363 LossAtt 0.2793 TrainAcc 0.6200 TestAcc 0.5513 0.6150
epoch 200 LossPred 0.8850 LossAtt 0.2522 TrainAcc 0.6500 TestAcc 0.5641 0.6650
epoch 300 LossPred 0.8575 LossAtt 0.2361 TrainAcc 0.6600 TestAcc 0.5335 0.6400
epoch 400 LossPred 0.8234 LossAtt 0.2284 TrainAcc 0.6900 TestAcc 0.5603 0.6850
epoch 500 LossPred 0.8123 LossAtt 0.2455 TrainAcc 0.6800 TestAcc 0.5603 0.6850
epoch 600 LossPred 0.8048 LossAtt 0.2475 TrainAcc 0.7000 TestAcc 0.5611 0.6850
epoch 700 LossPred 0.7870 LossAtt 0.2911 TrainAcc 0.7600 TestAcc 0.5958 0.7400
epoch 800 LossPred 0.7224 LossAtt 0.3498 TrainAcc 0.7700 TestAcc 0.5998 0.7650
epoch 900 LossPred 0.6454 LossAtt 0.4244 TrainAcc 0.7600 TestAcc 0.6066 0.7350
epoch 1000 LossPred 0.4833 LossAtt 0.3846 TrainAcc 0.8700 TestAcc 0.6592 0.8300
epoch 1100 LossPred 0.6329 LossAtt 0.4013 TrainAcc 0.7500 TestAcc 0.6639 0.7550
epoch 1200 LossPred 0.3271 LossAtt 0.3876 TrainAcc 0.9100 TestAcc 0.7735 0.8850
epoch 1300 LossPred 0.2440 LossAtt 0.3852 TrainAcc 0.9500 TestAcc 0.7915 0.8800
epoch 1400 LossPred 0.2514 LossAtt 0.3627 TrainAcc 0.9500 TestAcc 0.7860 0.9250
epoch 1500 LossPred 0.2158 LossAtt 0.3821 TrainAcc 0.9600 TestAcc 0.7828 0.9300
epoch 1600 LossPred 0.1964 LossAtt 0.3425 TrainAcc 0.9600 TestAcc 0.7908 0.9000
epoch 1700 LossPred 0.1909 LossAtt 0.3549 TrainAcc 0.9700 TestAcc 0.7983 0.8950
epoch 1800 LossPred 0.1509 LossAtt 0.3544 TrainAcc 0.9800 TestAcc 0.7948 0.9050
epoch 1900 LossPred 0.1555 LossAtt 0.3484 TrainAcc 0.9700 TestAcc 0.7883 0.9250
epoch 2000 LossPred 0.1920 LossAtt 0.3479 TrainAcc 0.9500 TestAcc 0.7888 0.9300
epoch 2100 LossPred 0.1442 LossAtt 0.3408 TrainAcc 0.9700 TestAcc 0.7965 0.9250
epoch 2200 LossPred 0.1367 LossAtt 0.3255 TrainAcc 0.9800 TestAcc 0.8006 0.9200
epoch 2300 LossPred 0.1388 LossAtt 0.3294 TrainAcc 0.9700 TestAcc 0.7973 0.9200
epoch 2400 LossPred 0.1527 LossAtt 0.3303 TrainAcc 0.9600 TestAcc 0.7838 0.9400
epoch 2500 LossPred 0.1327 LossAtt 0.3281 TrainAcc 0.9800 TestAcc 0.8038 0.9200
Optimization Finished!
********** replication  80  **********
epoch   0 LossPred 1.2244 LossAtt 1.0128 TrainAcc 0.4100 TestAcc 0.3856 0.4200
epoch 100 LossPred 0.9764 LossAtt 0.2641 TrainAcc 0.5900 TestAcc 0.6144 0.5850
epoch 200 LossPred 0.5182 LossAtt 0.3342 TrainAcc 0.9400 TestAcc 0.8569 0.9250
epoch 300 LossPred 0.1934 LossAtt 0.3189 TrainAcc 0.9900 TestAcc 0.9197 0.9800
epoch 400 LossPred 0.2048 LossAtt 0.3336 TrainAcc 0.9400 TestAcc 0.8699 0.9450
epoch 500 LossPred 0.1710 LossAtt 0.3344 TrainAcc 0.9600 TestAcc 0.8649 0.9400
epoch 600 LossPred 0.0944 LossAtt 0.3076 TrainAcc 0.9800 TestAcc 0.9022 0.9650
epoch 700 LossPred 0.0824 LossAtt 0.3052 TrainAcc 0.9900 TestAcc 0.8934 0.9650
epoch 800 LossPred 0.0644 LossAtt 0.2957 TrainAcc 0.9900 TestAcc 0.8999 0.9700
epoch 900 LossPred 0.1112 LossAtt 0.2803 TrainAcc 0.9700 TestAcc 0.8936 0.9650
epoch 1000 LossPred 0.1563 LossAtt 0.2858 TrainAcc 0.9300 TestAcc 0.8751 0.9600
epoch 1100 LossPred 0.0958 LossAtt 0.2726 TrainAcc 0.9600 TestAcc 0.8879 0.9750
epoch 1200 LossPred 0.0567 LossAtt 0.2656 TrainAcc 0.9900 TestAcc 0.8966 0.9700
epoch 1300 LossPred 0.0704 LossAtt 0.2705 TrainAcc 0.9800 TestAcc 0.8929 0.9750
epoch 1400 LossPred 0.0698 LossAtt 0.2767 TrainAcc 0.9800 TestAcc 0.8916 0.9800
epoch 1500 LossPred 0.0373 LossAtt 0.2872 TrainAcc 0.9900 TestAcc 0.9052 0.9900
epoch 1600 LossPred 0.0349 LossAtt 0.2869 TrainAcc 1.0000 TestAcc 0.9109 0.9950
Optimization Finished!
********** replication  81  **********
epoch   0 LossPred 0.9917 LossAtt 1.0278 TrainAcc 0.5400 TestAcc 0.5005 0.5550
epoch 100 LossPred 0.8379 LossAtt 0.3450 TrainAcc 0.6900 TestAcc 0.6056 0.6850
epoch 200 LossPred 0.2242 LossAtt 0.2832 TrainAcc 0.9500 TestAcc 0.9127 0.9150
epoch 300 LossPred 0.2173 LossAtt 0.2621 TrainAcc 0.9200 TestAcc 0.8734 0.9300
epoch 400 LossPred 0.1667 LossAtt 0.2621 TrainAcc 0.9500 TestAcc 0.9239 0.9350
epoch 500 LossPred 0.1739 LossAtt 0.2459 TrainAcc 0.9200 TestAcc 0.8979 0.9400
epoch 600 LossPred 0.2215 LossAtt 0.2470 TrainAcc 0.9400 TestAcc 0.9322 0.9250
epoch 700 LossPred 0.1605 LossAtt 0.2306 TrainAcc 0.9500 TestAcc 0.9059 0.9500
epoch 800 LossPred 0.1970 LossAtt 0.2130 TrainAcc 0.9200 TestAcc 0.8826 0.9300
epoch 900 LossPred 0.2340 LossAtt 0.2157 TrainAcc 0.9300 TestAcc 0.9062 0.9250
epoch 1000 LossPred 0.1575 LossAtt 0.2038 TrainAcc 0.9500 TestAcc 0.9342 0.9550
epoch 1100 LossPred 0.1787 LossAtt 0.2107 TrainAcc 0.9500 TestAcc 0.9214 0.9400
epoch 1200 LossPred 0.1540 LossAtt 0.2116 TrainAcc 0.9600 TestAcc 0.9114 0.9550
epoch 1300 LossPred 0.2017 LossAtt 0.2192 TrainAcc 0.9200 TestAcc 0.8724 0.9350
epoch 1400 LossPred 0.1480 LossAtt 0.2089 TrainAcc 0.9600 TestAcc 0.9089 0.9600
epoch 1500 LossPred 0.1475 LossAtt 0.2118 TrainAcc 0.9600 TestAcc 0.9014 0.9500
epoch 1600 LossPred 0.1901 LossAtt 0.2175 TrainAcc 0.9300 TestAcc 0.8836 0.9300
epoch 1700 LossPred 0.3271 LossAtt 0.2135 TrainAcc 0.8700 TestAcc 0.8719 0.8850
epoch 1800 LossPred 0.1615 LossAtt 0.2246 TrainAcc 0.9500 TestAcc 0.8791 0.9400
epoch 1900 LossPred 0.2109 LossAtt 0.2286 TrainAcc 0.9300 TestAcc 0.8659 0.9350
epoch 2000 LossPred 0.1919 LossAtt 0.2339 TrainAcc 0.9400 TestAcc 0.9044 0.9350
epoch 2100 LossPred 0.1539 LossAtt 0.2310 TrainAcc 0.9700 TestAcc 0.9022 0.9700
epoch 2200 LossPred 0.2860 LossAtt 0.2396 TrainAcc 0.9000 TestAcc 0.8278 0.9100
epoch 2300 LossPred 0.1760 LossAtt 0.2330 TrainAcc 0.9500 TestAcc 0.9012 0.9500
epoch 2400 LossPred 0.1201 LossAtt 0.2459 TrainAcc 0.9700 TestAcc 0.9204 0.9700
epoch 2500 LossPred 0.1305 LossAtt 0.2465 TrainAcc 0.9500 TestAcc 0.9347 0.9500
Optimization Finished!
********** replication  82  **********
epoch   0 LossPred 0.9290 LossAtt 1.0243 TrainAcc 0.6200 TestAcc 0.5681 0.6400
epoch 100 LossPred 0.7404 LossAtt 0.3556 TrainAcc 0.7300 TestAcc 0.6619 0.7350
epoch 200 LossPred 0.2527 LossAtt 0.3304 TrainAcc 0.9300 TestAcc 0.8886 0.8900
epoch 300 LossPred 0.1034 LossAtt 0.3393 TrainAcc 0.9800 TestAcc 0.9257 0.9600
epoch 400 LossPred 0.0893 LossAtt 0.3422 TrainAcc 0.9800 TestAcc 0.9227 0.9600
epoch 500 LossPred 0.0997 LossAtt 0.3222 TrainAcc 0.9700 TestAcc 0.9172 0.9350
epoch 600 LossPred 0.0548 LossAtt 0.3165 TrainAcc 1.0000 TestAcc 0.9164 0.9400
Optimization Finished!
********** replication  83  **********
epoch   0 LossPred 1.0696 LossAtt 1.0204 TrainAcc 0.4300 TestAcc 0.4109 0.4150
epoch 100 LossPred 0.8738 LossAtt 0.3027 TrainAcc 0.6700 TestAcc 0.6749 0.6400
epoch 200 LossPred 0.4162 LossAtt 0.3158 TrainAcc 0.8800 TestAcc 0.8849 0.8650
epoch 300 LossPred 0.3083 LossAtt 0.3018 TrainAcc 0.9200 TestAcc 0.9157 0.8750
epoch 400 LossPred 0.3627 LossAtt 0.2787 TrainAcc 0.8800 TestAcc 0.8756 0.8700
epoch 500 LossPred 0.8766 LossAtt 0.2589 TrainAcc 0.7000 TestAcc 0.7295 0.7000
epoch 600 LossPred 0.4323 LossAtt 0.2530 TrainAcc 0.8400 TestAcc 0.8531 0.8300
epoch 700 LossPred 0.2711 LossAtt 0.2442 TrainAcc 0.9500 TestAcc 0.9117 0.9200
epoch 800 LossPred 0.3531 LossAtt 0.2425 TrainAcc 0.8500 TestAcc 0.8876 0.8700
epoch 900 LossPred 0.2593 LossAtt 0.2530 TrainAcc 0.9500 TestAcc 0.9299 0.9250
epoch 1000 LossPred 0.2321 LossAtt 0.2445 TrainAcc 0.9300 TestAcc 0.9317 0.9550
epoch 1100 LossPred 0.4262 LossAtt 0.2355 TrainAcc 0.8600 TestAcc 0.8514 0.8150
epoch 1200 LossPred 0.3144 LossAtt 0.2380 TrainAcc 0.9100 TestAcc 0.9054 0.9000
epoch 1300 LossPred 0.2453 LossAtt 0.2462 TrainAcc 0.9100 TestAcc 0.9122 0.9200
epoch 1400 LossPred 0.2100 LossAtt 0.2279 TrainAcc 0.9500 TestAcc 0.9402 0.9450
epoch 1500 LossPred 0.2543 LossAtt 0.2342 TrainAcc 0.9300 TestAcc 0.8996 0.9250
epoch 1600 LossPred 0.1980 LossAtt 0.2293 TrainAcc 0.9300 TestAcc 0.9202 0.9400
epoch 1700 LossPred 0.2124 LossAtt 0.2290 TrainAcc 0.9300 TestAcc 0.9152 0.9400
epoch 1800 LossPred 0.1484 LossAtt 0.2228 TrainAcc 0.9700 TestAcc 0.9377 0.9550
epoch 1900 LossPred 0.1174 LossAtt 0.2291 TrainAcc 0.9800 TestAcc 0.9555 0.9850
epoch 2000 LossPred 0.1258 LossAtt 0.2296 TrainAcc 0.9500 TestAcc 0.9585 0.9600
epoch 2100 LossPred 0.1116 LossAtt 0.2283 TrainAcc 0.9600 TestAcc 0.9494 0.9750
epoch 2200 LossPred 0.1493 LossAtt 0.2390 TrainAcc 0.9600 TestAcc 0.9484 0.9600
epoch 2300 LossPred 0.1413 LossAtt 0.2430 TrainAcc 0.9500 TestAcc 0.9575 0.9600
epoch 2400 LossPred 0.2846 LossAtt 0.2407 TrainAcc 0.9000 TestAcc 0.8979 0.8800
epoch 2500 LossPred 0.1412 LossAtt 0.2462 TrainAcc 0.9600 TestAcc 0.9444 0.9650
Optimization Finished!
********** replication  84  **********
epoch   0 LossPred 1.1964 LossAtt 1.0165 TrainAcc 0.4800 TestAcc 0.4494 0.5000
epoch 100 LossPred 0.9099 LossAtt 0.3341 TrainAcc 0.6400 TestAcc 0.6221 0.6400
epoch 200 LossPred 0.5160 LossAtt 0.3343 TrainAcc 0.8300 TestAcc 0.8636 0.8150
epoch 300 LossPred 0.3227 LossAtt 0.3293 TrainAcc 0.9000 TestAcc 0.8694 0.8600
epoch 400 LossPred 0.1933 LossAtt 0.2934 TrainAcc 0.9500 TestAcc 0.9019 0.9350
epoch 500 LossPred 0.1642 LossAtt 0.2708 TrainAcc 0.9900 TestAcc 0.9612 0.9550
epoch 600 LossPred 0.1579 LossAtt 0.2635 TrainAcc 0.9500 TestAcc 0.9179 0.9400
epoch 700 LossPred 0.1679 LossAtt 0.2619 TrainAcc 0.9500 TestAcc 0.9069 0.9200
epoch 800 LossPred 0.2213 LossAtt 0.2421 TrainAcc 0.9100 TestAcc 0.9012 0.9200
epoch 900 LossPred 0.1678 LossAtt 0.2426 TrainAcc 0.9500 TestAcc 0.9112 0.9150
epoch 1000 LossPred 0.1677 LossAtt 0.2394 TrainAcc 0.9600 TestAcc 0.9064 0.9150
epoch 1100 LossPred 0.1900 LossAtt 0.2493 TrainAcc 0.9400 TestAcc 0.8921 0.9100
epoch 1200 LossPred 0.1835 LossAtt 0.2362 TrainAcc 0.9400 TestAcc 0.9164 0.9200
epoch 1300 LossPred 0.1385 LossAtt 0.2290 TrainAcc 0.9600 TestAcc 0.9094 0.9350
epoch 1400 LossPred 0.1338 LossAtt 0.2308 TrainAcc 0.9600 TestAcc 0.9187 0.9350
epoch 1500 LossPred 0.2624 LossAtt 0.2195 TrainAcc 0.9200 TestAcc 0.9154 0.9150
epoch 1600 LossPred 0.1180 LossAtt 0.2256 TrainAcc 0.9700 TestAcc 0.9209 0.9400
epoch 1700 LossPred 0.1242 LossAtt 0.2072 TrainAcc 0.9800 TestAcc 0.9269 0.9450
epoch 1800 LossPred 0.1254 LossAtt 0.1908 TrainAcc 0.9800 TestAcc 0.9354 0.9500
epoch 1900 LossPred 0.1643 LossAtt 0.1899 TrainAcc 0.9400 TestAcc 0.9394 0.9500
epoch 2000 LossPred 0.0987 LossAtt 0.1929 TrainAcc 0.9800 TestAcc 0.9387 0.9550
epoch 2100 LossPred 0.1780 LossAtt 0.1986 TrainAcc 0.9400 TestAcc 0.9357 0.9350
epoch 2200 LossPred 0.3566 LossAtt 0.2007 TrainAcc 0.8700 TestAcc 0.8696 0.8650
epoch 2300 LossPred 0.2774 LossAtt 0.1921 TrainAcc 0.8900 TestAcc 0.8941 0.8850
epoch 2400 LossPred 0.4054 LossAtt 0.2126 TrainAcc 0.8500 TestAcc 0.8458 0.8600
epoch 2500 LossPred 0.1734 LossAtt 0.1961 TrainAcc 0.9600 TestAcc 0.9054 0.9500
Optimization Finished!
********** replication  85  **********
epoch   0 LossPred 1.0612 LossAtt 0.9980 TrainAcc 0.4500 TestAcc 0.5118 0.4250
epoch 100 LossPred 0.7855 LossAtt 0.3101 TrainAcc 0.6900 TestAcc 0.6416 0.6750
epoch 200 LossPred 0.3392 LossAtt 0.3084 TrainAcc 0.9300 TestAcc 0.8969 0.8900
epoch 300 LossPred 0.2795 LossAtt 0.2897 TrainAcc 0.9100 TestAcc 0.8709 0.9000
epoch 400 LossPred 0.2424 LossAtt 0.2680 TrainAcc 0.9000 TestAcc 0.8811 0.9000
epoch 500 LossPred 0.2777 LossAtt 0.2412 TrainAcc 0.8700 TestAcc 0.8846 0.8850
epoch 600 LossPred 0.1828 LossAtt 0.2512 TrainAcc 0.9300 TestAcc 0.9192 0.9250
epoch 700 LossPred 0.1472 LossAtt 0.2548 TrainAcc 0.9500 TestAcc 0.9189 0.9300
epoch 800 LossPred 0.1416 LossAtt 0.2412 TrainAcc 0.9600 TestAcc 0.9219 0.9350
epoch 900 LossPred 0.1488 LossAtt 0.2469 TrainAcc 0.9700 TestAcc 0.9204 0.9300
epoch 1000 LossPred 0.1393 LossAtt 0.2491 TrainAcc 0.9800 TestAcc 0.9319 0.9450
epoch 1100 LossPred 0.1502 LossAtt 0.2327 TrainAcc 0.9300 TestAcc 0.9192 0.9300
epoch 1200 LossPred 0.1584 LossAtt 0.2291 TrainAcc 0.9300 TestAcc 0.9152 0.9250
epoch 1300 LossPred 0.2475 LossAtt 0.2237 TrainAcc 0.9000 TestAcc 0.8854 0.8800
epoch 1400 LossPred 0.1609 LossAtt 0.2313 TrainAcc 0.9300 TestAcc 0.9152 0.9200
epoch 1500 LossPred 0.1687 LossAtt 0.2363 TrainAcc 0.9300 TestAcc 0.9182 0.9250
epoch 1600 LossPred 0.2225 LossAtt 0.2334 TrainAcc 0.9100 TestAcc 0.8866 0.8850
epoch 1700 LossPred 0.2128 LossAtt 0.2361 TrainAcc 0.9200 TestAcc 0.9217 0.9000
epoch 1800 LossPred 0.2043 LossAtt 0.2216 TrainAcc 0.9300 TestAcc 0.9079 0.9050
epoch 1900 LossPred 0.3764 LossAtt 0.2297 TrainAcc 0.8900 TestAcc 0.8333 0.8550
epoch 2000 LossPred 0.2620 LossAtt 0.2258 TrainAcc 0.8800 TestAcc 0.8764 0.8800
epoch 2100 LossPred 0.3231 LossAtt 0.2188 TrainAcc 0.8900 TestAcc 0.8764 0.8850
epoch 2200 LossPred 0.2121 LossAtt 0.2096 TrainAcc 0.9200 TestAcc 0.8961 0.9150
epoch 2300 LossPred 0.2364 LossAtt 0.2034 TrainAcc 0.9100 TestAcc 0.8921 0.9100
epoch 2400 LossPred 0.2989 LossAtt 0.2163 TrainAcc 0.9200 TestAcc 0.8566 0.8850
epoch 2500 LossPred 0.2251 LossAtt 0.1930 TrainAcc 0.9300 TestAcc 0.9024 0.9050
Optimization Finished!
********** replication  86  **********
epoch   0 LossPred 1.0190 LossAtt 1.0054 TrainAcc 0.4600 TestAcc 0.5053 0.4450
epoch 100 LossPred 0.5477 LossAtt 0.3283 TrainAcc 0.8300 TestAcc 0.8156 0.8150
epoch 200 LossPred 0.4512 LossAtt 0.2601 TrainAcc 0.8300 TestAcc 0.8361 0.8150
epoch 300 LossPred 0.4746 LossAtt 0.2519 TrainAcc 0.8400 TestAcc 0.8053 0.8400
epoch 400 LossPred 0.3672 LossAtt 0.2319 TrainAcc 0.8900 TestAcc 0.8546 0.8800
epoch 500 LossPred 0.3569 LossAtt 0.2248 TrainAcc 0.8800 TestAcc 0.8789 0.8650
epoch 600 LossPred 0.1984 LossAtt 0.2464 TrainAcc 0.9500 TestAcc 0.9032 0.9450
epoch 700 LossPred 0.1501 LossAtt 0.2381 TrainAcc 0.9700 TestAcc 0.8734 0.9450
epoch 800 LossPred 0.1327 LossAtt 0.2234 TrainAcc 0.9500 TestAcc 0.9129 0.9500
epoch 900 LossPred 0.1076 LossAtt 0.2077 TrainAcc 0.9700 TestAcc 0.9149 0.9650
epoch 1000 LossPred 0.1083 LossAtt 0.1954 TrainAcc 0.9700 TestAcc 0.9099 0.9700
epoch 1100 LossPred 0.1331 LossAtt 0.2040 TrainAcc 0.9700 TestAcc 0.8881 0.9600
epoch 1200 LossPred 0.1312 LossAtt 0.1881 TrainAcc 0.9700 TestAcc 0.8901 0.9600
epoch 1300 LossPred 0.1204 LossAtt 0.1902 TrainAcc 0.9500 TestAcc 0.9324 0.9650
epoch 1400 LossPred 0.0679 LossAtt 0.1849 TrainAcc 0.9800 TestAcc 0.9214 0.9750
epoch 1500 LossPred 0.0630 LossAtt 0.1916 TrainAcc 1.0000 TestAcc 0.9334 0.9800
Optimization Finished!
********** replication  87  **********
epoch   0 LossPred 1.1840 LossAtt 1.0243 TrainAcc 0.5000 TestAcc 0.4942 0.5050
epoch 100 LossPred 0.9108 LossAtt 0.2798 TrainAcc 0.6500 TestAcc 0.6044 0.6100
epoch 200 LossPred 0.9009 LossAtt 0.2231 TrainAcc 0.6300 TestAcc 0.5818 0.6150
epoch 300 LossPred 0.8916 LossAtt 0.2268 TrainAcc 0.6100 TestAcc 0.5636 0.6350
epoch 400 LossPred 0.8690 LossAtt 0.2398 TrainAcc 0.6000 TestAcc 0.5480 0.6500
epoch 500 LossPred 0.7929 LossAtt 0.2542 TrainAcc 0.7000 TestAcc 0.5608 0.6950
epoch 600 LossPred 0.7377 LossAtt 0.2718 TrainAcc 0.7600 TestAcc 0.5783 0.6950
epoch 700 LossPred 0.6683 LossAtt 0.2543 TrainAcc 0.7900 TestAcc 0.5791 0.6900
epoch 800 LossPred 0.6200 LossAtt 0.2452 TrainAcc 0.7800 TestAcc 0.5856 0.7150
epoch 900 LossPred 0.6055 LossAtt 0.2527 TrainAcc 0.8100 TestAcc 0.5908 0.7050
epoch 1000 LossPred 0.5807 LossAtt 0.2561 TrainAcc 0.8200 TestAcc 0.5911 0.7050
epoch 1100 LossPred 0.5524 LossAtt 0.2566 TrainAcc 0.8400 TestAcc 0.5853 0.7100
epoch 1200 LossPred 0.5511 LossAtt 0.2541 TrainAcc 0.8400 TestAcc 0.5841 0.7000
epoch 1300 LossPred 0.5448 LossAtt 0.2518 TrainAcc 0.8200 TestAcc 0.5848 0.7500
epoch 1400 LossPred 0.5374 LossAtt 0.2594 TrainAcc 0.8400 TestAcc 0.5693 0.7450
epoch 1500 LossPred 0.5038 LossAtt 0.2508 TrainAcc 0.8500 TestAcc 0.5628 0.7550
epoch 1600 LossPred 0.5241 LossAtt 0.2660 TrainAcc 0.8300 TestAcc 0.5641 0.7550
epoch 1700 LossPred 0.4964 LossAtt 0.2538 TrainAcc 0.8600 TestAcc 0.5636 0.7850
epoch 1800 LossPred 0.4381 LossAtt 0.2473 TrainAcc 0.8900 TestAcc 0.5708 0.8000
epoch 1900 LossPred 0.4346 LossAtt 0.2423 TrainAcc 0.8900 TestAcc 0.5806 0.7850
epoch 2000 LossPred 0.4400 LossAtt 0.2380 TrainAcc 0.9000 TestAcc 0.5751 0.7900
epoch 2100 LossPred 0.5249 LossAtt 0.2364 TrainAcc 0.8200 TestAcc 0.5748 0.7850
epoch 2200 LossPred 0.4699 LossAtt 0.2450 TrainAcc 0.8700 TestAcc 0.5778 0.7600
epoch 2300 LossPred 0.4517 LossAtt 0.2402 TrainAcc 0.8900 TestAcc 0.5701 0.7600
epoch 2400 LossPred 0.4893 LossAtt 0.2372 TrainAcc 0.8500 TestAcc 0.5718 0.7750
epoch 2500 LossPred 0.4906 LossAtt 0.2420 TrainAcc 0.8500 TestAcc 0.5776 0.7650
Optimization Finished!
********** replication  88  **********
epoch   0 LossPred 1.0595 LossAtt 0.9965 TrainAcc 0.4800 TestAcc 0.4344 0.4600
epoch 100 LossPred 0.7703 LossAtt 0.3683 TrainAcc 0.7100 TestAcc 0.7720 0.7150
epoch 200 LossPred 0.2907 LossAtt 0.3423 TrainAcc 0.9400 TestAcc 0.9179 0.8950
epoch 300 LossPred 0.2077 LossAtt 0.3314 TrainAcc 0.9600 TestAcc 0.9555 0.9400
epoch 400 LossPred 0.2891 LossAtt 0.3436 TrainAcc 0.8800 TestAcc 0.8676 0.8750
epoch 500 LossPred 0.2460 LossAtt 0.3365 TrainAcc 0.9000 TestAcc 0.9134 0.8650
epoch 600 LossPred 0.1485 LossAtt 0.3186 TrainAcc 0.9700 TestAcc 0.9432 0.9300
epoch 700 LossPred 0.1612 LossAtt 0.3218 TrainAcc 0.9600 TestAcc 0.9489 0.9250
epoch 800 LossPred 0.1744 LossAtt 0.3202 TrainAcc 0.9600 TestAcc 0.9324 0.9250
epoch 900 LossPred 0.2636 LossAtt 0.3338 TrainAcc 0.9200 TestAcc 0.9012 0.9100
epoch 1000 LossPred 0.2432 LossAtt 0.3316 TrainAcc 0.9100 TestAcc 0.8961 0.9100
epoch 1100 LossPred 0.1860 LossAtt 0.3181 TrainAcc 0.9300 TestAcc 0.9164 0.9100
epoch 1200 LossPred 0.1590 LossAtt 0.3113 TrainAcc 0.9500 TestAcc 0.9412 0.9150
epoch 1300 LossPred 0.1746 LossAtt 0.3200 TrainAcc 0.9400 TestAcc 0.8989 0.9050
epoch 1400 LossPred 0.1913 LossAtt 0.3101 TrainAcc 0.9300 TestAcc 0.8956 0.9200
epoch 1500 LossPred 0.0887 LossAtt 0.3072 TrainAcc 0.9800 TestAcc 0.9307 0.9400
epoch 1600 LossPred 0.2117 LossAtt 0.3221 TrainAcc 0.9400 TestAcc 0.9192 0.8750
epoch 1700 LossPred 0.1142 LossAtt 0.3089 TrainAcc 0.9700 TestAcc 0.9254 0.9000
epoch 1800 LossPred 0.3033 LossAtt 0.3010 TrainAcc 0.8700 TestAcc 0.9017 0.8400
epoch 1900 LossPred 0.0680 LossAtt 0.2963 TrainAcc 0.9800 TestAcc 0.9257 0.9100
epoch 2000 LossPred 0.0487 LossAtt 0.2864 TrainAcc 0.9900 TestAcc 0.9382 0.9300
epoch 2100 LossPred 0.0788 LossAtt 0.2900 TrainAcc 0.9700 TestAcc 0.9324 0.9150
epoch 2200 LossPred 0.0451 LossAtt 0.2805 TrainAcc 0.9900 TestAcc 0.9402 0.9300
epoch 2300 LossPred 0.0658 LossAtt 0.2685 TrainAcc 0.9700 TestAcc 0.9317 0.9200
epoch 2400 LossPred 0.0403 LossAtt 0.2697 TrainAcc 0.9900 TestAcc 0.9429 0.9200
epoch 2500 LossPred 0.1321 LossAtt 0.2658 TrainAcc 0.9500 TestAcc 0.9264 0.8900
Optimization Finished!
********** replication  89  **********
epoch   0 LossPred 1.0301 LossAtt 1.0021 TrainAcc 0.4400 TestAcc 0.4007 0.4400
epoch 100 LossPred 0.9520 LossAtt 0.2117 TrainAcc 0.5800 TestAcc 0.4902 0.5800
epoch 200 LossPred 0.5906 LossAtt 0.2467 TrainAcc 0.8100 TestAcc 0.8456 0.8250
epoch 300 LossPred 0.4521 LossAtt 0.2257 TrainAcc 0.8500 TestAcc 0.8561 0.8600
epoch 400 LossPred 0.4772 LossAtt 0.2072 TrainAcc 0.8700 TestAcc 0.8619 0.8400
epoch 500 LossPred 0.3839 LossAtt 0.1928 TrainAcc 0.8500 TestAcc 0.9132 0.8850
epoch 600 LossPred 0.3453 LossAtt 0.1995 TrainAcc 0.8700 TestAcc 0.9057 0.8850
epoch 700 LossPred 0.7465 LossAtt 0.2098 TrainAcc 0.7400 TestAcc 0.7703 0.7550
epoch 800 LossPred 0.4723 LossAtt 0.2016 TrainAcc 0.8300 TestAcc 0.8456 0.8300
epoch 900 LossPred 0.5591 LossAtt 0.2012 TrainAcc 0.7800 TestAcc 0.8068 0.7950
epoch 1000 LossPred 0.3576 LossAtt 0.2152 TrainAcc 0.8900 TestAcc 0.9014 0.8950
epoch 1100 LossPred 0.3959 LossAtt 0.2342 TrainAcc 0.8500 TestAcc 0.8864 0.8650
epoch 1200 LossPred 0.4762 LossAtt 0.2314 TrainAcc 0.8200 TestAcc 0.8421 0.8250
epoch 1300 LossPred 0.2246 LossAtt 0.2301 TrainAcc 0.9400 TestAcc 0.9197 0.9200
epoch 1400 LossPred 0.4119 LossAtt 0.2278 TrainAcc 0.8700 TestAcc 0.8641 0.8500
epoch 1500 LossPred 0.2791 LossAtt 0.2147 TrainAcc 0.9100 TestAcc 0.9074 0.9150
epoch 1600 LossPred 0.2502 LossAtt 0.2078 TrainAcc 0.9100 TestAcc 0.9024 0.9050
epoch 1700 LossPred 0.2795 LossAtt 0.2034 TrainAcc 0.9000 TestAcc 0.8916 0.8900
epoch 1800 LossPred 0.2668 LossAtt 0.2002 TrainAcc 0.9100 TestAcc 0.8934 0.8750
epoch 1900 LossPred 0.2047 LossAtt 0.1977 TrainAcc 0.9400 TestAcc 0.9217 0.9050
epoch 2000 LossPred 0.2324 LossAtt 0.1955 TrainAcc 0.9200 TestAcc 0.9074 0.9000
epoch 2100 LossPred 0.4323 LossAtt 0.2021 TrainAcc 0.8400 TestAcc 0.8576 0.8550
epoch 2200 LossPred 0.3112 LossAtt 0.2168 TrainAcc 0.9200 TestAcc 0.8966 0.9100
epoch 2300 LossPred 0.1825 LossAtt 0.2239 TrainAcc 0.9500 TestAcc 0.9189 0.9300
epoch 2400 LossPred 0.4427 LossAtt 0.2220 TrainAcc 0.8100 TestAcc 0.8504 0.8550
epoch 2500 LossPred 0.3325 LossAtt 0.2192 TrainAcc 0.8900 TestAcc 0.8866 0.8550
Optimization Finished!
********** replication  90  **********
epoch   0 LossPred 0.9730 LossAtt 1.0290 TrainAcc 0.5600 TestAcc 0.5651 0.5500
epoch 100 LossPred 0.7272 LossAtt 0.3236 TrainAcc 0.7400 TestAcc 0.6249 0.7100
epoch 200 LossPred 0.2999 LossAtt 0.2857 TrainAcc 0.9100 TestAcc 0.8996 0.8900
epoch 300 LossPred 0.2494 LossAtt 0.2431 TrainAcc 0.9200 TestAcc 0.9132 0.8850
epoch 400 LossPred 0.1731 LossAtt 0.2220 TrainAcc 0.9600 TestAcc 0.9234 0.9150
epoch 500 LossPred 0.1813 LossAtt 0.2250 TrainAcc 0.9500 TestAcc 0.9227 0.8950
epoch 600 LossPred 0.1851 LossAtt 0.2222 TrainAcc 0.9400 TestAcc 0.9074 0.9200
epoch 700 LossPred 0.3082 LossAtt 0.2203 TrainAcc 0.8800 TestAcc 0.8774 0.8750
epoch 800 LossPred 0.1533 LossAtt 0.2068 TrainAcc 0.9800 TestAcc 0.9264 0.9250
epoch 900 LossPred 0.4645 LossAtt 0.2040 TrainAcc 0.8300 TestAcc 0.8453 0.8050
epoch 1000 LossPred 0.4195 LossAtt 0.2081 TrainAcc 0.8300 TestAcc 0.8571 0.8300
epoch 1100 LossPred 0.4532 LossAtt 0.2326 TrainAcc 0.8800 TestAcc 0.7833 0.8500
epoch 1200 LossPred 0.5070 LossAtt 0.2213 TrainAcc 0.8100 TestAcc 0.7970 0.8050
epoch 1300 LossPred 0.3866 LossAtt 0.2049 TrainAcc 0.8500 TestAcc 0.8193 0.8500
epoch 1400 LossPred 0.2455 LossAtt 0.1936 TrainAcc 0.9100 TestAcc 0.8969 0.8950
epoch 1500 LossPred 0.5977 LossAtt 0.1845 TrainAcc 0.8100 TestAcc 0.8078 0.8100
epoch 1600 LossPred 0.3558 LossAtt 0.1849 TrainAcc 0.8800 TestAcc 0.8711 0.8700
epoch 1700 LossPred 0.3445 LossAtt 0.1851 TrainAcc 0.9000 TestAcc 0.8741 0.8650
epoch 1800 LossPred 0.2318 LossAtt 0.1646 TrainAcc 0.9500 TestAcc 0.8909 0.9300
epoch 1900 LossPred 0.2012 LossAtt 0.1633 TrainAcc 0.9500 TestAcc 0.9204 0.9350
epoch 2000 LossPred 0.2367 LossAtt 0.1602 TrainAcc 0.9400 TestAcc 0.9049 0.9100
epoch 2100 LossPred 0.4171 LossAtt 0.1593 TrainAcc 0.8500 TestAcc 0.8616 0.8500
epoch 2200 LossPred 0.2447 LossAtt 0.1932 TrainAcc 0.9300 TestAcc 0.8766 0.9250
epoch 2300 LossPred 0.2271 LossAtt 0.1796 TrainAcc 0.9300 TestAcc 0.8776 0.9300
epoch 2400 LossPred 0.1938 LossAtt 0.1750 TrainAcc 0.9500 TestAcc 0.9107 0.9350
epoch 2500 LossPred 0.1857 LossAtt 0.1813 TrainAcc 0.9400 TestAcc 0.9169 0.9200
Optimization Finished!
********** replication  91  **********
epoch   0 LossPred 0.9887 LossAtt 1.0361 TrainAcc 0.5000 TestAcc 0.4967 0.5150
epoch 100 LossPred 0.8888 LossAtt 0.3150 TrainAcc 0.6400 TestAcc 0.6056 0.6300
epoch 200 LossPred 0.2882 LossAtt 0.3119 TrainAcc 0.8800 TestAcc 0.8889 0.8700
epoch 300 LossPred 0.2340 LossAtt 0.2783 TrainAcc 0.9300 TestAcc 0.8841 0.8750
epoch 400 LossPred 0.2600 LossAtt 0.2583 TrainAcc 0.9200 TestAcc 0.8829 0.8850
epoch 500 LossPred 0.2738 LossAtt 0.2246 TrainAcc 0.9000 TestAcc 0.8764 0.8900
epoch 600 LossPred 0.2990 LossAtt 0.2308 TrainAcc 0.9100 TestAcc 0.8681 0.8800
epoch 700 LossPred 0.1978 LossAtt 0.2116 TrainAcc 0.9300 TestAcc 0.8971 0.9100
epoch 800 LossPred 0.2366 LossAtt 0.2255 TrainAcc 0.9100 TestAcc 0.8871 0.8950
epoch 900 LossPred 0.1566 LossAtt 0.2082 TrainAcc 0.9500 TestAcc 0.9089 0.9150
epoch 1000 LossPred 0.1850 LossAtt 0.2214 TrainAcc 0.9400 TestAcc 0.9154 0.9100
epoch 1100 LossPred 0.2479 LossAtt 0.1922 TrainAcc 0.9300 TestAcc 0.8811 0.9100
epoch 1200 LossPred 0.2824 LossAtt 0.1990 TrainAcc 0.9000 TestAcc 0.8784 0.8950
epoch 1300 LossPred 0.2364 LossAtt 0.1900 TrainAcc 0.9300 TestAcc 0.8889 0.9050
epoch 1400 LossPred 0.2635 LossAtt 0.2031 TrainAcc 0.9100 TestAcc 0.8886 0.9100
epoch 1500 LossPred 0.1354 LossAtt 0.2007 TrainAcc 0.9400 TestAcc 0.9152 0.9200
epoch 1600 LossPred 0.2286 LossAtt 0.1927 TrainAcc 0.9100 TestAcc 0.8966 0.9100
epoch 1700 LossPred 0.1590 LossAtt 0.2047 TrainAcc 0.9400 TestAcc 0.9212 0.9100
epoch 1800 LossPred 0.1339 LossAtt 0.1929 TrainAcc 0.9400 TestAcc 0.9204 0.9300
epoch 1900 LossPred 0.2460 LossAtt 0.1851 TrainAcc 0.9000 TestAcc 0.8976 0.9050
epoch 2000 LossPred 0.1235 LossAtt 0.1943 TrainAcc 0.9400 TestAcc 0.9257 0.9400
epoch 2100 LossPred 0.1434 LossAtt 0.1975 TrainAcc 0.9700 TestAcc 0.9317 0.9250
epoch 2200 LossPred 0.1210 LossAtt 0.1953 TrainAcc 0.9400 TestAcc 0.9232 0.9400
epoch 2300 LossPred 0.2904 LossAtt 0.1993 TrainAcc 0.8900 TestAcc 0.8909 0.9000
epoch 2400 LossPred 0.1457 LossAtt 0.1954 TrainAcc 0.9500 TestAcc 0.9164 0.9250
epoch 2500 LossPred 0.1395 LossAtt 0.2038 TrainAcc 0.9500 TestAcc 0.9097 0.9350
Optimization Finished!
********** replication  92  **********
epoch   0 LossPred 1.0856 LossAtt 1.0321 TrainAcc 0.5300 TestAcc 0.5335 0.5350
epoch 100 LossPred 0.9154 LossAtt 0.2581 TrainAcc 0.6500 TestAcc 0.6031 0.6450
epoch 200 LossPred 0.8835 LossAtt 0.2057 TrainAcc 0.6500 TestAcc 0.6031 0.6500
epoch 300 LossPred 0.6220 LossAtt 0.2303 TrainAcc 0.7700 TestAcc 0.7490 0.7900
epoch 400 LossPred 0.2979 LossAtt 0.2132 TrainAcc 0.9000 TestAcc 0.8664 0.8900
epoch 500 LossPred 0.2475 LossAtt 0.2056 TrainAcc 0.9100 TestAcc 0.8976 0.8900
epoch 600 LossPred 0.2267 LossAtt 0.2002 TrainAcc 0.9200 TestAcc 0.8914 0.9000
epoch 700 LossPred 0.1532 LossAtt 0.2088 TrainAcc 0.9400 TestAcc 0.9057 0.9350
epoch 800 LossPred 0.1362 LossAtt 0.2099 TrainAcc 0.9500 TestAcc 0.9397 0.9200
epoch 900 LossPred 0.1057 LossAtt 0.2109 TrainAcc 0.9700 TestAcc 0.9279 0.9350
epoch 1000 LossPred 0.1263 LossAtt 0.2263 TrainAcc 0.9500 TestAcc 0.9367 0.9100
epoch 1100 LossPred 0.1451 LossAtt 0.2178 TrainAcc 0.9500 TestAcc 0.9092 0.9150
epoch 1200 LossPred 0.0476 LossAtt 0.2203 TrainAcc 1.0000 TestAcc 0.9499 0.9550
Optimization Finished!
********** replication  93  **********
epoch   0 LossPred 1.1863 LossAtt 1.0045 TrainAcc 0.4900 TestAcc 0.4474 0.4750
epoch 100 LossPred 0.8889 LossAtt 0.2803 TrainAcc 0.6500 TestAcc 0.6161 0.6500
epoch 200 LossPred 0.4615 LossAtt 0.2950 TrainAcc 0.9000 TestAcc 0.8541 0.8550
epoch 300 LossPred 0.2663 LossAtt 0.2917 TrainAcc 0.9100 TestAcc 0.8741 0.8950
epoch 400 LossPred 0.1931 LossAtt 0.2838 TrainAcc 0.9500 TestAcc 0.8946 0.9250
epoch 500 LossPred 0.1767 LossAtt 0.2724 TrainAcc 0.9400 TestAcc 0.8889 0.9200
epoch 600 LossPred 0.1963 LossAtt 0.2610 TrainAcc 0.9500 TestAcc 0.8864 0.9150
epoch 700 LossPred 0.1566 LossAtt 0.2587 TrainAcc 0.9400 TestAcc 0.8886 0.9200
epoch 800 LossPred 0.1458 LossAtt 0.2567 TrainAcc 0.9500 TestAcc 0.9002 0.9200
epoch 900 LossPred 0.1702 LossAtt 0.2394 TrainAcc 0.9500 TestAcc 0.8991 0.9400
epoch 1000 LossPred 0.1239 LossAtt 0.2496 TrainAcc 0.9600 TestAcc 0.8976 0.9350
epoch 1100 LossPred 0.1182 LossAtt 0.2405 TrainAcc 0.9600 TestAcc 0.9139 0.9500
epoch 1200 LossPred 0.0862 LossAtt 0.2605 TrainAcc 0.9700 TestAcc 0.9139 0.9650
epoch 1300 LossPred 0.2016 LossAtt 0.2977 TrainAcc 0.9500 TestAcc 0.8741 0.9200
epoch 1400 LossPred 0.3936 LossAtt 0.2496 TrainAcc 0.8600 TestAcc 0.8093 0.8400
epoch 1500 LossPred 0.1081 LossAtt 0.2552 TrainAcc 0.9700 TestAcc 0.8841 0.9650
epoch 1600 LossPred 0.0729 LossAtt 0.2547 TrainAcc 0.9800 TestAcc 0.9179 0.9750
epoch 1700 LossPred 0.0674 LossAtt 0.2443 TrainAcc 0.9800 TestAcc 0.9189 0.9850
epoch 1800 LossPred 0.0750 LossAtt 0.2457 TrainAcc 0.9900 TestAcc 0.9197 0.9850
epoch 1900 LossPred 0.0620 LossAtt 0.2315 TrainAcc 0.9800 TestAcc 0.9279 0.9900
epoch 2000 LossPred 0.0716 LossAtt 0.2295 TrainAcc 0.9900 TestAcc 0.9167 0.9850
epoch 2100 LossPred 0.0684 LossAtt 0.2303 TrainAcc 0.9800 TestAcc 0.9159 0.9750
epoch 2200 LossPred 0.0742 LossAtt 0.2279 TrainAcc 0.9800 TestAcc 0.9117 0.9850
epoch 2300 LossPred 0.0563 LossAtt 0.2370 TrainAcc 0.9800 TestAcc 0.9304 0.9800
epoch 2400 LossPred 0.0895 LossAtt 0.2259 TrainAcc 0.9600 TestAcc 0.9007 0.9650
epoch 2500 LossPred 0.0537 LossAtt 0.2296 TrainAcc 0.9800 TestAcc 0.9277 0.9800
Optimization Finished!
********** replication  94  **********
epoch   0 LossPred 1.2168 LossAtt 1.0110 TrainAcc 0.5200 TestAcc 0.4562 0.5200
epoch 100 LossPred 0.9131 LossAtt 0.3388 TrainAcc 0.6400 TestAcc 0.5611 0.6400
epoch 200 LossPred 0.8981 LossAtt 0.2707 TrainAcc 0.6500 TestAcc 0.5581 0.6400
epoch 300 LossPred 0.8788 LossAtt 0.2864 TrainAcc 0.6600 TestAcc 0.5613 0.6550
epoch 400 LossPred 0.8187 LossAtt 0.3179 TrainAcc 0.6400 TestAcc 0.5641 0.6400
epoch 500 LossPred 0.7683 LossAtt 0.3491 TrainAcc 0.6900 TestAcc 0.6186 0.6800
epoch 600 LossPred 0.6626 LossAtt 0.4264 TrainAcc 0.7000 TestAcc 0.6674 0.7000
epoch 700 LossPred 0.3612 LossAtt 0.4384 TrainAcc 0.9000 TestAcc 0.7943 0.8600
epoch 800 LossPred 0.2561 LossAtt 0.4152 TrainAcc 0.9300 TestAcc 0.8118 0.9000
epoch 900 LossPred 0.1564 LossAtt 0.4382 TrainAcc 0.9700 TestAcc 0.8193 0.9100
epoch 1000 LossPred 0.0943 LossAtt 0.4261 TrainAcc 0.9800 TestAcc 0.8168 0.9300
epoch 1100 LossPred 0.0987 LossAtt 0.4343 TrainAcc 0.9700 TestAcc 0.8093 0.9300
epoch 1200 LossPred 0.0658 LossAtt 0.4168 TrainAcc 0.9900 TestAcc 0.8181 0.9300
epoch 1300 LossPred 0.0484 LossAtt 0.4242 TrainAcc 0.9800 TestAcc 0.8208 0.9300
epoch 1400 LossPred 0.0307 LossAtt 0.4044 TrainAcc 1.0000 TestAcc 0.8238 0.9500
Optimization Finished!
********** replication  95  **********
epoch   0 LossPred 1.1134 LossAtt 1.0276 TrainAcc 0.4600 TestAcc 0.4977 0.4450
epoch 100 LossPred 0.9445 LossAtt 0.2793 TrainAcc 0.5900 TestAcc 0.6054 0.6100
epoch 200 LossPred 0.6623 LossAtt 0.3148 TrainAcc 0.8200 TestAcc 0.8073 0.7900
epoch 300 LossPred 0.3505 LossAtt 0.2930 TrainAcc 0.8600 TestAcc 0.8864 0.8550
epoch 400 LossPred 0.2220 LossAtt 0.2949 TrainAcc 0.9200 TestAcc 0.9304 0.8850
epoch 500 LossPred 0.2744 LossAtt 0.2689 TrainAcc 0.9100 TestAcc 0.9044 0.8750
epoch 600 LossPred 0.1640 LossAtt 0.2450 TrainAcc 0.9400 TestAcc 0.9464 0.9050
epoch 700 LossPred 0.2795 LossAtt 0.2323 TrainAcc 0.9100 TestAcc 0.8956 0.8850
epoch 800 LossPred 0.3638 LossAtt 0.2305 TrainAcc 0.8800 TestAcc 0.8601 0.8700
epoch 900 LossPred 0.2645 LossAtt 0.2362 TrainAcc 0.9200 TestAcc 0.8929 0.9000
epoch 1000 LossPred 0.2566 LossAtt 0.2094 TrainAcc 0.9100 TestAcc 0.8899 0.9000
epoch 1100 LossPred 0.1922 LossAtt 0.2169 TrainAcc 0.9600 TestAcc 0.9157 0.9250
epoch 1200 LossPred 0.1752 LossAtt 0.2125 TrainAcc 0.9400 TestAcc 0.9274 0.9100
epoch 1300 LossPred 0.2879 LossAtt 0.1963 TrainAcc 0.8900 TestAcc 0.8871 0.8800
epoch 1400 LossPred 0.2321 LossAtt 0.1980 TrainAcc 0.9400 TestAcc 0.8996 0.9050
epoch 1500 LossPred 0.1769 LossAtt 0.1911 TrainAcc 0.9300 TestAcc 0.9207 0.9200
epoch 1600 LossPred 0.1721 LossAtt 0.1905 TrainAcc 0.9400 TestAcc 0.9382 0.9200
epoch 1700 LossPred 0.1667 LossAtt 0.1862 TrainAcc 0.9400 TestAcc 0.9397 0.9300
epoch 1800 LossPred 0.1367 LossAtt 0.1795 TrainAcc 0.9600 TestAcc 0.9517 0.9400
epoch 1900 LossPred 0.1423 LossAtt 0.1911 TrainAcc 0.9600 TestAcc 0.9447 0.9500
epoch 2000 LossPred 0.1339 LossAtt 0.1878 TrainAcc 0.9600 TestAcc 0.9507 0.9600
epoch 2100 LossPred 0.1681 LossAtt 0.1860 TrainAcc 0.9600 TestAcc 0.9274 0.9400
epoch 2200 LossPred 0.1724 LossAtt 0.2001 TrainAcc 0.9400 TestAcc 0.9214 0.9250
epoch 2300 LossPred 0.1749 LossAtt 0.1914 TrainAcc 0.9400 TestAcc 0.9222 0.9350
epoch 2400 LossPred 0.1270 LossAtt 0.1930 TrainAcc 0.9500 TestAcc 0.9530 0.9600
epoch 2500 LossPred 0.1711 LossAtt 0.2003 TrainAcc 0.9300 TestAcc 0.9232 0.9300
Optimization Finished!
********** replication  96  **********
epoch   0 LossPred 1.1974 LossAtt 1.0076 TrainAcc 0.3400 TestAcc 0.4422 0.3300
epoch 100 LossPred 0.8219 LossAtt 0.2156 TrainAcc 0.7100 TestAcc 0.5978 0.7100
epoch 200 LossPred 0.8036 LossAtt 0.1787 TrainAcc 0.7100 TestAcc 0.5978 0.7100
epoch 300 LossPred 0.6303 LossAtt 0.2484 TrainAcc 0.7500 TestAcc 0.8023 0.7450
epoch 400 LossPred 0.4625 LossAtt 0.2139 TrainAcc 0.8300 TestAcc 0.8551 0.8300
epoch 500 LossPred 0.4481 LossAtt 0.2182 TrainAcc 0.8300 TestAcc 0.8529 0.8400
epoch 600 LossPred 0.4616 LossAtt 0.2257 TrainAcc 0.8400 TestAcc 0.8306 0.8250
epoch 700 LossPred 0.4346 LossAtt 0.2473 TrainAcc 0.8900 TestAcc 0.8576 0.8550
epoch 800 LossPred 0.4971 LossAtt 0.2418 TrainAcc 0.7800 TestAcc 0.8471 0.8300
epoch 900 LossPred 0.4062 LossAtt 0.2339 TrainAcc 0.8500 TestAcc 0.8744 0.8350
epoch 1000 LossPred 0.4024 LossAtt 0.2275 TrainAcc 0.8500 TestAcc 0.8799 0.8600
epoch 1100 LossPred 0.4414 LossAtt 0.2254 TrainAcc 0.8500 TestAcc 0.8546 0.8550
epoch 1200 LossPred 0.3832 LossAtt 0.2165 TrainAcc 0.8800 TestAcc 0.8796 0.8750
epoch 1300 LossPred 0.3848 LossAtt 0.2248 TrainAcc 0.8600 TestAcc 0.8691 0.8550
epoch 1400 LossPred 0.3892 LossAtt 0.2283 TrainAcc 0.8300 TestAcc 0.8784 0.8550
epoch 1500 LossPred 0.3974 LossAtt 0.2247 TrainAcc 0.8500 TestAcc 0.8566 0.8600
epoch 1600 LossPred 0.4184 LossAtt 0.2369 TrainAcc 0.8200 TestAcc 0.8398 0.8450
epoch 1700 LossPred 0.3704 LossAtt 0.2546 TrainAcc 0.8600 TestAcc 0.8791 0.8500
epoch 1800 LossPred 0.5166 LossAtt 0.2428 TrainAcc 0.8200 TestAcc 0.8411 0.8250
epoch 1900 LossPred 0.6290 LossAtt 0.2373 TrainAcc 0.7500 TestAcc 0.7625 0.7600
epoch 2000 LossPred 0.3551 LossAtt 0.2532 TrainAcc 0.8700 TestAcc 0.8889 0.8450
epoch 2100 LossPred 0.4010 LossAtt 0.2587 TrainAcc 0.8400 TestAcc 0.8521 0.8500
epoch 2200 LossPred 0.3896 LossAtt 0.2541 TrainAcc 0.8600 TestAcc 0.8564 0.8350
epoch 2300 LossPred 0.3056 LossAtt 0.2531 TrainAcc 0.9000 TestAcc 0.9047 0.8800
epoch 2400 LossPred 0.4601 LossAtt 0.2416 TrainAcc 0.8200 TestAcc 0.8258 0.8300
epoch 2500 LossPred 0.4286 LossAtt 0.2445 TrainAcc 0.8400 TestAcc 0.8396 0.8250
Optimization Finished!
********** replication  97  **********
epoch   0 LossPred 1.0286 LossAtt 1.0240 TrainAcc 0.4300 TestAcc 0.3916 0.4400
epoch 100 LossPred 0.8863 LossAtt 0.3209 TrainAcc 0.6500 TestAcc 0.6326 0.6250
epoch 200 LossPred 0.3767 LossAtt 0.2870 TrainAcc 0.8700 TestAcc 0.8571 0.8800
epoch 300 LossPred 0.3257 LossAtt 0.2737 TrainAcc 0.9100 TestAcc 0.8559 0.8700
epoch 400 LossPred 0.3360 LossAtt 0.2605 TrainAcc 0.8700 TestAcc 0.8839 0.8400
epoch 500 LossPred 0.4088 LossAtt 0.2840 TrainAcc 0.8500 TestAcc 0.8866 0.8450
epoch 600 LossPred 0.3547 LossAtt 0.2820 TrainAcc 0.8700 TestAcc 0.8363 0.8550
epoch 700 LossPred 0.2105 LossAtt 0.2790 TrainAcc 0.9300 TestAcc 0.9194 0.8850
epoch 800 LossPred 0.1662 LossAtt 0.2872 TrainAcc 0.9400 TestAcc 0.9224 0.9300
epoch 900 LossPred 0.3704 LossAtt 0.2751 TrainAcc 0.8900 TestAcc 0.8203 0.8800
epoch 1000 LossPred 0.1849 LossAtt 0.2896 TrainAcc 0.9400 TestAcc 0.9082 0.9100
epoch 1100 LossPred 0.1623 LossAtt 0.2557 TrainAcc 0.9500 TestAcc 0.9199 0.9500
epoch 1200 LossPred 0.1870 LossAtt 0.2564 TrainAcc 0.9500 TestAcc 0.8984 0.9400
epoch 1300 LossPred 0.1958 LossAtt 0.2595 TrainAcc 0.9600 TestAcc 0.8909 0.9300
epoch 1400 LossPred 0.1578 LossAtt 0.2757 TrainAcc 0.9400 TestAcc 0.9097 0.9350
epoch 1500 LossPred 0.1590 LossAtt 0.2526 TrainAcc 0.9500 TestAcc 0.9044 0.9500
epoch 1600 LossPred 0.1599 LossAtt 0.2632 TrainAcc 0.9500 TestAcc 0.9142 0.9500
epoch 1700 LossPred 0.3667 LossAtt 0.2606 TrainAcc 0.8900 TestAcc 0.7993 0.8750
epoch 1800 LossPred 0.2442 LossAtt 0.2520 TrainAcc 0.9200 TestAcc 0.9057 0.9250
epoch 1900 LossPred 0.1249 LossAtt 0.2581 TrainAcc 0.9500 TestAcc 0.9112 0.9700
epoch 2000 LossPred 0.1723 LossAtt 0.2572 TrainAcc 0.9400 TestAcc 0.8961 0.9400
epoch 2100 LossPred 0.0963 LossAtt 0.2637 TrainAcc 0.9800 TestAcc 0.9107 0.9750
epoch 2200 LossPred 0.1082 LossAtt 0.2726 TrainAcc 0.9600 TestAcc 0.9334 0.9700
epoch 2300 LossPred 0.2198 LossAtt 0.2683 TrainAcc 0.9400 TestAcc 0.8706 0.9250
epoch 2400 LossPred 0.1006 LossAtt 0.2785 TrainAcc 0.9700 TestAcc 0.9332 0.9700
epoch 2500 LossPred 0.1890 LossAtt 0.2688 TrainAcc 0.9300 TestAcc 0.8871 0.9300
Optimization Finished!
********** replication  98  **********
epoch   0 LossPred 0.9366 LossAtt 1.0373 TrainAcc 0.6200 TestAcc 0.6124 0.6000
epoch 100 LossPred 0.8820 LossAtt 0.2790 TrainAcc 0.6500 TestAcc 0.5808 0.6500
epoch 200 LossPred 0.8741 LossAtt 0.1759 TrainAcc 0.6500 TestAcc 0.5808 0.6500
epoch 300 LossPred 0.8722 LossAtt 0.1506 TrainAcc 0.6500 TestAcc 0.5808 0.6700
epoch 400 LossPred 0.9233 LossAtt 0.1219 TrainAcc 0.6200 TestAcc 0.6124 0.6200
epoch 500 LossPred 0.4007 LossAtt 0.2039 TrainAcc 0.8200 TestAcc 0.8604 0.8100
epoch 600 LossPred 0.2593 LossAtt 0.1891 TrainAcc 0.9000 TestAcc 0.8904 0.8600
epoch 700 LossPred 0.2269 LossAtt 0.1847 TrainAcc 0.9200 TestAcc 0.8871 0.8900
epoch 800 LossPred 0.1698 LossAtt 0.1750 TrainAcc 0.9500 TestAcc 0.9079 0.9150
epoch 900 LossPred 0.1540 LossAtt 0.1699 TrainAcc 0.9500 TestAcc 0.9124 0.9150
epoch 1000 LossPred 0.1506 LossAtt 0.1720 TrainAcc 0.9500 TestAcc 0.9109 0.9150
epoch 1100 LossPred 0.1500 LossAtt 0.1576 TrainAcc 0.9500 TestAcc 0.9197 0.9250
epoch 1200 LossPred 0.1450 LossAtt 0.1714 TrainAcc 0.9500 TestAcc 0.9094 0.9250
epoch 1300 LossPred 0.1347 LossAtt 0.1662 TrainAcc 0.9500 TestAcc 0.9117 0.9250
epoch 1400 LossPred 0.1815 LossAtt 0.1619 TrainAcc 0.9400 TestAcc 0.9117 0.9250
epoch 1500 LossPred 0.2258 LossAtt 0.1649 TrainAcc 0.9300 TestAcc 0.8846 0.9000
epoch 1600 LossPred 0.1250 LossAtt 0.1646 TrainAcc 0.9600 TestAcc 0.9174 0.9300
epoch 1700 LossPred 0.3816 LossAtt 0.1801 TrainAcc 0.8600 TestAcc 0.8574 0.8500
epoch 1800 LossPred 0.4292 LossAtt 0.1826 TrainAcc 0.8400 TestAcc 0.8551 0.8500
epoch 1900 LossPred 0.3009 LossAtt 0.1703 TrainAcc 0.9000 TestAcc 0.8914 0.8850
epoch 2000 LossPred 0.1248 LossAtt 0.1676 TrainAcc 0.9600 TestAcc 0.9229 0.9300
epoch 2100 LossPred 0.1256 LossAtt 0.1643 TrainAcc 0.9700 TestAcc 0.9152 0.9150
epoch 2200 LossPred 0.1198 LossAtt 0.1631 TrainAcc 0.9600 TestAcc 0.9252 0.9200
epoch 2300 LossPred 0.1190 LossAtt 0.1599 TrainAcc 0.9700 TestAcc 0.9332 0.9400
epoch 2400 LossPred 0.1448 LossAtt 0.1554 TrainAcc 0.9400 TestAcc 0.9254 0.9250
epoch 2500 LossPred 0.1187 LossAtt 0.1530 TrainAcc 0.9600 TestAcc 0.9352 0.9250
Optimization Finished!
********** replication  99  **********
epoch   0 LossPred 1.0542 LossAtt 1.0004 TrainAcc 0.4800 TestAcc 0.5400 0.4850
epoch 100 LossPred 0.8575 LossAtt 0.2973 TrainAcc 0.6300 TestAcc 0.5986 0.6500
epoch 200 LossPred 0.5759 LossAtt 0.2903 TrainAcc 0.7700 TestAcc 0.8001 0.7750
epoch 300 LossPred 0.4156 LossAtt 0.2491 TrainAcc 0.8700 TestAcc 0.8331 0.8650
epoch 400 LossPred 0.3991 LossAtt 0.2456 TrainAcc 0.8600 TestAcc 0.8308 0.8450
epoch 500 LossPred 0.4289 LossAtt 0.2485 TrainAcc 0.8300 TestAcc 0.8281 0.8300
epoch 600 LossPred 0.3979 LossAtt 0.2376 TrainAcc 0.8700 TestAcc 0.8611 0.8500
epoch 700 LossPred 0.2643 LossAtt 0.2297 TrainAcc 0.9100 TestAcc 0.8906 0.9100
epoch 800 LossPred 0.3494 LossAtt 0.2497 TrainAcc 0.8600 TestAcc 0.8456 0.8700
epoch 900 LossPred 0.2337 LossAtt 0.2388 TrainAcc 0.9100 TestAcc 0.8909 0.9100
epoch 1000 LossPred 0.3089 LossAtt 0.2360 TrainAcc 0.9000 TestAcc 0.8916 0.9000
epoch 1100 LossPred 0.2644 LossAtt 0.2405 TrainAcc 0.9100 TestAcc 0.8681 0.8900
epoch 1200 LossPred 0.3210 LossAtt 0.2471 TrainAcc 0.9200 TestAcc 0.8859 0.8850
epoch 1300 LossPred 0.3440 LossAtt 0.2426 TrainAcc 0.8900 TestAcc 0.8701 0.8650
epoch 1400 LossPred 0.3572 LossAtt 0.2740 TrainAcc 0.8700 TestAcc 0.8488 0.8550
epoch 1500 LossPred 0.2322 LossAtt 0.2705 TrainAcc 0.9100 TestAcc 0.9029 0.9200
epoch 1600 LossPred 0.2001 LossAtt 0.2796 TrainAcc 0.9400 TestAcc 0.8804 0.9250
epoch 1700 LossPred 0.1224 LossAtt 0.2760 TrainAcc 0.9500 TestAcc 0.9054 0.9450
epoch 1800 LossPred 0.1276 LossAtt 0.2856 TrainAcc 0.9500 TestAcc 0.8929 0.9500
epoch 1900 LossPred 0.1727 LossAtt 0.3058 TrainAcc 0.9400 TestAcc 0.8809 0.9300
epoch 2000 LossPred 0.1092 LossAtt 0.2867 TrainAcc 0.9600 TestAcc 0.8981 0.9550
epoch 2100 LossPred 0.0913 LossAtt 0.2791 TrainAcc 0.9900 TestAcc 0.9117 0.9450
epoch 2200 LossPred 0.1148 LossAtt 0.2820 TrainAcc 0.9600 TestAcc 0.8861 0.9300
epoch 2300 LossPred 0.1535 LossAtt 0.2757 TrainAcc 0.9400 TestAcc 0.9144 0.9500
epoch 2400 LossPred 0.0758 LossAtt 0.2805 TrainAcc 0.9700 TestAcc 0.9002 0.9600
epoch 2500 LossPred 0.1958 LossAtt 0.2815 TrainAcc 0.9100 TestAcc 0.8716 0.9100
Optimization Finished!
********************************************************************
Namespace(arch='tanh', batch_size=256, display_epoch=100, input_noise_level=0.15, latent_attractor_space=True, loss_switch_frequency=0, lrate_attractor=0.002, lrate_prediction=0.002, lrate_wt_penalty=0.0, n_attractor_hidden=20, n_attractor_steps=5, n_hidden=10, n_replications=100, noise_level=0.5, report_best_train_performance=True, seq_len=15, task='majority', train_attr_weights_on_prediction=False, training_epochs=2500)
********************************************************************
mean train accuracy 0.97450006
indiv runs  [0.99, 1.0, 0.98, 1.0, 0.97, 1.0, 0.98, 0.99, 0.95, 0.98, 0.99, 0.98, 1.0, 1.0, 0.98, 0.98, 0.99, 0.99, 1.0, 1.0, 0.99, 0.99, 1.0, 0.97, 0.95, 0.95, 0.98, 0.91, 0.97, 0.97, 0.97, 0.99, 0.92, 0.94, 0.82, 0.96, 0.99, 0.98, 0.96, 1.0, 0.96, 0.96, 0.98, 0.99, 1.0, 0.99, 0.97, 0.96, 0.99, 1.0, 1.0, 0.99, 0.92, 0.98, 0.99, 0.99, 0.99, 1.0, 0.95, 0.95, 0.88, 0.98, 0.95, 0.96, 0.96, 0.99, 1.0, 0.96, 0.97, 1.0, 0.98, 0.96, 0.99, 0.96, 0.97, 1.0, 0.98, 0.99, 0.97, 0.98, 1.0, 0.97, 1.0, 0.98, 0.99, 0.98, 1.0, 0.9, 0.99, 0.95, 0.98, 0.97, 1.0, 0.99, 1.0, 0.96, 0.9, 0.98, 0.97, 0.99]
mean epoch 1358.14285714
indiv epochs  [1201, 2001, 1401, 1501, 601, 2201, 701, 1601, 1701, 2401, 801, 1101, 1101, 1101, 901, 1901, 1601, 601, 1501, 1201, 1401]
test1 accuracy mean  0.8982482  median  0.916041
test2 accuracy mean  0.9428  median  0.945
test1 indiv runs  [0.9164164, 0.9191692, 0.9274274, 0.951952, 0.9216717, 0.9204204, 0.9101602, 0.9024024, 0.9104104, 0.9291792, 0.9054054, 0.9474474, 0.9276777, 0.9394394, 0.9206707, 0.8951451, 0.9554555, 0.9274274, 0.8470971, 0.9084084, 0.9289289, 0.9146647, 0.8583584, 0.8616116, 0.8733734, 0.9291792, 0.9236737, 0.8490991, 0.8826326, 0.9366867, 0.8721221, 0.9179179, 0.5955956, 0.8806306, 0.5968468, 0.9476977, 0.9657157, 0.9171672, 0.9046547, 0.8846346, 0.9256757, 0.8893894, 0.9281782, 0.957958, 0.8631131, 0.9622122, 0.8866366, 0.5565566, 0.9241742, 0.9079079, 0.9486987, 0.9046547, 0.8798799, 0.9544545, 0.9446947, 0.9149149, 0.9309309, 0.9149149, 0.9019019, 0.9144144, 0.5938438, 0.9011512, 0.8943944, 0.9044044, 0.8896396, 0.9139139, 0.9279279, 0.9231732, 0.9574575, 0.9647147, 0.9079079, 0.9276777, 0.8808809, 0.9364364, 0.8691191, 0.9154154, 0.9406907, 0.9604605, 0.9319319, 0.7947948, 0.9109109, 0.9021522, 0.9164164, 0.9554555, 0.9612112, 0.9319319, 0.9334334, 0.5750751, 0.9381882, 0.9189189, 0.9264264, 0.9316817, 0.9499499, 0.9196697, 0.8238238, 0.9156657, 0.9046547, 0.9106607, 0.9151652, 0.9116617]
test2 indiv runs  [0.975, 0.965, 0.97, 0.98, 0.935, 0.915, 0.955, 0.99, 0.895, 0.935, 0.9, 0.945, 1.0, 1.0, 0.94, 0.94, 0.94, 0.93, 0.98, 0.99, 0.945, 0.975, 0.96, 0.93, 0.915, 0.93, 0.96, 0.86, 0.925, 0.925, 0.97, 0.96, 0.835, 0.92, 0.77, 0.945, 0.985, 0.985, 0.95, 0.975, 0.94, 0.945, 0.965, 0.97, 0.975, 0.97, 0.925, 0.89, 0.935, 0.975, 0.98, 0.99, 0.89, 0.97, 0.945, 0.97, 0.97, 0.995, 0.895, 0.95, 0.805, 0.93, 0.9, 0.91, 0.93, 0.975, 0.945, 0.96, 0.98, 0.95, 0.965, 0.905, 0.93, 0.92, 0.91, 0.985, 0.975, 0.99, 0.965, 0.905, 0.995, 0.97, 0.94, 0.985, 0.955, 0.945, 0.98, 0.79, 0.93, 0.93, 0.925, 0.925, 0.955, 0.985, 0.95, 0.925, 0.88, 0.975, 0.915, 0.945]
