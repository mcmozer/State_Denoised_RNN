Namespace(arch='tanh', batch_size=256, display_epoch=100, input_noise_level=0.15, latent_attractor_space=True, loss_switch_frequency=0, lrate_attractor=0.002, lrate_prediction=0.002, lrate_wt_penalty=0.0, n_attractor_hidden=10, n_attractor_steps=15, n_hidden=5, n_replications=100, noise_level=0.5, report_best_train_performance=True, seq_len=25, task='majority', train_attr_weights_on_prediction=False, training_epochs=2500)
TRAINING ON 100 EXAMPLES, TESTING ON 3996
********** replication  0  **********
epoch   0 LossPred 1.0830 LossAtt 1.0341 TrainAcc 0.4800 TestAcc 0.5283 0.5450
epoch 100 LossPred 0.9195 LossAtt 0.4445 TrainAcc 0.5900 TestAcc 0.5821 0.5900
epoch 200 LossPred 0.8732 LossAtt 0.3870 TrainAcc 0.6400 TestAcc 0.5823 0.6450
epoch 300 LossPred 0.8561 LossAtt 0.3877 TrainAcc 0.6400 TestAcc 0.5831 0.6350
epoch 400 LossPred 0.8478 LossAtt 0.2692 TrainAcc 0.6500 TestAcc 0.5978 0.6400
epoch 500 LossPred 0.8508 LossAtt 0.2095 TrainAcc 0.6500 TestAcc 0.5978 0.6350
epoch 600 LossPred 0.8491 LossAtt 0.1928 TrainAcc 0.6500 TestAcc 0.5978 0.6400
epoch 700 LossPred 0.8490 LossAtt 0.2084 TrainAcc 0.6500 TestAcc 0.5846 0.6600
epoch 800 LossPred 0.8393 LossAtt 0.2812 TrainAcc 0.6500 TestAcc 0.5978 0.6500
epoch 900 LossPred 0.8199 LossAtt 0.4517 TrainAcc 0.7200 TestAcc 0.6191 0.6550
epoch 1000 LossPred 0.6486 LossAtt 0.5867 TrainAcc 0.7800 TestAcc 0.7610 0.7550
epoch 1100 LossPred 0.6205 LossAtt 0.5666 TrainAcc 0.7700 TestAcc 0.7262 0.7500
epoch 1200 LossPred 0.5764 LossAtt 0.5792 TrainAcc 0.7900 TestAcc 0.7585 0.7600
epoch 1300 LossPred 0.5779 LossAtt 0.5919 TrainAcc 0.7800 TestAcc 0.7402 0.7800
epoch 1400 LossPred 0.4716 LossAtt 0.5899 TrainAcc 0.8400 TestAcc 0.7958 0.8200
epoch 1500 LossPred 0.5530 LossAtt 0.5797 TrainAcc 0.8300 TestAcc 0.7760 0.7850
epoch 1600 LossPred 0.4485 LossAtt 0.5880 TrainAcc 0.8700 TestAcc 0.8033 0.8200
epoch 1700 LossPred 0.4877 LossAtt 0.5927 TrainAcc 0.8500 TestAcc 0.8036 0.8000
epoch 1800 LossPred 0.4960 LossAtt 0.5943 TrainAcc 0.8400 TestAcc 0.8051 0.8300
epoch 1900 LossPred 0.4657 LossAtt 0.5852 TrainAcc 0.8500 TestAcc 0.8011 0.8050
epoch 2000 LossPred 0.4579 LossAtt 0.5904 TrainAcc 0.8800 TestAcc 0.7973 0.8300
epoch 2100 LossPred 0.5421 LossAtt 0.5845 TrainAcc 0.8000 TestAcc 0.7798 0.8300
epoch 2200 LossPred 0.4810 LossAtt 0.5437 TrainAcc 0.8500 TestAcc 0.7880 0.7550
epoch 2300 LossPred 0.5314 LossAtt 0.5637 TrainAcc 0.8100 TestAcc 0.7793 0.8350
epoch 2400 LossPred 0.3860 LossAtt 0.5645 TrainAcc 0.8900 TestAcc 0.8081 0.8700
epoch 2500 LossPred 0.4346 LossAtt 0.5751 TrainAcc 0.8800 TestAcc 0.7975 0.8100
Optimization Finished!
********** replication  1  **********
epoch   0 LossPred 1.1337 LossAtt 0.9976 TrainAcc 0.5500 TestAcc 0.4710 0.5550
epoch 100 LossPred 0.9993 LossAtt 0.2875 TrainAcc 0.5900 TestAcc 0.5040 0.5600
epoch 200 LossPred 0.9548 LossAtt 0.3077 TrainAcc 0.5900 TestAcc 0.5040 0.5900
epoch 300 LossPred 0.9121 LossAtt 0.4173 TrainAcc 0.6500 TestAcc 0.6084 0.6500
epoch 400 LossPred 0.4445 LossAtt 0.4846 TrainAcc 0.8500 TestAcc 0.8223 0.8050
epoch 500 LossPred 0.3842 LossAtt 0.4429 TrainAcc 0.8600 TestAcc 0.8191 0.8250
epoch 600 LossPred 0.4266 LossAtt 0.4300 TrainAcc 0.8500 TestAcc 0.8113 0.8200
epoch 700 LossPred 0.4388 LossAtt 0.4485 TrainAcc 0.8600 TestAcc 0.7898 0.8300
epoch 800 LossPred 0.3766 LossAtt 0.4578 TrainAcc 0.8700 TestAcc 0.8116 0.8450
epoch 900 LossPred 0.4081 LossAtt 0.4657 TrainAcc 0.8600 TestAcc 0.8223 0.8350
epoch 1000 LossPred 0.3488 LossAtt 0.4483 TrainAcc 0.8900 TestAcc 0.8111 0.8450
epoch 1100 LossPred 0.3093 LossAtt 0.4580 TrainAcc 0.9000 TestAcc 0.8208 0.8400
epoch 1200 LossPred 0.3279 LossAtt 0.4365 TrainAcc 0.8900 TestAcc 0.8108 0.8450
epoch 1300 LossPred 0.3301 LossAtt 0.4258 TrainAcc 0.9000 TestAcc 0.8138 0.8400
epoch 1400 LossPred 0.3539 LossAtt 0.4296 TrainAcc 0.8800 TestAcc 0.8176 0.8250
epoch 1500 LossPred 0.4834 LossAtt 0.4083 TrainAcc 0.8400 TestAcc 0.7873 0.8050
epoch 1600 LossPred 0.3394 LossAtt 0.3957 TrainAcc 0.8800 TestAcc 0.8163 0.8250
epoch 1700 LossPred 0.3500 LossAtt 0.3988 TrainAcc 0.8800 TestAcc 0.8151 0.8400
epoch 1800 LossPred 0.3630 LossAtt 0.3872 TrainAcc 0.8800 TestAcc 0.8056 0.8400
epoch 1900 LossPred 0.3753 LossAtt 0.3779 TrainAcc 0.8700 TestAcc 0.7860 0.8300
epoch 2000 LossPred 0.3553 LossAtt 0.3904 TrainAcc 0.8800 TestAcc 0.8036 0.8500
epoch 2100 LossPred 0.4086 LossAtt 0.3940 TrainAcc 0.8700 TestAcc 0.7755 0.8150
epoch 2200 LossPred 0.4166 LossAtt 0.3850 TrainAcc 0.8600 TestAcc 0.7948 0.8350
epoch 2300 LossPred 0.3942 LossAtt 0.3904 TrainAcc 0.8700 TestAcc 0.7780 0.8250
epoch 2400 LossPred 0.3947 LossAtt 0.4013 TrainAcc 0.8700 TestAcc 0.7810 0.8250
epoch 2500 LossPred 0.3869 LossAtt 0.4095 TrainAcc 0.8700 TestAcc 0.7783 0.8250
Optimization Finished!
********** replication  2  **********
epoch   0 LossPred 1.1526 LossAtt 1.0278 TrainAcc 0.4200 TestAcc 0.4237 0.4150
epoch 100 LossPred 0.9686 LossAtt 0.3284 TrainAcc 0.6300 TestAcc 0.5783 0.6300
epoch 200 LossPred 0.9374 LossAtt 0.1897 TrainAcc 0.6300 TestAcc 0.5783 0.6300
epoch 300 LossPred 0.9317 LossAtt 0.2556 TrainAcc 0.6300 TestAcc 0.5783 0.6300
epoch 400 LossPred 0.9298 LossAtt 0.3364 TrainAcc 0.6300 TestAcc 0.5783 0.6300
epoch 500 LossPred 0.9228 LossAtt 0.3618 TrainAcc 0.6300 TestAcc 0.5783 0.6300
epoch 600 LossPred 0.9163 LossAtt 0.4042 TrainAcc 0.6300 TestAcc 0.5783 0.6300
epoch 700 LossPred 0.8536 LossAtt 0.3870 TrainAcc 0.6700 TestAcc 0.5250 0.6550
epoch 800 LossPred 0.8550 LossAtt 0.3272 TrainAcc 0.6500 TestAcc 0.5290 0.6600
epoch 900 LossPred 0.8624 LossAtt 0.3700 TrainAcc 0.6600 TestAcc 0.5240 0.6450
epoch 1000 LossPred 0.8625 LossAtt 0.4244 TrainAcc 0.6400 TestAcc 0.5260 0.6400
epoch 1100 LossPred 0.8131 LossAtt 0.4515 TrainAcc 0.6800 TestAcc 0.5175 0.6700
epoch 1200 LossPred 0.8289 LossAtt 0.4611 TrainAcc 0.6900 TestAcc 0.5240 0.6900
epoch 1300 LossPred 0.8383 LossAtt 0.4666 TrainAcc 0.6600 TestAcc 0.5230 0.6800
epoch 1400 LossPred 0.8368 LossAtt 0.5041 TrainAcc 0.6700 TestAcc 0.5268 0.6650
epoch 1500 LossPred 0.8417 LossAtt 0.4784 TrainAcc 0.6700 TestAcc 0.5273 0.6650
epoch 1600 LossPred 0.8612 LossAtt 0.3814 TrainAcc 0.6600 TestAcc 0.5365 0.6550
epoch 1700 LossPred 0.8571 LossAtt 0.3811 TrainAcc 0.6700 TestAcc 0.5273 0.6650
epoch 1800 LossPred 0.8438 LossAtt 0.3941 TrainAcc 0.6800 TestAcc 0.5213 0.6550
epoch 1900 LossPred 0.8383 LossAtt 0.4561 TrainAcc 0.6800 TestAcc 0.5245 0.6450
epoch 2000 LossPred 0.8350 LossAtt 0.4327 TrainAcc 0.6600 TestAcc 0.5338 0.6600
epoch 2100 LossPred 0.7975 LossAtt 0.4313 TrainAcc 0.6800 TestAcc 0.5258 0.6450
epoch 2200 LossPred 0.8159 LossAtt 0.4209 TrainAcc 0.6900 TestAcc 0.5260 0.6350
epoch 2300 LossPred 0.7978 LossAtt 0.4359 TrainAcc 0.6800 TestAcc 0.5268 0.6400
epoch 2400 LossPred 0.7932 LossAtt 0.4189 TrainAcc 0.6900 TestAcc 0.5345 0.6550
epoch 2500 LossPred 0.7936 LossAtt 0.3768 TrainAcc 0.7100 TestAcc 0.5370 0.6850
Optimization Finished!
********** replication  3  **********
epoch   0 LossPred 1.0964 LossAtt 1.0169 TrainAcc 0.4400 TestAcc 0.3979 0.4600
epoch 100 LossPred 0.9911 LossAtt 0.2691 TrainAcc 0.5400 TestAcc 0.5105 0.5400
epoch 200 LossPred 0.9826 LossAtt 0.2226 TrainAcc 0.5600 TestAcc 0.6021 0.5650
epoch 300 LossPred 0.9764 LossAtt 0.2745 TrainAcc 0.5600 TestAcc 0.6021 0.5600
epoch 400 LossPred 0.4968 LossAtt 0.4572 TrainAcc 0.8700 TestAcc 0.8498 0.8850
epoch 500 LossPred 0.5317 LossAtt 0.4250 TrainAcc 0.8200 TestAcc 0.7878 0.8300
epoch 600 LossPred 0.7345 LossAtt 0.3819 TrainAcc 0.7100 TestAcc 0.7202 0.7250
epoch 700 LossPred 0.3410 LossAtt 0.3410 TrainAcc 0.8900 TestAcc 0.8421 0.9000
epoch 800 LossPred 0.3177 LossAtt 0.3300 TrainAcc 0.9100 TestAcc 0.8361 0.8750
epoch 900 LossPred 0.4157 LossAtt 0.3465 TrainAcc 0.8500 TestAcc 0.8363 0.8750
epoch 1000 LossPred 0.3702 LossAtt 0.3535 TrainAcc 0.8900 TestAcc 0.8361 0.8700
epoch 1100 LossPred 0.3572 LossAtt 0.3237 TrainAcc 0.8900 TestAcc 0.8321 0.8800
epoch 1200 LossPred 0.3019 LossAtt 0.3158 TrainAcc 0.9100 TestAcc 0.8373 0.9050
epoch 1300 LossPred 0.3555 LossAtt 0.3342 TrainAcc 0.9000 TestAcc 0.8398 0.8900
epoch 1400 LossPred 0.3871 LossAtt 0.3373 TrainAcc 0.8600 TestAcc 0.8403 0.8650
epoch 1500 LossPred 0.4010 LossAtt 0.3196 TrainAcc 0.8600 TestAcc 0.8198 0.8600
epoch 1600 LossPred 0.4118 LossAtt 0.3271 TrainAcc 0.8700 TestAcc 0.8333 0.8450
epoch 1700 LossPred 0.4086 LossAtt 0.3180 TrainAcc 0.8600 TestAcc 0.8358 0.8650
epoch 1800 LossPred 0.4404 LossAtt 0.3262 TrainAcc 0.8500 TestAcc 0.8016 0.8500
epoch 1900 LossPred 0.5790 LossAtt 0.3241 TrainAcc 0.8300 TestAcc 0.7843 0.8150
epoch 2000 LossPred 0.5137 LossAtt 0.3111 TrainAcc 0.8200 TestAcc 0.7928 0.8300
epoch 2100 LossPred 0.4481 LossAtt 0.3451 TrainAcc 0.8400 TestAcc 0.8323 0.8450
epoch 2200 LossPred 0.4295 LossAtt 0.3053 TrainAcc 0.8400 TestAcc 0.8266 0.8550
epoch 2300 LossPred 0.3680 LossAtt 0.3057 TrainAcc 0.8900 TestAcc 0.8323 0.8900
epoch 2400 LossPred 0.6430 LossAtt 0.3241 TrainAcc 0.7600 TestAcc 0.7450 0.7450
epoch 2500 LossPred 0.3377 LossAtt 0.3141 TrainAcc 0.9100 TestAcc 0.8318 0.9000
Optimization Finished!
********** replication  4  **********
epoch   0 LossPred 1.3185 LossAtt 1.0041 TrainAcc 0.4400 TestAcc 0.4184 0.4700
epoch 100 LossPred 1.0517 LossAtt 0.5161 TrainAcc 0.3900 TestAcc 0.4179 0.4000
epoch 200 LossPred 0.9752 LossAtt 0.5175 TrainAcc 0.5900 TestAcc 0.5380 0.5900
epoch 300 LossPred 0.8896 LossAtt 0.5095 TrainAcc 0.6600 TestAcc 0.5686 0.6600
epoch 400 LossPred 0.8501 LossAtt 0.4870 TrainAcc 0.6800 TestAcc 0.5926 0.6700
epoch 500 LossPred 0.7838 LossAtt 0.4635 TrainAcc 0.7000 TestAcc 0.6451 0.7150
epoch 600 LossPred 0.7558 LossAtt 0.4482 TrainAcc 0.7200 TestAcc 0.6371 0.7200
epoch 700 LossPred 0.7450 LossAtt 0.4399 TrainAcc 0.7400 TestAcc 0.6589 0.7350
epoch 800 LossPred 0.7281 LossAtt 0.4189 TrainAcc 0.7500 TestAcc 0.6544 0.7150
epoch 900 LossPred 0.7106 LossAtt 0.3955 TrainAcc 0.7500 TestAcc 0.6602 0.7200
epoch 1000 LossPred 0.7780 LossAtt 0.3782 TrainAcc 0.6900 TestAcc 0.6306 0.6750
epoch 1100 LossPred 0.7009 LossAtt 0.3769 TrainAcc 0.7500 TestAcc 0.6557 0.7150
epoch 1200 LossPred 0.7006 LossAtt 0.3735 TrainAcc 0.7500 TestAcc 0.6567 0.7250
epoch 1300 LossPred 0.7118 LossAtt 0.3546 TrainAcc 0.7500 TestAcc 0.6464 0.7200
epoch 1400 LossPred 0.6968 LossAtt 0.3670 TrainAcc 0.7500 TestAcc 0.6529 0.7250
epoch 1500 LossPred 0.7149 LossAtt 0.3701 TrainAcc 0.7500 TestAcc 0.6371 0.7150
epoch 1600 LossPred 0.7412 LossAtt 0.3644 TrainAcc 0.6700 TestAcc 0.6604 0.7150
epoch 1700 LossPred 0.7068 LossAtt 0.3661 TrainAcc 0.7500 TestAcc 0.6454 0.7250
epoch 1800 LossPred 0.7011 LossAtt 0.3725 TrainAcc 0.7200 TestAcc 0.6652 0.7200
epoch 1900 LossPred 0.6816 LossAtt 0.3886 TrainAcc 0.7500 TestAcc 0.6532 0.7400
epoch 2000 LossPred 0.6935 LossAtt 0.3653 TrainAcc 0.7400 TestAcc 0.6614 0.7250
epoch 2100 LossPred 0.6798 LossAtt 0.3668 TrainAcc 0.7400 TestAcc 0.6471 0.7350
epoch 2200 LossPred 0.7497 LossAtt 0.3832 TrainAcc 0.7100 TestAcc 0.6484 0.7300
epoch 2300 LossPred 0.6630 LossAtt 0.3528 TrainAcc 0.7700 TestAcc 0.6491 0.7300
epoch 2400 LossPred 0.7277 LossAtt 0.3730 TrainAcc 0.7200 TestAcc 0.6261 0.7050
epoch 2500 LossPred 0.6946 LossAtt 0.3362 TrainAcc 0.7400 TestAcc 0.6512 0.7450
Optimization Finished!
********** replication  5  **********
epoch   0 LossPred 1.0208 LossAtt 1.0038 TrainAcc 0.5800 TestAcc 0.5355 0.5500
epoch 100 LossPred 0.9471 LossAtt 0.4374 TrainAcc 0.6100 TestAcc 0.5653 0.6150
epoch 200 LossPred 0.9405 LossAtt 0.3856 TrainAcc 0.6100 TestAcc 0.5653 0.6150
epoch 300 LossPred 0.9340 LossAtt 0.3841 TrainAcc 0.6100 TestAcc 0.5653 0.6100
epoch 400 LossPred 0.8882 LossAtt 0.4472 TrainAcc 0.6400 TestAcc 0.6099 0.6350
epoch 500 LossPred 0.3938 LossAtt 0.3811 TrainAcc 0.8900 TestAcc 0.8238 0.8700
epoch 600 LossPred 0.3238 LossAtt 0.3106 TrainAcc 0.9000 TestAcc 0.8308 0.8850
epoch 700 LossPred 0.2816 LossAtt 0.2924 TrainAcc 0.9200 TestAcc 0.8146 0.8800
epoch 800 LossPred 0.3159 LossAtt 0.2846 TrainAcc 0.8900 TestAcc 0.8041 0.8650
epoch 900 LossPred 0.2688 LossAtt 0.2638 TrainAcc 0.9100 TestAcc 0.7985 0.8900
epoch 1000 LossPred 0.3953 LossAtt 0.2961 TrainAcc 0.8700 TestAcc 0.8048 0.8600
epoch 1100 LossPred 0.3936 LossAtt 0.3026 TrainAcc 0.8700 TestAcc 0.8171 0.8600
epoch 1200 LossPred 0.2691 LossAtt 0.2850 TrainAcc 0.9200 TestAcc 0.7848 0.8800
epoch 1300 LossPred 0.3920 LossAtt 0.3080 TrainAcc 0.8700 TestAcc 0.8218 0.8650
epoch 1400 LossPred 0.3446 LossAtt 0.3166 TrainAcc 0.8800 TestAcc 0.8151 0.8550
epoch 1500 LossPred 0.2631 LossAtt 0.3019 TrainAcc 0.9100 TestAcc 0.7930 0.8950
epoch 1600 LossPred 0.6273 LossAtt 0.3005 TrainAcc 0.7700 TestAcc 0.6769 0.7550
epoch 1700 LossPred 0.6769 LossAtt 0.3105 TrainAcc 0.7500 TestAcc 0.6909 0.7500
epoch 1800 LossPred 0.5720 LossAtt 0.2913 TrainAcc 0.8000 TestAcc 0.6857 0.7700
epoch 1900 LossPred 0.6126 LossAtt 0.2902 TrainAcc 0.7800 TestAcc 0.6697 0.7550
epoch 2000 LossPred 0.5781 LossAtt 0.2751 TrainAcc 0.7900 TestAcc 0.6707 0.7550
epoch 2100 LossPred 0.6443 LossAtt 0.2659 TrainAcc 0.7700 TestAcc 0.6702 0.7650
epoch 2200 LossPred 0.6145 LossAtt 0.3025 TrainAcc 0.7600 TestAcc 0.6702 0.7200
epoch 2300 LossPred 0.6273 LossAtt 0.2875 TrainAcc 0.7700 TestAcc 0.6729 0.7750
epoch 2400 LossPred 0.6393 LossAtt 0.2740 TrainAcc 0.7700 TestAcc 0.6627 0.7700
epoch 2500 LossPred 0.6490 LossAtt 0.2856 TrainAcc 0.7600 TestAcc 0.6682 0.7700
Optimization Finished!
********** replication  6  **********
epoch   0 LossPred 1.0220 LossAtt 1.0114 TrainAcc 0.4900 TestAcc 0.4757 0.5100
epoch 100 LossPred 0.9390 LossAtt 0.4260 TrainAcc 0.6200 TestAcc 0.5253 0.6200
epoch 200 LossPred 0.9381 LossAtt 0.3901 TrainAcc 0.6200 TestAcc 0.5260 0.6200
epoch 300 LossPred 0.9345 LossAtt 0.3830 TrainAcc 0.6200 TestAcc 0.5253 0.6200
epoch 400 LossPred 0.9317 LossAtt 0.3877 TrainAcc 0.6200 TestAcc 0.5290 0.6150
epoch 500 LossPred 0.9204 LossAtt 0.3887 TrainAcc 0.6200 TestAcc 0.5253 0.6200
epoch 600 LossPred 0.9089 LossAtt 0.4345 TrainAcc 0.6200 TestAcc 0.5253 0.6250
epoch 700 LossPred 0.9047 LossAtt 0.4590 TrainAcc 0.6300 TestAcc 0.5215 0.6100
epoch 800 LossPred 0.8929 LossAtt 0.4497 TrainAcc 0.6400 TestAcc 0.5135 0.6300
epoch 900 LossPred 0.8810 LossAtt 0.4761 TrainAcc 0.6500 TestAcc 0.5120 0.6350
epoch 1000 LossPred 0.8716 LossAtt 0.4370 TrainAcc 0.6500 TestAcc 0.5218 0.6350
epoch 1100 LossPred 0.8556 LossAtt 0.4151 TrainAcc 0.6400 TestAcc 0.5228 0.6350
epoch 1200 LossPred 0.8475 LossAtt 0.4110 TrainAcc 0.6400 TestAcc 0.5123 0.6550
epoch 1300 LossPred 0.8601 LossAtt 0.3713 TrainAcc 0.6100 TestAcc 0.5410 0.5850
epoch 1400 LossPred 0.8391 LossAtt 0.3785 TrainAcc 0.6300 TestAcc 0.5300 0.5850
epoch 1500 LossPred 0.8291 LossAtt 0.3877 TrainAcc 0.6700 TestAcc 0.5328 0.6150
epoch 1600 LossPred 0.8476 LossAtt 0.3800 TrainAcc 0.6300 TestAcc 0.5235 0.6200
epoch 1700 LossPred 0.8364 LossAtt 0.3623 TrainAcc 0.6700 TestAcc 0.5353 0.6300
epoch 1800 LossPred 0.8323 LossAtt 0.3918 TrainAcc 0.6500 TestAcc 0.5388 0.6400
epoch 1900 LossPred 0.8303 LossAtt 0.4160 TrainAcc 0.6500 TestAcc 0.5463 0.6500
epoch 2000 LossPred 0.8225 LossAtt 0.4005 TrainAcc 0.6500 TestAcc 0.5300 0.6550
epoch 2100 LossPred 0.8362 LossAtt 0.4820 TrainAcc 0.6700 TestAcc 0.5558 0.6650
epoch 2200 LossPred 0.8104 LossAtt 0.4448 TrainAcc 0.6800 TestAcc 0.5536 0.6700
epoch 2300 LossPred 0.8071 LossAtt 0.4161 TrainAcc 0.7000 TestAcc 0.5235 0.6700
epoch 2400 LossPred 0.8203 LossAtt 0.4047 TrainAcc 0.7000 TestAcc 0.5063 0.6750
epoch 2500 LossPred 0.8052 LossAtt 0.3411 TrainAcc 0.6900 TestAcc 0.5230 0.6650
Optimization Finished!
********** replication  7  **********
epoch   0 LossPred 1.0362 LossAtt 1.0065 TrainAcc 0.5300 TestAcc 0.5638 0.5250
epoch 100 LossPred 0.9634 LossAtt 0.4686 TrainAcc 0.5800 TestAcc 0.4995 0.5950
epoch 200 LossPred 0.9544 LossAtt 0.4570 TrainAcc 0.6100 TestAcc 0.5175 0.6000
epoch 300 LossPred 0.9408 LossAtt 0.4387 TrainAcc 0.6000 TestAcc 0.6009 0.5800
epoch 400 LossPred 0.9312 LossAtt 0.3838 TrainAcc 0.6000 TestAcc 0.6009 0.5800
epoch 500 LossPred 0.9256 LossAtt 0.3867 TrainAcc 0.6000 TestAcc 0.6009 0.5950
epoch 600 LossPred 0.8580 LossAtt 0.5981 TrainAcc 0.6900 TestAcc 0.6281 0.6950
epoch 700 LossPred 0.4933 LossAtt 0.6255 TrainAcc 0.8600 TestAcc 0.8053 0.8250
epoch 800 LossPred 0.3396 LossAtt 0.6208 TrainAcc 0.9400 TestAcc 0.8371 0.8850
epoch 900 LossPred 0.3133 LossAtt 0.6041 TrainAcc 0.8900 TestAcc 0.8381 0.8650
epoch 1000 LossPred 0.3186 LossAtt 0.5822 TrainAcc 0.8900 TestAcc 0.8551 0.8650
epoch 1100 LossPred 0.2955 LossAtt 0.5702 TrainAcc 0.9100 TestAcc 0.8666 0.9000
epoch 1200 LossPred 0.3110 LossAtt 0.5538 TrainAcc 0.9200 TestAcc 0.8781 0.8850
epoch 1300 LossPred 0.6220 LossAtt 0.5443 TrainAcc 0.7900 TestAcc 0.8148 0.7400
epoch 1400 LossPred 0.5042 LossAtt 0.5304 TrainAcc 0.8100 TestAcc 0.8501 0.7950
epoch 1500 LossPred 0.2446 LossAtt 0.5617 TrainAcc 0.9400 TestAcc 0.8463 0.9150
epoch 1600 LossPred 0.1856 LossAtt 0.5419 TrainAcc 0.9400 TestAcc 0.8789 0.9250
epoch 1700 LossPred 0.1910 LossAtt 0.5641 TrainAcc 0.9600 TestAcc 0.8846 0.9350
epoch 1800 LossPred 0.2010 LossAtt 0.5660 TrainAcc 0.9300 TestAcc 0.8891 0.9150
epoch 1900 LossPred 0.3197 LossAtt 0.5704 TrainAcc 0.9000 TestAcc 0.8378 0.8700
epoch 2000 LossPred 0.1619 LossAtt 0.5344 TrainAcc 0.9600 TestAcc 0.8796 0.9200
epoch 2100 LossPred 0.6181 LossAtt 0.4873 TrainAcc 0.8000 TestAcc 0.8118 0.7750
epoch 2200 LossPred 0.2814 LossAtt 0.5175 TrainAcc 0.9000 TestAcc 0.8834 0.8800
epoch 2300 LossPred 0.6199 LossAtt 0.5058 TrainAcc 0.7900 TestAcc 0.8151 0.7800
epoch 2400 LossPred 0.4281 LossAtt 0.5324 TrainAcc 0.8700 TestAcc 0.8056 0.8550
epoch 2500 LossPred 0.2446 LossAtt 0.5234 TrainAcc 0.9400 TestAcc 0.8554 0.9100
Optimization Finished!
********** replication  8  **********
epoch   0 LossPred 1.0631 LossAtt 1.0251 TrainAcc 0.5700 TestAcc 0.4920 0.5700
epoch 100 LossPred 0.9445 LossAtt 0.4169 TrainAcc 0.5700 TestAcc 0.4920 0.5700
epoch 200 LossPred 0.8778 LossAtt 0.3971 TrainAcc 0.6700 TestAcc 0.6031 0.6350
epoch 300 LossPred 0.8055 LossAtt 0.3995 TrainAcc 0.6900 TestAcc 0.6019 0.6950
epoch 400 LossPred 0.4341 LossAtt 0.4366 TrainAcc 0.8900 TestAcc 0.8091 0.8200
epoch 500 LossPred 0.3356 LossAtt 0.4253 TrainAcc 0.9000 TestAcc 0.8218 0.8850
epoch 600 LossPred 0.3485 LossAtt 0.4242 TrainAcc 0.8900 TestAcc 0.8256 0.8950
epoch 700 LossPred 0.3994 LossAtt 0.3883 TrainAcc 0.8500 TestAcc 0.8026 0.8600
epoch 800 LossPred 0.5448 LossAtt 0.3650 TrainAcc 0.7800 TestAcc 0.7725 0.7850
epoch 900 LossPred 0.3598 LossAtt 0.3562 TrainAcc 0.8600 TestAcc 0.8106 0.8550
epoch 1000 LossPred 0.3698 LossAtt 0.3496 TrainAcc 0.8700 TestAcc 0.8141 0.8700
epoch 1100 LossPred 0.3579 LossAtt 0.3514 TrainAcc 0.8700 TestAcc 0.8246 0.9050
epoch 1200 LossPred 0.4539 LossAtt 0.3572 TrainAcc 0.8300 TestAcc 0.7953 0.8400
epoch 1300 LossPred 0.3269 LossAtt 0.3481 TrainAcc 0.9200 TestAcc 0.8296 0.9050
epoch 1400 LossPred 0.3131 LossAtt 0.3559 TrainAcc 0.8800 TestAcc 0.8323 0.8750
epoch 1500 LossPred 0.3054 LossAtt 0.3638 TrainAcc 0.9000 TestAcc 0.8408 0.8750
epoch 1600 LossPred 0.4103 LossAtt 0.3640 TrainAcc 0.8600 TestAcc 0.7950 0.8350
epoch 1700 LossPred 0.3435 LossAtt 0.3683 TrainAcc 0.8700 TestAcc 0.8186 0.8650
epoch 1800 LossPred 0.2774 LossAtt 0.3634 TrainAcc 0.8900 TestAcc 0.8318 0.8600
epoch 1900 LossPred 0.3353 LossAtt 0.3569 TrainAcc 0.8800 TestAcc 0.8428 0.8700
epoch 2000 LossPred 0.3827 LossAtt 0.3517 TrainAcc 0.8700 TestAcc 0.8031 0.8450
epoch 2100 LossPred 0.3280 LossAtt 0.3709 TrainAcc 0.8900 TestAcc 0.8266 0.8750
epoch 2200 LossPred 0.3114 LossAtt 0.3550 TrainAcc 0.8800 TestAcc 0.8498 0.8700
epoch 2300 LossPred 0.3092 LossAtt 0.3413 TrainAcc 0.8900 TestAcc 0.8286 0.8650
epoch 2400 LossPred 0.2989 LossAtt 0.3565 TrainAcc 0.8800 TestAcc 0.8511 0.8600
epoch 2500 LossPred 0.4125 LossAtt 0.3660 TrainAcc 0.8700 TestAcc 0.7865 0.8650
Optimization Finished!
********** replication  9  **********
epoch   0 LossPred 0.9693 LossAtt 1.0038 TrainAcc 0.5800 TestAcc 0.5473 0.5650
epoch 100 LossPred 0.9394 LossAtt 0.4717 TrainAcc 0.5800 TestAcc 0.5583 0.5600
epoch 200 LossPred 0.9361 LossAtt 0.3912 TrainAcc 0.5800 TestAcc 0.5583 0.5600
epoch 300 LossPred 0.9323 LossAtt 0.3450 TrainAcc 0.5800 TestAcc 0.5583 0.5600
epoch 400 LossPred 0.9316 LossAtt 0.2782 TrainAcc 0.5800 TestAcc 0.5583 0.5450
epoch 500 LossPred 0.9276 LossAtt 0.2892 TrainAcc 0.5800 TestAcc 0.5583 0.5800
epoch 600 LossPred 0.9206 LossAtt 0.3451 TrainAcc 0.6000 TestAcc 0.5683 0.5950
epoch 700 LossPred 0.8923 LossAtt 0.4624 TrainAcc 0.6600 TestAcc 0.6071 0.6450
epoch 800 LossPred 0.8596 LossAtt 0.4613 TrainAcc 0.6700 TestAcc 0.6026 0.6650
epoch 900 LossPred 0.7949 LossAtt 0.5394 TrainAcc 0.6800 TestAcc 0.5941 0.6900
epoch 1000 LossPred 0.7433 LossAtt 0.5658 TrainAcc 0.7200 TestAcc 0.6076 0.7200
epoch 1100 LossPred 0.6946 LossAtt 0.5156 TrainAcc 0.7600 TestAcc 0.5816 0.7250
epoch 1200 LossPred 0.6804 LossAtt 0.5152 TrainAcc 0.7700 TestAcc 0.5876 0.7350
epoch 1300 LossPred 0.7006 LossAtt 0.4964 TrainAcc 0.7500 TestAcc 0.5843 0.7350
epoch 1400 LossPred 0.6836 LossAtt 0.4901 TrainAcc 0.7500 TestAcc 0.5901 0.7300
epoch 1500 LossPred 0.6814 LossAtt 0.4595 TrainAcc 0.7700 TestAcc 0.5883 0.7250
epoch 1600 LossPred 0.6916 LossAtt 0.4770 TrainAcc 0.7600 TestAcc 0.5866 0.7100
epoch 1700 LossPred 0.6961 LossAtt 0.4757 TrainAcc 0.7500 TestAcc 0.5888 0.7100
epoch 1800 LossPred 0.7107 LossAtt 0.5192 TrainAcc 0.7700 TestAcc 0.5776 0.7050
epoch 1900 LossPred 0.7167 LossAtt 0.4932 TrainAcc 0.7400 TestAcc 0.5848 0.7050
epoch 2000 LossPred 0.7288 LossAtt 0.4738 TrainAcc 0.7500 TestAcc 0.5881 0.7050
epoch 2100 LossPred 0.7430 LossAtt 0.5066 TrainAcc 0.7500 TestAcc 0.5838 0.7100
epoch 2200 LossPred 0.7292 LossAtt 0.4871 TrainAcc 0.7500 TestAcc 0.5951 0.7250
epoch 2300 LossPred 0.7304 LossAtt 0.4872 TrainAcc 0.7300 TestAcc 0.5961 0.7300
epoch 2400 LossPred 0.7419 LossAtt 0.4717 TrainAcc 0.7400 TestAcc 0.6046 0.7100
epoch 2500 LossPred 0.7311 LossAtt 0.4772 TrainAcc 0.7700 TestAcc 0.5908 0.7200
Optimization Finished!
********** replication  10  **********
epoch   0 LossPred 1.1283 LossAtt 1.0356 TrainAcc 0.5500 TestAcc 0.5818 0.5500
epoch 100 LossPred 0.9115 LossAtt 0.5232 TrainAcc 0.6300 TestAcc 0.6141 0.6700
epoch 200 LossPred 0.7078 LossAtt 0.5348 TrainAcc 0.8200 TestAcc 0.7307 0.7950
epoch 300 LossPred 0.5672 LossAtt 0.5600 TrainAcc 0.8400 TestAcc 0.8148 0.8300
epoch 400 LossPred 0.6578 LossAtt 0.5001 TrainAcc 0.7900 TestAcc 0.7025 0.7900
epoch 500 LossPred 0.4649 LossAtt 0.5019 TrainAcc 0.8800 TestAcc 0.8328 0.8750
epoch 600 LossPred 0.3881 LossAtt 0.4751 TrainAcc 0.9000 TestAcc 0.8423 0.8650
epoch 700 LossPred 0.4069 LossAtt 0.4725 TrainAcc 0.8800 TestAcc 0.8436 0.8650
epoch 800 LossPred 0.4012 LossAtt 0.4597 TrainAcc 0.8900 TestAcc 0.8083 0.8750
epoch 900 LossPred 0.3463 LossAtt 0.4146 TrainAcc 0.8900 TestAcc 0.8346 0.8850
epoch 1000 LossPred 0.3990 LossAtt 0.4246 TrainAcc 0.8800 TestAcc 0.8426 0.8450
epoch 1100 LossPred 0.3104 LossAtt 0.4006 TrainAcc 0.9100 TestAcc 0.8473 0.8900
epoch 1200 LossPred 0.3694 LossAtt 0.4022 TrainAcc 0.8800 TestAcc 0.8306 0.8550
epoch 1300 LossPred 0.3462 LossAtt 0.3827 TrainAcc 0.9000 TestAcc 0.8151 0.8900
epoch 1400 LossPred 0.3299 LossAtt 0.3764 TrainAcc 0.9100 TestAcc 0.8396 0.8800
epoch 1500 LossPred 0.4460 LossAtt 0.3858 TrainAcc 0.8700 TestAcc 0.7995 0.8700
epoch 1600 LossPred 0.3103 LossAtt 0.4000 TrainAcc 0.9000 TestAcc 0.8361 0.8800
epoch 1700 LossPred 0.3268 LossAtt 0.3815 TrainAcc 0.9100 TestAcc 0.8461 0.8800
epoch 1800 LossPred 0.2987 LossAtt 0.4066 TrainAcc 0.9200 TestAcc 0.8453 0.8850
epoch 1900 LossPred 0.2896 LossAtt 0.3922 TrainAcc 0.9200 TestAcc 0.8476 0.8750
epoch 2000 LossPred 0.4284 LossAtt 0.3805 TrainAcc 0.8700 TestAcc 0.7973 0.8750
epoch 2100 LossPred 0.3431 LossAtt 0.3962 TrainAcc 0.8800 TestAcc 0.8258 0.8750
epoch 2200 LossPred 0.5286 LossAtt 0.4063 TrainAcc 0.8300 TestAcc 0.8226 0.7900
epoch 2300 LossPred 0.4227 LossAtt 0.3528 TrainAcc 0.8500 TestAcc 0.8043 0.8550
epoch 2400 LossPred 0.3494 LossAtt 0.3931 TrainAcc 0.9000 TestAcc 0.8121 0.8850
epoch 2500 LossPred 0.3490 LossAtt 0.3765 TrainAcc 0.8900 TestAcc 0.8311 0.8850
Optimization Finished!
********** replication  11  **********
epoch   0 LossPred 1.2361 LossAtt 1.0063 TrainAcc 0.4800 TestAcc 0.5048 0.4800
epoch 100 LossPred 0.9870 LossAtt 0.5274 TrainAcc 0.5400 TestAcc 0.5015 0.5350
epoch 200 LossPred 0.9550 LossAtt 0.4609 TrainAcc 0.6000 TestAcc 0.5786 0.5950
epoch 300 LossPred 0.8943 LossAtt 0.5012 TrainAcc 0.6400 TestAcc 0.6296 0.6550
epoch 400 LossPred 0.3756 LossAtt 0.4953 TrainAcc 0.8900 TestAcc 0.8576 0.8850
epoch 500 LossPred 0.3527 LossAtt 0.4913 TrainAcc 0.8800 TestAcc 0.8559 0.8800
epoch 600 LossPred 0.3205 LossAtt 0.4871 TrainAcc 0.9000 TestAcc 0.8624 0.8950
epoch 700 LossPred 0.2944 LossAtt 0.4478 TrainAcc 0.9100 TestAcc 0.8586 0.9000
epoch 800 LossPred 0.3301 LossAtt 0.4394 TrainAcc 0.8900 TestAcc 0.8546 0.9050
epoch 900 LossPred 0.3186 LossAtt 0.4213 TrainAcc 0.8900 TestAcc 0.8511 0.8650
epoch 1000 LossPred 0.2861 LossAtt 0.4113 TrainAcc 0.9200 TestAcc 0.8709 0.8950
epoch 1100 LossPred 0.3278 LossAtt 0.3944 TrainAcc 0.8800 TestAcc 0.8506 0.8800
epoch 1200 LossPred 0.3275 LossAtt 0.4003 TrainAcc 0.8900 TestAcc 0.8634 0.9050
epoch 1300 LossPred 0.3178 LossAtt 0.3925 TrainAcc 0.9000 TestAcc 0.8639 0.8950
epoch 1400 LossPred 0.2830 LossAtt 0.3928 TrainAcc 0.9000 TestAcc 0.8514 0.8850
epoch 1500 LossPred 0.2817 LossAtt 0.3974 TrainAcc 0.9100 TestAcc 0.8621 0.8950
epoch 1600 LossPred 0.2949 LossAtt 0.4071 TrainAcc 0.9000 TestAcc 0.8579 0.8950
epoch 1700 LossPred 0.2741 LossAtt 0.3891 TrainAcc 0.9100 TestAcc 0.8604 0.8950
epoch 1800 LossPred 0.2762 LossAtt 0.3947 TrainAcc 0.9100 TestAcc 0.8338 0.8900
epoch 1900 LossPred 0.2786 LossAtt 0.3788 TrainAcc 0.9100 TestAcc 0.8569 0.9050
epoch 2000 LossPred 0.3815 LossAtt 0.4076 TrainAcc 0.8700 TestAcc 0.8248 0.8500
epoch 2100 LossPred 0.4176 LossAtt 0.3630 TrainAcc 0.8600 TestAcc 0.8086 0.8450
epoch 2200 LossPred 0.3086 LossAtt 0.3875 TrainAcc 0.8800 TestAcc 0.8253 0.8950
epoch 2300 LossPred 0.2970 LossAtt 0.3928 TrainAcc 0.9100 TestAcc 0.8276 0.9000
epoch 2400 LossPred 0.3618 LossAtt 0.3990 TrainAcc 0.8800 TestAcc 0.8241 0.8500
epoch 2500 LossPred 0.2910 LossAtt 0.3768 TrainAcc 0.9000 TestAcc 0.8574 0.9000
Optimization Finished!
********** replication  12  **********
epoch   0 LossPred 1.0268 LossAtt 1.0090 TrainAcc 0.6400 TestAcc 0.5325 0.6500
epoch 100 LossPred 0.8600 LossAtt 0.5282 TrainAcc 0.6600 TestAcc 0.5513 0.6700
epoch 200 LossPred 0.8208 LossAtt 0.5757 TrainAcc 0.7000 TestAcc 0.5453 0.6850
epoch 300 LossPred 0.7584 LossAtt 0.5932 TrainAcc 0.7300 TestAcc 0.5388 0.7050
epoch 400 LossPred 0.7512 LossAtt 0.5841 TrainAcc 0.7400 TestAcc 0.5415 0.6950
epoch 500 LossPred 0.7413 LossAtt 0.5367 TrainAcc 0.7500 TestAcc 0.5428 0.7150
epoch 600 LossPred 0.7354 LossAtt 0.5063 TrainAcc 0.7500 TestAcc 0.5475 0.7150
epoch 700 LossPred 0.7401 LossAtt 0.4827 TrainAcc 0.7400 TestAcc 0.5460 0.7200
epoch 800 LossPred 0.7242 LossAtt 0.4987 TrainAcc 0.7300 TestAcc 0.5516 0.7150
epoch 900 LossPred 0.7158 LossAtt 0.4916 TrainAcc 0.7500 TestAcc 0.5465 0.7100
epoch 1000 LossPred 0.7189 LossAtt 0.4810 TrainAcc 0.7400 TestAcc 0.5556 0.7250
epoch 1100 LossPred 0.7103 LossAtt 0.4896 TrainAcc 0.7400 TestAcc 0.5618 0.7200
epoch 1200 LossPred 0.7168 LossAtt 0.4875 TrainAcc 0.7300 TestAcc 0.5468 0.6800
epoch 1300 LossPred 0.7137 LossAtt 0.4684 TrainAcc 0.7300 TestAcc 0.5543 0.6950
epoch 1400 LossPred 0.7140 LossAtt 0.4783 TrainAcc 0.7400 TestAcc 0.5558 0.6800
epoch 1500 LossPred 0.7108 LossAtt 0.4832 TrainAcc 0.7400 TestAcc 0.5636 0.7050
epoch 1600 LossPred 0.7178 LossAtt 0.4747 TrainAcc 0.7500 TestAcc 0.5601 0.6850
epoch 1700 LossPred 0.7070 LossAtt 0.4449 TrainAcc 0.7400 TestAcc 0.5638 0.6850
epoch 1800 LossPred 0.7048 LossAtt 0.4456 TrainAcc 0.7300 TestAcc 0.5646 0.7100
epoch 1900 LossPred 0.7230 LossAtt 0.4479 TrainAcc 0.7300 TestAcc 0.5696 0.6950
epoch 2000 LossPred 0.7343 LossAtt 0.4228 TrainAcc 0.7400 TestAcc 0.5708 0.6900
epoch 2100 LossPred 0.7305 LossAtt 0.4211 TrainAcc 0.7400 TestAcc 0.5601 0.7000
epoch 2200 LossPred 0.7265 LossAtt 0.3997 TrainAcc 0.7300 TestAcc 0.5628 0.7100
epoch 2300 LossPred 0.7590 LossAtt 0.4139 TrainAcc 0.7200 TestAcc 0.5621 0.7100
epoch 2400 LossPred 0.7477 LossAtt 0.4083 TrainAcc 0.7100 TestAcc 0.5601 0.6850
epoch 2500 LossPred 0.7303 LossAtt 0.3907 TrainAcc 0.7400 TestAcc 0.5653 0.7350
Optimization Finished!
********** replication  13  **********
epoch   0 LossPred 1.0989 LossAtt 1.0276 TrainAcc 0.5000 TestAcc 0.5400 0.5000
epoch 100 LossPred 0.9599 LossAtt 0.4324 TrainAcc 0.6200 TestAcc 0.5493 0.6000
epoch 200 LossPred 0.9222 LossAtt 0.3706 TrainAcc 0.6200 TestAcc 0.5313 0.6250
epoch 300 LossPred 0.9105 LossAtt 0.4046 TrainAcc 0.5900 TestAcc 0.4965 0.6300
epoch 400 LossPred 0.9030 LossAtt 0.4078 TrainAcc 0.6400 TestAcc 0.5405 0.6400
epoch 500 LossPred 0.9119 LossAtt 0.4061 TrainAcc 0.6500 TestAcc 0.5751 0.6400
epoch 600 LossPred 0.8999 LossAtt 0.3640 TrainAcc 0.6600 TestAcc 0.5938 0.6350
epoch 700 LossPred 0.9065 LossAtt 0.4303 TrainAcc 0.6500 TestAcc 0.6096 0.6400
epoch 800 LossPred 0.8272 LossAtt 0.3901 TrainAcc 0.6800 TestAcc 0.5991 0.6950
epoch 900 LossPred 0.8180 LossAtt 0.3771 TrainAcc 0.6800 TestAcc 0.5971 0.6850
epoch 1000 LossPred 0.8094 LossAtt 0.3768 TrainAcc 0.7000 TestAcc 0.6001 0.6950
epoch 1100 LossPred 0.8008 LossAtt 0.3991 TrainAcc 0.7000 TestAcc 0.6014 0.7050
epoch 1200 LossPred 0.7834 LossAtt 0.3724 TrainAcc 0.7100 TestAcc 0.6021 0.7000
epoch 1300 LossPred 0.7794 LossAtt 0.3988 TrainAcc 0.7100 TestAcc 0.6059 0.7100
epoch 1400 LossPred 0.7768 LossAtt 0.4171 TrainAcc 0.7200 TestAcc 0.6184 0.7100
epoch 1500 LossPred 0.7209 LossAtt 0.4075 TrainAcc 0.7500 TestAcc 0.6341 0.7400
epoch 1600 LossPred 0.7143 LossAtt 0.3977 TrainAcc 0.7500 TestAcc 0.6274 0.7450
epoch 1700 LossPred 0.7068 LossAtt 0.3832 TrainAcc 0.7500 TestAcc 0.6314 0.7500
epoch 1800 LossPred 0.7025 LossAtt 0.4043 TrainAcc 0.7500 TestAcc 0.6331 0.7500
epoch 1900 LossPred 0.7151 LossAtt 0.4098 TrainAcc 0.7400 TestAcc 0.6324 0.7300
epoch 2000 LossPred 0.7566 LossAtt 0.3597 TrainAcc 0.7300 TestAcc 0.6096 0.7250
epoch 2100 LossPred 0.6965 LossAtt 0.4072 TrainAcc 0.7500 TestAcc 0.6349 0.7500
epoch 2200 LossPred 0.6967 LossAtt 0.4097 TrainAcc 0.7500 TestAcc 0.6356 0.7450
epoch 2300 LossPred 0.6899 LossAtt 0.4077 TrainAcc 0.7500 TestAcc 0.6359 0.7400
epoch 2400 LossPred 0.6935 LossAtt 0.3988 TrainAcc 0.7500 TestAcc 0.6331 0.7500
epoch 2500 LossPred 0.6856 LossAtt 0.3846 TrainAcc 0.7500 TestAcc 0.6344 0.7450
Optimization Finished!
********** replication  14  **********
epoch   0 LossPred 1.0654 LossAtt 1.0261 TrainAcc 0.5500 TestAcc 0.5163 0.5500
epoch 100 LossPred 0.9496 LossAtt 0.4142 TrainAcc 0.6000 TestAcc 0.5846 0.5950
epoch 200 LossPred 0.9449 LossAtt 0.3483 TrainAcc 0.6000 TestAcc 0.5846 0.6000
epoch 300 LossPred 0.9417 LossAtt 0.2979 TrainAcc 0.6000 TestAcc 0.5846 0.6000
epoch 400 LossPred 0.9293 LossAtt 0.3464 TrainAcc 0.6000 TestAcc 0.5846 0.6000
epoch 500 LossPred 0.8678 LossAtt 0.3724 TrainAcc 0.6500 TestAcc 0.6569 0.6500
epoch 600 LossPred 0.4996 LossAtt 0.5147 TrainAcc 0.8400 TestAcc 0.7365 0.8100
epoch 700 LossPred 0.2682 LossAtt 0.4883 TrainAcc 0.9100 TestAcc 0.8661 0.9000
epoch 800 LossPred 0.3202 LossAtt 0.4831 TrainAcc 0.8800 TestAcc 0.8724 0.8900
epoch 900 LossPred 0.2463 LossAtt 0.4468 TrainAcc 0.9300 TestAcc 0.8621 0.9050
epoch 1000 LossPred 0.2783 LossAtt 0.4681 TrainAcc 0.9200 TestAcc 0.8691 0.8950
epoch 1100 LossPred 0.2666 LossAtt 0.4203 TrainAcc 0.9300 TestAcc 0.8811 0.8950
epoch 1200 LossPred 0.2439 LossAtt 0.4003 TrainAcc 0.9300 TestAcc 0.8661 0.8900
epoch 1300 LossPred 0.2284 LossAtt 0.3773 TrainAcc 0.9300 TestAcc 0.8794 0.9100
epoch 1400 LossPred 0.2410 LossAtt 0.3535 TrainAcc 0.9300 TestAcc 0.8556 0.9050
epoch 1500 LossPred 0.2438 LossAtt 0.3595 TrainAcc 0.9200 TestAcc 0.8724 0.9150
epoch 1600 LossPred 0.3075 LossAtt 0.3418 TrainAcc 0.9100 TestAcc 0.8183 0.8800
epoch 1700 LossPred 0.2812 LossAtt 0.3460 TrainAcc 0.8900 TestAcc 0.8321 0.8850
epoch 1800 LossPred 0.2362 LossAtt 0.3732 TrainAcc 0.9200 TestAcc 0.8751 0.9200
epoch 1900 LossPred 0.2591 LossAtt 0.3648 TrainAcc 0.9200 TestAcc 0.8636 0.8950
epoch 2000 LossPred 0.4338 LossAtt 0.3814 TrainAcc 0.8500 TestAcc 0.8086 0.8000
epoch 2100 LossPred 0.2370 LossAtt 0.3536 TrainAcc 0.9300 TestAcc 0.8751 0.9200
epoch 2200 LossPred 0.2478 LossAtt 0.3497 TrainAcc 0.9200 TestAcc 0.8496 0.9000
epoch 2300 LossPred 0.2303 LossAtt 0.3613 TrainAcc 0.9200 TestAcc 0.8564 0.9050
epoch 2400 LossPred 0.2211 LossAtt 0.3473 TrainAcc 0.9200 TestAcc 0.8719 0.9300
epoch 2500 LossPred 0.2243 LossAtt 0.3288 TrainAcc 0.9300 TestAcc 0.8644 0.9100
Optimization Finished!
********** replication  15  **********
epoch   0 LossPred 1.0068 LossAtt 1.0507 TrainAcc 0.5400 TestAcc 0.5428 0.5350
epoch 100 LossPred 0.9130 LossAtt 0.4040 TrainAcc 0.6700 TestAcc 0.5766 0.6500
epoch 200 LossPred 0.8851 LossAtt 0.2929 TrainAcc 0.6700 TestAcc 0.5766 0.6700
epoch 300 LossPred 0.8807 LossAtt 0.1960 TrainAcc 0.6700 TestAcc 0.5766 0.6700
epoch 400 LossPred 0.8789 LossAtt 0.1678 TrainAcc 0.6700 TestAcc 0.5766 0.6700
epoch 500 LossPred 0.8873 LossAtt 0.1403 TrainAcc 0.6700 TestAcc 0.5766 0.6700
epoch 600 LossPred 0.8886 LossAtt 0.1751 TrainAcc 0.6700 TestAcc 0.5766 0.6700
epoch 700 LossPred 0.8858 LossAtt 0.1405 TrainAcc 0.6700 TestAcc 0.5766 0.6700
epoch 800 LossPred 0.8833 LossAtt 0.1030 TrainAcc 0.6700 TestAcc 0.5766 0.6700
epoch 900 LossPred 0.8821 LossAtt 0.1010 TrainAcc 0.6700 TestAcc 0.5766 0.6700
epoch 1000 LossPred 0.8813 LossAtt 0.0963 TrainAcc 0.6700 TestAcc 0.5766 0.6700
epoch 1100 LossPred 0.8805 LossAtt 0.0871 TrainAcc 0.6700 TestAcc 0.5766 0.6700
epoch 1200 LossPred 0.8790 LossAtt 0.0778 TrainAcc 0.6700 TestAcc 0.5766 0.6700
epoch 1300 LossPred 0.8773 LossAtt 0.0793 TrainAcc 0.6700 TestAcc 0.5766 0.6700
epoch 1400 LossPred 0.8724 LossAtt 0.0861 TrainAcc 0.6700 TestAcc 0.5766 0.6700
epoch 1500 LossPred 0.8671 LossAtt 0.0778 TrainAcc 0.6700 TestAcc 0.5766 0.6700
epoch 1600 LossPred 0.8756 LossAtt 0.1136 TrainAcc 0.6700 TestAcc 0.5766 0.6700
epoch 1700 LossPred 0.8096 LossAtt 0.4477 TrainAcc 0.6700 TestAcc 0.5766 0.6500
epoch 1800 LossPred 0.6410 LossAtt 0.3707 TrainAcc 0.7700 TestAcc 0.7885 0.7500
epoch 1900 LossPred 0.4672 LossAtt 0.3695 TrainAcc 0.8700 TestAcc 0.7945 0.8450
epoch 2000 LossPred 0.5117 LossAtt 0.3820 TrainAcc 0.8400 TestAcc 0.7725 0.8200
epoch 2100 LossPred 0.4472 LossAtt 0.3620 TrainAcc 0.8700 TestAcc 0.7973 0.8600
epoch 2200 LossPred 0.5453 LossAtt 0.3619 TrainAcc 0.8200 TestAcc 0.7870 0.8150
epoch 2300 LossPred 0.4679 LossAtt 0.3657 TrainAcc 0.8600 TestAcc 0.7935 0.8550
epoch 2400 LossPred 0.4724 LossAtt 0.3617 TrainAcc 0.8500 TestAcc 0.7945 0.8300
epoch 2500 LossPred 0.4446 LossAtt 0.3684 TrainAcc 0.8500 TestAcc 0.7918 0.8400
Optimization Finished!
********** replication  16  **********
epoch   0 LossPred 1.0647 LossAtt 1.0046 TrainAcc 0.4300 TestAcc 0.5220 0.4350
epoch 100 LossPred 0.9669 LossAtt 0.4046 TrainAcc 0.5700 TestAcc 0.4960 0.5750
epoch 200 LossPred 0.9674 LossAtt 0.2718 TrainAcc 0.5700 TestAcc 0.4870 0.5450
epoch 300 LossPred 0.9669 LossAtt 0.2311 TrainAcc 0.5700 TestAcc 0.4870 0.5650
epoch 400 LossPred 0.9659 LossAtt 0.2290 TrainAcc 0.5700 TestAcc 0.4870 0.5700
epoch 500 LossPred 0.9619 LossAtt 0.2673 TrainAcc 0.5700 TestAcc 0.4870 0.5700
epoch 600 LossPred 0.9523 LossAtt 0.3311 TrainAcc 0.6000 TestAcc 0.5058 0.5900
epoch 700 LossPred 0.9320 LossAtt 0.3516 TrainAcc 0.6400 TestAcc 0.5283 0.6250
epoch 800 LossPred 0.8834 LossAtt 0.3539 TrainAcc 0.6700 TestAcc 0.5263 0.6550
epoch 900 LossPred 0.8531 LossAtt 0.3602 TrainAcc 0.6900 TestAcc 0.5556 0.6750
epoch 1000 LossPred 0.8425 LossAtt 0.3445 TrainAcc 0.6800 TestAcc 0.5375 0.6650
epoch 1100 LossPred 0.8369 LossAtt 0.3378 TrainAcc 0.6800 TestAcc 0.5395 0.6750
epoch 1200 LossPred 0.8424 LossAtt 0.3276 TrainAcc 0.6700 TestAcc 0.5310 0.6650
epoch 1300 LossPred 0.8268 LossAtt 0.3179 TrainAcc 0.6800 TestAcc 0.5395 0.6700
epoch 1400 LossPred 0.8247 LossAtt 0.2920 TrainAcc 0.6800 TestAcc 0.5420 0.6750
epoch 1500 LossPred 0.8415 LossAtt 0.3030 TrainAcc 0.6300 TestAcc 0.5598 0.6600
epoch 1600 LossPred 0.8529 LossAtt 0.2843 TrainAcc 0.6700 TestAcc 0.5566 0.6450
epoch 1700 LossPred 0.8733 LossAtt 0.3069 TrainAcc 0.6600 TestAcc 0.5616 0.6550
epoch 1800 LossPred 0.9155 LossAtt 0.3268 TrainAcc 0.6300 TestAcc 0.5806 0.6250
epoch 1900 LossPred 0.9334 LossAtt 0.3337 TrainAcc 0.5800 TestAcc 0.5248 0.5800
epoch 2000 LossPred 0.9277 LossAtt 0.3075 TrainAcc 0.6300 TestAcc 0.5495 0.6200
epoch 2100 LossPred 0.9138 LossAtt 0.2876 TrainAcc 0.6000 TestAcc 0.5508 0.6100
epoch 2200 LossPred 0.9370 LossAtt 0.3126 TrainAcc 0.6200 TestAcc 0.5513 0.6200
epoch 2300 LossPred 0.9497 LossAtt 0.2261 TrainAcc 0.6400 TestAcc 0.5558 0.6250
epoch 2400 LossPred 0.9496 LossAtt 0.1889 TrainAcc 0.6400 TestAcc 0.5558 0.6200
epoch 2500 LossPred 0.9529 LossAtt 0.1631 TrainAcc 0.6300 TestAcc 0.5375 0.6300
Optimization Finished!
********** replication  17  **********
epoch   0 LossPred 1.2050 LossAtt 1.0131 TrainAcc 0.5600 TestAcc 0.5503 0.5450
epoch 100 LossPred 0.9165 LossAtt 0.4521 TrainAcc 0.6200 TestAcc 0.5731 0.6200
epoch 200 LossPred 0.8403 LossAtt 0.4906 TrainAcc 0.6400 TestAcc 0.5881 0.6600
epoch 300 LossPred 0.4552 LossAtt 0.4727 TrainAcc 0.8700 TestAcc 0.8569 0.8400
epoch 400 LossPred 0.4299 LossAtt 0.4604 TrainAcc 0.8800 TestAcc 0.8541 0.8350
epoch 500 LossPred 0.3501 LossAtt 0.4436 TrainAcc 0.8900 TestAcc 0.8626 0.8650
epoch 600 LossPred 0.6031 LossAtt 0.4809 TrainAcc 0.7600 TestAcc 0.8106 0.7850
epoch 700 LossPred 0.3643 LossAtt 0.4795 TrainAcc 0.9000 TestAcc 0.8476 0.8500
epoch 800 LossPred 0.3646 LossAtt 0.4672 TrainAcc 0.8900 TestAcc 0.8431 0.8800
epoch 900 LossPred 0.3413 LossAtt 0.4393 TrainAcc 0.9000 TestAcc 0.8443 0.8950
epoch 1000 LossPred 0.2679 LossAtt 0.4304 TrainAcc 0.9300 TestAcc 0.8616 0.8850
epoch 1100 LossPred 0.3379 LossAtt 0.4157 TrainAcc 0.8600 TestAcc 0.8476 0.8400
epoch 1200 LossPred 0.3784 LossAtt 0.4265 TrainAcc 0.8500 TestAcc 0.8341 0.8200
epoch 1300 LossPred 0.2914 LossAtt 0.4221 TrainAcc 0.9100 TestAcc 0.8524 0.8900
epoch 1400 LossPred 0.5719 LossAtt 0.4224 TrainAcc 0.8300 TestAcc 0.7638 0.7850
epoch 1500 LossPred 0.2826 LossAtt 0.4363 TrainAcc 0.9200 TestAcc 0.8473 0.8850
epoch 1600 LossPred 0.4059 LossAtt 0.4259 TrainAcc 0.8600 TestAcc 0.8386 0.8600
epoch 1700 LossPred 0.2749 LossAtt 0.4764 TrainAcc 0.9000 TestAcc 0.8606 0.8700
epoch 1800 LossPred 0.3600 LossAtt 0.4546 TrainAcc 0.9000 TestAcc 0.8486 0.8400
epoch 1900 LossPred 0.3630 LossAtt 0.4391 TrainAcc 0.8800 TestAcc 0.8451 0.8400
epoch 2000 LossPred 0.3011 LossAtt 0.4825 TrainAcc 0.9000 TestAcc 0.8646 0.8700
epoch 2100 LossPred 0.3379 LossAtt 0.4621 TrainAcc 0.8900 TestAcc 0.8576 0.8650
epoch 2200 LossPred 0.3166 LossAtt 0.4676 TrainAcc 0.8900 TestAcc 0.8649 0.8400
epoch 2300 LossPred 0.3155 LossAtt 0.4581 TrainAcc 0.8900 TestAcc 0.8664 0.8600
epoch 2400 LossPred 0.3155 LossAtt 0.4520 TrainAcc 0.9000 TestAcc 0.8641 0.8600
epoch 2500 LossPred 0.3233 LossAtt 0.4509 TrainAcc 0.9000 TestAcc 0.8579 0.8500
Optimization Finished!
********** replication  18  **********
epoch   0 LossPred 1.0798 LossAtt 1.0197 TrainAcc 0.5700 TestAcc 0.5460 0.5900
epoch 100 LossPred 0.9752 LossAtt 0.3974 TrainAcc 0.6000 TestAcc 0.5938 0.6000
epoch 200 LossPred 0.9636 LossAtt 0.3186 TrainAcc 0.6000 TestAcc 0.5938 0.6000
epoch 300 LossPred 0.9627 LossAtt 0.2724 TrainAcc 0.6000 TestAcc 0.5938 0.6000
epoch 400 LossPred 0.9621 LossAtt 0.2235 TrainAcc 0.6000 TestAcc 0.5938 0.6000
epoch 500 LossPred 0.9630 LossAtt 0.2406 TrainAcc 0.6000 TestAcc 0.5938 0.6000
epoch 600 LossPred 0.9628 LossAtt 0.2256 TrainAcc 0.6000 TestAcc 0.5938 0.6000
epoch 700 LossPred 0.9594 LossAtt 0.2098 TrainAcc 0.6000 TestAcc 0.5938 0.6000
epoch 800 LossPred 0.9593 LossAtt 0.1805 TrainAcc 0.6000 TestAcc 0.5938 0.6000
epoch 900 LossPred 0.9592 LossAtt 0.1642 TrainAcc 0.6000 TestAcc 0.5938 0.6000
epoch 1000 LossPred 0.9587 LossAtt 0.1507 TrainAcc 0.6000 TestAcc 0.5938 0.6000
epoch 1100 LossPred 0.9588 LossAtt 0.1449 TrainAcc 0.6000 TestAcc 0.5938 0.6000
epoch 1200 LossPred 0.9592 LossAtt 0.1520 TrainAcc 0.6000 TestAcc 0.5938 0.6000
epoch 1300 LossPred 0.9601 LossAtt 0.1563 TrainAcc 0.6000 TestAcc 0.5938 0.6000
epoch 1400 LossPred 0.9617 LossAtt 0.1715 TrainAcc 0.6000 TestAcc 0.5938 0.6000
epoch 1500 LossPred 0.9544 LossAtt 0.1933 TrainAcc 0.6000 TestAcc 0.5938 0.6000
epoch 1600 LossPred 0.9519 LossAtt 0.1453 TrainAcc 0.6000 TestAcc 0.5938 0.6000
epoch 1700 LossPred 0.9541 LossAtt 0.1329 TrainAcc 0.6000 TestAcc 0.5938 0.6000
epoch 1800 LossPred 0.9468 LossAtt 0.2043 TrainAcc 0.6000 TestAcc 0.5938 0.6000
epoch 1900 LossPred 0.9290 LossAtt 0.2781 TrainAcc 0.6300 TestAcc 0.5643 0.6300
epoch 2000 LossPred 0.9137 LossAtt 0.2816 TrainAcc 0.6400 TestAcc 0.5901 0.6400
epoch 2100 LossPred 0.8966 LossAtt 0.2851 TrainAcc 0.6500 TestAcc 0.5908 0.6500
epoch 2200 LossPred 0.8901 LossAtt 0.2655 TrainAcc 0.6600 TestAcc 0.5878 0.6650
epoch 2300 LossPred 0.8792 LossAtt 0.2714 TrainAcc 0.6600 TestAcc 0.5748 0.6500
epoch 2400 LossPred 0.9322 LossAtt 0.2718 TrainAcc 0.6100 TestAcc 0.5268 0.6050
epoch 2500 LossPred 0.9846 LossAtt 0.2054 TrainAcc 0.5100 TestAcc 0.4812 0.5250
Optimization Finished!
********** replication  19  **********
epoch   0 LossPred 1.0453 LossAtt 0.9987 TrainAcc 0.4800 TestAcc 0.5298 0.4700
epoch 100 LossPred 0.9481 LossAtt 0.4343 TrainAcc 0.5800 TestAcc 0.6061 0.5950
epoch 200 LossPred 0.9442 LossAtt 0.3977 TrainAcc 0.6000 TestAcc 0.5916 0.6050
epoch 300 LossPred 0.9447 LossAtt 0.2840 TrainAcc 0.5800 TestAcc 0.5646 0.5800
epoch 400 LossPred 0.9457 LossAtt 0.2187 TrainAcc 0.5800 TestAcc 0.5646 0.5800
epoch 500 LossPred 0.9451 LossAtt 0.1930 TrainAcc 0.5900 TestAcc 0.5621 0.5750
epoch 600 LossPred 0.9432 LossAtt 0.1981 TrainAcc 0.5900 TestAcc 0.5621 0.5800
epoch 700 LossPred 0.9374 LossAtt 0.1644 TrainAcc 0.6000 TestAcc 0.5248 0.5850
epoch 800 LossPred 0.9355 LossAtt 0.1553 TrainAcc 0.6000 TestAcc 0.5248 0.5850
epoch 900 LossPred 0.9354 LossAtt 0.1436 TrainAcc 0.6000 TestAcc 0.5248 0.6000
epoch 1000 LossPred 0.9338 LossAtt 0.1719 TrainAcc 0.6100 TestAcc 0.5343 0.6150
epoch 1100 LossPred 0.8921 LossAtt 0.3140 TrainAcc 0.6100 TestAcc 0.6086 0.6250
epoch 1200 LossPred 0.4842 LossAtt 0.3244 TrainAcc 0.8500 TestAcc 0.7347 0.8500
epoch 1300 LossPred 0.4890 LossAtt 0.3013 TrainAcc 0.8300 TestAcc 0.7788 0.8400
epoch 1400 LossPred 0.4696 LossAtt 0.3058 TrainAcc 0.8500 TestAcc 0.8293 0.8500
epoch 1500 LossPred 0.5130 LossAtt 0.2943 TrainAcc 0.8300 TestAcc 0.8013 0.8300
epoch 1600 LossPred 0.5324 LossAtt 0.3205 TrainAcc 0.8300 TestAcc 0.6924 0.8400
epoch 1700 LossPred 0.4698 LossAtt 0.3214 TrainAcc 0.8500 TestAcc 0.7503 0.8600
epoch 1800 LossPred 0.9130 LossAtt 0.3430 TrainAcc 0.6900 TestAcc 0.5380 0.7000
epoch 1900 LossPred 0.4677 LossAtt 0.3195 TrainAcc 0.8500 TestAcc 0.6909 0.8300
epoch 2000 LossPred 0.6604 LossAtt 0.2932 TrainAcc 0.8000 TestAcc 0.7845 0.8000
epoch 2100 LossPred 0.6036 LossAtt 0.3012 TrainAcc 0.8100 TestAcc 0.8151 0.8050
epoch 2200 LossPred 0.4229 LossAtt 0.3109 TrainAcc 0.8800 TestAcc 0.7898 0.8650
epoch 2300 LossPred 0.5934 LossAtt 0.3238 TrainAcc 0.8200 TestAcc 0.6539 0.8200
epoch 2400 LossPred 0.4481 LossAtt 0.3187 TrainAcc 0.8500 TestAcc 0.7835 0.8700
epoch 2500 LossPred 0.4900 LossAtt 0.3193 TrainAcc 0.8200 TestAcc 0.8271 0.8150
Optimization Finished!
********** replication  20  **********
epoch   0 LossPred 1.1638 LossAtt 1.0087 TrainAcc 0.5100 TestAcc 0.5363 0.5100
epoch 100 LossPred 0.9600 LossAtt 0.4707 TrainAcc 0.5600 TestAcc 0.4885 0.5450
epoch 200 LossPred 0.9501 LossAtt 0.4273 TrainAcc 0.5700 TestAcc 0.5138 0.5350
epoch 300 LossPred 0.9397 LossAtt 0.4033 TrainAcc 0.5900 TestAcc 0.5578 0.5750
epoch 400 LossPred 0.8287 LossAtt 0.4859 TrainAcc 0.7000 TestAcc 0.6386 0.6950
epoch 500 LossPred 1.2824 LossAtt 0.5224 TrainAcc 0.4600 TestAcc 0.5248 0.4750
epoch 600 LossPred 0.6174 LossAtt 0.4689 TrainAcc 0.8200 TestAcc 0.7325 0.8300
epoch 700 LossPred 0.7609 LossAtt 0.4707 TrainAcc 0.7200 TestAcc 0.6434 0.6950
epoch 800 LossPred 0.6087 LossAtt 0.4602 TrainAcc 0.8100 TestAcc 0.7367 0.7700
epoch 900 LossPred 0.5555 LossAtt 0.4453 TrainAcc 0.8400 TestAcc 0.7793 0.8200
epoch 1000 LossPred 0.6362 LossAtt 0.4459 TrainAcc 0.7900 TestAcc 0.7708 0.7800
epoch 1100 LossPred 0.5138 LossAtt 0.4159 TrainAcc 0.8500 TestAcc 0.7480 0.8350
epoch 1200 LossPred 0.5920 LossAtt 0.3959 TrainAcc 0.7700 TestAcc 0.7120 0.7750
epoch 1300 LossPred 0.4351 LossAtt 0.4036 TrainAcc 0.8500 TestAcc 0.7973 0.8600
epoch 1400 LossPred 0.4115 LossAtt 0.3717 TrainAcc 0.8700 TestAcc 0.7928 0.8700
epoch 1500 LossPred 0.5906 LossAtt 0.3747 TrainAcc 0.8300 TestAcc 0.7663 0.8250
epoch 1600 LossPred 0.5059 LossAtt 0.3763 TrainAcc 0.8600 TestAcc 0.7645 0.8500
epoch 1700 LossPred 0.4976 LossAtt 0.3780 TrainAcc 0.8300 TestAcc 0.7565 0.8200
epoch 1800 LossPred 0.4749 LossAtt 0.3766 TrainAcc 0.8400 TestAcc 0.7910 0.8400
epoch 1900 LossPred 0.5076 LossAtt 0.3783 TrainAcc 0.8500 TestAcc 0.7755 0.8650
epoch 2000 LossPred 0.5295 LossAtt 0.3632 TrainAcc 0.8300 TestAcc 0.7738 0.8200
epoch 2100 LossPred 0.4024 LossAtt 0.3499 TrainAcc 0.8800 TestAcc 0.7823 0.8700
epoch 2200 LossPred 0.4668 LossAtt 0.3548 TrainAcc 0.8500 TestAcc 0.7840 0.8500
epoch 2300 LossPred 0.3970 LossAtt 0.3361 TrainAcc 0.8700 TestAcc 0.7795 0.8700
epoch 2400 LossPred 0.3919 LossAtt 0.3141 TrainAcc 0.8600 TestAcc 0.7785 0.8750
epoch 2500 LossPred 0.7451 LossAtt 0.3469 TrainAcc 0.7700 TestAcc 0.7457 0.7850
Optimization Finished!
********** replication  21  **********
epoch   0 LossPred 1.0059 LossAtt 0.9932 TrainAcc 0.5000 TestAcc 0.5065 0.5250
epoch 100 LossPred 0.9425 LossAtt 0.4267 TrainAcc 0.5900 TestAcc 0.5678 0.5950
epoch 200 LossPred 0.8825 LossAtt 0.4474 TrainAcc 0.6200 TestAcc 0.5468 0.6100
epoch 300 LossPred 0.8721 LossAtt 0.4074 TrainAcc 0.6000 TestAcc 0.5465 0.6300
epoch 400 LossPred 0.8648 LossAtt 0.3900 TrainAcc 0.6300 TestAcc 0.5501 0.6050
epoch 500 LossPred 0.8403 LossAtt 0.4113 TrainAcc 0.6600 TestAcc 0.5365 0.6250
epoch 600 LossPred 0.9204 LossAtt 0.4254 TrainAcc 0.5800 TestAcc 0.5363 0.6050
epoch 700 LossPred 0.8276 LossAtt 0.4430 TrainAcc 0.6300 TestAcc 0.5703 0.6600
epoch 800 LossPred 0.7445 LossAtt 0.4859 TrainAcc 0.7100 TestAcc 0.7012 0.7200
epoch 900 LossPred 0.4941 LossAtt 0.4920 TrainAcc 0.8300 TestAcc 0.7683 0.8300
epoch 1000 LossPred 0.5101 LossAtt 0.5002 TrainAcc 0.8400 TestAcc 0.7768 0.8350
epoch 1100 LossPred 0.9687 LossAtt 0.4489 TrainAcc 0.6300 TestAcc 0.5653 0.6100
epoch 1200 LossPred 0.6735 LossAtt 0.4713 TrainAcc 0.7700 TestAcc 0.6907 0.7650
epoch 1300 LossPred 0.7836 LossAtt 0.4600 TrainAcc 0.7200 TestAcc 0.6607 0.7150
epoch 1400 LossPred 0.5439 LossAtt 0.4993 TrainAcc 0.8300 TestAcc 0.7465 0.7850
epoch 1500 LossPred 0.4652 LossAtt 0.4805 TrainAcc 0.8700 TestAcc 0.7658 0.8600
epoch 1600 LossPred 1.0362 LossAtt 0.4568 TrainAcc 0.6200 TestAcc 0.6134 0.6400
epoch 1700 LossPred 0.5867 LossAtt 0.5026 TrainAcc 0.7900 TestAcc 0.7222 0.8000
epoch 1800 LossPred 0.4817 LossAtt 0.4959 TrainAcc 0.8500 TestAcc 0.7683 0.8350
epoch 1900 LossPred 0.4617 LossAtt 0.4945 TrainAcc 0.8700 TestAcc 0.7693 0.8400
epoch 2000 LossPred 0.5425 LossAtt 0.4819 TrainAcc 0.8500 TestAcc 0.7568 0.8200
epoch 2100 LossPred 0.4368 LossAtt 0.4447 TrainAcc 0.8700 TestAcc 0.7680 0.8400
epoch 2200 LossPred 0.5037 LossAtt 0.4353 TrainAcc 0.8400 TestAcc 0.7560 0.8500
epoch 2300 LossPred 0.4070 LossAtt 0.4327 TrainAcc 0.9000 TestAcc 0.7673 0.8650
epoch 2400 LossPred 0.4901 LossAtt 0.4334 TrainAcc 0.8400 TestAcc 0.7583 0.8350
epoch 2500 LossPred 0.3790 LossAtt 0.3976 TrainAcc 0.8900 TestAcc 0.7633 0.8350
Optimization Finished!
********** replication  22  **********
epoch   0 LossPred 1.2307 LossAtt 1.0284 TrainAcc 0.5200 TestAcc 0.5105 0.5200
epoch 100 LossPred 0.9837 LossAtt 0.3754 TrainAcc 0.5500 TestAcc 0.5608 0.5500
epoch 200 LossPred 0.9721 LossAtt 0.3428 TrainAcc 0.5700 TestAcc 0.5831 0.5600
epoch 300 LossPred 0.9442 LossAtt 0.3589 TrainAcc 0.6300 TestAcc 0.6004 0.6100
epoch 400 LossPred 0.8649 LossAtt 0.3768 TrainAcc 0.6600 TestAcc 0.6311 0.6450
epoch 500 LossPred 0.3877 LossAtt 0.3692 TrainAcc 0.8600 TestAcc 0.8514 0.8350
epoch 600 LossPred 0.3970 LossAtt 0.3596 TrainAcc 0.8600 TestAcc 0.8574 0.8400
epoch 700 LossPred 0.3714 LossAtt 0.3546 TrainAcc 0.8700 TestAcc 0.8574 0.8350
epoch 800 LossPred 0.3814 LossAtt 0.3700 TrainAcc 0.8700 TestAcc 0.8549 0.8400
epoch 900 LossPred 0.4006 LossAtt 0.3410 TrainAcc 0.8400 TestAcc 0.8674 0.8400
epoch 1000 LossPred 0.4224 LossAtt 0.3616 TrainAcc 0.8600 TestAcc 0.8601 0.8500
epoch 1100 LossPred 0.3685 LossAtt 0.3497 TrainAcc 0.8800 TestAcc 0.8734 0.8500
epoch 1200 LossPred 0.3813 LossAtt 0.3388 TrainAcc 0.8700 TestAcc 0.8754 0.8500
epoch 1300 LossPred 0.3736 LossAtt 0.3449 TrainAcc 0.8700 TestAcc 0.8744 0.8500
epoch 1400 LossPred 0.3890 LossAtt 0.3617 TrainAcc 0.8600 TestAcc 0.8791 0.8600
epoch 1500 LossPred 0.3742 LossAtt 0.3479 TrainAcc 0.8600 TestAcc 0.8759 0.8550
epoch 1600 LossPred 0.3701 LossAtt 0.3539 TrainAcc 0.8700 TestAcc 0.8786 0.8600
epoch 1700 LossPred 0.3718 LossAtt 0.3582 TrainAcc 0.8700 TestAcc 0.8764 0.8550
epoch 1800 LossPred 0.3631 LossAtt 0.3385 TrainAcc 0.8700 TestAcc 0.8796 0.8500
epoch 1900 LossPred 0.3698 LossAtt 0.3530 TrainAcc 0.8700 TestAcc 0.8771 0.8600
epoch 2000 LossPred 0.3884 LossAtt 0.3538 TrainAcc 0.8700 TestAcc 0.8769 0.8600
epoch 2100 LossPred 0.3657 LossAtt 0.3396 TrainAcc 0.8700 TestAcc 0.8794 0.8600
epoch 2200 LossPred 0.3614 LossAtt 0.3393 TrainAcc 0.8700 TestAcc 0.8739 0.8600
epoch 2300 LossPred 0.3704 LossAtt 0.3396 TrainAcc 0.8600 TestAcc 0.8749 0.8550
epoch 2400 LossPred 0.3621 LossAtt 0.3470 TrainAcc 0.8800 TestAcc 0.8821 0.8500
epoch 2500 LossPred 0.3669 LossAtt 0.3343 TrainAcc 0.8700 TestAcc 0.8774 0.8700
Optimization Finished!
********** replication  23  **********
epoch   0 LossPred 1.2898 LossAtt 0.9983 TrainAcc 0.3900 TestAcc 0.4317 0.4050
epoch 100 LossPred 1.0346 LossAtt 0.4486 TrainAcc 0.4100 TestAcc 0.5045 0.4450
epoch 200 LossPred 0.9744 LossAtt 0.4023 TrainAcc 0.5800 TestAcc 0.5886 0.5750
epoch 300 LossPred 0.9510 LossAtt 0.3116 TrainAcc 0.6000 TestAcc 0.5921 0.5950
epoch 400 LossPred 0.9394 LossAtt 0.3544 TrainAcc 0.6000 TestAcc 0.5921 0.5950
epoch 500 LossPred 0.6096 LossAtt 0.4707 TrainAcc 0.8500 TestAcc 0.7758 0.8050
epoch 600 LossPred 0.4777 LossAtt 0.4656 TrainAcc 0.8500 TestAcc 0.8278 0.8300
epoch 700 LossPred 0.4212 LossAtt 0.4726 TrainAcc 0.8700 TestAcc 0.8348 0.8500
epoch 800 LossPred 0.4092 LossAtt 0.4543 TrainAcc 0.8900 TestAcc 0.8504 0.8400
epoch 900 LossPred 0.3842 LossAtt 0.4455 TrainAcc 0.8800 TestAcc 0.8604 0.8350
epoch 1000 LossPred 0.3574 LossAtt 0.4455 TrainAcc 0.9200 TestAcc 0.8549 0.8550
epoch 1100 LossPred 0.3573 LossAtt 0.4209 TrainAcc 0.8900 TestAcc 0.8554 0.8650
epoch 1200 LossPred 0.3416 LossAtt 0.4219 TrainAcc 0.9000 TestAcc 0.8554 0.8750
epoch 1300 LossPred 0.5995 LossAtt 0.4309 TrainAcc 0.7800 TestAcc 0.8278 0.7850
epoch 1400 LossPred 0.4534 LossAtt 0.4090 TrainAcc 0.8600 TestAcc 0.7960 0.8650
epoch 1500 LossPred 0.3456 LossAtt 0.4104 TrainAcc 0.9200 TestAcc 0.8386 0.8800
epoch 1600 LossPred 0.3503 LossAtt 0.4031 TrainAcc 0.8700 TestAcc 0.8521 0.8750
epoch 1700 LossPred 0.4135 LossAtt 0.4052 TrainAcc 0.8800 TestAcc 0.8366 0.8350
epoch 1800 LossPred 0.3842 LossAtt 0.3895 TrainAcc 0.8900 TestAcc 0.8436 0.8800
epoch 1900 LossPred 0.5186 LossAtt 0.3977 TrainAcc 0.8400 TestAcc 0.7565 0.8200
epoch 2000 LossPred 0.3283 LossAtt 0.3915 TrainAcc 0.9300 TestAcc 0.8471 0.8600
epoch 2100 LossPred 0.3703 LossAtt 0.3986 TrainAcc 0.8900 TestAcc 0.8316 0.8800
epoch 2200 LossPred 0.3478 LossAtt 0.4124 TrainAcc 0.9000 TestAcc 0.8476 0.8500
epoch 2300 LossPred 0.3406 LossAtt 0.3910 TrainAcc 0.9000 TestAcc 0.8488 0.8500
epoch 2400 LossPred 0.4480 LossAtt 0.4054 TrainAcc 0.8700 TestAcc 0.8293 0.8300
epoch 2500 LossPred 0.3674 LossAtt 0.3928 TrainAcc 0.8800 TestAcc 0.8306 0.8700
Optimization Finished!
********** replication  24  **********
epoch   0 LossPred 1.3096 LossAtt 1.0176 TrainAcc 0.4300 TestAcc 0.4922 0.4350
epoch 100 LossPred 1.0270 LossAtt 0.3171 TrainAcc 0.4800 TestAcc 0.4660 0.4950
epoch 200 LossPred 0.9750 LossAtt 0.1974 TrainAcc 0.5400 TestAcc 0.5010 0.5400
epoch 300 LossPred 0.9625 LossAtt 0.2278 TrainAcc 0.6200 TestAcc 0.5766 0.6100
epoch 400 LossPred 0.9467 LossAtt 0.2356 TrainAcc 0.6200 TestAcc 0.5766 0.6200
epoch 500 LossPred 0.9369 LossAtt 0.2957 TrainAcc 0.6200 TestAcc 0.5766 0.6150
epoch 600 LossPred 0.8369 LossAtt 0.4431 TrainAcc 0.7000 TestAcc 0.6366 0.6900
epoch 700 LossPred 0.6267 LossAtt 0.4189 TrainAcc 0.8000 TestAcc 0.7285 0.7850
epoch 800 LossPred 0.5918 LossAtt 0.4349 TrainAcc 0.8300 TestAcc 0.7525 0.8000
epoch 900 LossPred 0.6340 LossAtt 0.4336 TrainAcc 0.7900 TestAcc 0.7325 0.7800
epoch 1000 LossPred 0.3556 LossAtt 0.4534 TrainAcc 0.8900 TestAcc 0.8211 0.8500
epoch 1100 LossPred 0.4505 LossAtt 0.4513 TrainAcc 0.8500 TestAcc 0.7588 0.7900
epoch 1200 LossPred 0.3435 LossAtt 0.4647 TrainAcc 0.8900 TestAcc 0.8506 0.8650
epoch 1300 LossPred 0.3675 LossAtt 0.4909 TrainAcc 0.8700 TestAcc 0.8636 0.8650
epoch 1400 LossPred 0.4717 LossAtt 0.4725 TrainAcc 0.8600 TestAcc 0.7680 0.8200
epoch 1500 LossPred 0.3742 LossAtt 0.4879 TrainAcc 0.9000 TestAcc 0.7885 0.8700
epoch 1600 LossPred 0.2858 LossAtt 0.4810 TrainAcc 0.8900 TestAcc 0.8371 0.8850
epoch 1700 LossPred 0.2697 LossAtt 0.5121 TrainAcc 0.9100 TestAcc 0.9004 0.9200
epoch 1800 LossPred 0.3663 LossAtt 0.4882 TrainAcc 0.8600 TestAcc 0.7888 0.8450
epoch 1900 LossPred 0.3640 LossAtt 0.4946 TrainAcc 0.9100 TestAcc 0.8794 0.8750
epoch 2000 LossPred 0.4097 LossAtt 0.4567 TrainAcc 0.8700 TestAcc 0.7800 0.8550
epoch 2100 LossPred 0.6542 LossAtt 0.4285 TrainAcc 0.8100 TestAcc 0.7205 0.7900
epoch 2200 LossPred 0.5104 LossAtt 0.4579 TrainAcc 0.8400 TestAcc 0.7550 0.8250
epoch 2300 LossPred 0.2436 LossAtt 0.4637 TrainAcc 0.9000 TestAcc 0.8411 0.8850
epoch 2400 LossPred 0.4291 LossAtt 0.4295 TrainAcc 0.8900 TestAcc 0.7803 0.8600
epoch 2500 LossPred 0.3818 LossAtt 0.4300 TrainAcc 0.8800 TestAcc 0.7893 0.8500
Optimization Finished!
********** replication  25  **********
epoch   0 LossPred 1.2079 LossAtt 1.0299 TrainAcc 0.4400 TestAcc 0.4622 0.4400
epoch 100 LossPred 0.9515 LossAtt 0.4933 TrainAcc 0.6300 TestAcc 0.5956 0.6250
epoch 200 LossPred 0.8983 LossAtt 0.4865 TrainAcc 0.6300 TestAcc 0.5951 0.6300
epoch 300 LossPred 0.8064 LossAtt 0.4984 TrainAcc 0.6900 TestAcc 0.6361 0.6750
epoch 400 LossPred 0.6189 LossAtt 0.4642 TrainAcc 0.7900 TestAcc 0.8111 0.7750
epoch 500 LossPred 0.5776 LossAtt 0.4351 TrainAcc 0.8000 TestAcc 0.7963 0.7900
epoch 600 LossPred 0.5259 LossAtt 0.4370 TrainAcc 0.8100 TestAcc 0.7903 0.8000
epoch 700 LossPred 0.5215 LossAtt 0.4220 TrainAcc 0.8200 TestAcc 0.7998 0.7900
epoch 800 LossPred 0.5468 LossAtt 0.4156 TrainAcc 0.8100 TestAcc 0.7900 0.7900
epoch 900 LossPred 0.5106 LossAtt 0.4180 TrainAcc 0.8200 TestAcc 0.7855 0.8100
epoch 1000 LossPred 0.4947 LossAtt 0.4111 TrainAcc 0.8300 TestAcc 0.7793 0.8050
epoch 1100 LossPred 0.4943 LossAtt 0.4063 TrainAcc 0.8300 TestAcc 0.8036 0.8150
epoch 1200 LossPred 0.4545 LossAtt 0.3913 TrainAcc 0.8600 TestAcc 0.7865 0.8000
epoch 1300 LossPred 0.4420 LossAtt 0.3939 TrainAcc 0.8600 TestAcc 0.7913 0.8100
epoch 1400 LossPred 0.4332 LossAtt 0.4147 TrainAcc 0.8700 TestAcc 0.8006 0.8300
epoch 1500 LossPred 0.4313 LossAtt 0.3849 TrainAcc 0.8600 TestAcc 0.7890 0.8100
epoch 1600 LossPred 0.4340 LossAtt 0.4014 TrainAcc 0.8600 TestAcc 0.7878 0.8200
epoch 1700 LossPred 0.4321 LossAtt 0.3817 TrainAcc 0.8600 TestAcc 0.7955 0.8350
epoch 1800 LossPred 0.5035 LossAtt 0.3814 TrainAcc 0.8400 TestAcc 0.7673 0.7950
epoch 1900 LossPred 0.4561 LossAtt 0.3918 TrainAcc 0.8400 TestAcc 0.7693 0.8100
epoch 2000 LossPred 0.4324 LossAtt 0.4002 TrainAcc 0.8600 TestAcc 0.7845 0.8000
epoch 2100 LossPred 0.4698 LossAtt 0.3961 TrainAcc 0.8500 TestAcc 0.7735 0.8050
epoch 2200 LossPred 0.4358 LossAtt 0.3894 TrainAcc 0.8600 TestAcc 0.7868 0.8200
epoch 2300 LossPred 0.4483 LossAtt 0.3863 TrainAcc 0.8600 TestAcc 0.8121 0.8300
epoch 2400 LossPred 0.4316 LossAtt 0.3874 TrainAcc 0.8500 TestAcc 0.7825 0.8300
epoch 2500 LossPred 0.4355 LossAtt 0.3729 TrainAcc 0.8300 TestAcc 0.7910 0.8300
Optimization Finished!
********** replication  26  **********
epoch   0 LossPred 0.9999 LossAtt 0.9861 TrainAcc 0.5400 TestAcc 0.4882 0.5100
epoch 100 LossPred 0.9691 LossAtt 0.4302 TrainAcc 0.5500 TestAcc 0.5393 0.5400
epoch 200 LossPred 0.9640 LossAtt 0.3444 TrainAcc 0.5400 TestAcc 0.5485 0.5350
epoch 300 LossPred 0.9635 LossAtt 0.2802 TrainAcc 0.5400 TestAcc 0.5485 0.5400
epoch 400 LossPred 0.9618 LossAtt 0.3055 TrainAcc 0.5500 TestAcc 0.5573 0.5500
epoch 500 LossPred 0.9468 LossAtt 0.3068 TrainAcc 0.5700 TestAcc 0.5571 0.5700
epoch 600 LossPred 0.9422 LossAtt 0.3444 TrainAcc 0.5400 TestAcc 0.5465 0.5450
epoch 700 LossPred 0.9495 LossAtt 0.3353 TrainAcc 0.5300 TestAcc 0.5465 0.5300
epoch 800 LossPred 0.9380 LossAtt 0.3112 TrainAcc 0.5700 TestAcc 0.5468 0.5800
epoch 900 LossPred 0.9571 LossAtt 0.2926 TrainAcc 0.5500 TestAcc 0.5460 0.5350
epoch 1000 LossPred 0.9578 LossAtt 0.3009 TrainAcc 0.5500 TestAcc 0.5418 0.5500
epoch 1100 LossPred 0.9452 LossAtt 0.3380 TrainAcc 0.5700 TestAcc 0.5368 0.5650
epoch 1200 LossPred 0.9349 LossAtt 0.3420 TrainAcc 0.5500 TestAcc 0.5303 0.5600
epoch 1300 LossPred 0.9454 LossAtt 0.3330 TrainAcc 0.5600 TestAcc 0.5410 0.5600
epoch 1400 LossPred 0.9507 LossAtt 0.3489 TrainAcc 0.5800 TestAcc 0.5350 0.5800
epoch 1500 LossPred 0.9420 LossAtt 0.3357 TrainAcc 0.6000 TestAcc 0.5250 0.5800
epoch 1600 LossPred 0.9402 LossAtt 0.3185 TrainAcc 0.6000 TestAcc 0.5501 0.5850
epoch 1700 LossPred 0.9382 LossAtt 0.3197 TrainAcc 0.6100 TestAcc 0.5425 0.5600
epoch 1800 LossPred 0.9649 LossAtt 0.2639 TrainAcc 0.5400 TestAcc 0.5095 0.5400
epoch 1900 LossPred 0.9736 LossAtt 0.1952 TrainAcc 0.5400 TestAcc 0.5095 0.5400
epoch 2000 LossPred 0.9852 LossAtt 0.1312 TrainAcc 0.5400 TestAcc 0.5095 0.5400
epoch 2100 LossPred 0.9853 LossAtt 0.1159 TrainAcc 0.5400 TestAcc 0.5095 0.5400
epoch 2200 LossPred 0.9853 LossAtt 0.1102 TrainAcc 0.5400 TestAcc 0.5095 0.5400
epoch 2300 LossPred 0.9851 LossAtt 0.1019 TrainAcc 0.5400 TestAcc 0.5095 0.5400
epoch 2400 LossPred 0.9853 LossAtt 0.1029 TrainAcc 0.5400 TestAcc 0.5095 0.5400
epoch 2500 LossPred 0.9853 LossAtt 0.1064 TrainAcc 0.5400 TestAcc 0.5095 0.5400
Optimization Finished!
********** replication  27  **********
epoch   0 LossPred 1.0882 LossAtt 1.0596 TrainAcc 0.6300 TestAcc 0.5793 0.5650
epoch 100 LossPred 0.8809 LossAtt 0.4626 TrainAcc 0.6600 TestAcc 0.5283 0.6400
epoch 200 LossPred 0.8863 LossAtt 0.3858 TrainAcc 0.6300 TestAcc 0.4997 0.6200
epoch 300 LossPred 0.8683 LossAtt 0.3455 TrainAcc 0.6300 TestAcc 0.4997 0.6300
epoch 400 LossPred 0.8596 LossAtt 0.3377 TrainAcc 0.6300 TestAcc 0.4997 0.6300
epoch 500 LossPred 0.8501 LossAtt 0.3358 TrainAcc 0.6300 TestAcc 0.4997 0.6300
epoch 600 LossPred 0.8437 LossAtt 0.2973 TrainAcc 0.6600 TestAcc 0.5243 0.6300
epoch 700 LossPred 0.8427 LossAtt 0.2519 TrainAcc 0.6500 TestAcc 0.5233 0.6250
epoch 800 LossPred 0.8479 LossAtt 0.2440 TrainAcc 0.6400 TestAcc 0.5703 0.6350
epoch 900 LossPred 0.8337 LossAtt 0.2010 TrainAcc 0.6700 TestAcc 0.5891 0.6750
epoch 1000 LossPred 0.8260 LossAtt 0.1759 TrainAcc 0.6800 TestAcc 0.5513 0.6650
epoch 1100 LossPred 0.8334 LossAtt 0.1361 TrainAcc 0.6800 TestAcc 0.5513 0.6700
epoch 1200 LossPred 0.8606 LossAtt 0.2533 TrainAcc 0.6400 TestAcc 0.5318 0.6350
epoch 1300 LossPred 0.8496 LossAtt 0.2115 TrainAcc 0.6200 TestAcc 0.5088 0.6250
epoch 1400 LossPred 0.8427 LossAtt 0.1935 TrainAcc 0.6200 TestAcc 0.5088 0.6350
epoch 1500 LossPred 0.8377 LossAtt 0.1548 TrainAcc 0.6000 TestAcc 0.5055 0.6250
epoch 1600 LossPred 0.8346 LossAtt 0.1354 TrainAcc 0.6000 TestAcc 0.5055 0.6350
epoch 1700 LossPred 0.8312 LossAtt 0.1420 TrainAcc 0.6600 TestAcc 0.5283 0.6600
epoch 1800 LossPred 0.8281 LossAtt 0.1149 TrainAcc 0.6000 TestAcc 0.5055 0.6350
epoch 1900 LossPred 0.8239 LossAtt 0.1215 TrainAcc 0.6500 TestAcc 0.5258 0.6550
epoch 2000 LossPred 0.8211 LossAtt 0.1319 TrainAcc 0.6500 TestAcc 0.5546 0.6550
epoch 2100 LossPred 0.8186 LossAtt 0.1180 TrainAcc 0.6600 TestAcc 0.5283 0.6600
epoch 2200 LossPred 0.8153 LossAtt 0.1105 TrainAcc 0.6600 TestAcc 0.5328 0.6650
epoch 2300 LossPred 0.8012 LossAtt 0.1210 TrainAcc 0.6800 TestAcc 0.5443 0.6600
epoch 2400 LossPred 0.7703 LossAtt 0.2234 TrainAcc 0.6800 TestAcc 0.5628 0.6550
epoch 2500 LossPred 0.7700 LossAtt 0.1774 TrainAcc 0.6800 TestAcc 0.5581 0.6550
Optimization Finished!
********** replication  28  **********
epoch   0 LossPred 1.4284 LossAtt 0.9871 TrainAcc 0.4200 TestAcc 0.4707 0.4450
epoch 100 LossPred 1.0656 LossAtt 0.3957 TrainAcc 0.4100 TestAcc 0.4232 0.4100
epoch 200 LossPred 0.9987 LossAtt 0.2647 TrainAcc 0.4700 TestAcc 0.5128 0.4850
epoch 300 LossPred 0.9973 LossAtt 0.2009 TrainAcc 0.5500 TestAcc 0.5881 0.5500
epoch 400 LossPred 0.9863 LossAtt 0.2091 TrainAcc 0.5500 TestAcc 0.5881 0.5500
epoch 500 LossPred 0.9734 LossAtt 0.2071 TrainAcc 0.5900 TestAcc 0.5768 0.5900
epoch 600 LossPred 0.9606 LossAtt 0.2183 TrainAcc 0.5900 TestAcc 0.5768 0.5900
epoch 700 LossPred 0.9501 LossAtt 0.2588 TrainAcc 0.5900 TestAcc 0.5768 0.5900
epoch 800 LossPred 0.9164 LossAtt 0.2823 TrainAcc 0.6100 TestAcc 0.6201 0.6300
epoch 900 LossPred 0.5032 LossAtt 0.2622 TrainAcc 0.8300 TestAcc 0.8113 0.8300
epoch 1000 LossPred 0.4910 LossAtt 0.2338 TrainAcc 0.8500 TestAcc 0.8083 0.8250
epoch 1100 LossPred 0.5112 LossAtt 0.2418 TrainAcc 0.8300 TestAcc 0.7603 0.8500
epoch 1200 LossPred 0.5579 LossAtt 0.2428 TrainAcc 0.8000 TestAcc 0.8113 0.8100
epoch 1300 LossPred 0.5020 LossAtt 0.2331 TrainAcc 0.8200 TestAcc 0.7915 0.8250
epoch 1400 LossPred 0.5828 LossAtt 0.2480 TrainAcc 0.8100 TestAcc 0.8146 0.8250
epoch 1500 LossPred 0.4969 LossAtt 0.2414 TrainAcc 0.8500 TestAcc 0.8003 0.8300
epoch 1600 LossPred 0.5523 LossAtt 0.2461 TrainAcc 0.8200 TestAcc 0.8216 0.8250
epoch 1700 LossPred 0.4750 LossAtt 0.2505 TrainAcc 0.8500 TestAcc 0.8036 0.8400
epoch 1800 LossPred 0.5525 LossAtt 0.2441 TrainAcc 0.8100 TestAcc 0.8166 0.8150
epoch 1900 LossPred 0.5975 LossAtt 0.2434 TrainAcc 0.7900 TestAcc 0.7813 0.7800
epoch 2000 LossPred 0.9343 LossAtt 0.2323 TrainAcc 0.6900 TestAcc 0.6647 0.7000
epoch 2100 LossPred 0.6644 LossAtt 0.2680 TrainAcc 0.7900 TestAcc 0.7247 0.7800
epoch 2200 LossPred 0.4845 LossAtt 0.2481 TrainAcc 0.8400 TestAcc 0.8021 0.8200
epoch 2300 LossPred 0.4990 LossAtt 0.2563 TrainAcc 0.8200 TestAcc 0.7963 0.8300
epoch 2400 LossPred 0.6174 LossAtt 0.2367 TrainAcc 0.8100 TestAcc 0.7422 0.8050
epoch 2500 LossPred 0.8322 LossAtt 0.2557 TrainAcc 0.6700 TestAcc 0.6842 0.6650
Optimization Finished!
********** replication  29  **********
epoch   0 LossPred 1.2153 LossAtt 1.0198 TrainAcc 0.5000 TestAcc 0.5225 0.4750
epoch 100 LossPred 0.9583 LossAtt 0.4463 TrainAcc 0.6100 TestAcc 0.5928 0.6100
epoch 200 LossPred 0.9279 LossAtt 0.3546 TrainAcc 0.6100 TestAcc 0.5928 0.6100
epoch 300 LossPred 0.9317 LossAtt 0.2971 TrainAcc 0.6100 TestAcc 0.5928 0.6250
epoch 400 LossPred 0.9164 LossAtt 0.2184 TrainAcc 0.6100 TestAcc 0.5928 0.6150
epoch 500 LossPred 0.9128 LossAtt 0.2253 TrainAcc 0.6100 TestAcc 0.5928 0.6100
epoch 600 LossPred 0.8971 LossAtt 0.2552 TrainAcc 0.6600 TestAcc 0.6161 0.6300
epoch 700 LossPred 1.0353 LossAtt 0.3269 TrainAcc 0.5900 TestAcc 0.6767 0.5950
epoch 800 LossPred 0.8584 LossAtt 0.3011 TrainAcc 0.6500 TestAcc 0.5561 0.6600
epoch 900 LossPred 0.8243 LossAtt 0.3007 TrainAcc 0.6900 TestAcc 0.6181 0.6700
epoch 1000 LossPred 0.8175 LossAtt 0.2811 TrainAcc 0.6900 TestAcc 0.6141 0.6650
epoch 1100 LossPred 0.7698 LossAtt 0.2855 TrainAcc 0.7000 TestAcc 0.6617 0.6850
epoch 1200 LossPred 0.6040 LossAtt 0.2905 TrainAcc 0.7700 TestAcc 0.7292 0.7550
epoch 1300 LossPred 0.5746 LossAtt 0.2823 TrainAcc 0.7800 TestAcc 0.7395 0.7600
epoch 1400 LossPred 0.5698 LossAtt 0.2831 TrainAcc 0.7800 TestAcc 0.7472 0.7500
epoch 1500 LossPred 0.5507 LossAtt 0.2748 TrainAcc 0.7900 TestAcc 0.7650 0.7600
epoch 1600 LossPred 0.5472 LossAtt 0.2844 TrainAcc 0.8000 TestAcc 0.7708 0.7800
epoch 1700 LossPred 0.5437 LossAtt 0.2811 TrainAcc 0.8000 TestAcc 0.7773 0.7800
epoch 1800 LossPred 0.6590 LossAtt 0.2805 TrainAcc 0.7600 TestAcc 0.7322 0.7250
epoch 1900 LossPred 0.4700 LossAtt 0.2765 TrainAcc 0.8400 TestAcc 0.8076 0.8200
epoch 2000 LossPred 0.4683 LossAtt 0.2895 TrainAcc 0.8500 TestAcc 0.8268 0.8300
epoch 2100 LossPred 0.5412 LossAtt 0.2953 TrainAcc 0.8200 TestAcc 0.8186 0.8000
epoch 2200 LossPred 0.5458 LossAtt 0.2678 TrainAcc 0.8300 TestAcc 0.8163 0.7950
epoch 2300 LossPred 0.4673 LossAtt 0.2831 TrainAcc 0.8500 TestAcc 0.8251 0.8200
epoch 2400 LossPred 0.4692 LossAtt 0.2801 TrainAcc 0.8200 TestAcc 0.8278 0.8350
epoch 2500 LossPred 0.4678 LossAtt 0.2686 TrainAcc 0.8500 TestAcc 0.8166 0.8250
Optimization Finished!
********** replication  30  **********
epoch   0 LossPred 1.1385 LossAtt 1.0111 TrainAcc 0.5400 TestAcc 0.5173 0.5200
epoch 100 LossPred 0.9289 LossAtt 0.4981 TrainAcc 0.6700 TestAcc 0.5813 0.6300
epoch 200 LossPred 0.8334 LossAtt 0.4724 TrainAcc 0.7400 TestAcc 0.6041 0.7100
epoch 300 LossPred 0.7538 LossAtt 0.5376 TrainAcc 0.7500 TestAcc 0.6194 0.7050
epoch 400 LossPred 0.5121 LossAtt 0.5914 TrainAcc 0.8400 TestAcc 0.7653 0.8150
epoch 500 LossPred 0.4563 LossAtt 0.5637 TrainAcc 0.8800 TestAcc 0.8301 0.8400
epoch 600 LossPred 0.4289 LossAtt 0.5119 TrainAcc 0.8500 TestAcc 0.8306 0.8350
epoch 700 LossPred 0.4497 LossAtt 0.5459 TrainAcc 0.8400 TestAcc 0.8313 0.8500
epoch 800 LossPred 0.3266 LossAtt 0.5167 TrainAcc 0.9100 TestAcc 0.8504 0.8650
epoch 900 LossPred 0.2724 LossAtt 0.4953 TrainAcc 0.9100 TestAcc 0.8516 0.8750
epoch 1000 LossPred 0.2646 LossAtt 0.4900 TrainAcc 0.9200 TestAcc 0.8511 0.8750
epoch 1100 LossPred 0.3036 LossAtt 0.4822 TrainAcc 0.9000 TestAcc 0.8556 0.8700
epoch 1200 LossPred 0.2658 LossAtt 0.4702 TrainAcc 0.9200 TestAcc 0.8541 0.8800
epoch 1300 LossPred 0.2867 LossAtt 0.4575 TrainAcc 0.9100 TestAcc 0.8511 0.8650
epoch 1400 LossPred 0.2805 LossAtt 0.4632 TrainAcc 0.9200 TestAcc 0.8488 0.8750
epoch 1500 LossPred 0.2854 LossAtt 0.4572 TrainAcc 0.9000 TestAcc 0.8478 0.8800
epoch 1600 LossPred 0.4326 LossAtt 0.4605 TrainAcc 0.8600 TestAcc 0.8033 0.8200
epoch 1700 LossPred 0.3737 LossAtt 0.4329 TrainAcc 0.8900 TestAcc 0.8406 0.8550
epoch 1800 LossPred 0.4084 LossAtt 0.4493 TrainAcc 0.8900 TestAcc 0.8311 0.8400
epoch 1900 LossPred 0.4760 LossAtt 0.3647 TrainAcc 0.8600 TestAcc 0.8198 0.8150
epoch 2000 LossPred 0.5803 LossAtt 0.3716 TrainAcc 0.7700 TestAcc 0.7543 0.7450
epoch 2100 LossPred 0.5688 LossAtt 0.3141 TrainAcc 0.7900 TestAcc 0.7623 0.7800
epoch 2200 LossPred 0.3956 LossAtt 0.3397 TrainAcc 0.8900 TestAcc 0.8101 0.8100
epoch 2300 LossPred 0.4072 LossAtt 0.3259 TrainAcc 0.8900 TestAcc 0.8288 0.8300
epoch 2400 LossPred 0.4268 LossAtt 0.3299 TrainAcc 0.8700 TestAcc 0.8191 0.8250
epoch 2500 LossPred 0.4409 LossAtt 0.3344 TrainAcc 0.8700 TestAcc 0.8283 0.8250
Optimization Finished!
********** replication  31  **********
epoch   0 LossPred 1.1985 LossAtt 1.0067 TrainAcc 0.5200 TestAcc 0.5498 0.5100
epoch 100 LossPred 0.9932 LossAtt 0.3861 TrainAcc 0.5300 TestAcc 0.5528 0.5300
epoch 200 LossPred 0.9617 LossAtt 0.4339 TrainAcc 0.6000 TestAcc 0.5318 0.5750
epoch 300 LossPred 0.8918 LossAtt 0.4740 TrainAcc 0.6400 TestAcc 0.5003 0.6800
epoch 400 LossPred 0.8265 LossAtt 0.4243 TrainAcc 0.6800 TestAcc 0.5150 0.7000
epoch 500 LossPred 0.7980 LossAtt 0.4056 TrainAcc 0.7100 TestAcc 0.5133 0.7100
epoch 600 LossPred 0.7827 LossAtt 0.3783 TrainAcc 0.7300 TestAcc 0.5165 0.7350
epoch 700 LossPred 0.7889 LossAtt 0.3778 TrainAcc 0.7100 TestAcc 0.5158 0.6950
epoch 800 LossPred 0.7763 LossAtt 0.3705 TrainAcc 0.7200 TestAcc 0.5263 0.7000
epoch 900 LossPred 0.7590 LossAtt 0.3540 TrainAcc 0.7500 TestAcc 0.5405 0.6950
epoch 1000 LossPred 0.7699 LossAtt 0.3470 TrainAcc 0.7300 TestAcc 0.5483 0.6800
epoch 1100 LossPred 0.7576 LossAtt 0.3673 TrainAcc 0.7200 TestAcc 0.5473 0.6850
epoch 1200 LossPred 0.7389 LossAtt 0.3849 TrainAcc 0.7400 TestAcc 0.5538 0.6850
epoch 1300 LossPred 0.6976 LossAtt 0.4178 TrainAcc 0.7700 TestAcc 0.5380 0.6900
epoch 1400 LossPred 0.6994 LossAtt 0.4638 TrainAcc 0.7300 TestAcc 0.5308 0.7000
epoch 1500 LossPred 0.6634 LossAtt 0.4257 TrainAcc 0.8100 TestAcc 0.5460 0.7250
epoch 1600 LossPred 0.6337 LossAtt 0.4204 TrainAcc 0.8200 TestAcc 0.5546 0.7200
epoch 1700 LossPred 0.6425 LossAtt 0.4140 TrainAcc 0.8000 TestAcc 0.5521 0.7350
epoch 1800 LossPred 0.6175 LossAtt 0.3931 TrainAcc 0.8100 TestAcc 0.5495 0.7400
epoch 1900 LossPred 0.5993 LossAtt 0.4111 TrainAcc 0.8100 TestAcc 0.5653 0.7350
epoch 2000 LossPred 0.6038 LossAtt 0.4088 TrainAcc 0.7500 TestAcc 0.5618 0.7200
epoch 2100 LossPred 0.6156 LossAtt 0.4269 TrainAcc 0.7700 TestAcc 0.5601 0.7300
epoch 2200 LossPred 0.6544 LossAtt 0.3942 TrainAcc 0.7700 TestAcc 0.5703 0.7300
epoch 2300 LossPred 0.6289 LossAtt 0.3806 TrainAcc 0.7800 TestAcc 0.5731 0.7200
epoch 2400 LossPred 0.7245 LossAtt 0.3767 TrainAcc 0.7200 TestAcc 0.6264 0.7000
epoch 2500 LossPred 0.6988 LossAtt 0.3715 TrainAcc 0.8000 TestAcc 0.5906 0.7400
Optimization Finished!
********** replication  32  **********
epoch   0 LossPred 1.2413 LossAtt 1.0186 TrainAcc 0.4700 TestAcc 0.5168 0.5050
epoch 100 LossPred 0.9757 LossAtt 0.3956 TrainAcc 0.5700 TestAcc 0.5158 0.5850
epoch 200 LossPred 0.9523 LossAtt 0.3515 TrainAcc 0.6000 TestAcc 0.5388 0.6000
epoch 300 LossPred 0.9511 LossAtt 0.3218 TrainAcc 0.6000 TestAcc 0.5388 0.5950
epoch 400 LossPred 0.9369 LossAtt 0.4188 TrainAcc 0.6000 TestAcc 0.5433 0.5850
epoch 500 LossPred 0.9060 LossAtt 0.4684 TrainAcc 0.6600 TestAcc 0.5383 0.6500
epoch 600 LossPred 0.8718 LossAtt 0.5121 TrainAcc 0.6700 TestAcc 0.5263 0.6350
epoch 700 LossPred 0.8613 LossAtt 0.5318 TrainAcc 0.6500 TestAcc 0.5390 0.6600
epoch 800 LossPred 0.8362 LossAtt 0.5749 TrainAcc 0.6900 TestAcc 0.5433 0.6600
epoch 900 LossPred 0.8311 LossAtt 0.5785 TrainAcc 0.7000 TestAcc 0.5465 0.6650
epoch 1000 LossPred 0.8243 LossAtt 0.5802 TrainAcc 0.6900 TestAcc 0.5478 0.6750
epoch 1100 LossPred 0.8159 LossAtt 0.5836 TrainAcc 0.7300 TestAcc 0.5453 0.6750
epoch 1200 LossPred 0.8035 LossAtt 0.6053 TrainAcc 0.7000 TestAcc 0.5511 0.6750
epoch 1300 LossPred 0.7851 LossAtt 0.6266 TrainAcc 0.6800 TestAcc 0.5470 0.6800
epoch 1400 LossPred 0.7717 LossAtt 0.6292 TrainAcc 0.6800 TestAcc 0.5528 0.6800
epoch 1500 LossPred 0.7524 LossAtt 0.6537 TrainAcc 0.7300 TestAcc 0.5531 0.6850
epoch 1600 LossPred 0.7361 LossAtt 0.6208 TrainAcc 0.7100 TestAcc 0.5558 0.6850
epoch 1700 LossPred 0.7633 LossAtt 0.6421 TrainAcc 0.7200 TestAcc 0.5626 0.6750
epoch 1800 LossPred 0.7124 LossAtt 0.6183 TrainAcc 0.7600 TestAcc 0.5883 0.7050
epoch 1900 LossPred 0.6886 LossAtt 0.5939 TrainAcc 0.7600 TestAcc 0.6009 0.7100
epoch 2000 LossPred 0.5545 LossAtt 0.6362 TrainAcc 0.7900 TestAcc 0.7257 0.7550
epoch 2100 LossPred 0.6384 LossAtt 0.6076 TrainAcc 0.7500 TestAcc 0.6782 0.7150
epoch 2200 LossPred 0.5377 LossAtt 0.6077 TrainAcc 0.8000 TestAcc 0.7635 0.7950
epoch 2300 LossPred 0.4892 LossAtt 0.5884 TrainAcc 0.8300 TestAcc 0.7760 0.8450
epoch 2400 LossPred 0.3623 LossAtt 0.5756 TrainAcc 0.8900 TestAcc 0.7933 0.8250
epoch 2500 LossPred 0.6614 LossAtt 0.5988 TrainAcc 0.7600 TestAcc 0.6969 0.7550
Optimization Finished!
********** replication  33  **********
epoch   0 LossPred 1.2443 LossAtt 1.0132 TrainAcc 0.4800 TestAcc 0.5671 0.4850
epoch 100 LossPred 1.0342 LossAtt 0.4811 TrainAcc 0.5300 TestAcc 0.5953 0.5250
epoch 200 LossPred 1.0039 LossAtt 0.4972 TrainAcc 0.5200 TestAcc 0.5778 0.5300
epoch 300 LossPred 0.9876 LossAtt 0.5111 TrainAcc 0.5500 TestAcc 0.5606 0.5450
epoch 400 LossPred 0.6574 LossAtt 0.5907 TrainAcc 0.8000 TestAcc 0.7217 0.7800
epoch 500 LossPred 0.4368 LossAtt 0.5210 TrainAcc 0.8900 TestAcc 0.8246 0.8700
epoch 600 LossPred 0.4024 LossAtt 0.4711 TrainAcc 0.8900 TestAcc 0.8243 0.8550
epoch 700 LossPred 0.4174 LossAtt 0.4635 TrainAcc 0.8600 TestAcc 0.8186 0.8700
epoch 800 LossPred 0.3553 LossAtt 0.4308 TrainAcc 0.8800 TestAcc 0.8191 0.8750
epoch 900 LossPred 0.3550 LossAtt 0.4233 TrainAcc 0.8800 TestAcc 0.8233 0.8650
epoch 1000 LossPred 0.3391 LossAtt 0.4287 TrainAcc 0.8800 TestAcc 0.8276 0.8650
epoch 1100 LossPred 0.3354 LossAtt 0.4139 TrainAcc 0.8900 TestAcc 0.8343 0.8800
epoch 1200 LossPred 0.3126 LossAtt 0.3850 TrainAcc 0.8800 TestAcc 0.8371 0.8800
epoch 1300 LossPred 0.2976 LossAtt 0.4052 TrainAcc 0.9300 TestAcc 0.8326 0.9000
epoch 1400 LossPred 0.3471 LossAtt 0.3931 TrainAcc 0.9100 TestAcc 0.7965 0.8950
epoch 1500 LossPred 0.2657 LossAtt 0.4068 TrainAcc 0.9300 TestAcc 0.8318 0.9200
epoch 1600 LossPred 0.2633 LossAtt 0.3835 TrainAcc 0.9300 TestAcc 0.8281 0.9200
epoch 1700 LossPred 0.2681 LossAtt 0.3758 TrainAcc 0.9400 TestAcc 0.8303 0.9200
epoch 1800 LossPred 0.2476 LossAtt 0.3943 TrainAcc 0.9500 TestAcc 0.8286 0.9300
epoch 1900 LossPred 0.4090 LossAtt 0.3766 TrainAcc 0.9000 TestAcc 0.8166 0.8950
epoch 2000 LossPred 0.3716 LossAtt 0.3769 TrainAcc 0.9000 TestAcc 0.7718 0.8750
epoch 2100 LossPred 0.2813 LossAtt 0.3756 TrainAcc 0.9300 TestAcc 0.8101 0.9200
epoch 2200 LossPred 0.2585 LossAtt 0.3724 TrainAcc 0.9300 TestAcc 0.8221 0.9100
epoch 2300 LossPred 0.2815 LossAtt 0.3757 TrainAcc 0.9300 TestAcc 0.8218 0.9000
epoch 2400 LossPred 0.3219 LossAtt 0.3700 TrainAcc 0.9200 TestAcc 0.8153 0.9000
epoch 2500 LossPred 0.2039 LossAtt 0.3508 TrainAcc 0.9500 TestAcc 0.8188 0.9200
Optimization Finished!
********** replication  34  **********
epoch   0 LossPred 1.0162 LossAtt 1.0073 TrainAcc 0.5300 TestAcc 0.5148 0.5300
epoch 100 LossPred 0.9102 LossAtt 0.2804 TrainAcc 0.6400 TestAcc 0.5921 0.6400
epoch 200 LossPred 0.8938 LossAtt 0.2877 TrainAcc 0.6400 TestAcc 0.5921 0.6550
epoch 300 LossPred 0.7265 LossAtt 0.4046 TrainAcc 0.7400 TestAcc 0.7555 0.7550
epoch 400 LossPred 0.4993 LossAtt 0.4042 TrainAcc 0.8400 TestAcc 0.8166 0.8050
epoch 500 LossPred 0.5080 LossAtt 0.4114 TrainAcc 0.8100 TestAcc 0.8321 0.8100
epoch 600 LossPred 0.4519 LossAtt 0.3920 TrainAcc 0.8400 TestAcc 0.8251 0.8150
epoch 700 LossPred 0.5290 LossAtt 0.3779 TrainAcc 0.8200 TestAcc 0.8396 0.8100
epoch 800 LossPred 0.5170 LossAtt 0.3855 TrainAcc 0.8300 TestAcc 0.8391 0.7800
epoch 900 LossPred 0.4775 LossAtt 0.3753 TrainAcc 0.8400 TestAcc 0.8478 0.8250
epoch 1000 LossPred 0.4431 LossAtt 0.3804 TrainAcc 0.8500 TestAcc 0.8483 0.8250
epoch 1100 LossPred 0.4428 LossAtt 0.3629 TrainAcc 0.8600 TestAcc 0.8381 0.8350
epoch 1200 LossPred 0.4479 LossAtt 0.3846 TrainAcc 0.8300 TestAcc 0.8621 0.8200
epoch 1300 LossPred 0.4556 LossAtt 0.3734 TrainAcc 0.8200 TestAcc 0.8413 0.8300
epoch 1400 LossPred 0.5062 LossAtt 0.3636 TrainAcc 0.7900 TestAcc 0.8288 0.8150
epoch 1500 LossPred 0.4105 LossAtt 0.3638 TrainAcc 0.8600 TestAcc 0.8559 0.8400
epoch 1600 LossPred 0.3984 LossAtt 0.3588 TrainAcc 0.8300 TestAcc 0.8436 0.8450
epoch 1700 LossPred 0.3299 LossAtt 0.3643 TrainAcc 0.9100 TestAcc 0.8749 0.8700
epoch 1800 LossPred 0.3295 LossAtt 0.3597 TrainAcc 0.9200 TestAcc 0.8644 0.8850
epoch 1900 LossPred 0.3719 LossAtt 0.3788 TrainAcc 0.8900 TestAcc 0.8744 0.8500
epoch 2000 LossPred 0.2898 LossAtt 0.3484 TrainAcc 0.9100 TestAcc 0.8666 0.9100
epoch 2100 LossPred 0.2329 LossAtt 0.3506 TrainAcc 0.9400 TestAcc 0.8809 0.9050
epoch 2200 LossPred 0.7495 LossAtt 0.3470 TrainAcc 0.7900 TestAcc 0.7525 0.7950
epoch 2300 LossPred 0.2652 LossAtt 0.3666 TrainAcc 0.9300 TestAcc 0.8831 0.9100
epoch 2400 LossPred 0.2274 LossAtt 0.3553 TrainAcc 0.9300 TestAcc 0.8854 0.9050
epoch 2500 LossPred 0.3123 LossAtt 0.3567 TrainAcc 0.9000 TestAcc 0.8453 0.8850
Optimization Finished!
********** replication  35  **********
epoch   0 LossPred 1.2517 LossAtt 1.0296 TrainAcc 0.5100 TestAcc 0.4537 0.5350
epoch 100 LossPred 1.0155 LossAtt 0.3477 TrainAcc 0.5900 TestAcc 0.5053 0.5900
epoch 200 LossPred 0.9984 LossAtt 0.3653 TrainAcc 0.5900 TestAcc 0.5053 0.5900
epoch 300 LossPred 0.9512 LossAtt 0.2974 TrainAcc 0.5900 TestAcc 0.5053 0.5900
epoch 400 LossPred 0.9276 LossAtt 0.2720 TrainAcc 0.6400 TestAcc 0.6006 0.6150
epoch 500 LossPred 0.9224 LossAtt 0.2706 TrainAcc 0.6400 TestAcc 0.6006 0.6250
epoch 600 LossPred 0.8710 LossAtt 0.4058 TrainAcc 0.6900 TestAcc 0.6582 0.6800
epoch 700 LossPred 0.6870 LossAtt 0.4204 TrainAcc 0.7600 TestAcc 0.7107 0.7450
epoch 800 LossPred 0.5723 LossAtt 0.4075 TrainAcc 0.8300 TestAcc 0.8026 0.8450
epoch 900 LossPred 0.5428 LossAtt 0.3766 TrainAcc 0.8300 TestAcc 0.7945 0.8100
epoch 1000 LossPred 0.5097 LossAtt 0.3806 TrainAcc 0.8300 TestAcc 0.7975 0.8300
epoch 1100 LossPred 0.5483 LossAtt 0.3871 TrainAcc 0.8200 TestAcc 0.7923 0.8200
epoch 1200 LossPred 0.5051 LossAtt 0.4059 TrainAcc 0.8300 TestAcc 0.7955 0.8150
epoch 1300 LossPred 0.4597 LossAtt 0.3946 TrainAcc 0.8500 TestAcc 0.7988 0.8250
epoch 1400 LossPred 0.5460 LossAtt 0.4021 TrainAcc 0.8000 TestAcc 0.7710 0.7850
epoch 1500 LossPred 0.5445 LossAtt 0.3866 TrainAcc 0.8000 TestAcc 0.7698 0.7900
epoch 1600 LossPred 0.4405 LossAtt 0.3699 TrainAcc 0.8500 TestAcc 0.8093 0.8500
epoch 1700 LossPred 0.4928 LossAtt 0.3580 TrainAcc 0.8500 TestAcc 0.7890 0.8350
epoch 1800 LossPred 0.5884 LossAtt 0.3364 TrainAcc 0.8100 TestAcc 0.7347 0.7850
epoch 1900 LossPred 0.5487 LossAtt 0.3438 TrainAcc 0.8200 TestAcc 0.7723 0.8300
epoch 2000 LossPred 0.6411 LossAtt 0.3383 TrainAcc 0.7800 TestAcc 0.7197 0.7550
epoch 2100 LossPred 0.4578 LossAtt 0.3394 TrainAcc 0.8500 TestAcc 0.8068 0.8500
epoch 2200 LossPred 1.0362 LossAtt 0.3190 TrainAcc 0.6600 TestAcc 0.5873 0.6550
epoch 2300 LossPred 0.4768 LossAtt 0.3443 TrainAcc 0.8600 TestAcc 0.8066 0.8350
epoch 2400 LossPred 1.3152 LossAtt 0.2742 TrainAcc 0.5900 TestAcc 0.5088 0.5900
epoch 2500 LossPred 0.6733 LossAtt 0.3213 TrainAcc 0.7900 TestAcc 0.7698 0.7850
Optimization Finished!
********** replication  36  **********
epoch   0 LossPred 1.0951 LossAtt 1.0277 TrainAcc 0.5900 TestAcc 0.5671 0.5900
epoch 100 LossPred 0.9129 LossAtt 0.4215 TrainAcc 0.6000 TestAcc 0.5831 0.6250
epoch 200 LossPred 0.8880 LossAtt 0.4371 TrainAcc 0.6600 TestAcc 0.5926 0.6600
epoch 300 LossPred 0.8722 LossAtt 0.3924 TrainAcc 0.6600 TestAcc 0.6026 0.6600
epoch 400 LossPred 0.8605 LossAtt 0.4046 TrainAcc 0.6700 TestAcc 0.6039 0.6500
epoch 500 LossPred 0.6266 LossAtt 0.5111 TrainAcc 0.7900 TestAcc 0.7492 0.7800
epoch 600 LossPred 0.5195 LossAtt 0.5072 TrainAcc 0.8100 TestAcc 0.7943 0.7900
epoch 700 LossPred 0.2371 LossAtt 0.4880 TrainAcc 0.9400 TestAcc 0.8739 0.9400
epoch 800 LossPred 0.2144 LossAtt 0.4532 TrainAcc 0.9300 TestAcc 0.8706 0.9150
epoch 900 LossPred 0.2105 LossAtt 0.4504 TrainAcc 0.9300 TestAcc 0.8779 0.9300
epoch 1000 LossPred 0.2186 LossAtt 0.4266 TrainAcc 0.9300 TestAcc 0.8776 0.9200
epoch 1100 LossPred 0.2030 LossAtt 0.4282 TrainAcc 0.9400 TestAcc 0.8869 0.9300
epoch 1200 LossPred 0.2229 LossAtt 0.4450 TrainAcc 0.9000 TestAcc 0.8739 0.9050
epoch 1300 LossPred 0.1731 LossAtt 0.4229 TrainAcc 0.9400 TestAcc 0.8846 0.9400
epoch 1400 LossPred 0.2401 LossAtt 0.4283 TrainAcc 0.9200 TestAcc 0.8629 0.9050
epoch 1500 LossPred 0.1538 LossAtt 0.4425 TrainAcc 0.9500 TestAcc 0.8919 0.9450
epoch 1600 LossPred 0.1767 LossAtt 0.4171 TrainAcc 0.9300 TestAcc 0.8866 0.9450
epoch 1700 LossPred 0.1411 LossAtt 0.4100 TrainAcc 0.9500 TestAcc 0.8936 0.9500
epoch 1800 LossPred 0.1821 LossAtt 0.4194 TrainAcc 0.9400 TestAcc 0.8774 0.9350
epoch 1900 LossPred 0.2261 LossAtt 0.3977 TrainAcc 0.9200 TestAcc 0.8709 0.9050
epoch 2000 LossPred 0.1392 LossAtt 0.3982 TrainAcc 0.9500 TestAcc 0.8931 0.9500
epoch 2100 LossPred 0.2187 LossAtt 0.4012 TrainAcc 0.9200 TestAcc 0.8729 0.9150
epoch 2200 LossPred 0.2788 LossAtt 0.4006 TrainAcc 0.9000 TestAcc 0.8546 0.9050
epoch 2300 LossPred 0.1217 LossAtt 0.3918 TrainAcc 0.9700 TestAcc 0.8956 0.9600
epoch 2400 LossPred 0.1994 LossAtt 0.3915 TrainAcc 0.9300 TestAcc 0.8689 0.9300
epoch 2500 LossPred 0.1649 LossAtt 0.3834 TrainAcc 0.9400 TestAcc 0.8836 0.9400
Optimization Finished!
********** replication  37  **********
epoch   0 LossPred 1.1243 LossAtt 1.0115 TrainAcc 0.4800 TestAcc 0.5098 0.4800
epoch 100 LossPred 0.9398 LossAtt 0.4048 TrainAcc 0.5900 TestAcc 0.5913 0.5950
epoch 200 LossPred 0.8586 LossAtt 0.4179 TrainAcc 0.7100 TestAcc 0.6486 0.6950
epoch 300 LossPred 0.5720 LossAtt 0.4219 TrainAcc 0.8300 TestAcc 0.7775 0.7950
epoch 400 LossPred 0.5562 LossAtt 0.3630 TrainAcc 0.8100 TestAcc 0.7630 0.8000
epoch 500 LossPred 0.5477 LossAtt 0.3577 TrainAcc 0.8200 TestAcc 0.7675 0.8050
epoch 600 LossPred 0.5519 LossAtt 0.3399 TrainAcc 0.8300 TestAcc 0.7870 0.8150
epoch 700 LossPred 0.5441 LossAtt 0.3386 TrainAcc 0.8100 TestAcc 0.7583 0.8050
epoch 800 LossPred 0.5430 LossAtt 0.3469 TrainAcc 0.8100 TestAcc 0.7665 0.7950
epoch 900 LossPred 0.5418 LossAtt 0.3547 TrainAcc 0.8300 TestAcc 0.7650 0.8000
epoch 1000 LossPred 0.5411 LossAtt 0.3370 TrainAcc 0.8300 TestAcc 0.7665 0.8050
epoch 1100 LossPred 0.5404 LossAtt 0.3789 TrainAcc 0.8300 TestAcc 0.7625 0.8150
epoch 1200 LossPred 0.5401 LossAtt 0.3470 TrainAcc 0.8300 TestAcc 0.7658 0.8050
epoch 1300 LossPred 0.5395 LossAtt 0.3571 TrainAcc 0.8200 TestAcc 0.7640 0.8050
epoch 1400 LossPred 0.5390 LossAtt 0.3510 TrainAcc 0.8000 TestAcc 0.7618 0.7900
epoch 1500 LossPred 0.5405 LossAtt 0.3742 TrainAcc 0.8200 TestAcc 0.7335 0.8250
epoch 1600 LossPred 0.4872 LossAtt 0.3677 TrainAcc 0.8500 TestAcc 0.7668 0.8000
epoch 1700 LossPred 0.4683 LossAtt 0.3634 TrainAcc 0.8500 TestAcc 0.7705 0.8250
epoch 1800 LossPred 0.4578 LossAtt 0.3752 TrainAcc 0.8500 TestAcc 0.7725 0.8450
epoch 1900 LossPred 0.5057 LossAtt 0.3392 TrainAcc 0.8400 TestAcc 0.7763 0.8350
epoch 2000 LossPred 0.4547 LossAtt 0.3548 TrainAcc 0.8600 TestAcc 0.7683 0.8400
epoch 2100 LossPred 0.4710 LossAtt 0.3556 TrainAcc 0.8600 TestAcc 0.7773 0.8450
epoch 2200 LossPred 0.4526 LossAtt 0.3492 TrainAcc 0.8700 TestAcc 0.7675 0.8350
epoch 2300 LossPred 0.4508 LossAtt 0.3342 TrainAcc 0.8600 TestAcc 0.7808 0.8400
epoch 2400 LossPred 0.4510 LossAtt 0.3393 TrainAcc 0.8500 TestAcc 0.7805 0.8350
epoch 2500 LossPred 0.4609 LossAtt 0.3394 TrainAcc 0.8600 TestAcc 0.7673 0.8400
Optimization Finished!
********** replication  38  **********
epoch   0 LossPred 1.1416 LossAtt 1.0108 TrainAcc 0.4800 TestAcc 0.5323 0.4950
epoch 100 LossPred 0.9101 LossAtt 0.3205 TrainAcc 0.6600 TestAcc 0.5818 0.6600
epoch 200 LossPred 0.9021 LossAtt 0.2905 TrainAcc 0.6600 TestAcc 0.5818 0.6600
epoch 300 LossPred 0.8997 LossAtt 0.1819 TrainAcc 0.6600 TestAcc 0.5818 0.6600
epoch 400 LossPred 0.8964 LossAtt 0.1636 TrainAcc 0.6600 TestAcc 0.5818 0.6600
epoch 500 LossPred 0.8903 LossAtt 0.1647 TrainAcc 0.6600 TestAcc 0.5818 0.6600
epoch 600 LossPred 0.8747 LossAtt 0.1661 TrainAcc 0.6600 TestAcc 0.5818 0.6800
epoch 700 LossPred 0.8016 LossAtt 0.2668 TrainAcc 0.7000 TestAcc 0.6429 0.6900
epoch 800 LossPred 0.6500 LossAtt 0.2433 TrainAcc 0.7700 TestAcc 0.7425 0.7650
epoch 900 LossPred 0.3516 LossAtt 0.2569 TrainAcc 0.9000 TestAcc 0.8786 0.8850
epoch 1000 LossPred 0.3889 LossAtt 0.2576 TrainAcc 0.8700 TestAcc 0.8724 0.8550
epoch 1100 LossPred 0.4039 LossAtt 0.2490 TrainAcc 0.8600 TestAcc 0.8584 0.8400
epoch 1200 LossPred 0.4035 LossAtt 0.2444 TrainAcc 0.8600 TestAcc 0.8801 0.8550
epoch 1300 LossPred 0.5550 LossAtt 0.2659 TrainAcc 0.8300 TestAcc 0.7833 0.8250
epoch 1400 LossPred 0.2948 LossAtt 0.2519 TrainAcc 0.9200 TestAcc 0.8674 0.8750
epoch 1500 LossPred 0.2704 LossAtt 0.2767 TrainAcc 0.9200 TestAcc 0.9009 0.8900
epoch 1600 LossPred 0.2444 LossAtt 0.2720 TrainAcc 0.9400 TestAcc 0.8874 0.8950
epoch 1700 LossPred 0.3410 LossAtt 0.2745 TrainAcc 0.8900 TestAcc 0.8596 0.8850
epoch 1800 LossPred 0.2989 LossAtt 0.2638 TrainAcc 0.9200 TestAcc 0.8774 0.8650
epoch 1900 LossPred 0.6348 LossAtt 0.2838 TrainAcc 0.8100 TestAcc 0.7310 0.7750
epoch 2000 LossPred 0.3644 LossAtt 0.2773 TrainAcc 0.8900 TestAcc 0.8574 0.8650
epoch 2100 LossPred 0.4355 LossAtt 0.2520 TrainAcc 0.8500 TestAcc 0.8241 0.8450
epoch 2200 LossPred 0.3883 LossAtt 0.2734 TrainAcc 0.9000 TestAcc 0.8526 0.8550
epoch 2300 LossPred 0.4066 LossAtt 0.2672 TrainAcc 0.8500 TestAcc 0.8211 0.8200
epoch 2400 LossPred 0.2195 LossAtt 0.2661 TrainAcc 0.9500 TestAcc 0.8876 0.8900
epoch 2500 LossPred 0.3475 LossAtt 0.2780 TrainAcc 0.9000 TestAcc 0.8661 0.8800
Optimization Finished!
********** replication  39  **********
epoch   0 LossPred 1.2267 LossAtt 0.9980 TrainAcc 0.4700 TestAcc 0.4454 0.4600
epoch 100 LossPred 0.9922 LossAtt 0.3320 TrainAcc 0.4800 TestAcc 0.4427 0.5550
epoch 200 LossPred 0.9707 LossAtt 0.3618 TrainAcc 0.6400 TestAcc 0.5285 0.6400
epoch 300 LossPred 0.9097 LossAtt 0.4796 TrainAcc 0.6300 TestAcc 0.5803 0.6200
epoch 400 LossPred 0.3490 LossAtt 0.5087 TrainAcc 0.9000 TestAcc 0.8251 0.8800
epoch 500 LossPred 0.2332 LossAtt 0.4762 TrainAcc 0.9500 TestAcc 0.8624 0.9300
epoch 600 LossPred 0.3098 LossAtt 0.4593 TrainAcc 0.9100 TestAcc 0.8526 0.9000
epoch 700 LossPred 0.3140 LossAtt 0.4459 TrainAcc 0.9100 TestAcc 0.8416 0.8900
epoch 800 LossPred 0.3975 LossAtt 0.4486 TrainAcc 0.8800 TestAcc 0.8363 0.8500
epoch 900 LossPred 0.4965 LossAtt 0.4430 TrainAcc 0.8300 TestAcc 0.8413 0.8600
epoch 1000 LossPred 0.4172 LossAtt 0.4375 TrainAcc 0.8700 TestAcc 0.8581 0.8750
epoch 1100 LossPred 0.3806 LossAtt 0.4232 TrainAcc 0.8800 TestAcc 0.8576 0.8700
epoch 1200 LossPred 0.5084 LossAtt 0.4238 TrainAcc 0.8100 TestAcc 0.7993 0.8000
epoch 1300 LossPred 0.4036 LossAtt 0.4187 TrainAcc 0.8600 TestAcc 0.8328 0.8350
epoch 1400 LossPred 0.3104 LossAtt 0.4335 TrainAcc 0.8900 TestAcc 0.8581 0.8800
epoch 1500 LossPred 0.2694 LossAtt 0.4137 TrainAcc 0.9200 TestAcc 0.8586 0.8900
epoch 1600 LossPred 0.3814 LossAtt 0.4107 TrainAcc 0.8700 TestAcc 0.8231 0.8500
epoch 1700 LossPred 0.2370 LossAtt 0.4102 TrainAcc 0.9300 TestAcc 0.8591 0.9050
epoch 1800 LossPred 0.2266 LossAtt 0.4274 TrainAcc 0.9200 TestAcc 0.8679 0.9100
epoch 1900 LossPred 0.4587 LossAtt 0.4450 TrainAcc 0.8400 TestAcc 0.8463 0.8550
epoch 2000 LossPred 0.2426 LossAtt 0.4282 TrainAcc 0.9200 TestAcc 0.8646 0.8950
epoch 2100 LossPred 0.2477 LossAtt 0.4152 TrainAcc 0.9100 TestAcc 0.8579 0.8800
epoch 2200 LossPred 0.3350 LossAtt 0.4454 TrainAcc 0.8900 TestAcc 0.8308 0.8750
epoch 2300 LossPred 0.3712 LossAtt 0.4251 TrainAcc 0.8700 TestAcc 0.8238 0.8650
epoch 2400 LossPred 0.4159 LossAtt 0.4670 TrainAcc 0.8700 TestAcc 0.8493 0.8650
epoch 2500 LossPred 0.3754 LossAtt 0.4844 TrainAcc 0.8800 TestAcc 0.8481 0.8750
Optimization Finished!
********** replication  40  **********
epoch   0 LossPred 1.1041 LossAtt 1.0185 TrainAcc 0.5900 TestAcc 0.5821 0.5850
epoch 100 LossPred 0.8789 LossAtt 0.3486 TrainAcc 0.6400 TestAcc 0.6251 0.6550
epoch 200 LossPred 0.5524 LossAtt 0.3099 TrainAcc 0.8400 TestAcc 0.8251 0.8100
epoch 300 LossPred 0.8491 LossAtt 0.2853 TrainAcc 0.6000 TestAcc 0.6154 0.6200
epoch 400 LossPred 0.8965 LossAtt 0.2646 TrainAcc 0.5900 TestAcc 0.6141 0.6000
epoch 500 LossPred 0.8710 LossAtt 0.2422 TrainAcc 0.6300 TestAcc 0.6024 0.6300
epoch 600 LossPred 0.8531 LossAtt 0.2410 TrainAcc 0.6800 TestAcc 0.6314 0.6700
epoch 700 LossPred 0.8304 LossAtt 0.2445 TrainAcc 0.6900 TestAcc 0.6324 0.6750
epoch 800 LossPred 0.8419 LossAtt 0.2254 TrainAcc 0.6800 TestAcc 0.6301 0.6700
epoch 900 LossPred 0.8396 LossAtt 0.2137 TrainAcc 0.6800 TestAcc 0.6309 0.6700
epoch 1000 LossPred 0.8224 LossAtt 0.2259 TrainAcc 0.6800 TestAcc 0.6294 0.6700
epoch 1100 LossPred 0.9302 LossAtt 0.2066 TrainAcc 0.6100 TestAcc 0.5968 0.6100
epoch 1200 LossPred 0.8936 LossAtt 0.2104 TrainAcc 0.6400 TestAcc 0.6059 0.6400
epoch 1300 LossPred 0.8356 LossAtt 0.2174 TrainAcc 0.6700 TestAcc 0.6254 0.6700
epoch 1400 LossPred 0.8372 LossAtt 0.2210 TrainAcc 0.6800 TestAcc 0.6274 0.6750
epoch 1500 LossPred 0.8253 LossAtt 0.2211 TrainAcc 0.6800 TestAcc 0.6316 0.6750
epoch 1600 LossPred 0.8173 LossAtt 0.1970 TrainAcc 0.6800 TestAcc 0.6281 0.6750
epoch 1700 LossPred 0.8296 LossAtt 0.2041 TrainAcc 0.6800 TestAcc 0.6264 0.6750
epoch 1800 LossPred 0.8215 LossAtt 0.2112 TrainAcc 0.6800 TestAcc 0.6316 0.6800
epoch 1900 LossPred 0.8182 LossAtt 0.2093 TrainAcc 0.6800 TestAcc 0.6296 0.6800
epoch 2000 LossPred 0.8168 LossAtt 0.2244 TrainAcc 0.6800 TestAcc 0.6316 0.6750
epoch 2100 LossPred 0.8079 LossAtt 0.2294 TrainAcc 0.6800 TestAcc 0.6271 0.6750
epoch 2200 LossPred 0.8072 LossAtt 0.2570 TrainAcc 0.6800 TestAcc 0.6311 0.6750
epoch 2300 LossPred 0.8062 LossAtt 0.2713 TrainAcc 0.6800 TestAcc 0.6259 0.6750
epoch 2400 LossPred 0.7948 LossAtt 0.2344 TrainAcc 0.6800 TestAcc 0.6321 0.6800
epoch 2500 LossPred 0.7766 LossAtt 0.2270 TrainAcc 0.6900 TestAcc 0.6304 0.6750
Optimization Finished!
********** replication  41  **********
epoch   0 LossPred 1.1706 LossAtt 1.0008 TrainAcc 0.5300 TestAcc 0.4895 0.5300
epoch 100 LossPred 0.9691 LossAtt 0.4628 TrainAcc 0.5600 TestAcc 0.5886 0.5600
epoch 200 LossPred 0.9520 LossAtt 0.4500 TrainAcc 0.5600 TestAcc 0.5886 0.5550
epoch 300 LossPred 0.9239 LossAtt 0.4634 TrainAcc 0.5700 TestAcc 0.6064 0.5800
epoch 400 LossPred 0.5430 LossAtt 0.4693 TrainAcc 0.8600 TestAcc 0.8493 0.8550
epoch 500 LossPred 0.5259 LossAtt 0.4498 TrainAcc 0.8000 TestAcc 0.8416 0.8300
epoch 600 LossPred 0.3941 LossAtt 0.4286 TrainAcc 0.8800 TestAcc 0.8676 0.8550
epoch 700 LossPred 0.7097 LossAtt 0.4091 TrainAcc 0.7000 TestAcc 0.7422 0.7100
epoch 800 LossPred 0.3776 LossAtt 0.4287 TrainAcc 0.8600 TestAcc 0.8661 0.8800
epoch 900 LossPred 0.3632 LossAtt 0.4157 TrainAcc 0.8900 TestAcc 0.8504 0.8500
epoch 1000 LossPred 0.4040 LossAtt 0.4019 TrainAcc 0.8400 TestAcc 0.8604 0.8800
epoch 1100 LossPred 0.3487 LossAtt 0.3881 TrainAcc 0.8900 TestAcc 0.8521 0.8750
epoch 1200 LossPred 0.4244 LossAtt 0.3929 TrainAcc 0.8300 TestAcc 0.8453 0.8550
epoch 1300 LossPred 0.3812 LossAtt 0.3991 TrainAcc 0.8900 TestAcc 0.8436 0.8800
epoch 1400 LossPred 0.3874 LossAtt 0.3834 TrainAcc 0.8600 TestAcc 0.8403 0.8450
epoch 1500 LossPred 0.3399 LossAtt 0.3747 TrainAcc 0.8800 TestAcc 0.8546 0.8750
epoch 1600 LossPred 0.3598 LossAtt 0.3702 TrainAcc 0.8800 TestAcc 0.8453 0.8500
epoch 1700 LossPred 0.4381 LossAtt 0.3823 TrainAcc 0.8800 TestAcc 0.8256 0.8550
epoch 1800 LossPred 0.3744 LossAtt 0.3678 TrainAcc 0.8800 TestAcc 0.8391 0.8500
epoch 1900 LossPred 0.3496 LossAtt 0.3698 TrainAcc 0.8800 TestAcc 0.8461 0.8850
epoch 2000 LossPred 0.4680 LossAtt 0.3515 TrainAcc 0.8700 TestAcc 0.8101 0.8600
epoch 2100 LossPred 0.4786 LossAtt 0.3484 TrainAcc 0.8300 TestAcc 0.8346 0.8550
epoch 2200 LossPred 0.3628 LossAtt 0.3627 TrainAcc 0.8700 TestAcc 0.8401 0.8700
epoch 2300 LossPred 0.3472 LossAtt 0.3518 TrainAcc 0.8900 TestAcc 0.8436 0.8750
epoch 2400 LossPred 0.3557 LossAtt 0.3469 TrainAcc 0.8900 TestAcc 0.8473 0.8900
epoch 2500 LossPred 0.3817 LossAtt 0.3506 TrainAcc 0.8900 TestAcc 0.8311 0.8800
Optimization Finished!
********** replication  42  **********
epoch   0 LossPred 1.0266 LossAtt 0.9658 TrainAcc 0.4200 TestAcc 0.4212 0.4250
epoch 100 LossPred 0.9696 LossAtt 0.4715 TrainAcc 0.5800 TestAcc 0.5788 0.5800
epoch 200 LossPred 0.8995 LossAtt 0.4245 TrainAcc 0.6400 TestAcc 0.5733 0.6350
epoch 300 LossPred 1.1088 LossAtt 0.6230 TrainAcc 0.5500 TestAcc 0.5586 0.5450
epoch 400 LossPred 0.4041 LossAtt 0.5347 TrainAcc 0.9100 TestAcc 0.8483 0.8800
epoch 500 LossPred 0.3325 LossAtt 0.4947 TrainAcc 0.8900 TestAcc 0.8596 0.8750
epoch 600 LossPred 0.3112 LossAtt 0.4577 TrainAcc 0.9200 TestAcc 0.8609 0.8700
epoch 700 LossPred 0.2478 LossAtt 0.4475 TrainAcc 0.9400 TestAcc 0.8799 0.9200
epoch 800 LossPred 0.2572 LossAtt 0.4475 TrainAcc 0.9200 TestAcc 0.8774 0.8950
epoch 900 LossPred 0.5268 LossAtt 0.4568 TrainAcc 0.8100 TestAcc 0.8141 0.8050
epoch 1000 LossPred 1.1540 LossAtt 0.4356 TrainAcc 0.6200 TestAcc 0.6441 0.6250
epoch 1100 LossPred 0.3133 LossAtt 0.4267 TrainAcc 0.9000 TestAcc 0.8428 0.8900
epoch 1200 LossPred 0.3519 LossAtt 0.4215 TrainAcc 0.8800 TestAcc 0.8138 0.8550
epoch 1300 LossPred 0.3455 LossAtt 0.4043 TrainAcc 0.8900 TestAcc 0.8631 0.8950
epoch 1400 LossPred 0.3192 LossAtt 0.3990 TrainAcc 0.9000 TestAcc 0.8283 0.9000
epoch 1500 LossPred 0.2587 LossAtt 0.4084 TrainAcc 0.9300 TestAcc 0.8716 0.9050
epoch 1600 LossPred 0.2739 LossAtt 0.4151 TrainAcc 0.9300 TestAcc 0.8666 0.8950
epoch 1700 LossPred 0.2757 LossAtt 0.4240 TrainAcc 0.9100 TestAcc 0.8699 0.8950
epoch 1800 LossPred 0.3291 LossAtt 0.4123 TrainAcc 0.9000 TestAcc 0.8719 0.8950
epoch 1900 LossPred 0.2665 LossAtt 0.4146 TrainAcc 0.9100 TestAcc 0.8841 0.9150
epoch 2000 LossPred 0.3208 LossAtt 0.4485 TrainAcc 0.8900 TestAcc 0.8168 0.8900
epoch 2100 LossPred 0.2956 LossAtt 0.4461 TrainAcc 0.9200 TestAcc 0.8706 0.8900
epoch 2200 LossPred 0.2781 LossAtt 0.4624 TrainAcc 0.9200 TestAcc 0.8584 0.9000
epoch 2300 LossPred 0.2334 LossAtt 0.4580 TrainAcc 0.9300 TestAcc 0.8721 0.9250
epoch 2400 LossPred 0.2828 LossAtt 0.4449 TrainAcc 0.8900 TestAcc 0.8246 0.9000
epoch 2500 LossPred 0.2301 LossAtt 0.4569 TrainAcc 0.9300 TestAcc 0.8656 0.9200
Optimization Finished!
********** replication  43  **********
epoch   0 LossPred 1.0682 LossAtt 1.0324 TrainAcc 0.5300 TestAcc 0.5295 0.5100
epoch 100 LossPred 0.9151 LossAtt 0.5124 TrainAcc 0.5900 TestAcc 0.5090 0.5900
epoch 200 LossPred 0.7906 LossAtt 0.5117 TrainAcc 0.7200 TestAcc 0.5586 0.7050
epoch 300 LossPred 0.3121 LossAtt 0.5647 TrainAcc 0.9200 TestAcc 0.8446 0.8650
epoch 400 LossPred 0.2326 LossAtt 0.5719 TrainAcc 0.9200 TestAcc 0.8514 0.9150
epoch 500 LossPred 0.2352 LossAtt 0.5538 TrainAcc 0.9200 TestAcc 0.8441 0.9150
epoch 600 LossPred 0.2321 LossAtt 0.4653 TrainAcc 0.9200 TestAcc 0.8574 0.9200
epoch 700 LossPred 0.2100 LossAtt 0.4511 TrainAcc 0.9400 TestAcc 0.8488 0.9350
epoch 800 LossPred 0.2091 LossAtt 0.4746 TrainAcc 0.9400 TestAcc 0.8456 0.9300
epoch 900 LossPred 0.2058 LossAtt 0.4351 TrainAcc 0.9400 TestAcc 0.8626 0.9300
epoch 1000 LossPred 0.2027 LossAtt 0.4429 TrainAcc 0.9600 TestAcc 0.8534 0.9400
epoch 1100 LossPred 0.2275 LossAtt 0.4518 TrainAcc 0.9300 TestAcc 0.8719 0.9300
epoch 1200 LossPred 0.2187 LossAtt 0.4279 TrainAcc 0.9200 TestAcc 0.8381 0.9100
epoch 1300 LossPred 0.2346 LossAtt 0.4165 TrainAcc 0.9200 TestAcc 0.8148 0.9150
epoch 1400 LossPred 0.2338 LossAtt 0.4243 TrainAcc 0.9200 TestAcc 0.8366 0.9200
epoch 1500 LossPred 0.2177 LossAtt 0.4151 TrainAcc 0.9400 TestAcc 0.8811 0.9250
epoch 1600 LossPred 0.2236 LossAtt 0.4122 TrainAcc 0.9200 TestAcc 0.8551 0.9200
epoch 1700 LossPred 0.1925 LossAtt 0.4189 TrainAcc 0.9500 TestAcc 0.8601 0.9450
epoch 1800 LossPred 0.1915 LossAtt 0.4250 TrainAcc 0.9600 TestAcc 0.8701 0.9600
epoch 1900 LossPred 0.2050 LossAtt 0.4153 TrainAcc 0.9400 TestAcc 0.8764 0.9400
epoch 2000 LossPred 0.1997 LossAtt 0.3987 TrainAcc 0.9500 TestAcc 0.8504 0.9500
epoch 2100 LossPred 0.2109 LossAtt 0.4004 TrainAcc 0.9200 TestAcc 0.8734 0.9200
epoch 2200 LossPred 0.1827 LossAtt 0.3870 TrainAcc 0.9600 TestAcc 0.8571 0.9600
epoch 2300 LossPred 0.2109 LossAtt 0.3896 TrainAcc 0.9300 TestAcc 0.8809 0.9350
epoch 2400 LossPred 0.3175 LossAtt 0.3751 TrainAcc 0.9100 TestAcc 0.8591 0.9100
epoch 2500 LossPred 0.2504 LossAtt 0.3810 TrainAcc 0.9100 TestAcc 0.8796 0.9150
Optimization Finished!
********** replication  44  **********
epoch   0 LossPred 1.1438 LossAtt 1.0191 TrainAcc 0.5800 TestAcc 0.5440 0.5800
epoch 100 LossPred 0.9790 LossAtt 0.4733 TrainAcc 0.5900 TestAcc 0.5608 0.5850
epoch 200 LossPred 0.9292 LossAtt 0.4640 TrainAcc 0.6200 TestAcc 0.5638 0.6250
epoch 300 LossPred 0.8814 LossAtt 0.5038 TrainAcc 0.6400 TestAcc 0.5838 0.6350
epoch 400 LossPred 0.8608 LossAtt 0.5159 TrainAcc 0.6600 TestAcc 0.5833 0.6500
epoch 500 LossPred 0.8333 LossAtt 0.4869 TrainAcc 0.6700 TestAcc 0.5968 0.6700
epoch 600 LossPred 0.8185 LossAtt 0.4766 TrainAcc 0.6900 TestAcc 0.5746 0.6950
epoch 700 LossPred 0.8100 LossAtt 0.4890 TrainAcc 0.6900 TestAcc 0.5676 0.6850
epoch 800 LossPred 0.8068 LossAtt 0.4553 TrainAcc 0.6900 TestAcc 0.5556 0.6750
epoch 900 LossPred 0.7953 LossAtt 0.4272 TrainAcc 0.7000 TestAcc 0.5621 0.6750
epoch 1000 LossPred 0.7880 LossAtt 0.4082 TrainAcc 0.7300 TestAcc 0.5918 0.7100
epoch 1100 LossPred 0.7577 LossAtt 0.3939 TrainAcc 0.7400 TestAcc 0.6044 0.7400
epoch 1200 LossPred 0.7675 LossAtt 0.3657 TrainAcc 0.7400 TestAcc 0.6081 0.7350
epoch 1300 LossPred 0.7473 LossAtt 0.4045 TrainAcc 0.7400 TestAcc 0.6111 0.7200
epoch 1400 LossPred 0.7492 LossAtt 0.3813 TrainAcc 0.7400 TestAcc 0.5998 0.7350
epoch 1500 LossPred 0.7431 LossAtt 0.3988 TrainAcc 0.7200 TestAcc 0.5966 0.7200
epoch 1600 LossPred 0.7347 LossAtt 0.3777 TrainAcc 0.7300 TestAcc 0.5946 0.7200
epoch 1700 LossPred 0.7452 LossAtt 0.4142 TrainAcc 0.7200 TestAcc 0.5768 0.7100
epoch 1800 LossPred 0.7670 LossAtt 0.3928 TrainAcc 0.7200 TestAcc 0.5726 0.7000
epoch 1900 LossPred 0.7782 LossAtt 0.3836 TrainAcc 0.7100 TestAcc 0.5716 0.7100
epoch 2000 LossPred 0.7799 LossAtt 0.3783 TrainAcc 0.7000 TestAcc 0.5736 0.7200
epoch 2100 LossPred 0.7734 LossAtt 0.3642 TrainAcc 0.7100 TestAcc 0.5741 0.7200
epoch 2200 LossPred 0.7742 LossAtt 0.3399 TrainAcc 0.7200 TestAcc 0.5748 0.7200
epoch 2300 LossPred 0.7712 LossAtt 0.3550 TrainAcc 0.7100 TestAcc 0.5761 0.7250
epoch 2400 LossPred 0.7651 LossAtt 0.3442 TrainAcc 0.7100 TestAcc 0.5828 0.7250
epoch 2500 LossPred 0.7596 LossAtt 0.3688 TrainAcc 0.7100 TestAcc 0.5836 0.7300
Optimization Finished!
********** replication  45  **********
epoch   0 LossPred 1.1799 LossAtt 0.9960 TrainAcc 0.5000 TestAcc 0.5250 0.4900
epoch 100 LossPred 0.9422 LossAtt 0.3991 TrainAcc 0.6000 TestAcc 0.5898 0.6000
epoch 200 LossPred 0.9128 LossAtt 0.3673 TrainAcc 0.6000 TestAcc 0.5898 0.6000
epoch 300 LossPred 0.8254 LossAtt 0.4021 TrainAcc 0.6900 TestAcc 0.6622 0.6600
epoch 400 LossPred 0.6006 LossAtt 0.4025 TrainAcc 0.7800 TestAcc 0.7898 0.7750
epoch 500 LossPred 0.4780 LossAtt 0.3739 TrainAcc 0.8500 TestAcc 0.7968 0.8250
epoch 600 LossPred 0.8237 LossAtt 0.3344 TrainAcc 0.7200 TestAcc 0.6644 0.7300
epoch 700 LossPred 0.6309 LossAtt 0.3268 TrainAcc 0.7900 TestAcc 0.7257 0.7800
epoch 800 LossPred 0.7543 LossAtt 0.3425 TrainAcc 0.7200 TestAcc 0.7107 0.7100
epoch 900 LossPred 0.4891 LossAtt 0.3069 TrainAcc 0.8400 TestAcc 0.7940 0.8400
epoch 1000 LossPred 0.4250 LossAtt 0.3199 TrainAcc 0.8400 TestAcc 0.8381 0.8450
epoch 1100 LossPred 0.6200 LossAtt 0.2854 TrainAcc 0.7900 TestAcc 0.7270 0.8000
epoch 1200 LossPred 0.5385 LossAtt 0.3037 TrainAcc 0.8200 TestAcc 0.8141 0.8050
epoch 1300 LossPred 0.3971 LossAtt 0.3070 TrainAcc 0.8900 TestAcc 0.8106 0.8550
epoch 1400 LossPred 0.4400 LossAtt 0.3023 TrainAcc 0.8500 TestAcc 0.8158 0.8400
epoch 1500 LossPred 0.4158 LossAtt 0.2982 TrainAcc 0.8500 TestAcc 0.8361 0.8450
epoch 1600 LossPred 0.6233 LossAtt 0.2989 TrainAcc 0.7900 TestAcc 0.7332 0.7950
epoch 1700 LossPred 0.4002 LossAtt 0.3033 TrainAcc 0.8800 TestAcc 0.8128 0.8700
epoch 1800 LossPred 0.3987 LossAtt 0.3027 TrainAcc 0.8600 TestAcc 0.8481 0.8650
epoch 1900 LossPred 0.4057 LossAtt 0.2926 TrainAcc 0.8600 TestAcc 0.8073 0.8600
epoch 2000 LossPred 0.4867 LossAtt 0.3218 TrainAcc 0.8200 TestAcc 0.7800 0.8400
epoch 2100 LossPred 0.3997 LossAtt 0.3051 TrainAcc 0.8700 TestAcc 0.8051 0.8600
epoch 2200 LossPred 0.3700 LossAtt 0.3270 TrainAcc 0.8800 TestAcc 0.8549 0.8600
epoch 2300 LossPred 0.3406 LossAtt 0.3178 TrainAcc 0.8900 TestAcc 0.8504 0.8800
epoch 2400 LossPred 0.3573 LossAtt 0.3084 TrainAcc 0.8900 TestAcc 0.8391 0.8650
epoch 2500 LossPred 0.2969 LossAtt 0.3183 TrainAcc 0.8900 TestAcc 0.8604 0.8700
Optimization Finished!
********** replication  46  **********
epoch   0 LossPred 1.1341 LossAtt 1.0341 TrainAcc 0.4100 TestAcc 0.4907 0.4000
epoch 100 LossPred 0.8996 LossAtt 0.3867 TrainAcc 0.6800 TestAcc 0.5791 0.6750
epoch 200 LossPred 0.8614 LossAtt 0.3080 TrainAcc 0.6800 TestAcc 0.5791 0.6800
epoch 300 LossPred 0.8655 LossAtt 0.1887 TrainAcc 0.6800 TestAcc 0.5791 0.6750
epoch 400 LossPred 0.8465 LossAtt 0.2116 TrainAcc 0.6800 TestAcc 0.5791 0.6650
epoch 500 LossPred 0.3788 LossAtt 0.2434 TrainAcc 0.8800 TestAcc 0.7960 0.8950
epoch 600 LossPred 0.3279 LossAtt 0.2332 TrainAcc 0.8900 TestAcc 0.7935 0.8750
epoch 700 LossPred 0.3217 LossAtt 0.2357 TrainAcc 0.8900 TestAcc 0.7938 0.8750
epoch 800 LossPred 0.3139 LossAtt 0.2373 TrainAcc 0.8900 TestAcc 0.7910 0.8750
epoch 900 LossPred 0.3173 LossAtt 0.2271 TrainAcc 0.8900 TestAcc 0.7938 0.8750
epoch 1000 LossPred 0.3162 LossAtt 0.2361 TrainAcc 0.9000 TestAcc 0.7933 0.8800
epoch 1100 LossPred 0.2948 LossAtt 0.2289 TrainAcc 0.8900 TestAcc 0.7938 0.8700
epoch 1200 LossPred 0.2797 LossAtt 0.2281 TrainAcc 0.9000 TestAcc 0.8018 0.8900
epoch 1300 LossPred 0.3112 LossAtt 0.2230 TrainAcc 0.8900 TestAcc 0.7865 0.8800
epoch 1400 LossPred 0.2846 LossAtt 0.2418 TrainAcc 0.8900 TestAcc 0.8008 0.8850
epoch 1500 LossPred 0.2554 LossAtt 0.2330 TrainAcc 0.9100 TestAcc 0.8021 0.8900
epoch 1600 LossPred 0.2629 LossAtt 0.2321 TrainAcc 0.9300 TestAcc 0.8201 0.9000
epoch 1700 LossPred 0.2516 LossAtt 0.2321 TrainAcc 0.9300 TestAcc 0.8206 0.9000
epoch 1800 LossPred 0.2406 LossAtt 0.2246 TrainAcc 0.9200 TestAcc 0.8161 0.9000
epoch 1900 LossPred 0.2860 LossAtt 0.2337 TrainAcc 0.9000 TestAcc 0.8306 0.9100
epoch 2000 LossPred 0.2245 LossAtt 0.2468 TrainAcc 0.9200 TestAcc 0.8133 0.8950
epoch 2100 LossPred 0.2177 LossAtt 0.2431 TrainAcc 0.9300 TestAcc 0.8313 0.9150
epoch 2200 LossPred 0.1905 LossAtt 0.2392 TrainAcc 0.9400 TestAcc 0.8231 0.9050
epoch 2300 LossPred 0.2506 LossAtt 0.2481 TrainAcc 0.9100 TestAcc 0.8058 0.9050
epoch 2400 LossPred 0.3131 LossAtt 0.2646 TrainAcc 0.8800 TestAcc 0.7750 0.8750
epoch 2500 LossPred 0.2703 LossAtt 0.2770 TrainAcc 0.9000 TestAcc 0.8041 0.9000
Optimization Finished!
********** replication  47  **********
epoch   0 LossPred 1.2017 LossAtt 1.0098 TrainAcc 0.3800 TestAcc 0.4530 0.3750
epoch 100 LossPred 0.9425 LossAtt 0.3029 TrainAcc 0.6000 TestAcc 0.5058 0.6100
epoch 200 LossPred 0.9300 LossAtt 0.2293 TrainAcc 0.6200 TestAcc 0.5148 0.6000
epoch 300 LossPred 0.9276 LossAtt 0.2873 TrainAcc 0.6200 TestAcc 0.5148 0.6100
epoch 400 LossPred 0.9250 LossAtt 0.2909 TrainAcc 0.6300 TestAcc 0.5691 0.6200
epoch 500 LossPred 0.9237 LossAtt 0.2568 TrainAcc 0.6300 TestAcc 0.5691 0.6300
epoch 600 LossPred 0.9236 LossAtt 0.2606 TrainAcc 0.6200 TestAcc 0.5255 0.6250
epoch 700 LossPred 0.9236 LossAtt 0.2420 TrainAcc 0.6200 TestAcc 0.5248 0.6250
epoch 800 LossPred 0.9230 LossAtt 0.2180 TrainAcc 0.6500 TestAcc 0.5380 0.6350
epoch 900 LossPred 0.9254 LossAtt 0.2028 TrainAcc 0.6200 TestAcc 0.5233 0.6300
epoch 1000 LossPred 0.9254 LossAtt 0.1855 TrainAcc 0.6300 TestAcc 0.5691 0.6300
epoch 1100 LossPred 0.9244 LossAtt 0.1425 TrainAcc 0.6300 TestAcc 0.5691 0.6300
epoch 1200 LossPred 0.9236 LossAtt 0.1293 TrainAcc 0.6300 TestAcc 0.5691 0.6300
epoch 1300 LossPred 0.9231 LossAtt 0.1098 TrainAcc 0.6300 TestAcc 0.5691 0.6300
epoch 1400 LossPred 0.9228 LossAtt 0.1015 TrainAcc 0.6300 TestAcc 0.5691 0.6300
epoch 1500 LossPred 0.9226 LossAtt 0.1007 TrainAcc 0.6300 TestAcc 0.5691 0.6300
epoch 1600 LossPred 0.9225 LossAtt 0.1002 TrainAcc 0.6300 TestAcc 0.5691 0.6300
epoch 1700 LossPred 0.9224 LossAtt 0.0889 TrainAcc 0.6300 TestAcc 0.5691 0.6300
epoch 1800 LossPred 0.9224 LossAtt 0.0981 TrainAcc 0.6300 TestAcc 0.5691 0.6300
epoch 1900 LossPred 0.9223 LossAtt 0.1006 TrainAcc 0.6300 TestAcc 0.5691 0.6300
epoch 2000 LossPred 0.9223 LossAtt 0.1058 TrainAcc 0.6300 TestAcc 0.5691 0.6300
epoch 2100 LossPred 0.9223 LossAtt 0.1029 TrainAcc 0.6300 TestAcc 0.5691 0.6300
epoch 2200 LossPred 0.9223 LossAtt 0.1057 TrainAcc 0.6300 TestAcc 0.5691 0.6300
epoch 2300 LossPred 0.9223 LossAtt 0.0893 TrainAcc 0.6300 TestAcc 0.5691 0.6300
epoch 2400 LossPred 0.9223 LossAtt 0.1014 TrainAcc 0.6300 TestAcc 0.5691 0.6300
epoch 2500 LossPred 0.9222 LossAtt 0.1062 TrainAcc 0.6300 TestAcc 0.5691 0.6300
Optimization Finished!
********** replication  48  **********
epoch   0 LossPred 1.1474 LossAtt 1.0065 TrainAcc 0.4800 TestAcc 0.5473 0.4750
epoch 100 LossPred 0.9618 LossAtt 0.4969 TrainAcc 0.5900 TestAcc 0.5723 0.5850
epoch 200 LossPred 0.9429 LossAtt 0.4767 TrainAcc 0.5900 TestAcc 0.5781 0.6200
epoch 300 LossPred 0.9130 LossAtt 0.4565 TrainAcc 0.6400 TestAcc 0.5968 0.6450
epoch 400 LossPred 0.8915 LossAtt 0.4359 TrainAcc 0.6500 TestAcc 0.5943 0.6450
epoch 500 LossPred 0.8739 LossAtt 0.3957 TrainAcc 0.6700 TestAcc 0.5831 0.6300
epoch 600 LossPred 0.8532 LossAtt 0.4494 TrainAcc 0.6900 TestAcc 0.5801 0.6500
epoch 700 LossPred 0.8377 LossAtt 0.4040 TrainAcc 0.7000 TestAcc 0.5826 0.6650
epoch 800 LossPred 0.8291 LossAtt 0.3791 TrainAcc 0.7100 TestAcc 0.5846 0.6850
epoch 900 LossPred 0.8226 LossAtt 0.4053 TrainAcc 0.7100 TestAcc 0.5853 0.7150
epoch 1000 LossPred 0.8245 LossAtt 0.3739 TrainAcc 0.7100 TestAcc 0.5838 0.6850
epoch 1100 LossPred 0.8512 LossAtt 0.3691 TrainAcc 0.7100 TestAcc 0.5851 0.6950
epoch 1200 LossPred 0.8321 LossAtt 0.4047 TrainAcc 0.7000 TestAcc 0.5896 0.6950
epoch 1300 LossPred 0.8178 LossAtt 0.3757 TrainAcc 0.6900 TestAcc 0.5901 0.7050
epoch 1400 LossPred 0.8308 LossAtt 0.3971 TrainAcc 0.6800 TestAcc 0.5878 0.6950
epoch 1500 LossPred 0.8092 LossAtt 0.3766 TrainAcc 0.6900 TestAcc 0.5903 0.7000
epoch 1600 LossPred 0.7993 LossAtt 0.3999 TrainAcc 0.7200 TestAcc 0.5883 0.7050
epoch 1700 LossPred 0.7942 LossAtt 0.3465 TrainAcc 0.7200 TestAcc 0.5851 0.7200
epoch 1800 LossPred 0.7892 LossAtt 0.3493 TrainAcc 0.7200 TestAcc 0.5866 0.7100
epoch 1900 LossPred 0.7885 LossAtt 0.3374 TrainAcc 0.7000 TestAcc 0.5916 0.7100
epoch 2000 LossPred 0.7825 LossAtt 0.3347 TrainAcc 0.7200 TestAcc 0.5856 0.7350
epoch 2100 LossPred 0.7777 LossAtt 0.3585 TrainAcc 0.6900 TestAcc 0.5643 0.6750
epoch 2200 LossPred 0.7713 LossAtt 0.3491 TrainAcc 0.7400 TestAcc 0.5863 0.7400
epoch 2300 LossPred 0.7641 LossAtt 0.3230 TrainAcc 0.7400 TestAcc 0.5898 0.7250
epoch 2400 LossPred 0.7657 LossAtt 0.3578 TrainAcc 0.7300 TestAcc 0.5808 0.7100
epoch 2500 LossPred 0.7713 LossAtt 0.3358 TrainAcc 0.7300 TestAcc 0.5818 0.6650
Optimization Finished!
********** replication  49  **********
epoch   0 LossPred 1.1841 LossAtt 1.0142 TrainAcc 0.3800 TestAcc 0.4612 0.3750
epoch 100 LossPred 0.8721 LossAtt 0.4172 TrainAcc 0.6900 TestAcc 0.5868 0.6900
epoch 200 LossPred 0.8492 LossAtt 0.2171 TrainAcc 0.6900 TestAcc 0.5868 0.6900
epoch 300 LossPred 0.8441 LossAtt 0.1645 TrainAcc 0.6900 TestAcc 0.5868 0.6900
epoch 400 LossPred 0.8403 LossAtt 0.1668 TrainAcc 0.6900 TestAcc 0.5868 0.6900
epoch 500 LossPred 0.8371 LossAtt 0.1796 TrainAcc 0.6900 TestAcc 0.5868 0.6900
epoch 600 LossPred 0.8172 LossAtt 0.2566 TrainAcc 0.6500 TestAcc 0.6146 0.6800
epoch 700 LossPred 0.6311 LossAtt 0.3292 TrainAcc 0.7800 TestAcc 0.8088 0.7650
epoch 800 LossPred 0.6968 LossAtt 0.3714 TrainAcc 0.7200 TestAcc 0.6929 0.6900
epoch 900 LossPred 0.7310 LossAtt 0.3600 TrainAcc 0.7400 TestAcc 0.6874 0.7100
epoch 1000 LossPred 0.6829 LossAtt 0.3770 TrainAcc 0.7500 TestAcc 0.6924 0.7350
epoch 1100 LossPred 0.5935 LossAtt 0.3709 TrainAcc 0.7700 TestAcc 0.7640 0.7400
epoch 1200 LossPred 0.6605 LossAtt 0.3736 TrainAcc 0.7500 TestAcc 0.7390 0.7600
epoch 1300 LossPred 0.5620 LossAtt 0.3831 TrainAcc 0.7900 TestAcc 0.7735 0.7800
epoch 1400 LossPred 0.6253 LossAtt 0.3709 TrainAcc 0.7600 TestAcc 0.7988 0.7700
epoch 1500 LossPred 0.6968 LossAtt 0.3397 TrainAcc 0.7400 TestAcc 0.7015 0.7400
epoch 1600 LossPred 0.5681 LossAtt 0.3506 TrainAcc 0.7900 TestAcc 0.7668 0.7750
epoch 1700 LossPred 0.6919 LossAtt 0.3273 TrainAcc 0.7400 TestAcc 0.7020 0.7350
epoch 1800 LossPred 0.6177 LossAtt 0.3330 TrainAcc 0.7900 TestAcc 0.7645 0.7800
epoch 1900 LossPred 0.7057 LossAtt 0.3446 TrainAcc 0.7300 TestAcc 0.7052 0.7150
epoch 2000 LossPred 0.5309 LossAtt 0.3692 TrainAcc 0.8100 TestAcc 0.7875 0.8000
epoch 2100 LossPred 0.5252 LossAtt 0.3509 TrainAcc 0.8100 TestAcc 0.7868 0.8000
epoch 2200 LossPred 0.6344 LossAtt 0.3585 TrainAcc 0.7400 TestAcc 0.7885 0.7700
epoch 2300 LossPred 0.8814 LossAtt 0.3374 TrainAcc 0.6600 TestAcc 0.6602 0.6600
epoch 2400 LossPred 0.9359 LossAtt 0.3318 TrainAcc 0.6200 TestAcc 0.5888 0.6150
epoch 2500 LossPred 0.6917 LossAtt 0.3439 TrainAcc 0.7400 TestAcc 0.6582 0.7300
Optimization Finished!
********** replication  50  **********
epoch   0 LossPred 1.0088 LossAtt 0.9994 TrainAcc 0.5400 TestAcc 0.5495 0.5450
epoch 100 LossPred 0.9355 LossAtt 0.3882 TrainAcc 0.6100 TestAcc 0.5823 0.6100
epoch 200 LossPred 0.9105 LossAtt 0.4018 TrainAcc 0.6100 TestAcc 0.5823 0.6250
epoch 300 LossPred 0.8912 LossAtt 0.3973 TrainAcc 0.6100 TestAcc 0.5418 0.6000
epoch 400 LossPred 0.8866 LossAtt 0.3907 TrainAcc 0.6300 TestAcc 0.5448 0.6200
epoch 500 LossPred 0.8756 LossAtt 0.4195 TrainAcc 0.6300 TestAcc 0.5433 0.6350
epoch 600 LossPred 0.8687 LossAtt 0.4309 TrainAcc 0.6300 TestAcc 0.5453 0.6150
epoch 700 LossPred 0.8612 LossAtt 0.4290 TrainAcc 0.6400 TestAcc 0.5470 0.6250
epoch 800 LossPred 0.8550 LossAtt 0.4189 TrainAcc 0.6200 TestAcc 0.5475 0.6100
epoch 900 LossPred 0.8511 LossAtt 0.4245 TrainAcc 0.6200 TestAcc 0.5458 0.6150
epoch 1000 LossPred 0.8464 LossAtt 0.4384 TrainAcc 0.6200 TestAcc 0.5438 0.6050
epoch 1100 LossPred 0.8330 LossAtt 0.4424 TrainAcc 0.6800 TestAcc 0.5796 0.6550
epoch 1200 LossPred 0.8209 LossAtt 0.4159 TrainAcc 0.6900 TestAcc 0.5771 0.6600
epoch 1300 LossPred 0.8279 LossAtt 0.4442 TrainAcc 0.6700 TestAcc 0.5658 0.6450
epoch 1400 LossPred 0.8186 LossAtt 0.4189 TrainAcc 0.6300 TestAcc 0.5658 0.6450
epoch 1500 LossPred 0.8030 LossAtt 0.4078 TrainAcc 0.6700 TestAcc 0.5596 0.6950
epoch 1600 LossPred 0.7942 LossAtt 0.4019 TrainAcc 0.7200 TestAcc 0.5671 0.6900
epoch 1700 LossPred 0.7751 LossAtt 0.4154 TrainAcc 0.7000 TestAcc 0.5771 0.6850
epoch 1800 LossPred 0.7790 LossAtt 0.5059 TrainAcc 0.6800 TestAcc 0.5971 0.7000
epoch 1900 LossPred 0.7595 LossAtt 0.4015 TrainAcc 0.7100 TestAcc 0.6159 0.6900
epoch 2000 LossPred 0.6944 LossAtt 0.3858 TrainAcc 0.7400 TestAcc 0.6496 0.7350
epoch 2100 LossPred 0.4959 LossAtt 0.4656 TrainAcc 0.8200 TestAcc 0.7045 0.8000
epoch 2200 LossPred 0.4170 LossAtt 0.4551 TrainAcc 0.9000 TestAcc 0.6997 0.8350
epoch 2300 LossPred 0.4263 LossAtt 0.4182 TrainAcc 0.8700 TestAcc 0.7385 0.8700
epoch 2400 LossPred 0.4778 LossAtt 0.4074 TrainAcc 0.8500 TestAcc 0.7387 0.8650
epoch 2500 LossPred 0.4072 LossAtt 0.4054 TrainAcc 0.9000 TestAcc 0.7095 0.8750
Optimization Finished!
********** replication  51  **********
epoch   0 LossPred 1.1366 LossAtt 1.0102 TrainAcc 0.4600 TestAcc 0.4520 0.4750
epoch 100 LossPred 0.9733 LossAtt 0.5283 TrainAcc 0.5200 TestAcc 0.4642 0.5400
epoch 200 LossPred 0.9433 LossAtt 0.4588 TrainAcc 0.6100 TestAcc 0.5756 0.6100
epoch 300 LossPred 0.9311 LossAtt 0.3791 TrainAcc 0.5800 TestAcc 0.5485 0.5900
epoch 400 LossPred 0.9315 LossAtt 0.3487 TrainAcc 0.6000 TestAcc 0.5768 0.6100
epoch 500 LossPred 0.9364 LossAtt 0.3212 TrainAcc 0.6000 TestAcc 0.5758 0.5900
epoch 600 LossPred 0.9291 LossAtt 0.3498 TrainAcc 0.6100 TestAcc 0.5783 0.6050
epoch 700 LossPred 0.9184 LossAtt 0.3595 TrainAcc 0.6000 TestAcc 0.5828 0.6150
epoch 800 LossPred 0.9103 LossAtt 0.3674 TrainAcc 0.6500 TestAcc 0.6011 0.5900
epoch 900 LossPred 0.9032 LossAtt 0.3700 TrainAcc 0.6100 TestAcc 0.5831 0.6200
epoch 1000 LossPred 0.8941 LossAtt 0.4074 TrainAcc 0.6100 TestAcc 0.5833 0.6300
epoch 1100 LossPred 0.8790 LossAtt 0.4251 TrainAcc 0.6600 TestAcc 0.6081 0.6350
epoch 1200 LossPred 0.7823 LossAtt 0.6587 TrainAcc 0.7100 TestAcc 0.6431 0.7000
epoch 1300 LossPred 0.6318 LossAtt 0.6428 TrainAcc 0.8000 TestAcc 0.6874 0.7650
epoch 1400 LossPred 0.4869 LossAtt 0.6213 TrainAcc 0.8500 TestAcc 0.7795 0.8500
epoch 1500 LossPred 0.3985 LossAtt 0.5279 TrainAcc 0.8600 TestAcc 0.8198 0.8600
epoch 1600 LossPred 0.4097 LossAtt 0.4532 TrainAcc 0.8500 TestAcc 0.8301 0.8750
epoch 1700 LossPred 0.4084 LossAtt 0.4539 TrainAcc 0.8800 TestAcc 0.8211 0.8650
epoch 1800 LossPred 0.4661 LossAtt 0.4558 TrainAcc 0.8500 TestAcc 0.7905 0.8550
epoch 1900 LossPred 0.2703 LossAtt 0.4519 TrainAcc 0.9100 TestAcc 0.8216 0.8850
epoch 2000 LossPred 0.2715 LossAtt 0.4412 TrainAcc 0.9100 TestAcc 0.8298 0.8800
epoch 2100 LossPred 0.3061 LossAtt 0.4733 TrainAcc 0.9000 TestAcc 0.8438 0.9150
epoch 2200 LossPred 0.3185 LossAtt 0.4614 TrainAcc 0.9000 TestAcc 0.8438 0.8950
epoch 2300 LossPred 0.2972 LossAtt 0.4599 TrainAcc 0.9000 TestAcc 0.8433 0.8900
epoch 2400 LossPred 0.2784 LossAtt 0.4619 TrainAcc 0.9100 TestAcc 0.8443 0.8900
epoch 2500 LossPred 0.3266 LossAtt 0.4410 TrainAcc 0.8800 TestAcc 0.8056 0.8500
Optimization Finished!
********** replication  52  **********
epoch   0 LossPred 0.9622 LossAtt 1.0167 TrainAcc 0.6100 TestAcc 0.5616 0.5800
epoch 100 LossPred 0.9060 LossAtt 0.4118 TrainAcc 0.6500 TestAcc 0.5926 0.6500
epoch 200 LossPred 0.8980 LossAtt 0.3381 TrainAcc 0.6500 TestAcc 0.5926 0.6500
epoch 300 LossPred 0.8976 LossAtt 0.3539 TrainAcc 0.6500 TestAcc 0.5926 0.6500
epoch 400 LossPred 0.9001 LossAtt 0.2966 TrainAcc 0.6500 TestAcc 0.5926 0.6500
epoch 500 LossPred 0.9027 LossAtt 0.2799 TrainAcc 0.6500 TestAcc 0.5926 0.6500
epoch 600 LossPred 0.8148 LossAtt 0.4268 TrainAcc 0.7000 TestAcc 0.6664 0.6950
epoch 700 LossPred 0.4295 LossAtt 0.3800 TrainAcc 0.8700 TestAcc 0.8338 0.8500
epoch 800 LossPred 0.6944 LossAtt 0.3977 TrainAcc 0.7500 TestAcc 0.7392 0.7750
epoch 900 LossPred 0.6172 LossAtt 0.4242 TrainAcc 0.7700 TestAcc 0.7442 0.8000
epoch 1000 LossPred 0.8046 LossAtt 0.3853 TrainAcc 0.6900 TestAcc 0.6877 0.7000
epoch 1100 LossPred 0.7314 LossAtt 0.4051 TrainAcc 0.7400 TestAcc 0.7150 0.7250
epoch 1200 LossPred 0.7642 LossAtt 0.4110 TrainAcc 0.7100 TestAcc 0.6857 0.7050
epoch 1300 LossPred 0.5345 LossAtt 0.4318 TrainAcc 0.8400 TestAcc 0.7973 0.8300
epoch 1400 LossPred 0.7992 LossAtt 0.3946 TrainAcc 0.6900 TestAcc 0.6757 0.6850
epoch 1500 LossPred 0.5535 LossAtt 0.3729 TrainAcc 0.8200 TestAcc 0.7650 0.8000
epoch 1600 LossPred 0.4875 LossAtt 0.3517 TrainAcc 0.8400 TestAcc 0.8191 0.8400
epoch 1700 LossPred 0.4417 LossAtt 0.3315 TrainAcc 0.8600 TestAcc 0.8286 0.8500
epoch 1800 LossPred 0.8817 LossAtt 0.2979 TrainAcc 0.6800 TestAcc 0.6752 0.6950
epoch 1900 LossPred 0.4072 LossAtt 0.3222 TrainAcc 0.8700 TestAcc 0.8278 0.8650
epoch 2000 LossPred 0.4218 LossAtt 0.3564 TrainAcc 0.8500 TestAcc 0.8248 0.8600
epoch 2100 LossPred 0.6012 LossAtt 0.3493 TrainAcc 0.7900 TestAcc 0.7903 0.8150
epoch 2200 LossPred 0.5403 LossAtt 0.3565 TrainAcc 0.8000 TestAcc 0.7953 0.8000
epoch 2300 LossPred 0.5434 LossAtt 0.3524 TrainAcc 0.8100 TestAcc 0.7878 0.8000
epoch 2400 LossPred 0.5399 LossAtt 0.3606 TrainAcc 0.8000 TestAcc 0.7860 0.8050
epoch 2500 LossPred 0.5427 LossAtt 0.3666 TrainAcc 0.8200 TestAcc 0.7973 0.8100
Optimization Finished!
********** replication  53  **********
epoch   0 LossPred 1.1342 LossAtt 1.0005 TrainAcc 0.4100 TestAcc 0.4372 0.4100
epoch 100 LossPred 0.9439 LossAtt 0.4593 TrainAcc 0.6100 TestAcc 0.5891 0.5950
epoch 200 LossPred 0.9190 LossAtt 0.4183 TrainAcc 0.6300 TestAcc 0.5866 0.6300
epoch 300 LossPred 0.9099 LossAtt 0.4279 TrainAcc 0.6300 TestAcc 0.5866 0.6300
epoch 400 LossPred 0.8906 LossAtt 0.4509 TrainAcc 0.6300 TestAcc 0.5866 0.6300
epoch 500 LossPred 0.8664 LossAtt 0.4944 TrainAcc 0.6300 TestAcc 0.5866 0.6350
epoch 600 LossPred 0.8321 LossAtt 0.5120 TrainAcc 0.6300 TestAcc 0.5913 0.6250
epoch 700 LossPred 0.4461 LossAtt 0.5795 TrainAcc 0.8700 TestAcc 0.7970 0.8650
epoch 800 LossPred 0.3060 LossAtt 0.5583 TrainAcc 0.9100 TestAcc 0.8366 0.9000
epoch 900 LossPred 0.3087 LossAtt 0.5306 TrainAcc 0.9000 TestAcc 0.8293 0.8900
epoch 1000 LossPred 0.2626 LossAtt 0.4687 TrainAcc 0.9300 TestAcc 0.8378 0.9250
epoch 1100 LossPred 0.2191 LossAtt 0.4710 TrainAcc 0.9300 TestAcc 0.8151 0.9350
epoch 1200 LossPred 0.2787 LossAtt 0.4603 TrainAcc 0.9200 TestAcc 0.8096 0.9050
epoch 1300 LossPred 0.3072 LossAtt 0.4585 TrainAcc 0.9100 TestAcc 0.8056 0.8850
epoch 1400 LossPred 0.1965 LossAtt 0.4673 TrainAcc 0.9500 TestAcc 0.8303 0.9100
epoch 1500 LossPred 0.1903 LossAtt 0.4416 TrainAcc 0.9500 TestAcc 0.8381 0.9300
epoch 1600 LossPred 0.1871 LossAtt 0.4420 TrainAcc 0.9500 TestAcc 0.8361 0.9250
epoch 1700 LossPred 0.1799 LossAtt 0.4538 TrainAcc 0.9400 TestAcc 0.8476 0.9200
epoch 1800 LossPred 0.1789 LossAtt 0.4235 TrainAcc 0.9400 TestAcc 0.8586 0.9200
epoch 1900 LossPred 0.2017 LossAtt 0.4228 TrainAcc 0.9400 TestAcc 0.8624 0.9200
epoch 2000 LossPred 0.3547 LossAtt 0.4118 TrainAcc 0.8800 TestAcc 0.8046 0.8500
epoch 2100 LossPred 0.1747 LossAtt 0.4140 TrainAcc 0.9500 TestAcc 0.8574 0.9250
epoch 2200 LossPred 0.2099 LossAtt 0.4282 TrainAcc 0.9400 TestAcc 0.8453 0.9050
epoch 2300 LossPred 0.2821 LossAtt 0.4068 TrainAcc 0.9000 TestAcc 0.8308 0.8850
epoch 2400 LossPred 0.1926 LossAtt 0.4130 TrainAcc 0.9400 TestAcc 0.8554 0.8800
epoch 2500 LossPred 0.3251 LossAtt 0.3916 TrainAcc 0.8800 TestAcc 0.8411 0.8450
Optimization Finished!
********** replication  54  **********
epoch   0 LossPred 1.0133 LossAtt 0.9944 TrainAcc 0.5100 TestAcc 0.5373 0.4900
epoch 100 LossPred 0.9390 LossAtt 0.2498 TrainAcc 0.6200 TestAcc 0.5821 0.6200
epoch 200 LossPred 0.9215 LossAtt 0.0895 TrainAcc 0.6200 TestAcc 0.5821 0.6200
epoch 300 LossPred 0.9316 LossAtt 0.0907 TrainAcc 0.6200 TestAcc 0.5821 0.6200
epoch 400 LossPred 0.9457 LossAtt 0.0901 TrainAcc 0.5700 TestAcc 0.5013 0.5700
epoch 500 LossPred 0.9469 LossAtt 0.1135 TrainAcc 0.5700 TestAcc 0.5013 0.5700
epoch 600 LossPred 0.9539 LossAtt 0.1195 TrainAcc 0.5700 TestAcc 0.5013 0.5700
epoch 700 LossPred 0.9678 LossAtt 0.0902 TrainAcc 0.5700 TestAcc 0.5013 0.5700
epoch 800 LossPred 0.9759 LossAtt 0.0986 TrainAcc 0.5700 TestAcc 0.5013 0.5700
epoch 900 LossPred 0.9789 LossAtt 0.0872 TrainAcc 0.5700 TestAcc 0.5013 0.5700
epoch 1000 LossPred 0.9807 LossAtt 0.0651 TrainAcc 0.5700 TestAcc 0.5013 0.5700
epoch 1100 LossPred 0.9800 LossAtt 0.0596 TrainAcc 0.5700 TestAcc 0.5013 0.5700
epoch 1200 LossPred 0.9801 LossAtt 0.0613 TrainAcc 0.5700 TestAcc 0.5013 0.5700
epoch 1300 LossPred 0.9797 LossAtt 0.0802 TrainAcc 0.5700 TestAcc 0.5013 0.5700
epoch 1400 LossPred 0.9798 LossAtt 0.0531 TrainAcc 0.5700 TestAcc 0.5013 0.5700
epoch 1500 LossPred 0.9799 LossAtt 0.0435 TrainAcc 0.5700 TestAcc 0.5013 0.5700
epoch 1600 LossPred 0.9798 LossAtt 0.0666 TrainAcc 0.5700 TestAcc 0.5013 0.5700
epoch 1700 LossPred 0.9799 LossAtt 0.0611 TrainAcc 0.5700 TestAcc 0.5013 0.5700
epoch 1800 LossPred 0.9795 LossAtt 0.0607 TrainAcc 0.5700 TestAcc 0.5013 0.5700
epoch 1900 LossPred 0.9795 LossAtt 0.0498 TrainAcc 0.5700 TestAcc 0.5013 0.5700
epoch 2000 LossPred 0.9801 LossAtt 0.0538 TrainAcc 0.5700 TestAcc 0.5013 0.5700
epoch 2100 LossPred 0.9789 LossAtt 0.0613 TrainAcc 0.5700 TestAcc 0.5013 0.5700
epoch 2200 LossPred 0.9773 LossAtt 0.0540 TrainAcc 0.5700 TestAcc 0.5013 0.5700
epoch 2300 LossPred 0.9723 LossAtt 0.0739 TrainAcc 0.5700 TestAcc 0.5013 0.5700
epoch 2400 LossPred 0.9729 LossAtt 0.0750 TrainAcc 0.5700 TestAcc 0.5013 0.5700
epoch 2500 LossPred 0.9771 LossAtt 0.0637 TrainAcc 0.5700 TestAcc 0.5013 0.5700
Optimization Finished!
********** replication  55  **********
epoch   0 LossPred 1.0876 LossAtt 1.0010 TrainAcc 0.3600 TestAcc 0.4234 0.3600
epoch 100 LossPred 0.9253 LossAtt 0.3384 TrainAcc 0.6400 TestAcc 0.5766 0.6400
epoch 200 LossPred 0.9262 LossAtt 0.1781 TrainAcc 0.6400 TestAcc 0.5766 0.6400
epoch 300 LossPred 0.9260 LossAtt 0.1300 TrainAcc 0.6400 TestAcc 0.5766 0.6400
epoch 400 LossPred 0.9304 LossAtt 0.1168 TrainAcc 0.6400 TestAcc 0.5766 0.6400
epoch 500 LossPred 0.9331 LossAtt 0.1135 TrainAcc 0.6400 TestAcc 0.5766 0.6400
epoch 600 LossPred 0.9490 LossAtt 0.1325 TrainAcc 0.6400 TestAcc 0.5766 0.6400
epoch 700 LossPred 0.9204 LossAtt 0.1441 TrainAcc 0.6400 TestAcc 0.5766 0.6400
epoch 800 LossPred 0.9135 LossAtt 0.1831 TrainAcc 0.6400 TestAcc 0.5766 0.6400
epoch 900 LossPred 0.8561 LossAtt 0.2435 TrainAcc 0.6500 TestAcc 0.6642 0.6750
epoch 1000 LossPred 0.6476 LossAtt 0.2036 TrainAcc 0.7500 TestAcc 0.8258 0.8050
epoch 1100 LossPred 0.7474 LossAtt 0.2012 TrainAcc 0.7500 TestAcc 0.7352 0.7400
epoch 1200 LossPred 0.7180 LossAtt 0.2085 TrainAcc 0.7500 TestAcc 0.7815 0.7250
epoch 1300 LossPred 0.5297 LossAtt 0.2029 TrainAcc 0.8300 TestAcc 0.8276 0.8100
epoch 1400 LossPred 0.5243 LossAtt 0.2100 TrainAcc 0.8300 TestAcc 0.8311 0.8000
epoch 1500 LossPred 0.8429 LossAtt 0.1843 TrainAcc 0.6800 TestAcc 0.7265 0.7250
epoch 1600 LossPred 0.5411 LossAtt 0.1984 TrainAcc 0.8000 TestAcc 0.8323 0.7950
epoch 1700 LossPred 0.6847 LossAtt 0.1988 TrainAcc 0.7500 TestAcc 0.7810 0.7650
epoch 1800 LossPred 0.4904 LossAtt 0.2040 TrainAcc 0.8300 TestAcc 0.8356 0.8200
epoch 1900 LossPred 0.5175 LossAtt 0.2020 TrainAcc 0.8300 TestAcc 0.8263 0.8050
epoch 2000 LossPred 0.6053 LossAtt 0.2059 TrainAcc 0.8000 TestAcc 0.8133 0.8000
epoch 2100 LossPred 0.7396 LossAtt 0.1921 TrainAcc 0.7300 TestAcc 0.7287 0.7400
epoch 2200 LossPred 0.6299 LossAtt 0.1936 TrainAcc 0.7800 TestAcc 0.8128 0.8050
epoch 2300 LossPred 0.6221 LossAtt 0.1938 TrainAcc 0.7900 TestAcc 0.8191 0.8000
epoch 2400 LossPred 0.5159 LossAtt 0.2007 TrainAcc 0.8200 TestAcc 0.8298 0.8200
epoch 2500 LossPred 0.6739 LossAtt 0.2016 TrainAcc 0.7700 TestAcc 0.7955 0.7850
Optimization Finished!
********** replication  56  **********
epoch   0 LossPred 1.0731 LossAtt 1.0114 TrainAcc 0.5400 TestAcc 0.4730 0.5200
epoch 100 LossPred 0.9530 LossAtt 0.2428 TrainAcc 0.5800 TestAcc 0.5013 0.5800
epoch 200 LossPred 0.9530 LossAtt 0.1951 TrainAcc 0.5800 TestAcc 0.5013 0.5800
epoch 300 LossPred 0.9450 LossAtt 0.1623 TrainAcc 0.5800 TestAcc 0.5013 0.5800
epoch 400 LossPred 0.9409 LossAtt 0.1720 TrainAcc 0.5800 TestAcc 0.5013 0.5800
epoch 500 LossPred 0.9392 LossAtt 0.2011 TrainAcc 0.5800 TestAcc 0.5013 0.5800
epoch 600 LossPred 0.9358 LossAtt 0.2420 TrainAcc 0.5900 TestAcc 0.5691 0.5750
epoch 700 LossPred 0.9629 LossAtt 0.3692 TrainAcc 0.6500 TestAcc 0.5871 0.6350
epoch 800 LossPred 0.5715 LossAtt 0.3444 TrainAcc 0.8200 TestAcc 0.7985 0.7900
epoch 900 LossPred 0.5886 LossAtt 0.3420 TrainAcc 0.8200 TestAcc 0.7840 0.7800
epoch 1000 LossPred 0.5637 LossAtt 0.3411 TrainAcc 0.8200 TestAcc 0.8221 0.7800
epoch 1100 LossPred 0.5604 LossAtt 0.3327 TrainAcc 0.7800 TestAcc 0.8298 0.8000
epoch 1200 LossPred 0.5019 LossAtt 0.3291 TrainAcc 0.8300 TestAcc 0.8206 0.8100
epoch 1300 LossPred 0.4519 LossAtt 0.3303 TrainAcc 0.8700 TestAcc 0.8193 0.8050
epoch 1400 LossPred 0.6166 LossAtt 0.3291 TrainAcc 0.7900 TestAcc 0.7447 0.7600
epoch 1500 LossPred 0.4543 LossAtt 0.3279 TrainAcc 0.8400 TestAcc 0.8373 0.8350
epoch 1600 LossPred 0.5790 LossAtt 0.3276 TrainAcc 0.8300 TestAcc 0.8398 0.7900
epoch 1700 LossPred 0.7684 LossAtt 0.3218 TrainAcc 0.7200 TestAcc 0.8013 0.7600
epoch 1800 LossPred 0.4583 LossAtt 0.3261 TrainAcc 0.8300 TestAcc 0.8453 0.8100
epoch 1900 LossPred 0.5341 LossAtt 0.3229 TrainAcc 0.8200 TestAcc 0.8023 0.8000
epoch 2000 LossPred 0.5192 LossAtt 0.3299 TrainAcc 0.8500 TestAcc 0.8471 0.8050
epoch 2100 LossPred 0.4488 LossAtt 0.3022 TrainAcc 0.8400 TestAcc 0.8463 0.8450
epoch 2200 LossPred 0.4622 LossAtt 0.3308 TrainAcc 0.8700 TestAcc 0.8481 0.8200
epoch 2300 LossPred 0.5138 LossAtt 0.3174 TrainAcc 0.7900 TestAcc 0.8226 0.7900
epoch 2400 LossPred 0.4538 LossAtt 0.3158 TrainAcc 0.8400 TestAcc 0.8396 0.8250
epoch 2500 LossPred 0.4145 LossAtt 0.3194 TrainAcc 0.8700 TestAcc 0.8318 0.8200
Optimization Finished!
********** replication  57  **********
epoch   0 LossPred 0.9371 LossAtt 1.0151 TrainAcc 0.6000 TestAcc 0.5546 0.6250
epoch 100 LossPred 0.8738 LossAtt 0.3250 TrainAcc 0.6500 TestAcc 0.5811 0.6500
epoch 200 LossPred 0.7747 LossAtt 0.4548 TrainAcc 0.7200 TestAcc 0.6174 0.7100
epoch 300 LossPred 0.6413 LossAtt 0.3761 TrainAcc 0.7800 TestAcc 0.7120 0.7600
epoch 400 LossPred 0.6731 LossAtt 0.3342 TrainAcc 0.7900 TestAcc 0.7165 0.7700
epoch 500 LossPred 0.6185 LossAtt 0.3200 TrainAcc 0.8000 TestAcc 0.7060 0.7500
epoch 600 LossPred 0.6194 LossAtt 0.3162 TrainAcc 0.7900 TestAcc 0.7097 0.7600
epoch 700 LossPred 0.6028 LossAtt 0.3218 TrainAcc 0.8000 TestAcc 0.7668 0.7850
epoch 800 LossPred 0.5969 LossAtt 0.3163 TrainAcc 0.7900 TestAcc 0.7523 0.7900
epoch 900 LossPred 0.6173 LossAtt 0.3142 TrainAcc 0.8300 TestAcc 0.7002 0.7700
epoch 1000 LossPred 0.5829 LossAtt 0.2961 TrainAcc 0.8000 TestAcc 0.7440 0.7700
epoch 1100 LossPred 0.5347 LossAtt 0.3043 TrainAcc 0.8000 TestAcc 0.7840 0.7850
epoch 1200 LossPred 0.5262 LossAtt 0.2896 TrainAcc 0.7800 TestAcc 0.7778 0.7900
epoch 1300 LossPred 0.6724 LossAtt 0.2815 TrainAcc 0.7200 TestAcc 0.7973 0.8100
epoch 1400 LossPred 0.5756 LossAtt 0.3026 TrainAcc 0.7900 TestAcc 0.8028 0.7850
epoch 1500 LossPred 0.9192 LossAtt 0.2968 TrainAcc 0.6700 TestAcc 0.7437 0.6650
epoch 1600 LossPred 0.6221 LossAtt 0.3067 TrainAcc 0.7900 TestAcc 0.7958 0.7900
epoch 1700 LossPred 0.5879 LossAtt 0.2911 TrainAcc 0.7900 TestAcc 0.7980 0.7800
epoch 1800 LossPred 0.6149 LossAtt 0.2983 TrainAcc 0.7700 TestAcc 0.8073 0.7750
epoch 1900 LossPred 0.6759 LossAtt 0.3133 TrainAcc 0.7400 TestAcc 0.7027 0.7500
epoch 2000 LossPred 0.6077 LossAtt 0.3004 TrainAcc 0.7700 TestAcc 0.7082 0.7650
epoch 2100 LossPred 0.5775 LossAtt 0.2981 TrainAcc 0.7900 TestAcc 0.7307 0.7700
epoch 2200 LossPred 0.5509 LossAtt 0.2905 TrainAcc 0.8000 TestAcc 0.7645 0.7750
epoch 2300 LossPred 0.5485 LossAtt 0.2927 TrainAcc 0.7900 TestAcc 0.7633 0.7750
epoch 2400 LossPred 0.5713 LossAtt 0.2973 TrainAcc 0.8300 TestAcc 0.7177 0.7700
epoch 2500 LossPred 0.5797 LossAtt 0.2905 TrainAcc 0.8000 TestAcc 0.7718 0.7800
Optimization Finished!
********** replication  58  **********
epoch   0 LossPred 0.9655 LossAtt 0.9918 TrainAcc 0.5900 TestAcc 0.5355 0.6050
epoch 100 LossPred 0.9029 LossAtt 0.3995 TrainAcc 0.6700 TestAcc 0.5981 0.6200
epoch 200 LossPred 0.8949 LossAtt 0.3525 TrainAcc 0.6400 TestAcc 0.5748 0.6500
epoch 300 LossPred 0.8790 LossAtt 0.3782 TrainAcc 0.6600 TestAcc 0.5846 0.6750
epoch 400 LossPred 0.7371 LossAtt 0.4740 TrainAcc 0.7100 TestAcc 0.6859 0.7200
epoch 500 LossPred 0.4343 LossAtt 0.4273 TrainAcc 0.8600 TestAcc 0.7973 0.8600
epoch 600 LossPred 0.3141 LossAtt 0.3757 TrainAcc 0.9100 TestAcc 0.8488 0.9100
epoch 700 LossPred 0.3089 LossAtt 0.3736 TrainAcc 0.8900 TestAcc 0.8143 0.9100
epoch 800 LossPred 0.2679 LossAtt 0.3707 TrainAcc 0.9300 TestAcc 0.8041 0.9200
epoch 900 LossPred 0.3092 LossAtt 0.3810 TrainAcc 0.8900 TestAcc 0.7823 0.9000
epoch 1000 LossPred 0.2624 LossAtt 0.3616 TrainAcc 0.9400 TestAcc 0.8473 0.9200
epoch 1100 LossPred 0.2321 LossAtt 0.3754 TrainAcc 0.9200 TestAcc 0.8266 0.9150
epoch 1200 LossPred 0.2877 LossAtt 0.3861 TrainAcc 0.9100 TestAcc 0.7990 0.9000
epoch 1300 LossPred 0.2917 LossAtt 0.3828 TrainAcc 0.9100 TestAcc 0.7948 0.9050
epoch 1400 LossPred 0.2393 LossAtt 0.3662 TrainAcc 0.9400 TestAcc 0.8171 0.9350
epoch 1500 LossPred 0.3036 LossAtt 0.3767 TrainAcc 0.9200 TestAcc 0.8564 0.9100
epoch 1600 LossPred 0.2360 LossAtt 0.3709 TrainAcc 0.9100 TestAcc 0.8321 0.9150
epoch 1700 LossPred 0.2521 LossAtt 0.3790 TrainAcc 0.9200 TestAcc 0.8351 0.9100
epoch 1800 LossPred 0.2587 LossAtt 0.3898 TrainAcc 0.9400 TestAcc 0.8471 0.9200
epoch 1900 LossPred 0.3249 LossAtt 0.3722 TrainAcc 0.9100 TestAcc 0.8589 0.9050
epoch 2000 LossPred 0.2280 LossAtt 0.3519 TrainAcc 0.9400 TestAcc 0.8133 0.9350
epoch 2100 LossPred 0.3210 LossAtt 0.3671 TrainAcc 0.8900 TestAcc 0.7705 0.9000
epoch 2200 LossPred 0.3171 LossAtt 0.3599 TrainAcc 0.9100 TestAcc 0.8023 0.9000
epoch 2300 LossPred 0.2561 LossAtt 0.3619 TrainAcc 0.9300 TestAcc 0.8529 0.9100
epoch 2400 LossPred 0.2513 LossAtt 0.3367 TrainAcc 0.9400 TestAcc 0.8481 0.9100
epoch 2500 LossPred 0.2564 LossAtt 0.3475 TrainAcc 0.9000 TestAcc 0.7968 0.9100
Optimization Finished!
********** replication  59  **********
epoch   0 LossPred 1.3225 LossAtt 1.0022 TrainAcc 0.4500 TestAcc 0.4660 0.4150
epoch 100 LossPred 0.9645 LossAtt 0.3244 TrainAcc 0.6400 TestAcc 0.5796 0.6300
epoch 200 LossPred 0.9100 LossAtt 0.3528 TrainAcc 0.6300 TestAcc 0.5473 0.6300
epoch 300 LossPred 0.9068 LossAtt 0.2830 TrainAcc 0.6300 TestAcc 0.5473 0.6300
epoch 400 LossPred 0.8992 LossAtt 0.2890 TrainAcc 0.6300 TestAcc 0.5473 0.6300
epoch 500 LossPred 0.8763 LossAtt 0.4183 TrainAcc 0.6800 TestAcc 0.5513 0.6550
epoch 600 LossPred 0.8670 LossAtt 0.4429 TrainAcc 0.6500 TestAcc 0.5828 0.6450
epoch 700 LossPred 0.8358 LossAtt 0.5011 TrainAcc 0.6700 TestAcc 0.5958 0.6500
epoch 800 LossPred 0.2995 LossAtt 0.5310 TrainAcc 0.9300 TestAcc 0.8401 0.9300
epoch 900 LossPred 0.2597 LossAtt 0.5291 TrainAcc 0.9300 TestAcc 0.8323 0.9250
epoch 1000 LossPred 0.2190 LossAtt 0.5123 TrainAcc 0.9300 TestAcc 0.8691 0.9300
epoch 1100 LossPred 0.2191 LossAtt 0.4882 TrainAcc 0.9200 TestAcc 0.8659 0.9250
epoch 1200 LossPred 0.1378 LossAtt 0.4873 TrainAcc 0.9700 TestAcc 0.8561 0.9800
epoch 1300 LossPred 0.2346 LossAtt 0.4885 TrainAcc 0.9100 TestAcc 0.8526 0.9050
epoch 1400 LossPred 0.1675 LossAtt 0.4818 TrainAcc 0.9400 TestAcc 0.8431 0.9350
epoch 1500 LossPred 0.1010 LossAtt 0.4810 TrainAcc 0.9800 TestAcc 0.8671 0.9850
epoch 1600 LossPred 0.1187 LossAtt 0.4798 TrainAcc 0.9500 TestAcc 0.8531 0.9600
epoch 1700 LossPred 0.0680 LossAtt 0.4700 TrainAcc 0.9900 TestAcc 0.8691 0.9700
epoch 1800 LossPred 0.2866 LossAtt 0.4385 TrainAcc 0.9100 TestAcc 0.8403 0.8900
epoch 1900 LossPred 0.1093 LossAtt 0.4380 TrainAcc 0.9500 TestAcc 0.8556 0.9500
epoch 2000 LossPred 0.1007 LossAtt 0.4321 TrainAcc 0.9700 TestAcc 0.8619 0.9500
epoch 2100 LossPred 0.1182 LossAtt 0.4283 TrainAcc 0.9600 TestAcc 0.8709 0.9650
epoch 2200 LossPred 0.1716 LossAtt 0.4221 TrainAcc 0.9300 TestAcc 0.8546 0.9450
epoch 2300 LossPred 0.0694 LossAtt 0.4228 TrainAcc 0.9800 TestAcc 0.8656 0.9750
epoch 2400 LossPred 0.2839 LossAtt 0.4531 TrainAcc 0.9000 TestAcc 0.8276 0.8850
epoch 2500 LossPred 0.0904 LossAtt 0.4661 TrainAcc 0.9600 TestAcc 0.8468 0.9600
Optimization Finished!
********** replication  60  **********
epoch   0 LossPred 1.0201 LossAtt 0.9836 TrainAcc 0.4600 TestAcc 0.4970 0.4650
epoch 100 LossPred 0.9416 LossAtt 0.4284 TrainAcc 0.5900 TestAcc 0.5726 0.6000
epoch 200 LossPred 0.8187 LossAtt 0.5619 TrainAcc 0.7300 TestAcc 0.6669 0.7100
epoch 300 LossPred 0.6401 LossAtt 0.5899 TrainAcc 0.7700 TestAcc 0.7805 0.7550
epoch 400 LossPred 0.4175 LossAtt 0.5552 TrainAcc 0.8600 TestAcc 0.8448 0.8600
epoch 500 LossPred 0.3408 LossAtt 0.5265 TrainAcc 0.8800 TestAcc 0.8954 0.8950
epoch 600 LossPred 0.2686 LossAtt 0.5370 TrainAcc 0.9200 TestAcc 0.9037 0.9100
epoch 700 LossPred 0.2536 LossAtt 0.5148 TrainAcc 0.9000 TestAcc 0.8639 0.9000
epoch 800 LossPred 0.1741 LossAtt 0.5193 TrainAcc 0.9400 TestAcc 0.9137 0.9200
epoch 900 LossPred 0.1742 LossAtt 0.5041 TrainAcc 0.9500 TestAcc 0.9217 0.9250
epoch 1000 LossPred 0.1819 LossAtt 0.5152 TrainAcc 0.9300 TestAcc 0.9147 0.9200
epoch 1100 LossPred 0.1360 LossAtt 0.4777 TrainAcc 0.9500 TestAcc 0.9174 0.9400
epoch 1200 LossPred 0.1297 LossAtt 0.4861 TrainAcc 0.9600 TestAcc 0.9122 0.9400
epoch 1300 LossPred 0.1281 LossAtt 0.4931 TrainAcc 0.9600 TestAcc 0.8994 0.9350
epoch 1400 LossPred 0.1162 LossAtt 0.4824 TrainAcc 0.9700 TestAcc 0.9197 0.9300
epoch 1500 LossPred 0.2198 LossAtt 0.5023 TrainAcc 0.9400 TestAcc 0.9037 0.8950
epoch 1600 LossPred 0.1154 LossAtt 0.5070 TrainAcc 0.9700 TestAcc 0.9007 0.9450
epoch 1700 LossPred 0.1004 LossAtt 0.4674 TrainAcc 0.9700 TestAcc 0.9282 0.9450
epoch 1800 LossPred 0.1739 LossAtt 0.4699 TrainAcc 0.9500 TestAcc 0.9217 0.9250
epoch 1900 LossPred 0.2597 LossAtt 0.4592 TrainAcc 0.8900 TestAcc 0.8809 0.8900
epoch 2000 LossPred 0.1914 LossAtt 0.4565 TrainAcc 0.9300 TestAcc 0.8631 0.9150
epoch 2100 LossPred 0.2354 LossAtt 0.4618 TrainAcc 0.9100 TestAcc 0.8911 0.9000
epoch 2200 LossPred 0.1754 LossAtt 0.4394 TrainAcc 0.9300 TestAcc 0.8609 0.9150
epoch 2300 LossPred 0.3151 LossAtt 0.4469 TrainAcc 0.8900 TestAcc 0.8171 0.8700
epoch 2400 LossPred 0.4075 LossAtt 0.4179 TrainAcc 0.8400 TestAcc 0.7908 0.8400
epoch 2500 LossPred 0.1517 LossAtt 0.4239 TrainAcc 0.9400 TestAcc 0.8839 0.9400
Optimization Finished!
********** replication  61  **********
epoch   0 LossPred 1.1292 LossAtt 1.0134 TrainAcc 0.4900 TestAcc 0.5158 0.4950
epoch 100 LossPred 0.9899 LossAtt 0.3650 TrainAcc 0.5600 TestAcc 0.5008 0.5600
epoch 200 LossPred 0.9827 LossAtt 0.2490 TrainAcc 0.5600 TestAcc 0.5008 0.5600
epoch 300 LossPred 0.9780 LossAtt 0.2300 TrainAcc 0.5600 TestAcc 0.5008 0.5600
epoch 400 LossPred 0.9634 LossAtt 0.3426 TrainAcc 0.5900 TestAcc 0.5551 0.5700
epoch 500 LossPred 0.9174 LossAtt 0.4644 TrainAcc 0.6300 TestAcc 0.5340 0.6250
epoch 600 LossPred 0.8822 LossAtt 0.5489 TrainAcc 0.6600 TestAcc 0.5648 0.6600
epoch 700 LossPred 1.0058 LossAtt 0.5858 TrainAcc 0.5400 TestAcc 0.5623 0.5450
epoch 800 LossPred 0.8518 LossAtt 0.4251 TrainAcc 0.7400 TestAcc 0.6689 0.7200
epoch 900 LossPred 0.2739 LossAtt 0.4846 TrainAcc 0.9200 TestAcc 0.8609 0.8950
epoch 1000 LossPred 0.1848 LossAtt 0.5073 TrainAcc 0.9600 TestAcc 0.9069 0.9200
epoch 1100 LossPred 0.2516 LossAtt 0.4950 TrainAcc 0.8900 TestAcc 0.8724 0.8950
epoch 1200 LossPred 0.1467 LossAtt 0.4845 TrainAcc 0.9600 TestAcc 0.9077 0.9450
epoch 1300 LossPred 0.4890 LossAtt 0.4628 TrainAcc 0.8200 TestAcc 0.7868 0.8400
epoch 1400 LossPred 0.2159 LossAtt 0.4621 TrainAcc 0.9400 TestAcc 0.8724 0.9250
epoch 1500 LossPred 0.2341 LossAtt 0.4519 TrainAcc 0.9200 TestAcc 0.8656 0.9150
epoch 1600 LossPred 0.2746 LossAtt 0.4685 TrainAcc 0.9200 TestAcc 0.8604 0.8900
epoch 1700 LossPred 0.2210 LossAtt 0.4789 TrainAcc 0.9500 TestAcc 0.8806 0.9300
epoch 1800 LossPred 0.2042 LossAtt 0.4700 TrainAcc 0.9500 TestAcc 0.8716 0.9450
epoch 1900 LossPred 0.2016 LossAtt 0.4527 TrainAcc 0.9300 TestAcc 0.8754 0.9350
epoch 2000 LossPred 0.1787 LossAtt 0.4626 TrainAcc 0.9500 TestAcc 0.8819 0.9350
epoch 2100 LossPred 0.2700 LossAtt 0.5035 TrainAcc 0.9200 TestAcc 0.8483 0.8800
epoch 2200 LossPred 0.2241 LossAtt 0.4824 TrainAcc 0.9200 TestAcc 0.8674 0.9150
epoch 2300 LossPred 0.1577 LossAtt 0.4783 TrainAcc 0.9500 TestAcc 0.8779 0.9400
epoch 2400 LossPred 0.4567 LossAtt 0.4413 TrainAcc 0.8600 TestAcc 0.8243 0.8750
epoch 2500 LossPred 0.1739 LossAtt 0.4673 TrainAcc 0.9400 TestAcc 0.8854 0.9400
Optimization Finished!
********** replication  62  **********
epoch   0 LossPred 1.2237 LossAtt 1.0380 TrainAcc 0.4600 TestAcc 0.4449 0.4550
epoch 100 LossPred 0.9887 LossAtt 0.5115 TrainAcc 0.5300 TestAcc 0.4862 0.5300
epoch 200 LossPred 0.9572 LossAtt 0.5274 TrainAcc 0.5700 TestAcc 0.4847 0.5800
epoch 300 LossPred 0.9256 LossAtt 0.5550 TrainAcc 0.5900 TestAcc 0.5335 0.5900
epoch 400 LossPred 0.8675 LossAtt 0.5369 TrainAcc 0.6900 TestAcc 0.5783 0.6900
epoch 500 LossPred 0.8149 LossAtt 0.6125 TrainAcc 0.6800 TestAcc 0.6311 0.7050
epoch 600 LossPred 0.4993 LossAtt 0.5722 TrainAcc 0.8400 TestAcc 0.8343 0.8050
epoch 700 LossPred 0.4593 LossAtt 0.5113 TrainAcc 0.8800 TestAcc 0.8133 0.8400
epoch 800 LossPred 0.3015 LossAtt 0.5229 TrainAcc 0.9100 TestAcc 0.8383 0.8700
epoch 900 LossPred 0.2462 LossAtt 0.5054 TrainAcc 0.9300 TestAcc 0.8406 0.9100
epoch 1000 LossPred 0.2027 LossAtt 0.5070 TrainAcc 0.9400 TestAcc 0.8521 0.9100
epoch 1100 LossPred 0.3735 LossAtt 0.4929 TrainAcc 0.8800 TestAcc 0.8141 0.8650
epoch 1200 LossPred 0.2442 LossAtt 0.5075 TrainAcc 0.9300 TestAcc 0.8689 0.9300
epoch 1300 LossPred 0.2036 LossAtt 0.4800 TrainAcc 0.9400 TestAcc 0.8576 0.9050
epoch 1400 LossPred 0.1928 LossAtt 0.4588 TrainAcc 0.9600 TestAcc 0.8516 0.9400
epoch 1500 LossPred 0.1796 LossAtt 0.4804 TrainAcc 0.9600 TestAcc 0.8463 0.9500
epoch 1600 LossPred 0.1917 LossAtt 0.4940 TrainAcc 0.9600 TestAcc 0.8506 0.9500
epoch 1700 LossPred 0.1870 LossAtt 0.4674 TrainAcc 0.9500 TestAcc 0.8376 0.9350
epoch 1800 LossPred 0.1665 LossAtt 0.4992 TrainAcc 0.9700 TestAcc 0.8431 0.9300
epoch 1900 LossPred 0.4139 LossAtt 0.4785 TrainAcc 0.8700 TestAcc 0.7935 0.8650
epoch 2000 LossPred 0.1697 LossAtt 0.4833 TrainAcc 0.9700 TestAcc 0.8448 0.9450
epoch 2100 LossPred 0.1452 LossAtt 0.4884 TrainAcc 0.9700 TestAcc 0.8433 0.9450
epoch 2200 LossPred 0.1426 LossAtt 0.5004 TrainAcc 0.9700 TestAcc 0.8441 0.9450
epoch 2300 LossPred 0.1435 LossAtt 0.4818 TrainAcc 0.9800 TestAcc 0.8468 0.9550
epoch 2400 LossPred 0.1701 LossAtt 0.5136 TrainAcc 0.9600 TestAcc 0.8466 0.9400
epoch 2500 LossPred 0.1645 LossAtt 0.4691 TrainAcc 0.9700 TestAcc 0.8529 0.9400
Optimization Finished!
********** replication  63  **********
epoch   0 LossPred 1.1640 LossAtt 1.0111 TrainAcc 0.4400 TestAcc 0.4622 0.3950
epoch 100 LossPred 0.9139 LossAtt 0.4552 TrainAcc 0.7100 TestAcc 0.5776 0.7050
epoch 200 LossPred 0.8589 LossAtt 0.5269 TrainAcc 0.6600 TestAcc 0.5671 0.6600
epoch 300 LossPred 0.7661 LossAtt 0.4958 TrainAcc 0.6900 TestAcc 0.6206 0.7200
epoch 400 LossPred 0.5120 LossAtt 0.5193 TrainAcc 0.8300 TestAcc 0.8196 0.8150
epoch 500 LossPred 0.3684 LossAtt 0.5194 TrainAcc 0.9000 TestAcc 0.8368 0.8800
epoch 600 LossPred 0.3122 LossAtt 0.5267 TrainAcc 0.9100 TestAcc 0.8516 0.9050
epoch 700 LossPred 0.2587 LossAtt 0.5155 TrainAcc 0.9300 TestAcc 0.8461 0.9200
epoch 800 LossPred 0.2055 LossAtt 0.5130 TrainAcc 0.9400 TestAcc 0.8383 0.9200
epoch 900 LossPred 0.1799 LossAtt 0.5373 TrainAcc 0.9500 TestAcc 0.8651 0.9200
epoch 1000 LossPred 0.1405 LossAtt 0.5552 TrainAcc 0.9500 TestAcc 0.8571 0.9300
epoch 1100 LossPred 0.1917 LossAtt 0.5486 TrainAcc 0.9400 TestAcc 0.8438 0.9400
epoch 1200 LossPred 0.1246 LossAtt 0.5494 TrainAcc 0.9500 TestAcc 0.8791 0.9450
epoch 1300 LossPred 0.1269 LossAtt 0.5390 TrainAcc 0.9600 TestAcc 0.8689 0.9300
epoch 1400 LossPred 0.1818 LossAtt 0.5383 TrainAcc 0.9400 TestAcc 0.8526 0.9400
epoch 1500 LossPred 0.1334 LossAtt 0.5243 TrainAcc 0.9500 TestAcc 0.8839 0.9550
epoch 1600 LossPred 0.1036 LossAtt 0.5118 TrainAcc 0.9700 TestAcc 0.8874 0.9450
epoch 1700 LossPred 0.0813 LossAtt 0.5369 TrainAcc 0.9900 TestAcc 0.8876 0.9500
epoch 1800 LossPred 0.0770 LossAtt 0.5092 TrainAcc 0.9800 TestAcc 0.8901 0.9600
epoch 1900 LossPred 0.0953 LossAtt 0.5360 TrainAcc 0.9600 TestAcc 0.8654 0.9650
epoch 2000 LossPred 0.1851 LossAtt 0.5369 TrainAcc 0.9200 TestAcc 0.8651 0.9300
epoch 2100 LossPred 0.0950 LossAtt 0.5395 TrainAcc 0.9700 TestAcc 0.8911 0.9600
epoch 2200 LossPred 0.1793 LossAtt 0.5519 TrainAcc 0.9400 TestAcc 0.8644 0.9300
epoch 2300 LossPred 0.0588 LossAtt 0.5679 TrainAcc 0.9800 TestAcc 0.8854 0.9550
epoch 2400 LossPred 0.0746 LossAtt 0.5713 TrainAcc 0.9800 TestAcc 0.8854 0.9350
epoch 2500 LossPred 0.0494 LossAtt 0.5717 TrainAcc 0.9900 TestAcc 0.8781 0.9500
Optimization Finished!
********** replication  64  **********
epoch   0 LossPred 1.1471 LossAtt 0.9962 TrainAcc 0.4500 TestAcc 0.4680 0.4600
epoch 100 LossPred 0.9519 LossAtt 0.4188 TrainAcc 0.6200 TestAcc 0.5713 0.6250
epoch 200 LossPred 0.9313 LossAtt 0.4187 TrainAcc 0.6000 TestAcc 0.5651 0.6100
epoch 300 LossPred 0.9255 LossAtt 0.3595 TrainAcc 0.5700 TestAcc 0.5896 0.5900
epoch 400 LossPred 0.8903 LossAtt 0.3974 TrainAcc 0.6300 TestAcc 0.6071 0.6400
epoch 500 LossPred 0.4258 LossAtt 0.4347 TrainAcc 0.8700 TestAcc 0.8181 0.8700
epoch 600 LossPred 0.4300 LossAtt 0.4547 TrainAcc 0.8600 TestAcc 0.8356 0.8900
epoch 700 LossPred 0.4478 LossAtt 0.4393 TrainAcc 0.8400 TestAcc 0.8133 0.8800
epoch 800 LossPred 0.4446 LossAtt 0.4398 TrainAcc 0.8500 TestAcc 0.8133 0.8700
epoch 900 LossPred 0.4026 LossAtt 0.4150 TrainAcc 0.8600 TestAcc 0.8261 0.8850
epoch 1000 LossPred 0.3651 LossAtt 0.3894 TrainAcc 0.8600 TestAcc 0.8298 0.8800
epoch 1100 LossPred 0.3586 LossAtt 0.3957 TrainAcc 0.8800 TestAcc 0.7970 0.8950
epoch 1200 LossPred 0.3284 LossAtt 0.3888 TrainAcc 0.8900 TestAcc 0.8243 0.8900
epoch 1300 LossPred 0.3282 LossAtt 0.3743 TrainAcc 0.8900 TestAcc 0.8251 0.8950
epoch 1400 LossPred 0.2953 LossAtt 0.3861 TrainAcc 0.9100 TestAcc 0.7995 0.8850
epoch 1500 LossPred 0.3106 LossAtt 0.3704 TrainAcc 0.9100 TestAcc 0.8273 0.9200
epoch 1600 LossPred 0.7101 LossAtt 0.3654 TrainAcc 0.7500 TestAcc 0.6922 0.7500
epoch 1700 LossPred 0.3201 LossAtt 0.3635 TrainAcc 0.9100 TestAcc 0.8383 0.9100
epoch 1800 LossPred 0.2535 LossAtt 0.3867 TrainAcc 0.9400 TestAcc 0.8386 0.9250
epoch 1900 LossPred 0.5227 LossAtt 0.3664 TrainAcc 0.8200 TestAcc 0.7548 0.8250
epoch 2000 LossPred 0.2695 LossAtt 0.3857 TrainAcc 0.9100 TestAcc 0.8196 0.9200
epoch 2100 LossPred 0.2258 LossAtt 0.3729 TrainAcc 0.9200 TestAcc 0.8356 0.9350
epoch 2200 LossPred 0.3280 LossAtt 0.3962 TrainAcc 0.9000 TestAcc 0.8311 0.9250
epoch 2300 LossPred 0.1746 LossAtt 0.3945 TrainAcc 0.9400 TestAcc 0.8358 0.9400
epoch 2400 LossPred 0.2576 LossAtt 0.3994 TrainAcc 0.9100 TestAcc 0.8226 0.9350
epoch 2500 LossPred 0.1805 LossAtt 0.4151 TrainAcc 0.9600 TestAcc 0.8393 0.9350
Optimization Finished!
********** replication  65  **********
epoch   0 LossPred 1.1588 LossAtt 1.0013 TrainAcc 0.5000 TestAcc 0.4630 0.5000
epoch 100 LossPred 0.9497 LossAtt 0.4050 TrainAcc 0.6000 TestAcc 0.5813 0.5750
epoch 200 LossPred 0.9441 LossAtt 0.3590 TrainAcc 0.6000 TestAcc 0.5813 0.6000
epoch 300 LossPred 0.9415 LossAtt 0.3132 TrainAcc 0.6000 TestAcc 0.5813 0.6150
epoch 400 LossPred 0.9315 LossAtt 0.2740 TrainAcc 0.6400 TestAcc 0.5783 0.6200
epoch 500 LossPred 0.9265 LossAtt 0.3041 TrainAcc 0.6000 TestAcc 0.5293 0.6300
epoch 600 LossPred 0.9249 LossAtt 0.3110 TrainAcc 0.5800 TestAcc 0.5245 0.6250
epoch 700 LossPred 0.9256 LossAtt 0.3313 TrainAcc 0.6100 TestAcc 0.5318 0.6150
epoch 800 LossPred 0.9255 LossAtt 0.3502 TrainAcc 0.6000 TestAcc 0.5360 0.6150
epoch 900 LossPred 0.9258 LossAtt 0.3659 TrainAcc 0.5900 TestAcc 0.5345 0.5950
epoch 1000 LossPred 0.9126 LossAtt 0.3528 TrainAcc 0.6200 TestAcc 0.5521 0.6350
epoch 1100 LossPred 0.8916 LossAtt 0.3198 TrainAcc 0.6700 TestAcc 0.5578 0.6700
epoch 1200 LossPred 0.8817 LossAtt 0.2813 TrainAcc 0.6700 TestAcc 0.5608 0.6550
epoch 1300 LossPred 0.8789 LossAtt 0.2792 TrainAcc 0.6700 TestAcc 0.5608 0.6500
epoch 1400 LossPred 0.8749 LossAtt 0.2846 TrainAcc 0.6700 TestAcc 0.5596 0.6600
epoch 1500 LossPred 0.8674 LossAtt 0.3083 TrainAcc 0.6500 TestAcc 0.5518 0.6550
epoch 1600 LossPred 0.8644 LossAtt 0.3269 TrainAcc 0.6700 TestAcc 0.5556 0.6600
epoch 1700 LossPred 0.8616 LossAtt 0.3415 TrainAcc 0.6700 TestAcc 0.5593 0.6750
epoch 1800 LossPred 0.8567 LossAtt 0.3210 TrainAcc 0.6900 TestAcc 0.5768 0.6750
epoch 1900 LossPred 0.8480 LossAtt 0.3383 TrainAcc 0.6700 TestAcc 0.5768 0.6750
epoch 2000 LossPred 0.8375 LossAtt 0.3740 TrainAcc 0.7000 TestAcc 0.5856 0.6850
epoch 2100 LossPred 0.8132 LossAtt 0.4014 TrainAcc 0.6800 TestAcc 0.5888 0.6950
epoch 2200 LossPred 0.8094 LossAtt 0.3638 TrainAcc 0.6900 TestAcc 0.5823 0.6750
epoch 2300 LossPred 0.8116 LossAtt 0.3458 TrainAcc 0.7100 TestAcc 0.5743 0.7300
epoch 2400 LossPred 0.8037 LossAtt 0.3370 TrainAcc 0.7100 TestAcc 0.5748 0.7000
epoch 2500 LossPred 0.8078 LossAtt 0.3418 TrainAcc 0.7100 TestAcc 0.5763 0.6850
Optimization Finished!
********** replication  66  **********
epoch   0 LossPred 1.1636 LossAtt 1.0071 TrainAcc 0.3700 TestAcc 0.4134 0.3750
epoch 100 LossPred 0.9044 LossAtt 0.3425 TrainAcc 0.6300 TestAcc 0.5866 0.6300
epoch 200 LossPred 0.8252 LossAtt 0.3158 TrainAcc 0.7100 TestAcc 0.6559 0.6950
epoch 300 LossPred 0.4703 LossAtt 0.3415 TrainAcc 0.8800 TestAcc 0.8223 0.8250
epoch 400 LossPred 0.5944 LossAtt 0.3268 TrainAcc 0.8100 TestAcc 0.7723 0.7950
epoch 500 LossPred 0.5669 LossAtt 0.3273 TrainAcc 0.8100 TestAcc 0.8073 0.7950
epoch 600 LossPred 0.6640 LossAtt 0.3762 TrainAcc 0.7300 TestAcc 0.7610 0.7200
epoch 700 LossPred 0.6886 LossAtt 0.3386 TrainAcc 0.7400 TestAcc 0.7523 0.7500
epoch 800 LossPred 0.5594 LossAtt 0.3446 TrainAcc 0.8100 TestAcc 0.8153 0.7850
epoch 900 LossPred 0.5910 LossAtt 0.3406 TrainAcc 0.7900 TestAcc 0.8028 0.7700
epoch 1000 LossPred 0.4857 LossAtt 0.3797 TrainAcc 0.8300 TestAcc 0.8266 0.8400
epoch 1100 LossPred 0.5405 LossAtt 0.3757 TrainAcc 0.8100 TestAcc 0.8036 0.8050
epoch 1200 LossPred 0.4451 LossAtt 0.3471 TrainAcc 0.8400 TestAcc 0.8353 0.8300
epoch 1300 LossPred 0.4621 LossAtt 0.3565 TrainAcc 0.8300 TestAcc 0.8293 0.8250
epoch 1400 LossPred 0.4398 LossAtt 0.3701 TrainAcc 0.8600 TestAcc 0.8358 0.8550
epoch 1500 LossPred 0.4297 LossAtt 0.3760 TrainAcc 0.8700 TestAcc 0.8328 0.8450
epoch 1600 LossPred 0.4175 LossAtt 0.3751 TrainAcc 0.9100 TestAcc 0.8258 0.8550
epoch 1700 LossPred 0.3501 LossAtt 0.3646 TrainAcc 0.8700 TestAcc 0.8463 0.8600
epoch 1800 LossPred 0.3287 LossAtt 0.3742 TrainAcc 0.8800 TestAcc 0.8651 0.8700
epoch 1900 LossPred 0.2854 LossAtt 0.3693 TrainAcc 0.9100 TestAcc 0.8806 0.8700
epoch 2000 LossPred 0.2745 LossAtt 0.3704 TrainAcc 0.9000 TestAcc 0.8899 0.8900
epoch 2100 LossPred 0.2722 LossAtt 0.3689 TrainAcc 0.9200 TestAcc 0.8759 0.9050
epoch 2200 LossPred 0.2253 LossAtt 0.3571 TrainAcc 0.9200 TestAcc 0.8916 0.9100
epoch 2300 LossPred 0.2227 LossAtt 0.3598 TrainAcc 0.9300 TestAcc 0.8936 0.9100
epoch 2400 LossPred 0.2625 LossAtt 0.3575 TrainAcc 0.9000 TestAcc 0.8856 0.9050
epoch 2500 LossPred 0.2171 LossAtt 0.3427 TrainAcc 0.9300 TestAcc 0.8901 0.9150
Optimization Finished!
********** replication  67  **********
epoch   0 LossPred 1.0491 LossAtt 1.0084 TrainAcc 0.5300 TestAcc 0.5473 0.5300
epoch 100 LossPred 0.9808 LossAtt 0.3289 TrainAcc 0.5700 TestAcc 0.5558 0.5550
epoch 200 LossPred 0.9765 LossAtt 0.2609 TrainAcc 0.5800 TestAcc 0.5688 0.5800
epoch 300 LossPred 0.9779 LossAtt 0.1069 TrainAcc 0.6200 TestAcc 0.5938 0.5950
epoch 400 LossPred 0.9791 LossAtt 0.1370 TrainAcc 0.5800 TestAcc 0.5688 0.5800
epoch 500 LossPred 0.9740 LossAtt 0.1369 TrainAcc 0.5800 TestAcc 0.5688 0.5800
epoch 600 LossPred 0.9597 LossAtt 0.1973 TrainAcc 0.5800 TestAcc 0.5688 0.5850
epoch 700 LossPred 0.8891 LossAtt 0.3850 TrainAcc 0.6200 TestAcc 0.6179 0.6100
epoch 800 LossPred 0.3670 LossAtt 0.2533 TrainAcc 0.9000 TestAcc 0.8896 0.8600
epoch 900 LossPred 0.6242 LossAtt 0.2287 TrainAcc 0.7700 TestAcc 0.8626 0.8050
epoch 1000 LossPred 0.4257 LossAtt 0.2148 TrainAcc 0.8200 TestAcc 0.8944 0.8550
epoch 1100 LossPred 0.4691 LossAtt 0.2182 TrainAcc 0.8400 TestAcc 0.8481 0.8200
epoch 1200 LossPred 0.4963 LossAtt 0.2033 TrainAcc 0.8300 TestAcc 0.8839 0.8300
epoch 1300 LossPred 0.4337 LossAtt 0.2256 TrainAcc 0.8600 TestAcc 0.8791 0.8450
epoch 1400 LossPred 0.3572 LossAtt 0.2174 TrainAcc 0.9000 TestAcc 0.9067 0.8600
epoch 1500 LossPred 0.3760 LossAtt 0.2198 TrainAcc 0.8800 TestAcc 0.9057 0.8550
epoch 1600 LossPred 0.4392 LossAtt 0.2227 TrainAcc 0.8500 TestAcc 0.8709 0.8400
epoch 1700 LossPred 0.5909 LossAtt 0.1913 TrainAcc 0.8000 TestAcc 0.8649 0.8150
epoch 1800 LossPred 0.3672 LossAtt 0.2232 TrainAcc 0.9000 TestAcc 0.8916 0.8450
epoch 1900 LossPred 0.3934 LossAtt 0.2206 TrainAcc 0.8700 TestAcc 0.8846 0.8450
epoch 2000 LossPred 0.4538 LossAtt 0.2240 TrainAcc 0.8400 TestAcc 0.8468 0.8450
epoch 2100 LossPred 0.3480 LossAtt 0.2121 TrainAcc 0.8800 TestAcc 0.8904 0.8550
epoch 2200 LossPred 0.4939 LossAtt 0.1903 TrainAcc 0.8300 TestAcc 0.8831 0.8300
epoch 2300 LossPred 0.4376 LossAtt 0.1901 TrainAcc 0.8300 TestAcc 0.8999 0.8450
epoch 2400 LossPred 0.4399 LossAtt 0.1933 TrainAcc 0.8300 TestAcc 0.9039 0.8350
epoch 2500 LossPred 0.3937 LossAtt 0.1972 TrainAcc 0.8400 TestAcc 0.9084 0.8500
Optimization Finished!
********** replication  68  **********
epoch   0 LossPred 0.8950 LossAtt 0.9931 TrainAcc 0.7200 TestAcc 0.5796 0.7100
epoch 100 LossPred 0.7845 LossAtt 0.4404 TrainAcc 0.7200 TestAcc 0.5886 0.7200
epoch 200 LossPred 0.7307 LossAtt 0.4102 TrainAcc 0.7200 TestAcc 0.5886 0.7200
epoch 300 LossPred 0.6953 LossAtt 0.4101 TrainAcc 0.7800 TestAcc 0.6016 0.7700
epoch 400 LossPred 0.6750 LossAtt 0.4281 TrainAcc 0.7800 TestAcc 0.6016 0.7750
epoch 500 LossPred 0.6449 LossAtt 0.4297 TrainAcc 0.7700 TestAcc 0.6456 0.7700
epoch 600 LossPred 0.4895 LossAtt 0.4160 TrainAcc 0.8300 TestAcc 0.7783 0.8300
epoch 700 LossPred 0.4911 LossAtt 0.4056 TrainAcc 0.8300 TestAcc 0.7645 0.8150
epoch 800 LossPred 0.5117 LossAtt 0.3729 TrainAcc 0.8100 TestAcc 0.7745 0.8200
epoch 900 LossPred 0.4415 LossAtt 0.3669 TrainAcc 0.8500 TestAcc 0.7873 0.8500
epoch 1000 LossPred 0.4925 LossAtt 0.3383 TrainAcc 0.8200 TestAcc 0.7728 0.8150
epoch 1100 LossPred 0.4767 LossAtt 0.3249 TrainAcc 0.8300 TestAcc 0.7873 0.8250
epoch 1200 LossPred 0.4334 LossAtt 0.3414 TrainAcc 0.8300 TestAcc 0.7828 0.8300
epoch 1300 LossPred 0.4706 LossAtt 0.3324 TrainAcc 0.8300 TestAcc 0.7873 0.8350
epoch 1400 LossPred 0.4523 LossAtt 0.3483 TrainAcc 0.8100 TestAcc 0.7948 0.8150
epoch 1500 LossPred 0.4593 LossAtt 0.3232 TrainAcc 0.8100 TestAcc 0.7933 0.8150
epoch 1600 LossPred 0.4782 LossAtt 0.3459 TrainAcc 0.8300 TestAcc 0.7920 0.8100
epoch 1700 LossPred 0.4834 LossAtt 0.3178 TrainAcc 0.8100 TestAcc 0.7795 0.8000
epoch 1800 LossPred 0.7739 LossAtt 0.3190 TrainAcc 0.7000 TestAcc 0.6929 0.7000
epoch 1900 LossPred 0.5109 LossAtt 0.3346 TrainAcc 0.8300 TestAcc 0.7518 0.8350
epoch 2000 LossPred 0.4610 LossAtt 0.3718 TrainAcc 0.8100 TestAcc 0.7823 0.8150
epoch 2100 LossPred 0.5495 LossAtt 0.2875 TrainAcc 0.7900 TestAcc 0.7733 0.7850
epoch 2200 LossPred 0.4582 LossAtt 0.3258 TrainAcc 0.8500 TestAcc 0.7770 0.8500
epoch 2300 LossPred 0.5311 LossAtt 0.3090 TrainAcc 0.8200 TestAcc 0.7482 0.8200
epoch 2400 LossPred 0.4677 LossAtt 0.3041 TrainAcc 0.8400 TestAcc 0.7908 0.8250
epoch 2500 LossPred 0.4726 LossAtt 0.3342 TrainAcc 0.8300 TestAcc 0.7683 0.8200
Optimization Finished!
********** replication  69  **********
epoch   0 LossPred 1.3777 LossAtt 1.0423 TrainAcc 0.4600 TestAcc 0.4595 0.4500
epoch 100 LossPred 1.0899 LossAtt 0.4310 TrainAcc 0.4500 TestAcc 0.4552 0.4700
epoch 200 LossPred 0.9844 LossAtt 0.3496 TrainAcc 0.6200 TestAcc 0.5210 0.5950
epoch 300 LossPred 0.9321 LossAtt 0.3465 TrainAcc 0.5900 TestAcc 0.5548 0.6000
epoch 400 LossPred 0.9071 LossAtt 0.3624 TrainAcc 0.6800 TestAcc 0.6196 0.6500
epoch 500 LossPred 0.8896 LossAtt 0.4011 TrainAcc 0.6500 TestAcc 0.6161 0.6500
epoch 600 LossPred 0.8808 LossAtt 0.3903 TrainAcc 0.6600 TestAcc 0.6181 0.6700
epoch 700 LossPred 0.8645 LossAtt 0.3962 TrainAcc 0.6800 TestAcc 0.6289 0.6600
epoch 800 LossPred 0.8506 LossAtt 0.3715 TrainAcc 0.6800 TestAcc 0.6311 0.6650
epoch 900 LossPred 0.8363 LossAtt 0.3661 TrainAcc 0.6800 TestAcc 0.6316 0.6850
epoch 1000 LossPred 0.8207 LossAtt 0.3771 TrainAcc 0.6800 TestAcc 0.6329 0.6850
epoch 1100 LossPred 0.7754 LossAtt 0.3920 TrainAcc 0.7200 TestAcc 0.6632 0.7100
epoch 1200 LossPred 0.7312 LossAtt 0.4278 TrainAcc 0.7300 TestAcc 0.6744 0.7300
epoch 1300 LossPred 0.7398 LossAtt 0.4044 TrainAcc 0.7200 TestAcc 0.7135 0.7600
epoch 1400 LossPred 0.3795 LossAtt 0.3776 TrainAcc 0.8900 TestAcc 0.7848 0.8600
epoch 1500 LossPred 0.5121 LossAtt 0.4160 TrainAcc 0.8300 TestAcc 0.7760 0.8250
epoch 1600 LossPred 0.3681 LossAtt 0.4152 TrainAcc 0.9000 TestAcc 0.8058 0.8500
epoch 1700 LossPred 0.4448 LossAtt 0.4111 TrainAcc 0.8600 TestAcc 0.8073 0.8500
epoch 1800 LossPred 0.3557 LossAtt 0.3834 TrainAcc 0.9000 TestAcc 0.8028 0.8550
epoch 1900 LossPred 0.3850 LossAtt 0.3841 TrainAcc 0.8800 TestAcc 0.8048 0.8650
epoch 2000 LossPred 0.3356 LossAtt 0.3494 TrainAcc 0.9000 TestAcc 0.8113 0.8700
epoch 2100 LossPred 0.3489 LossAtt 0.3279 TrainAcc 0.9000 TestAcc 0.7885 0.8550
epoch 2200 LossPred 0.4232 LossAtt 0.3422 TrainAcc 0.8600 TestAcc 0.7780 0.8500
epoch 2300 LossPred 0.3410 LossAtt 0.3279 TrainAcc 0.9000 TestAcc 0.7958 0.8650
epoch 2400 LossPred 0.4033 LossAtt 0.3434 TrainAcc 0.8700 TestAcc 0.7848 0.8500
epoch 2500 LossPred 0.3994 LossAtt 0.3213 TrainAcc 0.8700 TestAcc 0.8046 0.8600
Optimization Finished!
********** replication  70  **********
epoch   0 LossPred 1.1213 LossAtt 1.0167 TrainAcc 0.5600 TestAcc 0.5385 0.5600
epoch 100 LossPred 0.9486 LossAtt 0.4928 TrainAcc 0.5800 TestAcc 0.5581 0.5950
epoch 200 LossPred 0.9170 LossAtt 0.4507 TrainAcc 0.6400 TestAcc 0.5756 0.6400
epoch 300 LossPred 0.8908 LossAtt 0.4341 TrainAcc 0.6400 TestAcc 0.5756 0.6400
epoch 400 LossPred 0.8188 LossAtt 0.4937 TrainAcc 0.7000 TestAcc 0.6189 0.7100
epoch 500 LossPred 0.8758 LossAtt 0.4562 TrainAcc 0.6400 TestAcc 0.5948 0.6500
epoch 600 LossPred 0.8715 LossAtt 0.4460 TrainAcc 0.6000 TestAcc 0.5886 0.6400
epoch 700 LossPred 0.8604 LossAtt 0.4065 TrainAcc 0.6000 TestAcc 0.5903 0.6250
epoch 800 LossPred 0.8521 LossAtt 0.4009 TrainAcc 0.6400 TestAcc 0.5958 0.6300
epoch 900 LossPred 0.8274 LossAtt 0.4224 TrainAcc 0.6400 TestAcc 0.6091 0.6600
epoch 1000 LossPred 0.7914 LossAtt 0.3956 TrainAcc 0.7000 TestAcc 0.6399 0.7300
epoch 1100 LossPred 0.8796 LossAtt 0.4087 TrainAcc 0.6400 TestAcc 0.5706 0.6450
epoch 1200 LossPred 0.8588 LossAtt 0.4295 TrainAcc 0.6500 TestAcc 0.5751 0.6500
epoch 1300 LossPred 0.8274 LossAtt 0.4499 TrainAcc 0.6600 TestAcc 0.5816 0.6650
epoch 1400 LossPred 0.6717 LossAtt 0.4575 TrainAcc 0.7300 TestAcc 0.7052 0.7900
epoch 1500 LossPred 0.5722 LossAtt 0.4334 TrainAcc 0.7900 TestAcc 0.7112 0.8050
epoch 1600 LossPred 0.5364 LossAtt 0.4011 TrainAcc 0.8000 TestAcc 0.7115 0.8150
epoch 1700 LossPred 0.5050 LossAtt 0.4291 TrainAcc 0.8100 TestAcc 0.7360 0.7850
epoch 1800 LossPred 0.4843 LossAtt 0.4203 TrainAcc 0.8100 TestAcc 0.7660 0.8200
epoch 1900 LossPred 0.4927 LossAtt 0.3864 TrainAcc 0.8400 TestAcc 0.7590 0.8350
epoch 2000 LossPred 0.7294 LossAtt 0.4062 TrainAcc 0.7600 TestAcc 0.7017 0.7400
epoch 2100 LossPred 0.3789 LossAtt 0.3933 TrainAcc 0.8600 TestAcc 0.7860 0.8500
epoch 2200 LossPred 0.4331 LossAtt 0.4097 TrainAcc 0.8300 TestAcc 0.7778 0.8400
epoch 2300 LossPred 0.3832 LossAtt 0.3714 TrainAcc 0.8500 TestAcc 0.8061 0.8850
epoch 2400 LossPred 1.0391 LossAtt 0.3717 TrainAcc 0.5800 TestAcc 0.5766 0.5900
epoch 2500 LossPred 0.4069 LossAtt 0.4075 TrainAcc 0.8400 TestAcc 0.7688 0.8300
Optimization Finished!
********** replication  71  **********
epoch   0 LossPred 1.1580 LossAtt 1.0015 TrainAcc 0.5000 TestAcc 0.5343 0.4850
epoch 100 LossPred 0.9833 LossAtt 0.4088 TrainAcc 0.5900 TestAcc 0.5110 0.5750
epoch 200 LossPred 0.9731 LossAtt 0.2994 TrainAcc 0.5900 TestAcc 0.5110 0.5900
epoch 300 LossPred 0.9653 LossAtt 0.2773 TrainAcc 0.5900 TestAcc 0.5110 0.5950
epoch 400 LossPred 0.9451 LossAtt 0.2969 TrainAcc 0.5900 TestAcc 0.5110 0.5950
epoch 500 LossPred 0.9266 LossAtt 0.3993 TrainAcc 0.6300 TestAcc 0.5280 0.6550
epoch 600 LossPred 0.9078 LossAtt 0.3731 TrainAcc 0.6300 TestAcc 0.5070 0.6000
epoch 700 LossPred 0.8688 LossAtt 0.3561 TrainAcc 0.6600 TestAcc 0.5183 0.6450
epoch 800 LossPred 0.8323 LossAtt 0.3840 TrainAcc 0.6700 TestAcc 0.5188 0.6900
epoch 900 LossPred 0.8201 LossAtt 0.3915 TrainAcc 0.7000 TestAcc 0.5210 0.6950
epoch 1000 LossPred 0.7814 LossAtt 0.4478 TrainAcc 0.7000 TestAcc 0.5528 0.6950
epoch 1100 LossPred 0.7371 LossAtt 0.4545 TrainAcc 0.7300 TestAcc 0.5253 0.7150
epoch 1200 LossPred 0.7455 LossAtt 0.4183 TrainAcc 0.7200 TestAcc 0.5193 0.7100
epoch 1300 LossPred 0.7128 LossAtt 0.3942 TrainAcc 0.7200 TestAcc 0.5225 0.7350
epoch 1400 LossPred 0.7101 LossAtt 0.3951 TrainAcc 0.7200 TestAcc 0.5303 0.7000
epoch 1500 LossPred 0.7436 LossAtt 0.3546 TrainAcc 0.7200 TestAcc 0.5646 0.7100
epoch 1600 LossPred 0.7318 LossAtt 0.3169 TrainAcc 0.7200 TestAcc 0.5395 0.7150
epoch 1700 LossPred 0.7353 LossAtt 0.3259 TrainAcc 0.7200 TestAcc 0.5703 0.7350
epoch 1800 LossPred 0.7365 LossAtt 0.2915 TrainAcc 0.7200 TestAcc 0.5693 0.7450
epoch 1900 LossPred 0.7405 LossAtt 0.2994 TrainAcc 0.7200 TestAcc 0.5701 0.7200
epoch 2000 LossPred 0.7373 LossAtt 0.2954 TrainAcc 0.7100 TestAcc 0.5638 0.7150
epoch 2100 LossPred 0.7389 LossAtt 0.2829 TrainAcc 0.7100 TestAcc 0.5653 0.7100
epoch 2200 LossPred 0.7318 LossAtt 0.2720 TrainAcc 0.7100 TestAcc 0.5653 0.7150
epoch 2300 LossPred 0.7287 LossAtt 0.2958 TrainAcc 0.7100 TestAcc 0.5653 0.7100
epoch 2400 LossPred 0.7228 LossAtt 0.2570 TrainAcc 0.7100 TestAcc 0.5726 0.7150
epoch 2500 LossPred 0.7144 LossAtt 0.2484 TrainAcc 0.7200 TestAcc 0.5691 0.7050
Optimization Finished!
********** replication  72  **********
epoch   0 LossPred 0.9655 LossAtt 0.9858 TrainAcc 0.6200 TestAcc 0.5398 0.6000
epoch 100 LossPred 0.8405 LossAtt 0.3835 TrainAcc 0.6900 TestAcc 0.5726 0.6900
epoch 200 LossPred 0.8235 LossAtt 0.2829 TrainAcc 0.6900 TestAcc 0.5726 0.6900
epoch 300 LossPred 0.8308 LossAtt 0.2388 TrainAcc 0.6900 TestAcc 0.5726 0.6900
epoch 400 LossPred 0.8116 LossAtt 0.2964 TrainAcc 0.6900 TestAcc 0.5726 0.6900
epoch 500 LossPred 0.7648 LossAtt 0.4417 TrainAcc 0.7000 TestAcc 0.5788 0.6750
epoch 600 LossPred 0.5586 LossAtt 0.5534 TrainAcc 0.8000 TestAcc 0.7170 0.8000
epoch 700 LossPred 0.6886 LossAtt 0.4564 TrainAcc 0.7100 TestAcc 0.6431 0.7400
epoch 800 LossPred 0.5147 LossAtt 0.4297 TrainAcc 0.8300 TestAcc 0.7543 0.8050
epoch 900 LossPred 0.5022 LossAtt 0.4107 TrainAcc 0.8500 TestAcc 0.7580 0.8450
epoch 1000 LossPred 0.4642 LossAtt 0.3956 TrainAcc 0.8700 TestAcc 0.7265 0.8550
epoch 1100 LossPred 0.4279 LossAtt 0.3632 TrainAcc 0.8600 TestAcc 0.7605 0.8400
epoch 1200 LossPred 0.4125 LossAtt 0.3630 TrainAcc 0.8700 TestAcc 0.7570 0.8500
epoch 1300 LossPred 0.4121 LossAtt 0.3797 TrainAcc 0.8800 TestAcc 0.7342 0.8600
epoch 1400 LossPred 0.5025 LossAtt 0.3697 TrainAcc 0.8400 TestAcc 0.7735 0.8150
epoch 1500 LossPred 0.5034 LossAtt 0.3792 TrainAcc 0.8200 TestAcc 0.7362 0.7900
epoch 1600 LossPred 0.4119 LossAtt 0.3785 TrainAcc 0.8800 TestAcc 0.7898 0.8500
epoch 1700 LossPred 0.4125 LossAtt 0.3561 TrainAcc 0.8600 TestAcc 0.7763 0.8500
epoch 1800 LossPred 0.4009 LossAtt 0.3788 TrainAcc 0.8800 TestAcc 0.7803 0.8500
epoch 1900 LossPred 0.4199 LossAtt 0.3798 TrainAcc 0.8400 TestAcc 0.7903 0.8500
epoch 2000 LossPred 0.4327 LossAtt 0.3830 TrainAcc 0.8400 TestAcc 0.7618 0.8550
epoch 2100 LossPred 0.4060 LossAtt 0.3572 TrainAcc 0.8900 TestAcc 0.7573 0.8550
epoch 2200 LossPred 0.4311 LossAtt 0.3685 TrainAcc 0.8600 TestAcc 0.8038 0.8500
epoch 2300 LossPred 0.4281 LossAtt 0.3735 TrainAcc 0.8700 TestAcc 0.7750 0.8600
epoch 2400 LossPred 0.3932 LossAtt 0.3813 TrainAcc 0.8800 TestAcc 0.7965 0.8500
epoch 2500 LossPred 0.4703 LossAtt 0.3571 TrainAcc 0.8400 TestAcc 0.8003 0.8500
Optimization Finished!
********** replication  73  **********
epoch   0 LossPred 0.9906 LossAtt 1.0080 TrainAcc 0.5600 TestAcc 0.5596 0.5800
epoch 100 LossPred 0.8918 LossAtt 0.2840 TrainAcc 0.6500 TestAcc 0.4932 0.6500
epoch 200 LossPred 0.8886 LossAtt 0.1720 TrainAcc 0.6500 TestAcc 0.4932 0.6500
epoch 300 LossPred 0.8847 LossAtt 0.1878 TrainAcc 0.6500 TestAcc 0.4932 0.6500
epoch 400 LossPred 0.8740 LossAtt 0.2631 TrainAcc 0.6500 TestAcc 0.4932 0.6500
epoch 500 LossPred 0.5001 LossAtt 0.2444 TrainAcc 0.8400 TestAcc 0.7908 0.8150
epoch 600 LossPred 0.4745 LossAtt 0.2485 TrainAcc 0.8600 TestAcc 0.8416 0.8350
epoch 700 LossPred 0.3677 LossAtt 0.2392 TrainAcc 0.8500 TestAcc 0.8734 0.8800
epoch 800 LossPred 0.3902 LossAtt 0.2306 TrainAcc 0.8700 TestAcc 0.8559 0.8850
epoch 900 LossPred 0.3903 LossAtt 0.2434 TrainAcc 0.8500 TestAcc 0.8596 0.8500
epoch 1000 LossPred 0.4107 LossAtt 0.2334 TrainAcc 0.8600 TestAcc 0.8589 0.8800
epoch 1100 LossPred 0.3675 LossAtt 0.2223 TrainAcc 0.8700 TestAcc 0.8566 0.8750
epoch 1200 LossPred 0.3839 LossAtt 0.2247 TrainAcc 0.8600 TestAcc 0.8504 0.8550
epoch 1300 LossPred 0.3674 LossAtt 0.2212 TrainAcc 0.8700 TestAcc 0.8779 0.8850
epoch 1400 LossPred 0.4041 LossAtt 0.2191 TrainAcc 0.8500 TestAcc 0.8406 0.8550
epoch 1500 LossPred 0.4493 LossAtt 0.2123 TrainAcc 0.8400 TestAcc 0.8423 0.8650
epoch 1600 LossPred 0.6122 LossAtt 0.2326 TrainAcc 0.7700 TestAcc 0.7120 0.7950
epoch 1700 LossPred 0.7521 LossAtt 0.2162 TrainAcc 0.7000 TestAcc 0.7432 0.6850
epoch 1800 LossPred 0.4039 LossAtt 0.2206 TrainAcc 0.8800 TestAcc 0.8451 0.8700
epoch 1900 LossPred 0.4677 LossAtt 0.2058 TrainAcc 0.8600 TestAcc 0.8101 0.8600
epoch 2000 LossPred 0.4458 LossAtt 0.1982 TrainAcc 0.8500 TestAcc 0.8151 0.8350
epoch 2100 LossPred 0.3890 LossAtt 0.1999 TrainAcc 0.8600 TestAcc 0.8646 0.8500
epoch 2200 LossPred 0.5304 LossAtt 0.2113 TrainAcc 0.8100 TestAcc 0.8156 0.8200
epoch 2300 LossPred 0.5014 LossAtt 0.2215 TrainAcc 0.8300 TestAcc 0.8021 0.8500
epoch 2400 LossPred 0.3969 LossAtt 0.2100 TrainAcc 0.8600 TestAcc 0.8448 0.8350
epoch 2500 LossPred 0.4129 LossAtt 0.2102 TrainAcc 0.8600 TestAcc 0.8413 0.8600
Optimization Finished!
********** replication  74  **********
epoch   0 LossPred 1.1000 LossAtt 0.9861 TrainAcc 0.4000 TestAcc 0.4717 0.4150
epoch 100 LossPred 0.9593 LossAtt 0.3910 TrainAcc 0.5700 TestAcc 0.5093 0.5700
epoch 200 LossPred 0.9401 LossAtt 0.4144 TrainAcc 0.5900 TestAcc 0.5383 0.5900
epoch 300 LossPred 0.9352 LossAtt 0.4060 TrainAcc 0.5800 TestAcc 0.5343 0.5800
epoch 400 LossPred 0.9252 LossAtt 0.4766 TrainAcc 0.5900 TestAcc 0.5781 0.5950
epoch 500 LossPred 0.5438 LossAtt 0.4268 TrainAcc 0.8900 TestAcc 0.7973 0.8950
epoch 600 LossPred 0.4332 LossAtt 0.3988 TrainAcc 0.9000 TestAcc 0.8088 0.9000
epoch 700 LossPred 0.3443 LossAtt 0.4043 TrainAcc 0.9000 TestAcc 0.8013 0.8950
epoch 800 LossPred 0.3151 LossAtt 0.3921 TrainAcc 0.9300 TestAcc 0.8036 0.9050
epoch 900 LossPred 0.3362 LossAtt 0.3947 TrainAcc 0.9100 TestAcc 0.8028 0.8950
epoch 1000 LossPred 0.3531 LossAtt 0.3823 TrainAcc 0.9000 TestAcc 0.8013 0.8850
epoch 1100 LossPred 0.3245 LossAtt 0.3706 TrainAcc 0.9200 TestAcc 0.8013 0.9000
epoch 1200 LossPred 0.2480 LossAtt 0.3715 TrainAcc 0.9400 TestAcc 0.8041 0.9000
epoch 1300 LossPred 0.4880 LossAtt 0.3811 TrainAcc 0.8500 TestAcc 0.7440 0.8650
epoch 1400 LossPred 0.3131 LossAtt 0.3620 TrainAcc 0.9100 TestAcc 0.8066 0.9000
epoch 1500 LossPred 0.3432 LossAtt 0.3517 TrainAcc 0.9000 TestAcc 0.8058 0.9050
epoch 1600 LossPred 0.2742 LossAtt 0.3327 TrainAcc 0.9400 TestAcc 0.8026 0.9050
epoch 1700 LossPred 0.2816 LossAtt 0.3259 TrainAcc 0.9200 TestAcc 0.8046 0.8900
epoch 1800 LossPred 0.2931 LossAtt 0.3432 TrainAcc 0.9200 TestAcc 0.7905 0.9050
epoch 1900 LossPred 0.2965 LossAtt 0.3191 TrainAcc 0.9300 TestAcc 0.8073 0.9000
epoch 2000 LossPred 0.3924 LossAtt 0.3257 TrainAcc 0.8800 TestAcc 0.7630 0.8550
epoch 2100 LossPred 0.3450 LossAtt 0.3207 TrainAcc 0.9000 TestAcc 0.8016 0.8950
epoch 2200 LossPred 0.3388 LossAtt 0.3199 TrainAcc 0.9000 TestAcc 0.7990 0.9050
epoch 2300 LossPred 0.2990 LossAtt 0.3068 TrainAcc 0.9100 TestAcc 0.8048 0.9000
epoch 2400 LossPred 0.2990 LossAtt 0.3088 TrainAcc 0.9100 TestAcc 0.8038 0.9000
epoch 2500 LossPred 0.3286 LossAtt 0.3105 TrainAcc 0.8900 TestAcc 0.7890 0.8750
Optimization Finished!
********** replication  75  **********
epoch   0 LossPred 1.3594 LossAtt 1.0100 TrainAcc 0.4400 TestAcc 0.5018 0.4200
epoch 100 LossPred 1.0408 LossAtt 0.4846 TrainAcc 0.5200 TestAcc 0.4094 0.5000
epoch 200 LossPred 0.9709 LossAtt 0.5017 TrainAcc 0.6100 TestAcc 0.4319 0.5900
epoch 300 LossPred 0.9324 LossAtt 0.5119 TrainAcc 0.6500 TestAcc 0.4927 0.6450
epoch 400 LossPred 0.9020 LossAtt 0.5118 TrainAcc 0.6700 TestAcc 0.5073 0.6450
epoch 500 LossPred 0.8811 LossAtt 0.4863 TrainAcc 0.6700 TestAcc 0.5073 0.6600
epoch 600 LossPred 0.8649 LossAtt 0.4473 TrainAcc 0.6700 TestAcc 0.5400 0.6700
epoch 700 LossPred 0.8498 LossAtt 0.4129 TrainAcc 0.6800 TestAcc 0.5403 0.6850
epoch 800 LossPred 0.8368 LossAtt 0.3814 TrainAcc 0.6800 TestAcc 0.5333 0.6700
epoch 900 LossPred 0.8211 LossAtt 0.3775 TrainAcc 0.6800 TestAcc 0.5340 0.6750
epoch 1000 LossPred 0.8063 LossAtt 0.3825 TrainAcc 0.6800 TestAcc 0.5345 0.6750
epoch 1100 LossPred 0.7883 LossAtt 0.3859 TrainAcc 0.6800 TestAcc 0.5338 0.6800
epoch 1200 LossPred 0.7718 LossAtt 0.4537 TrainAcc 0.7100 TestAcc 0.5390 0.7150
epoch 1300 LossPred 0.7580 LossAtt 0.4707 TrainAcc 0.7100 TestAcc 0.5320 0.7050
epoch 1400 LossPred 0.7410 LossAtt 0.5426 TrainAcc 0.7300 TestAcc 0.5418 0.7100
epoch 1500 LossPred 0.7084 LossAtt 0.5394 TrainAcc 0.7300 TestAcc 0.5448 0.7300
epoch 1600 LossPred 0.6892 LossAtt 0.5031 TrainAcc 0.7600 TestAcc 0.5200 0.7500
epoch 1700 LossPred 0.6689 LossAtt 0.4951 TrainAcc 0.7800 TestAcc 0.5108 0.7600
epoch 1800 LossPred 0.6528 LossAtt 0.4898 TrainAcc 0.8000 TestAcc 0.5118 0.7600
epoch 1900 LossPred 0.6326 LossAtt 0.5031 TrainAcc 0.7800 TestAcc 0.5235 0.7550
epoch 2000 LossPred 0.6204 LossAtt 0.4913 TrainAcc 0.7700 TestAcc 0.5298 0.7450
epoch 2100 LossPred 0.6050 LossAtt 0.5033 TrainAcc 0.7900 TestAcc 0.5255 0.7600
epoch 2200 LossPred 0.5867 LossAtt 0.4820 TrainAcc 0.7900 TestAcc 0.5303 0.7500
epoch 2300 LossPred 0.5860 LossAtt 0.5001 TrainAcc 0.7800 TestAcc 0.5300 0.7450
epoch 2400 LossPred 0.5849 LossAtt 0.4775 TrainAcc 0.8000 TestAcc 0.5203 0.7650
epoch 2500 LossPred 0.5837 LossAtt 0.4815 TrainAcc 0.8000 TestAcc 0.5215 0.7650
Optimization Finished!
********** replication  76  **********
epoch   0 LossPred 0.9987 LossAtt 0.9678 TrainAcc 0.6000 TestAcc 0.5548 0.5550
epoch 100 LossPred 0.9092 LossAtt 0.5515 TrainAcc 0.6100 TestAcc 0.5878 0.6250
epoch 200 LossPred 0.8860 LossAtt 0.4931 TrainAcc 0.6200 TestAcc 0.5981 0.6300
epoch 300 LossPred 0.8164 LossAtt 0.4483 TrainAcc 0.6500 TestAcc 0.6552 0.6350
epoch 400 LossPred 0.5404 LossAtt 0.3405 TrainAcc 0.8000 TestAcc 0.7975 0.7700
epoch 500 LossPred 0.6309 LossAtt 0.3240 TrainAcc 0.7700 TestAcc 0.7945 0.7650
epoch 600 LossPred 0.5317 LossAtt 0.3205 TrainAcc 0.8300 TestAcc 0.8076 0.7950
epoch 700 LossPred 0.6781 LossAtt 0.3143 TrainAcc 0.7800 TestAcc 0.7452 0.7350
epoch 800 LossPred 0.5998 LossAtt 0.3100 TrainAcc 0.8000 TestAcc 0.7870 0.7600
epoch 900 LossPred 0.5934 LossAtt 0.2883 TrainAcc 0.8400 TestAcc 0.8053 0.8150
epoch 1000 LossPred 0.5802 LossAtt 0.2888 TrainAcc 0.8300 TestAcc 0.8046 0.8150
epoch 1100 LossPred 0.5841 LossAtt 0.2776 TrainAcc 0.8400 TestAcc 0.7998 0.8150
epoch 1200 LossPred 0.7156 LossAtt 0.2827 TrainAcc 0.7500 TestAcc 0.7335 0.7050
epoch 1300 LossPred 0.7126 LossAtt 0.2986 TrainAcc 0.7500 TestAcc 0.7382 0.7050
epoch 1400 LossPred 0.6786 LossAtt 0.2836 TrainAcc 0.7700 TestAcc 0.7608 0.7150
epoch 1500 LossPred 0.5968 LossAtt 0.3050 TrainAcc 0.8000 TestAcc 0.7838 0.7600
epoch 1600 LossPred 0.6295 LossAtt 0.3044 TrainAcc 0.8000 TestAcc 0.7848 0.7750
epoch 1700 LossPred 0.6132 LossAtt 0.3314 TrainAcc 0.8000 TestAcc 0.7823 0.7750
epoch 1800 LossPred 0.5916 LossAtt 0.3135 TrainAcc 0.8200 TestAcc 0.8001 0.7800
epoch 1900 LossPred 0.6474 LossAtt 0.3614 TrainAcc 0.8000 TestAcc 0.7603 0.7600
epoch 2000 LossPred 0.4379 LossAtt 0.3478 TrainAcc 0.8700 TestAcc 0.8068 0.7800
epoch 2100 LossPred 0.4300 LossAtt 0.3434 TrainAcc 0.8800 TestAcc 0.8093 0.8050
epoch 2200 LossPred 0.4997 LossAtt 0.3592 TrainAcc 0.8200 TestAcc 0.8093 0.7800
epoch 2300 LossPred 0.4089 LossAtt 0.3543 TrainAcc 0.8900 TestAcc 0.8138 0.8050
epoch 2400 LossPred 0.4956 LossAtt 0.3610 TrainAcc 0.8700 TestAcc 0.7973 0.7950
epoch 2500 LossPred 0.4797 LossAtt 0.3563 TrainAcc 0.8300 TestAcc 0.8038 0.7950
Optimization Finished!
********** replication  77  **********
epoch   0 LossPred 0.9548 LossAtt 0.9971 TrainAcc 0.6000 TestAcc 0.5658 0.6000
epoch 100 LossPred 0.8807 LossAtt 0.4678 TrainAcc 0.6600 TestAcc 0.5803 0.6800
epoch 200 LossPred 0.8704 LossAtt 0.4590 TrainAcc 0.6600 TestAcc 0.5803 0.6750
epoch 300 LossPred 0.8314 LossAtt 0.5080 TrainAcc 0.6600 TestAcc 0.5906 0.6700
epoch 400 LossPred 0.4835 LossAtt 0.5355 TrainAcc 0.8500 TestAcc 0.8051 0.8550
epoch 500 LossPred 0.4364 LossAtt 0.4774 TrainAcc 0.8600 TestAcc 0.8241 0.8650
epoch 600 LossPred 0.5284 LossAtt 0.4357 TrainAcc 0.8500 TestAcc 0.7735 0.8500
epoch 700 LossPred 0.4335 LossAtt 0.4164 TrainAcc 0.8600 TestAcc 0.8168 0.8650
epoch 800 LossPred 0.4525 LossAtt 0.4121 TrainAcc 0.8400 TestAcc 0.8096 0.8600
epoch 900 LossPred 0.4516 LossAtt 0.4102 TrainAcc 0.8400 TestAcc 0.8303 0.8700
epoch 1000 LossPred 0.4639 LossAtt 0.4124 TrainAcc 0.8600 TestAcc 0.8273 0.8700
epoch 1100 LossPred 0.4418 LossAtt 0.3912 TrainAcc 0.8700 TestAcc 0.8211 0.8800
epoch 1200 LossPred 0.4777 LossAtt 0.3899 TrainAcc 0.8500 TestAcc 0.8213 0.8550
epoch 1300 LossPred 0.4561 LossAtt 0.4002 TrainAcc 0.8500 TestAcc 0.8308 0.8700
epoch 1400 LossPred 0.4914 LossAtt 0.3849 TrainAcc 0.8400 TestAcc 0.7943 0.8150
epoch 1500 LossPred 0.4273 LossAtt 0.3972 TrainAcc 0.8600 TestAcc 0.8378 0.8800
epoch 1600 LossPred 0.4443 LossAtt 0.4088 TrainAcc 0.8500 TestAcc 0.8076 0.8500
epoch 1700 LossPred 0.4194 LossAtt 0.3910 TrainAcc 0.8800 TestAcc 0.8233 0.8800
epoch 1800 LossPred 0.4199 LossAtt 0.4047 TrainAcc 0.8700 TestAcc 0.8246 0.8800
epoch 1900 LossPred 0.4316 LossAtt 0.3894 TrainAcc 0.8800 TestAcc 0.8188 0.8800
epoch 2000 LossPred 0.4179 LossAtt 0.3967 TrainAcc 0.8600 TestAcc 0.8106 0.8700
epoch 2100 LossPred 0.4137 LossAtt 0.3911 TrainAcc 0.8600 TestAcc 0.8101 0.8750
epoch 2200 LossPred 0.4556 LossAtt 0.3839 TrainAcc 0.8600 TestAcc 0.8091 0.8700
epoch 2300 LossPred 0.5418 LossAtt 0.3759 TrainAcc 0.8300 TestAcc 0.7773 0.8500
epoch 2400 LossPred 0.4646 LossAtt 0.3954 TrainAcc 0.8700 TestAcc 0.8076 0.8650
epoch 2500 LossPred 0.4594 LossAtt 0.3906 TrainAcc 0.8500 TestAcc 0.7993 0.8650
Optimization Finished!
********** replication  78  **********
epoch   0 LossPred 1.0238 LossAtt 0.9795 TrainAcc 0.5600 TestAcc 0.5528 0.5800
epoch 100 LossPred 0.8962 LossAtt 0.4070 TrainAcc 0.6800 TestAcc 0.6004 0.6750
epoch 200 LossPred 0.8405 LossAtt 0.3656 TrainAcc 0.7000 TestAcc 0.6204 0.7150
epoch 300 LossPred 0.7722 LossAtt 0.3100 TrainAcc 0.7200 TestAcc 0.7082 0.7050
epoch 400 LossPred 0.6818 LossAtt 0.2854 TrainAcc 0.7300 TestAcc 0.7933 0.7450
epoch 500 LossPred 0.6009 LossAtt 0.2760 TrainAcc 0.7800 TestAcc 0.7810 0.8250
epoch 600 LossPred 0.8798 LossAtt 0.2091 TrainAcc 0.6800 TestAcc 0.6389 0.6850
epoch 700 LossPred 0.9291 LossAtt 0.1899 TrainAcc 0.6200 TestAcc 0.5801 0.6150
epoch 800 LossPred 0.9230 LossAtt 0.1717 TrainAcc 0.6200 TestAcc 0.5801 0.6200
epoch 900 LossPred 0.9161 LossAtt 0.1685 TrainAcc 0.6200 TestAcc 0.5801 0.6200
epoch 1000 LossPred 0.9086 LossAtt 0.1721 TrainAcc 0.6200 TestAcc 0.5801 0.6200
epoch 1100 LossPred 0.8979 LossAtt 0.1893 TrainAcc 0.6200 TestAcc 0.5881 0.6250
epoch 1200 LossPred 0.6646 LossAtt 0.2175 TrainAcc 0.7700 TestAcc 0.7060 0.7700
epoch 1300 LossPred 0.6581 LossAtt 0.2130 TrainAcc 0.7600 TestAcc 0.7060 0.7700
epoch 1400 LossPred 0.6387 LossAtt 0.2154 TrainAcc 0.7800 TestAcc 0.7172 0.7650
epoch 1500 LossPred 0.6516 LossAtt 0.2193 TrainAcc 0.7700 TestAcc 0.7117 0.7700
epoch 1600 LossPred 0.6200 LossAtt 0.2262 TrainAcc 0.7900 TestAcc 0.7160 0.7650
epoch 1700 LossPred 0.6521 LossAtt 0.2122 TrainAcc 0.7700 TestAcc 0.7160 0.7800
epoch 1800 LossPred 0.5934 LossAtt 0.2286 TrainAcc 0.7600 TestAcc 0.7508 0.7400
epoch 1900 LossPred 0.9030 LossAtt 0.2622 TrainAcc 0.6300 TestAcc 0.6692 0.6100
epoch 2000 LossPred 0.8937 LossAtt 0.2405 TrainAcc 0.6400 TestAcc 0.5916 0.6400
epoch 2100 LossPred 0.8961 LossAtt 0.2466 TrainAcc 0.6400 TestAcc 0.5896 0.6400
epoch 2200 LossPred 0.8943 LossAtt 0.2429 TrainAcc 0.6400 TestAcc 0.5928 0.6400
epoch 2300 LossPred 0.8885 LossAtt 0.2502 TrainAcc 0.6400 TestAcc 0.5941 0.6400
epoch 2400 LossPred 0.8919 LossAtt 0.2404 TrainAcc 0.6400 TestAcc 0.5913 0.6500
epoch 2500 LossPred 0.8882 LossAtt 0.2531 TrainAcc 0.6400 TestAcc 0.5933 0.6400
Optimization Finished!
********** replication  79  **********
epoch   0 LossPred 1.1715 LossAtt 1.0337 TrainAcc 0.4400 TestAcc 0.4855 0.4600
epoch 100 LossPred 0.9395 LossAtt 0.4278 TrainAcc 0.6600 TestAcc 0.5718 0.6450
epoch 200 LossPred 0.8873 LossAtt 0.4280 TrainAcc 0.6000 TestAcc 0.5753 0.6350
epoch 300 LossPred 0.4078 LossAtt 0.4693 TrainAcc 0.8500 TestAcc 0.8481 0.8350
epoch 400 LossPred 0.4911 LossAtt 0.4323 TrainAcc 0.8400 TestAcc 0.8236 0.7950
epoch 500 LossPred 0.4017 LossAtt 0.3992 TrainAcc 0.8400 TestAcc 0.8381 0.8550
epoch 600 LossPred 0.3839 LossAtt 0.3806 TrainAcc 0.8700 TestAcc 0.8353 0.8500
epoch 700 LossPred 0.3719 LossAtt 0.3777 TrainAcc 0.8900 TestAcc 0.8333 0.8750
epoch 800 LossPred 0.4335 LossAtt 0.3660 TrainAcc 0.8500 TestAcc 0.8291 0.8450
epoch 900 LossPred 0.3216 LossAtt 0.3726 TrainAcc 0.9000 TestAcc 0.8476 0.8750
epoch 1000 LossPred 0.3015 LossAtt 0.3691 TrainAcc 0.9000 TestAcc 0.8446 0.8750
epoch 1100 LossPred 0.3096 LossAtt 0.3604 TrainAcc 0.8900 TestAcc 0.8418 0.8700
epoch 1200 LossPred 0.3307 LossAtt 0.3573 TrainAcc 0.8700 TestAcc 0.8421 0.8700
epoch 1300 LossPred 0.3195 LossAtt 0.3687 TrainAcc 0.9000 TestAcc 0.8448 0.8850
epoch 1400 LossPred 0.4262 LossAtt 0.3777 TrainAcc 0.8500 TestAcc 0.8266 0.8300
epoch 1500 LossPred 0.3155 LossAtt 0.3592 TrainAcc 0.9200 TestAcc 0.8421 0.8800
epoch 1600 LossPred 0.4556 LossAtt 0.3642 TrainAcc 0.8600 TestAcc 0.8158 0.8250
epoch 1700 LossPred 0.3620 LossAtt 0.3503 TrainAcc 0.8800 TestAcc 0.8298 0.8700
epoch 1800 LossPred 0.3938 LossAtt 0.3738 TrainAcc 0.8700 TestAcc 0.8141 0.8600
epoch 1900 LossPred 0.4258 LossAtt 0.3611 TrainAcc 0.8500 TestAcc 0.8176 0.8400
epoch 2000 LossPred 0.3489 LossAtt 0.3658 TrainAcc 0.8700 TestAcc 0.8361 0.8550
epoch 2100 LossPred 0.3781 LossAtt 0.3498 TrainAcc 0.8700 TestAcc 0.8348 0.8500
epoch 2200 LossPred 0.3363 LossAtt 0.3561 TrainAcc 0.8900 TestAcc 0.8368 0.8800
epoch 2300 LossPred 0.2681 LossAtt 0.3645 TrainAcc 0.9100 TestAcc 0.8428 0.8800
epoch 2400 LossPred 0.3107 LossAtt 0.3690 TrainAcc 0.9000 TestAcc 0.8356 0.8650
epoch 2500 LossPred 0.3150 LossAtt 0.3716 TrainAcc 0.8900 TestAcc 0.8363 0.8850
Optimization Finished!
********** replication  80  **********
epoch   0 LossPred 1.1405 LossAtt 1.0116 TrainAcc 0.4900 TestAcc 0.4447 0.4550
epoch 100 LossPred 0.9952 LossAtt 0.4799 TrainAcc 0.5000 TestAcc 0.4449 0.4900
epoch 200 LossPred 0.9383 LossAtt 0.4505 TrainAcc 0.5700 TestAcc 0.4997 0.5650
epoch 300 LossPred 0.9178 LossAtt 0.3692 TrainAcc 0.6200 TestAcc 0.5876 0.6200
epoch 400 LossPred 0.9044 LossAtt 0.3103 TrainAcc 0.6200 TestAcc 0.5876 0.6150
epoch 500 LossPred 0.8940 LossAtt 0.2603 TrainAcc 0.6200 TestAcc 0.5876 0.6150
epoch 600 LossPred 0.8890 LossAtt 0.1948 TrainAcc 0.6200 TestAcc 0.5638 0.6250
epoch 700 LossPred 0.8877 LossAtt 0.1363 TrainAcc 0.6200 TestAcc 0.5638 0.6300
epoch 800 LossPred 0.8867 LossAtt 0.1300 TrainAcc 0.6200 TestAcc 0.5638 0.6350
epoch 900 LossPred 0.8845 LossAtt 0.1645 TrainAcc 0.6200 TestAcc 0.5926 0.6250
epoch 1000 LossPred 0.8276 LossAtt 0.3493 TrainAcc 0.7200 TestAcc 0.6674 0.6600
epoch 1100 LossPred 0.6614 LossAtt 0.3123 TrainAcc 0.7800 TestAcc 0.7533 0.7450
epoch 1200 LossPred 0.4911 LossAtt 0.2851 TrainAcc 0.8400 TestAcc 0.7978 0.8200
epoch 1300 LossPred 0.5414 LossAtt 0.2517 TrainAcc 0.8100 TestAcc 0.7608 0.8150
epoch 1400 LossPred 0.4877 LossAtt 0.2453 TrainAcc 0.8500 TestAcc 0.7958 0.8350
epoch 1500 LossPred 0.4973 LossAtt 0.2486 TrainAcc 0.8400 TestAcc 0.7928 0.8450
epoch 1600 LossPred 0.5228 LossAtt 0.2478 TrainAcc 0.8500 TestAcc 0.7918 0.8550
epoch 1700 LossPred 0.4783 LossAtt 0.2486 TrainAcc 0.8300 TestAcc 0.7973 0.8400
epoch 1800 LossPred 0.4909 LossAtt 0.2374 TrainAcc 0.8400 TestAcc 0.7923 0.8400
epoch 1900 LossPred 0.5877 LossAtt 0.2421 TrainAcc 0.8000 TestAcc 0.7755 0.8150
epoch 2000 LossPred 0.5682 LossAtt 0.2461 TrainAcc 0.8200 TestAcc 0.7793 0.8200
epoch 2100 LossPred 0.5117 LossAtt 0.2537 TrainAcc 0.8200 TestAcc 0.7935 0.8150
epoch 2200 LossPred 0.5793 LossAtt 0.2384 TrainAcc 0.8400 TestAcc 0.7940 0.8300
epoch 2300 LossPred 0.5281 LossAtt 0.2324 TrainAcc 0.8300 TestAcc 0.8001 0.8150
epoch 2400 LossPred 0.5311 LossAtt 0.2364 TrainAcc 0.8100 TestAcc 0.7663 0.7850
epoch 2500 LossPred 0.5255 LossAtt 0.2314 TrainAcc 0.8300 TestAcc 0.7933 0.8150
Optimization Finished!
********** replication  81  **********
epoch   0 LossPred 1.2798 LossAtt 1.0090 TrainAcc 0.3700 TestAcc 0.4595 0.3700
epoch 100 LossPred 0.9250 LossAtt 0.4000 TrainAcc 0.5700 TestAcc 0.5000 0.5700
epoch 200 LossPred 0.9065 LossAtt 0.2220 TrainAcc 0.6100 TestAcc 0.5078 0.6100
epoch 300 LossPred 0.9058 LossAtt 0.1309 TrainAcc 0.5700 TestAcc 0.5000 0.6050
epoch 400 LossPred 0.9077 LossAtt 0.1117 TrainAcc 0.6100 TestAcc 0.5078 0.6100
epoch 500 LossPred 0.9018 LossAtt 0.0836 TrainAcc 0.6100 TestAcc 0.5078 0.5900
epoch 600 LossPred 0.8990 LossAtt 0.0677 TrainAcc 0.6100 TestAcc 0.5078 0.5950
epoch 700 LossPred 0.8977 LossAtt 0.0687 TrainAcc 0.6100 TestAcc 0.5078 0.5950
epoch 800 LossPred 0.8969 LossAtt 0.0779 TrainAcc 0.6500 TestAcc 0.5893 0.6100
epoch 900 LossPred 0.8968 LossAtt 0.0896 TrainAcc 0.6100 TestAcc 0.5816 0.5900
epoch 1000 LossPred 0.8971 LossAtt 0.1076 TrainAcc 0.6100 TestAcc 0.5816 0.5950
epoch 1100 LossPred 0.8970 LossAtt 0.1286 TrainAcc 0.6100 TestAcc 0.5816 0.6000
epoch 1200 LossPred 0.8954 LossAtt 0.1408 TrainAcc 0.6100 TestAcc 0.5816 0.6050
epoch 1300 LossPred 0.8403 LossAtt 0.4900 TrainAcc 0.6600 TestAcc 0.5831 0.6550
epoch 1400 LossPred 0.9127 LossAtt 0.2010 TrainAcc 0.6100 TestAcc 0.5078 0.6100
epoch 1500 LossPred 0.8257 LossAtt 0.2694 TrainAcc 0.7100 TestAcc 0.6479 0.7050
epoch 1600 LossPred 0.8789 LossAtt 0.2731 TrainAcc 0.6300 TestAcc 0.6847 0.6650
epoch 1700 LossPred 0.5826 LossAtt 0.2878 TrainAcc 0.8100 TestAcc 0.7733 0.7950
epoch 1800 LossPred 0.6046 LossAtt 0.3044 TrainAcc 0.8000 TestAcc 0.7878 0.7700
epoch 1900 LossPred 0.5447 LossAtt 0.3038 TrainAcc 0.8200 TestAcc 0.8153 0.7950
epoch 2000 LossPred 0.5081 LossAtt 0.3071 TrainAcc 0.8100 TestAcc 0.8053 0.7800
epoch 2100 LossPred 0.5566 LossAtt 0.3054 TrainAcc 0.7800 TestAcc 0.8076 0.7850
epoch 2200 LossPred 0.5251 LossAtt 0.3052 TrainAcc 0.8100 TestAcc 0.8071 0.7900
epoch 2300 LossPred 0.5776 LossAtt 0.2934 TrainAcc 0.8100 TestAcc 0.7898 0.7500
epoch 2400 LossPred 0.5118 LossAtt 0.3140 TrainAcc 0.8400 TestAcc 0.8023 0.7750
epoch 2500 LossPred 0.5624 LossAtt 0.3184 TrainAcc 0.7900 TestAcc 0.8051 0.7800
Optimization Finished!
********** replication  82  **********
epoch   0 LossPred 1.1666 LossAtt 0.9914 TrainAcc 0.4700 TestAcc 0.5050 0.4700
epoch 100 LossPred 0.9487 LossAtt 0.3017 TrainAcc 0.6000 TestAcc 0.5808 0.6050
epoch 200 LossPred 0.9503 LossAtt 0.2230 TrainAcc 0.5800 TestAcc 0.5038 0.5850
epoch 300 LossPred 0.9498 LossAtt 0.2223 TrainAcc 0.6000 TestAcc 0.5808 0.6000
epoch 400 LossPred 0.9474 LossAtt 0.2367 TrainAcc 0.6000 TestAcc 0.5808 0.6000
epoch 500 LossPred 0.9458 LossAtt 0.2391 TrainAcc 0.6000 TestAcc 0.5808 0.6000
epoch 600 LossPred 0.9420 LossAtt 0.2585 TrainAcc 0.6000 TestAcc 0.5808 0.6000
epoch 700 LossPred 0.9365 LossAtt 0.2850 TrainAcc 0.6000 TestAcc 0.5808 0.5950
epoch 800 LossPred 0.9163 LossAtt 0.3351 TrainAcc 0.6500 TestAcc 0.6189 0.6400
epoch 900 LossPred 0.9391 LossAtt 0.3441 TrainAcc 0.6600 TestAcc 0.6111 0.6500
epoch 1000 LossPred 0.9301 LossAtt 0.2957 TrainAcc 0.6300 TestAcc 0.6009 0.6250
epoch 1100 LossPred 0.9184 LossAtt 0.2663 TrainAcc 0.6300 TestAcc 0.5988 0.6400
epoch 1200 LossPred 0.9114 LossAtt 0.2782 TrainAcc 0.6300 TestAcc 0.5981 0.6450
epoch 1300 LossPred 0.9061 LossAtt 0.2550 TrainAcc 0.6300 TestAcc 0.5978 0.6350
epoch 1400 LossPred 0.9030 LossAtt 0.2544 TrainAcc 0.6300 TestAcc 0.6009 0.6350
epoch 1500 LossPred 0.9004 LossAtt 0.2658 TrainAcc 0.6300 TestAcc 0.5976 0.6300
epoch 1600 LossPred 0.8973 LossAtt 0.2688 TrainAcc 0.6300 TestAcc 0.5988 0.6450
epoch 1700 LossPred 0.8860 LossAtt 0.2573 TrainAcc 0.6400 TestAcc 0.6016 0.6350
epoch 1800 LossPred 0.8909 LossAtt 0.2721 TrainAcc 0.6300 TestAcc 0.6014 0.6350
epoch 1900 LossPred 0.8774 LossAtt 0.2715 TrainAcc 0.6400 TestAcc 0.6069 0.6400
epoch 2000 LossPred 0.8740 LossAtt 0.2749 TrainAcc 0.6400 TestAcc 0.6059 0.6450
epoch 2100 LossPred 0.8626 LossAtt 0.2868 TrainAcc 0.6400 TestAcc 0.6519 0.6450
epoch 2200 LossPred 0.8576 LossAtt 0.2806 TrainAcc 0.6400 TestAcc 0.6692 0.6450
epoch 2300 LossPred 0.9786 LossAtt 0.3128 TrainAcc 0.5300 TestAcc 0.5846 0.5300
epoch 2400 LossPred 0.9583 LossAtt 0.3096 TrainAcc 0.5500 TestAcc 0.5921 0.5450
epoch 2500 LossPred 0.9257 LossAtt 0.3015 TrainAcc 0.5700 TestAcc 0.6016 0.5800
Optimization Finished!
********** replication  83  **********
epoch   0 LossPred 1.1511 LossAtt 0.9974 TrainAcc 0.5200 TestAcc 0.5666 0.5100
epoch 100 LossPred 0.9793 LossAtt 0.4546 TrainAcc 0.5900 TestAcc 0.5683 0.5900
epoch 200 LossPred 0.9630 LossAtt 0.3326 TrainAcc 0.5900 TestAcc 0.5683 0.5900
epoch 300 LossPred 0.9543 LossAtt 0.2466 TrainAcc 0.5900 TestAcc 0.5683 0.5950
epoch 400 LossPred 0.9216 LossAtt 0.2301 TrainAcc 0.6200 TestAcc 0.5561 0.6250
epoch 500 LossPred 0.9083 LossAtt 0.2810 TrainAcc 0.6200 TestAcc 0.5561 0.6200
epoch 600 LossPred 0.8948 LossAtt 0.3316 TrainAcc 0.6100 TestAcc 0.5773 0.6200
epoch 700 LossPred 0.8932 LossAtt 0.3341 TrainAcc 0.6000 TestAcc 0.5721 0.5900
epoch 800 LossPred 0.6383 LossAtt 0.4611 TrainAcc 0.7800 TestAcc 0.7422 0.7800
epoch 900 LossPred 0.3763 LossAtt 0.4593 TrainAcc 0.8800 TestAcc 0.8418 0.8800
epoch 1000 LossPred 0.3627 LossAtt 0.4897 TrainAcc 0.8800 TestAcc 0.8418 0.8900
epoch 1100 LossPred 0.3187 LossAtt 0.4696 TrainAcc 0.8800 TestAcc 0.8549 0.9200
epoch 1200 LossPred 0.5799 LossAtt 0.4375 TrainAcc 0.8000 TestAcc 0.7770 0.8000
epoch 1300 LossPred 0.3527 LossAtt 0.4359 TrainAcc 0.8800 TestAcc 0.8426 0.8800
epoch 1400 LossPred 0.3299 LossAtt 0.4004 TrainAcc 0.8800 TestAcc 0.8433 0.8850
epoch 1500 LossPred 0.3288 LossAtt 0.3873 TrainAcc 0.8900 TestAcc 0.8544 0.8800
epoch 1600 LossPred 0.4483 LossAtt 0.3734 TrainAcc 0.8300 TestAcc 0.8041 0.8300
epoch 1700 LossPred 0.4589 LossAtt 0.3717 TrainAcc 0.8200 TestAcc 0.7963 0.8350
epoch 1800 LossPred 0.3089 LossAtt 0.3858 TrainAcc 0.9000 TestAcc 0.8406 0.8950
epoch 1900 LossPred 0.2964 LossAtt 0.3822 TrainAcc 0.8800 TestAcc 0.8481 0.9100
epoch 2000 LossPred 0.4082 LossAtt 0.3928 TrainAcc 0.8700 TestAcc 0.8156 0.8650
epoch 2100 LossPred 0.3767 LossAtt 0.3756 TrainAcc 0.8900 TestAcc 0.8428 0.8900
epoch 2200 LossPred 0.2951 LossAtt 0.3960 TrainAcc 0.9200 TestAcc 0.8333 0.9050
epoch 2300 LossPred 0.2895 LossAtt 0.3843 TrainAcc 0.9000 TestAcc 0.8436 0.9000
epoch 2400 LossPred 0.3514 LossAtt 0.3856 TrainAcc 0.9100 TestAcc 0.8433 0.9100
epoch 2500 LossPred 0.3827 LossAtt 0.3866 TrainAcc 0.8800 TestAcc 0.8191 0.8800
Optimization Finished!
********** replication  84  **********
epoch   0 LossPred 1.1947 LossAtt 1.0208 TrainAcc 0.3700 TestAcc 0.4822 0.3800
epoch 100 LossPred 0.9346 LossAtt 0.4116 TrainAcc 0.6400 TestAcc 0.5816 0.6400
epoch 200 LossPred 0.9075 LossAtt 0.3661 TrainAcc 0.6200 TestAcc 0.5395 0.6500
epoch 300 LossPred 0.8841 LossAtt 0.2832 TrainAcc 0.6500 TestAcc 0.5936 0.6600
epoch 400 LossPred 0.8638 LossAtt 0.3078 TrainAcc 0.6600 TestAcc 0.5771 0.6750
epoch 500 LossPred 0.8346 LossAtt 0.3248 TrainAcc 0.6600 TestAcc 0.5771 0.6800
epoch 600 LossPred 0.4965 LossAtt 0.3762 TrainAcc 0.8600 TestAcc 0.8286 0.8450
epoch 700 LossPred 0.4997 LossAtt 0.3723 TrainAcc 0.8200 TestAcc 0.8293 0.8400
epoch 800 LossPred 0.5092 LossAtt 0.3548 TrainAcc 0.8100 TestAcc 0.8048 0.8250
epoch 900 LossPred 0.5012 LossAtt 0.3384 TrainAcc 0.8200 TestAcc 0.8366 0.8300
epoch 1000 LossPred 0.4864 LossAtt 0.3044 TrainAcc 0.8300 TestAcc 0.8368 0.8400
epoch 1100 LossPred 0.4765 LossAtt 0.2998 TrainAcc 0.8400 TestAcc 0.8198 0.8350
epoch 1200 LossPred 0.4763 LossAtt 0.2736 TrainAcc 0.8200 TestAcc 0.8196 0.8500
epoch 1300 LossPred 0.4783 LossAtt 0.2700 TrainAcc 0.8300 TestAcc 0.8191 0.8400
epoch 1400 LossPred 0.4515 LossAtt 0.2673 TrainAcc 0.8500 TestAcc 0.8303 0.8450
epoch 1500 LossPred 0.4538 LossAtt 0.2648 TrainAcc 0.8500 TestAcc 0.8338 0.8350
epoch 1600 LossPred 0.4605 LossAtt 0.2340 TrainAcc 0.8400 TestAcc 0.8208 0.8650
epoch 1700 LossPred 0.4639 LossAtt 0.2404 TrainAcc 0.8300 TestAcc 0.8188 0.8350
epoch 1800 LossPred 0.4382 LossAtt 0.2336 TrainAcc 0.8600 TestAcc 0.8391 0.8600
epoch 1900 LossPred 0.4481 LossAtt 0.2451 TrainAcc 0.8400 TestAcc 0.8338 0.8650
epoch 2000 LossPred 0.4508 LossAtt 0.2252 TrainAcc 0.8300 TestAcc 0.8308 0.8600
epoch 2100 LossPred 0.4479 LossAtt 0.2263 TrainAcc 0.8400 TestAcc 0.8348 0.8350
epoch 2200 LossPred 0.4304 LossAtt 0.2390 TrainAcc 0.8600 TestAcc 0.8448 0.8500
epoch 2300 LossPred 0.4358 LossAtt 0.2311 TrainAcc 0.8500 TestAcc 0.8436 0.8450
epoch 2400 LossPred 0.4664 LossAtt 0.2225 TrainAcc 0.8300 TestAcc 0.8316 0.8100
epoch 2500 LossPred 0.4172 LossAtt 0.2246 TrainAcc 0.8600 TestAcc 0.8411 0.8300
Optimization Finished!
********** replication  85  **********
epoch   0 LossPred 1.2859 LossAtt 1.0603 TrainAcc 0.3600 TestAcc 0.4807 0.3600
epoch 100 LossPred 1.0006 LossAtt 0.3339 TrainAcc 0.5200 TestAcc 0.4900 0.5250
epoch 200 LossPred 0.9982 LossAtt 0.2436 TrainAcc 0.5200 TestAcc 0.4900 0.5200
epoch 300 LossPred 1.0013 LossAtt 0.2277 TrainAcc 0.5200 TestAcc 0.4900 0.5200
epoch 400 LossPred 0.9988 LossAtt 0.2179 TrainAcc 0.5200 TestAcc 0.4900 0.5200
epoch 500 LossPred 0.9269 LossAtt 0.3299 TrainAcc 0.6400 TestAcc 0.5268 0.6300
epoch 600 LossPred 0.8342 LossAtt 0.3851 TrainAcc 0.6400 TestAcc 0.5285 0.6600
epoch 700 LossPred 0.7979 LossAtt 0.3667 TrainAcc 0.7200 TestAcc 0.5350 0.7050
epoch 800 LossPred 0.7882 LossAtt 0.3448 TrainAcc 0.7200 TestAcc 0.5353 0.7100
epoch 900 LossPred 0.7824 LossAtt 0.3559 TrainAcc 0.7200 TestAcc 0.5345 0.7100
epoch 1000 LossPred 0.7767 LossAtt 0.3659 TrainAcc 0.7100 TestAcc 0.5370 0.7150
epoch 1100 LossPred 0.7686 LossAtt 0.3879 TrainAcc 0.7200 TestAcc 0.5368 0.7250
epoch 1200 LossPred 0.7623 LossAtt 0.3859 TrainAcc 0.7200 TestAcc 0.5410 0.7150
epoch 1300 LossPred 0.7565 LossAtt 0.3670 TrainAcc 0.7000 TestAcc 0.5458 0.6950
epoch 1400 LossPred 0.7481 LossAtt 0.3679 TrainAcc 0.7000 TestAcc 0.5561 0.6900
epoch 1500 LossPred 0.7460 LossAtt 0.3580 TrainAcc 0.7100 TestAcc 0.5791 0.7100
epoch 1600 LossPred 0.7312 LossAtt 0.3597 TrainAcc 0.7000 TestAcc 0.5851 0.7000
epoch 1700 LossPred 0.7335 LossAtt 0.3896 TrainAcc 0.7000 TestAcc 0.5998 0.7000
epoch 1800 LossPred 0.7263 LossAtt 0.3667 TrainAcc 0.7100 TestAcc 0.5961 0.7150
epoch 1900 LossPred 0.7515 LossAtt 0.4010 TrainAcc 0.7200 TestAcc 0.6144 0.7000
epoch 2000 LossPred 0.7411 LossAtt 0.4174 TrainAcc 0.7100 TestAcc 0.6036 0.7200
epoch 2100 LossPred 0.7090 LossAtt 0.4542 TrainAcc 0.7300 TestAcc 0.6206 0.7300
epoch 2200 LossPred 0.7138 LossAtt 0.4589 TrainAcc 0.7300 TestAcc 0.6386 0.7350
epoch 2300 LossPred 0.3365 LossAtt 0.4347 TrainAcc 0.8900 TestAcc 0.8376 0.9000
epoch 2400 LossPred 0.2788 LossAtt 0.4576 TrainAcc 0.9100 TestAcc 0.8343 0.9150
epoch 2500 LossPred 0.2300 LossAtt 0.4610 TrainAcc 0.9300 TestAcc 0.8401 0.9450
Optimization Finished!
********** replication  86  **********
epoch   0 LossPred 1.0509 LossAtt 1.0200 TrainAcc 0.5200 TestAcc 0.4249 0.5050
epoch 100 LossPred 0.9265 LossAtt 0.4538 TrainAcc 0.6100 TestAcc 0.5433 0.6000
epoch 200 LossPred 0.9128 LossAtt 0.4109 TrainAcc 0.6300 TestAcc 0.5638 0.6050
epoch 300 LossPred 0.9061 LossAtt 0.4169 TrainAcc 0.6300 TestAcc 0.5638 0.6100
epoch 400 LossPred 0.8840 LossAtt 0.4238 TrainAcc 0.6300 TestAcc 0.5803 0.6500
epoch 500 LossPred 0.4891 LossAtt 0.4797 TrainAcc 0.8300 TestAcc 0.7863 0.8200
epoch 600 LossPred 0.4573 LossAtt 0.4299 TrainAcc 0.8500 TestAcc 0.7835 0.8350
epoch 700 LossPred 0.4649 LossAtt 0.4354 TrainAcc 0.8400 TestAcc 0.7793 0.8400
epoch 800 LossPred 0.4110 LossAtt 0.4147 TrainAcc 0.8700 TestAcc 0.8086 0.8650
epoch 900 LossPred 0.4132 LossAtt 0.4164 TrainAcc 0.8700 TestAcc 0.7900 0.8700
epoch 1000 LossPred 0.3755 LossAtt 0.4362 TrainAcc 0.8700 TestAcc 0.8028 0.8700
epoch 1100 LossPred 0.3729 LossAtt 0.4271 TrainAcc 0.8800 TestAcc 0.8026 0.8750
epoch 1200 LossPred 0.3498 LossAtt 0.4329 TrainAcc 0.8800 TestAcc 0.8091 0.8850
epoch 1300 LossPred 0.3517 LossAtt 0.4313 TrainAcc 0.8800 TestAcc 0.8113 0.8800
epoch 1400 LossPred 0.3478 LossAtt 0.4396 TrainAcc 0.8800 TestAcc 0.8046 0.8800
epoch 1500 LossPred 0.3336 LossAtt 0.4281 TrainAcc 0.8900 TestAcc 0.8216 0.8850
epoch 1600 LossPred 0.3707 LossAtt 0.4355 TrainAcc 0.8800 TestAcc 0.8168 0.8650
epoch 1700 LossPred 0.3202 LossAtt 0.4549 TrainAcc 0.9200 TestAcc 0.8276 0.8950
epoch 1800 LossPred 0.3398 LossAtt 0.4634 TrainAcc 0.8800 TestAcc 0.8166 0.8900
epoch 1900 LossPred 0.3054 LossAtt 0.4322 TrainAcc 0.9100 TestAcc 0.8286 0.9100
epoch 2000 LossPred 0.2850 LossAtt 0.4594 TrainAcc 0.9200 TestAcc 0.8308 0.9250
epoch 2100 LossPred 0.2711 LossAtt 0.4539 TrainAcc 0.9100 TestAcc 0.8326 0.9100
epoch 2200 LossPred 0.2542 LossAtt 0.4571 TrainAcc 0.9300 TestAcc 0.8326 0.9150
epoch 2300 LossPred 0.2659 LossAtt 0.4522 TrainAcc 0.9200 TestAcc 0.8123 0.9150
epoch 2400 LossPred 0.2770 LossAtt 0.4590 TrainAcc 0.9000 TestAcc 0.8053 0.9000
epoch 2500 LossPred 0.2196 LossAtt 0.4620 TrainAcc 0.9200 TestAcc 0.8303 0.9250
Optimization Finished!
********** replication  87  **********
epoch   0 LossPred 0.9915 LossAtt 1.0257 TrainAcc 0.6100 TestAcc 0.5465 0.5850
epoch 100 LossPred 0.8848 LossAtt 0.3803 TrainAcc 0.6500 TestAcc 0.5863 0.6500
epoch 200 LossPred 0.8720 LossAtt 0.2631 TrainAcc 0.6500 TestAcc 0.5863 0.6500
epoch 300 LossPred 0.8632 LossAtt 0.2399 TrainAcc 0.6500 TestAcc 0.5796 0.6500
epoch 400 LossPred 0.8551 LossAtt 0.2402 TrainAcc 0.6500 TestAcc 0.5796 0.6550
epoch 500 LossPred 0.8506 LossAtt 0.2853 TrainAcc 0.6400 TestAcc 0.5801 0.6400
epoch 600 LossPred 0.8457 LossAtt 0.3294 TrainAcc 0.6300 TestAcc 0.5796 0.6250
epoch 700 LossPred 0.8402 LossAtt 0.3173 TrainAcc 0.6600 TestAcc 0.5766 0.6100
epoch 800 LossPred 0.8312 LossAtt 0.3432 TrainAcc 0.6400 TestAcc 0.5708 0.6250
epoch 900 LossPred 0.8143 LossAtt 0.3756 TrainAcc 0.6700 TestAcc 0.6031 0.6500
epoch 1000 LossPred 0.7957 LossAtt 0.3631 TrainAcc 0.6900 TestAcc 0.5946 0.6550
epoch 1100 LossPred 0.7892 LossAtt 0.3711 TrainAcc 0.6800 TestAcc 0.5948 0.6650
epoch 1200 LossPred 0.8240 LossAtt 0.3419 TrainAcc 0.6800 TestAcc 0.5851 0.6500
epoch 1300 LossPred 0.8232 LossAtt 0.3393 TrainAcc 0.6700 TestAcc 0.5821 0.6550
epoch 1400 LossPred 0.8071 LossAtt 0.3416 TrainAcc 0.6800 TestAcc 0.5828 0.6600
epoch 1500 LossPred 0.7958 LossAtt 0.3731 TrainAcc 0.6800 TestAcc 0.5796 0.6350
epoch 1600 LossPred 0.8020 LossAtt 0.3358 TrainAcc 0.6900 TestAcc 0.5828 0.6500
epoch 1700 LossPred 0.8198 LossAtt 0.3614 TrainAcc 0.7000 TestAcc 0.5783 0.6350
epoch 1800 LossPred 0.7783 LossAtt 0.3586 TrainAcc 0.6700 TestAcc 0.5941 0.6700
epoch 1900 LossPred 0.7699 LossAtt 0.3882 TrainAcc 0.7000 TestAcc 0.6031 0.6700
epoch 2000 LossPred 0.7503 LossAtt 0.4079 TrainAcc 0.6700 TestAcc 0.5886 0.6700
epoch 2100 LossPred 0.7335 LossAtt 0.4411 TrainAcc 0.7000 TestAcc 0.6221 0.6850
epoch 2200 LossPred 0.7063 LossAtt 0.4371 TrainAcc 0.7300 TestAcc 0.5986 0.7200
epoch 2300 LossPred 0.6693 LossAtt 0.4999 TrainAcc 0.7500 TestAcc 0.6351 0.7550
epoch 2400 LossPred 0.4977 LossAtt 0.5493 TrainAcc 0.7900 TestAcc 0.7025 0.8050
epoch 2500 LossPred 0.6118 LossAtt 0.5773 TrainAcc 0.7700 TestAcc 0.7042 0.7650
Optimization Finished!
********** replication  88  **********
epoch   0 LossPred 1.3529 LossAtt 1.0114 TrainAcc 0.4000 TestAcc 0.4382 0.3850
epoch 100 LossPred 1.0605 LossAtt 0.5079 TrainAcc 0.4400 TestAcc 0.4572 0.4350
epoch 200 LossPred 0.9677 LossAtt 0.3989 TrainAcc 0.5200 TestAcc 0.5628 0.5450
epoch 300 LossPred 0.9290 LossAtt 0.3499 TrainAcc 0.5500 TestAcc 0.5753 0.5650
epoch 400 LossPred 0.9138 LossAtt 0.3379 TrainAcc 0.6000 TestAcc 0.5941 0.6000
epoch 500 LossPred 0.9059 LossAtt 0.3014 TrainAcc 0.6000 TestAcc 0.5956 0.6050
epoch 600 LossPred 0.8998 LossAtt 0.3269 TrainAcc 0.6000 TestAcc 0.5956 0.6050
epoch 700 LossPred 0.8558 LossAtt 0.4145 TrainAcc 0.6400 TestAcc 0.6339 0.6050
epoch 800 LossPred 0.9241 LossAtt 0.3146 TrainAcc 0.5900 TestAcc 0.6289 0.5800
epoch 900 LossPred 0.8512 LossAtt 0.3363 TrainAcc 0.6500 TestAcc 0.6854 0.6600
epoch 1000 LossPred 0.5569 LossAtt 0.3762 TrainAcc 0.8200 TestAcc 0.7695 0.8150
epoch 1100 LossPred 0.4589 LossAtt 0.3748 TrainAcc 0.8400 TestAcc 0.7608 0.8500
epoch 1200 LossPred 0.4735 LossAtt 0.3638 TrainAcc 0.8600 TestAcc 0.7915 0.8200
epoch 1300 LossPred 0.4500 LossAtt 0.3647 TrainAcc 0.8600 TestAcc 0.8003 0.8250
epoch 1400 LossPred 0.4326 LossAtt 0.3563 TrainAcc 0.8600 TestAcc 0.8043 0.8250
epoch 1500 LossPred 0.3859 LossAtt 0.3596 TrainAcc 0.9000 TestAcc 0.8091 0.8600
epoch 1600 LossPred 0.4042 LossAtt 0.3311 TrainAcc 0.8700 TestAcc 0.8143 0.8450
epoch 1700 LossPred 0.4151 LossAtt 0.3482 TrainAcc 0.8600 TestAcc 0.8126 0.8600
epoch 1800 LossPred 0.3710 LossAtt 0.3294 TrainAcc 0.8900 TestAcc 0.8221 0.8950
epoch 1900 LossPred 0.3371 LossAtt 0.3257 TrainAcc 0.9100 TestAcc 0.8243 0.8950
epoch 2000 LossPred 0.5611 LossAtt 0.3375 TrainAcc 0.7900 TestAcc 0.7955 0.8050
epoch 2100 LossPred 0.3397 LossAtt 0.3214 TrainAcc 0.8800 TestAcc 0.8321 0.9000
epoch 2200 LossPred 0.3540 LossAtt 0.3279 TrainAcc 0.9000 TestAcc 0.8293 0.8900
epoch 2300 LossPred 0.3023 LossAtt 0.3091 TrainAcc 0.9200 TestAcc 0.8353 0.8850
epoch 2400 LossPred 0.3050 LossAtt 0.3115 TrainAcc 0.8900 TestAcc 0.8373 0.9100
epoch 2500 LossPred 0.2891 LossAtt 0.2980 TrainAcc 0.9200 TestAcc 0.8393 0.8800
Optimization Finished!
********** replication  89  **********
epoch   0 LossPred 0.9974 LossAtt 0.9958 TrainAcc 0.4900 TestAcc 0.5173 0.4850
epoch 100 LossPred 0.8476 LossAtt 0.4895 TrainAcc 0.6800 TestAcc 0.5746 0.6850
epoch 200 LossPred 0.7792 LossAtt 0.4923 TrainAcc 0.7400 TestAcc 0.6286 0.7250
epoch 300 LossPred 0.6567 LossAtt 0.4698 TrainAcc 0.7700 TestAcc 0.7090 0.7650
epoch 400 LossPred 0.5997 LossAtt 0.4506 TrainAcc 0.8100 TestAcc 0.7590 0.7900
epoch 500 LossPred 0.5693 LossAtt 0.3656 TrainAcc 0.7800 TestAcc 0.8303 0.7850
epoch 600 LossPred 0.5940 LossAtt 0.3419 TrainAcc 0.7500 TestAcc 0.8058 0.7250
epoch 700 LossPred 0.5204 LossAtt 0.2923 TrainAcc 0.8400 TestAcc 0.7700 0.8300
epoch 800 LossPred 0.4323 LossAtt 0.3002 TrainAcc 0.8800 TestAcc 0.7958 0.8700
epoch 900 LossPred 0.5143 LossAtt 0.3060 TrainAcc 0.8300 TestAcc 0.8423 0.8250
epoch 1000 LossPred 0.5241 LossAtt 0.3031 TrainAcc 0.8100 TestAcc 0.8408 0.8150
epoch 1100 LossPred 0.5525 LossAtt 0.2961 TrainAcc 0.8000 TestAcc 0.8383 0.7800
epoch 1200 LossPred 0.5349 LossAtt 0.3045 TrainAcc 0.7600 TestAcc 0.7580 0.7650
epoch 1300 LossPred 0.5885 LossAtt 0.2870 TrainAcc 0.8000 TestAcc 0.7765 0.8150
epoch 1400 LossPred 0.5049 LossAtt 0.2765 TrainAcc 0.8300 TestAcc 0.8148 0.8250
epoch 1500 LossPred 0.4936 LossAtt 0.2918 TrainAcc 0.8300 TestAcc 0.7878 0.8250
epoch 1600 LossPred 0.8645 LossAtt 0.2441 TrainAcc 0.6900 TestAcc 0.6191 0.6950
epoch 1700 LossPred 0.5734 LossAtt 0.3043 TrainAcc 0.7700 TestAcc 0.8068 0.7950
epoch 1800 LossPred 0.4605 LossAtt 0.2766 TrainAcc 0.8300 TestAcc 0.8376 0.8150
epoch 1900 LossPred 0.5814 LossAtt 0.3039 TrainAcc 0.7700 TestAcc 0.8241 0.7650
epoch 2000 LossPred 0.5064 LossAtt 0.2955 TrainAcc 0.8100 TestAcc 0.8428 0.8000
epoch 2100 LossPred 0.7107 LossAtt 0.2963 TrainAcc 0.7100 TestAcc 0.7863 0.7100
epoch 2200 LossPred 0.5083 LossAtt 0.3033 TrainAcc 0.8100 TestAcc 0.8378 0.8150
epoch 2300 LossPred 0.5126 LossAtt 0.2822 TrainAcc 0.8100 TestAcc 0.8331 0.8150
epoch 2400 LossPred 0.4932 LossAtt 0.2843 TrainAcc 0.8200 TestAcc 0.8271 0.8050
epoch 2500 LossPred 0.5790 LossAtt 0.2493 TrainAcc 0.7600 TestAcc 0.8036 0.7900
Optimization Finished!
********** replication  90  **********
epoch   0 LossPred 1.2677 LossAtt 1.0045 TrainAcc 0.4400 TestAcc 0.4472 0.4650
epoch 100 LossPred 1.0182 LossAtt 0.3793 TrainAcc 0.5100 TestAcc 0.4712 0.5100
epoch 200 LossPred 0.9465 LossAtt 0.4257 TrainAcc 0.6200 TestAcc 0.5783 0.6200
epoch 300 LossPred 0.8526 LossAtt 0.4582 TrainAcc 0.7500 TestAcc 0.6592 0.7050
epoch 400 LossPred 0.4379 LossAtt 0.5248 TrainAcc 0.8600 TestAcc 0.8278 0.7950
epoch 500 LossPred 0.7298 LossAtt 0.4680 TrainAcc 0.7100 TestAcc 0.7710 0.7800
epoch 600 LossPred 0.4215 LossAtt 0.4665 TrainAcc 0.8600 TestAcc 0.8291 0.8200
epoch 700 LossPred 0.4599 LossAtt 0.4249 TrainAcc 0.8300 TestAcc 0.8216 0.8100
epoch 800 LossPred 1.1450 LossAtt 0.3441 TrainAcc 0.6100 TestAcc 0.6557 0.6350
epoch 900 LossPred 0.8305 LossAtt 0.3487 TrainAcc 0.6600 TestAcc 0.6877 0.6500
epoch 1000 LossPred 0.8447 LossAtt 0.3134 TrainAcc 0.7100 TestAcc 0.7127 0.6550
epoch 1100 LossPred 0.9289 LossAtt 0.2812 TrainAcc 0.6900 TestAcc 0.6271 0.6750
epoch 1200 LossPred 0.9067 LossAtt 0.2740 TrainAcc 0.6900 TestAcc 0.6241 0.6950
epoch 1300 LossPred 0.8933 LossAtt 0.2594 TrainAcc 0.6900 TestAcc 0.6241 0.6950
epoch 1400 LossPred 0.8875 LossAtt 0.2674 TrainAcc 0.6700 TestAcc 0.6201 0.6600
epoch 1500 LossPred 0.8849 LossAtt 0.2497 TrainAcc 0.6600 TestAcc 0.6214 0.6600
epoch 1600 LossPred 0.8809 LossAtt 0.2423 TrainAcc 0.7100 TestAcc 0.6319 0.7000
epoch 1700 LossPred 0.8775 LossAtt 0.2452 TrainAcc 0.7100 TestAcc 0.6319 0.7100
epoch 1800 LossPred 0.8735 LossAtt 0.2644 TrainAcc 0.6900 TestAcc 0.6241 0.6900
epoch 1900 LossPred 0.8687 LossAtt 0.2488 TrainAcc 0.6900 TestAcc 0.6241 0.6900
epoch 2000 LossPred 0.8659 LossAtt 0.2576 TrainAcc 0.6900 TestAcc 0.6241 0.6900
epoch 2100 LossPred 0.8601 LossAtt 0.2595 TrainAcc 0.6900 TestAcc 0.6241 0.6950
epoch 2200 LossPred 0.8536 LossAtt 0.2588 TrainAcc 0.6900 TestAcc 0.6241 0.6950
epoch 2300 LossPred 0.8506 LossAtt 0.2450 TrainAcc 0.6900 TestAcc 0.6241 0.7000
epoch 2400 LossPred 0.8441 LossAtt 0.2619 TrainAcc 0.6900 TestAcc 0.6241 0.7000
epoch 2500 LossPred 0.8364 LossAtt 0.2678 TrainAcc 0.6900 TestAcc 0.6241 0.7050
Optimization Finished!
********** replication  91  **********
epoch   0 LossPred 1.0299 LossAtt 0.9915 TrainAcc 0.4500 TestAcc 0.5013 0.4650
epoch 100 LossPred 0.9237 LossAtt 0.4650 TrainAcc 0.6000 TestAcc 0.5808 0.5850
epoch 200 LossPred 0.9060 LossAtt 0.4750 TrainAcc 0.6000 TestAcc 0.6006 0.5950
epoch 300 LossPred 0.8282 LossAtt 0.5006 TrainAcc 0.6600 TestAcc 0.6827 0.6800
epoch 400 LossPred 0.7693 LossAtt 0.4665 TrainAcc 0.7100 TestAcc 0.7665 0.7150
epoch 500 LossPred 0.7133 LossAtt 0.4432 TrainAcc 0.7400 TestAcc 0.8263 0.7250
epoch 600 LossPred 0.6758 LossAtt 0.4194 TrainAcc 0.7400 TestAcc 0.8158 0.7350
epoch 700 LossPred 0.8062 LossAtt 0.4154 TrainAcc 0.7100 TestAcc 0.7798 0.6800
epoch 800 LossPred 0.6932 LossAtt 0.4228 TrainAcc 0.7700 TestAcc 0.8146 0.7650
epoch 900 LossPred 0.7299 LossAtt 0.4313 TrainAcc 0.7400 TestAcc 0.7810 0.7500
epoch 1000 LossPred 0.6741 LossAtt 0.4520 TrainAcc 0.7500 TestAcc 0.8088 0.7500
epoch 1100 LossPred 0.8383 LossAtt 0.4327 TrainAcc 0.6800 TestAcc 0.6982 0.6750
epoch 1200 LossPred 0.6628 LossAtt 0.4615 TrainAcc 0.7400 TestAcc 0.8076 0.7400
epoch 1300 LossPred 0.6122 LossAtt 0.4754 TrainAcc 0.7900 TestAcc 0.8453 0.7550
epoch 1400 LossPred 0.7034 LossAtt 0.4352 TrainAcc 0.7300 TestAcc 0.7683 0.7400
epoch 1500 LossPred 0.9989 LossAtt 0.4784 TrainAcc 0.6000 TestAcc 0.6949 0.6150
epoch 1600 LossPred 0.7437 LossAtt 0.4345 TrainAcc 0.7400 TestAcc 0.8111 0.7400
epoch 1700 LossPred 0.8211 LossAtt 0.3876 TrainAcc 0.6800 TestAcc 0.6634 0.6750
epoch 1800 LossPred 0.7115 LossAtt 0.4602 TrainAcc 0.7300 TestAcc 0.7758 0.7350
epoch 1900 LossPred 0.7708 LossAtt 0.4652 TrainAcc 0.7300 TestAcc 0.7357 0.7050
epoch 2000 LossPred 0.6460 LossAtt 0.5083 TrainAcc 0.7900 TestAcc 0.8108 0.7750
epoch 2100 LossPred 1.0268 LossAtt 0.5101 TrainAcc 0.5400 TestAcc 0.6319 0.5350
epoch 2200 LossPred 0.8519 LossAtt 0.5182 TrainAcc 0.6300 TestAcc 0.7050 0.6550
epoch 2300 LossPred 0.6756 LossAtt 0.5304 TrainAcc 0.7400 TestAcc 0.7925 0.7750
epoch 2400 LossPred 0.5741 LossAtt 0.5104 TrainAcc 0.8600 TestAcc 0.8516 0.8050
epoch 2500 LossPred 0.5259 LossAtt 0.5135 TrainAcc 0.8600 TestAcc 0.8649 0.8250
Optimization Finished!
********** replication  92  **********
epoch   0 LossPred 1.2618 LossAtt 0.9982 TrainAcc 0.4400 TestAcc 0.4482 0.4600
epoch 100 LossPred 0.9855 LossAtt 0.3522 TrainAcc 0.5700 TestAcc 0.4880 0.5800
epoch 200 LossPred 0.9298 LossAtt 0.2870 TrainAcc 0.5700 TestAcc 0.4880 0.5850
epoch 300 LossPred 0.8648 LossAtt 0.3174 TrainAcc 0.7100 TestAcc 0.5908 0.7150
epoch 400 LossPred 1.0191 LossAtt 0.3829 TrainAcc 0.5700 TestAcc 0.4882 0.5700
epoch 500 LossPred 0.8173 LossAtt 0.3671 TrainAcc 0.6600 TestAcc 0.6096 0.6850
epoch 600 LossPred 0.9108 LossAtt 0.3724 TrainAcc 0.6300 TestAcc 0.5408 0.6200
epoch 700 LossPred 0.6374 LossAtt 0.4173 TrainAcc 0.7800 TestAcc 0.8163 0.7950
epoch 800 LossPred 0.5702 LossAtt 0.3879 TrainAcc 0.8200 TestAcc 0.8178 0.8000
epoch 900 LossPred 0.7076 LossAtt 0.4144 TrainAcc 0.7400 TestAcc 0.7703 0.7700
epoch 1000 LossPred 0.5855 LossAtt 0.4051 TrainAcc 0.8000 TestAcc 0.8301 0.8150
epoch 1100 LossPred 0.5695 LossAtt 0.4156 TrainAcc 0.8100 TestAcc 0.8173 0.7950
epoch 1200 LossPred 0.5155 LossAtt 0.3901 TrainAcc 0.8300 TestAcc 0.8173 0.7900
epoch 1300 LossPred 0.5897 LossAtt 0.4048 TrainAcc 0.7800 TestAcc 0.7860 0.7900
epoch 1400 LossPred 0.5796 LossAtt 0.4018 TrainAcc 0.7900 TestAcc 0.7868 0.7850
epoch 1500 LossPred 0.5456 LossAtt 0.4098 TrainAcc 0.8300 TestAcc 0.8068 0.8100
epoch 1600 LossPred 0.5799 LossAtt 0.4108 TrainAcc 0.7600 TestAcc 0.8233 0.7950
epoch 1700 LossPred 0.5478 LossAtt 0.4111 TrainAcc 0.8200 TestAcc 0.8138 0.7950
epoch 1800 LossPred 0.5410 LossAtt 0.3946 TrainAcc 0.8000 TestAcc 0.8046 0.7750
epoch 1900 LossPred 0.5420 LossAtt 0.3963 TrainAcc 0.8300 TestAcc 0.8121 0.8100
epoch 2000 LossPred 0.5304 LossAtt 0.4016 TrainAcc 0.8000 TestAcc 0.8171 0.7800
epoch 2100 LossPred 0.5526 LossAtt 0.3935 TrainAcc 0.8000 TestAcc 0.7963 0.8000
epoch 2200 LossPred 0.5243 LossAtt 0.3912 TrainAcc 0.8100 TestAcc 0.8056 0.7850
epoch 2300 LossPred 0.5508 LossAtt 0.3852 TrainAcc 0.7900 TestAcc 0.7965 0.7950
epoch 2400 LossPred 0.5052 LossAtt 0.4105 TrainAcc 0.8100 TestAcc 0.8086 0.8100
epoch 2500 LossPred 0.5743 LossAtt 0.3881 TrainAcc 0.8000 TestAcc 0.7623 0.8050
Optimization Finished!
********** replication  93  **********
epoch   0 LossPred 1.2172 LossAtt 1.0288 TrainAcc 0.5000 TestAcc 0.5445 0.4750
epoch 100 LossPred 1.0337 LossAtt 0.4811 TrainAcc 0.5100 TestAcc 0.5495 0.4950
epoch 200 LossPred 0.9698 LossAtt 0.4088 TrainAcc 0.5400 TestAcc 0.5506 0.5400
epoch 300 LossPred 0.9380 LossAtt 0.3805 TrainAcc 0.5900 TestAcc 0.5470 0.5800
epoch 400 LossPred 0.9232 LossAtt 0.3472 TrainAcc 0.6000 TestAcc 0.5821 0.5900
epoch 500 LossPred 0.9200 LossAtt 0.3703 TrainAcc 0.6200 TestAcc 0.5676 0.6150
epoch 600 LossPred 0.9188 LossAtt 0.3887 TrainAcc 0.5700 TestAcc 0.5501 0.5700
epoch 700 LossPred 0.9239 LossAtt 0.3282 TrainAcc 0.5800 TestAcc 0.5641 0.5900
epoch 800 LossPred 0.9251 LossAtt 0.2747 TrainAcc 0.5800 TestAcc 0.5400 0.5650
epoch 900 LossPred 0.8924 LossAtt 0.2704 TrainAcc 0.6200 TestAcc 0.5571 0.6100
epoch 1000 LossPred 0.8153 LossAtt 0.4492 TrainAcc 0.6800 TestAcc 0.6341 0.6750
epoch 1100 LossPred 0.7164 LossAtt 0.3774 TrainAcc 0.7300 TestAcc 0.6649 0.7150
epoch 1200 LossPred 0.7017 LossAtt 0.3315 TrainAcc 0.7400 TestAcc 0.6662 0.7300
epoch 1300 LossPred 0.6925 LossAtt 0.2768 TrainAcc 0.7500 TestAcc 0.6704 0.7400
epoch 1400 LossPred 0.6839 LossAtt 0.2800 TrainAcc 0.7500 TestAcc 0.6784 0.7500
epoch 1500 LossPred 0.6706 LossAtt 0.2635 TrainAcc 0.7500 TestAcc 0.6772 0.7450
epoch 1600 LossPred 0.6671 LossAtt 0.2712 TrainAcc 0.7500 TestAcc 0.6769 0.7500
epoch 1700 LossPred 0.6543 LossAtt 0.3020 TrainAcc 0.7400 TestAcc 0.6637 0.7450
epoch 1800 LossPred 0.6321 LossAtt 0.3188 TrainAcc 0.7700 TestAcc 0.6657 0.7500
epoch 1900 LossPred 0.6308 LossAtt 0.3495 TrainAcc 0.7700 TestAcc 0.6499 0.7600
epoch 2000 LossPred 0.6063 LossAtt 0.3449 TrainAcc 0.7800 TestAcc 0.6474 0.7650
epoch 2100 LossPred 0.5965 LossAtt 0.3406 TrainAcc 0.7900 TestAcc 0.6502 0.7850
epoch 2200 LossPred 0.5878 LossAtt 0.3701 TrainAcc 0.7900 TestAcc 0.6502 0.7900
epoch 2300 LossPred 0.6023 LossAtt 0.3817 TrainAcc 0.7900 TestAcc 0.6607 0.7700
epoch 2400 LossPred 0.5765 LossAtt 0.3881 TrainAcc 0.8300 TestAcc 0.6564 0.8100
epoch 2500 LossPred 0.5739 LossAtt 0.3820 TrainAcc 0.8300 TestAcc 0.6549 0.8250
Optimization Finished!
********** replication  94  **********
epoch   0 LossPred 1.0443 LossAtt 0.9853 TrainAcc 0.4900 TestAcc 0.4409 0.4850
epoch 100 LossPred 0.9368 LossAtt 0.4354 TrainAcc 0.5800 TestAcc 0.5015 0.5600
epoch 200 LossPred 0.9082 LossAtt 0.4255 TrainAcc 0.6100 TestAcc 0.5408 0.5950
epoch 300 LossPred 0.8813 LossAtt 0.4618 TrainAcc 0.5900 TestAcc 0.5430 0.5650
epoch 400 LossPred 0.8713 LossAtt 0.3648 TrainAcc 0.6100 TestAcc 0.5318 0.6050
epoch 500 LossPred 0.8619 LossAtt 0.3508 TrainAcc 0.6300 TestAcc 0.5313 0.6150
epoch 600 LossPred 0.8549 LossAtt 0.3647 TrainAcc 0.6300 TestAcc 0.5330 0.5950
epoch 700 LossPred 0.8404 LossAtt 0.3627 TrainAcc 0.6300 TestAcc 0.5485 0.6550
epoch 800 LossPred 0.8314 LossAtt 0.3892 TrainAcc 0.6700 TestAcc 0.5498 0.6700
epoch 900 LossPred 0.8153 LossAtt 0.4360 TrainAcc 0.6700 TestAcc 0.5373 0.6500
epoch 1000 LossPred 0.7747 LossAtt 0.5069 TrainAcc 0.7400 TestAcc 0.5485 0.7150
epoch 1100 LossPred 0.7180 LossAtt 0.5406 TrainAcc 0.7400 TestAcc 0.5410 0.7100
epoch 1200 LossPred 0.7032 LossAtt 0.5319 TrainAcc 0.7400 TestAcc 0.5498 0.7400
epoch 1300 LossPred 0.7066 LossAtt 0.5247 TrainAcc 0.7600 TestAcc 0.5415 0.7600
epoch 1400 LossPred 0.6975 LossAtt 0.5510 TrainAcc 0.7500 TestAcc 0.5370 0.7450
epoch 1500 LossPred 0.7830 LossAtt 0.5642 TrainAcc 0.6900 TestAcc 0.5458 0.7200
epoch 1600 LossPred 0.7224 LossAtt 0.5468 TrainAcc 0.7500 TestAcc 0.5420 0.7350
epoch 1700 LossPred 0.7000 LossAtt 0.5207 TrainAcc 0.7500 TestAcc 0.5335 0.7200
epoch 1800 LossPred 0.6798 LossAtt 0.5510 TrainAcc 0.7900 TestAcc 0.5343 0.7300
epoch 1900 LossPred 0.6371 LossAtt 0.5289 TrainAcc 0.8200 TestAcc 0.5320 0.7350
epoch 2000 LossPred 0.6488 LossAtt 0.5332 TrainAcc 0.7800 TestAcc 0.5355 0.7300
epoch 2100 LossPred 0.6262 LossAtt 0.5318 TrainAcc 0.8000 TestAcc 0.5350 0.7450
epoch 2200 LossPred 0.6140 LossAtt 0.5307 TrainAcc 0.8100 TestAcc 0.5348 0.7400
epoch 2300 LossPred 0.6145 LossAtt 0.5195 TrainAcc 0.8100 TestAcc 0.5285 0.7300
epoch 2400 LossPred 0.6162 LossAtt 0.5319 TrainAcc 0.8000 TestAcc 0.5300 0.7550
epoch 2500 LossPred 0.6176 LossAtt 0.5506 TrainAcc 0.7900 TestAcc 0.5383 0.7200
Optimization Finished!
********** replication  95  **********
epoch   0 LossPred 1.1391 LossAtt 0.9917 TrainAcc 0.3900 TestAcc 0.4720 0.3800
epoch 100 LossPred 0.8934 LossAtt 0.3411 TrainAcc 0.6600 TestAcc 0.5806 0.6600
epoch 200 LossPred 0.8771 LossAtt 0.1823 TrainAcc 0.6600 TestAcc 0.5806 0.6600
epoch 300 LossPred 0.8811 LossAtt 0.2283 TrainAcc 0.6600 TestAcc 0.5806 0.6600
epoch 400 LossPred 0.8759 LossAtt 0.2327 TrainAcc 0.6600 TestAcc 0.5806 0.6600
epoch 500 LossPred 0.8566 LossAtt 0.2352 TrainAcc 0.6600 TestAcc 0.5806 0.6600
epoch 600 LossPred 0.7889 LossAtt 0.3065 TrainAcc 0.6900 TestAcc 0.6627 0.7000
epoch 700 LossPred 0.8286 LossAtt 0.2874 TrainAcc 0.6800 TestAcc 0.6299 0.6700
epoch 800 LossPred 0.7429 LossAtt 0.2768 TrainAcc 0.7200 TestAcc 0.6639 0.7250
epoch 900 LossPred 0.7385 LossAtt 0.2614 TrainAcc 0.7100 TestAcc 0.6609 0.7100
epoch 1000 LossPred 0.7038 LossAtt 0.2409 TrainAcc 0.7400 TestAcc 0.6684 0.7300
epoch 1100 LossPred 0.8217 LossAtt 0.2171 TrainAcc 0.6900 TestAcc 0.6481 0.6850
epoch 1200 LossPred 0.8371 LossAtt 0.2063 TrainAcc 0.5800 TestAcc 0.5601 0.6100
epoch 1300 LossPred 0.6876 LossAtt 0.2102 TrainAcc 0.7100 TestAcc 0.6284 0.6950
epoch 1400 LossPred 0.8813 LossAtt 0.1759 TrainAcc 0.6600 TestAcc 0.5993 0.6650
epoch 1500 LossPred 0.8700 LossAtt 0.1773 TrainAcc 0.6600 TestAcc 0.6061 0.6700
epoch 1600 LossPred 0.7292 LossAtt 0.1919 TrainAcc 0.7200 TestAcc 0.6424 0.7100
epoch 1700 LossPred 0.6793 LossAtt 0.1940 TrainAcc 0.7400 TestAcc 0.6577 0.7400
epoch 1800 LossPred 0.7143 LossAtt 0.1700 TrainAcc 0.7100 TestAcc 0.6557 0.7150
epoch 1900 LossPred 0.7241 LossAtt 0.1867 TrainAcc 0.7100 TestAcc 0.6529 0.7200
epoch 2000 LossPred 1.0034 LossAtt 0.1558 TrainAcc 0.6200 TestAcc 0.6061 0.6250
epoch 2100 LossPred 0.8643 LossAtt 0.1652 TrainAcc 0.6300 TestAcc 0.6064 0.6350
epoch 2200 LossPred 0.8528 LossAtt 0.1500 TrainAcc 0.6100 TestAcc 0.6224 0.6300
epoch 2300 LossPred 0.8548 LossAtt 0.1580 TrainAcc 0.6300 TestAcc 0.6174 0.6200
epoch 2400 LossPred 0.8528 LossAtt 0.1500 TrainAcc 0.6500 TestAcc 0.6106 0.6600
epoch 2500 LossPred 0.8536 LossAtt 0.1491 TrainAcc 0.6100 TestAcc 0.6216 0.5800
Optimization Finished!
********** replication  96  **********
epoch   0 LossPred 1.0779 LossAtt 0.9993 TrainAcc 0.4900 TestAcc 0.5075 0.4950
epoch 100 LossPred 0.9429 LossAtt 0.4414 TrainAcc 0.5800 TestAcc 0.5223 0.6150
epoch 200 LossPred 0.9084 LossAtt 0.4783 TrainAcc 0.6500 TestAcc 0.5483 0.6500
epoch 300 LossPred 0.8833 LossAtt 0.4213 TrainAcc 0.6600 TestAcc 0.5556 0.6700
epoch 400 LossPred 0.8533 LossAtt 0.3813 TrainAcc 0.6600 TestAcc 0.5556 0.6850
epoch 500 LossPred 0.8207 LossAtt 0.4262 TrainAcc 0.7100 TestAcc 0.5641 0.7000
epoch 600 LossPred 0.8031 LossAtt 0.4100 TrainAcc 0.7100 TestAcc 0.5603 0.6900
epoch 700 LossPred 0.8026 LossAtt 0.3905 TrainAcc 0.6900 TestAcc 0.5480 0.6650
epoch 800 LossPred 0.7052 LossAtt 0.4334 TrainAcc 0.7600 TestAcc 0.5533 0.7300
epoch 900 LossPred 0.6682 LossAtt 0.4511 TrainAcc 0.7600 TestAcc 0.5443 0.7550
epoch 1000 LossPred 0.6698 LossAtt 0.4708 TrainAcc 0.7600 TestAcc 0.5418 0.7400
epoch 1100 LossPred 0.7185 LossAtt 0.5374 TrainAcc 0.7100 TestAcc 0.5430 0.7550
epoch 1200 LossPred 0.6684 LossAtt 0.5171 TrainAcc 0.8000 TestAcc 0.5388 0.7200
epoch 1300 LossPred 0.6294 LossAtt 0.5023 TrainAcc 0.7700 TestAcc 0.5393 0.7250
epoch 1400 LossPred 0.6228 LossAtt 0.4866 TrainAcc 0.7700 TestAcc 0.5410 0.7300
epoch 1500 LossPred 0.6073 LossAtt 0.4796 TrainAcc 0.7700 TestAcc 0.5493 0.7250
epoch 1600 LossPred 0.5827 LossAtt 0.4881 TrainAcc 0.8000 TestAcc 0.5408 0.7450
epoch 1700 LossPred 0.5830 LossAtt 0.4729 TrainAcc 0.7800 TestAcc 0.5408 0.7250
epoch 1800 LossPred 0.6077 LossAtt 0.4592 TrainAcc 0.7900 TestAcc 0.5388 0.7150
epoch 1900 LossPred 0.6255 LossAtt 0.4595 TrainAcc 0.7700 TestAcc 0.5305 0.7050
epoch 2000 LossPred 0.6352 LossAtt 0.4495 TrainAcc 0.7800 TestAcc 0.5323 0.7050
epoch 2100 LossPred 0.6102 LossAtt 0.4546 TrainAcc 0.7800 TestAcc 0.5435 0.7400
epoch 2200 LossPred 0.5923 LossAtt 0.4524 TrainAcc 0.8000 TestAcc 0.5348 0.7250
epoch 2300 LossPred 0.5876 LossAtt 0.4496 TrainAcc 0.7800 TestAcc 0.5443 0.7500
epoch 2400 LossPred 0.5725 LossAtt 0.4446 TrainAcc 0.8000 TestAcc 0.5365 0.7650
epoch 2500 LossPred 0.5819 LossAtt 0.4472 TrainAcc 0.7900 TestAcc 0.5458 0.7650
Optimization Finished!
********** replication  97  **********
epoch   0 LossPred 1.0232 LossAtt 0.9980 TrainAcc 0.5500 TestAcc 0.5430 0.5350
epoch 100 LossPred 0.9460 LossAtt 0.3390 TrainAcc 0.5600 TestAcc 0.5551 0.5350
epoch 200 LossPred 0.9302 LossAtt 0.2585 TrainAcc 0.6100 TestAcc 0.5886 0.6200
epoch 300 LossPred 0.9234 LossAtt 0.2525 TrainAcc 0.6100 TestAcc 0.5886 0.6100
epoch 400 LossPred 0.9202 LossAtt 0.2750 TrainAcc 0.6100 TestAcc 0.5886 0.6100
epoch 500 LossPred 0.8899 LossAtt 0.2099 TrainAcc 0.6400 TestAcc 0.5741 0.6400
epoch 600 LossPred 0.9173 LossAtt 0.2563 TrainAcc 0.6100 TestAcc 0.5886 0.6100
epoch 700 LossPred 0.8932 LossAtt 0.2046 TrainAcc 0.6400 TestAcc 0.5741 0.6400
epoch 800 LossPred 0.8898 LossAtt 0.1835 TrainAcc 0.6400 TestAcc 0.5741 0.6400
epoch 900 LossPred 0.8888 LossAtt 0.1729 TrainAcc 0.6400 TestAcc 0.5741 0.6400
epoch 1000 LossPred 0.8912 LossAtt 0.1758 TrainAcc 0.6400 TestAcc 0.5741 0.6400
epoch 1100 LossPred 0.8923 LossAtt 0.1248 TrainAcc 0.6400 TestAcc 0.5741 0.6400
epoch 1200 LossPred 0.9123 LossAtt 0.1864 TrainAcc 0.6000 TestAcc 0.6121 0.6050
epoch 1300 LossPred 0.8909 LossAtt 0.1780 TrainAcc 0.6300 TestAcc 0.5976 0.6300
epoch 1400 LossPred 0.8854 LossAtt 0.1833 TrainAcc 0.6400 TestAcc 0.5741 0.6400
epoch 1500 LossPred 0.8465 LossAtt 0.2458 TrainAcc 0.6800 TestAcc 0.6001 0.6850
epoch 1600 LossPred 0.5246 LossAtt 0.4193 TrainAcc 0.8200 TestAcc 0.7583 0.8150
epoch 1700 LossPred 0.4639 LossAtt 0.4107 TrainAcc 0.8500 TestAcc 0.7785 0.8350
epoch 1800 LossPred 0.4564 LossAtt 0.4114 TrainAcc 0.8500 TestAcc 0.7820 0.8250
epoch 1900 LossPred 0.4662 LossAtt 0.4330 TrainAcc 0.8400 TestAcc 0.7765 0.8300
epoch 2000 LossPred 0.4278 LossAtt 0.4118 TrainAcc 0.8400 TestAcc 0.8163 0.8350
epoch 2100 LossPred 0.4288 LossAtt 0.4197 TrainAcc 0.8700 TestAcc 0.7998 0.8300
epoch 2200 LossPred 0.5009 LossAtt 0.4778 TrainAcc 0.8000 TestAcc 0.7740 0.7950
epoch 2300 LossPred 0.2714 LossAtt 0.4779 TrainAcc 0.9300 TestAcc 0.8098 0.8800
epoch 2400 LossPred 0.3272 LossAtt 0.5016 TrainAcc 0.9200 TestAcc 0.7893 0.8750
epoch 2500 LossPred 0.2343 LossAtt 0.4811 TrainAcc 0.9500 TestAcc 0.8141 0.8900
Optimization Finished!
********** replication  98  **********
epoch   0 LossPred 0.9954 LossAtt 1.0031 TrainAcc 0.6100 TestAcc 0.4915 0.5950
epoch 100 LossPred 0.9187 LossAtt 0.4680 TrainAcc 0.6500 TestAcc 0.5483 0.6350
epoch 200 LossPred 0.9110 LossAtt 0.4584 TrainAcc 0.6400 TestAcc 0.5325 0.6400
epoch 300 LossPred 0.9092 LossAtt 0.4456 TrainAcc 0.6600 TestAcc 0.5340 0.6600
epoch 400 LossPred 0.9051 LossAtt 0.4108 TrainAcc 0.6600 TestAcc 0.5413 0.6550
epoch 500 LossPred 0.9001 LossAtt 0.3755 TrainAcc 0.6700 TestAcc 0.5438 0.6700
epoch 600 LossPred 0.8938 LossAtt 0.3621 TrainAcc 0.6600 TestAcc 0.5445 0.6650
epoch 700 LossPred 0.8712 LossAtt 0.4254 TrainAcc 0.6700 TestAcc 0.5403 0.6650
epoch 800 LossPred 0.8329 LossAtt 0.4682 TrainAcc 0.7000 TestAcc 0.5558 0.6750
epoch 900 LossPred 0.8562 LossAtt 0.5243 TrainAcc 0.6600 TestAcc 0.5358 0.6950
epoch 1000 LossPred 0.8529 LossAtt 0.3931 TrainAcc 0.6600 TestAcc 0.5435 0.6600
epoch 1100 LossPred 0.8439 LossAtt 0.3642 TrainAcc 0.6800 TestAcc 0.5353 0.6700
epoch 1200 LossPred 0.8448 LossAtt 0.3854 TrainAcc 0.6800 TestAcc 0.5350 0.6650
epoch 1300 LossPred 0.8439 LossAtt 0.3621 TrainAcc 0.6800 TestAcc 0.5373 0.6700
epoch 1400 LossPred 0.8389 LossAtt 0.3726 TrainAcc 0.6800 TestAcc 0.5370 0.6650
epoch 1500 LossPred 0.8379 LossAtt 0.3516 TrainAcc 0.6800 TestAcc 0.5375 0.6650
epoch 1600 LossPred 0.8319 LossAtt 0.3382 TrainAcc 0.6800 TestAcc 0.5358 0.6600
epoch 1700 LossPred 0.8292 LossAtt 0.3321 TrainAcc 0.6800 TestAcc 0.5368 0.6750
epoch 1800 LossPred 0.8219 LossAtt 0.3238 TrainAcc 0.6800 TestAcc 0.5385 0.6800
epoch 1900 LossPred 0.8186 LossAtt 0.3315 TrainAcc 0.6900 TestAcc 0.5425 0.6750
epoch 2000 LossPred 0.8179 LossAtt 0.3345 TrainAcc 0.6900 TestAcc 0.5423 0.6750
epoch 2100 LossPred 0.8174 LossAtt 0.3318 TrainAcc 0.6900 TestAcc 0.5408 0.6750
epoch 2200 LossPred 0.8155 LossAtt 0.3345 TrainAcc 0.6900 TestAcc 0.5393 0.6750
epoch 2300 LossPred 0.8140 LossAtt 0.3433 TrainAcc 0.7000 TestAcc 0.5405 0.6800
epoch 2400 LossPred 0.8137 LossAtt 0.3456 TrainAcc 0.7000 TestAcc 0.5373 0.6750
epoch 2500 LossPred 0.8116 LossAtt 0.3471 TrainAcc 0.7000 TestAcc 0.5390 0.6750
Optimization Finished!
********** replication  99  **********
epoch   0 LossPred 1.0069 LossAtt 1.0174 TrainAcc 0.5500 TestAcc 0.4980 0.5400
epoch 100 LossPred 0.9705 LossAtt 0.2997 TrainAcc 0.5700 TestAcc 0.5843 0.5600
epoch 200 LossPred 0.9700 LossAtt 0.2493 TrainAcc 0.5700 TestAcc 0.5843 0.5600
epoch 300 LossPred 0.9703 LossAtt 0.1595 TrainAcc 0.5700 TestAcc 0.5843 0.5600
epoch 400 LossPred 0.9711 LossAtt 0.1369 TrainAcc 0.5700 TestAcc 0.5843 0.5600
epoch 500 LossPred 0.9779 LossAtt 0.1071 TrainAcc 0.5500 TestAcc 0.5048 0.5500
epoch 600 LossPred 0.9854 LossAtt 0.0797 TrainAcc 0.5500 TestAcc 0.5048 0.5500
epoch 700 LossPred 0.9861 LossAtt 0.1095 TrainAcc 0.5500 TestAcc 0.5048 0.5500
epoch 800 LossPred 0.9859 LossAtt 0.1139 TrainAcc 0.5500 TestAcc 0.5048 0.5500
epoch 900 LossPred 0.9829 LossAtt 0.1127 TrainAcc 0.5500 TestAcc 0.5048 0.5500
epoch 1000 LossPred 0.9031 LossAtt 0.3127 TrainAcc 0.6300 TestAcc 0.6792 0.6200
epoch 1100 LossPred 0.3783 LossAtt 0.3638 TrainAcc 0.8900 TestAcc 0.8496 0.9350
epoch 1200 LossPred 0.3407 LossAtt 0.3648 TrainAcc 0.9100 TestAcc 0.8516 0.9300
epoch 1300 LossPred 0.3740 LossAtt 0.3496 TrainAcc 0.9000 TestAcc 0.7980 0.8600
epoch 1400 LossPred 0.3223 LossAtt 0.3595 TrainAcc 0.9000 TestAcc 0.8138 0.9050
epoch 1500 LossPred 0.3647 LossAtt 0.3683 TrainAcc 0.8800 TestAcc 0.8506 0.8600
epoch 1600 LossPred 0.2877 LossAtt 0.3640 TrainAcc 0.9200 TestAcc 0.8661 0.9300
epoch 1700 LossPred 0.2691 LossAtt 0.3599 TrainAcc 0.9200 TestAcc 0.8283 0.9100
epoch 1800 LossPred 0.2585 LossAtt 0.3670 TrainAcc 0.9400 TestAcc 0.8744 0.9250
epoch 1900 LossPred 0.2386 LossAtt 0.3660 TrainAcc 0.9300 TestAcc 0.8754 0.9500
epoch 2000 LossPred 0.2430 LossAtt 0.3618 TrainAcc 0.9400 TestAcc 0.8386 0.9050
epoch 2100 LossPred 0.2129 LossAtt 0.3738 TrainAcc 0.9400 TestAcc 0.8461 0.9300
epoch 2200 LossPred 0.2298 LossAtt 0.3670 TrainAcc 0.9400 TestAcc 0.8486 0.9100
epoch 2300 LossPred 0.2184 LossAtt 0.3762 TrainAcc 0.9400 TestAcc 0.8566 0.9500
epoch 2400 LossPred 0.2398 LossAtt 0.3667 TrainAcc 0.9200 TestAcc 0.8716 0.9300
epoch 2500 LossPred 0.4089 LossAtt 0.3710 TrainAcc 0.8600 TestAcc 0.7995 0.8600
Optimization Finished!
********************************************************************
Namespace(arch='tanh', batch_size=256, display_epoch=100, input_noise_level=0.15, latent_attractor_space=True, loss_switch_frequency=0, lrate_attractor=0.002, lrate_prediction=0.002, lrate_wt_penalty=0.0, n_attractor_hidden=10, n_attractor_steps=15, n_hidden=5, n_replications=100, noise_level=0.5, report_best_train_performance=True, seq_len=25, task='majority', train_attr_weights_on_prediction=False, training_epochs=2500)
********************************************************************
mean train accuracy 0.8598
indiv runs  [0.89, 0.9, 0.71, 0.91, 0.77, 0.92, 0.7, 0.96, 0.92, 0.77, 0.92, 0.92, 0.75, 0.75, 0.93, 0.87, 0.69, 0.93, 0.66, 0.88, 0.88, 0.9, 0.88, 0.93, 0.91, 0.87, 0.61, 0.68, 0.85, 0.85, 0.92, 0.82, 0.89, 0.95, 0.94, 0.86, 0.97, 0.87, 0.95, 0.95, 0.84, 0.89, 0.94, 0.96, 0.74, 0.89, 0.94, 0.65, 0.74, 0.81, 0.9, 0.91, 0.87, 0.95, 0.62, 0.83, 0.87, 0.83, 0.94, 0.99, 0.97, 0.96, 0.98, 0.99, 0.96, 0.71, 0.93, 0.9, 0.85, 0.9, 0.86, 0.73, 0.89, 0.88, 0.94, 0.8, 0.89, 0.88, 0.79, 0.92, 0.85, 0.84, 0.66, 0.92, 0.86, 0.93, 0.93, 0.79, 0.92, 0.88, 0.86, 0.86, 0.83, 0.83, 0.82, 0.74, 0.8, 0.95, 0.7, 0.94]
mean epoch nan
indiv epochs  []
test1 accuracy mean  0.76643145  median  0.81431437
test2 accuracy mean  0.8302501  median  0.85
test1 indiv runs  [0.8080581, 0.8208208, 0.537037, 0.8360861, 0.6491491, 0.8145646, 0.5235235, 0.8846346, 0.8295796, 0.5875876, 0.8453453, 0.8708709, 0.5427928, 0.6341341, 0.8621121, 0.7945445, 0.5555556, 0.8616116, 0.5878378, 0.7897898, 0.7822823, 0.7672673, 0.8733734, 0.8470971, 0.9004004, 0.8005506, 0.5425425, 0.5513013, 0.8083083, 0.8268268, 0.8511011, 0.5545546, 0.7932933, 0.8285786, 0.8808809, 0.8065566, 0.8956456, 0.7675175, 0.8876376, 0.8623624, 0.8250751, 0.8503504, 0.8798799, 0.8533534, 0.6043544, 0.8105606, 0.8230731, 0.538038, 0.5863363, 0.7875375, 0.6996997, 0.8215716, 0.8338338, 0.8303303, 0.5820821, 0.8275776, 0.8193193, 0.7002002, 0.8473473, 0.8691191, 0.9196697, 0.9069069, 0.8468468, 0.8876376, 0.8393393, 0.5743243, 0.8936436, 0.8896396, 0.7872873, 0.8058058, 0.786036, 0.5252753, 0.7572573, 0.8450951, 0.8040541, 0.5117618, 0.8138138, 0.8233233, 0.715966, 0.8420921, 0.7957958, 0.8023023, 0.6111111, 0.8333333, 0.8285786, 0.8400901, 0.8325826, 0.7024525, 0.8353353, 0.7957958, 0.8278278, 0.8516016, 0.8173173, 0.6564064, 0.532032, 0.6684184, 0.5387888, 0.8140641, 0.5558058, 0.8743744]
test2 indiv runs  [0.87, 0.84, 0.685, 0.875, 0.73, 0.88, 0.67, 0.935, 0.905, 0.735, 0.885, 0.895, 0.715, 0.74, 0.905, 0.845, 0.675, 0.885, 0.665, 0.865, 0.87, 0.865, 0.85, 0.86, 0.92, 0.83, 0.56, 0.665, 0.825, 0.83, 0.875, 0.72, 0.825, 0.93, 0.905, 0.835, 0.96, 0.835, 0.89, 0.93, 0.81, 0.85, 0.92, 0.94, 0.74, 0.855, 0.905, 0.635, 0.74, 0.8, 0.835, 0.885, 0.85, 0.91, 0.62, 0.81, 0.805, 0.77, 0.92, 0.97, 0.93, 0.92, 0.955, 0.95, 0.935, 0.73, 0.91, 0.86, 0.85, 0.85, 0.85, 0.715, 0.855, 0.87, 0.9, 0.76, 0.805, 0.88, 0.765, 0.88, 0.835, 0.775, 0.65, 0.905, 0.845, 0.945, 0.915, 0.805, 0.885, 0.87, 0.795, 0.805, 0.79, 0.81, 0.735, 0.73, 0.72, 0.89, 0.675, 0.925]
