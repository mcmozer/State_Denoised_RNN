#!/bin/csh


foreach x ( 11 17 23 29 35 ) 
   # RNN
   python rnn_attr.py -seq_len $x -task majority -display_epoch 100 -training_epochs 2500 -n_replications 200 -lrate_prediction .002 -arch tanh -latent_attractor_space -n_hidden 10 -n_attractor_hidden 20 -input_noise_level 0.15 -loss_switch_frequency 0 -report_best_train_performance -batch_size 256 -noise_level .250 -lrate_attractor .000 -n_attractor_steps 0 > rnn_${x}.out

   # SDPRNN (state denoise RNN with attractors also trained on prediction task)
   python rnn_attr.py -seq_len $x -task majority -display_epoch 100 -training_epochs 2500 -n_replications 100 -lrate_prediction .002 -arch tanh -latent_attractor_space -n_hidden 10 -n_attractor_hidden 20 -input_noise_level 0.15 -loss_switch_frequency 0 -report_best_train_performance -batch_size 256 -noise_level .250 -lrate_attractor .002 -n_attractor_steps 5 -train_attr_weights_on_prediction > sdprnn_${x}.out

   # RNN-A (RNN + attractor net trained only on prediction task)
   python rnn_attr.py -seq_len $x -task majority -display_epoch 100 -training_epochs 2500 -n_replications 100 -lrate_prediction .002 -arch tanh -latent_attractor_space -n_hidden 10 -n_attractor_hidden 20 -input_noise_level 0.15 -loss_switch_frequency 0 -report_best_train_performance -batch_size 256 -noise_level .250 -lrate_attractor .0 -n_attractor_steps 5 -train_attr_weights_on_prediction > rnna_${x}.out
end
